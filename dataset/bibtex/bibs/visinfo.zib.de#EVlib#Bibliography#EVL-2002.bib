%%% ----------------------------------------------------------------------
%%% BibTeX-file {
%%%    author	 = "{Electronic Visualization Library Service}",
%%%    filename  = "EVL-2002.bib",
%%%    address   = "Konrad-Zuse-Zentrum f{\"u}r
%%%                 Informationstechnik Berlin (ZIB)
%%%                 Scientific Visualization Department
%%%                 Takustr. 7
%%%                 14195 Berlin
%%%                 Germany",
%%%    URL       = "http://visinfo.zib.de/EVlib/",
%%%    email     = "davis@zib.de",
%%%    supported = "yes",
%%%    docstring = "This file contains the complete bibliography of
%%%                 references submitted to the 
%%%                 Electronic Visualization Library for the year 2002.",
%%% }


@InProceedings{EVL-2002-1,
  year =         "2002",
  title =        "Glyph Representation of Texture Properties",
  author =       "S. Battiato and G. Gallo and S. Nicotra",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-1",
  abstract =     "A novel approach to visually represent perceptual
                 features of textures is proposed and analysed. This
                 approach combines statistical properties of the texture
                 together with qualitative measures coming from human
                 perception. Quantitative measures, coming from
                 co-occurrence analysis, have been in turn visually
                 represented using an effective iconic representation,
                 producing an immediate and easy tool to discriminate a
                 texture from a larger set. Such a representation is
                 very effective to formulate approximate queries to a
                 database of textures for similarity based",
  editor =       "V. Skala",
  keywords =     "Texture perception, iconic representation, scientific
                 visualization",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-10,
  year =         "2002",
  title =        "Shape Invariants and Principal Directions from 3{D}
                 Points and Normals",
  author =       "G. Kamberov and G. Kamberov",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-10",
  abstract =     "A new technique for computing the differential
                 invariants of a surface from 3D sample points and
                 normals is presented. It is based on a new conformal
                 geometric approach to computing shape invariants
                 directly from the Gauss map. In the current
                 implementation we compute the mean curvature, the Gauss
                 curvature, and the principal curvature axes at 3D
                 points reconstructed by area-based stereo. The
                 differential invariants are computed directly from the
                 points and the normals without prior recovery of a 3D
                 surface model and an approximate surface
                 parameterization. The technique is stable
                 computationally.",
  editor =       "V. Skala",
  keywords =     "Shape, mean curvature, Gauss curvature, principal
                 directions",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-100,
  year =         "2002",
  title =        "Reconstruction Filters for Bump Mapping",
  author =       "A. Hast and T. Barrera and E. Bengtsson",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-100",
  abstract =     "Textures that are magnified appears jagged, and
                 therefore reconstruction filters using linear or cubic
                 interpolation polynomials are often used to reduce
                 aliasing. The same aliasing problem is noticed for bump
                 mapping, where it is often solved by bilinear
                 interpolation of the height map, in order to obtain
                 intermediate values. Low-pass filtering of the height
                 map is not suitable for the magnification problem since
                 it will suppress the bumps. It will be shown that
                 reconstruction filters can be used to interpolate
                 gradients, rather than height values directly. The goal
                 is to produce non jagged bumps, without removing high
                 frequency details by low-pass filtering.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Bump Mapping, Antialiasing, Reconstruction filters",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-101,
  year =         "2002",
  title =        "An Approach for a Campus Visualization System",
  author =       "B. Hetze and G. H{\"{u}}bsch and H. Kohlschmidt",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-101",
  abstract =     "Intense work is spent especially in the fields of city
                 planning and tourist information to examine
                 possibilities for combining generic information with
                 graphic data to enhance computer based information desk
                 systems. This article presents an approach towards the
                 creation of a campus information system. This campus
                 information system shall allow the user to navigate and
                 select information with the help of a User Interface
                 that integrates possibilities to use 2D and 3D
                 interaction concepts simultaneously. The VR entities
                 are accessed by user interaction via the render
                 window.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Visualisation, desktop VR, interaction techniques, 3D
                 Modelling, VR walk through, computer graphics",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-102,
  year =         "2002",
  title =        "Classification of Systems for Simulation and
                 Visualization of Physical Phenomena",
  author =       "J. Chludil and J. Zara",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-102",
  abstract =     "The paper provides an overview and a comparison of
                 several tools for visualization of physical
                 simulations. We concentrate on new visualization tools
                 and architectures that have been developed during last
                 years (VRToolBox, VRML + Java, etc.). Classification of
                 these approaches is presented together with practical
                 examples including authors? subjective opinion. This
                 overview has been prepared with respect to
                 visualization in three-dimensional virtual
                 environments.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Physical Simulation, Visualization, Virtual
                 Environment",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-103,
  year =         "2002",
  title =        "Rule-Based Modeling for 3{D} {GIS}",
  author =       "S.-S. Kim and S.-H. Lee and J-H. Park and Y.-K. Yang",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-103",
  abstract =     "One popular approach for modeling 3D geo-features is
                 to create 3D CAD model manually. In particular, manual
                 3D geo-feature modeling approach provides a high
                 quality of visualization for 3D GIS features. However,
                 this approach can be time consuming to generate 3D
                 models being created manually and requires high costs.
                 We introduce a novel modeling concept; so-called,
                 Rule-based modeling (RBD) that can model 3D
                 geo-features using 2D profiles and 3D feature
                 attributes. By using rule-based engine and model
                 library, we are able to create 3D geo-features
                 automatically. The RBD component combines a synthetic
                 modeler with efficient LOD (level-of-detail) control
                 for real-time rendering. In addition to, describing the
                 details of our component, we present the comparison
                 result between manual modeling and proposed rule-based
                 modeling in terms of the following criteria: input data
                 domain, interoperability, reusability and modeling
                 cost.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "3D GIS, geometric modeling, data reuse, software
                 components",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-104,
  year =         "2002",
  title =        "Architecture of System for Configurable {GIS} Data
                 Compression",
  author =       "J. Komzak and P. Slavik",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-104",
  abstract =     "The paper deals with formal description of data
                 transformation (compression and decompression process).
                 An adaptive compression tool for different data types
                 (both raster and vector), that is based on finite
                 automata, is introduced. When using distributed
                 geographic information system (GIS), data of different
                 types has to be transmitted. The introduced tool
                 enables flexible changes of compression method and
                 selective loss control during compression process.
                 Finite automata are discussed for several dictionary
                 and other string-based compression methods. Application
                 of one dimensional compression methods in the field of
                 computer graphics is discussed.",
  editor =       "V. Skala",
  keywords =     "Compression, geographic information system, flexible
                 tools, finite automaton, selective compression,
                 adaptive compression, multidimensional compression,
                 lossy compression, LZW, RLC",
  volume =       "10(3)",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-105,
  year =         "2002",
  title =        "Ambiguous Digitizations by Dilation",
  author =       "C. Lincke and C. A. W{\"{u}}thrich",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-105",
  abstract =     "This article deals with ambiguous surface
                 digitizations by dilation in n-dimensional space. The
                 digitization of a sufficiently regular surface is
                 separating but not necessarily minimal. We will
                 determine conditions under which the supercover and the
                 grid intersection digitizations are discrete surfaces.
                 It will also be proven that non-overlapping domains do
                 not solve the problem of simple point in digitizations.
                 No matter how the digitization domain is chosen there
                 will will occur ambiguous cases which have to be
                 treated differently.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "N-dimensional raster graphics, digitization, discrete
                 surfaces, simple points",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-106,
  year =         "2002",
  title =        "Camera Calibration Using Neural Network",
  author =       "M. Mendon{\c{c}}a and I. N. da Silva and J. E. C.
                 Castanho",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-106",
  abstract =     "This work presents a procedure for camera calibration
                 using artificial neural networks of the type back
                 propagation perceptron. Camera calibration is employed
                 in computer vision for pose determination and it
                 requires a solution of non-linear system of equations.
                 By employing neural network, it becomes unnecessary to
                 know the parameters of the cameras, such as focus,
                 distortions besides the geometry of the system. Camera
                 simulations and real experiments are used to
                 demonstrate and evaluate the procedure.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Computer vision, camera calibration, neural networks,
                 stereo vision",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-107,
  year =         "2002",
  title =        "Optimized Net Exchange Monte Carlo Simulation for
                 Participating Media",
  author =       "P. Perez and M. Paulin and M. El Hafi and R.
                 Fournier",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-107",
  abstract =     "The aim of this paper is to present the use of Monte
                 Carlo method in engineering applications to solve the
                 radiative transfer equation in participating media.
                 Adapted probability density functions that allow to
                 optimize the Monte Carlo algorithm are discussed. 1D
                 and 2D test cases are treated and a validation work has
                 been performed. The 3D implementation is in progress.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Monte Carlo, Participating Medium, pdf optimization,
                 spectral properties, radiative heat transfer",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-108,
  year =         "2002",
  title =        "3{D} Modeling Based on Radon Transform with
                 Application in Volume Measurement",
  author =       "C. Pintavirooj and M. Sangworasil",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-108",
  abstract =     "In this paper, we have adopted a novel method for 3D
                 modeling. We derived a volumetric data which is
                 constructed from a stack of cross-section images- the
                 so-called tomographic image. Each of the cross-section
                 images is computed from a series of photographs taken
                 at a number of angles around the object. A
                 corresponding intensity profile (row) on each digitized
                 photograph resembles a projection data, which can be
                 used to reconstruct the cross-section image. Once the
                 volumetric data is obtained, iso-surface of the object
                 is extracted using the well-known marching-cube
                 algorithm before being rendered with a conventional
                 surface-rendering technique. Unlike conventional 3D
                 modeling (3D-shape recovery) method of using stereo
                 pairs of camera, our technique does not suffer from
                 laborious corresponding problem. Nor does it require a
                 sophisticated scanning system as it does in the laser
                 range finder. Our purposed method is tested to perform
                 3D modeling of a variety of objects. The application of
                 our purposed method for volume measurement is also
                 presented in this paper. The results are very
                 promising.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Filtered back-projection, 3D modeling, 3D-shape
                 recovery, 3D-object reconstruction, surface rendering,
                 marching cube, 3D visualization",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-109,
  year =         "2002",
  title =        "Weighted Multiple Bit-Plane Matching, a Simple and
                 Efficient Matching Criterion for Electronic Digital
                 Image Stabilizer Application",
  author =       "H. R. Pourreza and M. Rahmati and F. Behazin",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-109",
  abstract =     "In this paper we propose two new matching criteria for
                 template matching. The performance evaluation of these
                 two criteria is applied to electronic digital image
                 stabilizer (EDIS) application. These two criteria are
                 based on bit-plane matching (BPM) criterion, where four
                 decimated bit-planes are used in our criteria. These
                 criteria can be realized using only Boolean functions;
                 hence they can be realized very simple in any digital
                 systems. We compared our criteria with other known
                 criteria by employing twenty real video sequences.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Block matching, matching criterion, electronic digital
                 image stabilization",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-11,
  year =         "2002",
  title =        "Extended Visual Cryptography for Natural Images",
  author =       "M. Nakajima and Y. Yamaguchi",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-11",
  abstract =     "Extended Visual Cryptography is a type of cryptography
                 which encodes a number of images in the way that when
                 the images on transparencies are stacked together, the
                 hidden message appears without a trace of original
                 images. The decryption is done directly by the human
                 visual system with no special cryptographic
                 calculations. This paper presents a system which takes
                 three pictures as an input and generates two images
                 which correspond to two of the three input pictures.
                 The third picture is reconstructed by printing the two
                 output images onto transparencies and stacking them
                 together. While the previous researches basically
                 handle only binary images, this paper establishes the
                 extended visual cryptography scheme suitable for
                 natural images. Generally, visual cryptography suffers
                 from the deterioration of the image quality. This paper
                 also describes the method to improve the quality of the
                 output images. The trade-off between the image quality
                 and the security are discussed and assessed by
                 observing the actual results of this method.
                 Furthermore, the optimization of the image quality is
                 discussed. keywords: Visual Cryptography, Halftoning,
                 Extended Visual Cryptography",
  editor =       "V. Skala",
  keywords =     "Visual Cryptography, Halftoning, Extended Visual
                 Cryptography",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-110,
  year =         "2002",
  title =        "A Variational Representation for Efficient Noisy
                 Segmentation",
  author =       "R. Romano and D. Vitulano",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-110",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Image Segmentation, Variational Models, Textures",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-111,
  year =         "2002",
  title =        "Real-Time Clothing: Geometry and Physics",
  author =       "I. Rudom{\'{i}}n and J. Luis Castillo",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-116",
  abstract =     "This paper describes a technique that allows pieces of
                 clothing to be placed over an animated articulated
                 character in real-time. In order to do this, the
                 character to be dressed must be approximated using a
                 hierarchy of ellipsoids. The pieces of clothing are
                 represented using mass-spring particle systems; the
                 particles move by applying dynamic forces to them and
                 integrating the system with an explicit method.
                 Penetration of the character?s ellipsoids by any
                 particle are avoided; to facilitate and accelerate
                 these calculations the ellipsoids are arranged in
                 groups and an adjacency graph is constructed between
                 these groups. This method is fast enough to deliver
                 real-time performance on mid-range PCs and
                 workstations, using only portable and standard C++ and
                 OpenGL code.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Cloth simulation, physically based modelling,
                 real-time clothing, particle systems",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-112,
  year =         "2002",
  title =        "Graphics Simulator for Adversary Adaptive Agents in
                 War Environment with Real Time Parallel Processing",
  author =       "A. C. D. Silva",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-112",
  abstract =     "The presented paper is part of a prototyping effort in
                 the sense of searching solutions for combat systems,
                 where through the use of virtual reality and feedback
                 control techniques is provided a real time aircraft
                 decision system for an operational combat environment.
                 Using virtual reality to develop the prototyping and
                 simulation for highly complex systems is quite
                 advantageous, once that it provides an appropriated
                 system follow up with lower cost and higher safety.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Virtual reality, visualization, parallel processing,
                 autonomous adaptive control, real time system",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-113,
  year =         "2002",
  title =        "A Surface Reconstruction Approach Based on
                 Multi-resolution Methods and the {T}-Surfaces
                 Framework",
  author =       "E. Strauss and W. Jim{\'{e}}nez and G. Giraldi and R.
                 Silva and A. Oliveira",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-113",
  abstract =     "In this paper we present a new approach which
                 integrates the T-Surfaces framework and a
                 multi-resolution method in a unified methodology for
                 segmentation and surface reconstruction. For noise
                 images, we can improve the result by anisotropic
                 diffusion. Despite this improvement, some manual
                 intervention may be required to complete the
                 reconstruction. Thus, we take advantage of the
                 topological capabilities of T-Surfaces to enable the
                 user to modify the topology of a surface. We test the
                 method for synthetic and medical volumes images.",
  editor =       "V. Skala",
  keywords =     "Surface Reconstruction, Segmentation,
                 Multi-Resolution, T-Surfaces",
  volume =       "10(3)",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-114,
  year =         "2002",
  title =        "{DEMEDITOR}: {A} Tool for Editing {DEM}s",
  author =       "V. Teichrieb and A. C. Frery and J. Kelner",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-114",
  abstract =     "A system to visualize and edit digital elevation
                 models based on interferometric synthetic aperture
                 radar data is presented. The visualization and
                 exploration of digital elevation models has been
                 basically done through the use of two-dimensional
                 interfaces. As virtual reality interfaces have proven
                 to offer a high degree of presentation realism and
                 several interaction facilities, they are an appropriate
                 way to visualize and interact with objects such as
                 terrain models. The realistic presentation of the
                 height component of such kind of object is fundamental
                 for its comprehension. Digital elevation models
                 frequently present elevation errors due to problems
                 occurred during imaging process or raw data processing.
                 Several methods have been developed to correct these
                 errors, but a total elimination is not much probably.
                 The visual interpretation of the data, the use of
                 analyse tools to assess this interpretation, and the
                 manual editing of error areas in the digital elevation
                 model compose the error reduction procedure presented
                 by this work. The system offers both a two and
                 three-dimensional interface to visualize and interact
                 with the digital elevation models, and allows the
                 selection of error areas in the terrain in order to
                 remove them. The removed areas can later be
                 interpolated and smoothed.",
  editor =       "V. Skala",
  keywords =     "Virtual reality, remote sensing, digital elevation
                 models, DEMs visualization, error editing",
  volume =       "10(3)",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-115,
  year =         "2002",
  title =        "Watershed Transformation: Reducing the
                 Over-Segmentation Problem by Applying a Noice Reducer
                 and a Region Merger",
  author =       "Y. Vanderstockt and R. N. Whyte",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-115",
  abstract =     "Image segmentation is used to identify homogeneous
                 regions in an image, it has been a subject of research
                 for the last three decades. It is usually the first,
                 and most difficult task for any image understanding
                 system. Image segmentation is usually associated with
                 pattern recognition problems and is considered the
                 first phase of such a process. Consequently, the
                 success of the pattern recognition process is dependent
                 on the quality of this initial stage. Here we examine
                 image segmentation. We describe the watershed
                 transformation algorithm and our variation of it. We
                 provide results for our implementation and compare then
                 to previously published results from traditional
                 implementations of the watershed transformation.
                 Finally, we believe that these results substantiate the
                 case that our modifications to the watershed provide
                 much improved segmentation results.",
  editor =       "V. Skala",
  keywords =     "Image segmentation, watershed transformation, region
                 merging",
  volume =       "10(3)",
  booktitle =    "Journal of WSCG 2002",
}

@{,
}

@TechReport{EVL-2002-117,
  year =         "2002",
  title =        "{S}tate-of-the-{A}rt {R}eport 2002 in {F}low
                 {V}isualization",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-117",
  author =       "Helwig Hauser and Robert S. Laramee and Helmut
                 Doleisch",
  abstract =     "Flow visualization (FlowViz) has been a very
                 attractive field within visualization research for a
                 long time already. Usually huge datasets need to be
                 processed, which often consist of multi-variate data
                 with a really large number of sample locations, often
                 arranged in multiple time-steps. Recently, the ever
                 increasing performance of ocmputers again has become a
                 driving factor for a resurgence of FlowViz research,
                 especially in FlowViz based on additional computation
                 such as feature extraction, vector field clustering,
                 and topology extraction. In this state-of-the-art
                 report, an attempt was made to (1) provide a userful
                 categoritation of FlowViz solutions, (2) give a
                 survey-like overview about existing solutions, and (3)
                 focus on recent work, especially in the field of
                 FlowViz based on derived data. We give careful
                 consideration as to how these topics are best organized
                 for such a presentation. In separate sections we
                 describe (a) direct FlowViz techniques such as using
                 arrows, (b) FlowViz using integral objects such as
                 stream lines, (c) space-filling FlowViz, including spot
                 noise or line integral convolution, and (d) FlowViz
                 based on derived data such as flow topology. Within
                 those sections, the discussion of FlowViz literature is
                 sub-structured according to the dimensionality of the
                 flow data (from 2D to 3D).",
  organization = "Research Center for Virtual Reality and
                 Visualization",
  address =      "www.VRVis.at",
  month =        feb,
  note =         "TR-VRVis-2002-003",
  institution =  "{VRVis} {R}esearch {C}enter",
}

@InCollection{EVL-2002-118,
  pages =        "5--17",
  year =         "2002",
  title =        "Psychovisual Evaluation of Lossy {CMYK} Image
                 Compression for Printing Applications",
  author =       "K. Denecker and P. De Neve and S. Van Assche and R.
                 Van de Walle and I. Lemahieu and W. Philips",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-118",
  abstract =     "In the digital prepress workflow, images are
                 represented in the CMYK colour space. Lossy image
                 compression alleviates the need for high storage and
                 bandwidth capacities, resulting from the high spatial
                 and tonal resolution. After the image has been printed
                 on paper, the introduced visual quality loss should not
                 be noticeable to a human observer. Since visual image
                 quality depends on the compression algorithm both
                 quantitatively and qualitatively, and since no visual
                 image quality models incorporating the end-to-end image
                 reproduction process are satisfactory, an experimental
                 comparison is the only viable way to quantify
                 subjective image quality. This paper presents the
                 results from an intensive psychovisual study based on a
                 two-alternative forced-choice approach involving 164
                 people, with expert and non-expert observers
                 distinguished. The primary goal is to evaluate two
                 previously published adaptations of JPEG to CMYK
                 images, and to determine a visually lossless
                 compression ratio threshold for typical printing
                 applications. The improvements are based on tonal
                 decorrelation and overlapping block transforms. Results
                 on three typical prepress test images indicate that the
                 proposed adaptations are useful and that for the
                 investigated printing configuration, compression ratios
                 up to 20 can be used safely",
  editor =       "David Duke and Roberto Scopignio",
  volume =       "21(1)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishers",
}

@InCollection{EVL-2002-119,
  pages =        "19--31",
  year =         "2002",
  title =        "Exact Isosurfaces for Marching Cubes",
  author =       "Holger Theisel",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-119",
  abstract =     "In this paper we study the exact contours of a
                 piecewise trilinear scalar field. We show how to
                 represent these contours exactly as trimmed surfaces of
                 triangular rational cubic B{\'{e}}zier patches. As part
                 of this, we introduce an extension of the marching
                 cubes algorithm which gives a topologically exact
                 triangular approximation of the contours for any case.
                 Finally, we modify the exact contours to be globally G1
                 continuous without changing their topologies. We test
                 the algorithm on both theoretical and practical data
                 sets.",
  editor =       "David Duke and Roberto Scopignio",
  volume =       "21(1)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishers",
}

@InProceedings{EVL-2002-12,
  year =         "2002",
  title =        "Human Pose Estimation from Silhouettes - {A}
                 Consistent Approach Using Distance Level Sets",
  author =       "C. Sminchisescu and A. Telea",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-12",
  abstract =     "We present a novel similarity measure (likelihood) for
                 estimating three-dimensional human pose from image
                 silhouettes in model-based vision applications. One of
                 the challenges in such approaches is the construction
                 of a model-to-image likelihood that truly reflects the
                 good configurations of the problem. This is hard,
                 commonly due to the violation of consistency principle
                 resulting in the introduction of spurious, unrelated
                 peaks/minima that make the search for model
                 localization difficult. We introduce an entirely
                 continuous formulation which enforces model estimation
                 consistency by means of an attraction/explanation
                 silhouette-based term pair. We subsequently show how
                 the proposed method provides significant consolidation
                 and improved attraction zone around the desired
                 likelihood configurations and elimination of some of
                 the spurious ones. Finally, we present a skeleton-based
                 smoothing method for the image silhouettes that
                 stabilizes and accelerates the search process.",
  editor =       "V. Skala",
  keywords =     "Hman tracking, model-based estimation, constrained
                 optimization, level set methods, fast marching
                 methods",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InCollection{EVL-2002-120,
  pages =        "43--64",
  year =         "2002",
  title =        "Web 2{D} Graphics File Formats",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-120",
  author =       "David Duce and Ivan Herman and Bob Hopgood",
  abstract =     "The earliest Web browsers focussed on the display of
                 textual information. When graphics were added,
                 essentially only image graphics and image file formats
                 were supported. For a significant range of
                 applications, image graphics has severe limitations,
                 for example in terms of file size, download time and
                 inability to interact with and modify the graphics
                 client-side. Vector graphics may be more appropriate in
                 these cases, and this has become possible through the
                 introduction of the WebCGM and Scalable Vector Graphics
                 (SVG) formats, both of which are open standards, the
                 former from ISO/IEC and W3C and the latter from W3C.
                 This paper reviews the background to Web graphics,
                 presents the WebCGM file format, and gives a more
                 detailed exposition of the most recent format, SVG. The
                 paper concludes with reflections on the current state
                 of this area and future prospects.",
  editor =       "David Duke and Roberto Scopignio",
  volume =       "21(1)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishers",
}

@InCollection{EVL-2002-121,
  pages =        "33--42",
  year =         "2002",
  title =        "A Coherence-based Collision Detection Method for
                 Dressed Human Simulation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-121",
  author =       "Dongliang Zhang and Matthew M. F. Yuen",
  abstract =     "In this paper, paper we present a coherence-based
                 method to detect collisions between the garment and
                 human model for dressed human simulations. Based on the
                 property of coherence, collisions can be rapidly
                 detected by tracking the movement of the most likely
                 geometric elements to collide. The voxel technique is
                 employed to quickly identify the potential collision
                 region. Experimental results show that our method is
                 very efficient.",
  editor =       "David Duke and Roberto Scopignio",
  volume =       "21(1)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishers",
}

@InCollection{EVL-2002-122,
  pages =        "65--81",
  year =         "2002",
  title =        "Techniques for Realistic Visualization of Fluids: {A}
                 Survey",
  author =       "Neeharika Adabala and Swami Manohar",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-122",
  abstract =     "Visualization of fluids has wide applications in
                 science, engineering and entertainment. Various
                 methodologies of visualizing fluids have evolved which
                 emphasize on capturing different aspects of the fluids
                 accurately. In this survey the existing methods for
                 realistic visualization of fluids are reviewed. The
                 approaches are classified based on the key concept they
                 rely on for fluid modeling. This classification allows
                 for easy selection of the method to be adopted for
                 visualization given an application. It also enables
                 identification of alternative techniques for fluid
                 modeling.",
  editor =       "David Duke and Roberto Scopignio",
  volume =       "21(1)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishers",
}

@InCollection{EVL-2002-123,
  pages =        "99--110",
  year =         "2002",
  title =        "Artistic Surface Rendering Using Layout of Text",
  author =       "Tatiana Surazhsky and Gershon Elber",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-123",
  abstract =     "An artistic rendering method of free-form surfaces
                 with the aid of half-toned text that is laid-out on the
                 given surface is presented. The layout of the text is
                 computed using symbolic composition of the free-form
                 parametric surface S(u, v) with cubic or linear
                 B{\'{e}}zier curve segments C(t) = &lcub;cu(t),
                 cv(t)&rcub;, comprising the outline of the text
                 symbols. Once the layout is constructed on the surface,
                 a shading process is applied to the text, affecting the
                 width of the symbols as well as their color, according
                 to some shader function. The shader function depends on
                 the surface orientation and the view direction as well
                 as the color and the direction or position of the light
                 source.",
  editor =       "David Duke and Roberto Scopignio",
  volume =       "21(2)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishers",
}

@InCollection{EVL-2002-124,
  pages =        "111--119",
  year =         "2002",
  title =        "An Adaptive Sampling Scheme for Out-of-Core
                 Simplification",
  author =       "Guangzheng Fei and Kangying Cai and Baining Guo and
                 Enhua Wu",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-124",
  abstract =     "Current out-of-core simplification algorithms can
                 efficiently simplify large models that are too complex
                 to be loaded in to the main memory at one time.
                 However, these algorithms do not preserve surface
                 details well since adaptive sampling, a typical
                 strategy for detail preservation, remains to be an open
                 issue for out-of-core simplification. In this paper, we
                 present an adaptive sampling scheme, called the
                 balanced retriangulation (BR), for out-of-core
                 simplification. A key idea behind BR is that we can use
                 Garland's quadric error matrix to analyze the global
                 distribution of surface details. Based on this
                 analysis, a local retriangulation achieves adaptive
                 sampling by restoring detailed areas with cell split
                 operations while further simplifying smooth areas with
                 edge collapse operations. For a given triangle budget,
                 BR preserves surface details significantly better than
                 uniform sampling algorithms such as uniform clustering.
                 Like uniform clustering, our algorithm has linear
                 running time and small memory requirement.",
  editor =       "David Duke and Roberto Scopignio",
  volume =       "21(2)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishers",
}

@InCollection{EVL-2002-125,
  pages =        "121--136",
  year =         "2002",
  title =        "Multiresolution Surfaces having Arbitrary Topologies
                 by a Reverse Doo Subdivision Method",
  author =       "Faramarz F. Samavati and Nezam Mahdavi-Amiri and
                 Richard H. Bartels",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-125",
  abstract =     "We have shown how to construct multiresolution
                 structures for reversing subdivision rules using global
                 least squares models (Samavati and Bartels, Computer
                 Graphics Forum, 18(2):97-119, June 1999). As a result,
                 semiorthogonal wavelet systems have also been
                 generated. To construct a multiresolution surface of an
                 arbitrary topology, however, biorthogonal wavelets are
                 needed. In Bartels and Samavati (Journal of
                 Computational and Applied Mathematics, 119:29-67, 2000)
                 we introduced local least squares models for reversing
                 subdivision rules to construct multiresolution curves
                 and tensor product surfaces, noticing that the
                 resulting wavelets were biorthogonal (under an induced
                 inner product). Here, we construct multiresolution
                 surfaces of arbitrary topologies by locally reversing
                 the Doo subdivision scheme. In a Doo subdivision, a
                 coarse surface is converted into a fine one by the
                 contraction of coarse faces and the addition of new
                 adjoining faces. We propose a novel reversing process
                 to convert a fine surface into a coarse one plus an
                 error. The conversion has the property that the
                 subdivision of the resulting coarse surface is locally
                 closest to the original fine surface, in the least
                 squares sense, for two important face geometries. In
                 this process, we first find those faces of the fine
                 surface which might have been produced by the
                 contraction of a coarse face in a Doo subdivision
                 scheme. Then, we expand these faces. Since the expanded
                 faces are not necessarily joined properly, several
                 candidates are usually at hand for a single vertex of
                 the coarse surface. To identify the set of candidates
                 corresponding to a vertex, we construct a graph in such
                 a way that any set of candidates corresponds to a
                 connected component. The connected components can
                 easily be identified by a depth first search traversal
                 of the graph. Finally, vertices of the coarse surface
                 are set to be the average of their corresponding
                 candidates, and this is shown to be equivalent to local
                 least squares approximation for regular arrangements of
                 triangular and quadrilateral faces.",
  editor =       "David Duke and Roberto Scopignio",
  volume =       "21(2)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishers",
}

@InCollection{EVL-2002-126,
  pages =        "137--148",
  year =         "2002",
  title =        "Universal Rendering Sequences for Transparent Vertex
                 Caching of Progressive Meshes",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-126",
  author =       "A. Bogomjakov and C. Gotsman",
  abstract =     "We present methods to generate rendering sequences for
                 triangle meshes which preserve mesh locality as much as
                 possible. This is useful for maximizing vertex reuse
                 when rendering the mesh using a FIFO vertex buffer,
                 such as those available in modern 3D graphics hardware.
                 The sequences are universal in the sense that they
                 perform well for all sizes of vertex buffers, and
                 generalize to progressive meshes. This has been
                 verified experimentally.",
  editor =       "David Duke and Roberto Scopignio",
  volume =       "21(2)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishers",
}

@InCollection{EVL-2002-127,
  pages =        "149--172",
  year =         "2002",
  title =        "The 3{D} Model Acquisition Pipeline",
  author =       "Fausto Bernardini and Holly Rushmeier",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-127",
  abstract =     "Three-dimensional (3D) image acquisition systems are
                 rapidly becoming more affordable, especially systems
                 based on commodity electronic cameras. At the same
                 time, personal computers with graphics hardware capable
                 of displaying complex 3D models are also becoming
                 inexpensive enough to be available to a large
                 population. As a result, there is potentially an
                 opportunity to consider new virtual reality
                 applications as diverse as cultural heritage and retail
                 sales that will allow people to view realistic 3D
                 objects on home computers. Although there are many
                 physical techniques for acquiring 3D
                 data&mdash;including laser scanners, structured light
                 and time-of-flight&mdash;there is a basic pipeline of
                 operations for taking the acquired data and producing a
                 usable numerical model. We look at the fundamental
                 problems of range image registration, line-of-sight
                 errors, mesh integration, surface detail and color, and
                 texture mapping. In the area of registration we
                 consider both the problems of finding an initial global
                 alignment using manual and automatic means, and
                 refining this alignment with variations of the
                 Iterative Closest Point methods. To account for scanner
                 line-of-sight errors we compare several averaging
                 approaches. In the area of mesh integration, that is
                 finding a single mesh joining the data from all scans,
                 we compare various methods for computing interpolating
                 and approximating surfaces. We then look at various
                 ways in which surface properties such as color (more
                 properly, spectral reflectance) can be extracted from
                 acquired imagery. Finally, we examine techniques for
                 producing a final model representation that can be
                 efficiently rendered using graphics hardware.",
  editor =       "David Duke and Roberto Scopignio",
  volume =       "21(2)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishers",
}

@InCollection{EVL-2002-128,
  pages =        "173--196",
  year =         "2002",
  title =        "Recent Advances in Mesh Morphing",
  author =       "Marc Alexa",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-128",
  abstract =     "Meshes have become a widespread and popular
                 representation of models in computer graphics. Morphing
                 techniques aim at transforming a given source shape
                 into a target shape. Morphing techniques have various
                 applications ranging from special effects in television
                 and movies to medical imaging and scientific
                 visualization. Not surprisingly, morphing techniques
                 for meshes have received a lot of interest lately. This
                 work sums up recent developments in the area of mesh
                 morphing. It presents a consistent framework to
                 classify and compare various techniques approaching the
                 same underlying problems from different angles.",
  editor =       "David Duke and Roberto Scopignio",
  volume =       "21(2)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishers",
}

@InCollection{EVL-2002-129,
  pages =        "1--8",
  year =         "2002",
  title =        "Information Visualization and Visual Data Mining",
  author =       "Daniel A. Keim",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-129",
  abstract =     "Abstract-Never before in history has data been
                 generated at such high volumes as it is today.
                 Exploring and analyzing the vast volumes of data is
                 becoming increasingly difficult. Information
                 visualization and visual data mining can help to deal
                 with the flood of information. The advantage of visual
                 data exploration is that the user is directly involved
                 in the data mining process. There are a large number of
                 information visualization techniques which have been
                 developed over the last decade to support the
                 exploration of large data sets. In this paper, we
                 propose a classification of information visualization
                 and visual data mining techniques which is based on the
                 data type to be visualized, the visualization
                 technique, and the interaction and distortion
                 technique. We exemplify the classification using a few
                 examples, most of them referring to techniques and
                 systems presented in this special section.",
  volume =       "8(1)",
  keywords =     "Information visualization, visual data mining, visual
                 data exploration, classification",
  booktitle =    "IEEE Transcations on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InProceedings{EVL-2002-13,
  year =         "2002",
  title =        "An Overview of Visibility Problem Algorithms in
                 1,5{D}",
  author =       "B. Kaucic and B. Zalik",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-13",
  abstract =     "The paper gives an overview of algorithms for the
                 terrain visibility problem. First, a comprehensive
                 background of the problem is given. It is explained how
                 the 2,5D problem is transformed to a 1,5D problem.
                 Next, six algorithms (a naive approach, an approach
                 with the height of line-of-sight (LOS), an approach
                 with the biggest slope of LOS, an approach with the
                 cross product, an incremental approach, and an improved
                 incremental approach) are briefly explained and their
                 theoretical time complexities are given. After that,
                 run-times of the algorithms are measured for different
                 terrain configurations and different viewpoint heights.
                 The best algorithm is selected at the end.",
  editor =       "V. Skala",
  keywords =     "Visibility problem, digital terrain model, GIS,
                 overview",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InCollection{EVL-2002-130,
  pages =        "9--20",
  year =         "2002",
  title =        "ThemeRiver: Visualizing Thematic Changes in Large
                 Document Collections",
  author =       "Susan Havre and Elizabeth Hetzler and Paul Whitney and
                 Lucy Nowell",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-130",
  abstract =     "he ThemeRiver visualization depicts thematic
                 variations over time within a large collection of
                 documents. The thematic changes are shown in the
                 context of a time line and corresponding external
                 events. The focus on temporal thematic change within a
                 context framework allows a user to discern patterns
                 that suggest relationships or trends. For example, the
                 sudden change of thematic strength following an
                 external event may indicate a causal relationship. Such
                 patterns are not readily accessible in other
                 visualizations of the data. We use a river metaphor to
                 convey several key notions. The document collection's
                 time line, selected thematic content, and thematic
                 strength are indicated by the river's directed flow,
                 composition, and changing width, respectively. The
                 directed flow from left to right is interpreted as
                 movement through time and the horizontal distance
                 between two points on the river defines a time
                 interval. At any point in time, the vertical distance,
                 or width, of the river indicates the collective
                 strength of the selected themes. Colored ?currents?
                 flowing within the river represent individual themes. A
                 current's vertical width narrows or broadens to
                 indicate decreases or increases in the strength of the
                 individual theme.",
  volume =       "8(1)",
  keywords =     "Visualization, metaphor, trend analysis, time line",
  booktitle =    "IEEE Transcations on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2002-131,
  pages =        "21--38",
  year =         "2002",
  title =        "{MGV}: {A} System for Visualizing Massive
                 Multidigraphs",
  author =       "James Abello and Jeffrey Korn",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-131",
  abstract =     "We describe MGV, an integrated visualization and
                 exploration system for massive multidigraph navigation.
                 It adheres to the Visual Information-Seeking Mantra:
                 overview first, zoom and filter, then details on
                 demand. MGV's only assumption is that the vertex set of
                 the underlying digraph corresponds to the set of leaves
                 of a predetermined tree $T$. MGV builds an out-of-core
                 graph hierarchy and provides mechanisms to plug in
                 arbitrary visual representations for each graph
                 hierarchy slice. Navigation from one level to another
                 of the hierarchy corresponds to the implementation of a
                 drill-down interface. In order to provide the user with
                 navigation control and interactive response, MGV
                 incorporates a number of visualization techniques like
                 interactive pixel-oriented 2D and 3D maps, statistical
                 displays, color maps, multilinked views, and a zoomable
                 label based interface. This makes the association of
                 geographic information and graph data very natural. To
                 automate the creation of the vertex set hierarchy for
                 MGV, we use the notion of graph sketches. They can be
                 thought of as visual indices that guide the navigation
                 of a multigraph too large to fit on the available
                 display. MGV follows the client-server paradigm and it
                 is implemented in C and Java-3D. We highlight the main
                 algorithmic and visualization techniques behind the
                 tools and, along the way, point out several possible
                 application scenarios. Our techniques are being applied
                 to multigraphs defined on vertex sets with sizes
                 ranging from 100 million to 250 million vertices",
  volume =       "8(1)",
  keywords =     "External memory, visualization, massive data sets,
                 graphs, hierarchie",
  booktitle =    "IEEE Transcations on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2002-132,
  pages =        "39--51",
  year =         "2002",
  title =        "A Flexible Approach for Visual Data Mining",
  author =       "Matthias Kreuseler and Heidrun Schumann",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-132",
  abstract =     "The exploration of heterogenous information spaces
                 requires suitable mining methods as well as effective
                 visual interfaces. Most of the existing systems
                 concentrate either on mining algorithms or on
                 visualization techniques. This paper describes a
                 flexible framework for Visual Data Mining which
                 combines analytical and visual methods to achieve a
                 better understanding of the information space. We
                 provide several preprocessing methods for unstructured
                 information spaces such as a flexible hierarchy
                 generation with user controlled refinement. Moreover,
                 we develop new visualization techniques including an
                 intuitive Focus+Context technique to visualize complex
                 hierarchical graphs. A special feature of our system is
                 a new paradigm for visualizing information structures
                 within their frame of reference.",
  volume =       "8(1)",
  keywords =     "Information visualization, multidimenisional
                 information modeling, hierarchies, focus+context
                 techniques, clustering, maps, information analysis.",
  booktitle =    "IEEE Transcations on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2002-133,
  pages =        "52--65",
  year =         "2002",
  title =        "Polaris: {A} System for Query, Analysis, and
                 Visualization of Multidimensional Relational
                 Databases",
  author =       "Chris Stolte and Diane Tang and Pat Hanrahan",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-133",
  abstract =     "In the last several years, large multidimensional
                 databases have become common in a variety of
                 applications such as data warehousing and scientific
                 computing. Analysis and exploration tasks place
                 significant demands on the interfaces to these
                 databases. Because of the size of the data sets, dense
                 graphical representations are more effective for
                 exploration than spreadsheets and charts. Furthermore,
                 because of the exploratory nature of the analysis, it
                 must be possible for the analysts to change
                 visualizations rapidly as they pursue a cycle involving
                 first hypothesis and then experimentation. In this
                 paper, we present Polaris, an interface for exploring
                 large multidimensional databases that extends the
                 well-known Pivot Table interface. The novel features of
                 Polaris include an interface for constructing visual
                 specifications of table-based graphical displays and
                 the ability to generate a precise set of relational
                 queries from the visual specifications. The visual
                 specifications can be rapidly and incrementally
                 developed, giving the analyst visual feedback as they
                 construct complex queries and visualizations.",
  volume =       "8(1)",
  keywords =     "Database visualization, database analysis,
                 visualization formalism, multidimensional databases",
  booktitle =    "IEEE Transcations on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2002-134,
  pages =        "66--75",
  year =         "2002",
  title =        "The Classification of Volumetric Display Systems:
                 Characteristics and Predictability of the Image Space",
  author =       "Barry G. Blundell and Adam J. Schwarz",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-134",
  abstract =     "A diverse range of volumetric display systems has been
                 proposed during the last 90 years. In order to
                 facilitate a comparison between the various approaches,
                 the three subsystems that comprise displays of this
                 type are identified and are used as a basis for a
                 classification scheme. The general characteristics of a
                 number of volumetric display system configurations are
                 examined, with emphasis given to issues relating to the
                 predictability of the volume within which images are
                 depicted. Key characteristics of this image space are
                 identified and the complex manner in which they depend
                 upon the display unit subsystems are illustrated for
                 several current volumetric display techniques.",
  volume =       "8(1)",
  keywords =     "Volumetric, 3D, visualization, display system,
                 graphics.",
  booktitle =    "IEEE Transcations on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2002-135,
  pages =        "99--118",
  year =         "2002",
  title =        "A Generic Rendering System",
  author =       "J. D{\"{o}}llner and K. Hinrichs",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-135",
  abstract =     "We describe the software architecture of a rendering
                 system that follows a pragmatic approach to integrating
                 and bundling the power of different low-level rendering
                 systems within an object-oriented framework. The
                 generic rendering system provides higher-level
                 abstractions to existing rendering systems and serves
                 as a framework for developing new rendering techniques.
                 It wraps the functionality of several, widely used
                 rendering systems, defines a unified, object-oriented
                 application programming interface, and provides an
                 extensible, customizable apparatus for evaluating and
                 interpreting hierarchical scene information. As a
                 fundamental property, individual features of a specific
                 rendering system can be integrated into the generic
                 rending system in a transparent way. The system is
                 based on a state machine, called engine, which operates
                 on rendering components. Four major categories of
                 rendering components constitute the generic rendering
                 system: shapes represent geometries, attributes specify
                 properties assigned to geometries and scenes, handlers
                 encapsulate rendering algorithms, and techniques
                 represent evaluation strategies for rendering
                 components. As a proof of concept, we have implemented
                 the described software architecture by the Virtual
                 Rendering System which currently wraps OpenGL,
                 Radiance, POV Ray, and RenderMan.",
  volume =       "8(2)",
  keywords =     "Rendering systems, object-oriented graphics, generic
                 rendering, rendering framework, multipass rendering",
  booktitle =    "IEEE Transcations on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2002-136,
  pages =        "119--128",
  year =         "2002",
  title =        "General Construction of Time-Domain Filters for
                 Orientation Data",
  author =       "J. Lee and S. Y. Shin",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-136",
  abstract =     "Capturing live motion has gained considerable
                 attention in computer animation as an important motion
                 generation technique. Canned motion data are comprised
                 of both position and orientation components. Although a
                 great number of signal processing methods are available
                 for manipulating position data, the majority of these
                 methods cannot be generalized easily to orientation
                 data due to the inherent nonlinearity of the
                 orientation space. In this paper, we present a new
                 scheme that enables us to apply a filter mask (or a
                 convolution filter) to orientation data. The key idea
                 is to transform the orientation data into their
                 analogues in a vector space, to apply a filter mask on
                 them, and then to transform the results back to the
                 orientation space. This scheme gives time-domain
                 filters for orientation data that are computationally
                 efficient and satisfy such important properties as
                 coordinate-invariance, time-invariance, and symmetry.
                 Experimental results indicate that our scheme is useful
                 for various purposes including smoothing and
                 sharpening.",
  volume =       "8(2)",
  keywords =     "Orientation and rotation, unit quaternions, motion
                 signal processing, LTI filters, convolution filters,
                 coordinate-invariance, time-invarianc",
  booktitle =    "IEEE Transcations on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2002-137,
  pages =        "129--143",
  year =         "2002",
  title =        "A Geometric Comparison of Algorithms for Fusion
                 Control in Stereoscopic {HTD}s",
  author =       "Z. Wartell and L. F. Hodges and W. Ribarsky",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-137",
  abstract =     "This paper concerns stereoscopic virtual reality
                 displays in which the head is tracked and the display
                 is stationary, attached to a desk, tabletop, or wall.
                 These are called stereoscopic HTDs (Head-Tracked
                 Display). Stereoscopic displays render two perspective
                 views of a scene, each of which is seen by one eye of
                 the user. Ideally, the user's natural visual system
                 combines the stereo image pair into a single, 3D
                 perceived image. Unfortunately, users often have
                 difficulty fusing the stereo image pair. Researchers
                 use a number of software techniques to reduce fusion
                 problems. This paper geometrically examines and
                 compares a number of these techniques and reaches the
                 following conclusions: In interactive stereoscopic
                 applications, the combination of view placement, scale,
                 and either false eye separation or \alpha{\hbox{-}}{\rm
                 false} eye separation can provide fusion control
                 geometrically similar to image shifting and image
                 scaling. However, in stereo HTDs, image shifting and
                 image scaling also generate additional geometric
                 artifacts not generated by the other methods. We
                 anecdotally link some of these artifacts to exceeding
                 perceptual limitations of human vision. While formal
                 perceptual studies are still needed, geometric analysis
                 suggests that image shifting and image scaling may be
                 less appropriate than the other methods for
                 interactive, stereo HTDs.V",
  volume =       "8(2)",
  keywords =     "Virtual reality, stereoscopic display, head-tracking,
                 distortion",
  booktitle =    "IEEE Transcations on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2002-138,
  pages =        "144--153",
  year =         "2002",
  title =        "Spatial-Temporal Antialiasing",
  author =       "K. Sung and A. Pearce and C. Wang",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-138",
  abstract =     "A framework for discussing the motion blur image
                 generation process is formulated. Previous work is
                 studied in the context of the framework. Due to the
                 implicit assumptions on low temporal frequencies in
                 most motion blur algorithms, issues involved in large
                 screen space movements and fast illumination changes in
                 time have not been adequately addressed so far. A new
                 approach that does not make these assumptions is
                 introduced to solve the spatial-temporal geometric and
                 shading aliasing problems separately. Based on newly
                 developed adaptive algorithms in the spatial-temporal
                 domain, an implementation of the new approach is
                 developed to efficiently deliver high quality motion
                 blurred images in general computer graphics production
                 environments.",
  volume =       "8(2)",
  keywords =     "Rendering, antialiasing, temporal aliasing",
  booktitle =    "IEEE Transcations on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2002-139,
  pages =        "154--170",
  year =         "2002",
  title =        "An Anatomy-Based Approach to Human Muscle Modeling and
                 Deformation",
  author =       "F. Dong and G. J. Clapworthy and M. A. Krokos and J.
                 Yao",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-139",
  abstract =     "Muscle simulation is an important component of human
                 modeling, but there have been few attempts to
                 demonstrate, in three dimensions and in an anatomically
                 correct way, the structures of muscles and the way in
                 which these change during motion. This paper proposes
                 an anatomically-based approach to muscle modeling that
                 attempts to provide models for human musculature based
                 on the real morphological structures. These models
                 provide a good visual description of muscle form and
                 action and represent a sound base from which to produce
                 further progress toward medically accurate simulation
                 of human bodies. Three major problems have been
                 addressed: geometric modeling, deformation, and
                 texture. To allow for the wide variety of deformable
                 muscle shapes encountered in the body, while retaining
                 as many of their common properties as possible, the
                 geometric models are classified into several categories
                 according to the characteristics of their structures
                 and actions. Within each category, the model for each
                 muscle has an efficient structural form, created using
                 anatomical data. Deformation is also performed on the
                 basis of the categories, with all models within each
                 category sharing the same deformation scheme. The
                 categories cover both general and special cases. The
                 result is an efficient, anatomically accurate muscle
                 representation that is specifically designed to
                 accommodate the particular form of deformation
                 exhibited by each individual muscle. Interactions
                 between muscles are also taken into account to avoid
                 penetration occurring between adjacent muscles in our
                 model. To provide a suitable visual effect, the muscle
                 texture is generated directly on the model surface. The
                 textures and colors are obtained from anatomical data
                 via image analysis. Some results are presented on the
                 geometric modeling, the deformation, and the texture of
                 muscles related to the lower limb.",
  volume =       "8(2)",
  keywords =     "Human modeling, figure animation, deformation,
                 texture",
  booktitle =    "IEEE Transcations on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InProceedings{EVL-2002-14,
  year =         "2002",
  author =       "O. Schneider and Storyworld Creation: Authoring For
                 Interactive Storytelling",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-14",
  abstract =     "Storytelling - humankinds universal choice for content
                 transmission - is becoming of great importance in the
                 field of computer graphics, as the human ability to
                 keep track of information in the information society of
                 the 21st century is dependent on the quality of the
                 information providing systems. Basically, the first
                 steps towards storytelling systems have been taken;
                 everyone today has the possibility to step into
                 enfolding 3D worlds and become immersed in extensive
                 loads of data. However, there is still a great backlog
                 on the human-like organization of the associated data.
                 The reason for this is the absence of the basic
                 authoring systems for interactive storytelling. This
                 position paper presents an approach to new authoring
                 methods for interactive storytelling. It considers the
                 authors view of the tools to be used and introduces a
                 coherent environment that does not restrict the
                 creative process and lets the author feel comfortable,
                 leading him to create well-narrated, interactive
                 non-linear stories.",
  editor =       "V. Skala",
  keywords =     "Authoring, non-linear story narration, human computer
                 interaction, computer games.",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InCollection{EVL-2002-140,
  pages =        "171--182",
  year =         "2002",
  title =        "VideoPlus: {A} Method for Capturing the Structure and
                 Appearance of Immersive Environments",
  author =       "C. J. Taylor",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-140",
  abstract =     "This paper presents a simple approach to capturing the
                 appearance and structure of immersive scenes based on
                 the imagery acquired with an omnidirectional video
                 camera. The scheme proceeds by combining techniques
                 from structure from motion with ideas from image based
                 rendering. An interactive photogrammetric modeling
                 scheme is used to recover the locations of a set of
                 salient features in the scene (points and lines) from
                 image measurements in a small set of keyframe images.
                 The estimates obtained from this process are then used
                 as a basis for estimating the position and orientation
                 of the camera at every frame in the video clip. By
                 augmenting the video sequence with pose information we
                 provide the end user with the ability to index the
                 video sequence spatially as opposed to temporally. This
                 allows the user to explore the immersive scene by
                 interactively selecting the desired viewpoint and
                 viewing direction.",
  volume =       "8(2)",
  keywords =     "Reconstruction, immersive environments,
                 omnidirectional video, pose estimation",
  booktitle =    "IEEE Transcations on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2002-141,
  pages =        "183--197",
  year =         "2002",
  title =        "Designing Effective Transfer Functions for Volume
                 Rendering from Photographic Volumes",
  author =       "D. S. Ebert and C. J. Morris and P. Rheingans and T.
                 S. Yoo",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-141",
  abstract =     "Photographic volumes present a unique, interesting
                 challenge for volume rendering. In photographic
                 volumes, voxel color is predetermined, making color
                 selection through transfer functions unnecessary.
                 However, photographic data does not contain a clear
                 mapping from the multivalued color values to a scalar
                 density or opacity, making projection and compositing
                 much more difficult than with traditional volumes.
                 Moreover, because of the nonlinear nature of color
                 spaces, there is no meaningful norm for the multivalued
                 voxels. Thus, the individual color channels of
                 photographic data must be treated as incomparable data
                 tuples rather than as vector values. Traditional
                 differential geometric tools, such as intensity
                 gradients, density, and Laplacians, are distorted by
                 the nonlinear nonorthonormal color spaces that are the
                 domain of the voxel values. We have developed different
                 techniques for managing these issues while directly
                 rendering volumes from photographic data. We present
                 and justify the normalization of color values by
                 mapping RGB values to the CIE L^\ast u^\ast v^\ast
                 color space. We explore and compare different opacity
                 transfer functions that map three channel color values
                 to opacity. We apply these many-to-one mappings to the
                 original RGB values as well as to the voxels after
                 conversion to L^\ast u^\ast v^\ast space. Direct
                 rendering using transfer functions allows us to explore
                 photographic volumes without having to commit to an a
                 priori segmentation that might mask fine variations of
                 interest. We empirically compare the combined effects
                 of each of the two color spaces with our opacity
                 transfer functions using source data from the Visible
                 Human Project.",
  volume =       "8(2)",
  keywords =     "Volume rendering, transfer functions, photographic
                 data",
  booktitle =    "IEEE Transcations on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2002-142,
  pages =        "198--207",
  year =         "2002",
  title =        "Texture Mapping Using Surface Flattening via
                 Multidimensional Scaling",
  author =       "G. Zigelman and R. Kimmel and N. Kiryati",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-142",
  abstract =     "We present a novel technique for texture mapping on
                 arbitrary surfaces with minimal distortions by
                 preserving the local and global structure of the
                 texture. The recent introduction of the fast marching
                 method on triangulated surfaces made it possible to
                 compute a geodesic distance map from a given surface
                 point in O( n \lg n) operations, where n is the number
                 of triangles that represent the surface. We use this
                 method to design a surface flattening approach based on
                 multidimensional scaling (MDS). MDS is a family of
                 methods that map a set of points into a finite
                 dimensional flat (Euclidean) domain, where the only
                 given data is the corresponding distances between every
                 pair of points. The MDS mapping yields minimal changes
                 of the distances between the corresponding points. We
                 then solve an inverse problem and map a flat texture
                 patc",
  volume =       "8(2)",
  keywords =     "Texture mapping, multidimensional scaling, fast
                 marching method, Geodesic distance, Euclidean
                 distance",
  booktitle =    "IEEE Transcations on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2002-143,
  pages =        "1--19",
  year =         "2002",
  title =        "Controlling a camera in a virtual environment",
  author =       "{\'{E}}. Marchand and N. Courty",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-143",
  abstract =     "This paper presents an original solution to the camera
                 control problem in a virtual environment. Our objective
                 is to present a general framework that allows the
                 automatic control of a camera in a dynamic environment.
                 The proposed method is based on the image-based control
                 or visual servoing approach. It consists of positioning
                 a camera according to the information perceived in the
                 image. This is thus a very intuitive approach of
                 animation. To be able to react automatically to
                 modifications of the environment, we also considered
                 the introduction of constraints into the control. This
                 approach is thus adapted to highly reactive contexts
                 (virtual reality, video games). Numerous examples
                 dealing with classic problems in animation are
                 considered within this framework and presented in this
                 paper.",
  volume =       "18(1)",
  keywords =     "Automatic camera motion, Automatic cinematography,
                 Visual servoing, Animation",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-144,
  pages =        "20--28",
  year =         "2002",
  title =        "Real-time visualisation of fibre networks",
  author =       "J. Lindemann and O. Dahlblom",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-144",
  abstract =     "Different methods of real-time fibre-network
                 visualisation have been studied. Using an
                 extrusion-based method yields very good results, but
                 for large networks the frame rate becomes unacceptably
                 low. To increase the number of fibres that can be
                 visualised in real time, a textured billboard method
                 has been implemented. With this method, an average
                 performance gain of 60% has been achieved, using an
                 OpenGL implementation.",
  volume =       "18(1)",
  keywords =     "Fibre network, Visualisation, Billboard, Extrusion,
                 Real time",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-145,
  pages =        "29--40",
  year =         "2002",
  title =        "A {JPEG}-like texture compression with adaptive
                 quantization for 3{D} graphics application",
  author =       "C.-H. Chen and C.-Y. Lee",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-145",
  abstract =     "DCT-based compression is widely used in video and
                 image compression for a high compression ratio, but it
                 suffers from random-access problem when applied to
                 texture compression. In this paper we present a
                 JPEG-Like DCT-based texture compression technique which
                 is suitable for 3D graphics rendering system. We apply
                 a simple adaptive quantization on an 88 block-size
                 texture, such that the length of the encoded bit stream
                 of one block can be approximated to the target. A
                 pre-defined quantizer scale is encoded with the bit
                 stream with a small overhead. Our technique achieved a
                 high compression ratio, quality control of true color
                 texture, and random access of texture data.",
  volume =       "18(1)",
  keywords =     "3D graphics, Texture compression",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-146,
  pages =        "41--53",
  year =         "2002",
  title =        "A numerically efficient and stable algorithm for
                 animating water waves",
  author =       "Anita T. Layton and Michiel van de Panne",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-146",
  abstract =     "Water motion can be realistically captured by
                 physically based fluid models. We begin by presenting a
                 survey on fluid simulation models that are based on
                 fluid dynamics equations, from the most comprehensive
                 Navier-Stokes equations to the simple wave equation. We
                 then present a model that is based on the
                 two-dimensional shallow water equations. The equations
                 are integrated by a novel numerical method - the
                 implicit semi-Lagrangian integration scheme - which
                 allows large timesteps while maintaining stability, and
                 which is described in detail in this paper. Gentle wave
                 motions, the superposition of waves, drifting objects,
                 and obstacles and boundaries of various shapes can be
                 efficiently simulated with this model.",
  volume =       "18(1)",
  keywords =     "Fluid dynamics, Physically based model, Shallow water
                 equations, Semi-Lagrangian method, Implicit
                 integration",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-147,
  pages =        "54--67",
  year =         "2002",
  title =        "Compressing isosurfaces generated with marching
                 cubes",
  author =       "Shi-Nine Yang and Tian-Sheng Wu",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-147",
  abstract =     "The marching cubes (MC) algorithm has been widely used
                 for isosurface generation in volume rendering. However,
                 it usually generates an extensive amount of geometric
                 data that requires enormous storage and communication
                 bandwidth. This work presents a geometry compression
                 algorithm that employs several geometric properties of
                 the MC algorithm to reduce the number of bits of
                 generated triangle data. The proposed algorithm
                 attempts to encode each triangle-vertex according to
                 the index of its containing cube, the index of its
                 containing cube-edge, and its relative position on the
                 containing cube-edge. Furthermore, the connectivity
                 among triangle-vertices in a cube is encoded by the
                 signs of its vertices, computed by comparing their
                 values to the isosurface threshold. Both theoretical
                 analysis and experimental results show that the
                 proposed algorithm can achieve an excellent compression
                 ratio.",
  volume =       "18(1)",
  keywords =     "Geometry compression, Volume visualization,
                 Marching-cubes, Isosurface",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-148,
  pages =        "70--80",
  year =         "2002",
  title =        "Modeling a Murex cabritii sea shell with a structured
                 implicit surface modeler",
  author =       "Callum Galbraith and Przemyslaw Prusinkiewicz and
                 Brian Wyvill",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-148",
  abstract =     "Implicit surface modeling systems have been used since
                 the mid-1980s for the generation of cartoon-like
                 characters. Recently implicit models combined with
                 constructive solid geometry (CSG) have been used to
                 build engineering models with automatic blending. This
                 work is based on a structured implicit modeling system
                 which includes CSG, warping, 2D texture mapping and
                 operations based on the BlobTree, and its application
                 to the generation of a complex and visually accurate
                 biological model of the sea shell Murex cabritii. Since
                 the model is purely procedurally defined and does not
                 rely on polygon mesh operations, it is resolution
                 independent and can be rendered directly using ray
                 tracing. An interface has been built for the BlobTree
                 using an interpreted programming language (Python). The
                 language interface readily allows a user to
                 procedurally describe the shell based on numeric data
                 taken from the actual object.",
  volume =       "18(2)",
  keywords =     "Modeling, Seashells, Implicit surfaces, Constructive
                 solid geometry",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-149,
  pages =        "81--96",
  year =         "2002",
  title =        "Dynamic sculpting and animation of free-form
                 subdivision solids",
  author =       "Kevin T. McDonnell and Hong Qin",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-149",
  abstract =     "This paper presents a sculptured solid modeling system
                 founded upon free-form splines: (i) tri-variate
                 B-spline solids for regular (i.e., topologically
                 cuboid) shapes and (ii) dynamic MacCracken-Joy
                 subdivision-based solids of arbitrary topology. Our
                 primary contribution is that we integrate the geometry
                 of sculptured free-form solids with the powerful
                 physics-based modeling framework by augmenting pure
                 geometric entities with material properties and
                 physical behaviors. We have developed a sculpting
                 system with an array of design tools that afford users
                 the ability to deform and sculpt a variety of free-form
                 solids via a three-dimensional input device.",
  volume =       "18(2)",
  keywords =     "Computer graphics, Interactive techniques, Dynamics,
                 Solid sculpting, Animation",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InProceedings{EVL-2002-15,
  year =         "2002",
  title =        ": Interactive 3{D} Geometric Modelers with 2{D} {UI}",
  author =       "S.-T. Wu and M. de G. Malheiros",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-15",
  abstract =     "This paper presents an object-oriented framework which
                 enhances the collaboration of three categories of
                 experts that play fundamental role in the development
                 of a software for interactive 3D geometric modelers. It
                 aims at three purposes. First, it supports application
                 developers to build a graphics interface for
                 manipulating with 2D devices their own 3D data
                 representations, without intimate knowledge of its
                 internal structure. Second, it provides facilities for
                 interface researchers to create and experiment 3D
                 widgets from reusable draggers and 2D-3D mapping
                 strategies. Finally, it permits graphics experts to
                 implement sophisticated draggers and complex 2D-3D
                 mapping strategies by overriding operations of the
                 predefined abstract classes.",
  editor =       "V. Skala",
  keywords =     "Tools and toolkits, user interface design, interactive
                 geometric modeling, interactive 3D graphics, 2D
                 input/output devices",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InCollection{EVL-2002-150,
  pages =        "97--110",
  year =         "2002",
  title =        "Automated generation of control skeletons for use in
                 animation",
  author =       "Lawson Wade and Richard E. Parent",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-150",
  abstract =     "This paper describes an algorithm for automatically
                 generating a control skeleton (sometimes called an IK
                 skeleton) for use in animating a polygonal data model.
                 The algorithm consists of several steps, each of which
                 is performed automatically. The basic process involves
                 discretizing the figure, computing its discrete medial
                 surface (DMS), and then using the DMS both to create
                 the skeletal structure and to attach the vertices of
                 the model to that structure. The system can produce a
                 reasonably good control skeleton for any of a variety
                 of figures in as little as 1 or 2 min on a low-end
                 PC.",
  volume =       "ht18(2)",
  keywords =     "Control skeleton, IK skeleton, Skeleton rig,
                 Articulated figure",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-151,
  pages =        "111--120",
  year =         "2002",
  title =        "HyperMask - projecting a talking head onto a real
                 object",
  author =       "T. Yotsukura and S. Morishima and F. Nielsen and K.
                 Binsted and C. Pinhanez",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-151",
  abstract =     "HyperMask is a system which projects an animated face
                 onto a physical mask worn by an actor. As the mask
                 moves within a prescribed area, its position and
                 orientation are detected by a camera and the projected
                 image changes with respect to the viewpoint of the
                 audience. The lips of the projected face are
                 automatically synthesized in real time with the voice
                 of the actor, who also controls the facial expressions.
                 As a theatrical tool, HyperMask enables a new style of
                 storytelling. As a prototype system, we put a
                 self-contained HyperMask system in a trolley (disguised
                 as a linen cart), so that it projects onto the mask
                 worn by the actor pushing the trolley.",
  volume =       "18(2)",
  keywords =     "Talking heads, Homography, Neural networks,
                 Computerized theatrical performances. Lip-synch",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-152,
  pages =        "121--133",
  year =         "2002",
  title =        "Detection of human faces in a compressed domain for
                 video stratification",
  author =       "Tat-Seng Chua and Yunlong Zhao and Mohan S.
                 Kankanhalli",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-152",
  abstract =     "A news video can be modeled using the stratification
                 approach by identifying, among other entities, human
                 faces appearing in the video stream. To facilitate
                 this, we need to develop techniques to detect and track
                 human faces in video. This paper presents a frontal
                 face detection method that uses the gradient energy
                 representation extracted directly from the MPEG video.
                 The gradient energy representation permits pertinent
                 facial features of high contrast, such as the eyes,
                 nose and mouth, to be highlighted. A rule-based
                 classifier and a neural-network-based classifier are
                 designed to classify a gradient energy pattern as face
                 or non-face. The parameters for the two classifiers are
                 learnt from face and non-face samples. First, we use
                 the gradient energy face model to locate potential face
                 regions at multiple scales and locations. Second, we
                 perform skin-color verification to eliminate falsely
                 detected regions. The main contribution of this work is
                 in developing an efficient scale and position invariant
                 method to detect faces that operates in a transformed
                 gradient energy space in a compressed domain. The
                 system was tested on selected video clips from an
                 MPEG-7 data set and was found to be effective.",
  volume =       "18(2)",
  keywords =     "Video stratification, Face detection, MPEG video,
                 Compressed-domain processing, Neural network",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-153,
  pages =        "135--149",
  year =         "2002",
  title =        "Realistic rendering of an organ surface in real-time
                 for laparoscopic surgery simulation",
  author =       "Fabrice Neyret and Rapha{\"{e}}l Heiss and Franck
                 S{\'{e}}n{\'{e}}gas:",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-153",
  abstract =     "This paper deals with the rendering issues of the
                 problem of producing a real-time convincing surgery
                 simulation. The main scope of our project is to
                 simulate laparoscopic liver surgery. Nevertheless large
                 parts of the technique apply to other organs. We
                 address three aspects of the appearance of the organ
                 surface: the organ skin texture, the specular
                 highlights, and the reactions of the organ to the
                 instruments. For this last aspect we address three
                 effects: blood drops rolling on the surface, clear or
                 deep cauterization, and whitening of the surface under
                 local pressure. To meet the real-time constraint we use
                 advanced graphics features such as multipass rendering,
                 OpenGL texture extensions and lookup tables. Our target
                 hardware are high-end graphics accelerators such as the
                 SGI Infinite Reality. Nevertheless most of the
                 techniques apply to low-end graphics accelerators.",
  volume =       "18(3)",
  keywords =     "Real-time rendering, Multipass, Simulator, Medical
                 applications, Textures",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-154,
  pages =        "150--163",
  year =         "2002",
  title =        "Hands on a virtually elastic object",
  author =       "K. C. Hui and N. N. Wong",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-154",
  abstract =     "This paper reports on the development of a system for
                 manipulating a virtually elastic object by integrating
                 various techniques. A sensor glove is used for
                 interacting with the virtual object, and a virtual hand
                 is used for visualizing the interaction between the
                 hand and the object. Motion of the virtual hand is
                 controlled with the sensor glove. By using a simplified
                 hand model and a virtual object with a hierarchical
                 representation based on a sphere-tree, collision
                 between the fingers and the object is detected. Contact
                 points between the virtual hand and the object are used
                 for establishing constraints for the estimation of
                 deformation based on the finite-element method.
                 Experiments show that the critical process for
                 attaining interactive response is the inversion of the
                 stiffness matrix in finite-element analysis. The method
                 of condensation is adopted for reducing the sizes of
                 the matrices to be inverted. Parallel processing is
                 used for speeding up the matrix inversion process. Test
                 results show that an interactive response can be
                 attained for objects with a matrix to be inverted being
                 composed of less than 300 nodes, and the response time
                 of the system is inversely proportional to the number
                 of processors.",
  volume =       "18(3)",
  keywords =     "Deformable object, Glove-based input, Virtual reality,
                 Parallel processing",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-155,
  pages =        "164--185",
  year =         "2002",
  title =        "An algorithm for blob hierarchy layout",
  author =       "David Harel and Gregory Yashchin",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-155",
  abstract =     "We present an algorithm for the aesthetic drawing of
                 basic hierarchical blob structures, of the kind found
                 in higraphs and statecharts and in other diagrams in
                 which hierarchy is depicted as topological inclusion.
                 Our work could also be useful in Web page design,
                 window system dynamics, and possibly also newspaper
                 layout etc. Several criteria for aesthetics are
                 formulated, and we discuss their motivation, our
                 methods of implementation and the algorithm's
                 performance.",
  volume =       "18(3)",
  keywords =     "Aesthetics, Hierarchy, Higraph, Layout, Statechart",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-156,
  pages =        "186--204",
  year =         "2002",
  title =        "Acquiring, stitching and blending diffuse appearance
                 attributes on 3{D} models",
  author =       "C. Rocchini and P. Cignoni and C. Montani and R.
                 Scopigno",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-156",
  abstract =     "A new system for the construction of highly realistic
                 models of real free-form 3D objects is proposed, based
                 on the integration of several techniques (automatic 3D
                 scanning, inverse illumination, inverse texture-mapping
                 and textured 3D graphics). Our system improves the
                 quality of a 3D model (e.g. acquired with a range
                 scanning device) by adding color detail and, if
                 required, high-frequency shape detail. Detail is
                 obtained by processing a set of digital photographs of
                 the object. This is carried out by performing several
                 subtasks: to compute camera calibration and position,
                 to remove illumination effects obtaining both
                 illumination-invariant reflectance properties and a
                 high-resolution surface normal field, and finally to
                 blend and stitch the acquired detail on the triangle
                 mesh via standard texture mapping. In particular, the
                 smooth join between different images that map on
                 adjacent sections of the surface is obtained by
                 applying an accurate piecewise local registration of
                 the original images and by blending textures. For each
                 mesh face which is on the adjacency border between
                 different observed images, a corresponding triangular
                 texture patch can also be resampled as a weighted blend
                 of the corresponding adjacent image sections. Examples
                 of the results obtained with sample works of art are
                 presented and discussed.",
  volume =       "18(3)",
  keywords =     "3D scanning, Image processing, Inverse illumination,
                 Texture_to_geometry registration, Texture mapping",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-157,
  pages =        "1--19",
  year =         "2002",
  title =        "Steerable illumination textures",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-157",
  author =       "Michael Ashikhmin and Peter Shirley",
  abstract =     "We introduce a new set of illumination basis functions
                 designed for lighting bumpy surfaces. This lighting
                 includes shadowing and interreflection. To create an
                 image with a new light direction, only a linear
                 combination of precomputed textures is required. This
                 is possible by using a carefully selected set of
                 steerable basis functions. Steerable basis lights have
                 the property that they allow lights to move
                 continuously without jarring visual artifacts. The new
                 basis lights are shown to produce images of high visual
                 quality with as few as 49 basis textures.",
  editor =       "Jessica Hodgins",
  keywords =     "Bump mapping, displacement mapping, relighting,
                 steerable functions, textures",
  volume =       "21(1)",
  booktitle =    "ACM Transactions on Graphics",
  publisher =    "ACM Press",
}

@InCollection{EVL-2002-158,
  pages =        "20--51",
  year =         "2002",
  title =        "A framework for geometric warps and deformations",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-158",
  author =       "Tim Milliron and Robert J. Jensen and Ronen Barzel and
                 Adam Finkelstein",
  abstract =     "We present a framework for geometric warps and
                 deformations. The framework provides a conceptual and
                 mathematical foundation for analyzing known warps and
                 for developing new warps, and serves as a common base
                 for many warps and deformations. Our framework is
                 composed of two components: a generic modular algorithm
                 for warps and deformations; and a concise,
                 geometrically meaningful formula that describes how
                 warps are evaluated. Together, these two elements
                 comprise a complete framework useful for analyzing,
                 evaluating, designing, and implementing deformation
                 algorithms. While the framework is independent of
                 user-interfaces and geometric model representations and
                 is formally capable of describing any warping
                 algorithm, its design is geared toward the most
                 prevalent class of user-controlled deformations: those
                 computed using geometric operations. To demonstrate the
                 expressive power of the framework, we cast several
                 well-known warps in terms of the framework. To
                 illustrate the framework's usefulness for analyzing and
                 modifying existing warps, we present variations of
                 these warps that provide additional functionality or
                 improved behavior. To show the utility of the framework
                 for developing new warps, we design a novel 3-D warping
                 algorithm: a mesh warp---useful as a modeling and
                 animation tool---that allows users to deform a detailed
                 surface by manipulating a low-resolution mesh of
                 similar shape. Finally, to demonstrate the mathematical
                 utility of the framework, we use the framework to
                 develop guarantees of several mathematical properties
                 such as commutativity and continuity for large classes
                 of deformations.",
  editor =       "Jessica Hodgins",
  keywords =     "Deformation, warp",
  volume =       "21(1)",
  booktitle =    "ACM Transactions on Graphics",
  publisher =    "ACM Press",
}

@InCollection{EVL-2002-159,
  pages =        "52--86",
  year =         "2002",
  title =        "On the algebraic and geometric foundations of computer
                 graphics",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-159",
  author =       "Ron Goldman",
  abstract =     "Today's computer graphics is ostensibly based upon
                 insights from projective geometry and computations on
                 homogeneous coordinates. Paradoxically, however,
                 projective spaces and homogeneous coordinates are
                 incompatible with much of the algebra and a good deal
                 of the geometry currently in actual use in computer
                 graphics. To bridge this gulf between theory and
                 practice, Grassmann spaces are proposed here as an
                 alternative to projective spaces. We establish that
                 unlike projective spaces, Grassmann spaces do support
                 all the algebra and geometry needed for contemporary
                 computer graphics. We then go on to explain how to
                 exploit this algebra and geometry for a variety of
                 applications, both old and new, including the graphics
                 pipeline, shading algorithms, texture maps, and
                 overcrown surfaces.",
  editor =       "Jessica Hodgins",
  keywords =     "Grassmann space, homogeneous coordinates, mass-points,
                 projective space",
  volume =       "21(1)",
  booktitle =    "ACM Transactions on Graphics",
  publisher =    "ACM Press",
}

@InProceedings{EVL-2002-16,
  year =         "2002",
  title =        "{PGF} - {A} New Progressive File Format for Lossy and
                 Lossless Image Compression",
  author =       "C. Stamm",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-16",
  abstract =     "We present a new image file format, called Progressive
                 Graphics File (PGF), which is based on a discrete
                 wavelet transform with progressive coding features. We
                 show all steps of a transform based coder in detail and
                 discuss some important aspects of our careful
                 implementation. PGF can be used for lossless and lossy
                 compression. It performs best for natural images and
                 aerial ortho-photos. For these types of images it shows
                 in its lossy compression mode a better compression
                 efficiency than JPEG. This efficiency gain is almost
                 for free, because the encoding and decoding times are
                 only marginally longer. We also compare PGF with JPEG
                 2000 and show that JPEG 2000 is about ten times slower
                 than PGF. In its lossless compression mode PGF has a
                 slightly worse compression efficiency than JPEG 2000,
                 but a clearly better compression efficiency than
                 JPEG-LS and PNG. If both, compression efficiency and
                 runtime, is important, then PGF is the best of the
                 tested algorithms for compression of natural images and
                 aerial photos.",
  editor =       "V. Skala",
  keywords =     "Still image file format, lossy/lossless image
                 compression, progressive coding, discrete wavelet
                 transform",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InCollection{EVL-2002-160,
  pages =        "88--105",
  year =         "2002",
  title =        "Topology-reducing surface simplification using a
                 discrete solid representation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-160",
  author =       "Carlos And{\'{u}}jar and Pere Brunet and Dolors
                 Ayala",
  abstract =     "This paper presents a new approach for generating
                 coarse-level approximations of topologically complex
                 models. Dramatic topology reduction is achieved by
                 converting a 3D model to and from a volumetric
                 representation. Our approach produces valid,
                 error-bounded models and supports the creation of
                 approximations that do not interpenetrate the original
                 model, either being completely contained in the input
                 solid or bounding it. Several simple to implement
                 versions of our approach are presented and discussed.
                 We show that these methods perform significantly better
                 than other surface-based approaches when simplifying
                 topologically-rich models such as scene parts and
                 complex mechanical assemblies.",
  editor =       "Jessica Hodgins",
  keywords =     "Geometry simplification, multiresolution models,
                 surface reconstruction",
  volume =       "21(2)",
  booktitle =    "ACM Transactions on Graphics",
  publisher =    "ACM Press",
}

@InCollection{EVL-2002-161,
  pages =        "106--131",
  year =         "2002",
  title =        "Meshed atlases for real-time procedural solid
                 texturing",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-161",
  author =       "Nathan A. Carr and John C. Hart",
  abstract =     "We describe an implementation of procedural solid
                 texturing that uses the texture atlas, a one-to-one
                 mapping from an object's surface into its texture
                 space. The method uses the graphics hardware to
                 rasterize the solid texture coordinates as colors
                 directly into the atlas. A texturing procedure is
                 applied per-pixel to the texture map, replacing each
                 solid texture coordinate with its corresponding
                 procedural solid texture result. The procedural solid
                 texture is then mapped back onto the object surface
                 using standard texture mapping. The implementation
                 renders procedural solid textures in real time, and the
                 user can design them interactively.The quality of this
                 technique depends greatly on the layout of the texture
                 atlas. A broad survey of texture atlas schemes is used
                 to develop a set of general purpose mesh atlases and
                 tools for measuring their effectiveness at distributing
                 as many available texture samples as evenly across the
                 surface as possible. The main contribution of this
                 paper is a new multiresolution texture atlas. It
                 distributes all available texture samples in a nearly
                 uniform distribution. This multiresolution texture
                 atlas also supports MIP-mapped minification
                 antialiasing and linear magnification filtering.",
  editor =       "Jessica Hodgins",
  keywords =     "MIP-map, Mesh partitioning, procedural texturing,
                 solid texturing, texture atlas, texture mapping",
  volume =       "21(2)",
  booktitle =    "ACM Transactions on Graphics",
  publisher =    "ACM Press",
}

@InCollection{EVL-2002-162,
  pages =        "132--175",
  year =         "2002",
  title =        "Pareto-optimal formulations for cost versus
                 colorimetric accuracy trade-offs in printer color
                 management",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-162",
  author =       "D. J. Littlewood and P. A. Drakopoulos and G.
                 Subbarayan",
  abstract =     "Color management for the printing of digital images is
                 a challenging task, due primarily to nonlinear
                 ink-mixing behavior and the presence of redundant
                 solutions for print devices with more than three inks.
                 Algorithms for the conversion of image data to
                 printer-specific format are typically designed to
                 achieve a single predetermined rendering intent, such
                 as colorimetric accuracy. In the present paper we
                 present two CIELAB to CMYK color conversion schemes
                 based on a general Pareto-optimal formulation for
                 printer color management. The schemes operate using a
                 149-color characterization data set selected to
                 efficiently capture the entire CMYK gamut. The first
                 scheme uses artificial neural networks as transfer
                 functions between the CIELAB and CMYK spaces. The
                 second scheme is based on a reformulation of
                 tetrahedral interpolation as an optimization problem.
                 Characterization data are divided into tetrahedra for
                 the interpolation-based approach using the program
                 Qhull, which removes the common restriction that
                 characterization data be well organized. Both schemes
                 offer user control over trade-off problems such as cost
                 versus reproduction accuracy, allowing for
                 user-specified print objectives and the use of
                 constraints such as maximum allowable ink and maximum
                 allowable &Delta;E&ast;ab. A formulation for
                 minimization of ink is shown to be particularly
                 favorable, integrating both clipping and gamut
                 compression features into a single methodology. Codes
                 developed as applications of these schemes were used to
                 convert several CIELAB Tiff images to CMYK format,
                 providing both qualitative and quantitative
                 verification of the Pareto-optimal approach. Prints of
                 the MacBeth ColorCheckertm chart were accurate within
                 approximately to 3 &Delta;E&ast;ab for in-gamut colors.
                 Modifications to this approach are presented that offer
                 user control over grey component replacement and
                 provide additional options for rendering intent.",
  editor =       "Jessica Hodgins",
  keywords =     "Artificial Neural Networks, CMYK, Color Conversion,
                 Color Fidelity, Color Management, Color Matching, Color
                 Printing, Color Space Transformation, Optimization,
                 Pareto-optimization, Tetrahedral Interpolation",
  volume =       "21(2)",
  booktitle =    "ACM Transactions on Graphics",
  publisher =    "ACM Press",
}

@InCollection{EVL-2002-163,
  pages =        "176--206",
  year =         "2002",
  title =        "The 3{D} visibility complex",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-163",
  author =       "Fr{\'{e}}do Durand and George Drettakis and Claude
                 Puech",
  abstract =     "Visibility problems are central to many computer
                 graphics applications. The most common examples include
                 hidden-part removal for view computation, shadow
                 boundaries, mutual visibility of objects for lighting
                 simulation. In this paper, we present a theoretical
                 study of 3D visibility properties for scenes of smooth
                 convex objects. We work in the space of light rays, or
                 more precisely, of maximal free segments. We group
                 segments that {"}see{"} the same object; this defines
                 the 3D visibility complex. The boundaries of these
                 groups of segments correspond to the visual events of
                 the scene (limits of shadows, disappearance of an
                 object when the viewpoint is moved, etc.). We provide a
                 worst case analysis of the complexity of the visibility
                 complex of 3D scenes, as well as a probabilistic study
                 under a simple assumption for {"}normal{"} scenes. We
                 extend the visibility complex to handle temporal
                 visibility. We give an output-sensitive construction
                 algorithm and present applications of our approach.",
  editor =       "Jessica Hodgins",
  keywords =     "Line-space, visibility classification, visibility
                 complex, visibility skeleton",
  volume =       "21(2)",
  booktitle =    "ACM Transactions on Graphics",
  publisher =    "ACM Press",
}

@InCollection{EVL-2002-164,
  pages =        "207--229",
  year =         "2002",
  title =        "Permission grids: practical, error-bounded
                 simplification",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-164",
  author =       "Steve Zelink and and Michael Garland",
  abstract =     "We introduce the permission grid, a spatial occupancy
                 grid which can be used to guide almost any standard
                 polygonal surface simplification algorithm into
                 generating an approximation with a guaranteed geometric
                 error bound. In particular, all points on the
                 approximation are guaranteed to be within some
                 user-specified distance from the original surface. Such
                 bounds are notably absent from many current
                 simplification methods, and are becoming increasingly
                 important for applications in scientific computing and
                 adaptive level of detail control. Conceptually simple,
                 the permission grid defines a volume in which the
                 approximation must lie, and does not permit the
                 underlying simplification algorithm to generate
                 approximations outside the volume.The permission grid
                 makes three important, practical improvements over
                 current error-bounded simplification methods. First, it
                 works on arbitrary triangular models, handling all
                 manners of mesh degeneracies gracefully. Further, the
                 error tolerance may be easily expanded as
                 simplification proceeds, allowing the construction of
                 an error-bounded level of detail hierarchy with vertex
                 correspondences among all levels of detail. And
                 finally, the permission grid has a representation
                 complexity independent of the size of the input model,
                 and a small running time overhead, making it more
                 practical and efficient than current methods with
                 similar guarantees.",
  editor =       "Jessica Hodgins",
  keywords =     "Error bounds, level of detail, surface
                 simplification",
  volume =       "21(2)",
  booktitle =    "ACM Transactions on Graphics",
  publisher =    "ACM Press",
}

@{,
}

@InProceedings{EVL-2002-166,
  pages =        "243--248",
  year =         "2002",
  title =        "Video Matting",
  author =       "Yung-Yu Chuang and Aseem Agarwala and Brian Curless
                 and David H. Salesin and Richard Szeliski",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-166",
  abstract =     "This paper describes a new framework for video
                 matting, the process of pulling a high-quality alpha
                 matte and foreground from a video sequence. The
                 framework builds upon techniques in natural image
                 matting, optical flow computation, and background
                 estimation. User interaction is comprised of garbage
                 matte specification if background estimation is needed,
                 and hand-drawn keyframe segmentations into
                 {"}foreground,{"} {"}background,{"} and {"}unknown{"}.
                 The segmentations, called trimaps, are interpolated
                 across the video volume using forward and backward
                 optical flow. Competing flow estimates are combined
                 based on information about where flow is likely to be
                 accurate. A Bayesian matting technique uses the flowed
                 trimaps to yield high-quality mattes of moving
                 foreground elements with complex boundaries filmed by a
                 moving camera. A novel technique for smoke matte
                 extraction is also demonstrated.",
  editor =       "John Hughes",
  keywords =     "Alpha channel, blue-screen matting, image-based
                 rendering, layer extraction, matting and compositing,
                 video processing",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-167,
  pages =        "249--256",
  year =         "2002",
  title =        "Gradient Domain High Dynamic Range Compression",
  author =       "Raanan Fattal and Dani Lischinski and Michael Werman",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-167",
  abstract =     "We present a new method for rendering high dynamic
                 range images on conventional displays. Our method is
                 conceptually simple, computationally efficient, robust,
                 and easy to use. We manipulate the gradient field of
                 the luminance image by attenuating the magnitudes of
                 large gradients. A new, low dynamic range image is then
                 obtained by solving a Poisson equation on the modified
                 gradient field. Our results demonstrate that the method
                 is capable of drastic dynamic range compression, while
                 preserving fine details and avoiding common artifacts,
                 such as halos, gradient reversals, or loss of local
                 contrast. The method is also able to significantly
                 enhance ordinary images by bringing out detail in dark
                 regions.",
  editor =       "John Hughes",
  keywords =     "Digital photography, high dynamic range
                 compression,image-based rendering, image processing,
                 signal processing, tone mapping",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-168,
  pages =        "257--265",
  year =         "2002",
  title =        "Fast Bilateral Filtering for the Display of High
                 Dynamic Range Image",
  author =       "Fr{\'{e}}do Durand and Julie Dorsey",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-168",
  abstract =     "We present a new technique for the display of
                 high-dynamic-range-images, which reduces the contrast
                 while preserving detail. It is based on a two-scale
                 decomposition of the image into a base layer, encoding
                 large-scale variations, and a detail layer. Only the
                 base layer has its contrast reduced, thereby preserving
                 detail. The base layer is obtained using an
                 edge-preserving filter called the bilateral filter.
                 This is a non-linear filter, where the weight of each
                 pixel is computed using a Gaussian in the spatial
                 domain multiplied by an influence function in the
                 intensity domain that decreases the weight of pixels
                 with large intensity differences. We express bilateral
                 filtering in the framework of robust statistics and
                 show how it relates to anisotropic diffusion. We then
                 accelerate bilateral filtering by using a
                 piecewise-linear approximation in the intensity domain
                 and appropriate subsampling. This results in a speedup
                 of two orders of magnitude. The method is fast and
                 requires no parameter setting.",
  editor =       "John Hughes",
  keywords =     "Image processing, tone mapping, contrast reduction,
                 edge-preserving filtering, weird maths",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Graphics Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-169,
  pages =        "267--276",
  year =         "2002",
  title =        "Photographic Tone Reproduction for Digital Images",
  author =       "Erik Reinhard and Michael Stark and Peter Shirley and
                 Jim Ferwerda",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-169",
  abstract =     "A classic photographic task is the mapping of the
                 potentially high dynamic range of real world luminances
                 to the low dynamic range of the photographic print.
                 This tone reproduction problem is also faced by
                 computer graphics practitioners who map digital images
                 to a low dynamic range print or screen. The work
                 presented in this paper leverages the time-tested
                 techniques of photographic practice to develop a new
                 tone reproduction operator. In particular, we use and
                 extend the techniques developed by Ansel Adams to deal
                 with digital images. The resulting algorithm is simple
                 and produces good results for a wide variety of
                 images.",
  editor =       "John Hughes",
  keywords =     "Tone reproduction, dynamic range, Zone System",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Confernce Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-17,
  year =         "2002",
  title =        "Line Scratch Detection on Digital Images: An Energy
                 Based Model",
  author =       "D. Vitulano and V. Bruni and P. Ciarlini",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-17",
  abstract =     "In this paper, a model for automatic detection of line
                 scratches on digital images is proposed. It consists in
                 a generalization of the Kokaram's model using width and
                 height features of the line profile along with Weber's
                 law, to test scratches visibility on the image.
                 Experimental results show that the algorithm works
                 better than the existing models in detecting true
                 scratches with a lower computing time.",
  editor =       "V. Skala",
  keywords =     "Digital Film Restoration, Scratch Detection, Weber's
                 Law",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-170,
  pages =        "277--280",
  year =         "2002",
  title =        "Transferring Color to Greyscale Images",
  author =       "Tomihisa Welsh and Michael Ashikhmin and Klaus
                 Mueller",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-170",
  abstract =     "We introduce a general technique for ?colorizing?
                 greyscale images by transferring color between a
                 source, color image and a destination, greyscale image.
                 Although the general problem of adding chromatic values
                 to a greyscale image has no exact, objective solution,
                 the current approach attempts to provide a method to
                 help minimize the amount of human labor required for
                 this task. Rather than choosing RGB colors from a
                 palette to color individual components, we transfer the
                 entire color ?mood? from the source to the target image
                 by matching luminance and texture information between
                 the images. We choose to transfer only chromaticity
                 information and retain the original luminance values of
                 the target image. The procedure is further enhanced by
                 allowing the user to match areas of the two images with
                 rectangular swatches. We show that this simple
                 technique can be successfully applied to a variety of
                 images and video provided that texture and luminance
                 are sufficiently distinct. The images we have generated
                 demonstrate the potential and utility of our technique
                 in a diverse set of application domains.",
  editor =       "John Hughes",
  keywords =     "Image Processing, Color, Texture Synthesis, Video",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-171,
  pages =        "281--290",
  year =         "2002",
  title =        "{CHARMS}: {A} Simple Framework for Adaptive
                 Simulation",
  author =       "Eitan Grinspun and Petr Krysl and Peter
                 Schr{\"{o}}der",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-171",
  abstract =     "Finite element solvers are a basic component of
                 simulation applications; they are common in computer
                 graphics, engineering, and medical simulations.
                 Although adaptive solvers can be of great value in
                 reducing the often high computational cost of
                 simulations they are not employed broadly. Indeed,
                 building adaptive solvers can be a daunting task
                 especially for 3D finite elements. In this paper we are
                 introducing a new approach to produce conforming,
                 hierarchical, adaptive refinement methods (CHARMS). The
                 basic principle of our approach is to refine basis
                 functions, not elements. This removes a number of
                 implementation headaches associated with other
                 approaches and is a general technique independent of
                 domain dimension (here 2D and 3D), element type (e.g.,
                 triangle, quad, tetrahedron, hexahedron), and basis
                 function order (piecewise linear, higher order
                 B-splines, Loop subdivision, etc.). The (un-)refinement
                 algorithms are simple and require little in terms of
                 data structure support. We demonstrate the versatility
                 of our new approach through 2D and 3D examples,
                 including medical applications and thin-shell
                 animations.",
  editor =       "John Hughes",
  keywords =     "Adaptive Computation, Refinement Relation, Basis
                 Function, Subdivision, Multiresolution",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-172,
  pages =        "291--294",
  year =         "2002",
  title =        "Graphical Modeling and Animation of Ductile Fracture",
  author =       "James F. O'Brien and Adam W. Bargteil and Jessica K.
                 Hodgins",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-172",
  abstract =     "In this paper, we describe a method for realistically
                 animating ductile fracture in common solid materials
                 such as plastics and metals. The effects that
                 characterize ductile fracture occur due to interaction
                 between plastic yielding and the fracture process. By
                 modeling this interaction, our ductile fracture method
                 can generate realistic motion for a much wider range of
                 materials than could be realized with a purely brittle
                 model. This method directly extends our prior work on
                 brittle fracture [O'Brien and Hodgins, SIGGRAPH 99]. We
                 show that adapting that method to ductile as well as
                 brittle materials requires only a simple to implement
                 modification that is computationally inexpensive. This
                 paper describes this modification and presents results
                 demonstrating some of the effects that may be realized
                 with it.",
  editor =       "John Hughes",
  keywords =     "Animation techniques, physically based modeling,
                 simulation, dynamics, fracture, cracking, deformation,
                 finite element method, ductile fracture, plasticity",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-173,
  pages =        "295--301",
  year =         "2002",
  title =        "Creating Models of Truss Structures With
                 Optimization",
  author =       "Jeffrey Smith and Jessica K. Hodgins and Irving
                 Oppenheim and Andrew Witkin",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-173",
  abstract =     "We present a method for designing truss structures, a
                 common and complex category of buildings, using
                 non-linear optimization. Truss structures are
                 ubiquitous in the industrialized world, appearing as
                 bridges, towers, roof supports and building
                 exoskeletons, yet are complex enough that modeling them
                 by hand is time consuming and tedious. We represent
                 trusses as a set of rigid bars connected by pin joints,
                 which may change location during optimization. By
                 including the location of the joints as well as the
                 strength of individual beams in our design variables,
                 we can simultaneously optimize the geometry and the
                 mass of structures. We present the details of our
                 technique together with examples illustrating its use,
                 including comparisons with real structures.",
  editor =       "John Hughes",
  keywords =     "Physically based modeling, truss structures,
                 constrained optimization, nonlinear optimization",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-174,
  pages =        "302--311",
  year =         "2002",
  title =        "A Procedural Approach to Authoring Solid Models",
  author =       "Barbara Cutler and Julie Dorsey and Leonard McMillan
                 and Matthias M{\"{u}}ller and Robert Jagnow",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-174",
  abstract =     "We present a procedural approach to authoring layered,
                 solid models. Using a simple scripting language, we
                 define the internal structure of a volume from one or
                 more input meshes. Sculpting and simulation operators
                 are applied within the context of the language to shape
                 and modify the model. Our framework treats simulation
                 as a modeling operator rather than simply as a tool for
                 animation, thereby suggesting a new paradigm for
                 modeling as well as a new level of abstraction for
                 interacting with simulation environments. Capturing
                 real-world effects with standard modeling techniques is
                 extremely challenging. Our key contribution is a
                 concise procedural approach for seamlessly building and
                 modifying complex solid geometry. We present an
                 implementation of our language using a flexible
                 tetrahedral representation. We show a variety of
                 complex objects modeled in our system using tools that
                 interface with finite element method and particle
                 system simulations.",
  editor =       "John Hughes",
  keywords =     "Volumetric modeling, signed-distance function,
                 tetrahedral representation",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-175,
  pages =        "312--321",
  year =         "2002",
  title =        "Cut-and-Paste Editing of Multiresolution Surfaces",
  author =       "Henning Biermann and Ioana Martin and Fausto
                 Bernardini and Denis Zorin",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-175",
  abstract =     "Cutting and pasting to combine different elements into
                 a common structure are widely used operations that have
                 been successfully adapted to many media types. Surface
                 design could also benefit from the availability of a
                 general, robust, and efficient cut-and-paste tool,
                 especially during the initial stages of design when a
                 large space of alternatives needs to be explored.
                 Techniques to support cut-and-paste operations for
                 surfaces have been proposed in the past, but have been
                 of limited usefulness due to constraints on the type of
                 shapes supported and the lack of real-time interaction.
                 In this paper, we describe a set of algorithms based on
                 multiresolution subdivision surfaces that perform at
                 interactive rates and enable intuitive cut-and-paste
                 operations.",
  editor =       "John Hughes",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-176,
  pages =        "322--329",
  year =         "2002",
  title =        "Pointshop 3{D}: An Interactive System for Point-Based
                 Surface Editing",
  author =       "Matthias Zwicker and Mark Pauly and Oliver Knoll and
                 Markus Gross",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-176",
  abstract =     "We present a system for interactive shape and
                 appearance editing of 3D point-sampled geometry. By
                 generalizing conventional 2D pixel editors, our system
                 supports a great variety of different interaction
                 techniques to alter shape and appearance of 3D point
                 models, including cleaning, texturing, sculpting,
                 carving, filtering, and resampling. One key ingredient
                 of our framework is a novel concept for interactive
                 point cloud parameterization allowing for distortion
                 minimal and aliasing-free texture mapping. A second one
                 is a dynamic, adaptive resampling method which builds
                 upon a continuous reconstruction of the model surface
                 and its attributes. These techniques allow us to
                 transfer the full functionality of 2D image editing
                 operations to the irregular 3D point setting. Our
                 system reads, processes, and writes point-sampled
                 models without intermediate tesselation. It is intended
                 to complement existing low cost 3D scanners and point
                 rendering pipelines for efficient 3D content
                 creation.",
  editor =       "John Hughes",
  keywords =     "3D Content Creation, Point-Based Graphics,Surface
                 Painting, Surface Sculpting, Texture Mapping,
                 Parameterization",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-177,
  pages =        "330--338",
  year =         "2002",
  title =        "Level Set Surface Editing Operators",
  author =       "Ken Museth and David E. Bree and and Ross T. Whitaker
                 and Alan H. Barr",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-177",
  abstract =     "We present a level set framework for implementing
                 editing operators for surfaces. Level set models are
                 deformable implicit surfaces where the deformation of
                 the surface is controlled by a speed function in the
                 level set partial differential equation. In this paper
                 we define a collection of speed functions that produce
                 a set of surface editing operators. The speed functions
                 describe the velocity at each point on the evolving
                 surface in the direction of the surface normal. All of
                 the information needed to deform a surface is
                 encapsulated in the speed function, providing a simple,
                 unified computational framework. The user combines
                 predefined building blocks to create the desired speed
                 function. The surface editing operators are quickly
                 computed and may be applied both regionally and
                 globally. The level set framework offers several
                 advantages. 1)By construction, self-intersection cannot
                 occur, which guarantees the generation of
                 physically-realizable, simple, closed surfaces. 2)Level
                 set models easily change topological genus, and 3) are
                 free of the edge connectivity and mesh quality problems
                 associated with mesh models. We present five examples
                 of surface editing operators: blending, smoothing,
                 sharpening, openings/closings and embossing. We
                 demonstrate their effectiveness on several scanned
                 objects and scan-converted models.",
  editor =       "John Hughes",
  keywords =     "Deformations, geometric modeling, implicit surfaces,
                 shape blending",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-178,
  pages =        "339--346",
  year =         "2002",
  title =        "Dual Contouring of Hermite Data",
  author =       "Tao Ju and Frank Losasso and Scott Schaefer and Joe
                 Warren",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-178",
  abstract =     "This paper describes a new method for contouring a
                 signed grid whose edges are tagged by Hermite data
                 (i.e; exact intersection points and normals). This
                 method avoids the need to explicitly identify and
                 process {"}features{"} as required in previous Hermite
                 contouring methods. We extend this contouring method to
                 the case of multi-signed functions and demonstrate how
                 to model textured contours using multi-signed
                 functions. Using a new, numerically stable
                 representation for quadratic error functions, we
                 develop an octree-based method for simplifying these
                 contours and their textured regions. We next extend our
                 contouring method to these simplified octrees. This new
                 method imposes no constraints on the octree (such as
                 being a restricted octree) and requires no {"}crack
                 patching{"}. We conclude with a simple test for
                 preserving the topology of both the contour and its
                 textured regions during simplification.",
  editor =       "John Hughes",
  keywords =     "Implicit functions, contouring, crack prevention,
                 quadratic error function, polyhedral simplification",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-179,
  pages =        "347--354",
  year =         "2002",
  title =        "Interactive Geometry Remeshing",
  author =       "Pierre Alliez and Mark Meyer and Mathieu Desbrun",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-179",
  abstract =     "We present a novel technique, both flexible and
                 efficient, for interactive remeshing of irregular
                 geometry. First, the original (arbitrary genus) mesh is
                 substituted by a series of 2D maps in parameter space.
                 Using these maps, our algorithm is then able to take
                 advantage of established signal processing and
                 halftoning tools that offer real-time interaction and
                 intricate control. The user can easily combine these
                 maps to create a control map - a map which controls the
                 sampling density over the surface patch. This map is
                 then sampled at interactive rates allowing the user to
                 easily design a tailored resampling. Once this sampling
                 is complete, a Delaunay triangulation and fast
                 optimization are performed to perfect the final mesh.
                 As a result, our remeshing technique is extremely
                 versatile and general, being able to produce
                 arbitrarily complex meshes with a variety of properties
                 including: uniformity, regularity, semi-regularity,
                 curvature sensitive resampling, and feature
                 preservation. We provide a high level of control over
                 the sampling distribution allowing the user to
                 interactively custom design the mesh based on their
                 requirements thereby increasing their productivity in
                 creating a wide variety of meshes.",
  editor =       "John Hughes",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-18,
  year =         "2002",
  title =        "Fuzzy Linking Models for Pyramidal Edge Detection",
  author =       "Z.-G. Wang and W. Wang and X.-M. Xu",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-18",
  abstract =     "This paper presents a novel approach to
                 multiresolution edge detection, which combines the
                 grayscale morphological filtering, pyramid data
                 structure and fuzzy technique. It mainly addresses the
                 linking of edge nodes at adjacent levels in image
                 pyramid. In previous pyramidal approaches, linking is
                 based on linear relationship and intensity proximity
                 only. The approach proposed here contains multiple
                 linking mechanisms and introduces fuzzy technique. It
                 considers the parent-child linking relationship of edge
                 nodes between the two adjacent levels as fuzzy model,
                 which is trained offline using real image data. Through
                 this fuzzy linking model, the coarse, low-resolution
                 edge map is propagated and refined to the fine,
                 high-resolution edge map in the pyramid. The validation
                 experiment is carried out on one synthetic image and
                 two real images, and the results show that our approach
                 has better performance on the localization and
                 detection of continuous large-scale object boundaries
                 than Cannys edge detector and other previous
                 multiresolution approaches. In addition, the proposed
                 approach has high computational efficiency.",
  editor =       "V. Skala",
  keywords =     "Mathematical morphology, pyramid structure, fuzzy
                 sets, edge detection, multiresolution image analysis.",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-180,
  pages =        "335--361",
  year =         "2002",
  title =        "Geometry Images",
  author =       "Xianfeng Gu and Steven J. Gortler and Hugues Hoppe",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-180",
  abstract =     "Surface geometry is often modeled with irregular
                 triangle meshes. The process of remeshing refers to
                 approximating such geometry using a mesh with
                 (semi)-regular connectivity, which has advantages for
                 many graphics applications. However, current techniques
                 for remeshing arbitrary surfaces create only
                 semi-regular meshes. The original mesh is typically
                 decomposed into a set of disk-like charts, onto which
                 the geometry is parametrized and sampled. In this
                 paper, we propose to remesh an arbitrary surface onto a
                 completely regular structure we call a geometry image.
                 It captures geometry as a simple 2D array of quantized
                 points. Surface signals like normals and colors are
                 stored in similar 2D arrays using the same implicit
                 surface parametrization -- texture coordinates are
                 absent. To create a geometry image, we cut an arbitrary
                 mesh along a network of edge paths, and parametrize the
                 resulting single chart onto a square. Geometry images
                 can be encoded using traditional image compression
                 algorithms, such as wavelet-based coders.",
  editor =       "John Hughes",
  keywords =     "Remeshing, surface parametrization",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-181,
  pages =        "362--371",
  year =         "2002",
  title =        "Least Squares Conformal Maps for Automatic Texture
                 Atlas Generation",
  author =       "Bruno L{\'{e}}vy and Sylvain Petitjean and Nicolas Ray
                 and J{\'{e}}rome Maillot",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-181",
  abstract =     "A Texture Atlas is an efficient color representation
                 for 3D Paint Systems. The model to be textured is
                 decomposed into charts homeomorphic to discs, each
                 chart is parameterized, and the unfolded charts are
                 packed in texture space. Existing texture atlas methods
                 for triangulated surfaces suffer from several
                 limitations, requiring them to generate a large number
                 of small charts with simple borders. The
                 discontinuities between the charts cause artifacts, and
                 make it difficult to paint large areas with regular
                 patterns. In this paper, our main contribution is a new
                 quasi-conformal parameterization method, based on a
                 least-squares approximation of the Cauchy-Riemann
                 equations. The so-defined objective function minimizes
                 angle deformations, and we prove the following
                 properties: the minimum is unique, independent of a
                 similarity in texture space, independent of the
                 resolution of the mesh and cannot generate triangle
                 flips. The function is numerically well behaved and can
                 therefore be very efficiently minimized. Our approach
                 is robust, and can parameterize large charts with
                 complex borders. We also introduce segmentation methods
                 to decompose the model into charts with natural shapes,
                 and a new packing algorithm to gather them in texture
                 space. We demonstrate our approach applied to paint
                 both scanned and modeled data sets.",
  editor =       "John Hughes",
  keywords =     "Texture Mapping, Paint Systems, Polygonal Modeling",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-182,
  pages =        "372--379",
  year =         "2002",
  title =        "Progressive Lossless Compression of Arbitrary
                 Simplicial Complexes",
  author =       "Pierre-Marie Gandoin and Olivier Devillers",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-182",
  abstract =     "Efficient algorithms for compressing geometric data
                 have been widely developed in the recent years, but
                 they are mainly designed for closed polyhedral surfaces
                 which are manifold or {"}nearly manifold{"}. We propose
                 here a progressive geometry compression scheme which
                 can handle manifold models as well as {"}triangle
                 soups{"} and 3D tetrahedral meshes. The method is
                 lossless when the decompression is complete which is
                 extremely important in some domains such as medical or
                 finite element. While most existing methods enumerate
                 the vertices of the mesh in an order depending on the
                 connectivity, we use a kd-tree technique [Devillers and
                 Gandoin 2000] which does not depend on the
                 connectivity. Then we compute a compatible sequence of
                 meshes which can be encoded using edge expansion [Hoppe
                 et al. 1993] and vertex split [Popovi'c and Hoppe
                 1997]. The main contributions of this paper are: the
                 idea of using the kd-tree encoding of the geometry to
                 drive the construction of a sequence of meshes, an
                 improved coding of the edge expansion and vertex split
                 since the vertices to split are implicitly defined, a
                 prediction scheme which reduces the code for simplices
                 incident to the split vertex, and a new generalization
                 of the edge expansion operation to tetrahedral
                 meshes.",
  editor =       "John Hughes",
  keywords =     "Mesh Compression, Non manifold Meshes, Coding,
                 Progressivity, Imteractivity",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-183,
  pages =        "380--387",
  year =         "2002",
  title =        "Linear Combination of Transformations",
  author =       "Marc Alexa",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-183",
  abstract =     "Geometric transformations are most commonly
                 represented as square matrices in computer graphics.
                 Following simple geometric arguments we derive a
                 natural and geometrically meaningful definition of
                 scalar multiples and a commutative addition of
                 transformations based on the matrix representation,
                 given that the matrices have no negative real
                 eigenvalues. Together, these operations allow the
                 linear combination of transformations. This provides
                 the ability to create weighted combination of
                 transformations, interpolate between transformations,
                 and to construct or use arbitrary transformations in a
                 structure similar to a basis of a vector space. These
                 basic techniques are useful for synthesis and analysis
                 of motions or animations. Animations through a set of
                 key transformations are generated using standard
                 techniquesisuch as subdivision curves. For analysis and
                 progressive compression a PCA can be applied to
                 sequences of transformations. We describe an
                 implementation of the techniques that enables an
                 easy-to-use and transparent way of dealing with
                 geometric transformations in graphics software. We
                 compare and relate our approach to other techniques
                 such as matrix decomposition and quaternion
                 interpolation.",
  editor =       "John Hughes",
  keywords =     "Transformations, linear space, matrix exponential and
                 logarithm, exponential map",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-184,
  pages =        "388--398",
  year =         "2002",
  title =        "Trainable Videorealistic Facial Animation",
  author =       "Tony Ezzat and Gadi Geiger and Tomaso Poggio",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-184",
  abstract =     "We describe how to create with machine learning
                 techniques a generative, videorealistic, speech
                 animation module. A human subject is first recorded
                 using a videocamera as he/she utters a pre-determined
                 speech corpus. After processing the corpus
                 automatically, a visual speech module is learned from
                 the data that is capable of synthesizing the human
                 subject's mouth uttering entirely novel utterances that
                 were not recorded in the original video. The
                 synthesized utterance is re-composited onto a
                 background sequence which contains natural head and eye
                 movement. The final output is videorealistic in the
                 sense that it looks like a video camera recording of
                 the subject. At run time, the input to the system can
                 be either real audio sequences or synthetic audio
                 produced by a text-to-speech system, as long as they
                 have been phonetically aligned. The two key
                 contributions of this paper are 1) a variant of the
                 multidimensional morphable model (MMM) to synthesize
                 new, previously unseen mouth configurations from a
                 small set of mouth image prototypes; and 2) a
                 trajectory synthesis technique based onregularization,
                 which is automatically trained from the recorded video
                 corpus, and which is capable of synthesizing
                 trajectories in MMM space corresponding to any desired
                 utterance.",
  editor =       "John Hughes",
  keywords =     "Facial modeling, facial animation, morphing, optical
                 flow, speech synthesis, lip synchronization",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-185,
  pages =        "399--407",
  year =         "2002",
  title =        "Turning to the Masters: Motion Capturing Cartoons",
  author =       "Christoph Bregler and Lorie Loeb and Erika Chuang and
                 Hrishi Deshpande",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-185",
  abstract =     "In this paper, we present a technique we call
                 {"}cartoon capture and retargeting{"} which we use to
                 track the motion from traditionally animated cartoons
                 and retarget it onto 3-D models, 2-D drawings, and
                 photographs. By using animation as the source, we can
                 produce new animations that are expressive, exaggerated
                 or non-realistic. Cartoon capture transforms a
                 digitized cartoon into a cartoon motion representation.
                 Using a combination of affine transformation and
                 key-shape interpolation, cartoon capture tracks
                 non-rigid shape changes in cartoon layers. Cartoon
                 retargeting translates this information into different
                 output media. The result is an animation with a new
                 look but with the movement of the original cartoon.",
  editor =       "John Hughes",
  keywords =     "Animation, Computer Vision, Deformations, Morphing,
                 Object Tracking, Shape Blending, Video",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-186,
  pages =        "408--416",
  year =         "2002",
  title =        "Synthesis of Complex Dynamic Character Motion from
                 Simple Animations",
  author =       "C. Karen Liu and Zoran Popovic",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-186",
  abstract =     "In this paper we present a general method for rapid
                 prototyping of realistic character motion. We solve for
                 the natural motion from a simple animation provided by
                 the animator. Our framework can be used to produce
                 relatively complex realistic motion with little user
                 effort. We describe a novel constraint detection method
                 that automatically determines different constraints on
                 the character by analyzing the input motion. We show
                 that realistic motion can be achieved by enforcing a
                 small set of linear and angular momentum constraints.
                 This simplified approach helps us avoid the
                 complexities of computing muscle forces. Simpler
                 dynamic constraints also allow us to generate
                 animations of models with greater complexity,
                 performing more intricate motions. Finally, we show
                 that by learning a small set of key parameters that
                 describe a character pose we can help a non-skilled
                 animator rapidly create realistic character motion.",
  editor =       "John Hughes",
  keywords =     "Animation, Animation w/Constraints, Physically Based
                 Animation, Physically Based Modeling, Motion
                 Transformation, Spacetime Constraints",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-187,
  pages =        "417--426",
  year =         "2002",
  title =        "Integrated Learning for Interactive Synthetic
                 Characters",
  author =       "Bruce Blumberg and Marc Downie and Yuri Ivanov and
                 Matt Berlin and Michael Patrick Johnson and Bill
                 Tomlinson",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-187",
  abstract =     "The ability to learn is a potentially compelling and
                 important quality for interactive synthetic characters.
                 To that end, we describe a practical approach to
                 real-time learning for synthetic characters. Our
                 implementation is grounded in the techniques of
                 reinforcement learning and informed by insights from
                 animal training. It simplifies The the learning task
                 for characters by (a) enabling them to take advantage
                 of predictable regularities in their world, (b)
                 allowing them to make maximal use of any supervisory
                 signals, and (c) making them easy to train by humans.
                 We built an autonomous animated dog that can be trained
                 with a technique used to train real dogs called
                 'clicker training;. Capabilities demonstrated include
                 being trained to recognize and use acoustic patterns as
                 cues for actions, as well as to synthesize new actions
                 from novel paths through its motion space. A key
                 contribution of this paper is to demonstrate that by
                 addressing the three problems of state, action, and
                 state-action space discovery at the same time, the
                 solution for each becomes easier. Finally, we
                 articulate heuristics and design principles that make
                 learning practical for synthetic characters.",
  keywords =     "Behavioral animation, animation, computer games",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
}

@InProceedings{EVL-2002-188,
  pages =        "427--437",
  year =         "2002",
  title =        "Image-Based 3{D} Photography Using Opacity Hulls",
  author =       "Wojciech Matusik and Hanspeter Pfister and Addy Ngan
                 and Paul Beardsley and Remo Ziegler and Leonard
                 McMillan",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-188",
  abstract =     "We have built a system for acquiring and displaying
                 high quality graphical models of objects that are
                 impossible to scan with traditional scanners. Our
                 system can acquire highly specular and fuzzy materials,
                 such as fur and feathers. The hardware set-up consists
                 of a turntable, two plasma displays, an array of
                 cameras, and a rotating array of directional lights. We
                 use multi-background matting techniques to acquire
                 alpha mattes of the object from multiple viewpoints.
                 The alpha mattes are used to construct an opacity hull.
                 The opacity hull is a new shape representation, defined
                 as the visual hull of the object with view-dependent
                 opacity. It enables visualization of complex object
                 silhouettes and seamless blending of objects into new
                 environments. Our system also supports relighting of
                 objects with arbitrary appearance using surface
                 reflectance fields, a purely image-based appearance
                 representation. Our system is the first to acquire and
                 render surface reflectance fields under varying
                 illumination from arbitrary viewpoints. We have built
                 three generations of digitizers with increasing
                 sophistication. In this paper, we present our results
                 from digitizing hundreds of models.",
  keywords =     "Image-based rendering, 3D photography",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
}

@InProceedings{EVL-2002-189,
  pages =        "438--446",
  year =         "2002",
  title =        "Real-Time 3{D} Model Acquisition",
  author =       "Szymon Rusinkiewicz and Olaf Hall-Holt and Marc
                 Levoy",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-189",
  abstract =     "The digitization of the 3D shape of real objects is a
                 rapidly expanding field, with applications in
                 entertainment, design, and archaeology. We propose a
                 new 3D model acquisition system that permits the user
                 to rotate an object by hand and see a
                 continuously-updated model as the object is scanned.
                 This tight feedback loop allows the user to find and
                 fill holes in the model in real time, and determine
                 when the object has been completely covered. Our system
                 is based on a 60 Hz. structured-light rangefinder, a
                 real-time variant of ICP (iterative closest points) for
                 alignment, and point-based merging and rendering
                 algorithms. We demonstrate the ability of our prototype
                 to scan objects faster and with greater ease than
                 conventional model acquisition pipelines.",
  editor =       "John Hughes",
  keywords =     "3D model acquisition, 3D scanning, range scanning,
                 real-time modeling",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-19,
  year =         "2002",
  title =        "Arbitrary Viewpoint Video Synthesis from Uncalibrated
                 Multiple Cameras",
  author =       "S. Yaguchi and H. Saito",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-19",
  abstract =     "In this paper, we propose a method for arbitrary view
                 synthesis from uncalibrated multiple camera system,
                 targeting large space such as soccer stadium. In
                 Projective Grid Space (PGS), that is the
                 three-dimensional space defined by epipolar geometry
                 between the two basis cameras in the camera system, we
                 reconstruct three dimensional shape models from the
                 silhouette images. By using the three dimensional shape
                 model reconstructed in PGS, we can obtain the dense
                 point correspondence map between reference images. The
                 obtained correspondence can synthesize the image of
                 arbitrary view between the reference images. We also
                 propose the method for merging the synthesized images
                 with the virtual background scene in PGS. We apply the
                 proposed method to image sequences taken by the
                 multiple camera system, which is developed in a large
                 space on a concert hall. The synthesized image
                 sequences of virtual camera have enough quality to
                 demonstrate effectiveness of the proposed method.",
  editor =       "V. Skala",
  keywords =     "Virtual view synthesis, Shape from multiple cameras,
                 View interpolation, Projective geometry, Fundamental
                 matrix, Projective grid space",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-190,
  pages =        "447--456",
  year =         "2002",
  title =        "Light Field Mapping: Efficient Representation and
                 Hardware Rendering of Surface Light Fields",
  author =       "Wei-Chao Chen and Jean-Yves Bouguet and Michael H. Chu
                 and Radek Grzeszczuk",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-190",
  abstract =     "A light field parameterized on the surface offers a
                 natural and intuitive description of the view-dependent
                 appearance of scenes with complex reflectance
                 properties. To enable the use of surface light fields
                 in real-time rendering we develop a compact
                 representation suitable for an accelerated graphics
                 pipeline. We propose to approximate the light field
                 data by partitioning it over elementary surface
                 primitives and factorizing each part into a small set
                 of lower-dimensional functions. We show that our
                 representation can be further compressed using standard
                 image compression techniques leading to extremely
                 compact data sets that are up to four orders of
                 magnitude smaller than the input data. Finally, we
                 develop an image-based rendering method, light field
                 mapping, that can visualize surface light fields
                 directly from this compact representation at
                 interactive frame rates on a personal computer. We also
                 implement a new method of approximating the light field
                 data that produces positive only factors allowing for
                 faster rendering using simpler graphics hardware than
                 earlier methods. We demonstrate the results for a
                 variety of non-trivial synthetic scenes and physical
                 objects scanned through 3D photography.",
  editor =       "John Hughes",
  keywords =     "Image-based Rendering, Texture Mapping, Compression
                 Algorithms, Rendering Hardware",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-191,
  pages =        "457--464",
  year =         "2002",
  title =        "Feature-Based Light Field Morphing",
  author =       "Zhunping Zhang and Lifeng Wang and Baining Guo and
                 Heung-Yeung Shum",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-191",
  abstract =     "We present a feature-based technique for morphing 3D
                 objects represented by light fields. Our technique
                 enables morphing of image based objects whose geometry
                 and surface properties are too difficult to model with
                 traditional vision and graphics techniques. Light field
                 morphing is not based on 3D reconstruction; instead it
                 relies on ray correspondence, i.e., the correspondence
                 between rays of the source and target light fields. We
                 address two main issues in light field morphing:
                 feature specification and visibility changes. For
                 feature specification, we develop an intuitive and
                 easy-to-use user interface (UI). The key to this UI is
                 feature polygons, which are intuitively specified as 3D
                 polygons and are used as a control mechanism for ray
                 correspondence in the abstract 4D ray space. For
                 handling visibility changes due to object shape
                 changes, we introduce ray-space warping. Ray-space
                 warping can fill arbitrarily large holes caused by
                 object shape changes; these holes are usually too large
                 to be properly handled by traditional image warping.
                 Our method can deal with non-Lambertian surfaces,
                 including specular surfaces (with dense light fields).
                 We demonstrate that light field morphing is an
                 effective and easy-to-use technqiue that can generate
                 convincing 3D morphing effects.",
  editor =       "John Hughes",
  keywords =     "3D morphing, light field, ray correspondence, feature
                 polygons, global visibility map, ray-space warping",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-192,
  pages =        "465--471",
  year =         "2002",
  title =        "Motion Texture: {A} Two-Level Statistical Model for
                 Character Motion Synthesis",
  author =       "Yan Li and Tianshu Wang and Heung-Yeung Shum",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-192",
  abstract =     "In this paper, we describe a novel technique, called
                 motion texture, for synthesizing complex human-figure
                 motion (e.g., dancing) that is statistically similar to
                 the original motion captured data. We define motion
                 texture as a set of motion textons and their
                 distribution, which characterize the stochastic and
                 dynamic nature of the captured motion. Specifically, a
                 motion texton is modeled by a linear dynamic system
                 (LDS) while the texton distribution is represented by a
                 transition matrix indicating how likely each texton is
                 switched to another. We have designed a maximum
                 likelihood algorithm to learn the motion textons and
                 their relationship from the captured dance motion. The
                 learnt motion texture can then be used to generate new
                 animations automatically and/or edit animation
                 sequences interactively. Most interestingly, motion
                 texture can be manipulated at different levels, either
                 by changing the fine details of a specific motion at
                 the texton level or by designing a new choreography at
                 the distribution level. Our approach is demonstrated by
                 many synthesized sequences of visually compelling dance
                 motion.",
  editor =       "John Hughes",
  keywords =     "Motion Texture, Motion Synthesis, Texture Synthesis,
                 Motion Editing, Linear Dynamic Systems",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-193,
  pages =        "473--482",
  year =         "2002",
  title =        "Motion Graphs",
  author =       "Lucas Kovar and Michael Gleicher and
                 Fr{\'{e}}d{\'{e}}ric Pighin",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-193",
  abstract =     "In this paper we present a novel method for creating
                 realistic, controllable motion. Given a corpus of
                 motion capture data, we automatically construct a
                 directed graph called a motion graph that encapsulates
                 connections among the database. The motion graph
                 consists both of pieces of original motion and
                 automatically generated transitions. Motion can be
                 generated simply by building walks on the graph. We
                 present a general framework for extracting particular
                 graph walks that meet a user's specifications. We then
                 show how this framework can be applied to the specific
                 problem of generating different styles of locomotion
                 along arbitrary paths.",
  editor =       "John Hughes",
  keywords =     "Motion synthesis, motion capture, animation with
                 constraints",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-194,
  pages =        "483--490",
  year =         "2002",
  title =        "Interactive Motion Generation From Examples",
  author =       "Okan Arikan and D. A. Forsyth",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-194",
  abstract =     "There are many applications that demand large
                 quantities of natural looking motion. It is difficult
                 to synthesize motion that looks natural, particularly
                 when it is people who must move. In this paper, we
                 present a framework that generates human motions by
                 cutting and pasting motion capture data. Selecting a
                 collection of clips that yields an acceptable motion is
                 a combinatorial problem that we manage as a randomized
                 search of a hierarchy of graphs. This approach can
                 generate motion sequences that satisfy a variety of
                 constraints automatically. The motions are smooth and
                 human-looking. They are generated in real time so that
                 we can author complex motions interactively. The
                 algorithm generates multiple motions that satisfy a
                 given set of constraints, allowing a variety of choices
                 for the animator. It can easily synthesize multiple
                 motions that interact with each other using
                 constraints. This framework allows the extensive re-use
                 of motion capture data for new purposes.",
  editor =       "John Hughes",
  keywords =     "Motion Capture, Motion Synthesis, Human motion, Graph
                 Search, Clustering, Animation with Constraints",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-195,
  pages =        "491--500",
  year =         "2002",
  title =        "Interactive Control of Avatars Animated With Human
                 Motion Data",
  author =       "Jehee Lee and Jinxiang Cha and Paul S. A. Reitsma and
                 Jessica K. Hodgins and Nancy S. Pollard",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-195",
  abstract =     "Real-time control of three-dimensional avatars is an
                 important problem in the context of computer games and
                 virtual environments. Avatar animation and control is
                 difficult, however, because a large repertoire of
                 avatar behaviors must be made available, and the user
                 must be able to select from this set of behaviors,
                 possibly with a low-dimensional input device. One
                 appealing approach to obtaining a rich set of avatar
                 behaviors is to collect an extended, unlabeled sequence
                 of motion data appropriate to the application. In this
                 paper, we show that such a motion database can be
                 preprocessed for flexibility in behavior and efficient
                 search and exploited for real-time avatar control.
                 Flexibility is created by identifying plausible
                 transitions between motion segments, and efficient
                 search through the resulting graph structure is
                 obtained through clustering. Three interface techniques
                 are demonstrated for controlling avatar motion using
                 this data structure: the user selects from a set of
                 available choices, sketches a path through an
                 environment, or acts out a desired motion in front of a
                 video camera. We demonstrate the flexibility of the
                 approach through four different applications and
                 compare the avatar motion to directly recorded human
                 motion.",
  editor =       "John Hughes",
  keywords =     "Human motion, motion capture, avatars, virtual
                 environments, interactive control",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-196,
  pages =        "501--508",
  year =         "2002",
  title =        "Motion Capture Assisted Animation: Texturing and
                 Synthesis",
  author =       "Katherine Pullen and Christoph Bregler",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-196",
  abstract =     "We discuss a method for creating animations that
                 allows the animator to sketch an animation by setting a
                 small number of keyframes on a fraction of the possible
                 degrees of freedom. Motion capture data is then used to
                 enhance the animation. Detail is added to degrees of
                 freedom that were keyframed, a process we call
                 texturing. Degrees of freedom that were not keyframed
                 are synthesized. The method takes advantage of the fact
                 that joint motions of an articulated figure are often
                 correlated, so that given an incomplete data set, the
                 missing degrees of freedom can be predicted from those
                 that are present.",
  editor =       "John Hughes",
  keywords =     "Animation, motion capture, motion texture, motion
                 synthesis",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-197,
  pages =        "509--516",
  year =         "2002",
  title =        "Homomorphic Factorization of {BRDF}-Based Lighting
                 Computation",
  author =       "Lutz Latta and Andreas Kolb",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-197",
  abstract =     "Several techniques have been developed to approximate
                 Bidirectional Reflectance Distribution Functions (BRDF)
                 with acceptable quality and performance for realtime
                 applications. The recently published Homomorphic
                 Factorization by McCool et al. is a general
                 approximation approach that can be used with various
                 setups and for different quality requirements. In this
                 paper we propose a new technique based on the
                 Homomorphic Factorization. Instead of approximating the
                 BRDF, our technique factorizes the full lighting
                 computation of an isotropic BRDF in a global
                 illumination scenario. With this method materials in
                 complex lighting situations can be simulated with only
                 two textures by using commonly available computation
                 capabilities of current graphics hardware. The new
                 technique can also be considered as a generalized
                 approach to several environment map prefiltering
                 techniques. Existing prefiltering techniques are
                 usually limited to specific BRDFs or require advanced
                 hardware capabilities like 3D texturing. With the
                 factorization only common 2D textures are required.",
  editor =       "John Hughes",
  keywords =     "Illumination, Reflectance & Shading Model, Rendering,
                 Rendering Hardware, Texture Mapping",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-198,
  pages =        "517--526",
  year =         "2002",
  title =        "Frequency Space Environment Map Rendering",
  author =       "Ravi Ramamoorthi and Pat Hanrahan",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-198",
  abstract =     "We present a new method for real-time rendering of
                 objects with complex isotropic BRDFs under distant
                 natural illumination, as specified by an environment
                 map. Our approach is based on spherical frequency space
                 analysis and includes three main contributions.
                 Firstly, we are able to theoretically analyze required
                 sampling rates and resolutions, which have
                 traditionally been determined in an ad-hoc manner. We
                 also introduce a new compact representation, which we
                 call a spherical harmonic reflection map (SHRM) , for
                 efficient representation and rendering. Finally, we
                 show how to rapidly prefilter the environment map to
                 compute the SHRM ---our frequency domain prefiltering
                 algorithm is generally orders of magnitude faster than
                 previous angular (spatial) domain approaches.",
  editor =       "John Hughes",
  keywords =     "Environment Maps, Image-Based Rendering,
                 Signal-Processing, Complexity Analysis, Spherical
                 Harmonics",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-199,
  pages =        "527--536",
  year =         "2002",
  title =        "Precomputed Radiance Transfer for Real-Time Rendering
                 in Dynamic, Low-Frequency Lighting Environments",
  author =       "Peter-Pike Sloa and Jan Kautz and John Snyde",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-199",
  abstract =     "We present a new, real-time method for rendering
                 diffuse and glossy objects in low-frequency lighting
                 environments that captures soft shadows,
                 interreflections, and caustics. As a preprocess, a
                 novel global transport simulator creates functions over
                 the object's surface representing transfer of
                 arbitrary, low-frequency incident lighting into
                 transferred radiance which includes global effects like
                 shadows and interreflections from the object onto
                 itself. At run-time, these transfer functions are
                 applied to actual incident lighting. Dynamic, local
                 lighting is handled by sampling it close to the object
                 every frame; the object can also be rigidly rotated
                 with respect to the lighting and vice versa. Lighting
                 and transfer functions are represented using low-order
                 spherical harmonics. This avoids aliasing and evaluates
                 efficiently on graphics hardware by reducing the
                 shading integral to a dot product of 9 to 25 element
                 vectors for diffuse receivers. Glossy objects are
                 handled using matrices rather than vectors. We further
                 introduce functions for radiance transfer from a
                 dynamic lighting environment through a preprocessed
                 object to neighboring points in space. These allow soft
                 shadows and caustics from rigidly moving objects to be
                 cast onto arbitrary, dynamic receivers. We demonstrate
                 real-time global lighting effects with this approach.",
  editor =       "John Hughes",
  keywords =     "Graphics Hardware, Illumination, Monte Carlo
                 Techniques, Rendering, Shadow Algorithms",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-2,
  year =         "2002",
  title =        "Model Centred Approach to Scientific Visualization",
  author =       "B. Belaton and K. W. Brodlie",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-2",
  abstract =     "One of the crucial requirements for a Scientific
                 Visualization system is to produce reliable and
                 accurate results. There are many possible sources of
                 errors that could jeopardise these efforts, such as
                 measurement or simulation errors in the pre-analysis
                 stage, or errors generated in the visualization process
                 itself. Our focus here is to control errors introduced
                 during the visualization processes. To this end we
                 propose a conceptual model for visualization known as
                 the Model Centred Approach (MCA). This new paradigm
                 separates the modelling and viewing processes in
                 visualization, and this provides the opportunity to
                 consistently utilise a single modelling function
                 throughout the visualization process. Results show that
                 consistent visualizations are produced by our approach
                 when compared to conventional methods.",
  editor =       "V. Skala",
  keywords =     "Scientific visualization, conceptual model",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-20,
  year =         "2002",
  title =        "A Method for Obtaining the Tesseract by Unraveling the
                 4{D} Hypercube",
  author =       "A. Aguilera and R. Perez",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-20",
  abstract =     "This article presents a method for unraveling the
                 hypercube and obtaining the 3D-cross (tesseract) that
                 corresponds to the hyper-flattening of its boundary.
                 The hypercube can be raveled back using the method in
                 an inverse way. Also a method for visualizing the
                 processes is presented. The transformations to apply
                 include rotations around a plane (characteristic of the
                 4D space). All these processes can be viewed using a
                 computer animation system.",
  editor =       "V. Skala",
  keywords =     "4D-Modeling, 4D-Animation, Computational Geometry",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-200,
  pages =        "537--546",
  year =         "2002",
  title =        "Interactive Global Illumination in Dynamic Scenes",
  author =       "Parag Tole and Fabio Pellacini and Bruce Walter and
                 Donald P. Greenberg",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-200",
  abstract =     "In this paper, we present a system for interactive
                 computation of global illumination in dynamic scenes.
                 Our system uses a novel scheme for caching the results
                 of a high quality pixel-based renderer such as a
                 bidirectional path tracer. The Shading Cache is an
                 object space hierarchical subdivision mesh with lazily
                 computed shading values at its vertices. A high frame
                 rate display is generated from the Shading Cache using
                 hardware-based interpolation and texture mapping. An
                 image space sampling scheme refines the Shading Cache
                 in regions that have the most interpolation error or
                 those that are most likely to be affected by object or
                 camera motion. Our system handles dynamic scenes and
                 moving light sources efficiently, providing useful
                 feedback within a few seconds and high quality images
                 within a few tens of seconds, without the need for any
                 pre-computation. Our approach allows us to
                 significantly outperform other interactive systems
                 based on caching ray-tracing samples, especially in
                 dynamic scenes. Based on our results, we believe that
                 the Shading Cache will be an invaluable tool in
                 lighting design and modelling while rendering.",
  editor =       "John Hughes",
  keywords =     "Rendering, Ray Tracing, Parallel Computing, Rendering
                 Systems, Illumination, Monte Carlo Techniques",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-201,
  pages =        "547--556",
  year =         "2002",
  title =        "A Lighting Reproduction Approach to Live-Action
                 Compositing",
  author =       "Paul Debevec and Andreas Wenger and Chris Tchou and
                 Andrew Gardner and Jamie Waese and Tim Hawkins",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-201",
  abstract =     "We describe a process for compositing a live
                 performance of an actor into a virtual set wherein the
                 actor is consistently illuminated by the virtual
                 environment. The Light Stage used in this work is a
                 two-meter sphere of inward-pointing RGB light emitting
                 diodes focused on the actor, where each light can be
                 set to an arbitrary color and intensity to replicate a
                 real-world or virtual lighting environment. We
                 implement a digital two-camera infrared matting system
                 to composite the actor into the background plate of the
                 environment without affecting the visible-spectrum
                 illumination on the actor. The color reponse of the
                 system is calibrated to produce correct color
                 renditions of the actor as illuminated by the
                 environment. We demonstrate moving-camera composites of
                 actors into real-world environments and virtual sets
                 such that the actor is properly illuminated by the
                 environment into which they are composited.",
  editor =       "John Hughes",
  keywords =     "Matting and Compositing, Image-Based Lighting,
                 Radiosity, Global Illumination, Reflectance and
                 Shading",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-202,
  pages =        "557--562",
  year =         "2002",
  title =        "Perspective Shadow Maps",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-202",
  author =       "Marc Stamminger and George Drettakis",
  abstract =     "Shadow maps are probably the most widely used means
                 for the generation of shadows, despite their well known
                 aliasing problems. In this paper we introduce
                 perspective shadow maps, which are generated in
                 normalized device coordinate space, i.e., after
                 perspective transformation. This results in important
                 reduction of shadow map aliasing with almost no
                 overhead. We correctly treat light source
                 transformations and show how to include all objects
                 which cast shadows in the transformed space.
                 Perspective shadow maps can directly replace standard
                 shadow maps for interactive hardware accelerated
                 rendering as well as in high-quality, offline
                 renderers.",
  editor =       "John Hughes",
  keywords =     "Frame Buffer Algorithms, Graphics Hardware,
                 Illumination, Level of Detail Algorithms, Rendering,
                 Shadow Algorithms",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ ACM SIGGRAPH",
}

@InProceedings{EVL-2002-203,
  pages =        "563--566",
  year =         "2002",
  title =        "A User Interface for Interactive Cinematic Shadow
                 Design",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-203",
  author =       "Fabio Pellacini and Parag Tole and Donald P.
                 Greenberg",
  abstract =     "Placing shadows is difficult task since shadows depend
                 on the relative positions of lights and objects in an
                 unintuitive manner. To simplify the task of the
                 modeler, we present a user interface for designing
                 shadows in 3d environments. In our interface, shadows
                 are treated as first-class modeling primitives just
                 like objects and lights. To transform a shadow, the
                 user can simply move, rescale or rotate the shadow as
                 if it was a 2d object on the scene's surfaces. When the
                 user transforms a shadow, the system moves lights or
                 objects in the scene as required and updates the
                 shadows in realtime during mouse movement. To
                 facilitate interaction, the user can also specify
                 constraints that the shadows must obey, such as never
                 casting a shadow on the face of a character. These
                 constraints are then verified in real-time, limiting
                 mouse movement when necessary. We also integrate in our
                 interface fake shadows typically used in computer
                 animation. This allows the user to draw shadowed and
                 non-shadowed regions directly on surfaces in the
                 scene.",
  editor =       "John Hughes",
  keywords =     "Human Computer Interaction, Illumination, User
                 Interface Design, Lighting Design",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ ACM SIGGRAPH",
}

@InProceedings{EVL-2002-204,
  pages =        "567--575",
  year =         "2002",
  title =        "Robust Epsilon Visibility",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-204",
  author =       "Florent Duguet and George Drettakis",
  abstract =     "Analytic visibility algorithms, for example methods
                 which compute a subdivided mesh to represent shadows,
                 are notoriously unrobust and hard to use in practice.
                 We present a new method based on a generalized
                 definition of extremal stabbing lines, which are the
                 extremities of shadow boundaries. We treat scenes
                 containing multiple edges or vertices in degenerate
                 configurations, (e.g., collinear or coplanar). We
                 introduce a robust Epsilon method to determine whether
                 each generalized extremal stabbing line is blocked, or
                 is touched by these scene elements, and thus added to
                 the line's generators. We develop robust blocker
                 predicates for polygons which are smaller than Epsilon
                 . For larger Epsilon values, small shadow features
                 merge and eventually disappear. We can thus robustly
                 connect generalized extremal stabbing lines in
                 degenerate scenes to form shadow boundaries. We show
                 that our approach is consistent, and that shadow
                 boundary connectivity is preserved when features merge.
                 We have implemented our algorithm, and show that we can
                 robustly compute analytic shadow boundaries to the
                 precision of our chosen Epsilon threshold for
                 non-trivial models, containing numerous degeneracies.",
  editor =       "John Hughes",
  keywords =     "Illumination, Shadow Algorithms, 3D Visibility, Robust
                 Visibility Predicates, Epsilon Visibility",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-205,
  pages =        "576--581",
  year =         "2002",
  title =        "A Rapid Hierarchical Rendering Technique for
                 Translucent Materials",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-205",
  author =       "Henrik Wann Jensen and Juan Buhler",
  abstract =     "This paper introduces an efficient two-pass rendering
                 technique for translucent materials. We decouple the
                 computation of irradiance at the surface from the
                 evaluation of scattering inside the material. This is
                 done by splitting the evaluation into two passes, where
                 the first pass consists of computing the irradiance at
                 selected points on the surface. The second pass uses a
                 rapid hierarchical integration technique to evaluate a
                 diffusion approximation based on the irradiance
                 samples. This approach is substantially faster than
                 previous methods for rendering translucent materials,
                 and it has the advantage that it integrates seamlessly
                 with both scanline rendering and global illumination
                 methods. We show several images and animations from our
                 implementation that demonstrate that the approach is
                 both fast and robust, making it suitable for rendering
                 translucent materials in production.",
  editor =       "John Hughes",
  keywords =     "Subsurface scattering, BSSRDF, reflection models,
                 light transport, diffusion theory, global illumination,
                 realistic image synthesis",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-206,
  pages =        "582--585",
  year =         "2002",
  title =        "Dy{RT}: Dynamic Response Textures for Real Time
                 Deformation Simulation With Graphics Hardware",
  author =       "Doug L. James and Dinesh K. Pai",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-206",
  abstract =     "In this paper we describe how to simulate
                 geometrically complex, interactive, physically-based,
                 volumetric, dynamic deformation models with negligible
                 main CPU costs. This is achieved using a Dynamic
                 Response Texture, or DyRT, that can be mapped onto any
                 conventional animation as an optional rendering stage
                 using commodity graphics hardware. The DyRT simulation
                 process employs precomputed modal vibration models
                 excited by rigid body motions. We present several
                 examples, with an emphasis on bone-based character
                 animation for interactive applications.",
  editor =       "John Hughes",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-207,
  pages =        "586--593",
  year =         "2002",
  title =        "Interactive Skeleton-Driven Dynamic Deformations",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-207",
  author =       "Steve Capell and Seth Green and Brian Curless and Tom
                 Duchamp and Zoran Popovic",
  abstract =     "This paper presents a framework for the
                 skeleton-driven animation of elastically deformable
                 characters. A character is embedded in a coarse
                 volumetric control lattice, which provides the
                 structure needed to apply the finite element method. To
                 incorporate skeletal controls, we introduce line
                 constraints along the bones of simple skeletons. The
                 bones are made to coincide with edges of the control
                 lattice, which enables us to apply the constraints
                 efficiently using algebraic methods. To accelerate
                 computation, we associate regions of the volumetric
                 mesh with particular bones and perform locally
                 linearized simulations, which are blended at each time
                 step. We define a hierarchical basis on the control
                 lattice, so for detailed interactions the simulation
                 can adapt the level of detail. We demonstrate the
                 ability to animate complex models using simple
                 skeletons and coarse volumetric meshes in a manner that
                 simulates secondary motions at interactive rates.",
  editor =       "John Hughes",
  keywords =     "Animation, deformation, physically-based animation,
                 physically-based modeling",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-208,
  pages =        "594--603",
  year =         "2002",
  title =        "Robust Treatment of Collisions, Contact, and Friction
                 for Cloth Animation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-208",
  author =       "Robert Bridson and Ronald P. Fedkiw and John
                 Anderson",
  abstract =     "We present an algorithm to efficiently and robustly
                 process collisions, contact and friction in cloth
                 simulation. It works with any technique for simulating
                 the internal dynamics of the cloth, and allows true
                 modeling of cloth thickness. We also show how our
                 simulation data can be post-processed with a
                 collision-aware subdivision scheme to produce smooth
                 and interference-free data for rendering.",
  editor =       "John Hughes",
  keywords =     "Cloth, collision detection, collision response,
                 contacts, kinetic friction, static friction, physically
                 based animation",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-209,
  pages =        "604--611",
  year =         "2002",
  title =        "Stable but Responsive Cloth",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-209",
  author =       "Kwang-Jin Choi and Hyeong-Seok Ko",
  abstract =     "We present a semi-implicit cloth simulation technique
                 that is very stable yet also responsive. The stability
                 of the technique allows the use of a large fixed time
                 step when simulating all types of fabrics and character
                 motions. The animations generated using this technique
                 are strikingly realistic. Wrinkles form and disappear
                 in a quite natural way, which is the feature that most
                 distinguishes textile fabrics from other sheet
                 materials. Significant improvements in both the
                 stability and realism were made possible by overcoming
                 the post-buckling instability as well as the numerical
                 instability. The instability caused by buckling arises
                 from a structural instability and therefore cannot be
                 avoided by simply employing a semi-implicit method.
                 Addition of a damping force may help to avoid
                 instabilities; however, it can significantly degrade
                 the realism of the cloth motion. The method presented
                 here uses a particle based physical model to handle the
                 instability in the post-buckling response without
                 introducing any fictitious damping.",
  editor =       "John Hughes",
  keywords =     "Deformations, Numerical Analysis, Physically Based
                 Animation, Physically Based Modeling",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-21,
  year =         "2002",
  title =        "Exploiting Advanced Collision Detection Libraries in a
                 Probabilistic Motion Planner",
  author =       "S. Caselli and M. Reggiani and M. Mazzoli",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-21",
  abstract =     "Motion planning is a fundamental problem in a number
                 of application areas, including robotics, automation,
                 and virtual reality. The performance of motion planning
                 is largely affected by the underlying collision
                 detection technique. In this paper we report the
                 results of an experimental evaluation of several recent
                 collision detection libraries within the context of
                 motion planning for rigid and articulated robots in 3D
                 workspaces. The libraries investigated have been chosen
                 based also on their free availability to the research
                 community. Results reported in this paper show that
                 some of the collision detection packages investigated
                 are very sensitive to the type of problem to be solved,
                 possibly determining the best performance on certain
                 problems and proving very inefficient or even not
                 applicable on different problems. Other collision
                 detection libraries are much less sensitive to the type
                 of problem, although they do not necessarily exhibit
                 the best performance on any given problem. These
                 considerations suggest that a motion planner could take
                 advantage from the ability to select one among a range
                 of collision detection libraries based on
                 characteristics of the problem to be solved which could
                 be known a priori.",
  editor =       "V. Skala",
  keywords =     "Motion planning, collision detection",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-210,
  pages =        "612--619",
  year =         "2002",
  title =        "Articulated Body Deformation From Range Scan Data",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-210",
  author =       "Brett Allen and Brian Curless and Zoran Popovic",
  abstract =     "This paper presents an example-based method for
                 calculating skeleton-driven body deformations. Our
                 example data consists of range scans of a human body in
                 a variety of poses. Using markers captured during range
                 scanning, we construct a kinematic skeleton and
                 identify the pose of each scan. We then construct a
                 mutually consistent parameterization of all the scans
                 using a posable subdivision surface template. The
                 detail deformations are represented as displacements
                 from this surface, and holes are filled smoothly within
                 the displacement maps. Finally, we combine the range
                 scans using k-nearest neighbor interpolation in pose
                 space. We demonstrate results for a human upper body
                 with controllable pose, kinematics, and underlying
                 surface shape.",
  editor =       "John Hughes",
  keywords =     "Animation, character animation, deformation, human
                 body simulation, synthetic actor",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-211,
  pages =        "620--629",
  year =         "2002",
  title =        "Interactive Multiresolution Hair Modeling and
                 Editing",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-211",
  author =       "Tae-Yong Kim and Ulrich Neumann",
  abstract =     "Human hair modeling is a difficult task. This paper
                 presents a constructive hair modeling system with which
                 users can sculpt a wide variety of hairstyles. Our
                 Multiresolution Hair Modeling (MHM) system is based on
                 the observed tendency of adjacent hair strands to form
                 clusters at multiple scales due to static attraction.
                 In our system, initial hair designs are quickly created
                 with a small set of hair clusters. Refinements at finer
                 levels are achieved by subdividing these initial hair
                 clusters. Users can edit an evolving model at any level
                 of detail, down to a single hair strand. High level
                 editing tools support curling, scaling, and copy/paste,
                 enabling users to rapidly create widely varying
                 hairstyles. Editing ease and model realism are enhanced
                 by efficient hair rendering, shading, antialiasing, and
                 shadowing algorithms",
  editor =       "John Hughes",
  keywords =     "Hair modeling, multiresolution modeling, level of
                 detail, hair rendering, generalized cylinders",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-212,
  pages =        "630--636",
  year =         "2002",
  title =        "Modeling and Rendering of Realistic Feathers",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-212",
  author =       "Yanyun Chen and Yingqing Xu and Baining Guo and
                 Heung-Yeung Shum",
  abstract =     "We present techniques for realistic modeling and
                 rendering of feathers and birds. Our approach is
                 motivated by the observation that a feather is a
                 branching structure that can be described by an
                 L-system. The parametric L-system we derived allows the
                 user to easily create feathers of different types and
                 shapes by changing afew parameters. The randomness in
                 feather geometry is also incorporated into this
                 L-system. To render a feather realistically, we have
                 derived an efficient form of the bidirectional texture
                 function (BTF), which describes the small but visible
                 geometry details on the feather blade. A rendering
                 algorithm combining the L-system and the BTF displays
                 feathers photorealistically while capitalizing on
                 graphics hardware for efficiency. Based on this
                 framework of feather modeling and rendering, we
                 developed a system that can automatically generate
                 appropriate feathers to cover different parts of a
                 bird's body from a few 'key feathers' supplied by the
                 user, and produce realistic renderings of the bird.",
  editor =       "John Hughes",
  keywords =     "L-system, bidirectional texture function, natural
                 phenomena, rendering, feather, bird",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-213,
  pages =        "637--644",
  year =         "2002",
  title =        "Eyes Alive",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-213",
  author =       "Sooha Park Lee and Jeremy B. Badler and Norman I.
                 Badler",
  abstract =     "For an animated human face model to appear natural it
                 should produce eye movements consistent with human
                 ocular behavior. During face-to-face conversational
                 interactions, eyes exhibit conversational turn-taking
                 and agent thought processes through gaze direction,
                 saccades, and scan patterns. We have implemented an eye
                 movement model based on empirical models of saccades
                 and statistical models of eye-tracking data. Face
                 animations using stationary eyes, eyes with random
                 saccades only, and eyes with statistically derived
                 saccades are compared, to evaluate whether they appear
                 natural and effective while communicating.",
  editor =       "John Hughes",
  keywords =     "Eye movement synthesis, facial animation, statistical
                 modeling, saccades, HCI (Human-Computer Interface)",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-214,
  pages =        "645--652",
  year =         "2002",
  title =        "Physiological Measures of Presence in Stressful
                 Virtual Environments",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-214",
  author =       "Michael Meehan and Brent Insko and Mary Whitton and
                 Jr. Frederick P. Brooks",
  abstract =     "A common measure of the quality or effectiveness of a
                 virtual environment (VE) is the amount of presence it
                 evokes in users. Presence is often defined as the sense
                 of being there in a VE. There has been much debate
                 about the best way to measure presence, and presence
                 researchers need, and have sought, a measure that is
                 reliable, valid, sensitive, and objective. We
                 hypothesized that to the degree that a VE seems real,
                 it would evoke physiological responses similar to those
                 evoked by the corresponding real environment, and that
                 greater presence would evoke a greater response. To
                 examine this, we conducted three experiments, the
                 results of which support the use of physiological
                 reaction as a reliable, valid, sensitive, and objective
                 presence measure. The experiments compared
                 participants' physiological reactions to a
                 non-threatening virtual room and their reactions to a
                 stressful virtual height situation. We found that
                 change in heart rate satisfied our requirements for a
                 measure of presence, change in skin conductance did to
                 a lesser extent, and that change in skin temperature
                 did not. Moreover, the results showed that inclusion of
                 a passive haptic element in the VE significantly
                 increased presence and that for presence evoked: 30FPS
                 > 20FPS > 15FPS.",
  editor =       "John Hughes",
  keywords =     "Presence, Physiology, Haptics, Frame Rate",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-215,
  pages =        "653--656",
  year =         "2002",
  title =        "Self-Similarity Based Texture Editing",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-215",
  author =       "Stephen Brooks and Neil Dodgson",
  abstract =     "We present a simple method of interactive texture
                 editing that utilizes self-similarity to replicate
                 intended operations globally over an image. In spired
                 by the recent successes of hierarchical approaches to
                 texture synthesis, this method also uses multi-scale
                 neighborhoods to assess the similarity of pixels within
                 a texture. However,neighborhood matching is not
                 employed to generate new instances of a texture. We
                 instead locate similar neighborhoods for the purpose of
                 replicating editing operations on the original texture
                 itself, thereby creating a fundamentally new texture.
                 This general approach is applied to texture painting,
                 cloning and warping. These global operations are
                 performed interactively, most often directed with just
                 a single mouse movement.",
  editor =       "John Hughes",
  keywords =     "Texture editing, interactive, image cloning, texture
                 warping",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-216,
  pages =        "657--664",
  year =         "2002",
  title =        "Jigsaw Image Mosaics",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-216",
  author =       "Junhwan Kim and Fabio Pellacini",
  abstract =     "This paper introduces a new kind of mosaic, called
                 Jigsaw Image Mosaic (JIM), where image tiles of
                 arbitrary shape are used to compose the final picture.
                 The generation of a Jigsaw Image Mosaic is a solution
                 to the following problem: given an arbitrarily-shaped
                 container image and a set of arbitrarily-shaped image
                 tiles, fill the container as compactly as possible with
                 tiles of similar color to the container taken from the
                 input set while optionally deforming them slightly to
                 achieve a more visually-pleasing effect. We approach
                 the problem by defining a mosaic as the tile
                 configuration that minimizes a mosaicing energy
                 function. We introduce a general energy-based framework
                 for mosaicing problems that extends some of the
                 existing algorithms such as Photomosaics and Simulated
                 Decorative Mosaics. We also present a fast algorithm to
                 solve the mosaicing problem at an acceptable
                 computational cost. We demonstrate the use of our
                 method by applying it to a wide range of container
                 images and tiles.",
  editor =       "John Hughes",
  keywords =     "Mosaics, Morphing, Optimization",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-217,
  pages =        "665--672",
  year =         "2002",
  title =        "Synthesis of Bidirectional Texture Functions on
                 Arbitrary Surfaces",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-217",
  author =       "Xin Tong and Jingdan Zhang and Ligang Liu and Xi Wang
                 and Baining Guo and Heung-Yeung Shum",
  abstract =     "The bidirectional texture function (BTF) is a 6D
                 function that can describe textures arising from both
                 spatially-variant surface reflectance and surface
                 mesostructures. In this paper, we present an algorithm
                 for synthesizing the BTF on an arbitrary surface from a
                 sample BTF. A main challenge in surface BTF synthesis
                 is the requirement of a consistent mesostructure on the
                 surface, and to achieve that we must handle the large
                 amount of data in a BTF sample. Our algorithm performs
                 BTF synthesis based on surface textons, which extract
                 essential information from the sample BTF to facilitate
                 the synthesis. We also describe a general search
                 strategy, called the k-coherent search, for fast BTF
                 synthesis using surface textons. A BTF synthesized
                 using our algorithm not only looks similar to the BTF
                 sample in all viewing/lighthing conditions but also
                 exhibits a consistent mesostructure when viewing and
                 lighting directions change. Moreover, the synthesized
                 BTF fits the target surface naturally and seamlessly.
                 We demonstrate the effectiveness of our algorithm with
                 sample BTFs from various sources, including those
                 measured from real-world textures.",
  editor =       "John Hughes",
  keywords =     "Bidirectional texture function, 3D textons,
                 reflectance and shading models, texture synthesis,
                 texture mapping, surfaces",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-218,
  pages =        "673--680",
  year =         "2002",
  title =        "Hierarchical Pattern Mapping",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-218",
  author =       "Cyril Soler and Marie-Paule Cani and Alexis
                 Angelidis",
  abstract =     "We present a multi-scale algorithm for mapping a
                 texture defined by an input image onto an arbitrary
                 surface. It avoids the generation and storage of a new,
                 specific texture. The idea is to progressively cover
                 the surface by texture patches of various sizes and
                 shapes, selected from a single input image. The process
                 starts with large patches. A mapping that minimizes the
                 texture fitting error with already textured
                 neighbouring patches is selected. When this error is
                 above a threshold, the patch is split into smaller
                 ones, and the algorithm recursively looks for good fits
                 at a smaller scale. The process ends when the surface
                 is entirely covered. Our results show that the method
                 correctly handles a wide set of texture patterns, which
                 can be used at different mapping scales. Hierarchical
                 texture mapping only outputs texture coordinates in the
                 original texture for each triangle of the initial mesh.
                 Rendering is therefore easy and memory cost minimal.
                 Moreover the initial geometry is preserved.",
  editor =       "John Hughes",
  keywords =     "Level of Detail Algorithms, Texture Mapping, Texture
                 Synthesis",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-219,
  pages =        "681--682",
  year =         "2002",
  title =        "Improving Noise",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-219",
  author =       "Ken Perlin",
  abstract =     "Two deficiencies in the original Noise algorithm are
                 corrected: second order interpolation discontinuity and
                 unoptimal gradient computation. With these defects
                 corrected, Noise both looks better and runs faster. The
                 latter change also makes it easier to define a uniform
                 mathematical reference standard.",
  editor =       "John Hughes",
  keywords =     "Procedural Texture",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-22,
  year =         "2002",
  title =        "Comparing Rendering Methods for Julia Sets",
  author =       "V. Drakopoulos",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-22",
  abstract =     "Sequential rendering methods for the graphical
                 representation of Julia sets are compared. Two groups
                 of methods are presented. In the first, the attractor
                 of the Julia set is rendered and, in the second, the
                 complement of the attractor is rendered. Examples of
                 images obtained using these methods are also given.",
  editor =       "V. Skala",
  keywords =     "Attractor, Julia set, rendering methods",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-220,
  pages =        "683--692",
  year =         "2002",
  title =        "The {SAGE} Graphics Architecture",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-220",
  author =       "Michael F. Deering and David Naegle",
  abstract =     "The Scalable, Advanced Graphics Environment (SAGE) is
                 a new high-end, multi-chip rendering architecture. Each
                 single SAGE board can render in excess of 80 million
                 fully lit, textured, anti-aliased triangles per second.
                 SAGE brings high quality antialiasing filters to video
                 rate hardware for the first time. To achieve this, the
                 concept of a frame buffer is replaced by a fully
                 double-buffered sample buffer of between 1 and 16
                 non-uniformly placed samples per final output pixel.
                 The video output raster of samples is subject to
                 convolution by a 5*5 programmable reconstruction and
                 bandpass filter that replaces the traditional RAMDAC.
                 The reconstruction filter processes up to 400 samples
                 per output pixel, and supports any radially symmetric
                 filter, including those with negative lobes (full
                 Mitchell-Netravali filter). Each SAGE board comprises
                 four parallel rendering sub-units, and supports up to
                 two video output channels. Multiple SAGE systems can be
                 tiled together to support even higher fill rates,
                 resolutions, and performance.",
  editor =       "John Hughes",
  keywords =     "Rendering hardware, anti-aliasing, graphics hardware,
                 frame buffer algorithms, graphics systems, hardware
                 systems, video",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-221,
  pages =        "693--702",
  year =         "2002",
  title =        "Chromium: {A} Stream-Processing Framework for
                 Interactive Rendering on Clusters",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-221",
  author =       "Greg Humphreys and Mike Houston and Ren Ng and Randall
                 Frank and Sean Ahern and Peter Kirchner and Jim
                 Klosowski",
  abstract =     "We describe Chromium, a system for manipulating
                 streams of graphics API commands on clusters of
                 workstations. Chromium's stream filters can be arranged
                 to create sort-first and sort-last parallel graphics
                 architectures that, in many cases, support the same
                 applications while using only commodity graphics
                 accelerators. In addition, these stream filters can be
                 extended programmatically, allowing the user to
                 customize the stream transformations performed by nodes
                 in a cluster. Because our stream processing mechanism
                 is completely general, any cluster-parallel rendering
                 algorithm can be either implemented on top of or
                 embedded in Chromium. In this paper, we give examples
                 of real-world applications that use Chromium to achieve
                 good scalability on clusters of workstations, and
                 describe other potential uses of this stream processing
                 technology. By completely abstracting the underlying
                 graphics architecture, network topology, and API
                 command processing semantics, we allow a variety of
                 applications to run in different environments.",
  editor =       "John Hughes",
  keywords =     "Scalable Rendering, Cluster Rendering, Parallel
                 Rendering, Tiled Displays, Remote Graphics, Virtual
                 Graphics, Stream Processing",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-222,
  pages =        "703--712",
  year =         "2002",
  title =        "Ray Tracing on Programmable Graphics Hardware",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-222",
  author =       "Timothy J. Purcell and Ian Buck and William R. Mark
                 and Pat Hanrahan",
  abstract =     "Recently a breakthrough has occurred in graphics
                 hardware: fixed function pipelines have been replaced
                 with programmable vertex and fragment processors. In
                 the near future, the graphics pipeline is likely to
                 evolve into a general programmable stream processor
                 capable of more than simply feed-forward triangle
                 rendering. In this paper, we evaluate these trends in
                 programmability of the graphics pipeline and explain
                 how ray tracing can be mapped to graphics hardware.
                 Using our simulator, we analyze the performance of a
                 ray casting implementation on next generation
                 programmable graphics hardware. In addition, we compare
                 the performance difference between non-branching
                 programmable hardware using a multipass implementation
                 and an architecture that supports branching. We also
                 show how this approach is applicable to other ray
                 tracing algorithms such as Whitted ray tracing, path
                 tracing, and hybrid rendering algorithms. Finally, we
                 demonstrate that ray tracing on graphics hardware could
                 prove to be faster than CPU based implementations as
                 well as competitive with traditional hardware
                 accelerated feed-forward triangle rendering.",
  editor =       "John Hughes",
  keywords =     "Programmable Graphics Hardware, Ray Tracing",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-223,
  pages =        "713--719",
  year =         "2002",
  title =        "Shader-Driven Compilation of Rendering Assets",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-223",
  author =       "Paul Lalonde and Eric Schenk",
  abstract =     "Rendering performance of consumer graphics hardware
                 benefitsi from pre-processing geometric data into a
                 form targeted to the underlying API and hardware. The
                 various elements of geometric data are then coupled
                 with a shading program at runtime to draw the asset. In
                 this paper we describe a system in which pre-processing
                 is done in a compilation process in which the geometric
                 data are processed with knowledge of their shading
                 programs. The data are converted into structures
                 targeted directly to the hardware, and a code stream is
                 assembled that describes the manipulations required to
                 render these data structures. Our compiler is
                 structured like a traditional code compiler, with a
                 front end that reads the geometric data and attributes
                 (hereafter referred to as an art asset) output from a
                 3D modeling package and shaders in a platform
                 independent form and performs platform-independent
                 optimizations, and a back end that performs
                 platform-specific optimizations and generates
                 platform-targeted data structures and code streams. Our
                 compiler back-end has been targeted to four platforms,
                 three of which are radically different from one
                 another. On all platforms the rendering performance of
                 our compiled assets, used in real situations, is well
                 above that of hand-coded assets.",
  editor =       "John Hughes",
  keywords =     "Computer Games, Graphics Systems, Rendering, Rendering
                 Systems",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-224,
  pages =        "721--728",
  year =         "2002",
  title =        "Physically Based Modeling and Animation of Fire",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-224",
  author =       "Duc Quang Nguyen and Ronald P. Fedkiw and Henrik Wann
                 Jensen",
  abstract =     "We present a physically based method for modeling and
                 animating fire. Our method is suitable for both smooth
                 (laminar) and turbulent flames, and it can be used to
                 animate the burning of either solid or gas fuels. We
                 use the incompressible Navier-Stokes equations to
                 independently model both vaporized fuel and hot gaseous
                 products. We develop a physically based model for the
                 expansion that takes place when a vaporized fule reacts
                 to form hot gaseous products, and a realted model for
                 the similar expansion that takes place when a solid
                 fuel is vaporized into a gaseous state. The hot gaseous
                 products, smoke and soot rise under the influence of
                 buoyancy and are rendered using a blackbody radiation
                 model. We also model and render the blue core that
                 results from adicals in the chemical reaction zone
                 where fuel is converted into products. Our method
                 allows the fire and smoke to interact with objects, and
                 flammable objects can catch on fire.",
  editor =       "John Hughes",
  keywords =     "Flames, fire, smoke, chemical reaction, blackbody
                 radiation, implicit surface, incompressible flow,
                 stable fluids, vorticity confinement",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-225,
  pages =        "729--735",
  year =         "2002",
  title =        "Structural Modeling of Natural Flames",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-225",
  author =       "Arnauld Lamorlette and Nick Foster",
  abstract =     "In this paper we describe a system for animating
                 flames. Stochastic models of flickering and buoyant
                 diffusion provide realistic local appearance while
                 physics-based wind fields and Kolmogorov noise add
                 controllable motion and scale. Procedural mechanisms
                 are developed for animating all aspects of flame
                 behavior including moving sources, combustion spread,
                 flickering, separation and merging, and interaction
                 with stationary objects. At all stages in the process
                 the emphasis is on total artistic and behavioral
                 control while maintaining interactive animation rates.
                 The final system is suitable for a high volume
                 production pipeline.",
  editor =       "John Hughes",
  keywords =     "Animation systems, fire, flames, convection,
                 physically based modeling, wind fields, Kolmogorov
                 spectrum",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-226,
  pages =        "736--744",
  year =         "2002",
  title =        "Animation and Rendering of Complex Water Surfaces",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-226",
  author =       "Douglas P. Enright and Stephen R. Marschner and Ronald
                 P. Fedkiw",
  abstract =     "We present a new method for the animation and
                 rendering of photorealistic water effects. Our method
                 is designed to produce visually plausible three
                 dimensional effects, for example the pouring of water
                 into a glass and the breaking of an ocean wave, in a
                 manner which can be used in a computer animation
                 environment. In order to better obtain photorealism in
                 the behavior of the simulated water surface, we
                 introduce a new {"}thickened{"} front tracking
                 technique to accurately represent the water surface and
                 a new velocity extrapolation method to move the surface
                 in a smooth, water-like manner. The velocity
                 extrapolation method allows us to provide a degree of
                 control to the surface motion, e.g. to generate a
                 wind-blown look or to force the water to settle
                 quickly. To ensure that the photorealism of the
                 simulation carries over to the final images, we have
                 integrated our method with an advanced physically based
                 rendering system.",
  editor =       "John Hughes",
  keywords =     "Computational fluid dynamics, implicit surfaces,
                 nutarual phenomena, physically-based animation,
                 rendering, volume rendering",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-227,
  pages =        "745--754",
  year =         "2002",
  title =        "Image Based Flow Visualization",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-227",
  author =       "Jarke J. van Wijk",
  abstract =     "A new method for the visualization of two-dimensional
                 fluid flow is presented. The method is based on the
                 advection and decay of dye. These processes are
                 simulated by defining each frame of a flow animation as
                 a blend between a warped version of the previous image
                 and a number of background images. For the latter a
                 sequence of filtered white noise images is used:
                 filtered in time and space to remove high frequency
                 components. Because all steps are done using images,
                 the method is named Image Based Flow Visualization
                 (IBFV). With IBFV a wide variety of visualization
                 techniques can be emulated. Flow can be visualized as
                 moving textures with line integral convolution and spot
                 noise. Arrow plots, streamlines, particles, and
                 topological images can be generated by adding extra dye
                 to the image. Unsteady flows, defined on arbitrary
                 meshes, can be handled. IBFV achieves a high
                 performance by using standard features of graphics
                 hardware. Typically fifty frames per second are
                 generated using standard graphics cards on PCs.
                 Finally, IBFV is easy to understand, analyse, and
                 implement.",
  editor =       "John Hughes",
  keywords =     "Flow visualization, texture mapping, line integral
                 convolution",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-228,
  pages =        "755--762",
  year =         "2002",
  title =        "{WYSIWYG} {NPR}: Drawing Strokes Directly on 3{D}
                 Models",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-228",
  author =       "Robert D. Kalnins and Lee Markosia and Barbara J.
                 Meier and Michael A. Kowalski and Joseph C. Lee and
                 Philip L. Davidson and Matthew Webb and John F. Hughes
                 and Adam Finkelstein",
  abstract =     "We present a system that lets a designer directly
                 annotate a 3D model with strokes, imparting a personal
                 aesthetic to the non-photorealistic rendering of the
                 object. The artist chooses a {"}brush{"} style, then
                 draws strokes over the model from one or more
                 viewpoints. When the system renders the scene from any
                 new viewpoint, it adapts the number and placement of
                 the strokes appropriately to maintain the original
                 look.",
  editor =       "John Hughes",
  keywords =     "Interactive techniques, non-photorealism",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-229,
  pages =        "763--768",
  year =         "2002",
  title =        "Painting and Rendering Textures on Unparameterized
                 Models",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-229",
  author =       "David (grue) DeBry and Jonathan Gibbs and Devorah
                 DeLeon Petty and Nate Robins",
  abstract =     "This paper presents a solution for texture mapping
                 unparameterized models. The quality of a texture on a
                 model is often limited by the model's parameterization
                 into a 2D texture space. For models with complex
                 topologies or complex distributions of structural
                 detail, finding this parameterization can be very
                 difficult and usually must be performed manually
                 through a slow iterative process between the modeler
                 and texture painter. This is especially true of models
                 which carry no natural parameterizations, such as
                 subdivision surfaces or models acquired from 3D
                 scanners. Instead, we remove the 2D parameterization
                 and store the texture in 3D space as a sparse, adaptive
                 octree. Because no parameterization is necessary,
                 textures can be painted on any surface that can be
                 rendered. No mappings between disparate topologies are
                 used, so texture artifacts such as seams and stretching
                 do not exist. Because this method is adaptive, detail
                 is created in the map only where required by the
                 texture painter, conserving memory usage.",
  editor =       "John Hughes",
  keywords =     "Texture Mapping, Paint Systems, Rendering Systems,
                 Spatial Data Structures, Level of Detail Algorithms",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-23,
  year =         "2002",
  title =        "Computing Geodesic Paths on Triangular Meshes",
  author =       "M. Novotni and R. Klein",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-23",
  abstract =     "We present an approximation method to compute geodesic
                 distances on triangulated domains in the three
                 dimensional space. Our particular approach is based on
                 the Fast Marching Method for solving the Eikonal
                 equation on triangular meshes. As such, the algorithm
                 is a wavefront propagation method, a reminiscent of the
                 Dijkstra algorithm, which runs in O(n log n) steps.",
  editor =       "V. Skala",
  keywords =     "Geodesic distances, computational geometry",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-230,
  pages =        "769--776",
  year =         "2002",
  title =        "Stylization and Abstraction of Photographs",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-230",
  author =       "Doug DeCarlo and Anthony Santella",
  abstract =     "Good information design depends on clarifying the
                 meaningful structure in an image. We describe a
                 computational approach to stylizing and abstracting
                 photographs that explicitly responds to this design
                 goal. Our system transforms images into a line-drawing
                 style using bold edges and large regions of constant
                 color. To do this, it represents images as a
                 hierarchical structure of parts and boundaries computed
                 using state-of-the-art computer vision. Our system
                 identifies the meaningful elements of this structure
                 using a model of human perception and a record of a
                 user's eye movements in looking at the photo; the
                 system renders a new image using transformations that
                 preserve and highlight these visual elements. Our
                 method thus represents a new alternative for
                 non-photorealistic rendering both in its visual style,
                 in its approach to visual form, and in its techniques
                 for interaction.",
  editor =       "John Hughes",
  keywords =     "Non-photorealistic rendering, visual perception,
                 eyetracking, image simplification",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-231,
  pages =        "777--784",
  year =         "2002",
  title =        "Object-Based Image Editing",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-231",
  author =       "William A. Barrett and Alan S. Cheney",
  abstract =     "We introduce Object-Based Image Editing (OBIE) for
                 real-time animation and manipulation of static digital
                 photographs. Individual image objects (such as an arm
                 or nose, Figure 1) are selected, scaled, stretched,
                 bent, warped or even deleted (with automatic bale
                 filling) - at the object, rather than the pixel level -
                 using simple gesture motions with a mouse. OBIE gives
                 the uesr direct, local control over object shape, size,
                 and placement while dramatically reducing the time
                 required to perform image editing tasks. Object
                 selection is performed by manually collecting
                 (subobject) regions detected by a watershed algorithm.
                 Objects are tesselated into a triangular mesh, allowing
                 shape modifications to be performed in real time using
                 OpenGL texture mapping hardware. Through the use of
                 anchor points, the user is able to interactively
                 perform editing operations on a whole object, or just
                 part(s) of an object - including moving, scaling,
                 rotating, stretching, bending, and deleting. Indirect
                 manipulation of object shape is also provided through
                 the use of sliders and Bezier curves. Holes created by
                 movement are filled in real-time based on surrounding
                 texture. When objects stretch or scale, we provide a
                 method for preserving texture granularity or scale. We
                 also present different parts of an image, using
                 existing image texture(s). OBIE allows the user to
                 perform interactive, high-level editing of image
                 objects in a few seconds to a few ten's of seconds.",
  editor =       "John Hughes",
  keywords =     "Image editing, Image-based rendering, Animation,
                 Texture Synthesis, Image Warping",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-232,
  pages =        "785--790",
  year =         "2002",
  title =        "Octree Textures",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-232",
  author =       "David Benson and Joel Davis",
  abstract =     "Texturing using a set of two dimensional image maps is
                 an established and widespread practice. However, it has
                 many limitations. Parameterizing a model in texture
                 space can be very difficult, particularly with
                 representations such as implicit surfaces, subdivision
                 surfaces, and very dense or detailed polygonal meshes.
                 This paper proposes the use of a new kind of texture
                 based on an octree, which needs no parameterization
                 other than the surface itself, and yet has similar
                 storage requirements to 2D maps. In addition, it offers
                 adaptive detail, regular sampling over the surface, and
                 continuity across surface boundaries. The paper
                 addresses texture creation, painting, storage,
                 processing, and rendering with octree textures.",
  editor =       "John Hughes",
  keywords =     "Volume Texture",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  publisher =    "ACM Press/ACM SIGGRAPH",
}

@InProceedings{EVL-2002-233,
  pages =        "1--8",
  year =         "2002",
  title =        "Layered Environment-Map Impostors for Arbitrary
                 Scenes",
  author =       "Stefan Jeschke and Michael Wimmer and Heidrun
                 Schuman",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-233",
  abstract =     "This paper presents a new impostor-based approach to
                 accelerate the rendering of very complex static scenes.
                 The scene is partitioned into viewing regions, and a
                 layered impostor representation is precalculated for
                 each of them. An optimal placement of impostor layers
                 guarantees that our representation is indistinguishable
                 from the original geometry. Furthermore the algorithm
                 exploits common graphics hardware both during
                 preprocessing and rendering. Moreover the impostor
                 representation is compressed using several strategies
                 to cut down on storage space.",
  month =        may,
  keywords =     "Virtual environments, walkthroughs, image-based
                 rendering, impostors, environments maps",
  booktitle =    "Proceedings of Graphics Interface",
}

@InProceedings{EVL-2002-234,
  pages =        "9--16",
  year =         "2002",
  title =        "Animation with Threshold Textures",
  author =       "Oleg Veryovka",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-234",
  abstract =     "We present a method for frame coherent texturing and
                 hatching of 3D models with a discrete set of colors.
                 Our technique is inspired by various artistic styles
                 that use a limited set of colors to convey surface
                 shape and texture. In previous research discrete color
                 shading was produced by modifying smooth shading with a
                 threshold function. We extend this approach and specify
                 threshold values with an image or a procedural texture.
                 Texture values and mapping coordinates are adapted to
                 surface orientation and scale. Aliasing artifacts are
                 eliminated by the modified filtering technique. The
                 threshold texturing approach enables an animator to
                 control local shading and to display surface roughness
                 and curvature with a limited set of colors.",
  month =        may,
  keywords =     "Non-photorealistic rendering, texture mapping,
                 filtering, animation",
  booktitle =    "Proceedings of Graphics Interface",
}

@InProceedings{EVL-2002-235,
  pages =        "17--24",
  year =         "2002",
  title =        "A Fresh Perspective",
  author =       "Karan Singh",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-235",
  abstract =     "While general trends in computer graphics continue to
                 drive towards more photorealistic imagery, increasing
                 attention is also being devoted to painterly renderings
                 of computer generated scenes. Whereas artists using
                 traditional media almost always deviate from the
                 confines of a precise linear perspective view, digital
                 artists struggle to transcend the standard pin-hole
                 camera model in generating an envisioned image of a
                 three dimensional scene. More specifically, a key
                 limitation of existing camera models is that they
                 inhibit the artistic exploration and understanding of a
                 subject, which is essential for expressing it
                 successfully. Past experiments with non-linear
                 perspectives have primarily focused on abstract
                 mathematical camera models for raytracing, which are
                 both non-interactive and provide the artist with little
                 control over seeing what he wants to see. We address
                 this limitation with a cohesive, interactive approach
                 for exploring non-linear perspective projections. The
                 approach consists of a new camera model and a toolbox
                 of interactive local and global controls for a number
                 of properties, including regions of interest,
                 distortion, and spatial relationship. Furthermore, the
                 approach is incremental, allowing non-linear
                 perspective views of a scene to be built gradually by
                 blending and compositing multiple linear perspectives.
                 In addition to artistic non-photorealistic rendering,
                 our approach has interesting applications in conceptual
                 design and scientific visualization.",
  month =        may,
  keywords =     "Non-Photorealistic rendering, Multiprojection,
                 Non-linear Perspective, Camera Model",
  booktitle =    "Proceedings of Graphics Interface",
}

@InProceedings{EVL-2002-236,
  pages =        "25--34",
  year =         "2002",
  title =        "Constraint-Based Automatic Placement for Scene
                 Composition",
  author =       "Ken Xu and James Stewart and Eugene Fiume",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-236",
  abstract =     "The layout of large scenes can be a time-consuming and
                 tedious task. In most current systems, the user must
                 position each of the objects by hand, one at a time.
                 This paper presents a constraint-based automatic
                 placement system, which allows the user to quickly and
                 easily lay out complex scenes. The system uses a
                 combination of automatically-generated placement
                 constraints, pseudo-physics, and a semantic database to
                 guide the automatic placement of objects. Existing
                 scenes can quickly be rearranged simply by reweighting
                 the placement preferences. We show that the system
                 enables a user to lay out a complex scene of 300
                 objects in less than 10 minutes.",
  month =        may,
  booktitle =    "Proceedings of Graphics Interface",
}

@InProceedings{EVL-2002-237,
  pages =        "35--42",
  year =         "2002",
  title =        "Fa{ST} Sliders: Integrating Marking Menus and the
                 Adjustment of Continuous Values",
  author =       "Michael McGuffin and Nicolas Burtnyk and Gordon
                 Kurtenbach",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-237",
  abstract =     "We propose a technique, called FaST Sliders, for
                 selecting and adjusting continuous values using a fast,
                 transient interaction much like pop-up menus. FaST
                 Sliders combine marking menus and graphical sliders in
                 a design that allows operation with quick ballistic
                 movements for selection and coarse adjustment.
                 Furthermore, additional controls can be displayed
                 within the same interaction, for fine adjustments or
                 other functions. We describe the design of FaST Sliders
                 and a user study comparing FaST sliders to other
                 transient techniques. The results of our user study
                 indicate that FaST Sliders hold potential. We observed
                 that users found FaST Slider easy to learn and made use
                 of and preferred its affordances for ballistic movement
                 and additional controls.",
  month =        may,
  keywords =     "Marking menus, control menus, flowmenus, gestures,
                 sliders, fast slider, interaction design",
  booktitle =    "Proceedings of Graphics Interface",
}

@InProceedings{EVL-2002-238,
  pages =        "43--50",
  year =         "2002",
  title =        "Traces: Visualizing the Immediate Past to Support
                 Group Interaction",
  author =       "Carl Gutwin",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-238",
  abstract =     "Virtual embodiments of people in groupware systems
                 provide a wealth of information to others in the group.
                 They allow for explicit gestural communication, and
                 they provide implicit awareness information about
                 people?s locations and activities. However, the
                 constraints of current networked groupware limit the
                 effectiveness of these kinds of communication. This
                 paper investigates how embodiments can be augmented
                 with traces - visualizations of past movements - to
                 help others perceive and interpret bodily communication
                 more clearly and more accurately. The paper presents a
                 case study of traces applied to telepointers, and gives
                 several examples of how the concept can be used to
                 improve interaction effectiveness in groupware.",
  keywords =     "Synchronous groupware, groupware usability, awareness,
                 interaction histories, edit wear",
  booktitle =    "Proceedings of Graphics Interface",
}

@InProceedings{EVL-2002-239,
  pages =        "51--58",
  year =         "2002",
  title =        "Image-Based Hair Capture by Inverse Lighting",
  author =       "St{\'{e}}phane Grabli and Fran{\c{c}}ois X. Sillion
                 and Stephen R. Marschner and Jerome E. Lengyel",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-239",
  abstract =     "We introduce an image-based method for modeling a
                 specific subject's hair. The principle of the approach
                 is to study the variations of hair illumination under
                 controlled illumination. The use of a stationary
                 viewpoint and the assumption that the subject is still
                 allows us to work with perfectly registered images: all
                 pixels in an image sequence represent the same portion
                 of the hair, and the particular illumination profile
                 observed at each pixel can be used to infer the missing
                 degree of directional information. This is accomplished
                 by synthesizing reflection profiles using a hair
                 reflectance model, for a number of candidate directions
                 at each pixel, and choosing the orientation that
                 provides the best profile match. Our results
                 demonstrate the potential of this approach, by
                 effectively reconstructing accurate hair strands that
                 are well highlighted by a particular light source
                 movement.",
  month =        may,
  keywords =     "Hair reflectance, Hair Modeling, Reflectance Analysis,
                 Shape from Shading",
  booktitle =    "Proceedings of Graphics Interface",
}

@InProceedings{EVL-2002-24,
  year =         "2002",
  title =        "A Two-Level Differential Volume Rendering Method for
                 Time-Varying-Volume-Data",
  author =       "S.-K. Liao and Y. Ch. Chung and J. Z. C. Lai",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-24",
  abstract =     "The differential volume rendering method is a ray
                 casting based method for time-varying-volume-data. In
                 the differential volume rendering method, the changed
                 fractions of volume data between consecutive time steps
                 are extracted to form differential files. Based on the
                 differential files, only the changed pixels, instead of
                 all the pixels in the image, are updated by casting new
                 rays at the positions in each time step. The main
                 overhead of the differential volume rendering method is
                 to determine the changed pixel positions before casting
                 new rays for the changed pixels. In this paper, we
                 propose a two-level differential volume rendering
                 method, which is a modified differential volume
                 rendering method with faster determination of the
                 changed pixel positions. In the proposed method, the
                 determination of the changed pixel positions is
                 accelerated by the aid of second-order-difference.
                 Since voxels in two consecutive differential files may
                 partially overlap in the space, the computation spent
                 on determining the changed pixel positions due to the
                 overlapped area is redundant. We use this property to
                 extract the difference of changed voxel positions
                 between consecutive differential files to form the
                 second-order-difference. Based on the
                 second-order-difference, the changed pixel positions
                 can be determined efficiently. The experimental results
                 show that the proposed method outperforms the
                 differential volume rendering method for all test
                 datasets.",
  editor =       "V. Skala",
  keywords =     "Ray casting, differential volume rendering,
                 time-varying-volume-data, flow animation, CFD",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-240,
  pages =        "59--68",
  year =         "2002",
  title =        "The Simulation of Paint Cracking and Peeling",
  author =       "Eric Paquette and Pierre Poulin and George Drettakis",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-240",
  abstract =     "Weathering over long periods of time results in
                 cracking and peeling of layers such as paint. To
                 include these effects in computer graphics images it is
                 necessary to simulate crack propagation, loss of
                 adhesion, and the curling effect of paint peeling. We
                 present a new approach which computes such a simulation
                 on surfaces. Our simulation is inspired by the
                 underlying physical properties. We use paint strength
                 and tensile stress to determine where cracks appear on
                 the surface. Cracks are then propagated through a 2D
                 grid overlaid on the original surface, and we consider
                 elasticity to compute the reduction of paint stress
                 around the cracks. Simulation of the adhesion between
                 the paint and the underlying material finally
                 determines how the paint layer curls as it peels from
                 the surface. The result of this simulation is rendered
                 by generating explicit geometry to represent the
                 peeling curls. We provide user control of the surface
                 properties influencing the propagation of cracks.
                 Results of our simulation and rendering method show
                 that our approach produces convincing images of cracks
                 and peels.",
  month =        may,
  keywords =     "Deteriorations, surface imperfections, paint, cracks,
                 multi-layer surfaces, natural phenomena",
  booktitle =    "Proceedings of Graphics Interface",
}

@InProceedings{EVL-2002-241,
  pages =        "81--88",
  year =         "2002",
  title =        "Simulation and Rendering of Liquid Foams",
  author =       "Hendrik K{\"u}ck and Christian Vogelgsang and and
                 G{\"u}nther Greiner",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-241",
  abstract =     "In this paper we present a technique for simulating
                 and rendering liquid foams. We are aiming at a
                 functional realism that allows our simulation to be
                 consistent with the physical effects in real liquid
                 foam while avoiding the prohibitive computational cost
                 of a physically accurate simulation. To this end, we
                 have to recreate two important attributes of foam. The
                 dynamic behaviour of the simulated foam must be based
                 on the physics of real foam, and the characteristic
                 interior structures of foam and their optical
                 properties must be reproduced. We tackle these
                 requirements by introducing a two part hybrid rendering
                 approach. The first stage is geometric and determines
                 the dynamic behaviour of the foam by simulating
                 structural forces on a set of spheres, which represent
                 the foam bubbles. In the second stage we render these
                 spheres using a special surface shader that implicitly
                 reconstructs the foam surfaces and performs the shading
                 calculations. This two step approach allows us to
                 easily integrate our technique into existing
                 ray-tracing systems. We include images of an example
                 animation to demonstrate the visual quality.",
  month =        may,
  keywords =     "Liquid foam, simulation, rendering, natural phenomena,
                 shading techniques",
  booktitle =    "Proceedings of Graphics Interface",
}

@InProceedings{EVL-2002-242,
  pages =        "89--98",
  year =         "2002",
  title =        "Texturing Faces",
  author =       "Marco Tarini and Hitoshi Yamauchi and J{\"o}rg Haber
                 and Hans-Peter Seidel",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-242",
  abstract =     "We present a number of techniques to facilitate the
                 generation of textures for facial modeling. In
                 particular, we address the generation of facial skin
                 textures from uncalibrated input photographs as well as
                 the creation of individual textures for facial
                 components such as eyes or teeth. Apart from an initial
                 feature point selection for the skin texturing, all our
                 methods work fully automatically without any user
                 interaction. The resulting textures show a high quality
                 and are suitable for both photo-realistic and real-time
                 facial animation.",
  month =        may,
  keywords =     "Texture mapping, texture synthesis, mesh
                 parameterization, facial modeling, real-time
                 rendering",
  booktitle =    "Proceedings of Graphics Interface",
}

@InProceedings{EVL-2002-243,
  pages =        "99--106",
  year =         "2002",
  title =        "A Direct Method for Positioning the Arms of a Human
                 Model",
  author =       "John McDonald and Karen Alkoby and Jacob Furst and
                 Glenn Lancaster and Rosalee Wolfe",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-243",
  abstract =     "Many problems in computer graphics concern the precise
                 positioning of a human figure, and in particular, the
                 positioning of the joints in the upper body as a
                 virtual character performs some action. We explore a
                 new technique for precisely positioning the joints in
                 the arms of a human figure to achieve a desired
                 posture. We focus on an analytic solution for the IK
                 chains of the model's arms and an interface for
                 conveniently specifying a desired targeting point, or
                 articulator, on the model's hand. Also, we consider the
                 problem of specifying a target for that articulator in
                 space or in contact with the model's own body. These
                 methods recast the seven degrees of freedom in the arm
                 to provide a more intuitive interface for animation. We
                 demonstrate the efficacy and efficiency of these
                 techniques in positioning a virtual American Sign
                 Language interpreter.",
  month =        may,
  keywords =     "Analytic Algorithms, Inverse Kinematics, Human Arm,
                 ASL",
  booktitle =    "Proceedings of Graphics Interface",
}

@InProceedings{EVL-2002-244,
  pages =        "107--116",
  year =         "2002",
  title =        "Application-Specific Muscle Representations",
  author =       "Victor Ng-Thow-Hing and Eugene Fiume",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-244",
  abstract =     "The need to model muscles means different things to
                 artistic and technical practitioners. Three different
                 muscle representations are presented and the
                 motivations behind their design are discussed. Each
                 representation allows unique capabilities and
                 operations to be performed on the model, yet the
                 underlying mathematical foundation is the same for all.
                 This is achieved by developing a data-fitting pipeline
                 that allows samples that are generated from different
                 data sources to be used in the guided construction of a
                 B-spline solid. We show how B-spline solids can be used
                 to create muscles from contour curves extracted out of
                 medical images, digitized fibre sets from dissections
                 of muscle specimens, and profile curves that can be
                 interactively sketched and manipulated by an anatomical
                 modeller.",
  month =        may,
  keywords =     "Anatomical modelling, muscles, data-fitting, B-spline
                 solid",
  booktitle =    "Proceedings of Graphics Interface",
}

@InProceedings{EVL-2002-245,
  pages =        "117--124",
  year =         "2002",
  title =        "A Model of Two-Thumb Text Entry",
  author =       "I. Scott MacKenzie and R. William Soukoreff",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-245",
  abstract =     "Although text entry has been extensively studied for
                 touch typing on standard keyboards and finger and
                 stylus input on soft keyboards, no such work exists for
                 two-thumb text entry on miniature Qwerty keyboards. In
                 this paper, we propose a model for this mode of text
                 entry. The model provides a behavioural description of
                 the interaction as well as a predicted text entry rate
                 in words per minute. The prediction obtained is 60.74
                 words per minute. The prediction is based solely on the
                 linguistic and motor components of the task; thus, it
                 is a peak rate for expert text entry. A detailed
                 sensitivity analysis is included to examine the effect
                 of changing the model's components and parameters over
                 a broad range (+/-50% for the parameters). The model
                 demonstrates reasonable stability - predictions remain
                 within about 10% of the value just cited.",
  month =        may,
  booktitle =    "Proceedings of Graphics Interface",
}

@InProceedings{EVL-2002-246,
  pages =        "125--132",
  year =         "2002",
  title =        "Virtual Sculpting with Haptic Displacement Maps",
  author =       "Robert Jagnow and Julie Dorsey",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-246",
  abstract =     "This paper presents an efficient data structure that
                 facilitates high-speed haptic (force feedback)
                 interaction with detailed digital models. Models are
                 partitioned into coarse slabs, which collectively
                 define a piecewise continuous vector field over a thick
                 volumetric region surrounding the surface of the model.
                 Within each slab, the surface is represented as a
                 displacement map, which uses the vector field to define
                 a relationship between points in space and
                 corresponding points on the model's surface. This
                 representation facilitates efficient haptic interaction
                 without compromising the visual complexity of the
                 scene. Furthermore, the data structure provides a basis
                 for interactive local editing of a model's color and
                 geometry using the haptic interface. We describe
                 implementation details and demonstrate the use of the
                 data structure with a variety of digital models.",
  month =        may,
  keywords =     "Haptic, displacement map, sculpt, slab",
  booktitle =    "Proceedings of Graphics Interface",
}

@InProceedings{EVL-2002-247,
  pages =        "133--140",
  year =         "2002",
  title =        "A Desktop Input Device and Interface for Interactive
                 3{D} Character Animation",
  author =       "Sageev Oore and Demetri Terzopoulos and Geoffrey
                 Hinton",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-247",
  abstract =     "We present a novel input device and interface for
                 interactively controlling the animation of graphical
                 human character from a desktop environment. The
                 trackers are embedded in a new physical design, which
                 is both simple yet also provides significant benefits,
                 and establishes a tangible interface with coordinate
                 frames inherent to the character. A layered kinematic
                 motion recording strategy accesses subsets of the total
                 degrees of freedom of the character. We present the
                 experiences of three novice users with the system, and
                 that of a long-term user who has prior experience with
                 other complex continuous interfaces.",
  month =        may,
  keywords =     "Interactive character animation, Input device, Motion
                 capture, Expert user interaction, Tangible interfaces",
  booktitle =    "Proceedings of Graphics Interface",
}

@InProceedings{EVL-2002-248,
  pages =        "141--150",
  year =         "2002",
  title =        "Laser Pointers as Collaborative Pointing Devices",
  author =       "Ji-Young Oh and Wolfgang Stuerzlinger",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-248",
  abstract =     "Single Display Groupware (SDG) is a research area that
                 focuses on providing collaborative computing
                 environ-ments. Traditionally, most hardware platforms
                 for SDG support only one person interacting at any
                 given time, which limits collaboration. In this paper,
                 we present laser pointers as input devices that can
                 provide concurrent input streams ideally required to
                 the SDG environment. First, we discuss several issues
                 related to utilization of laser pointers and present
                 the new concept of computer controlled laser pointers.
                 Then we briefly present a performance evaluation of
                 laser pointers as input devices and a baseline
                 comparison with the mouse according to the ISO 9241-9
                 standard. Finally, we describe a new system that uses
                 multiple computer controlled laser pointers as
                 interaction devices for one or more displays. Several
                 alternatives for distinguishing between different laser
                 pointers are presented, and an implementation of one of
                 them is demonstrated with SDG applications.",
  month =        may,
  keywords =     "Single display groupware, hardware for collaboration,
                 laser pointer, input devices",
  booktitle =    "Proceedings of Graphics Interface",
}

@InProceedings{EVL-2002-249,
  year =         "2002",
  title =        "Real-Time Extendible-Resolution Display of On-line
                 Dynamic Terrain",
  author =       "Yefei He and James Cremer and Yiannis Papelis",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-249",
  abstract =     "We present a method for multiresolution view-dependent
                 real-time display of terrain undergoing on-line
                 modification. In other words, the method does not
                 assume static terrain geometry, nor does it assume that
                 the terrain update sequence is known ahead of time. The
                 method is both fast and space efficient. It is fast
                 because it relies on local updates to the
                 multiresolution structure as terrain changes. It is
                 much more space efficient than many previous approaches
                 because the multiresolution structure can be extended
                 on-line, to provide higher resolution terrain only
                 where needed. Our approach is especially well-suited
                 for applications like real-time off-road driving
                 simulation involving large terrain areas with localized
                 high-resolution terrain updates.",
  month =        may,
  keywords =     "Dynamic terrain, triangle bintree, multiresolution
                 representation, view-dependent mesh, level of detail",
  booktitle =    "Proceedings of Graphics Interface",
}

@InProceedings{EVL-2002-25,
  year =         "2002",
  title =        "A Qo{S} Framework for Interactive 3{D} Applications",
  author =       "N. P. Ngoc and W. van Raemdonck and G. Lafruit and G.
                 Deconinck and R. Lauwereins",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-25",
  abstract =     "We present a QoS (Quality of Service) framework for
                 interactive 3D applications, in which the QoS
                 management relies on high-level QoS parameters of
                 quality scalable 3D objects, which are transmitted from
                 the service provider to the user terminals. PSNR is
                 used as one of these high level parameters for
                 representing the perception quality of 3D objects. In
                 real-time, interactive 3D applications, one of the
                 tasks of the QoS management at the end-user?s terminal
                 consists in keeping a constant interactive frame rate,
                 by trading off the 3D scene perception quality for
                 frame rate, under resource constraints. We show that
                 this task involves solving a NP-hard optimization
                 problem and we present an approximation algorithm that
                 solves the problem with an accuracy of more than 95%,
                 compared to the optimal solution, while representing a
                 negligible computation effort for every frame.
                 Experimental results show the soundness of the proposed
                 framework and algorithm.",
  editor =       "V. Skala",
  keywords =     "3D Quality of Service, level of detail, interactive
                 applications, optimization, PSNR",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-250,
  pages =        "161--170",
  year =         "2002",
  title =        "Compressing Polygon Mesh Connectivity with Degree
                 Duality Prediction",
  author =       "Martin Isenburg",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-250",
  abstract =     "In this paper we present a coder for polygon mesh
                 connectivity that delivers the best connectivity
                 compression rates meshes reported so far. Our coder is
                 an extension of the vertex-based coder for triangle
                 mesh connectivity by Touma and Gotsman[GI98]. We code
                 polygonal connectivity as a sequence of face and vertex
                 degrees and exploit the correlation between them for
                 mutual predictive compression. Because low-degree
                 vertices are likely to be surrounded by high-degree
                 faces and vice versa, we predict vertex degrees based
                 on neighboring face degrees and face degrees based on
                 neighboring vertex degrees.",
  month =        may,
  keywords =     "Connectivity coding, graph coding, mesh compression,
                 non-manifold meshes, degree duality",
  booktitle =    "Proceedings of Graphics Interface",
}

@InProceedings{EVL-2002-251,
  pages =        "171--180",
  year =         "2002",
  title =        "Efficient Bounded Adaptive Tessellation of
                 Displacement Maps",
  author =       "Kevin Moule and Michael D. McCool",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-251",
  abstract =     "Displacement mapping is a technique for applying fine
                 geometric detail to a simpler base surface. The
                 displacement is often specified as a scalar function
                 which makes it relatively easy to increase visual
                 complexity without the difficulties inherent in more
                 general modeling techniques. We would like to use
                 displacement mapping in real-time applications.
                 Ideally, a graphics accelerator should create a
                 polygonal tessellation of the displaced surface on the
                 fly to avoid storage and host bandwidth overheads. We
                 present an online, adaptive, crack-free tessellation
                 scheme for real-time displacement mapping that uses
                 only local information for each triangle to perform a
                 view-dependent tessellation. The tessellation works in
                 homogeneous coordinates and avoids re-transformation of
                 displaced points, making it suitable for
                 high-performance hardware implementation. The use of
                 interval analysis produces meshes with good error
                 bounds that converge quickly to the true surface.",
  month =        may,
  keywords =     "Hardware acceleration, Bump mapping, Displacement
                 mapping, Adaptive tessellation",
  booktitle =    "Proceedings of Graphics Interface",
}

@InProceedings{EVL-2002-252,
  pages =        "181--188",
  year =         "2002",
  title =        "Automatic Generation of Subdivision Surface Head
                 Models from Point Cloud Data",
  author =       "Won-Ki Jeong and Kolja K{\"a}hler and J{\"o}rg Haber
                 and Hans-Peter Seidel",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-252",
  abstract =     "An automatic procedure is presented to generate a
                 multiresolution head model from sampled surface data. A
                 generic control mesh serves as the starting point for a
                 fitting algorithm that approximates the points in an
                 unstructured set of surface samples, e.g. a point cloud
                 obtained directly from range scans of an individual. A
                 hierarchical representation of the model is generated
                 by repeated refinement using subdivision rules and
                 measuring displacements to the input data. Key features
                 of our method are the fully automated construction
                 process, the ability to deal with noisy and incomplete
                 input data, and no requirement for further processing
                 of the scan data after registering the range images
                 into a single point cloud.",
  month =        may,
  keywords =     "Range scans, subdivision surface, facial animation,
                 point cloud fitting",
  booktitle =    "Proceedings of Graphics Interface",
}

@InProceedings{EVL-2002-253,
  pages =        "189--201",
  year =         "2002",
  title =        "A {BRDF} Database Employing the Beard-Maxwell
                 Reflection Model",
  author =       "Harold Westlund and Gary Meyer",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-253",
  abstract =     "The Beard-Maxwell reflection model is presented as a
                 new local reflection model for use in realistic image
                 synthesis. The model is important because there is a
                 public domain database of surface reflection
                 parameters, the Nonconventional Exploitation Factors
                 Data System (NEFDS), that utilizes a modified form of
                 the Beard-Maxwell model. Additional surface reflection
                 parameters for the database can be determined because a
                 measurement protocol, using existing radiometric
                 instruments, has been specified. The Beard-Maxwell
                 model is also of historical significance because it
                 predates many computer graphics reflection models and
                 because it includes several features that are
                 incorporated into existing local reflection models. The
                 NEFDS is described and a special shader is developed
                 for use with NEFDS. The shader makes use of the alias
                 method for determining random variates from discrete
                 probability distributions. Realistic images are
                 synthesized from the existing database and from samples
                 that were characterized using the measurement
                 protocol.",
  month =        may,
  keywords =     "BRDF, local illumination",
  booktitle =    "Proceedings of Graphics Interface",
}

@InProceedings{EVL-2002-254,
  pages =        "201--208",
  year =         "2002",
  title =        "Coherent Bump Map Recovery from a Single Texture
                 Image",
  author =       "Jean-Michel Dischler and Karl Maritaud and Djamchid
                 Ghazanfarpour",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-254",
  abstract =     "In order to texture surfaces realistically with
                 texture images (e.g. photos), it is important to
                 consider the underlying relief. Here, a method is
                 proposed to recover a coherent bump map from a single
                 texture image. Different visual zones are first
                 identified using segmentation and classification. Then,
                 by linearly separating the relief into a noise-like
                 small-scale component and a smooth shape-related
                 large-scale component, we can automatically deduce the
                 bump map as well as an unshaded color map of the
                 texture. The major advantage of our approach, compared
                 to sophisticated measurement techniques based on
                 multiple photos or specific devices, is its practical
                 simplicity and broad accessibility, while it allows us
                 to obtain very easily, via basic bump mapping or
                 displacement mapping, rendering results of good
                 quality.",
  keywords =     "Texturing, shape from shading, texture segmentation,
                 bump mapping",
  booktitle =    "Proceedings of Graphics Interface",
}

@InProceedings{EVL-2002-255,
  pages =        "219--228",
  year =         "2002",
  title =        "Single Sample Soft Shadows Using Depth Maps",
  author =       "Stefan Brabec and Hans-Peter Seidel",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-255",
  abstract =     "In this paper we propose a new method for rendering
                 soft shadows at interactive frame rates. Although the
                 algorithm only uses information obtained from a single
                 light source sample, it is capable of producing
                 subjectively realistic penumbra regions. We do not
                 claim that the proposed method is physically correct
                 but rather that it is aesthetically correct. Since the
                 algorithm operates on sampled representations of the
                 scene, the shadow computation does not directly depend
                 on the scene complexity. Having only a single depth and
                 object ID map representing the pixels seen by the light
                 source, we can approximate penumbrae by searching the
                 neighborhood of pixels warped from the camera view for
                 relevant blocker information. We explain the basic
                 technique in detail, showing how simple observations
                 can yield satisfying results. We also address sampling
                 issues relevant to the quality of the computed shadows,
                 as well as speed-up techniques that are able to bring
                 the performance up to interactive frame rates.",
  month =        may,
  booktitle =    "Proceedings of Graphics Interface",
}

@Article{EVL-2002-256,
  pages =        "833--854",
  year =         "2002",
  title =        "Ordered and quantum treemaps: Making effective use of
                 2{D} space to display hierarchies",
  author =       "Benjamin B. Bederson and Ben Shneiderman and Martin
                 Wattenberg",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-256",
  abstract =     "Treemaps, a space-filling method for visualizing large
                 hierarchical data sets, are receiving increasing
                 attention. Several algorithms have been previously
                 proposed to create more useful displays by controlling
                 the aspect ratios of the rectangles that make up a
                 treemap. While these algorithms do improve visibility
                 of small items in a single layout, they introduce
                 instability over time in the display of dynamically
                 changing data, fail to preserve order of the underlying
                 data, and create layouts that are difficult to visually
                 search. In addition, continuous treemap algorithms are
                 not suitable for displaying fixed-sized objects within
                 them, such as images.This paper introduces a new
                 {"}strip{"} treemap algorithm which addresses these
                 shortcomings, and analyzes other {"}pivot{"} algorithms
                 we recently developed showing the trade-offs between
                 them. These ordered treemap algorithms ensure that
                 items near each other in the given order will be near
                 each other in the treemap layout. Using experimental
                 evidence from Monte Carlo trials and from actual stock
                 market data, we show that, compared to other layout
                 algorithms, ordered treemaps are more stable, while
                 maintaining relatively favorable aspect ratios of the
                 constituent rectangles. A user study with 20
                 participants clarifies the human performance benefits
                 of the new algorithms. Finally, we present quantum
                 treemap algorithms, which modify the layout of the
                 continuous treemap algorithms to generate rectangles
                 that are integral multiples of an input object size.
                 The quantum treemap algorithm has been applied to
                 PhotoMesa, an application that supports browsing of
                 large numbers of images.",
  month =        oct,
  keywords =     "Hierarchies, human-computer interaction, image
                 browsers, information visualization, jazz, ordered
                 treemaps, treemaps, trees, zoomable user interfaces
                 (ZUIs).",
  volume =       "21",
  number =       "4",
  journal =      "ACM Transactions on Graphics",
}

@Article{EVL-2002-257,
  pages =        "807--832",
  year =         "2002",
  title =        "Shape distributions",
  author =       "Robert Osada and Thomas Funkhouser and Bernard
                 Chazelle and David Dobkin",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-257",
  abstract =     "Measuring the similarity between 3D shapes is a
                 fundamental problem, with applications in computer
                 graphics, computer vision, molecular biology, and a
                 variety of other fields. A challenging aspect of this
                 problem is to find a suitable shape signature that can
                 be constructed and compared quickly, while still
                 discriminating between similar and dissimilar shapes.In
                 this paper, we propose and analyze a method for
                 computing shape signatures for arbitrary (possibly
                 degenerate) 3D polygonal models. The key idea is to
                 represent the signature of an object as a shape
                 distribution sampled from a shape function measuring
                 global geometric properties of an object. The primary
                 motivation for this approach is to reduce the shape
                 matching problem to the comparison of probability
                 distributions, which is simpler than traditional shape
                 matching methods that require pose registration,
                 feature correspondence, or model fitting.We find that
                 the dissimilarities between sampled distributions of
                 simple shape functions (e.g., the distance between two
                 random points on a surface) provide a robust method for
                 discriminating between classes of objects (e.g., cars
                 versus airplanes) in a moderately sized database,
                 despite the presence of arbitrary translations,
                 rotations, scales, mirrors, tessellations,
                 simplifications, and model degeneracies. They can be
                 evaluated quickly, and thus the proposed method could
                 be applied as a pre-classifier in a complete
                 shape-based retrieval or analysis system concerned with
                 finding similar whole objects. The paper describes our
                 early experiences using shape distributions for object
                 classification and for interactive web-based retrieval
                 of 3D models.",
  keywords =     "Shape analysis, shape representation",
  volume =       "21",
  number =       "4",
  journal =      "ACM Transactions on Graphics",
}

@Article{EVL-2002-258,
  pages =        "855--873",
  year =         "2002",
  title =        "Modelling with implicit surfaces that interpolate",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-258",
  author =       "Greg Turk and James F. O'brien",
  abstract =     "We introduce new techniques for modelling with
                 interpolating implicit surfaces. This form of implicit
                 surface was first used for problems of surface
                 reconstruction and shape transformation, but the
                 emphasis of our work is on model creation. These
                 implicit surfaces are described by specifying locations
                 in 3D through which the surface should pass, and also
                 identifying locations that are interior or exterior to
                 the surface. A 3D implicit function is created from
                 these constraints using a variational scattered data
                 interpolation approach, and the iso-surface of this
                 function describes a surface. Like other implicit
                 surface descriptions, these surfaces can be used for
                 CSG and interference detection, may be interactively
                 manipulated, are readily approximated by polygonal
                 tilings, and are easy to ray trace. A key strength for
                 model creation is that interpolating implicit surfaces
                 allow the direct specification of both the location of
                 points on the surface and the surface normals. These
                 are two important manipulation techniques that are
                 difficult to achieve using other implicit surface
                 representations such as sums of spherical or
                 ellipsoidal Gaussian functions ({"}blobbies{"}). We
                 show that these properties make this form of implicit
                 surface particularly attractive for interactive
                 sculpting using the particle sampling technique
                 introduced by Witkin and Heckbert. Our formulation also
                 yields a simple method for converting a polygonal model
                 to a smooth implicit model, as well as a new way to
                 form blends between objects.",
  month =        oct,
  volume =       "21",
  keywords =     "Implicit surfaces, function interpolation, modeling,
                 thin-plate techniques",
  number =       "4",
  journal =      "ACM Transactions on Graphics",
}

@Article{EVL-2002-259,
  pages =        "874--890",
  year =         "2002",
  title =        "Smoothing an overlay grid to minimize linear
                 distortion in texture mapping",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-259",
  author =       "Alla Sheffer and Eric de Sturler",
  abstract =     "Texture is an essential component of computer
                 generated models. For a texture mapping procedure to be
                 effective it has to generate continuous textures and
                 cause only small mapping distortion. The Angle Based
                 Flattening (ABF) parameterization method is guaranteed
                 to provide a continuous (no foldovers) mapping. It also
                 minimizes the angular distortion of the
                 parameterization, including locating the optimal planar
                 domain boundary. However, since it concentrates on
                 minimizing the angular distortion of the mapping, it
                 can introduce relatively large linear distortion.In
                 this paper we introduce a new procedure for reducing
                 length distortion of an existing parameterization and
                 apply it to ABF results. The linear distortion
                 reduction is added as a second step in a texture
                 mapping computation. The new method is based on
                 computing a mapping from the plane to itself which has
                 length distortion very similar to that of the ABF
                 parameterization. By applying the inverse mapping to
                 the result of the initial parameterization, we obtain a
                 new parameterization with low length distortion. We
                 notice that the procedure for computing the inverse
                 mapping can be applied to any other (convenient)
                 mapping from the three-dimensional surface to the plane
                 in order to improve it.The mapping in the plane is
                 computed by applying weighted Laplacian smoothing to a
                 Cartesian grid covering the planar domain of the
                 initial mapping. Both the mapping and its inverse are
                 provably continuous. Since angle preserving (conformal)
                 mappings, such as ABF, locally preserve distances as
                 well, the planar mapping has small local deformation.
                 As a result, the inverse mapping does not significantly
                 increase the angular distortion.The combined texture
                 mapping procedure provides a mapping with low distance
                 and angular distortion, which is guaranteed to be
                 continuous.",
  month =        oct,
  volume =       "21",
  keywords =     "Parameterization, smoothing., texture mapping,
                 triangulation",
  number =       "4",
  journal =      "ACM Transactions on Graphics",
}

@InProceedings{EVL-2002-26,
  year =         "2002",
  title =        "A Virtual Memory System for Real-Time Visualization of
                 Multi-resolution 2{D} Objects",
  author =       "S. Pinheiro and L. Velho",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-26",
  abstract =     "We describe a predictive memory management system that
                 allows the visualization of 2D graphic objects in real
                 time. This system is based on a virtual memory model.
                 We show how the page loading system predicts and fetch
                 data before it is accessed by the application and how
                 the page replacement system decides which data should
                 be removed from memory. We demonstrate the
                 effectiveness of the system for real-time visualization
                 of panoramas.",
  editor =       "V. Skala",
  keywords =     "Texture, virtual memory, cache management, panorama,
                 visual simulation",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@Article{EVL-2002-260,
  pages =        "211--222",
  year =         "2002",
  title =        "Lagrangian-Eulerian Advection of Noise and Dye
                 Textures for Unsteady Flow Visualization",
  author =       "Bruno Jobard and Gordon Erlebacher and M. Yousuff
                 Hussaini",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-260",
  abstract =     "A new hybrid scheme (LEA) that combines the advantages
                 of Eulerian and Lagrangian frameworks is applied to the
                 visualization of dense representations of
                 time-dependent vector fields. The algorithm encodes the
                 particles into a texture that is then advected. By
                 treating every particle equally, we can handle texture
                 advection and dye advection within a single framework.
                 High temporal and spatial correlation is achieved
                 through the blending of successive frames. A
                 combination of particle and dye advection enables the
                 simultaneous visualization of streamlines, particle
                 paths, and streaklines. We demonstrate various
                 experimental techniques on several physical flow
                 fields. The simplicity of both the resulting data
                 structures and the implementation suggest that LEA
                 could become a useful component of any scientific
                 visualization toolkit concerned with the display of
                 unsteady flows.",
  keywords =     "Flow visualization, texture advection, unsteady flow
                 fields",
  volume =       "8",
  number =       "3",
  journal =      "IEEE Transactions on Visualization and Computer
                 Graphics",
}

@Article{EVL-2002-261,
  pages =        "223--238",
  year =         "2002",
  title =        "{EWA} Splatting",
  author =       "Matthias Zwicker and Hanspeter Pfister and Jeroen van
                 Baar and Markus Gross",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-261",
  abstract =     "In this paper, we present a framework for high quality
                 splatting based on elliptical Gaussian kernels. To
                 avoid aliasing artifacts, we introduce the concept of a
                 resampling filter, combining a reconstruction kernel
                 with a low-pass filter. Because of the similarity to
                 Heckbert's EWA (elliptical weighted average) filter for
                 texture mapping, we call our technique EWA splatting.
                 Our framework allows us to derive EWA splat primitives
                 for volume data and for point-sampled surface data. It
                 provides high image quality without aliasing artifacts
                 or excessive blurring for volume data and,
                 additionally, features anisotropic texture filtering
                 for point-sampled surfaces. It also handles
                 nonspherical volume kernels efficiently; hence, it is
                 suitable for regular, rectilinear, and irregular volume
                 datasets. Moreover, our framework introduces a novel
                 approach to compute the footprint function,
                 facilitating efficient perspective projection of
                 arbitrary elliptical kernels at very little additional
                 cost. Finally, we show that EWA volume reconstruction
                 kernels can be reduced to surface reconstruction
                 kernels. This makes our splat primitive universal in
                 rendering surface and volume data.",
  keywords =     "Rendering systems, volume rendering, texture mapping,
                 splatting, antialiasing",
  volume =       "8",
  number =       "3",
  journal =      "IEEE Transactions on Visualization and Computer
                 Graphics",
}

@Article{EVL-2002-262,
  pages =        "239--254",
  year =         "2002",
  title =        "Terrain Simplification Simplified: {A} General
                 Framework for View-Dependent Out-of-Core
                 Visualization",
  author =       "Peter Lindstrom and Valerio Pascucci",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-262",
  abstract =     "This paper describes a general framework for
                 out-of-core rendering and management of massive terrain
                 surfaces. The two key components of this framework are:
                 view-dependent refinement of the terrain mesh and a
                 simple scheme for organizing the terrain data to
                 improve coherence and reduce the number of paging
                 events from external storage to main memory. Similar to
                 several previously proposed methods for view-dependent
                 refinement, we recursively subdivide a triangle mesh
                 defined over regularly gridded data using longest-edge
                 bisection. As part of this single, per-frame refinement
                 pass, we perform triangle stripping, view frustum
                 culling, and smooth blending of geometry using
                 geomorphing. Meanwhile, our refinement framework
                 supports a large class of error metrics, is highly
                 competitive in terms of rendering performance, and is
                 surprisingly simple to implement. Independent of our
                 refinement algorithm, we also describe several data
                 layout techniques for providing coherent access to the
                 terrain data. By reordering the data in a manner that
                 is more consistent with our recursive access pattern,
                 we show that visualization of gigabyte-size data sets
                 can be realized even on low-end, commodity PCs without
                 the need for complicated and explicit data paging
                 techniques. Rather, by virtue of dramatic improvements
                 in multilevel cache coherence, we rely on the built-in
                 paging mechanisms of the operating system to perform
                 this task. The end result is a straightforward,
                 simple-to-implement, pointerless indexing scheme that
                 dramatically improves the data locality and paging
                 performance over conventional matrix-based layouts.",
  keywords =     "Terrain visualization, surface simplification,
                 view-dependent refinement, continuous levels of detail,
                 edge bisection, error metrics, geomorphing, out-of-core
                 algorithms, external memory paging, data layouts.",
  volume =       "8",
  number =       "3",
  journal =      "IEEE Transactions on Visualization and Computer
                 Graphics",
}

@Article{EVL-2002-263,
  pages =        "286--301",
  year =         "2002",
  title =        "A Hardware-Assisted Scalable Solution for Interactive
                 Volume Rendering of Time-Varying Data",
  author =       "Eric B. Lum and Kwan-Liu Ma and John Clyne",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-263",
  abstract =     "We present a scalable volume rendering technique that
                 exploits lossy compression and low-cost commodity
                 hardware to permit highly interactive exploration of
                 time-varying scalar volume data. A palette-based
                 decoding technique and an adaptive bit allocation
                 scheme are developed to fully utilize the texturing
                 capability of a commodity 3D graphics card. Using a
                 single PC equipped with a modest amount of memory, a
                 texture capable graphics card, and an inexpensive disk
                 array, we are able to render hundreds of time steps of
                 regularly gridded volume data (up to 42 million voxels
                 each time step) at interactive rates. By clustering
                 multiple PCs together, we demonstrate the data-size
                 scalability of our method. The frame rates achieved
                 make possible the interactive exploration of data in
                 the temporal, spatial, and transfer function domains. A
                 comprehensive evaluation of our method based on
                 experimental studies using data sets (up to 134 million
                 voxels per time step) from turbulence flow simulations
                 is also presented.",
  keywords =     "Compression, disk I/O, high performance computing,
                 out-of-core processing, parallel rendering, PC,
                 scalable algorithms, scientific visualization, texture
                 hardware, time-varying data, transform encoding, volume
                 rendering.",
  volume =       "8",
  number =       "3",
  journal =      "IEEE Transactions on Visualization and Computer
                 Graphics",
}

@Article{EVL-2002-264,
  pages =        "255--269",
  year =         "2002",
  title =        "Hierarchical Pixel Bar Charts",
  author =       "Daniel A. Keim and Ming C. Hao and Umeshwar Dayal",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-264",
  abstract =     "Simple presentation graphics are intuitive and
                 easy-to-use, but only show highly aggregated data. Bar
                 charts, for example, only show a rather small number of
                 data values and x-y-plots often have a high degree of
                 overlap. Presentation techniques are often chosen
                 depending on the considered data type--bar charts, for
                 example, are used for categorical data and x-y plots
                 are used for numerical data. In this article, we
                 propose a combination of traditional bar charts and
                 x-y-plots, which allows the visualization of large
                 amounts of data with categorical and numerical data.
                 The categorical data dimensions are used for the
                 partitioning into the bars and the numerical data
                 dimensions are used for the ordering arrangement within
                 the bars. The basic idea is to use the pixels within
                 the bars to present the detailed information of the
                 data records. Our so-called pixel bar charts retain the
                 intuitiveness of traditional bar charts while applying
                 the principle of x-y charts within the bars. In many
                 applications, a natural hierarchy is defined on the
                 categorical data dimensions such as time, region, or
                 product type. In hierarchical pixel bar charts, the
                 hierarchy is exploited to split the bars for selected
                 portions of the hierarchy. Our application to a number
                 of real-world e-business and Web services data sets
                 shows the wide applicability and usefulness of our new
                 idea.",
  keywords =     "Information visualization, multidimensional data
                 visualization, visual data exploration and data mining,
                 very large multiattributes data sets, hierarchical
                 visualization.",
  volume =       "8",
  number =       "3",
  journal =      "IEEE Transactions on Visualization and Computer
                 Graphics",
}

@Article{EVL-2002-265,
  pages =        "270--285",
  year =         "2002",
  title =        "Multidimensional Transfer Functions for Interactive
                 Volume Rendering",
  author =       "Joe Kniss and Gordon Kindlmann and Charles Hansen",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-265",
  abstract =     "Most direct volume renderings produced today employ
                 one-dimensional transfer functions which assign color
                 and opacity to the volume based solely on the single
                 scalar quantity which comprises the data set. Though
                 they have not received widespread attention,
                 multidimensional transfer functions are a very
                 effective way to extract materials and their boundaries
                 for both scalar and multivariate data. However,
                 identifying good transfer functions is difficult enough
                 in one dimension, let alone two or three dimensions.
                 This paper demonstrates an important class of
                 three-dimensional transfer functions for scalar data,
                 and describes the application of multidimensional
                 transfer functions to multivariate data. We present a
                 set of direct manipulation widgets that make specifying
                 such transfer functions intuitive and convenient. We
                 also describe how to use modern graphics hardware to
                 both interactively render with multidimensional
                 transfer functions and to provide interactive shadows
                 for volumes. The transfer functions, widgets, and
                 hardware combine to form a powerful system for
                 interactive volume exploration.",
  keywords =     "Volume visualization, direct volume rendering,
                 multidimensional transfer functions, direct
                 manipulation widgets, graphics hardware.",
  volume =       "8",
  number =       "3",
  journal =      "IEEE Transactions on Visualization and Computer
                 Graphics",
}

@Article{EVL-2002-266,
  pages =        "305--318",
  year =         "2002",
  title =        "hree-Dimensional Interfaces for Querying by Example in
                 Content-Based Image Retrieval",
  author =       "J{\"{u}}rgen Assfalg and Alberto Del Bimbo and Pietro
                 Pala",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-266",
  abstract =     "Image databases are nowadays widely exploited in a
                 number of different contexts, ranging from history of
                 art, through medicine, to education. Existing querying
                 paradigms are based either on the usage of textual
                 strings, for high-level semantic queries or on 2D
                 visual examples for the expression of perceptual
                 queries. Semantic queries require manual annotation of
                 the database images. Instead, perceptual queries only
                 require that image analysis is performed on the
                 database images in order to extract salient perceptual
                 features that are matched with those of the example.
                 However, usage of 2D examples is generally inadequate
                 as effective authoring of query images, attaining a
                 realistic reproduction of complex scenes, needs manual
                 editing and sketching ability. Investigation of new
                 querying paradigms is therefore an important-yet still
                 marginally investigated-factor for the success of
                 content-based image retrieval. In this paper, a novel
                 querying paradigm is presented which is based on usage
                 of 3D interfaces exploiting navigation and editing of
                 3D virtual environments. Query images are obtained by
                 taking a snapshot of the framed environment and by
                 using the snapshot as an example to retrieve similar
                 database images. A comparative analysis is carried out
                 between the usage of 3D and 2D interfaces and their
                 related query paradigms. This analysis develops on a
                 user test on retrieval efficiency and effectiveness, as
                 well as on an evaluation of users' satisfaction.",
  keywords =     "Content-based image retrieval, 3D user interfaces.",
  volume =       "8",
  number =       "4",
  journal =      "IEEE Transactions on Visualization and Computer
                 Graphics",
}

@Article{EVL-2002-267,
  pages =        "319--329",
  year =         "2002",
  title =        "Interactive Visualization of State Transition
                 Systems",
  author =       "Frank van Ham and Huub van de Wetering and Jarke J.
                 van Wijk",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-267",
  abstract =     "A new method for the visualization of state transition
                 systems is presented. Visual information is reduced by
                 clustering nodes, forming a tree structure of related
                 clusters. This structure is visualized in three
                 dimensions with concepts from cone trees and emphasis
                 on symmetry. A number of interactive options are
                 provided as well, allowing the user to superimpose
                 detail information on this tree structure. The
                 resulting visualization enables the user to relate
                 features in the visualization of the state transition
                 graph to semantic concepts in the corresponding process
                 and vice versa.",
  keywords =     "Graph visualization, transition systems, state spaces,
                 cone tree",
  volume =       "8",
  number =       "4",
  journal =      "IEEE Transactions on Visualization and Computer
                 Graphics",
}

@Article{EVL-2002-268,
  pages =        "330--345",
  year =         "2002",
  title =        "Stereoscopic View-Dependent Visualization of Terrain
                 Height Fields",
  author =       "Ugur G{\"{u}}d{\"{u}}kbay and T{\"{u}}rker Yilmaz",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-268",
  abstract =     "Visualization of large geometric environments has
                 always been an important problem of computer graphics.
                 In this paper, we present a framework for the
                 stereoscopic view-dependent visualization of large
                 scale terrain models. We use a quadtree based
                 multiresolution representation for the terrain data.
                 This structure is queried to obtain the view-dependent
                 approximations of the terrain model at different levels
                 of detail. In order not to lose depth information,
                 which is crucial for the stereoscopic visualization, we
                 make use of a different simplification criterion,
                 namely, distance-based angular error threshold. We also
                 present an algorithm for the construction of stereo
                 pairs in order to speed up the view-dependent
                 stereoscopic visualization. The approach we use is the
                 simultaneous generation of the triangles for two stereo
                 images using a single draw-list so that the view
                 frustum culling and vertex activation is done only once
                 for each frame. The cracking problem is solved using
                 the dependency information stored for each vertex. We
                 eliminate the popping artifacts that can occur while
                 switching between different resolutions of the data
                 using morphing. We implemented the proposed algorithms
                 on personal computers and graphics workstations.
                 Performance experiments show that the second eye image
                 can be produced approximately 45 percent faster than
                 drawing the two images separately and a smooth
                 stereoscopic visualization can be achieved at
                 interactive frame rates using continuous
                 multiresolution representation of height fields.",
  volume =       "8(4)",
  keywords =     "Stereoscopic visualization, terrain height fields,
                 multiresolution rendering, quadtrees.",
  journal =      "IEEE Transactions on Visualization and Computer
                 Graphics",
}

@Article{EVL-2002-269,
  pages =        "346--359",
  year =         "2002",
  title =        "Robust Creation of Implicit Surfaces from Polygonal
                 Meshes",
  author =       "Gary Yngve and Greg Turk",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-269",
  abstract =     "Implicit surfaces are used for a number of tasks in
                 computer graphics, including modeling soft or organic
                 objects, morphing, collision detection, and
                 constructive solid geometry. Although operating on
                 implicit surfaces is usually straightforward, creating
                 them is not. We introduce a practical method for
                 creating implicit surfaces from polygonal models that
                 produces high-quality results for complex surfaces.
                 Whereas much previous work in implicit surfaces has
                 been done with primitives such as {"}blobbies,{"} we
                 use implicit surfaces based on a variational
                 interpolation technique (the three-dimensional
                 generalization of thin-plate interpolation). Given a
                 polygonal mesh, we convert the data to a volumetric
                 representation to use as a guide for creating the
                 implicit surface iteratively. We begin by seeding the
                 surface with a number of constraint points through
                 which the surface must pass. Iteratively, additional
                 constraints are added; the resulting surfaces are
                 evaluated, and the errors guide the placement of
                 subsequent constraints. We have applied our method
                 successfully to a variety of polygonal meshes and
                 consider it to be robust.",
  keywords =     "Geometric modeling, surface representations, implicit
                 surfaces.",
  volume =       "8",
  number =       "4",
  journal =      "IEEE Transactions on Visualization and Computer
                 Graphics",
}

@InProceedings{EVL-2002-27,
  year =         "2002",
  title =        "Speech Synchronization for Physics-Based Facial
                 Animation",
  author =       "I. Albrecht and J. Haber and H.-P. Seidel",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-27",
  abstract =     "We present a method for generating realistic
                 speech-synchronized facial animations using a
                 physics-based approach and support for coarticulation,
                 i.e. the coloring of a speech segment by surrounding
                 segments. We have implemented several extensions to the
                 original coarticulation algorithm of Cohen and Massaro
                 (M. M. Cohen, D. W. Massaro. Modeling Coarticulation in
                 Synthetic Visual Speech. In Models and Techniques in
                 Computer Animation., pages 139-156. Springer Verlag,
                 Tokyo, 1993). The enhancements include an optimization
                 to improve performance as well as special treatment of
                 closure and release phases of bilabial stops and other
                 phonemes. Furthermore, for phonemes that are shorter
                 than the sampling intervals of the algorithm and might
                 therefore be missed, additional key frames are created
                 to ensure their impact onto the animation.",
  editor =       "V. Skala",
  keywords =     "Facial animation, lip sync, coarticulation",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@Article{EVL-2002-270,
  pages =        "360--372",
  year =         "2002",
  title =        "Adding Support for High-Level Skeletal Animation",
  author =       "Francisco J. Sero and and Rafael Rodriguez and Eva
                 Cerezo and Alfredo Pina",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-270",
  abstract =     "We hereby present a data structure specially geared
                 toward the definition and management of synthetic
                 actors in real-time computer graphics. The relation
                 between our proposed data structure and the Silicon
                 Graphics API Performer makes its implementation
                 possible on a low-cost real-time platform thanks to
                 current accelerating cards. We demonstrate how our data
                 structure is used to generate motion by means of two
                 different applications. Both of them make use of direct
                 (DK) and inverse kinematics (IK) and may use motion
                 capture. ARTgraph is a development environment devoted
                 to the creation of high-quality real-time 3D-graphics
                 applications (basically, 3D games) and the ALVW system
                 is a general platform that provides and coordinates a
                 sensing-analysis-acting loop to provide behavior for
                 synthetic actors in their own scenario. The aim of this
                 paper is to contribute to the standardization process
                 of multiplatform synthetic actor programs or
                 libraries.",
  keywords =     "Synthetic actors, real-time, computer animation,
                 Performer, API.",
  volume =       "8",
  number =       "4",
  journal =      "IEEE Transactions on Visualization and Computer
                 Graphics",
}

@Article{EVL-2002-271,
  pages =        "373--382",
  year =         "2002",
  title =        "Vertex Data Compression through Vector Quantization",
  author =       "Peter H. Chou and Teresa H. Meng",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-271",
  abstract =     "Rendering geometrically detailed 3D models requires
                 the transfer and processing of large amounts of
                 triangle and vertex geometry data. Compressing the
                 geometry bitstream can reduce bandwidth requirements
                 and alleviate transmission bottlenecks. In this paper,
                 we show vector quantization to be an effective
                 compression technique for triangle mesh vertex data. We
                 present predictive vector quantization methods using
                 unstructured codebooks as well as a product code
                 pyramid vector quantizer. The technique is compatible
                 with most existing mesh connectivity encoding schemes
                 and does not require the use of entropy coding. In
                 addition to compression, our vector quantization scheme
                 can be used for complexity reduction by accelerating
                 the computation of linear vertex transformations.
                 Consequently, an encoded set of vertices can be both
                 decoded and transformed in approximately 60 percent of
                 the time required by a conventional method without
                 compression.",
  keywords =     "Computer graphics, data compression, geometry
                 compression, vector quantization.",
  volume =       "8",
  number =       "4",
  journal =      "IEEE Transactions on Visualization and Computer
                 Graphics",
}

@Article{EVL-2002-272,
  pages =        "383--394",
  year =         "2002",
  title =        "Dynamic Particle Coating",
  author =       "Arash Habibi and Annie Luciani",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-272",
  abstract =     "Physically-based particle models are used by an
                 increasing community of computer graphics researchers
                 and users in order to produce a large variety of
                 dynamic motions. Among all of the methods dedicated to
                 the coating of point models, the implicit surface
                 method has proven to be one of the most powerful.
                 However, for the visualization of a wide variety of
                 objects ranging from smoke to solids, the
                 time-independent coating of traditional implicit
                 surfaces appears to be dynamically too poor and
                 restrictive. We propose a generalization of classic
                 implicit surfaces able to produce a larger variety of
                 particle coatings, from rigid solids to highly
                 deformable objects and even wave propagation and fluid
                 flow coatings, thus handling all these disparate
                 categories with the same paradigm. The method consists
                 of extracting the coating from a field function which
                 is not predetermined but calculated as the modulation
                 of a dynamic discrete medium by particles. For these
                 reasons, the coating behaviors present higher-order
                 dynamic behaviors closely correlated with the dynamics
                 of skeleton particles.",
  keywords =     "Shape modeling, computer animation, physically-based
                 modeling, particle modeling, implicit surfaces,
                 visualization.",
  volume =       "8",
  number =       "4",
  journal =      "IEEE Transactions on Visualization and Computer
                 Graphics",
}

@InProceedings{EVL-2002-273,
  year =         "2002",
  title =        "Artificial Animals and Humans: From Physics to
                 Intelligence",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-273",
  author =       "Demetri Terzopoulos",
  abstract =     "he confluence of virtual reality and artificial life,
                 an emerging discipline that spans the computational and
                 biological sciences, has yielded synthetic worlds
                 inhabited by realistic, artificial flora and fauna.
                 Artificial animals are complex synthetic organisms that
                 possess functional biomechanical bodies, sensors, and
                 brains with locomotion, perception, behavior, learning,
                 and cognition centers. Artificial humans and other
                 animals are of interest in computer graphics because
                 they are self-animating characters that dramatically
                 advance the state of the art of production animation
                 and interactive game technologies. More broadly, these
                 biomimetic autonomous agents in their realistic virtual
                 worlds also foster deeper, computationally oriented
                 insights into natural living systems.",
  organization = "European Association for Computer Graphics",
  editor =       "David Duke and Roberto Scopigno",
  volume =       "21(3)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing",
}

@InProceedings{EVL-2002-274,
  year =         "2002",
  title =        "Interactive Visualization with Programmable Graphics
                 Hardware",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-274",
  author =       "Thomas Ertl",
  abstract =     "One of the main scientific goals of visualization is
                 the development of algorithms and appropriate data
                 models which facilitate interactive visual analysis and
                 direct manipulation of the increasingly large data sets
                 which result from simulations running on massive
                 parallel computer systems, from measurements employing
                 fast high-resolution sensors, or from large databases
                 and hierarchical information spaces. This task can only
                 be achieved with the optimization of all stages of the
                 visualization pipeline: filtering, compression, and
                 feature extraction of the raw data sets, adaptive
                 visualization mappings which allow the users to choose
                 between speed and accuracy, and exploiting new graphics
                 hardware features for fast and high-quality rendering.
                 The recent introduction of advanced programmability in
                 widely available graphics hardware has already led to
                 impressive progress in the area of volume
                 visualization. However, besides the acceleration of the
                 final rendering, flexible graphics hardware is
                 increasingly being used also for the mapping and
                 filtering stages of the visualization pipeline, thus
                 giving rise to new levels of interactivity in
                 visualization applications. The talk will present
                 recent results of applying programmable graphics
                 hardware in various visualization algorithms covering
                 volume data, flow data, terrains, NPR rendering, and
                 distributed and remote applications.",
  editor =       "David Duke and Roberto Scopigno",
  volume =       "21(3)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing",
}

@InProceedings{EVL-2002-275,
  pages =        "209--218",
  year =         "2002",
  title =        "Intrinsic Parameterizations of Surface Meshes",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-275",
  author =       "Mathieu Desbrun and Mark Meyer and Pierre Alliez",
  abstract =     "Parameterization of discrete surfaces is a fundamental
                 and widely-used operation in graphics, required, for
                 instance, for texture mapping or remeshing. As 3D data
                 becomes more and more detailed, there is an increased
                 need for fast and robust techniques to automatically
                 compute least-distorted parameterizations of large
                 meshes. In this paper, we present new theoretical and
                 practical results on the parameterization of
                 triangulated surface patches. Given a few desirable
                 properties such as rotation and translation invariance,
                 we show that the only admissible parameterizations form
                 a two-dimensional set and each parameterization in this
                 set can be computed using a simple, sparse, linear
                 system. Since these parameterizations minimize the
                 distortion of different intrinsic measures of the
                 original mesh, we call them Intrinsic
                 Parameterizations. In addition to this partial
                 theoretical analysis, we propose robust, efficient and
                 tunable tools to obtain least-distorted
                 parameterizations automatically. In particular, we give
                 details on a novel, fast technique to provide an
                 optimal mapping without fixing the boundary positions,
                 thus providing a unique Natural Intrinsic
                 Parameterization. Other techniques based on this
                 parameterization family, designed to ease the rapid
                 design of parameterizations, are also proposed.",
  organization = "European Association for Computer Graphics",
  editor =       "David Duke and Roberto Scopigno",
  volume =       "21(3)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing",
}

@InProceedings{EVL-2002-276,
  pages =        "219--228",
  year =         "2002",
  title =        "Metamorphosis of Polyhedral Surfaces using
                 Decomposition",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-276",
  author =       "Shymon Shlafman and Ayellet Tal and Sagi Katz",
  abstract =     "This paper describes an algorithm for morphing
                 polyhedral surfaces based on their decompositions into
                 patches. The given surfaces need neither be genus-zero
                 nor two-manifolds. We present a new algorithm for
                 decomposing surfaces into patches. We also present a
                 new projection scheme that handles topologically
                 cylinder-like polyhedral surfaces. We show how these
                 two new techniques can be used within a general
                 framework and result with morph sequences that maintain
                 the distinctive features of the input models.",
  organization = "European Association for Computer Graphics",
  editor =       "David Duke and Roberto Scopigno",
  volume =       "21(3)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing",
}

@InProceedings{EVL-2002-277,
  pages =        "229--238",
  year =         "2002",
  title =        "Geometric Snakes for Triangular Meshes",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-277",
  author =       "Yunjin Lee and Seungyong Lee",
  abstract =     "Feature detection is important in various mesh
                 processing techniques, such as mesh editing, mesh
                 morphing, mesh compression, and mesh signal processing.
                 In spite of much research in computer vision, automatic
                 feature detection even for images still remains a
                 difficult problem. To avoid this difficulty,
                 semi-automatic or interactive techniques for image
                 feature detection have been investigated. In this
                 paper, we propose a geometric snake as an interactive
                 tool for feature detection on a 3D triangular mesh. A
                 geometric snake is an extension of an image snake,
                 which is an active contour model that slithers from its
                 initial position specified by the user to a nearby
                 feature while minimizing an energy functional. To
                 constrain the movement of a geometric snake onto the
                 surface of a mesh, we use the parameterization of the
                 surrounding region of a geometric snake. Although the
                 definition of a feature may vary among applications, we
                 use the normal changes of faces to detect features on a
                 mesh. Experimental results demonstrate that geometric
                 snakes can successfully capture nearby features from
                 user-specified initial positions.",
  organization = "European Association for Computer Graphics",
  editor =       "David Duke and Roberto Scopigno",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing",
}

@InProceedings{EVL-2002-278,
  pages =        "239--248",
  year =         "2002",
  title =        "Flattening 3{D} objects using silhouettes",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-278",
  author =       "D. Mart{\'{i}}n and J. D. Fekete and J. C. Torres",
  abstract =     "An important research area in non-photorealistic
                 rendering is the obtention of silhouettes. There are
                 many methods to do this using 3D models and raster
                 structures, but these are limited in their ability to
                 create stylised silhouettes while maintaining complete
                 flexibility. These limitations do not exist in
                 illustration, as each element is plane and the
                 interaction between them can be eliminated by locating
                 each one in a different layer. This is the approach
                 presented in this paper: a 3D model is flattened into
                 plane elements ordered in space, which allows the
                 silhouettes to be drawn with total flexibility",
  organization = "European Association for Computer Graphics",
  editor =       "David Duke and Roberto Scopigno",
  volume =       "21(3)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing",
}

@InProceedings{EVL-2002-279,
  pages =        "249--258",
  year =         "2002",
  title =        "Stylizing Silhouettes at Interactive Rates: From
                 Silhouette Edges to Silhouette Strokes",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-279",
  author =       "Tobias Isenberg and Nick Halper and Thomas
                 Strothotte",
  abstract =     "A way to create effective stylized line drawings is to
                 draw strokes that start and stop at visible portions
                 along the silhouette of an object to be portrayed. In
                 computer graphics to date, algorithms to extract
                 silhouette edges are many, although putting these edges
                 into a form such that stylized strokes may be applied
                 to them has not been greatly covered, so that existing
                 methods are either time-consuming or presented vaguely.
                 In this paper, we introduce an algorithm that takes a
                 set of silhouette edges originating from polygonal
                 meshes and efficiently computes the visible parts of
                 the edges before connecting them to form long smooth
                 silhouette strokes to which stylization algorithms may
                 be effectively applied. Features of our algorithm that
                 gain efficiency and accuracy over existing methods is
                 that we directly exploit the analytic connectivity
                 information of the mesh in combination with the
                 available z-buffer information during rendering, and
                 filter artifacts in connected edges during the process
                 to improve the visual quality of strokes after
                 stylization",
  organization = "European Association for Computer Graphics",
  editor =       "David Duke and Roberto Scopigno",
  volume =       "21(3)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing",
}

@InProceedings{EVL-2002-28,
  year =         "2002",
  title =        "{MLSL}ib: {A} Lip Sync Library for Multi Agents and
                 Languages",
  author =       "H. Murakami and H. Baba and T. Noma",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-28",
  abstract =     "This article presents MLSLib, a software library for
                 human figure animation with lip syncing. The library
                 enables us to easily use multiple TTSs and multiple lip
                 motion generators, and switch them arbitrarily. It also
                 helps use of multiple speaking agents, possibly with
                 different TTSs and lip motion generators. The MLSLib is
                 composed of three modules: LSSAgent, TTSManager, and
                 FCPManager; The LSSAgent module provides unified simple
                 APIs per single agent, independent of TTSs and lip
                 motion generators. The TTSManager and FCPManager manage
                 TTSs and lip motion generators, respectively. Both
                 modules support standard sets of phonetic alphabets per
                 language, and thus users are freed from TTS-dependent
                 implementation of lip motion generators. Applications
                 to multi-lingual agents and LOD in lip syncing are also
                 presented.",
  editor =       "V. Skala",
  keywords =     "Lip Sync, human figure animation, figure animation,
                 TTS, LOD, MLSLib",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-280,
  pages =        "259--568",
  year =         "2002",
  title =        "Modeling Surperspective Projection of Landscapes for
                 Geographical Guide-Map Generation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-280",
  author =       "Shigeo Takahashi and Naoya Ohta and Hiroko Nakamura
                 and Yuriko Takeshima and Issei Fujishiro",
  abstract =     "It is still challenging to generate hand-drawn
                 pictures because they differ from ordinary photographs
                 in that they are often drawn as seen from multiple
                 viewpoints. This paper presents a new approach for
                 modeling such surperspective projection based on shape
                 deformation techniques. Specifically, surperspective
                 landscape images for guide-maps are generated from 3D
                 geographical elevation data. Our method first
                 partitions a target geographical surface into feature
                 areas to provide designers with landmarks suitable for
                 editing. The system takes as input 2D visual effects,
                 which are converted to 3D geometric constraints for
                 geographical surface deformation. Using ordinary
                 perspective projection, the deformed shape is then
                 transformed into a target guide-map image where each
                 landmark enjoys its own vista points. An algorithm for
                 calculating such 2D visual effects semi-automatically
                 from the geographical shape features is also
                 considered.",
  organization = "European Association for Computer Graphics",
  editor =       "David Duke and Roberto Scopigno",
  volume =       "21(3)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing",
}

@InProceedings{EVL-2002-281,
  pages =        "269--278",
  year =         "2002",
  title =        "Deferred, Self-Organizing {BSP} Trees",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-281",
  author =       "Sigal Arand Gil Montag and Ayellet Tal",
  abstract =     "BSP trees and KD trees are fundamental data structures
                 for collision detection in walkthrough environments. A
                 basic issue in the construction of these hierarchical
                 data structures is the choice of cutting planes. Rather
                 than base these choices solely on the properties of the
                 scene, we propose using information about how the tree
                 is used in order to determine its structure. We
                 demonstrate how this leads to the creation of BSP trees
                 that are small, do not require much preprocessing time,
                 and respond very efficiently to sequences of collision
                 queries.",
  organization = "European Association for Computer Graphics",
  editor =       "David Duke and Roberto Scopigno",
  volume =       "21(3)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing",
}

@InProceedings{EVL-2002-282,
  pages =        "279--288",
  year =         "2002",
  title =        "Fast Continuous Collision Detection between Rigid
                 Bodies",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-282",
  abstract =     "This paper introduces a fast continuous collision
                 detection technique for polyhedral rigid bodies. As
                 opposed to most collision detection techniques, the
                 computation of the first contact time between two
                 objects is inherently part of the algorithm. The method
                 can thus robustly prevent objects interpenetrations or
                 collisions misses, even when objects are thin or have
                 large velocities. The method is valid for general
                 objects (polygon soups), handles multiple moving
                 objects and acyclic articulated bodies, and is
                 efficient in low and high coherency situations.
                 Moreover, the method can be used to speed up existent
                 continuous collision detection methods for parametric
                 or implicit rigid surfaces. The collision detection
                 algorithms have been successfully coupled to a
                 real-time dynamics simulator. Various experiments are
                 conducted that show the method's ability to produce
                 high-quality interaction (precise objects positioning
                 for example) between models up to tens of thousands of
                 triangles, which couldn't have been performed with
                 previous continuous methods.",
  organization = "European Association for Computer Graphics",
  editor =       "David Duke and Roberto Scopigno",
  volume =       "21(3)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing",
}

@InProceedings{EVL-2002-283,
  pages =        "289--298",
  year =         "2002",
  title =        "Virtual Visual Servoing: a framework for real-time
                 augmented reality",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-283",
  author =       "{\'{E}}ric Marchand and Fran{\c{c}}ois Chaumette",
  abstract =     "This paper presents a framework to achieve real-time
                 augmented reality applications. We propose a framework
                 based on the visual servoing approach well known in
                 robotics. We consider pose or viewpoint computation as
                 a similar problem to visual servoing. It allows one to
                 take advantage of all the research that has been
                 carried out in this domain in the past. The proposed
                 method features simplicity, accuracy, efficiency, and
                 scalability wrt. to the camera model as well as wrt.
                 the features extracted from the image. We illustrate
                 the efficiency of our approach on augmented reality
                 applications with various real image sequences.",
  organization = "European Association for Computer Graphics",
  editor =       "David Duke and Roberto Scopigno",
  volume =       "21(3)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing",
}

@InProceedings{EVL-2002-284,
  pages =        "299--308",
  year =         "2002",
  title =        "A Solid Model Based Virtual Hairy Brush",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-284",
  author =       "Songhua Xu and Min Tang and Francis Lau and Yunhe
                 Pan",
  abstract =     "We present the detailed modeling of the hairy brush
                 used typically in Chinese calligraphy. The complex
                 model, which includes also a model for the ink and the
                 paper, covers the various stages of the brush going
                 through a calligraphy process. The model relies on the
                 concept of writing primitives, which are the smallest
                 units of hair clusters, to reduce the load on the
                 simulation. Each such primitive is constructed through
                 the general sweeping operation in CAD and described by
                 a NURBS surface. The writing primitives dynamically
                 adjust themselves during the virtual writing process,
                 leaving an imprint on the virtual paper as they move.
                 The behavior of the brush is an aggregation of the
                 behavior of all the writing primitives. A software
                 system based on the model has been built and tested.
                 Samples of imitation artwork from using the system were
                 obtained and found to be nearly indistinguishable from
                 the real artwork.",
  organization = "European Association for Computer Graphics",
  editor =       "David Duke and Roberto Scopigno",
  volume =       "21(3)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing",
}

@InProceedings{EVL-2002-285,
  pages =        "309--316",
  year =         "2002",
  title =        "Geometric Approximations Towards Free Specular Comic
                 Shading",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-285",
  author =       "Holger Winnem{\"{o}}ller and Shaun Bangay",
  abstract =     "We extend the standard solution to comic rendering
                 with a comic-style specular component. To minimize the
                 computational overhead associated with this extension,
                 we introduce two optimising approximations; the
                 perspective correction angle and the vertex
                 face-orientation measure. Both of these optimisations
                 are generally applicable, but they are especially well
                 suited for applications where a physically correct
                 lighting simulation is not required. Using our
                 optimisations we achieve performances comparable to the
                 standard solution. As our approximations favour large
                 models, we even outperform the standard approach for
                 models consisting of 10,000 triangles or more, which we
                 can render exceeding 40 frames per second, including
                 the specular component.",
  organization = "European Association for Computer Graphics",
  editor =       "David Duke and Roberto Scopigno",
  volume =       "21(3)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing",
}

@InProceedings{EVL-2002-286,
  pages =        "317--326",
  year =         "2002",
  title =        "Transparency in Interactive Technical Illustrations",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-286",
  author =       "Joachim Diepstraten and Daniel Weiskopf and Thomas
                 Ertl",
  abstract =     "This paper describes how technical illustrations
                 containing opaque and non-opaque objects can be
                 automatically generated. Traditional methods to show
                 transparency in manual drawings are evaluated to
                 extract a small and effective set of rules for
                 computer-based rendering of technical illustrations,
                 leading to a novel view-dependent transparency model.
                 We propose a hardware-accelerated depth sorting
                 algorithm in image-space which specifically meets the
                 requirements of our transparency model. In this way,
                 real-time rendering of semi-transparent technical
                 illustrations is achieved. Finally, it is described how
                 our approach can be combined with other methods in the
                 field of non-photorealistic rendering in order to
                 enhance the visual perception of technical
                 illustrations.",
  organization = "European Association for Computer Graphics",
  editor =       "David Duke and Roberto Scopigno",
  volume =       "21(3)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing",
}

@InProceedings{EVL-2002-287,
  pages =        "327--328",
  year =         "2002",
  title =        "Real-time Animation of Dressed Virtual Human",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-287",
  author =       "Frederic Cordier and Nadia Magnenat-Thalmann",
  abstract =     "In this paper, we describe a method for cloth
                 animation in real-time. The algorithm works in a hybrid
                 manner exploiting the merits of both the physical-based
                 and geometric deformations. It makes use of
                 predetermined conditions between the cloth and the body
                 model, avoiding complex collision detection and
                 physical deformations wherever possible. Garments are
                 segmented into pieces that are simulated by various
                 algorithms, depending on how they are laid on the body
                 surface and whether they stick or flow on it. Tests
                 show that the method is well suited to fully dressed
                 virtual human models, achieving real-time performance
                 compared to ordinary cloth-simulations",
  organization = "European Association for Computer Graphics",
  editor =       "David Duke and Roberto Scopigno",
  volume =       "21(3)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing",
}

@InProceedings{EVL-2002-288,
  pages =        "337--346",
  year =         "2002",
  title =        "Local Physical Models for Interactive Character
                 Animation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-288",
  author =       "Sageev Oore and Demetri Terzopoulos and Geoffrey
                 Hinton",
  abstract =     "Our goal is to design and build a tool for the
                 creation of expressive character animation. Virtual
                 puppetry, also known as performance animation, is a
                 technique in which the user interactively controls a
                 character's motion. In this paper we introduce local
                 physical models for performance animation and describe
                 how they can augment an existing kinematic method to
                 achieve very effective animation control. These models
                 approximate specific physically-generated aspects of a
                 character's motion. They automate certain behaviours,
                 while still letting the user override such motion via a
                 PD-controller if he so desires. Furthermore, they can
                 be tuned to ignore certain undesirable effects, such as
                 the risk of having a character fall over, by ignoring
                 corresponding components of the force. Although local
                 physical models are a quite simple approximation to
                 real physical behaviour, we show that they are
                 extremely useful for interactive character control, and
                 contribute positively to the expressiveness of the
                 character's motion. In this paper, we develop such
                 models at the knees and ankles of an
                 interactively-animated 3D anthropomorphic character,
                 and demonstrate a resulting animation. This approach
                 can be applied in a straightforward way to other
                 joints",
  organization = "European Association for Computer Graphics",
  editor =       "David Duke and Roberto Scopigno",
  volume =       "21(3)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing",
}

@InProceedings{EVL-2002-289,
  pages =        "347--352",
  year =         "2002",
  title =        "{STRANDS}: Interactive Simulation of Thin Solids using
                 Cosserat Models",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-289",
  author =       "Dinesh K. Pai",
  abstract =     "STRANDS are thin elastic solids that are visually well
                 approximated as smooth curves, and yet possess
                 essential physical behaviors characteristic of solid
                 objects such as twisting. Common examples in computer
                 graphics include: sutures, catheters, and tendons in
                 surgical simulation; hairs, ropes, and vegetation in
                 animation. Physical models based on spring meshes or 3D
                 finite elements for such thin solids are either
                 inaccurate or inefficient for interactive simulation.
                 In this paper we show that models based on the Cosserat
                 theory of elastic rods are very well suited for
                 interactive simulation of these objects. The physical
                 model reduces to a system of spatial ordinary
                 differential equations that can be solved efficiently
                 for typical boundary conditions. The model handles the
                 important geometric non-linearity due to large changes
                 in shape. We introduce Cosserat-type physical models,
                 describe efficient numerical methods for interactive
                 simulation of these models, and implementation
                 results",
  organization = "European Association for Computer Graphics",
  editor =       "David Duke and Roberto Scopigno",
  volume =       "21(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2002
                 Proceedings)",
  publisher =    "Blackwell Publishing",
}

@InProceedings{EVL-2002-29,
  year =         "2002",
  title =        "Shadow Volumes Revisited",
  author =       "S. Roettger and A. Irion and T. Ertl",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-29",
  abstract =     "We present a method to utilize the Shadow Volume
                 Algorithm by Crow and Williams without using a stencil
                 buffer. We show that the shadow mask can be generated
                 in the alpha channel or even in the screen buffer, if a
                 hardware accelerated stencil buffer is not available.
                 In comparison to the original stencil buffer method, a
                 small speed up can be achieved, if the shadow mask is
                 computed in the alpha buffer. The method using the
                 screen buffer requires the scene to be rendered a
                 second time after the shadow mask has been computed.
                 Both methods are less restrictive with respect to
                 hardware requirements, since we use only standard color
                 blending and depth testing. In general, rasterization
                 bandwidth is the main bottle neck when generating the
                 shadow mask at high screen resolutions. In order to
                 overcome this bottle neck we propose a way to compute
                 the shadow mask at a resolution that is lower than the
                 resolution of the screen buffer. Then the shadow mask
                 is applied to the scene by utilizing texture mapping.
                 The latter method might be reasonable especially in
                 interactive entertainment, where rendering speed is
                 traded in favour of image quality.",
  editor =       "V. Skala",
  keywords =     "Shadow Volumes, Hardware-Accelerated Rendering,
                 Interactive Entertainment",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-290,
  pages =        "353--362",
  year =         "2002",
  title =        "Efficient Fitting and Rendering of Large Scattered
                 Data Sets Using Subdivision Surfaces",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-290",
  author =       "Vincent Scheib and J{\"{o}}rg Haber and Ming C. Lin
                 and Hans-Peter Seidel",
  abstract =     "We present a method to efficiently construct and
                 render a smooth surface for approximation of large
                 functional scattered data. Using a subdivision surface
                 framework and techniques from terrain rendering, the
                 resulting surface can be explored from any viewpoint
                 while maintaining high surface fairness and interactive
                 frame rates. We show the approximation error to be
                 sufficiently small for several large data sets. Our
                 system allows for adaptive simplification and provides
                 continuous levels of detail, taking into account the
                 local variation and distribution of the data.",
  organization = "European Association for Computer Graphics",
  editor =       "David Duke and Roberto Scopigno",
  volume =       "21(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2002
                 Proceedings)",
  publisher =    "Blackwell Publishing",
}

@InCollection{EVL-2002-291,
  title =        "Feature Model Visualization",
  address =      "Oxford, UK and Boston, USA",
  month =        nov,
  editor =       "David Duke and Roberto Scopigno",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing Inc",
  pages =        "661--673",
  year =         "2002",
  author =       "Willem F. Bronsvoort and Rafael Bidarra and Alex
                 Noort",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-291",
  abstract =     "Feature modelling is now the predominant way of
                 modelling products. Feature visualization is an
                 important aspect here that can still be considerably
                 improved. In this paper, an integrated way of
                 visualizing feature models is presented, using new
                 techniques for both the geometry and the structure of
                 models. For the geometry of feature models, techniques
                 are presented to visualize a selected subset of form
                 features in a way that clearly distinguishes them from
                 the rest of the model, as well as functional
                 information such as closure faces of subtractive form
                 features. For the structure of features models,
                 techniques are presented to visualize several types of
                 graphs. The different visualization techniques are used
                 in an integrated way. Implementation of some of the
                 techniques requires a non-manifold representation of
                 the geometry of the feature model. This representation,
                 and some other implementation aspects, are briefly
                 described. Throughout the paper, numerous examples of
                 images of feature models are given which show that the
                 new visualization techniques can indeed improve the
                 effectiveness of feature modelling.",
  volume =       "21(4)",
}

@InCollection{EVL-2002-292,
  title =        "Vortex Tracking and Visualisation in a Flow Past a
                 Tapered Cylinder",
  address =      "Oxford, UK and Boston, USA",
  month =        nov,
  editor =       "David Duke and Roberto Scopigno",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing Inc",
  pages =        "675--682",
  year =         "2002",
  author =       "Freek Reinders and I. Ari Sadarjoen and Benjamin
                 Vrolijk and Frits H. Post",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-292",
  abstract =     "In this paper we explore a novel combined application
                 of two of our existing visualisation techniques to the
                 tracking of 3D vortex tubes in an unsteady flow. The
                 applied techniques are the winding-angle vortex
                 extraction technique based on streamline geometry, and
                 the attribute-based feature tracking technique. We have
                 applied these to the well-known case of an unsteady 3D
                 flow past a tapered cylinder. First, 2D vortices are
                 detected in a number of horizontal slices for each time
                 step, by means of the winding-angle vortex extraction
                 method. For each 2D vortex a number of attributes are
                 calculated and stored. These vortices are visualised by
                 a special type of ellipse icons, showing the position,
                 shape and rotational direction and speed in each slice.
                 Next, for each time step, 3D vortex tubes are
                 constructed from the 2D vortices by applying the
                 feature tracking procedure in a spatial dimension to
                 connect the corresponding vortices in adjacent slices.
                 The result is a graph attribute set with the 2D vortex
                 attributes in the nodes and the spatial correspondences
                 as edges. Finally, the 3D vortex tubes are tracked in
                 time using the same tracking procedure, for finding the
                 corresponding tubes in successive time steps. The
                 result is a description of the evolution of the 3D
                 vortices. An interactive, timedependent visualisation
                 is generated using the temporal correspondences of each
                 vortex tube. This analysis reveals a number of
                 interesting patterns.",
  volume =       "21(4)",
}

@InCollection{EVL-2002-293,
  title =        "An Algorithm for Line Clipping Against a Polygon Based
                 on Shearing Transformation",
  address =      "Oxford, UK and Boston, USA",
  month =        nov,
  editor =       "David Duke and Roberto Scopigno",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing Inc",
  pages =        "683--688",
  year =         "2002",
  author =       "Y. Q. Huang and Y. K. Liu",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-293",
  abstract =     "Line clipping against a polygon is widely used in
                 computer graphics such as the hidden line problem. A
                 new line-clipping algorithm against a general polygon
                 is presented in this paper. The basic idea of this
                 algorithm is to change the line to be clipped into a
                 horizontal line by shearing transformation. Then each
                 edge of the polygonal window is transformed by a
                 shearing transformation with the same parameters as
                 those used to the line. Each edge of the polygon is
                 processed against a horizontal line, which makes the
                 clipping process simpler. The result in this paper
                 shows that less calculation is needed for the new
                 algorithm with a higher speed compared to existing
                 algorithms.",
  keywords =     "Computer graphics, concave window, line clipping,
                 shearing transformation, intersection calculation",
  volume =       "21(4)",
}

@InCollection{EVL-2002-294,
  title =        "A Skeleton-based Approach for Detection of
                 Perceptually Salient Features on Polygonal Surfaces",
  address =      "Oxford, UK and Boston, USA",
  month =        nov,
  editor =       "David Duke and Roberto Scopigno",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing Inc",
  pages =        "689--700",
  year =         "2002",
  author =       "Masayuki Hisada and Alexander G. Belyaev and Tosiyasu
                 L. Kunii",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-294",
  abstract =     "The paper presents a skeleton-based approach for
                 robust detection of perceptually salient shape
                 features. Given a shape approximated by a polygonal
                 surface, its skeleton is extracted using a
                 three-dimensional Voronoi diagram technique proposed
                 recently by Amenta et al. [3]. Shape creases, ridges
                 and ravines, are detected as curves corresponding to
                 skeletal edges. Salient shape regions are extracted via
                 skeleton decomposition into patches. The approach
                 explores the singularity theory for ridge and ravine
                 detection, combines several filtering methods for
                 skeleton denoising and for selecting perceptually
                 important ridges and ravines, and uses a topological
                 analysis of the skeleton for detection of salient shape
                 regions.",
  volume =       "21(4)",
}

@InCollection{EVL-2002-295,
  title =        "An Efficient Method for Rendering Underwater Optical
                 Effects Using Graphics Hardware",
  address =      "Oxford, UK and Boston, USA",
  month =        nov,
  editor =       "David Duke and Roberto Scopigno",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing Inc",
  pages =        "701--711",
  year =         "2002",
  author =       "Kei Iwasaki and Tomoyuki Nishita and Yoshinori
                 Dobashi",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-295",
  abstract =     "The display of realistic natural scenes is one of the
                 most important research areas in computer graphics. The
                 rendering of water is one of the essential components.
                 This paper proposes an efficient method for rendering
                 images of scenes within water. For underwater scenery,
                 the shafts of light and caustics are attractive and
                 important elements. However, computing these effects is
                 difficult and time-consuming since light refracts when
                 passing through waves. To address the problem, our
                 method makes use of graphics hardware to accelerate the
                 computation. Our method displays the shafts of light by
                 accumulating the intensities of streaks of light by
                 using hardware color blending functions. Making use of
                 a Z-buffer and a stencil buffer accelerates the
                 rendering of caustics. Moreover, by using a shadow
                 mapping technique, our method can display shafts of
                 light and caustics taking account of shadows due to
                 objects.",
  volume =       "21(4)",
}

@InCollection{EVL-2002-296,
  title =        "A Spoken Dialogue System for Navigation in
                 Non-Immersive Virtual Environments",
  address =      "Oxford, UK and Boston, USA",
  month =        nov,
  editor =       "David Duke and Roberto Scopigno",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing Inc",
  pages =        "713--723",
  year =         "2002",
  author =       "M. D. J. McNeill and H. Sayers and S. Wilson and P. Mc
                 Kevitt",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-296",
  abstract =     "Navigation is the process by which people control
                 their movement in virtual environments and is a core
                 functional requirement for all virtual environment (VE)
                 applications. Users require the ability to move,
                 controlling orientation, direction of movement and
                 speed, in order to achieve a particular goal within a
                 VE. Navigation is rarely the end point in itself (which
                 is typically interaction with the visual
                 representations of data) but applications often place a
                 high demand on navigation skills, which in turn means
                 that a high level of support for navigation is required
                 from the application. On desktop systems navigation in
                 non-immersive systems is usually supported through the
                 usual hardware devices of mouse and keyboard. Previous
                 work by the authors shows that many users experience
                 frustration when trying to perform even simple
                 navigation tasks &mdash; users complain about getting
                 lost, becoming disorientated and finding the interface
                 &lsquo;difficult to use&rsquo;. In this paper we report
                 on work in progress in exploiting natural language
                 processing (NLP) technology to support navigation in
                 non-immersive virtual environments. A multi-modal
                 system has been developed which supports a range of
                 high-level (spoken) navigation commands and indications
                 are that spoken dialogue interaction is an effective
                 alternative to mouse and keyboard interaction for many
                 tasks. We conclude that multi-modal interaction,
                 combining technologies such as NLP with mouse and
                 keyboard may offer the most effective interaction with
                 VEs and identify a number of areas where further work
                 is necessary.",
  volume =       "21(4)",
}

@InCollection{EVL-2002-297,
  title =        "Hierarchical Impostors for the Flocking Algorithm in
                 3{D}",
  address =      "Oxford, UK and Boston, USA",
  month =        nov,
  editor =       "David Duke and Roberto Scopigno",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing Inc",
  pages =        "723--731",
  year =         "2002",
  author =       "Noel O'Hara",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-297",
  abstract =     "The availability of powerful and affordable 3D PC
                 graphics boards has made the rendering of rich
                 immersive environments possible at interactive speeds.
                 The scene update rate and the appropriate behaviour of
                 objects within the world are central to this immersive
                 feeling. This paper is concerned with the behaviour
                 computations involved in the flocking algorithm, which
                 has been used extensively to emulate the flocking
                 behaviour of creatures found in nature. The main
                 contribution of this paper is a new method for
                 hierarchically combining portions of the flocks into
                 groups to reduce the cost of the behavioural
                 computation, allowing far larger flocks to be updated
                 in real-time in the world.",
  keywords =     "Flocking, hierarchical imposters, behavioural
                 animation, real-time animation",
  volume =       "21(4)",
}

@InCollection{EVL-2002-298,
  title =        "Levels of Detail for Crowds and Groups",
  address =      "Oxford, UK and Boston, USA",
  month =        nov,
  editor =       "David Duke and Roberto Scopigno",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing Inc",
  pages =        "733--741",
  year =         "2002",
  author =       "C. O'Sullivan and J. Cassell and H. Vilhj{\'{a}}lmsson
                 and J. Dingliana and S. Dobbyn and B. McNamee and C.
                 Peters and T. Giang",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-298",
  abstract =     "Work on levels of detail for human simulation has
                 occurred mainly on a geometrical level, either by
                 reducing the numbers of polygons representing a virtual
                 human, or replacing them with a two-dimensional
                 imposter. Approaches that reduce the complexity of
                 motions generated have also been proposed. In this
                 paper, we describe ongoing development of a framework
                 for Adaptive Level Of Detail for Human Animation
                 (ALOHA), which incorporates levels of detail for not
                 only geometry and motion, but also includes a
                 complexity gradient for natural behaviour, both
                 conversational and social.",
  keywords =     "Crowd animation, group animation, real-time animation,
                 human simulation, collision handling",
  volume =       "21(4)",
}

@InCollection{EVL-2002-299,
  title =        "Visualizing Crowds in Real-Time",
  address =      "Oxford, UK and Boston, USA",
  month =        nov,
  editor =       "David Duke and Roberto Scopigno",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing Inc",
  pages =        "753--765",
  year =         "2002",
  author =       "Franco Tecchia and Celine Loscos and Yiorgos
                 Chrysanthou",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-299",
  abstract =     "eal-time crowd visualization has recently attracted
                 quite an interest from the graphics community and, as
                 interactive applications become even more complex,
                 there is a natural demand for new and unexplored
                 application scenarios. However, the interactive
                 simulation of complex environments populated by large
                 numbers of virtual characters is a composite problem
                 which poses serious difficulties even on modern
                 computer hardware. In this paper we look at methods to
                 deal with various aspects of crowd visualization,
                 ranging from collision detection and behaviour modeling
                 to fast rendering with shadows and quality shading.
                 These methods make extensive use of current graphics
                 hardware capabilities with the aim of providing
                 scalability without compromising run-time speed.
                 Results from a system employing these techniques seem
                 to suggest that simulations of reasonably complex
                 environments populated with thousands of animated
                 characters are possible in real-time.",
  keywords =     "Crowd animation, image-based rendering, real-time
                 animation",
  volume =       "21(4)",
}

@InProceedings{EVL-2002-3,
  year =         "2002",
  title =        "Automatic Generation and Non-Photorealistic Rendering
                 of 2+1{D} Minkowski Diagrams",
  author =       "J. Diepstrate and D. Weiskopf and T. Ertl",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-3",
  abstract =     "In this paper, a system is proposed which can
                 automatically generate 2+1D Minkowski diagrams. We show
                 how these spacetime diagrams reveal more aspects of
                 special relativity than traditional Minkowski diagrams
                 and can therefore further enhance the understanding of
                 special relativity. The interactive system is based on
                 Java3D and can be used as widely applicable learning
                 and teaching tool. Moreover, we adapt and extend
                 non-photorelastic rendering techniques to improve the
                 perceptibility of the diagrams",
  editor =       "V. Skala",
  keywords =     "Non-photorealistic rendering, visualization, Java3D,
                 special relativity",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-30,
  year =         "2002",
  title =        "Automatic Keyframe Selection for High-Quality
                 Image-Based Walkthrough Animation Using Viewpoint
                 Entropy",
  author =       "P.-P. V{\'{a}}zquez and M. Sbert",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-30",
  abstract =     "The computation of high quality animation sequences is
                 expensive. Generation time for each frame can take a
                 few hours. Recently, Image-Based Rendering methods have
                 been proposed to solve this problem. As these
                 techniques obtain new arbitrary views from precomputed
                 ones at low cost, walkthroughs may be computed faster.
                 Consequently, the selection of the precomputed images
                 is a very important step. The initial set of views
                 should fulfill two requirements, it must be small but
                 provide as much information as possible on the scene.
                 In this paper we review several keyframe selection
                 strategies and then we propose a new method based on
                 entropy that achieve similar, and in some cases better,
                 results.",
  editor =       "V. Skala",
  keywords =     "High-Quality Walkthrough, Image-Based Rendering,
                 Keyframe Selection, Entropy",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InCollection{EVL-2002-300,
  title =        "Towards Interactive Real-Time Crowd Behavior
                 Simulation",
  address =      "Oxford, UK and Boston, USA",
  month =        nov,
  editor =       "David Duke and Roberto Scopigno",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing Inc",
  pages =        "767--775",
  year =         "2002",
  author =       "Branislav Ulicny and Daniel Thalmann",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-300",
  abstract =     "While virtual crowds are becoming common in
                 non-real-time applications, the real-time domain is
                 still relatively unexplored. In this paper we discuss
                 the challenges involved in creating such simulations,
                 especially the need to efficiently manage variety. We
                 introduce the concept of levels of variety. Then we
                 present our work on crowd behaviour simulation aimed at
                 interactive real-time applications such as computer
                 games or virtual environments. We define a modular
                 behavioural architecture of a multi-agent system
                 allowing autonomous and scripted behaviour of agents
                 supporting variety. Finally we show applications of our
                 system in a virtual reality training system and a
                 virtual heritage reconstruction.",
  keywords =     "Autonomous agents, crowd simulations, levels of
                 variety, multi-agent systems, virtual environments,
                 virtual heritage, virtual reality training systems",
  volume =       "21(4)",
}

@InCollection{EVL-2002-301,
  title =        "Adaptive Zooming in Web Cartography",
  address =      "Oxford, UK and Boston, USA",
  month =        nov,
  editor =       "David Duke and Roberto Scopigno",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing Inc",
  pages =        "787--799",
  year =         "2002",
  author =       "Alesandro Cecconi and Martin Galanda",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-301",
  abstract =     "Beyond any doubt much of the current web mapping and
                 web GIS applications lack cartographic quality. The
                 reasons aren&rsquo;t only the technical limitations
                 related to Internet delivery, but also the neglect of
                 one of the main cartographic principles of digital
                 mapping, namely adaptive zooming. Adaptive zooming
                 describes the adjustment of a map, its contents and the
                 symbolization to target scale in consequence of a
                 zooming operation. The approach described in this paper
                 proposes the combination of two commonly known
                 concepts: on the one hand levels of detail (LoD) for
                 those object classes, that require high computational
                 cost for the automated generalization process (e.g.
                 buildings, road network); on the other hand an
                 on-the-fly generalization for those object classes
                 which can be generalized by less complex methods and
                 algorithms (e.g. rivers, lakes). Realizing such
                 interactive and dynamic concept for web mapping
                 requires the use of vector based visualization tools.
                 The data format best meeting the criteria is the W3C
                 standard Scalable Vector Graphics (SVG). Thus, it has
                 been used to implement the presented ideas in a
                 prototype application for topographic web mapping based
                 on the landscape model VECTOR25 of the Swiss Federal
                 Office of Topography.",
  keywords =     "Web mapping with svg, adaptive zooming, cartographic
                 generalization",
  volume =       "21(4)",
}

@InProceedings{EVL-2002-302,
  pages =        "209--218",
  year =         "2002",
  title =        "Interactive Lighting Models and Pre-Integration for
                 Volume Rendering on {PC} Graphics Accelerators",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-302",
  author =       "Michael Mei{\ss}ner and Stefan Guthe and Wolfgang
                 Stra{\ss}er",
  abstract =     "Shading and classification are among the most powerful
                 and important techniques used in volume rendering.
                 Unfortunately, for hardware accelerated volume
                 rendering based on OpenGL, direct classification was
                 previously only supported on SGI platforms and shading
                 could only be approximated inaccurately, resulting in
                 artifacts mostly visible in darkening. In this paper,
                 we present a novel approach for accurate shading of
                 complex lighting models using multi-texturing,
                 dependent textures (e.g. cube maps), and register
                 combiners. Additionally, we present how different
                 material properties can be integrated as a per voxel
                 property to allow for more realistic image synthesis.
                 Furthermore, we present a new technique circumventing
                 the shading artifacts of previous approaches by
                 pre-integrating an interpolation weight. Finally, we
                 discuss how texture compression can be integrated to
                 reduce the memory bandwidth required for relatively
                 large volumes.",
  month =        may,
  keywords =     "Volume Rendering, Texture Mapping Hardware,
                 Multi-Texturing, Dependent Textures, Phong Shading,
                 Classification, Pre-Integration",
  booktitle =    "Proceedings of Graphics Interface",
}

@InProceedings{EVL-2002-303,
  pages =        "69--80",
  year =         "2002",
  title =        "Generating Spatial Distributions for Multilevel Models
                 of Plant Communities",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-303",
  author =       "Brendan Lane and Przemyslaw Prusinkiewicz",
  abstract =     "The simulation and visualization of large groups of
                 plants has many applications. The extreme visual
                 complexity of the resulting scenes can be captured
                 using multilevel models. For example, in two-level
                 models, plant distributions may be determined using
                 coarse plant representations, and realistic
                 visualizations may be obtained by substituting detailed
                 plant models for the coarse ones. In this paper, we
                 focus on the coarse aspect of modeling, the
                 specification of plant distribution. We consider two
                 classes of models: local-to-global models, rooted in
                 the individual-based ecosystem simulations, and
                 inverse, global-to-local models, in which positions of
                 individual plants are inferred from a given
                 distribution of plant densities. We extend previous
                 results obtained using both classes of models with
                 additional phenomena, including clustering and
                 succession of plants. We also introduce the formalism
                 of multiset L-systems to formalize the individual-based
                 simulation models.",
  month =        may,
  keywords =     "Realistic image synthesis, multilevel modeling, plant
                 ecosystems, spatial distribution, clustering,
                 succession, multiset L-system.",
  booktitle =    "Proceedings of Graphics Interface",
}

@InCollection{EVL-2002-304,
  title =        "Synthetic Vision and Memory for Autonomous Virtual
                 Humans",
  address =      "Oxford, UK and Boston, USA",
  month =        nov,
  editor =       "David Duke and Roberto Scopigno",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing Inc",
  pages =        "743--752",
  year =         "2002",
  author =       "C. Peters and C. O'Sullivan",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-304",
  abstract =     "A memory model based on 'stage theory', an influential
                 concept of memory from the field of cognitive
                 psychology, is presented for application to autonomous
                 virtual humans. The virtual human senses external
                 stimuli through a synthetic vision system. The vision
                 system incorporates multiple modes of vision in order
                 to accommodate a perceptual attention approach. The
                 memory model is used to store perceived and attended
                 object information at different stages in a filtering
                 process. The methods outlined in this paper have
                 applications in any area where simulation-based agents
                 are used: training, entertainment, ergonomics and
                 military simulations to name but a few.",
  volume =       "21(4)",
}

@InCollection{EVL-2002-305,
  pages =        "777--786",
  year =         "2002",
  title =        "{SVG} Linearization and Accessibility",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-305",
  author =       "Ivan Herman and Daniel Dardailler",
  address =      "Oxford, UK and Boston, USA",
  month =        nov,
  editor =       "David Duke and Roberto Scopigno",
  volume =       "21(4)",
  booktitle =    "Computer Graphics Forum",
  publisher =    "Blackwell Publishing Inc",
}

@InProceedings{EVL-2002-306,
  title =        "Integration of Measurement Tools in Medical 3d
                 Visualizations",
  month =        oct # "/" # nov,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "21--28",
  year =         "2002",
  author =       "Bernhard Preim and Christian Tietjen and Wolf Spindler
                 and Heinz-Otto Peitgen",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-306",
  abstract =     "We discuss 3d interaction techniques for the
                 quantitative analysis of spatial relations in medical
                 visualizations. We describe the design and
                 implementation of measurement tools to measure
                 distances, angles and volumes in 3d visualizations. The
                 visualization of measurement tools as recognizable 3d
                 objects and a 3d interaction, which is both intuitive
                 and precise, determines the usability of such
                 facilities. Measurements may be carried out in 2d
                 visualizations of the original radiological data and in
                 3d visualizations. The result of a measurement carried
                 out in one view is also displayed in the other view
                 appropriately. We discuss the validation of the
                 obtained measures. Finally, we describe how some
                 important measurement tasks may be solved
                 automatically.",
  organization = "IEEE Computer Society",
  keywords =     "Medical visualization, computer-assisted surgery,
                 quantitative analysis, interaction techniques",
}

@InProceedings{EVL-2002-307,
  title =        "Fast Visualization of Plane-Like Structures in Voxel
                 Data",
  month =        oct # "/" # nov,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "29--36",
  year =         "2002",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-307",
  author =       "Steffen Prohaska and Hans-Christian Hege",
  abstract =     "We present a robust, noise-resistant criterion
                 characterizing plane-like skeletons in binary voxel
                 objects. It is based on a distance map and the geodesic
                 distance along the object?s boundary. A parameter
                 allows to control the noise sensitivity. If needed,
                 homotopy with the original object might be
                 reconstructed in a second step, using an improved
                 distance ordered thinning algorithm. The skeleton is
                 analyzed to create a geometric representation for
                 rendering. Plane-like parts are transformed into an
                 triangulated surface not enclosing a volume by a
                 suitable triangulation scheme. The resulting surfaces
                 have lower triangle count than those created with
                 standard methods and tend to maintain the original
                 geometry, even after simplification with a high
                 decimation rate. Our algorithm allows to interactively
                 render expressive images of complex 3D structures,
                 emphasizing independently plane-like and rod-like
                 structures. The methods are applied for visualization
                 of the microstructure of bone biopsies.",
  organization = "IEEE Computer Society",
  keywords =     "Skeletonization, thinning, distance transform,
                 triangulation, visualization",
}

@InProceedings{EVL-2002-308,
  title =        "Direct Surface Extraction from 3{D} Freehand
                 Ultrasound Images",
  month =        oct # "/" # nov,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "45--52",
  year =         "2002",
  author =       "Youwei Zhang and Robert Rohling and Dinesh K. Pai",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-308",
  abstract =     "This paper presents a new technique for the extraction
                 of surfaces from 3D ultrasound data. Surface extraction
                 from ultrasound data is challenging for a number of
                 reasons including noise and artifacts in the images and
                 non-uniform data sampling. A method is proposed to fit
                 an approximating radial basis function to the group of
                 data samples. An explicit surface is then obtained by
                 iso-surfacing the function. In most previous 3D
                 ultrasound research, a pre-processing step is taken to
                 interpolate the data into a regular voxel array and a
                 corresponding loss of resolution. We are the first to
                 represent the set of semi-structured ultrasound pixel
                 data as a single function. From this we were able to
                 extract surfaces without first reconstructing the
                 irregularly spaced pixels into a regular 3D voxel
                 array.",
  organization = "IEEE Computer Society",
  keywords =     "Radial Basis Functions, Ultrasound, Isosurface, 3D
                 Freehand Ultrasound, Direct Surface Extraction,
                 Unstructured data",
}

@InProceedings{EVL-2002-309,
  title =        "{CPR} - Curved Planar Reformation",
  month =        oct # "/" # nov,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "37--44",
  year =         "2002",
  author =       "Armin Kanitsar and Dominik Fleischmann and Rainer
                 Wegenkittl and Petr Felkel and Meister Eduard
                 Gr{\"o}ller",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-309",
  abstract =     "Visualization of tubular structures such as blood
                 vessels is an important topic in medical imaging. One
                 way to display tubular structures for diagnostic
                 purposes is to generate longitudinal cross-sections in
                 order to show their lumen, wall, and surrounding tissue
                 in a curved plane. This process is called Curved Planar
                 Reformation (CPR). We present three different methods
                 to generate CPR images. A tube-phantom was scanned with
                 Computed Tomography (CT) to illustrate the properties
                 of the different CPR methods. Furthermore we introduce
                 enhancements to these methods: thick-CPR, rotating-CPR
                 and multi-path-CPR.",
  organization = "IEEE Computer Society",
  keywords =     "Computed tomography angiography, vessel analysis,
                 curved planar reformation.",
}

@InProceedings{EVL-2002-31,
  year =         "2002",
  title =        "Visual Simulation of Hydraulic Erosion",
  author =       "B. Benes and R. Forsbach",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-31",
  abstract =     "New algorithm for hydraulic terrain erosion is
                 introduced. The main goal of the paper is to provide
                 technique that is based on physics and allows for high
                 level of control. We divided the erosion process into
                 four independent steps that can be applied
                 independently to achieve high level of realism. The
                 erosion algorithm is based on the ability of water to
                 dissolve material that is then transported to another
                 locations. Because of the evaporation the sediment
                 capacity of water volume is exceeded and the material
                 is deposited. This kind of material transport
                 significantly influences the terrain morphology. The
                 algorithm has wide area of applications; we describe
                 here water sources, drying up the plashes, as well as
                 fictive rain on the surface of Mars.",
  editor =       "V. Skala",
  keywords =     "Physics-based modeling, erosion processes, weathering,
                 visual simulation",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-310,
  title =        "Interactive Rendering of Large Volume Data Sets",
  month =        oct # "/" # nov,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "53--60",
  year =         "2002",
  author =       "Stefan Guthe and Michael Wand and Julius Gonser and
                 Wolfgang Stra{\ss}er",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-310",
  abstract =     "We present a new algorithm for rendering very large
                 volume data sets at interactive framerates on standard
                 PC hardware. The algorithm accepts scalar data sampled
                 on a regular grid as input. The input data is converted
                 into a compressed hierarchical wavelet representation
                 in a preprocessing step. During rendering, the wavelet
                 representation is decompressed on-the-fly and rendered
                 using hardware texture mapping. The level of detail
                 used for rendering is adapted to the local frequency
                 spectrum of the data and its position relative to the
                 viewer. Using a prototype implementation of the
                 algorithm we were able to perform an interactive
                 walkthrough of large data sets such as the visible
                 human on a single of-the-shelf PC.",
  organization = "IEEE Computer Society",
  keywords =     "Compression Algorithms, Level of Detail Algorithms,
                 Scientific Visualization, Volume Rendering, Wavelets",
}

@InProceedings{EVL-2002-311,
  title =        "Semotus Visum: {A} Flexible Remote Visualization
                 Framework",
  month =        oct # "/" # nov,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "61--68",
  year =         "2002",
  author =       "Eric Luke and Charles Hansen",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-311",
  abstract =     "By offering more detail and precision, large data sets
                 can provide greater insights to researchers than small
                 data sets. However, these data sets require greater
                 computing resources to view and manage. Remote
                 visualization techniques allow the use of computers
                 that cannot be operated locally. The Semotus Visum
                 framework applies a high-performance client-server
                 paradigm to the problem. The framework utilizes both
                 client and server resources via multiple rendering
                 methods. Experimental results show the framework
                 delivers high framerates and low latency across a wide
                 range of data sets.",
  organization = "IEEE Computer Society",
  keywords =     "Remote visualization, client/server",
}

@InProceedings{EVL-2002-312,
  title =        "Out-of-Core Rendering of Massive Geometric Datasets",
  month =        oct # "/" # nov,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "69--76",
  year =         "2002",
  author =       "Gokul Varadhan and Dinesh Manocha",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-312",
  abstract =     "We present an external memory algorithm for fast
                 display of very large and complex geometric
                 environments. We represent the model using a scene
                 graph and employ different culling techniques for
                 rendering acceleration. Our algorithm uses a parallel
                 approach to render the scene as well as fetch objects
                 from the disk in a synchronous manner. We present a
                 novel prioritized prefetching technique that takes into
                 account LOD-switching and visibility-based events
                 between successive frames. We have applied our
                 algorithm to large gigabyte sized environments that are
                 composed of thousands of objects and tens of millions
                 of polygons. The memory overhead of our algorithm is
                 output sensitive and is typically tens of megabytes. In
                 practice, our approach scales with the model sizes, and
                 its rendering performance is comparable to that of an
                 in-core algorithm.",
  organization = "IEEE Computer Society",
  keywords =     "External memory, large datasets, walkthroughs,
                 visibility, LODs, prefetching.",
}

@InProceedings{EVL-2002-313,
  title =        "Optimized View-Dependent Rendering for Large Polygonal
                 Datasets",
  month =        oct # "/" # nov,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "77--84",
  year =         "2002",
  author =       "Jihad El-Sana and Eitan Bachmant",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-313",
  abstract =     "In this paper we are presenting a novel approach for
                 rendering large datasets in a view-dependent manner. In
                 a typical view-dependent rendering framework, an
                 appropriate level of detail is selected and sent to the
                 graphics hardware for rendering at each frame. In our
                 approach, we have successfully managed to speed up the
                 selection of the level of detail as well as the
                 rendering of the selected levels. We have accelerated
                 the selection of the appropriate level of detail by not
                 scanning active nodes that do not contribute to the
                 incremental update of the selected level of detail. Our
                 idea is based on imposing a spatial subdivision over
                 the view-dependence trees data-structure, which allows
                 spatial tree cells to refine and merge in real-time
                 rendering to comply with the changes in the active
                 nodes list. The rendering of the selected level of
                 detail is accelerated by using vertex arrays. To
                 overcome the dynamic changes in the selected levels of
                 detail we use multiple small vertex arrays whose sizes
                 depend on the memory on the graphics hardware. These
                 multiple vertex arrays are attached to the active cells
                 of the spatial tree and represent the active nodes of
                 these cells. These vertex arrays, which are sent to the
                 graphics hardware at each frame, merge and split with
                 respect to the changes in the cells of the spatial
                 tree.",
  organization = "IEEE Computer Society",
  keywords =     "Surface Simplification, Level of Detail,
                 Multiresolution Hierarchies, View-Dependent Rendering",
}

@InProceedings{EVL-2002-314,
  title =        "Volumetric Shadows Using Splatting",
  month =        oct # "/" # nov,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "85--92",
  year =         "2002",
  author =       "Caixia Zhang and Roger Crawfis",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-314",
  abstract =     "This paper describes an efficient algorithm to model
                 the light attenuation due to a participating media with
                 low albedo. The light attenuation is modeled using
                 splatting volume renderer for both the viewer and the
                 light source. During the rendering, a 2D shadow buffer
                 attenuates the light for each pixel. When the
                 contribution of a footprint is added to the image
                 buffer, as seen from the eye, we add the contribution
                 to the shadow buffer, as seen from the light source. We
                 have generated shadows for point lights and parallel
                 lights using this algorithm. The shadow algorithm has
                 been extended to deal with multiple light sources and
                 projective textured lights.",
  organization = "IEEE Computer Society",
  keywords =     "Visualization, volume rendering, shadows,
                 illumination",
}

@InProceedings{EVL-2002-315,
  pages =        "93--100",
  year =         "2002",
  title =        "Volume Clipping via Per-Fragment Operations in
                 Texture-Based Volume Visualization",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-315",
  author =       "Daniel Weiskopf and Klaus Engel and Thomas Ertl",
  organization = "IEEE Computer Society",
  month =        oct # "/" # nov,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
}

@InProceedings{EVL-2002-316,
  title =        "Interactive Spectral Volume Rendering",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "101--108",
  year =         "2002",
  author =       "Steven Bergner and Torsten M{\"o}ller and Mark S. Drew
                 and Graham D. Finlayson",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-316",
  abstract =     "We describe a method for volume rendering using a
                 spectral representation of colour instead of the
                 traditional RGB model. It is shown how to use this
                 framework for a novel exploration of datasets through
                 enhanced transfer function design. Furthermore, our
                 framework is extended to allow real-time re-lighting of
                 the scene created with any rendering method. The
                 technique of post-illumination is introduced to
                 generate new spectral images for arbitrary light
                 colours in real-time. Also a tool is described to
                 design a palette of lights and materials having certain
                 properties such as selective metamerism or colour
                 constancy. Applied to spectral transfer functions,
                 different light colours can accentuate or hide specific
                 qualities of the data. In connection with
                 post-illumination this provides a new degree of freedom
                 for guided exploration of volumetric data, which cannot
                 be achieved using the RGB model.",
  organization = "IEEE Computer Society",
  keywords =     "Spectral volume rendering, post-illumination,
                 interactive re-lighting",
}

@InProceedings{EVL-2002-317,
  title =        "Interactive Translucent Volume Rendering and
                 Procedural Modeling",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "109--116",
  year =         "2002",
  author =       "Joe Kniss and Simon Premoze and Charles Hansen and
                 David Ebert",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-317",
  abstract =     "Direct volume rendering is a commonly used technique
                 in visualization applications. Many of these
                 applications require sophisticated shading models to
                 capture subtle lighting effects and characteristics of
                 volumetric data and materials. Many common objects and
                 natural phenomena exhibit visual quality that cannot be
                 captured using simple lighting models or cannot be
                 solved at interactive rates using more sophisticated
                 methods. We present a simple yet effective interactive
                 shading model which captures volumetric light
                 attenuation effects to produce volumetric shadows and
                 the subtle appearance of translucency. We also present
                 a technique for volume displacement or perturbation
                 that allows realistic interactive modeling of high
                 frequency detail for real and synthetic volumetric
                 data.",
  organization = "IEEE Computer Society",
  keywords =     "Volume rendering, shading model, volume modeling,
                 procedural modeling",
}

@InProceedings{EVL-2002-318,
  title =        "A Multiphase Approach to Efficient Surface
                 Simplification",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "117--124",
  year =         "2002",
  author =       "Michael Garland and Eric Shaffer",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-318",
  abstract =     "We present a new multiphase method for efficiently
                 simplifying polygonal surface models of arbitrary size.
                 It operates by combining an initial out-of-core uniform
                 clustering phase with a subsequent in-core iterative
                 edge contraction phase. These two phases are both
                 driven by quadric error metrics, and quadrics are used
                 to pass information about the original surface between
                 phases. The result is a method that produces
                 approximations of a quality comparable to quadric-based
                 iterative edge contraction, but at a fraction of the
                 cost in terms of running time and memory consumption.",
  organization = "IEEE Computer Society",
  keywords =     "Multiphase simplification, quadric error metrics,
                 massive meshes, out-of-core simplification.",
}

@InProceedings{EVL-2002-319,
  title =        "Geometric Surface Smoothing via Anisotropic Diffusion
                 of Normals",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "125--132",
  year =         "2002",
  author =       "Tasdizen and Ross Whitaker and Paul Burchard and
                 Stanley Osher",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-319",
  abstract =     "This paper introduces a method for smoothing complex,
                 noisy surfaces, while preserving (and enhancing) sharp,
                 geometric features. It has two main advantages over
                 previous approaches to feature preserving surface
                 smoothing. First is the use of level set surface
                 models, which allows us to process very complex shapes
                 of arbitrary and changing topology. This generality
                 makes it well suited for processing surfaces that are
                 derived directly from measured data. The second
                 advantage is that the proposed method derives from a
                 well-founded formulation, which is a natural
                 generalization of anisotropic diffusion, as used in
                 image processing. This formulation is based on the
                 proposition that the generalization of image filtering
                 entails filtering the normals of the surface, rather
                 than processing the positions of points on a mesh.",
  organization = "IEEE Computer Society",
  keywords =     "Anisotropic diffusion, surface fairing, geometric
                 surface processing, intrinsic Laplacian of curvature,
                 level sets.",
}

@InProceedings{EVL-2002-32,
  year =         "2002",
  title =        "Fast Mesh Rendering Through Efficient Triangle Strip
                 Generation",
  author =       "M. V. G. de Silva and O. M. van Kaick and H. Pedrini",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-32",
  abstract =     "The development of methods for storing, manipulating,
                 and rendering large volumes of data efficiently is a
                 crucial task in several scientific applications, such
                 as medical image analysis, remote sensing, computer
                 vision, and computer-aided design. Unless data
                 reduction or compression methods are used, extremely
                 large data sets cannot be analyzed or visualized in
                 real time. Polygonal surfaces, typically defined by a
                 set of triangles, are one of the most widely used
                 representations for geometric models. This paper
                 presents an efficient algorithm for compressing
                 triangulated models through the construction of
                 triangle strips. Experimental results show that these
                 strips are significantly better than those generated by
                 the leading triangle strip algorithms.",
  editor =       "V. Skala",
  keywords =     "Triangle strips, geometry compression, rendering, mesh
                 representation",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-320,
  title =        "TetFusion: An Algorithm For Rapid Tetrahedral Mesh
                 Simplification",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "133--140",
  year =         "2002",
  author =       "Prashant Chopra and Joerg Meyer",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-320",
  abstract =     "This paper introduces an algorithm for rapid
                 progressive simplification of tetrahedral meshes:
                 TetFusion. We describe how a simple geometry decimation
                 operation steers a rapid and controlled progressive
                 simplification of tetrahedral meshes, while also taking
                 care of complex mesh-inconsistency problems. The
                 algorithm features a high decimation ratio per step,
                 and inherently discourages any cases of
                 self-intersection of boundary, element-boundary
                 intersection at concave boundary-regions, and negative
                 volume tetrahedra (flipping). We achieved rigorous
                 reduction ratios of up to 98% for meshes consisting of
                 827,904 elements in less than 2 minutes, progressing
                 through a series of level-of-details (LoDs) of the mesh
                 in a controlled manner. We describe how the approach
                 supports a balanced re-distribution of space between
                 tetrahedral elements, and explain some useful control
                 parameters that make it faster and more intuitive than
                 edge collapse-based decimation methods for volumetric
                 meshes [3, 19, 21, 22]. Finally, we discuss how this
                 approach can be employed for rapid LoD prototyping of
                 large time-varying datasets as an aid to interactive
                 visualization.",
  organization = "IEEE Computer Society",
  keywords =     "Mesh simplification, multi resolution,
                 level-of-detail, unstructured meshes",
}

@InProceedings{EVL-2002-321,
  title =        "Case Study: Visualization and Analysis of High
                 Rayleigh number - 3{D} Convection in the Earth's
                 Mantle",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "493--496",
  year =         "2002",
  author =       "Gordon Erlebacher and David A. Yuen and Fabien
                 Dubuffet",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-321",
  abstract =     "Data sets from large-scale simulations (up to 501
                 grid points) of mantle convection are analyzed with
                 volume rendering of the temperature field and a new
                 critical point analysis of the velocity field. As the
                 Rayleigh number Ra is increased the thermal field
                 develops increasingly thin plume-like structures along
                 which heat is convected. These eventually break down
                 and become turbulent. Visualization methods are used to
                 distinguish between various models of heat conductivity
                 and to develop an intuitive understanding of the
                 structure of the flow.",
  organization = "IEEE Computer Society",
  keywords =     "Mantle convection, plumes, volume rendering, unsteady
                 flow, feature extraction, critical points.",
}

@InProceedings{EVL-2002-322,
  title =        "Compressing Polygon Mesh Geometry with Parallelogram
                 Prediction",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "141--146",
  year =         "2002",
  author =       "Martin Isenburg and Pierre Alliez",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-322",
  abstract =     "In this paper we present a generalization of the
                 geometry coder by Touma and Gotsman [34] to polygon
                 meshes. We let the polygon information dictate where to
                 apply the parallelogram rule that they use to predict
                 vertex positions. Since polygons tend to be fairly
                 planar and fairly convex, it is beneficial to make
                 predictions within a polygon rather than across
                 polygons. This, for example, avoids poor predictions
                 due to a crease angle between polygons. Up to 90
                 percent of the vertices can be predicted this way. Our
                 strategy improves geometry compression by 10 to 40
                 percent depending on (a) how polygonal the mesh is and
                 (b) on the quality (planarity/ convexity) of the
                 polygons.",
  organization = "IEEE Computer Society",
  keywords =     "Mesh compression, polygon meshes, geometry coding,
                 linear prediction, parallelogram rule",
}

@InProceedings{EVL-2002-323,
  title =        "Probabilistic Surfaces: Point Based Primitives to Show
                 Surface Uncertainty",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "147--154",
  year =         "2002",
  author =       "Gevorg Grigoryan and Penny Rheingans",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-323",
  abstract =     "Efficient and informative visualization of surfaces
                 with uncertainties is an important topic with many
                 applications in science and engineering. Examples
                 include environmental pollution borderline
                 identification, identification of the limits of an oil
                 basin, or discrimination between contaminated and
                 healthy tissue in medicine. This paper presents an
                 approach for such visualization using points as display
                 primitives. Our approach is to render each polygon as a
                 collection of points and to displace each point from
                 the surface in the direction of the surface normal by
                 an amount proportional to some random number multiplied
                 by the uncertainty level at that point. This approach
                 can be used in combination with other techniques such
                 as pseudo-coloring and shading to give rise to
                 efficient and revealing visualizations. The method is
                 used to visualize real and simulated tumor formations
                 with uncertainty of tumor boundaries.",
  organization = "IEEE Computer Society",
  keywords =     "Uncertainty, visualizing surface uncertainty, points
                 as display primitives",
}

@InProceedings{EVL-2002-324,
  title =        "{PMR}: Point to Mesh Rendering, {A} Feature-Based
                 Approach",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "155--162",
  year =         "2002",
  author =       "Tamal K. Dey and James Hudson",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-324",
  abstract =     "Within the field of computer graphics and
                 visualization, it is often necessary to visualize
                 polygonal models with large number of polygons. Display
                 quality is mandatory, but it is also desirable to have
                 the ability to rapidly update the display in order to
                 facilitate interactive use. Point based rendering
                 methods have been shown effective for this task.
                 Building on this paradigm we introduce the PMR system
                 which uses a hierarchy both in points and triangles for
                 rendering. This hierarchy is fundamentally different
                 from the ones used in existing methods. It is based on
                 the feature geometry in the object space rather than
                 its projection in the screen space. This provides
                 certain advantages over the existing methods.",
  organization = "IEEE Computer Society",
  keywords =     "Rendering, feature, multi-resolution, level of
                 details, Voronoi diagram.",
}

@InProceedings{EVL-2002-325,
  pages =        "163--170",
  year =         "2002",
  title =        "Efficient Simplification of Point-Sampled Surfaces",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-325",
  author =       "Mark Pauly and Markus Gross and Leif P. Kobbelt",
  abstract =     "In this paper we introduce, analyze and quantitatively
                 compare a number of surface simplification methods for
                 point-sampled geometry. We have implemented incremental
                 and hierarchical clustering, iterative simplification,
                 and particle simulation algorithms to create
                 approximations of point-based models with lower
                 sampling density. All these methods work directly on
                 the point cloud, requiring no intermediate tesselation.
                 We show how local variation estimation and quadric
                 error metrics can be employed to diminish the
                 approximation error and concentrate more samples in
                 regions of high curvature. To compare the quality of
                 the simplified surfaces, we have designed a new method
                 for computing numerical and visual error estimates for
                 point-sampled surfaces. Our algorithms are fast, easy
                 to implement, and create high-quality surface
                 approximations, clearly demonstrating the effectiveness
                 of point-based surface simplification.",
  organization = "IEEE Computer Society",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
}

@InProceedings{EVL-2002-326,
  title =        "Christmas Tree Case Study: Computed Tomography as a
                 Tool for Mastering Complex Real World Objects with
                 Applications in Computer Graphics",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "489--492",
  year =         "2002",
  author =       "Armin Kanitsar and Thomas Theu{\ss}l and Lukas Mroz
                 and Milos Sr{\'{a}}mek and Anna Vilanova Batol{\'{i}}
                 and Bal{\'{a}}zs Cs{\'{e}}falvi and Jir{\'{i}}
                 Hlad{\`{u}}vka and Dominik Fleischmann and Michael
                 Knapp and Rainer Wegenkittl and Petr Felkel and Stefan
                 Guthe and Werner Purgathofer and Eduard Gr{\"o}ller",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-326",
  abstract =     "We report on using computed tomography (CT) as a model
                 acquisition tool for complex objects in computer
                 graphics. Unlike other modeling and scanning techniques
                 the complexity of the object is irrelevant in CT, which
                 naturally enables to model objects with, for example,
                 concavities, holes, twists or fine surface details.
                 Once the data is scanned, one can apply post-processing
                 techniques for data enhancement, modification or
                 presentation. For demonstration purposes we chose to
                 scan a Christmas tree which exhibits high complexity
                 which is difficult or even impossible to handle with
                 other techniques. However, care has to be taken to
                 achieve good scanning results with CT. Further, we
                 illustrate post-processing by means of data
                 segmentation and photorealistic as well as
                 non-photorealistic surface and volume rendering
                 techniques.",
  organization = "IEEE Computer Society",
  keywords =     "Mdeling, computed tomography, volume visualization",
}

@InProceedings{EVL-2002-327,
  title =        "Case Study: Hardware-Accelerated Selective {LIC}
                 Volume Rendering",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "485--488",
  year =         "2002",
  author =       "Yasuko Suzuki and Issei Fujishiro and Li Chen and
                 Hiroko Nakamura",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-327",
  abstract =     "Line Integral Convolution (LIC) is a promising method
                 for visualizing 2D dense flow fields. Direct extensions
                 of the LIC method to 3D have not been considered very
                 effective, because optical integration in viewing
                 directions tends to spoil the coherent structures along
                 3D local streamlines. In our previous reports, we have
                 proposed a selective approach to volume rendering of
                 LIC solid texture using 3D significance map (S-map),
                 derived from the characteristics of flow structures,
                 and a specific illumination model for 3D streamlines.
                 In this paper, we take full advantage of scalar volume
                 rendering hardware, such as VolumePro, to realize a
                 realtime 3D flow field visualization environment with
                 the LIC volume rendering method.",
  organization = "IEEE Computer Society",
  keywords =     "Flow visualization, flow topology, significance map,
                 illumination model",
}

@InProceedings{EVL-2002-328,
  title =        "Immersive Volume Visualization of Seismic Simulations:
                 {A} Case Study of Techniques Invented and Lessons
                 Learned",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "497--500",
  year =         "2002",
  author =       "Prashant Chopra and Joerg Meyer and Antonio
                 Fernandez",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-328",
  abstract =     "This paper is a documentation of techniques invented,
                 results obtained and lessons learned while creating
                 visualization algorithms to render outputs of
                 large-scale seismic simulations. The objective is the
                 development of techniques for a collaborative
                 simulation and visualization shared between structural
                 engineers, seismologists, and computer scientists. The
                 computer graphics research community has been
                 witnessing a large number of exemplary publications
                 addressing the challenges faced while trying to
                 visualize both large-scale surface and volumetric
                 datasets lately. From a visualization perspective,
                 issues like data preprocessing (simplification,
                 sampling, filtering, etc.); rendering algorithms
                 (surface and volume), and interaction paradigms
                 (large-scale, highly interactive, highly immersive,
                 etc.) have been areas of study. In this light, we
                 outline and describe the milestones achieved in a
                 large-scale simulation and visualization project, which
                 opened the scope for combining existing techniques with
                 new methods, especially in those cases where no
                 existing methods were suitable. We elucidate the data
                 simplification and reorganization schemes that we used,
                 and discuss the problems we encountered and the
                 solutions we found. We describe both desktop (high-end
                 local as well as remote) interfaces and immersive
                 visualization systems that we developed to employ
                 interactive surface and volume rendering algorithms.
                 Finally, we describe the results obtained, challenges
                 that still need to be addressed, and ongoing efforts to
                 meet the challenges of large-scale visualization.",
  organization = "IEEE Computer Society",
  keywords =     "Mesh simplification, multi resolution,
                 level-of-detail, unstructured meshes.",
}

@InProceedings{EVL-2002-329,
  title =        "Case Study: {A} Look of Performance Expression",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "501--504",
  year =         "2002",
  author =       "Rumi Hiraga",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-329",
  abstract =     "erformances as they are. Once we try to understand the
                 performance not in subjective terms but in an objective
                 way and share it with other people, visualizing the
                 performance parameters is indispensable. In this paper,
                 a figure for visualizing performance expressions is
                 described. This figure helps people understand the
                 cause and position of the performance expression as it
                 has expressive cues, which coincide with the cognitive
                 meaning of musical performance, and not by using only
                 MIDI parameter values. The differences we hear between
                 performances are clarified by visualized figures.",
  organization = "IEEE Computer Society",
  keywords =     "Music Performance, Expressive Cue, Performance
                 Visualization, Understanding Performance.",
}

@InProceedings{EVL-2002-33,
  year =         "2002",
  title =        "Redundancy in 3{D} Polygon Models and Its Application
                 to Digital Signature",
  author =       "S. Ichikawa and H. Chiyama and K. Akabane",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-33",
  abstract =     "This paper introduces new watermarking schemes for 3D
                 polygon models. The schemes presented here use just the
                 redundancy in model description, hence essential model
                 data such as vertex coordinates and topology are left
                 intact. Proposed FPS and PPS embed information by
                 permuting the order of vertices or faces, and PVS
                 embeds information by rotating the vertices of faces.
                 The digital signature procedure for verification
                 purposes is also presented, which works in cooperation
                 with popular public-key cryptography. Evaluation
                 results show that our schemes can embed 0.2% (by Packet
                 PVR) -- 2.8% (by FPS) of information compared to the
                 original model file size. Our methods are orthogonal
                 and complementary to the preceding methods that use
                 geometrical and topological domain.",
  editor =       "V. Skala",
  keywords =     "Watermarking, Polygon Models, Data Embedding, Model
                 Verification, Public-key Cryptography",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-330,
  title =        "Case Study: Interactive Visualization for Internet
                 Security",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "505--508",
  year =         "2002",
  author =       "Soon Tee Teoh and Kwan-Liu Ma and S. Felix Wu and
                 Xiaoliang Zhao",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-330",
  abstract =     "Internet connectivity is defined by a set of routing
                 protocols which let the routers that comprise the
                 Internet backbone choose the best route for a packet to
                 reach its destination. One way to improve the security
                 and performance of Internet is to routinely examine the
                 routing data. In this case study, we show how
                 interactive visualization of Border Gateway Protocol
                 (BGP) data helps characterize routing behavior,
                 identify weaknesses in connectivity which could
                 potentially cripple the Internet, as well as detect and
                 explain actual anomalous events.",
  organization = "IEEE Computer Society",
  keywords =     "Anomaly detection, graph drawing, information
                 visualization, network security.",
}

@InProceedings{EVL-2002-331,
  title =        "{PRIMA}: {A} Case Study of Using Information
                 Visualization Techniques for Patient Record Analysis",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "509--512",
  year =         "2002",
  author =       "Donna L. Gresh and David A. Rabenhorst and Amnon Shabo
                 and Shimon Slavin",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-331",
  abstract =     "We have created an application, called PRIMA (Patient
                 Record Intelligent Monitoring and Analysis), which can
                 be used to visualize and understand patient record
                 data. It was developed to better understand a large
                 collection of patient records of bone marrow
                 transplants at Hadassah Hospital in Jerusalem, Israel.
                 It is based on an information visualization toolkit,
                 Opal, which has been developed at the IBM T.J. Watson
                 Research Center. Opal allows intelligent, interactive
                 visualization of a wide variety of different types of
                 data. The PRIMA application is generally applicable to
                 a wide range of patient record data, as the underlying
                 toolkit is flexible with regard to the form of the
                 input data. This application is a good example of the
                 usefulness of information visualization techniques in
                 the bioinformatics domain, as these techniques have
                 been developed specifically to deal with diverse sets
                 of often unfamiliar data. We illustrate several
                 unanticipated findings which resulted from the use of a
                 flexible and interactive nformation visualizatio,
                 environment.",
  organization = "IEEE Computer Society",
  keywords =     "Visualization, information visualization,
                 bioinformatics, medical records.",
}

@InProceedings{EVL-2002-332,
  title =        "Case Study: {A} Virtual Environment for Genomic Data
                 Visualization",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "51--516",
  year =         "2002",
  author =       "R. Mark Adams and Blaze Stancampiano and Michael
                 McKenna and David Small",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-332",
  abstract =     "With the completion of the human genome sequence, and
                 with the proliferation of genome-related annotation
                 data, the need for scalable and more intuitive means
                 for analysis becomes critical. At Variagenics and Small
                 Design Firm, we have addressed this problem with a
                 coherent three-dimensional space in which all data can
                 be seen in a single context. This tool aids in
                 integrating information at vastly divergent scales
                 while maintaining accurate spatial and size
                 relationships. Our visualization was successful in
                 communicating to project teams with diverse backgrounds
                 the magnitude and biological implication of genetic
                 variation.",
  organization = "IEEE Computer Society",
  keywords =     "Bioinformatic,, Human Factors, 3-Dimensional
                 Interaction, Multi-scale Model, Data Navigation,
                 Virtual Environment",
}

@InProceedings{EVL-2002-333,
  title =        "Exploring Scalar Fields Using Critical Isovalues",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "171--178",
  year =         "2002",
  author =       "Gunther H. Weber and Gerik Scheuermann and Hans Hagen
                 and Bernd Hamann",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-333",
  abstract =     "Isosurfaces are commonly used to visualize scalar
                 fields. Critical isovalues indicate isosurface topology
                 changes: the creation of new surface components,
                 merging of surface components or the formation of holes
                 in a surface component. Therefore, they highlight
                 interesting isosurface behavior and are helpful in
                 exploration of large trivariate data sets. We present a
                 method that detects critical isovalues in a scalar
                 field defined by piecewise trilinear interpolation over
                 a rectilinear grid and describe how to use them when
                 examining volume data. We further review varieties of
                 the Marching Cubes (MC) algorithm, with the intention
                 to preserve topology of the trilinear interpolant when
                 extracting an isosurface. We combine and extend two
                 approaches in such a way that it is possible to extract
                 meaningful isosurfaces even when a critical value is
                 chosen as isovalue.",
  organization = "IEEE Computer Society",
  keywords =     "Scalar field topology, critical point, volume
                 visualization, data exploration, isosurfaces, marching
                 cubes.",
}

@InProceedings{EVL-2002-334,
  title =        "Level-Set Segmentation From Multiple Non-Uniform
                 Volume Datasets",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "179--186",
  year =         "2002",
  author =       "Ken Museth and David E. Breen and Leonid Zhukov and
                 Ross T. Whitaker",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-334",
  abstract =     "Typically 3-D MR and CT scans have a relatively high
                 resolution in the scanning XY plane, but much lower
                 resolution in the axial Z direction. This non-uniform
                 sampling of an object can miss small or thin
                 structures. One way to address this problem is to scan
                 the same object from multiple directions. In this paper
                 we describe a method for deforming a level set model
                 using velocity information derived from multiple volume
                 datasets with non-uniform resolution in order to
                 produce a single high-resolution 3D model. The method
                 locally approximates the values of the multiple
                 datasets by fitting a distance-weighted polynomial
                 using moving least-squares. The proposed method has
                 several advantageous properties: its computational cost
                 is proportional to the object surface area, it is
                 stable with respect to noise, imperfect registrations
                 and abrupt changes in the data, it provides
                 gain-correction, and it employs a distance-based
                 weighting to ensures that the contributions from each
                 scan are properly merged into the final result. We have
                 demonstrated the effectiveness of our approach on four
                 multi-scan datasets, a griffin laser scan
                 reconstruction, a CT scan of a teapot and MR scans of a
                 mouse embryo and a zucchini.",
  organization = "IEEE Computer Society",
  keywords =     "Segmentation, visualization, level set models, 3D
                 reconstruction",
}

@InProceedings{EVL-2002-335,
  title =        "Efficient Computation of the Topology of Level Sets",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "187--194",
  year =         "2002",
  author =       "V. Pascucci and K. Cole-McLaughlin",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-335",
  abstract =     "This paper introduces two efficient algorithms that
                 compute the Contour Tree of a 3D scalar field F and its
                 augmented version with the Betti numbers of each
                 isosurface. The Contour Tree is a fundamental data
                 structure in scientific visualization that is used to
                 preprocess the domain mesh to allow optimal computation
                 of isosurfaces with minimal overhead storage. The
                 Contour Tree can also be used to build user interfaces
                 reporting the complete topological characterization of
                 a scalar field, as shown in Figure 1. The first part of
                 the paper presents a new scheme that augments the
                 Contour Tree with the Betti numbers of each isocontour
                 in linear time. We show how to extend the scheme
                 introduced in [3] with the Betti number computation
                 without increasing its complexity. Thus, we improve on
                 the time complexity from our previous approach [10]
                 from O(m log m) to O(n log n + m), where m is the
                 number of tetrahedra and n is the number of vertices in
                 the domain of F The second part of the paper introduces
                 a new divide-and-conquer algorithm that computes the
                 Augmented Contour Tree withimproved efficiency. The
                 central part of the scheme computes the output Contour
                 Tree by merging two intermediate Contour Trees and is
                 independent of the interpolant. In this way we confine
                 any knowledge regarding a specific interpolant to an
                 oracle that computes the tree for a single cell. We
                 have implemented this oracle for the trilinear
                 interpolant and plan to replace it with higher order
                 interpolants when needed. The complexity of the scheme
                 is O(n + t log n), where t is the number of critical
                 points of F. For the first time we can compute the
                 Contour Tree in linear time in many practical cases
                 when t = 0(n^[1 - \varepsilon ] ) Lastly, we report the
                 running times for a parallel implementation of our
                 algorithm, showing good scalability with the number of
                 processors.",
  organization = "IEEE Computer Society",
  keywords =     "Isosurfaces, Level Set Topology, Betti Numbers",
}

@InProceedings{EVL-2002-336,
  title =        "Fast and Reliable Space Leaping for Interactive Volume
                 Rendering",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "195--202",
  year =         "2002",
  author =       "Ming Wan and Aamir Sadiq and Arie Kaufman",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-336",
  abstract =     "We present a fast reliable space-leaping scheme to
                 accelerate ray casting during interactive navigation in
                 a complex volumetric scene, where we combine innovative
                 space-leaping techniques in a number of ways. First, we
                 derive most of the pixel depths at the current frame by
                 exploiting the temporal coherence during navigation,
                 where we employ a novel fast cell-based reprojection
                 scheme that is more reliable than the traditional
                 intersection-point based reprojection. Next, we exploit
                 the object space coherence to quickly detect the
                 remaining pixel depths, by using a precomputed accurate
                 distance field that stores the Euclidean distance from
                 each empty (background) voxel toward its nearest object
                 boundary. In addition, we propose an effective solution
                 to the challenging new-incoming-objects problem during
                 navigation. Our algorithm has been implemented on a
                 16-processor SGI Power Challenge and reached
                 interactive rendering rates at more than 10Hz during
                 the navigation 512^[3] volume data sets acquired from
                 both a simulation phantom and actual patients.",
  organization = "IEEE Computer Society",
  keywords =     "Virtual navigation, volume visualization, ray-casting
                 optimization, space leaping.",
}

@InProceedings{EVL-2002-337,
  title =        "A New Object-Order Ray-Casting Algorithm",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "203--210",
  year =         "2002",
  author =       "Benjamin Mora and Jean-Pierre Jessel and Ren{\'{e}}
                 Caubet",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-337",
  abstract =     "Many direct volume rendering algorithms have been
                 proposed during the last decade to render 256 3 voxels
                 interactively. However a lot of limitations are
                 inherent to all of them, like low- quality images, a
                 small viewport size or a fixed classification. In
                 contrast, interactive high quality algorithms are still
                 a challenge nowadays. We introduce here an efficient
                 and accurate technique called object-order ray-casting
                 that can achieve up to 10 fps on current workstations.
                 Like usual ray-casting, colors and opacities are evenly
                 sampled along the ray, but now within a new object-
                 order algorithm. Thus, it allows to combine the main
                 advantages of both worlds in term of speed and quality.
                 We also describe an efficient hidden volume removal
                 technique to compensate for the loss of early ray
                 termination.",
  organization = "IEEE Computer Society",
  keywords =     "Volume Rendering, Scientific Visualization, Medical
                 Imaging, Ray Tracing.",
}

@InProceedings{EVL-2002-338,
  title =        "Non-Photorealistic Volume Rendering Using Stippling
                 Techniques",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "211--218",
  year =         "2002",
  author =       "Aidong Lu and Christopher J. Morris and David Ebert
                 and Penny Rheingans and Charles Hansen",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-338",
  abstract =     "Simulating hand-drawn illustration techniques can
                 succinctly express information in a manner that is
                 communicative and informative. We present a framework
                 for an interactive direct volume illustration system
                 that simulates traditional stipple drawing. By
                 combining the principles of artistic and scientific
                 illustration, we explore several feature enhancement
                 techniques to create effective, interactive
                 visualizations of scientific and medical datasets. We
                 also introduce a rendering mechanism that generates
                 appropriate point lists at all resolutions during an
                 automatic preprocess, and modifies rendering styles
                 through different combinations of these feature
                 enhancements. The new system is an effective way to
                 interactively preview large, complex volume datasets in
                 a concise, meaningful, and illustrative manner. Volume
                 stippling is effective for many applications and
                 provides a quick and efficient method to investigate
                 volume models.",
  organization = "IEEE Computer Society",
  keywords =     "Non-photorealistic rendering, volume rendering,
                 scientific visualization, medical imaging.",
}

@InProceedings{EVL-2002-339,
  title =        "Interactive Visualization of Complex Plant
                 Ecosystems",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "219--226",
  year =         "2002",
  author =       "Oliver Deussen and Carsten Colditz and Marc Stamminger
                 and George Drettakis",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-339",
  abstract =     "We present a method for interactive rendering of large
                 outdoor scenes. Complex polygonal plant models and
                 whole plant populations are represented by relatively
                 small sets of point and line primitives. This enables
                 us to show landscapes faithfully using only a limited
                 percentage of primitives. In addition, a hierarchical
                 data structure allows us to smoothly reduce the
                 geometrical representation to any desired number of
                 primitives. The scene is hierarchically divided into
                 local portions of geometry to achieve large reduction
                 factors for distant regions. Additionally, the data
                 reduction is adapted to the visual importance of
                 geometric objects. This allows us to maintain the
                 visual fidelity of the representation while reducing
                 most of the geometry drastically. With our system, we
                 are able to interactively render very complex
                 landscapes with good visual quality.",
  organization = "IEEE Computer Society",
  keywords =     "Synthetic Plants, Ecosystems, Point-based rendering,
                 Level-of-detail Algorithms",
}

@InProceedings{EVL-2002-34,
  year =         "2002",
  title =        "NonConformity Problem in 3{D} Grid Decompositions",
  author =       "A. Kolcun",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-34",
  abstract =     "3D modelling and visualization based on general meshes
                 needs a great amount of memory demands. Regular grids
                 can substantially decrease them. Moreover, using the
                 regular data structures results in efficient numerical
                 procedures and simplicity of algorithms. On the other
                 hand, disadvantage of regular grids is in lower
                 flexibility of shape expression. One of the
                 possibilities how to improve the shape expression of a
                 regular grid is its decomposition to tetrahedra. The
                 paper concerns the problem which arises here --
                 nonconformity of decomposition.",
  editor =       "V. Skala",
  keywords =     "Structured mesh, Decomposition, Nonconformity",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-340,
  title =        "Simulating Fire with Texture Splats",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "227--234",
  year =         "2002",
  author =       "Xiaoming Wei and Wei Li and Klaus Mueller and Arie
                 Kaufman",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-340",
  abstract =     "We propose the use of textured splats as the basic
                 display primitives for an open surface fire model. The
                 high-detail textures help to achieve a smooth boundary
                 of the fire and gain the small-scale turbulence
                 appearance. We utilize the Lattice Boltzmann Model
                 (LBM) to simulate physically-based equations describing
                 the fire evolution and its interaction with the
                 environment (e.g., obstacles, wind and temperature).
                 The property of fuel and non-burning objects are
                 defined on the lattice of the computation domain. A
                 temperature field is also incorporated to model the
                 generation of smoke from the fire due to incomplete
                 combustion. The linear and local characteristics of the
                 LBM enable us to accelerate the computation with
                 graphics hardware to reach real-time simulation speed,
                 while the texture splat primitives enable interactive
                 rendering frame rates.",
  organization = "IEEE Computer Society",
  keywords =     "Fire Modeling, Textured Splatting, Lattice Boltzmann
                 Model, Graphics Hardware",
}

@InProceedings{EVL-2002-341,
  title =        "Visualizing Dynamic Molecular Conformations",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "235--242",
  year =         "2002",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-341",
  author =       "Johannes Schmidt-Ehrenberg and Daniel Baum and
                 Hans-Christian Hege",
  abstract =     "The bioactivity of a molecule strongly depends on its
                 metastable conformational shapes and the transitions
                 between these. Therefore, conformation analysis and
                 visualization is a basic prerequisite for the
                 understanding of biochemical processes. We present
                 techniques for visual analysis of metastable molecular
                 conformations. Core of these are flexibly applicable
                 methods for alignment of molecular geometries, as well
                 as methods for depicting shape and fuzziness of
                 metastable conformations. All analysis tools are
                 provided in an integrated working environment. The
                 described techniques are demonstrated with
                 pharmaceutically active biomolecules.",
  organization = "IEEE Computer Society",
  keywords =     "Uncertainty visualization, molecular conformation
                 analysis, molecular modeling, drug design",
}

@InProceedings{EVL-2002-342,
  title =        "GeneVis: Visualization Tools for Genetic Regulatory
                 Network Dynamics",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "243--250",
  year =         "2002",
  author =       "C. A. H. Baker and M. S. T. Carpendale and P.
                 Prusinkiewicz and M. G. Surette",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-342",
  abstract =     "GeneVis provides a visual environment for exploring
                 the dynamics of genetic regulatory networks. At present
                 time, genetic regulation is the focus of intensive
                 research worldwide, and computational aids are being
                 called for to help in the research of factors that are
                 difficult to observe directly. GeneVis provides a
                 particle-based simulation of genetic networks and
                 visualizes the process of this simulation as it occurs.
                 Two dynamic visualization techniques are provided, a
                 visualization of the movement of the regulatory
                 proteins and a visualization of the relative
                 concentrations of these proteins. Several interactive
                 tools relate the dynamic visualizations to the
                 underlying genetic network structure.",
  organization = "IEEE Computer Society",
  keywords =     "Biological visualization, visualization,
                 multi-representation, genetic networks, lenses, focus,
                 context",
}

@InProceedings{EVL-2002-343,
  title =        "Isometric Embedding by Surface Reconstruction from
                 Distances",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "251--258",
  year =         "2002",
  author =       "Ingrid Hotz",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-343",
  abstract =     "To display the intuitive meaning of an abstract metric
                 it is helpful to look on an embedded surface with the
                 same inner geometry as the given metric. The resulting
                 partial differential equations have no standard
                 solution. Only for some special cases satisfactory
                 methods are known. I present a new algorithmic approach
                 which is not based on differential equations. In
                 contrast to other methods this technique also works if
                 the embedding exists only locally. The fundamental idea
                 is to estimate Euclidean distances, from which the
                 surface is built up. In this paper I focus on the
                 reconstruction of a surface from these estimated
                 distances. Particular the influence of a perturbation
                 of the distances on the shape of the resulting surface
                 is investigated.",
  organization = "IEEE Computer Society",
  keywords =     "Isometric embedding, metric, tensor fields.",
}

@InProceedings{EVL-2002-344,
  title =        "Fast View-Dependent Level-of-Detail Rendering Using
                 Cached Geometry",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "259--266",
  year =         "2002",
  author =       "Joshua Levenberg",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-344",
  abstract =     "Level-of-detail rendering is essential for rendering
                 very large, detailed worlds in real-time.
                 Unfortunately, level-of-detail computations can be
                 expensive, creating a bottleneck at the CPU. This paper
                 presents the CABTT algorithm, an extension to existing
                 binary-triangle-tree-based level-of-detail algorithms.
                 Instead of manipulating triangles, the CABTT algorithm
                 instead operates on clusters of geometry called
                 aggregate triangles. This reduces CPU overhead,
                 eliminating a bottleneck common to level-of-detail
                 algorithms. Since aggregate triangles stay fixed over
                 several frames, they may be cached on the video card.
                 This further reduces CPU load and fully utilizes the
                 hardware accelerated rendering pipeline on modern video
                 cards. These improvements result in a fourfold increase
                 in frame rate over ROAM [7] at high detail levels. Our
                 implementation renders an approximation of an 8 million
                 triangle heightfield at 42 frames per second with an
                 maximum error of 1 pixel on consumer hardware.",
  organization = "IEEE Computer Society",
  keywords =     "View-dependent mesh, level of detail, height fields,
                 terrain, binary triangle trees, triangle bintree,
                 multiresolution meshes, displacement maps,
                 frame-to-frame coherence",
}

@InProceedings{EVL-2002-345,
  title =        "Visibility-Guided Simplification",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "267--274",
  year =         "2002",
  author =       "Eugene Zhang and Greg Turk",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-345",
  abstract =     "For some graphics applications, object interiors and
                 hard-to-see regions contribute little to the final
                 images and need not be processed. In this paper, we
                 define a view-independent visibility measure on mesh
                 surfaces based on the visibility function between the
                 surfaces and a surrounding sphere of cameras. We
                 demonstrate the usefulness of this measure with a
                 visibility-guided simplification algorithm. Mesh
                 simplification reduces the polygon counts of 3D models
                 and speeds up the rendering process. Many mesh
                 simplification algorithms are based on sequences of
                 edge collapses that minimize geometric and attribute
                 errors. By combining the surface visibility measure
                 with a geometric error measure, we obtain simplified
                 models with improvement proportional to the amount of
                 low visibility regions in the original models.",
  organization = "IEEE Computer Society",
  keywords =     "Visualization, Visibility, Mesh Simplification,
                 Rendering",
}

@InProceedings{EVL-2002-346,
  title =        "Maximum Entropy Light Source Placement",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "275--282",
  year =         "2002",
  author =       "Stefan Gumhold",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-346",
  abstract =     "Finding the 'best' viewing parameters for a scene is
                 quite difficult but a very important problem. Fully
                 automatic procedures seem to be impossible as the
                 notion of 'best' strongly depends on the human judgment
                 as well as on the application. In this paper a solution
                 to the sub-problem of placing light sources for given
                 camera parameters is proposed. A light position is
                 defined to be optimal, when the resulting illumination
                 reveals more about the scene as the illuminations from
                 all other light positions, i.e. the light position
                 maximizes the information that is added to the image
                 through the illumination. With the help of an
                 experiment with several subjects we could adapt the
                 information measure to the actually perceived
                 information content. We present fast global
                 optimization procedures and solutions for two and more
                 light sources.",
  organization = "IEEE Computer Society",
  keywords =     "Lighting Design, Visualization, Illumination, Maximum
                 Entropy, Optimization, User Study",
}

@InProceedings{EVL-2002-347,
  title =        "Computing Singularities of 3{D} Vector Fields with
                 Geometric Algebra",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "283--290",
  year =         "2002",
  author =       "Stephen Mann and Alyn Rockwood",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-347",
  abstract =     "Critical points of a vector field are key to their
                 characterization. Not only their positions but also
                 their indexes are crucial for understanding vector
                 fields. Considerable work exists in 2D, but less is
                 available for 3D or higher dimensions. Geometric
                 Algebra is a derivative of Clifford Algebra that not
                 only enables a succinct definition of the index of a
                 critical point in higher dimension; it also provides
                 insight and computational pathways for calculating the
                 index. We describe the problems in terms of Geometric
                 Algebra and present an octree based solution using the
                 algebra for finding critical points and their index in
                 a 3D vector field.",
  organization = "IEEE Computer Society",
  keywords =     "Geometric Algebra, 3D Vector Fields, Singularities.",
}

@InProceedings{EVL-2002-348,
  title =        "Seamster: Inconspicuous Low-Distortion Texture Seam
                 Layout",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "291--298",
  year =         "2002",
  author =       "Alla Sheffer and John C. Hart",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-348",
  abstract =     "Surface texturing aids the visualization of polygonal
                 meshes by providing additional surface orientation cues
                 and feature annotations. Such texturing is usually
                 implemented via texture mapping, which is easier and
                 more effective when the distortion of the mapping from
                 the surface to the texture map is kept small. We have
                 previously shown that distortion occurs when areas of
                 high surface curvature are flattened into the texture
                 map. By cutting the surface in these areas one can
                 reduce texture map distortion at the expense of
                 additional seam artifacts. This paper describes a
                 faster technique for guiding a texture map seam through
                 high distortion regions, while restricting the seam to
                 regions of low visibility. This results in distortion
                 reducing seams that are less visually distracting and
                 take less time to compute. We have also observed that
                 visibility considerations improve the speed of a recent
                 method that adds cuts to reduce a surface genus.",
  organization = "IEEE Computer Society",
  keywords =     "Texture Mapping, Visibility Classification",
}

@InProceedings{EVL-2002-349,
  title =        "Face-based Luminance Matching for Perceptual Colormap
                 Generation",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "299--306",
  year =         "2002",
  author =       "Gordon Kindlmann and Erik Reinhard and Sarah Creem",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-349",
  abstract =     "Most systems used for creating and displaying
                 colormap-based visualizations are not photometrically
                 calibrated. That is, the relationship between RGB input
                 levels and perceived luminance is usually not known,
                 due to variations in the monitor, hardware
                 configuration, and the viewing environment. However,
                 the luminance component of perceptually based colormaps
                 should be controlled, due to the central role that
                 luminance plays in our visual processing. We address
                 this problem with a simple and effective method for
                 performing luminance matching on an uncalibrated
                 monitor. The method is akin to the minimally distinct
                 border technique (a previous method of luminance
                 matching used for measuring luminous efficiency), but
                 our method relies on the brain?s highly developed
                 ability to distinguish human faces. We present a user
                 study showing that our method produces equivalent
                 results to the minimally distinct border technique, but
                 with significantly improved precision. We demonstrate
                 how results from our luminance matching method can be
                 directly applied to create new univariate colormaps.",
  organization = "IEEE Computer Society",
  keywords =     "Colormaps, Color Scales, Isoluminance, Brightness
                 Matching, Perceptually-based Visualization",
}

@InProceedings{EVL-2002-35,
  year =         "2002",
  title =        "Weighted Multi-pass Method Based on Stochastic
                 Iteration and Random Walk Methods",
  author =       "G. Antal and L. Szirmay-Kalos and F. Csonka",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-35",
  abstract =     "Multipass algorithms implement different rendering
                 methods and combine their results. If carefully
                 implemented, these algorithms can keep the advantage of
                 individual methods. Algorithms for multipass global
                 illumination may handle disjoint parts of light
                 transport paths in different phases, and include all
                 light transport only once in the final solution. On the
                 other hand, they may also generate the same paths, thus
                 their contribution should be weighted in order to get
                 an unbiased estimation. In this paper a weighted
                 combination of global ray bundle iteration and path
                 tracing is presented. Heuristics for the weights are
                 derived to get the benefits from both approaches.
                 Results show significant improvements compared to both
                 ray bundle iteration and path tracing.",
  editor =       "V. Skala",
  keywords =     "Global illumination, stochastic iteration, multipass
                 algorithm",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-350,
  title =        "Geometric Verification of Features in Flow Fields",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "307--314",
  year =         "2002",
  author =       "Ming Jiang and Raghu Machiraju and David Thompson",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-350",
  abstract =     "In this paper, we present a verification algorithm for
                 swirling features in flow fields, based on the geometry
                 of streamlines. The features of interest in this case
                 are vortices. Without a formal definition, existing
                 detection algorithms lack the ability to accurately
                 identify these features, and the current method for
                 verifying the accuracy of their results is by human
                 visual inspection. Our verification algorithm addresses
                 this issue by automating the visual inspection process.
                 It is based on identifying the swirling streamlines
                 that surround the candidate vortex cores. We apply our
                 algorithm to both numerically simulated and
                 procedurally generated datasets to illustrate the
                 efficacy of our approach.",
  organization = "IEEE Computer Society",
  keywords =     "Feature verification, vortex detection, flow field
                 visualization.",
}

@InProceedings{EVL-2002-351,
  title =        "Comparative Evaluation of Visualization and
                 Experimental Results Using Image Comparison Metrics",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "315--322",
  year =         "2002",
  author =       "Hualin Zhou and Min Chen and Mike F. Webster",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-351",
  abstract =     "Comparative evaluation of visualization and experiment
                 results is a critical step in computational steering.
                 In this paper, we present a study of image comparison
                 metrics for quantifying the magnitude of difference
                 between a visualization of a computer simulation and a
                 photographic image captured from an experiment. We
                 examined eleven metrics, including three spatial
                 domain, four spatial-frequency domain and four HVS
                 (human-vision system) metrics. Among these metrics, a
                 spatial-frequency domain metric called 2nd-order
                 Fourier comparison was proposed specifically for this
                 work. Our study consisted of two stages: base cases and
                 field trials. The former is a general study on a
                 controlled comparison space using purposely selected
                 data, and the latter involves imagery results from
                 computational fluid dynamics and a rheological
                 experiment. This study has introduced a methodological
                 framework for analyzing image-level methods used in
                 comparative visualization. For the eleven metrics
                 considered, it has offered a set of informative
                 indicators as to the strengths and weaknesses of each
                 metric. In particular, we have identified three image
                 comparison metrics that are effective in separating
                 similar and different image groups. Our 2nd-order
                 Fourier comparison metric has compared favorably with
                 others in two of the three tests, and has shown its
                 potential to be used for steering computer simulation
                 quantitatively.",
  organization = "IEEE Computer Society",
  keywords =     "Image-based rendering, capture, reconstruction,
                 interactive, walkthrough.",
}

@InProceedings{EVL-2002-352,
  title =        "A Model for the Visualization Exploration Process",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "323--330",
  year =         "2002",
  author =       "T. J. Jankun-Kelly and Kwan-Liu Ma and Michael Gertz",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-352",
  abstract =     "The current state of the art in visualization research
                 places a strong emphasis on different techniques to
                 derive insight from disparate types of data. However,
                 little work has investigated the visualization process
                 itself. The information content of the visualization
                 process -- the results, history, and relationships
                 between those results -- is addressed by this work. A
                 characterization of the visualization process is
                 discussed, leading to a general model of the
                 visualization exploration process. The model, based
                 upon a new parameter derivation calculus, can be used
                 for automated reporting, analysis, or visualized
                 directly. An XML-based language for expressing
                 visualization sessions using the model is also
                 described. These sessions can then be shared and reused
                 by collaborators. The model, along with the XML
                 representation, provides an effective means to utilize
                 the information within the visualization process to
                 further data exploration.",
  organization = "IEEE Computer Society",
  keywords =     "Visualization process, visualization models,
                 visualization systems, scientific and information
                 visualization, collaboration, XML",
}

@InProceedings{EVL-2002-353,
  title =        "Sea of Images",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "331--338",
  year =         "2002",
  author =       "Daniel G. Aliaga and Thomas Funkhouser and Dimah
                 Yanovsky and Ingrid Carlbom",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-353",
  abstract =     "A long-standing research problem in computer graphics
                 is to reproduce the visual experience of walking
                 through a large photorealistic environment
                 interactively. On one hand, traditional geometry-based
                 rendering systems fall short of simulating the visual
                 realism of a complex environment. On the other hand,
                 image-based rendering systems have to date been unable
                 to capture and store a sampled representation of a
                 large environment with complex lighting and visibility
                 effects. In this paper, we present a 'Sea of Images', a
                 practical approach to dense sampling, storage, and
                 reconstruction of the plenoptic function in large,
                 complex indoor environments. We use a motorized cart to
                 capture omnidirectional images every few inches on a
                 eye-height plane throughout an environment. The
                 captured images are compressed and stored in a
                 multiresolution hierarchy suitable for real-time
                 prefetching during an interactive walkthrough. Later,
                 novel images are reconstructed for a simulated observer
                 by resampling nearby captured images. Our system
                 acquires 15,254 images over 1,050 square feet at an
                 average image spacing of 1.5 inches. The average
                 capture and processing time is 7 hours. We demonstrate
                 realistic walkthroughs of real-world environments
                 reproducing specular reflections and occlusion effects
                 while rendering 15-25 frames per second.",
  organization = "IEEE Computer Society",
  keywords =     "Image-based rendering, capture, reconstruction,
                 interactive, walkthrough.",
}

@InProceedings{EVL-2002-354,
  title =        "Scalable Alignment of Large-Format Multi-Projector
                 Displays Using Camera Homography Trees",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "339--346",
  year =         "2002",
  author =       "Han Chen and Rahul Sukthankar and Grant Wallace and
                 Kai Li",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-354",
  abstract =     "This paper presents a vision-based geometric alignment
                 system for aligning the projectors in an arbitrarily
                 large display wall. Existing algorithms typically rely
                 on a single camera view and degrade in accuracy as the
                 display resolution exceeds the camera resolution by
                 several orders of magnitude. Na{\..{i}}ve approaches to
                 integrating multiple zoomed camera views fail since
                 small errors in aligning adjacent views propagate
                 quickly over the display surface to create glaring
                 discontinuities. Our algorithm builds and refines a
                 camera homography tree to automatically register any
                 number of uncalibrated camera images; the resulting
                 system is both faster and significantly more accurate
                 than competing approaches, reliably achieving alignment
                 errors of 0.55 pixels on a 24-projector display in
                 under 9 minutes. Detailed experiments compare our
                 system to two recent display wall alignment algorithms,
                 both on our 18 Megapixel display wall and in
                 simulation. These results indicate that our approach
                 achieves sub-pixel accuracy even on dis-plays with
                 hundreds of projectors.",
  organization = "IEEE Computer Society",
  keywords =     "Large-format tiled projection display, display wall,
                 camera-projector systems, camera-based registration and
                 calibration, automatic alignment, scalability,
                 simulation, evaluation",
}

@InProceedings{EVL-2002-355,
  title =        "Efficient Compression and Rendering of
                 Multi-Resolution Meshes",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "347--354",
  year =         "2002",
  author =       "Zachi Karni and Alexander Bogomjakov and Craig
                 Gotsman",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-355",
  abstract =     "We present a method to code the multiresolution
                 structure of a 3D triangle mesh in a manner that allows
                 progressive decoding and efficient rendering at a
                 client machine. The code is based on a special ordering
                 of the mesh vertices which has good locality and
                 continuity properties, inducing a natural
                 multiresolution structure. This ordering also
                 incorporates information allowing efficient rendering
                 of the mesh at all resolutions using the contemporary
                 vertex buffer mechanism. The performance of our code is
                 shown to be competitive with existing progressive mesh
                 compression methods, while achieving superior rendering
                 speed.",
  organization = "IEEE Computer Society",
  keywords =     "Progressive compression, wavelets, geometry coding,
                 rendering",
}

@InProceedings{EVL-2002-356,
  title =        "Bounded-distortion Piecewise Mesh Parameterization",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "355--362",
  year =         "2002",
  author =       "lga Sorkine and Daniel Cohen-Or and Rony Goldenthal
                 and Dani Lischinski",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-356",
  abstract =     "Many computer graphics operations, such as texture
                 mapping, 3D painting, remeshing, mesh compression, and
                 digital geometry processing, require finding a
                 low-distortion parameterization for irregular
                 connectivity triangulations of arbitrary genus
                 2-manifolds. This paper presents a simple and fast
                 method for computing parameterizations with strictly
                 bounded distortion. The new method operates by
                 flattening the mesh onto a region of the 2D plane. To
                 comply with the distortion bound, the mesh is
                 automatically cut and partitioned on-the-fly. The
                 method guarantees avoiding global and local
                 self-intersections, while attempting to minimize the
                 total length of the introduced seams. To our knowledge,
                 this is the first method to compute the mesh
                 partitioning and the parameterization simultaneously
                 and entirely automatically, while providing guaranteed
                 distortion bounds. Our results on a variety of objects
                 demonstrate that the method is fast enough to work with
                 large complex irregular meshes in interactive
                 applications.",
  organization = "IEEE Computer Society",
  keywords =     "Atlas, mesh partitioning, parameterization, rface
                 flattening, texture mapping, 3D painting.",
}

@InProceedings{EVL-2002-357,
  title =        "{XF}astMesh: Fast View-dependent Meshing from External
                 Memory",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "363--370",
  year =         "2002",
  author =       "Christopher DeCoro and Renato Pajarola",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-357",
  abstract =     "We present a novel disk-based multiresolution triangle
                 mesh data structure that supports paging and
                 view-dependent rendering of very large meshes at
                 interactive frame rates from external memory. Our
                 approach, called XFastMesh, is based on a
                 view-dependent mesh simplification framework that
                 represents half-edge collapse operations in a binary
                 hierarchy known as a merge-tree forest. The proposed
                 technique partitions the merge-tree forest into
                 so-called detail blocks, which consist of binary
                 subtrees, that are stored on disk. We present an
                 efficient external memory data structure and file
                 format that stores all detail information of the
                 multiresolution triangulation method using
                 significantly less storage then previously reported
                 approaches. Furthermore, we present a paging algorithm
                 that provides efficient loading and interactive
                 rendering of large meshes from external memory at
                 varying and view-dependent level-of-detail. The
                 presented approach is highly efficient both in terms of
                 space cost and paging performance.",
  organization = "IEEE Computer Society",
  keywords =     "Level-of-detail, multiresolution modeling, out-of-core
                 rendering, interactive large-scale visualization.",
}

@InProceedings{EVL-2002-358,
  title =        "Case Study: Visual Debugging of Finite Element Codes",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "517--520",
  year =         "2002",
  author =       "Patricia Crossno and David H. Rogers and Christopher
                 J. Garasi",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-358",
  abstract =     "We present an innovative application developed at
                 Sandia National Laboratories for visual debugging of
                 unstructured finite element physics codes. Our tool
                 automatically locates anomalous regions, such as
                 inverted elements or nodes whose variable values lie
                 outside a prescribed range, then extracts mesh subsets
                 around these features for detailed examination. The
                 subsets are viewed using color coding of variable
                 values superimposed on the mesh structure. This allows
                 the values and their relative spatial locations within
                 the mesh to be correlated at a glance. Both topological
                 irregularities and hot spots within the data stand out
                 visually, allowing the user to explore the exact
                 numeric values of the grid at surrounding points over
                 time. We demonstrate the utility of this approach by
                 debugging a cell inversion in a simulation of an
                 exploding wire.",
  organization = "IEEE Computer Society",
  keywords =     "Visual debugging, parallel finite element codes and
                 simulation",
}

@InProceedings{EVL-2002-359,
  title =        "Case Study: Interactive Rendering of Adaptive Mesh
                 Refinement Data",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "521--524",
  year =         "2002",
  author =       "Sanghun Park and Chandrajit L. Bajaj and Vinay
                 Siddavanahalli",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-359",
  abstract =     "Adaptive mesh refinement (AMR) is a popular
                 computational simulation technique used in various
                 scientific and engineering fields. Although AMR data is
                 organized in a hierarchical multi-resolution data
                 structure, the traditional volume visualization
                 algorithms such as ray-casting and splatting cannot
                 handle the form without converting it to a
                 sophisticated data structure. In this paper, we present
                 a hierarchical multi-resolution splatting technique
                 using k-d trees and octrees for AMR data that is
                 suitable for implementation on the latest consumer PC
                 graphics hardware. We describe a graphical user
                 interface to set transfer function and viewing /
                 rendering parameters interactively. Experimental
                 results obtained on a general purpose PC equipped with
                 NVIDIA GeForce card are presented to demonstrate that
                 the technique can interactively render AMR data (over
                 20 frames per second). Our scheme can easily be applied
                 to parallel rendering of time-varying AMR data.",
  organization = "IEEE Computer Society",
  keywords =     "AMR, K-d trees, Octree, Hierarchical splatting,
                 Texture mapping",
}

@InProceedings{EVL-2002-36,
  year =         "2002",
  title =        "On Improving Kd Trees for Ray Shooting",
  author =       "V. Havran and L. Bittner",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-36",
  abstract =     "Efficient ray shooting algorithm is inherently
                 required by many computer graphics algorithms,
                 particularly in image synthesis. Practical ray shooting
                 algorithms aiming at the average-case complexity use
                 some underlying spatial data structure such as
                 $kd$-tree. We show the new termination criteria
                 algorithm that improves the space and time complexity
                 of the $kd$-tree construction. It provides efficient
                 ray-shooting queries and does not require any specific
                 constants from a user. Further, we show how to apply a
                 novel clipping algorithm into the $kd$-tree within
                 construction phase in order to improve its properties.
                 Keywords: ray shooting, ray casting, spatial data
                 structures, clipping, $kd$-tree.",
  editor =       "V. Skala",
  keywords =     "Ray shooting, ray casting, spatial data structures,
                 clipping, kd-tree",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-360,
  title =        "A Case Study in Selective Visualization of Unsteady
                 3{D} Flow",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "525--528",
  year =         "2002",
  author =       "Dirk Bauer and Ronald Peikert and Mie Sato and Mirjam
                 Sick",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-360",
  abstract =     "In this case study, we explore techniques for the
                 purpose of visualizing isolated flow structures in
                 time-dependent data. Our primary industrial application
                 is the visualization of the vortex rope, a rotating
                 helical structure which builds up in the draft tube of
                 a water turbine. The vortex rope can be characterized
                 by high values of normalized helicity, which is a
                 scalar field derived from the given CFD velocity data.
                 In two related applications, the goal is to visualize
                 the cavitation regions near the runner blades of a
                 Kaplan turbine and a water pump, respectively. Again,
                 the flow structure of interest can be defined by a
                 scalar field, namely by low pressure values. We propose
                 a particle seeding scheme based on quasi-random
                 numbers, which minimizes visual artifacts such as
                 clusters or patterns. By constraining the visualization
                 to a region of interest, occlusion problems are reduced
                 and storage efficiency is gained.",
  organization = "IEEE Computer Society",
  keywords =     "Flow Visualization, Feature Extraction, Particle
                 Tracing",
}

@InProceedings{EVL-2002-361,
  title =        "Case Study: Visualizing Ocean Flow Vertical Motions
                 using Lagrangian-Eulerian Time Surfaces",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "529--532",
  year =         "2002",
  author =       "Josh Grant and Gordon Erlebacher and James O'Brien",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-361",
  abstract =     "Ocean model simulations commonly assume the ocean is
                 hydrostatic, resulting in near zero vertical motion.
                 The vertical motion found is typically associated with
                 the variations of the thermocline depth over time,
                 which are mainly a result of the development and
                 movement of ocean fronts, eddies, and internal waves. A
                 new technique, extended from Lagrangian-Eulerian
                 Advection, is presented to help understand the
                 variation of vertical motion associated with the change
                 in thermocline depth over time. A time surface is
                 correctly deformed in a single direction according to
                 the flow. The evolution of the time surface is computed
                 via a mixture of Eulerian and Lagrangian techniques.
                 The dominant horizontal motion is textured onto the
                 surface using texture advection, while both the
                 horizontal and vertical motions are used to displace
                 the surface. The resulting surface is shaded for
                 enhanced contrast. Timings indicate that the overhead
                 over standard 2D texture advection is no more than
                 12%.",
  organization = "IEEE Computer Society",
  keywords =     "Unsteady vector fields, time surfaces, ocean currents,
                 vertical velocity",
}

@InProceedings{EVL-2002-362,
  title =        "A Case Study on Multiresolution Visualization of Local
                 Rainfall from Weather Radar Measurements",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "533--536",
  year =         "2002",
  author =       "Thomas Gerstner and Dirk Meetschen and Susanne Crewell
                 and Michael Griebel and Clemens Simmer",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-362",
  abstract =     "Weather radars can measure the backscatter from rain
                 drops in the atmosphere. A complete radar scan provides
                 three-dimensional precipitation information. For the
                 understanding of the underlying atmospheric processes
                 interactive visualization of these data sets is
                 necessary. This is a challenging task due to the size,
                 structure and required context of the data. In this
                 case study, a multiresolution approach for real-time
                 simultaneous visualization of radar measurements
                 together with the corresponding terrain data is
                 illustrated.",
  organization = "IEEE Computer Society",
  keywords =     "Triangular and tetrahedral grid refinement,
                 multiresolution isosurface extraction,
                 level-of-detail.",
}

@InProceedings{EVL-2002-363,
  title =        "Rendering The First Star In The Universe - {A} Case
                 Study",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "537--540",
  year =         "2002",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-363",
  author =       "Ralf K{\"a}hler and Donna Cox and Robert Patterson and
                 uart Levy and Hans-Christian Hege and Tom Abel",
  abstract =     "For quantitative examination of phenomena that
                 simultaneously occur on very different spatial and
                 temporal scales, adaptive hierarchical schemes are
                 required. A special numerical multilevel technique,
                 associated with a particular hierarchical data
                 structure, is so-called Adaptive Mesh Refinement (AMR).
                 It allows one to bridge a wide range of spatial and
                 temporal resolutions and therefore gains increasing
                 popularity. We describe the interplay of several
                 visualization and VR software packages for rendering
                 time dependent AMR simulations of the evolution of the
                 first star in the universe. The work was done in the
                 framework of a television production for DISCOVERY
                 CHANNEL TELEVISION, The Unfolding Universe. Parts of
                 the data were taken from one of the most complex AMR
                 simulation ever carried out: It contained up to 27
                 levels of resolution, requiring modifications to the
                 texture based AMR volume rendering algorithm that was
                 used to depict the density distribution of the gaseous
                 interstellar matter. A voice and gesture controlled
                 CAVE application was utilized to define camera paths
                 following the interesting features deep inside the
                 computational domains. Background images created from
                 cosmological computational data were combined with the
                 final renderings.",
  organization = "IEEE Computer Society",
  keywords =     "3D texture based volume rendering, adaptive mesh
                 refinement data, CAVE applications, data
                 visualization.",
}

@InProceedings{EVL-2002-364,
  title =        "{NASA}'s Great Zooms: {A} Case Study",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "541--544",
  year =         "2002",
  author =       "Gregory W. Shirah and Horace G. Mitchell",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-364",
  abstract =     "This paper examines a series of NASA outreach
                 visualizations created using several layers of remote
                 sensing satellite data ranging from 4-kilometers per
                 pixel to 1-meter per pixel. The viewer is taken on a
                 seamless, cloud free journey from a global view of the
                 Earth down to ground level where buildings, streets,
                 and cars are visible. The visualizations were produced
                 using a procedural shader that takes advantage of
                 accurate georegistration and color matching between
                 images. The shader accurately and efficiently maps the
                 data sets to geometry allowing for animations with few
                 perceptual transitions among data sets. We developed a
                 pipeline to facilitate the production of over twenty
                 zoom visualizations. Millions of people have seen these
                 visualizations through national and international media
                 coverage.",
  organization = "IEEE Computer Society",
  keywords =     "Visualization, remote sensing, renderman, shader,
                 georegistration, color matching.",
}

@InProceedings{EVL-2002-365,
  title =        "A Case Study on Automatic Camera Placement and Motion
                 for Visualizing Historical Data",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "545--548",
  year =         "2002",
  author =       "Stanislav L. Stoev and Wolfgang Stra{\ss}er",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-365",
  abstract =     "In this paper, we address the problem of automatic
                 camera positioning and automatic camera path generation
                 in the context of historical data visualization. After
                 short description of the given data, we elaborate on
                 the constraints for the positioning of a virtual camera
                 in such a way that not only the projected area is
                 maximized, but also the depth of the displayed scene.
                 This is especially important when displaying terrain
                 models, which do not provide good 3D impression when
                 only the projected area is maximized. Based on this
                 concept, we present a method for computing an optimal
                 camera position for each instant of time. Since the
                 explored data are not static, but change depending on
                 the explored scene time, we also discuss a method for
                 animation generation. In order to avoid sudden changes
                 of the camera position, when the previous method is
                 applied for each frame (point in time), we introduce
                 pseudo-events in time, which expand the bounding box
                 defined by the currently active events of interest. In
                 particular, this technique allows events happening in a
                 future point in time to be taken into account such that
                 when this time becomes current, all events of interest
                 are already within the current viewing frustum of the
                 camera.",
  organization = "IEEE Computer Society",
  keywords =     "Automatic Camera Control, Visualization, Historical
                 Data; Time-dependent Data, Visualization Techniques",
}

@InProceedings{EVL-2002-366,
  title =        "Tensor Field Visualisation using Adaptive Filtering of
                 Noise Fields combined with Glyph Rendering",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "371--378",
  year =         "2002",
  author =       "Andreas Sigfridsson and Tino Ebbers and Einar Heiberg
                 and Lars Wigstr{\"o}m",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-366",
  abstract =     "While many methods exist for visualising scalar and
                 vector data, visualisation of tensor data is still
                 troublesome. We present a method for visualising second
                 order tensors in three dimensions using a hybrid
                 between direct volume rendering and glyph rendering. An
                 overview scalar field is created by using
                 three-dimensional adaptive filtering of a scalar field
                 containing noise. The filtering process is controlled
                 by the tensor field to be visualised, creating patterns
                 that characterise the tensor field. By combining direct
                 volume rendering of the scalar field with standard
                 glyph rendering methods for detailed tensor
                 visualisation, a hybrid solution is created. A combined
                 volume and glyph renderer was implemented and tested
                 with both synthetic tensors and strain-rate tensors
                 from the human heart muscle, calculated from phase
                 contrast magnetic resonance image data. A
                 comprehensible result could be obtained, giving both an
                 overview of the tensor field as well as detailed
                 information on individual tensors.",
  organization = "IEEE Computer Society",
  keywords =     "Tensor, Visualisation, Volume rendering, Glyph
                 rendering, Hybrid rendering, Strain-rate",
}

@InProceedings{EVL-2002-367,
  title =        "Volume Deformation For Tensor Visualization",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "379--386",
  year =         "2002",
  author =       "Xiaoqiang Zheng and Alex Pang",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-367",
  abstract =     "Visualizing second-order 3D tensor fields continue to
                 be a challenging task. Although there are several
                 algorithms that have been presented, no single
                 algorithm by itself is sufficient for the analysis
                 because of the complex nature of tensor fields. In this
                 paper, we present two new methods, based on volume
                 deformation, to show the effects of the tensor field
                 upon its underlying media. We focus on providing a
                 continuous representation of the nature of the tensor
                 fields. Each of these visualization algorithms is good
                 at displaying some particular properties of the tensor
                 field.",
  organization = "IEEE Computer Society",
  keywords =     "Stress, strain, shear, symmetric tensors,
                 anti-symmetric tensors, anisotropic tensors",
}

@InProceedings{EVL-2002-368,
  title =        "Oriented Tensor Reconstruction: Tracing Neural
                 Pathways from Diffusion Tensor {MRI}",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "387--394",
  year =         "2002",
  author =       "Leonid Zhukov and Alan H. Barr",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-368",
  abstract =     "In this paper we develop a new technique for tracing
                 anatomical fibers from 3D tensor fields. The technique
                 extracts salient tensor features using a local
                 regularization technique that allows the algorithm to
                 cross noisy regions and bridge gaps in the data. We
                 applied the method to human brain DT-MRI data and
                 recovered identifiable anatomical structures that
                 correspond to the white matter brain-fiber pathways.
                 The images in this paper are derived from a dataset
                 having 121 x x resolution. We were able to recover
                 fibers with less than the voxel size resolution by
                 applying the regularization technique, i.e., using a
                 priori assumptions about fiber smoothness. The
                 regularization procedure is done through a moving least
                 squares filter directly incorporated in the tracing
                 algorithm.",
  organization = "IEEE Computer Society",
  keywords =     "Diffusion tensors, adaptive filtering, moving least
                 squares, streamlines, fiber tracing, pathways, salient
                 features",
}

@InProceedings{EVL-2002-369,
  title =        "Quad{TIN}: Quadtree based Triangulated Irregular
                 Networks",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "395--402",
  year =         "2002",
  author =       "Renato Pajarola and Marc Antonijuan and Roberto
                 Lario",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-369",
  abstract =     "Interactive visualization of large digital elevation
                 models is of continuing interest in scientific
                 visualization, GIS, and virtual reality applications.
                 Taking advantage of the regular structure of grid
                 digital elevation models, efficient hierarchical
                 multiresolution triangulation and adaptive
                 level-of-detail (LOD) rendering algorithms have been
                 developed for interactive terrain visualization.
                 Despite the higher triangle count, these approaches
                 generally outperform mesh simplification methods that
                 produce irregular triangulated network (TIN) based LOD
                 representations. In this project we combine the
                 advantage of a TIN based mesh simplification preprocess
                 with high-performance quadtree based LOD triangulation
                 and rendering at run-time. This approach, called
                 QuadTIN, generates an efficient quadtree triangulation
                 hierarchy over any irregular point set that may
                 originate from irregular terrain sampling or from
                 reducing oversampling in high-resolution grid digital
                 elevation models.",
  organization = "IEEE Computer Society",
  keywords =     "Multiresolution triangulation, real-time terrain
                 visualization, triangulated irregular networks,
                 level-of-detail.",
}

@InProceedings{EVL-2002-37,
  year =         "2002",
  title =        "Enhanced Vector Field Visualization by Local Contrast
                 Analysis",
  author =       "A. Sanna and B. Montrucchio and C. Zunino and P.
                 Montuschi",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-37",
  abstract =     "Visualizing vector fields is one of the most important
                 and attractive research areas in scientific
                 visualization. Several techniques are known in the
                 literature; some traditional approaches use 2D/3D
                 arrows or particle traces, while other methodologies
                 display vector fields by dense or sparse textures. This
                 paper focuses on the clustering problem arising for
                 dense texture algorithms where some low contrast areas
                 can appear in images thus reducing the capability of
                 investigating flow details. The proposed method assigns
                 pixel colors according to a local contrast analysis
                 phase. In this way streamlines denoting flow
                 characteristics are always well distinguishable.",
  editor =       "V. Skala",
  keywords =     "Vector field visualization, scientific visualization,
                 texture based algorithms, LIC, local contrast",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-370,
  title =        "Horizon Occlusion Culling for Real-time Rendering of
                 Hierarchical Terrains",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "403--410",
  year =         "2002",
  author =       "Brandon Lloyd and Parris Egbert",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-370",
  abstract =     "We present a technique to perform occlusion culling
                 for hierarchical terrains at run-time. The algorithm is
                 simple to implement and requires minimal pre-processing
                 and additional storage, yet leads to 2-4 times
                 improvement in framerate for views with high degrees of
                 occlusion. Our method is based on the well-known
                 occlusion horizon algorithm. We show how to adapt the
                 algorithm for use with hierarchical terrains. The
                 occlusion horizon is constructed as the terrain is
                 traversed in an approximate front to back ordering.
                 Regions of the terrain are compared to the horizon to
                 determine when they are completely occluded from the
                 viewpoint. Culling these regions leads to significant
                 savings in rendering.",
  organization = "IEEE Computer Society",
  keywords =     "Rendering algorithms, visibility, occlusion culling.",
}

@InProceedings{EVL-2002-371,
  title =        "Evaluation of a Multimodal Interface for 3{D} Terrain
                 Visualization",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "411--418",
  year =         "2002",
  author =       "David M. Krum and Olugbenga Omoteso and William
                 Ribarsky and Thad Starner and Larry F. Hodges",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-371",
  abstract =     "Novel speech and/or gesture interfaces are candidates
                 for use in future mobile or ubiquitous applications.
                 This paper describes an evaluation of various
                 interfaces for visual navigation of a whole Earth 3D
                 terrain model. A mouse driven interface, a speech
                 interface, a gesture interface, and a multimodal speech
                 and gesture interface were used to navigate to targets
                 placed at various points on the Earth. This study
                 measured each participant?s recall of target identity,
                 order, and location as a measure of cognitive load.
                 Timing information as well as a variety of subjective
                 measures including discomfort and user preference were
                 taken. While the familiar and mature mouse interface
                 scored best by most measures, the speech interface also
                 performed well. The gesture and multimodal interface
                 suffered from weaknesses in the gesture modality.
                 Weaknesses in the speech and multimodal modalities are
                 identified and areas for improvement are discussed.",
  organization = "IEEE Computer Society",
  keywords =     "Multimodal interaction, evaluation, navigation, speech
                 recognition, gesture recognition, virtual reality,
                 mobile visualization, GIS.",
}

@InProceedings{EVL-2002-372,
  title =        "Assisted Navigation of Complex Information Spaces",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "419--426",
  year =         "2002",
  author =       "Brent M. Dennis and Christopher G. Healey",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-372",
  abstract =     "This paper presents a new technique for visualizing
                 large, complex collections of data. The size and
                 dimensionality of these datasets make them challenging
                 to display in an effective manner. The images must show
                 the global structure of spatial relationships within
                 the dataset, yet at the same time accurately represent
                 the local detail of each data element being visualized.
                 We propose combining ideas from information and
                 scientific visualization together with a navigation
                 assistant, a software system designed to help users
                 identify and explore areas of interest within their
                 data. The assistant locates data elements of potential
                 importance to the user, clusters them into spatial
                 regions, and builds underlying graph structures to
                 connect the regions and the elements they contain.
                 Graph traversal algorithms, constraint-based viewpoint
                 construction, and intelligent camera planning
                 techniques can then be used to design animated tours of
                 these regions. In this way, the navigation assistant
                 can help users to explore any of the areas of interest
                 within their data. We conclude by demonstrating how our
                 assistant is being used to visualize a multidimensional
                 weather dataset.",
  organization = "IEEE Computer Society",
  keywords =     "Camera planning, information visualization,
                 multidimensional visualization, navigation, scientific
                 visualization.",
}

@InProceedings{EVL-2002-373,
  title =        "Kinetic Visualization - {A} Technique for Illustrating
                 3{D} Shape and Structure",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "435--442",
  year =         "2002",
  author =       "Eric B. Lum and Aleksander Stompel and Kwan-Liu Ma",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-373",
  abstract =     "Motion provides strong visual cues for the perception
                 of shape and depth, as demonstrated by cognitive
                 scientists and visual artists. This paper presents a
                 novel visualization technique -- kinetic visualization
                 -- that uses particle systems to add supplemental
                 motion cues which can aid in the perception of shape
                 and spatial relationships of static objects. Based on a
                 set of rules following perceptual and physical
                 principles, particles flowing over the surface of an
                 object not only bring out, but also attract attention
                 to, essential information on the shape of the object
                 that might not be readily visible with conventional
                 rendering that uses lighting and view changes.
                 Replacing still images with animations in this fashion,
                 we demonstrate with both surface and volumetric models
                 in the accompanying videos that in many cases the
                 resulting visualizations effectively enhance the
                 perception of three-dimensional shape and structure.
                 The results of a preliminary user study that we have
                 conducted also show evidence that the supplemental
                 motion cues help.",
  organization = "IEEE Computer Society",
  keywords =     "Aimation, visual perception, particle systems,
                 scientific visualization, volume rendering.",
}

@InProceedings{EVL-2002-374,
  title =        "A Radial Focus+Context Visualization for
                 Multi-Dimensional Functions",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "443--450",
  year =         "2002",
  author =       "njini Jayaraman and Chris North",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-374",
  abstract =     "The analysis of multidimensional functions is
                 important in many engineering disciplines, and poses a
                 major problem as the number of dimensions increases.
                 Previous visualization approaches focus on representing
                 three or fewer dimensions at a time. This paper
                 presents a new focus+context visualization that
                 provides an integrated overview of an entire
                 multidimensional function space, with uniform treatment
                 of all dimensions. The overview is displayed with
                 respect to a user-controlled polar focal point in the
                 function?s parameter space. Function value patterns are
                 viewed along rays that emanate from the focal point in
                 all directions in the parameter space, and represented
                 radially around the focal point in the visualization.
                 Data near the focal point receives proportionally more
                 screen space than distant data. This approach scales
                 smoothly from two dimensions to 10-20, with a 1000
                 pixel range on each dimension.",
  organization = "IEEE Computer Society",
  keywords =     "Visualization, multidimensional functions.",
}

@InProceedings{EVL-2002-375,
  pages =        "427--434",
  year =         "2002",
  title =        "{BM3D}: motion estimation in time dependent volume
                 data",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-375",
  author =       "Willem de Leeuw and Robert van Liere",
  organization = "IEEE Computer Society",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
}

@InProceedings{EVL-2002-376,
  title =        "{BLIC}: Bi-Level Isosurface Compression",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "451--458",
  year =         "2002",
  author =       "Gabriel Taubin",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-376",
  abstract =     "In this paper we introduce a new and simple algorithm
                 to compress isosurface data. This is the data extracted
                 by isosurface algorithms from scalar functions defined
                 on volume grids, and used to generate polygon meshes or
                 alternative representations. In this algorithm the mesh
                 connectivity and a substantial proportion of the
                 geometric information are encoded to a fraction of a
                 bit per Marching Cubes vertex with a context based
                 arithmetic coder closely related to the JBIG binary
                 image compression standard. The remaining optional
                 geometric information that specifies the location of
                 each Marching Cubes vertex more precisely along its
                 supporting intersecting grid edge, is efficiently
                 encoded in scan-order with the same mechanism. Vertex
                 normals can optionally be computed as normalized
                 gradient vectors by the encoder and included in the
                 bitstream after quantization and entropy encoding, or
                 computed by the decoder in a postprocessing smoothing
                 step. These choices are determined by trade-offs
                 associated with an in-core vs. out-of-core decoder
                 structure. The main features of our algorithm are its
                 extreme simplicity and high compression rates.",
  organization = "IEEE Computer Society",
  keywords =     "3D Geometry Compression, Algorithms, Graphics.",
}

@InProceedings{EVL-2002-377,
  title =        "Approximating Normals for Marching Cubes applied to
                 Locally Supported Isosurfaces",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "459--466",
  year =         "2002",
  author =       "Gregory M. Nielson and Adam Huang and Steve
                 Sylvester",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-377",
  abstract =     "We present some new methods for computing estimates of
                 normal vectors at the vertices of a triangular mesh
                 surface approximation to an isosurface which has been
                 computed by the marching cube algorithm. These
                 estimates are required for the smooth rendering of
                 triangular mesh surfaces. The conventional method of
                 computing estimates based upon divided difference
                 approximations of the gradient can lead to poor
                 estimates in some applications. This is particularly
                 true for isosurfaces obtained from a field function,
                 which is defined only for values near to the
                 isosurface. We describe some efficient methods for
                 computing the topology of the triangular mesh surface,
                 which is used for obtaining local estimates of the
                 normals. In addition, a new, one pass, approach for
                 these types of applications is described and compared
                 to existing methods.",
  organization = "IEEE Computer Society",
  keywords =     "Isosurface, normal vectors, marching cubes, triangular
                 mesh, topology, Gouraud shading, approximation.",
}

@InProceedings{EVL-2002-378,
  title =        "Volume Warping for Adaptive Isosurface Extraction",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "467--474",
  year =         "2002",
  author =       "Laurent Balmelli and Christopher J. Morris and Gabriel
                 Taubin and Fausto Bernardini",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-378",
  abstract =     "Polygonal approximations of isosurfaces extracted from
                 uniformly sampled volumes are increasing in size due to
                 the availability of higher resolution imaging
                 techniques. The large number of primitives represented
                 hinders the interactive exploration of the dataset.
                 Though many solutions have been proposed to this
                 problem, many require the creation of isosurfaces at
                 multiple resolutions or the use of additional data
                 structures, often hierarchical, to represent the
                 volume. We propose a technique for adaptive isosurface
                 extraction that is easy to implement and allows the
                 user to decide the degree of adaptivity as well as the
                 choice of isosurface extraction algorithm. Our method
                 optimizes the extraction of the isosurface by warping
                 the volume. In a warped volume, areas of importance
                 (e.g. containing significant details) are inflated
                 while unimportant ones are contracted. Once the volume
                 is warped, any extraction algorithm can be applied. The
                 extracted mesh is subsequently unwarped such that the
                 warped areas are rescaled to their initial proportions.
                 The resulting isosurface is represented by a mesh that
                 is more densely sampled in regions decided as
                 important.",
  organization = "IEEE Computer Society",
  keywords =     "Isosurfaces, adaptive isosurface extraction, volume
                 warping, adaptive tessellation",
}

@InProceedings{EVL-2002-379,
  title =        "Interactive View-Dependent Rendering of Large
                 IsoSurfaces",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "475--484",
  year =         "2002",
  author =       "Benjamin Gregorski and Mark Duchaineau and Peter
                 Lindstrom and Valerio Pascucci and Kenneth I. Joy",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-379",
  abstract =     "We present an algorithm for interactively extracting
                 and rendering isosurfaces of large volume datasets in a
                 view-dependent fashion. A recursive tetrahedral mesh
                 refinement scheme, based on longest edge bisection, is
                 used to hierarchically decompose the data into a
                 multiresolution structure. This data structure allows
                 fast extraction of arbitrary isosurfaces to within user
                 specified view-dependent error bounds. A data layout
                 scheme based on hierarchical space filling curves
                 provides access to the data in a cache coherent manner
                 that follows the data access pattern indicated by the
                 mesh refinement.",
  organization = "IEEE Computer Society",
  keywords =     "View-Dependent Rendering, Isosurfaces, Multiresolution
                 Tetrahedral Meshes, Multiresolution Techniques",
}

@InProceedings{EVL-2002-38,
  year =         "2002",
  title =        "Ray Tracing for Curves Primitive",
  author =       "K. Nakamaru and Y. Uhno",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-38",
  abstract =     "The Curves primitive defined in RenderMan is useful
                 for modelling and rendering ribbonlike objects. This
                 paper gives a simple framework for ray-curve
                 intersection tests in ray tracing, and provides
                 concrete details for one form of the primitive. The
                 form is especially important for fine objects such as
                 hair and fur.",
  editor =       "V. Skala",
  keywords =     "Ray tracing, curve, renderman, hair, fur",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-380,
  title =        "Case Study on the Adaptation of Interactive
                 Visualization Applications to Web-Based Production for
                 Operational Mesoscale Weather Models",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "549--552",
  year =         "2002",
  author =       "Lloyd A. Treinish",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-380",
  abstract =     "Visualization is required for the effective
                 utilization of data from a weather simulation.
                 Appropriate mapping of user goals to the design of
                 pictorial content has been useful in the development of
                 interactive applications with sufficient bandwidth for
                 timely access to the model data. When remote access to
                 the model visualizations is required the limited
                 bandwidth becomes the primary bottleneck. To help
                 address these problems, visualizations are presented on
                 a web page as a meta-representation of the model output
                 and serve as an index to simplify finding other
                 visualizations of relevance. To provide consistency
                 with extant interactive products and to leverage their
                 cost of development, the aforementioned applications
                 are adapted to automatically populate a web site with
                 images and interactions for an operational weather
                 forecasting system.",
  organization = "IEEE Computer Society",
  keywords =     "Visualization, meteorology, world-wide-web",
}

@InProceedings{EVL-2002-381,
  title =        "Exploring Surface Characteristics with Interactive
                 Gaussian Images ({A} Case Study)",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "553--556",
  year =         "2002",
  author =       "Bradley Lowekamp and Penny Rheingans and Terry S.
                 Yoo",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-381",
  abstract =     "The Gauss map projects surface normals to a unit
                 sphere, providing a powerful visualization of the
                 geometry of a graphical object. It can be used to
                 predict visual events caused by changes in lighting,
                 shading, and camera control. We present an interactive
                 technique for portraying the Gauss map of polygonal
                 models, mapping surface normals and the magnitudes of
                 surface curvature using a spherical projection. Unlike
                 other visualizations of surface curvature, we create
                 our Gauss map directly from polygonal meshes without
                 requiring any complex intermediate calculations of
                 differential geometry. For anything other than simple
                 shapes, surface information is densely mapped into the
                 Gaussian normal image, inviting the use of
                 visualization techniques to amplify and emphasize
                 details hidden within the wealth of data. We present
                 the use of interactive visualization tools such as
                 brushing and linking to explore the surface properties
                 of solid shapes. The Gauss map is shown to be simple to
                 compute, easy to view dynamically, and effective at
                 portraying important features of polygonal models.",
  organization = "IEEE Computer Society",
  keywords =     "Computational Geometry, Gauss map, Illumination and
                 shading, Interactive visualization",
}

@InProceedings{EVL-2002-382,
  title =        "A Case Study On The Applications Of {A} Generic
                 Library For Low-Cost Polychromatic Passive Stereo",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "557--560",
  year =         "2002",
  author =       "Simon Stegmaier and Dirc Rose and Thomas Ertl",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-382",
  abstract =     "Active stereo has been used by engineers and
                 industrial designers for several years to enhance the
                 perception of computer generated three-dimensional
                 images. Unfortunately, active stereo requires
                 specialized hardware. Therefore, as ubiquitous
                 computing and teleworking gain importance, using active
                 stereo becomes a problem. The goal of this case study
                 is to examine the concept of a generic library for
                 polychromatic passive stereo to make stereo vision
                 available everywhere.",
  organization = "IEEE Computer Society",
  keywords =     "Stereo Graphics, OpenGL, Preloading",
}

@InProceedings{EVL-2002-383,
  title =        "Case Study: 'The Office of Real Soon Now' for
                 Visualization",
  month =        oct,
  editor =       "Robert J. Moorhead and Markus Gross and Kenneth I.
                 Joy",
  booktitle =    "Proceedings of IEEE Visualization 2002",
  publisher =    "IEEE Computer Society Press",
  pages =        "561--567",
  year =         "2002",
  author =       "Samuel P. Uselton",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-383",
  abstract =     "As part of a larger effort exploring alternative
                 display systems, Lawrence Livermore National Laboratory
                 has installed systems in two offices that extend and
                 update the previously described Office of Real Soon Now
                 project to improve the value for visualization tasks.
                 These new systems use higher resolution projectors
                 driven by workstations that run Unix-based applications
                 via Linux and support hardware-accelerated 3D graphics,
                 even across the boundary between displays.",
  organization = "IEEE Computer Society",
  keywords =     "Display, projection, panoramic image display",
}

@InCollection{EVL-2002-384,
  pages =        "207--217",
  year =         "2002",
  title =        "Exploiting the Hessian matrix for content-based
                 retrieval of volume-data features",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-384",
  author =       "J. Hlad{\u{u}}vka and E. Gr{\"{o}}ller",
  abstract =     "We propose an algorithm for content-based retrieval of
                 representative subsets of volume data. Our technique is
                 based on thresholding of the eigenvalues of the Hessian
                 matrix. We compare our approach to feature detection
                 based on the gradient magnitude and observe that our
                 method allows the representation of volumes by a
                 smaller amount of voxels. Practical applications of our
                 method include fast volume display due to object-space
                 oriented techniques, generation of preview data sets
                 for web-based repositories, and the related progressive
                 visualization over the network. For these applications,
                 the size of the representative subset can be estimated
                 automatically with respect to the bottleneck of the
                 visualization system or a network bandwidth.",
  month =        jun,
  keywords =     "Volume visualization, sparse data, gradient, Hessian
                 matrix, Eigensystem",
  volume =       "18(4)",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-385,
  pages =        "218--225",
  year =         "2002",
  title =        "Transformation of dynamic facial image sequences using
                 static 2{D} prototypes",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-385",
  author =       "B. Tiddeman and D. Perrett",
  abstract =     "This paper describes a new method for creating
                 visually realistic moving facial image sequences that
                 retain an actor's personality (individuality,
                 expression and characteristic movements) while altering
                 the facial appearance along a certain specified facial
                 dimension. We combine two existing technologies, facial
                 feature tracking and facial image transformation, to
                 create the sequences. Examples are given of
                 transforming the apparent age, ethnic appearance and
                 gender of a face. We also create 'virtual cartoons' by
                 transforming image sequences into the style of famous
                 artists. The results show that static 2D face models
                 can be used to create realistic transformations of
                 sequences that include changes in pose, expression and
                 mouth shape.",
  month =        jun,
  keywords =     "Facial image transformation, Image processing.",
  volume =       "18(4)",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-386,
  pages =        "226--235",
  year =         "2002",
  title =        "Hypertexturing complex volume objects",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-386",
  author =       "Richard Satherley and Mark W. Jones",
  abstract =     "This paper will examine hypertexture rendering
                 techniques and will demonstrate how volume data sets
                 may be adapted in order for hypertexture to be applied.
                 Details are given of a process for the conversion of
                 complex objects, such as CT scans, into accurate
                 distance fields. Hypertexture is applied to these
                 objects and example renderings include the UNC CThead,
                 a chess piece, a dodecahedron and a tank. Additional
                 information is given about soft objects, density
                 modulation functions, ray marching and controlling
                 hypertexture application.",
  month =        jun,
  keywords =     "Hypertexture, Distance transform, Distance field.",
  volume =       "18(4)",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-387,
  pages =        "236--249",
  year =         "2002",
  title =        "Visualization and pre-processing of independent
                 finite-element meshes for car crash simulations",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-387",
  author =       "N. Frisch and D. Rose and O. Sommer and et al.",
  abstract =     "The recent transition from meshing the whole model to
                 the independent meshing of the assembly parts
                 introduced new challenges in the task of visualizing
                 and pre-processing the finite-element meshes. One part
                 of our work is the visualization and removal of mesh
                 penetrations and perforations, a frequently encountered
                 problem when assembly parts are meshed independently.
                 Furthermore, we focus on the visualization and the
                 interactive definition of mesh-independent connections
                 between car components represented by finite-element
                 meshes. We present methods to automatize the flange
                 recognition, as connections are usually placed along
                 flanges. There are basically three types of connections
                 to visualize and edit: point links, line links and
                 surface links.",
  month =        jun,
  keywords =     "Visualization, crash simulation, finite elements,
                 pre-processing, CAD",
  volume =       "18(4)",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-388,
  pages =        "250--258",
  year =         "2002",
  title =        "General relativistic image-based rendering",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-388",
  author =       "Daniel Kobras and Daniel Weiskopf and Hanns Ruder",
  abstract =     "Imaged-based rendering is a well-known method in
                 computer graphics to achieve photo-realistic images. In
                 this paper we show how conventional image-based
                 rendering algorithms can be extended to visualize
                 general relativistic effects in a restricted class of
                 spacetimes. We propose a generalized aberration formula
                 in order to treat the visualization of special and
                 general relativistic effects on the same footing. In
                 this way, image-based general relativistic rendering
                 can be regarded as an extension of special relativistic
                 rendering. As an example, we present snapshots from the
                 viewpoint of an observer traveling at warp speed.",
  month =        jun,
  keywords =     "General relativity, image-based endering, scientific
                 visualization, warp metric",
  volume =       "18(4)",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-389,
  pages =        "259--272",
  year =         "2002",
  title =        "Taxonomy of interpolation constraints on cursive
                 subdivision curves",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-389",
  author =       "Ahmad H. Nasri and Malcolm A. Sabin",
  abstract =     "This paper is the first of two, which together
                 describe and classify the various situations that any
                 complete study of interpolation constraints for a
                 recursive subdivision surface needs to consider. They
                 do so in the form of a systematic taxonomy of
                 situations. Presented here are curve cases, which
                 provide good illustrations of principles which will be
                 used in both contexts; surfaces will be addressed in
                 the second paper. Known results are classified and open
                 questions identified.",
  month =        jun,
  keywords =     "Recursive subdivision, interpolation constraints, end
                 control, points, target directions, B-spline curves,
                 B{\'{e}}zier.",
  volume =       "18(4)",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InProceedings{EVL-2002-39,
  year =         "2002",
  title =        "Layered Relief Textures",
  author =       "S. Parilov and W. Stuerzlinger",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-39",
  abstract =     "In this paper we present an Image-Based Rendering
                 method for post-warping LDI's in real-time on existing
                 systems. The algorithm performs accurate splatting at
                 low computational costs, reduces memory-access
                 bottlenecks, enables us to trade-off the quality for
                 the speed, and is simple to implement.",
  editor =       "V. Skala",
  keywords =     "Image-based rendering, image warping, real time
                 rendering, relief textures, layered depth images,
                 splatting",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InCollection{EVL-2002-390,
  pages =        "273--283",
  year =         "2002",
  title =        "Surface skinning revisited",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-390",
  author =       "Les A. Piegl and Wayne Tiller",
  abstract =     "Surface skinning is a powerful tool that allows the
                 designer to pass a B-spline surface through a set of
                 curves. Although this technique has been in use for
                 about two decades, its many problems raise questions
                 about its usefulness as a design tool. The contribution
                 of this paper is twofold: (1) several skinning problems
                 are studied and analyzed, and (2) a solution is
                 proposed that avoids all the anomalies at the expense
                 of increasing the number of control points and the
                 compute time.",
  month =        jun,
  keywords =     "NURBS, surface skinning, curves and surfaces,
                 algorithms.",
  volume =       "18(4)",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-391,
  pages =        "286--298",
  year =         "2002",
  title =        "Interactive rendering of Catmull/Clark surfaces with
                 crease edges",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-391",
  author =       "Sven Havemann",
  abstract =     "A scheme for delayed tesselation of Catmull/Clark
                 surfaces is described where only changes of the control
                 mesh and changes in visibility create workload.
                 Tesselation is performed on demand and is typically
                 spread over a number of frames, so that the number of
                 perceivable frame-rate drops is minimized. No special
                 preprocessing stage is necessary, and applications have
                 the greatest freedom for control-mesh manipulation. The
                 tesselation scheme is ideally suited for interactive
                 applications such as modeling and animation. The number
                 of operations for computing regular tesselations is
                 analyzed, and the most expensive part is optimized. The
                 display procedure uses precomputed index arrays to
                 switch between different adaptive triangulations at no
                 additional cost.",
  month =        aug,
  keywords =     "Subdivision surfaces, Catmull/Clark, view-dependent
                 rendering, tesselation on demand, adaptive
                 tesselation.",
  volume =       "18(5-6)",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-392,
  pages =        "299--315",
  year =         "2002",
  title =        "Evaluation of piecewise smooth subdivision surfaces",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-392",
  author =       "Denis Zorin and Daniel Kristjansson",
  abstract =     "In this paper we consider the constant-time evaluation
                 of subdivision surfaces at arbitrary points. Our work
                 extends the work of J. Stam by considering the
                 subdivision rules for piecewise smooth surfaces with
                 boundaries depending on parameters. The main innovation
                 described in this paper is the idea of using a
                 different set of basis vectors for evaluation, which,
                 unlike eigenvectors, depend continuously on the
                 coefficients of the subdivision rules. The advantage of
                 this approach is that it becomes possible to define
                 evaluation for parametric families of rules without
                 considering an excessive number of special cases and
                 while improving the numerical stability of
                 calculations. We demonstrate how such bases are
                 computed for a particular parametric family of
                 subdivision rules extending Loop subdivision to meshes
                 with boundaries, and we provide a detailed description
                 of the evaluation algorithms.",
  month =        aug,
  keywords =     "Subdivision surfaces, Loop subdivision, surfaces with
                 boundaries, creases, exact evaluation.",
  volume =       "18(5-6)",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-393,
  pages =        "316--325",
  year =         "2002",
  title =        "Bounded curvature triangle mesh subdivision with the
                 convex hull property",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-393",
  author =       "Charles Loop",
  abstract =     "The masks for Loop's triangle subdivision surface
                 algorithm are modified resulting in surfaces with
                 bounded curvature and the convex hull property. New
                 edge masks are generated using a cubic polynomial mask
                 equation whose Chebyshev coefficients are closely
                 related to the eigenvalues of the corresponding
                 subdivision matrix. The mask equation is found to
                 satisfy a set of smoothness constraints on these
                 eigenvalues. We observe that controlling the root
                 structure of the mask equation is important for
                 deriving subdivision masks with non-negative weights.",
  month =        aug,
  keywords =     "Triangle mesh, subdivision surface, convex hull
                 property, bounded curvature",
  volume =       "18(5-6)",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-394,
  pages =        "326--342",
  year =         "2002",
  title =        "Analysis and design of Hermite subdivision schemes",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-394",
  author =       "Bert J{\"{u}}ttler and Ulrich Schwanecke",
  abstract =     "Starting from an initial sequence of Hermite elements,
                 a Hermite subdivision scheme recursively generates
                 finer sequences of Hermite elements which are
                 associated with the dyadic points. With the help of the
                 interpolating splines that can be associated with the
                 Hermite elements, we analyze the smoothness of the
                 limit curves generated by Hermite subdivision schemes
                 of arbitrary order, including non-interpolatory ones.
                 After presenting these theoretical results, we describe
                 two new families of Hermite subdivision schemes.",
  month =        aug,
  keywords =     "Subdivision scheme, Hermite interpolation, Spline
                 curves, curve design.",
  volume =       "18(5-6)",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-395,
  pages =        "343--356",
  year =         "2002",
  title =        "A subdivision scheme for hexahedral meshes",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-395",
  author =       "Chandrajit Bajaj and Scott Schaefer and Joe Warren and
                 et al.",
  abstract =     "In a landmark paper, Catmull and Clark described a
                 simple generalization of the subdivision rules for
                 bi-cubic B-splines to arbitrary quadrilateral surface
                 meshes. This subdivision scheme has become a mainstay
                 of surface modeling systems. Joy and MacCracken
                 described a generalization of this surface scheme to
                 volume meshes. Unfortunately, little is known about the
                 smoothness and regularity of this scheme due to the
                 complexity of the subdivision rules. This paper
                 presents an alternative subdivision scheme for
                 hexahedral volume meshes that consist of a simple split
                 and average algorithm. Along extraordinary edges of the
                 volume mesh, the scheme provably converges to a smooth
                 limit volume. At extraordinary vertices, the authors
                 supply strong experimental evidence that the scheme
                 also converges to a smooth limit volume. The scheme
                 automatically produces reasonable rules for
                 non-manifold topology and can easily be extended to
                 incorporate boundaries and embedded creases expressed
                 as Catmull-Clark surfaces and B-spline curves.",
  month =        aug,
  keywords =     "Subdivision, hexahedral, meshes, volume, generation.",
  volume =       "18(5-6)",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-396,
  pages =        "357--367",
  year =         "2002",
  title =        "Detecting and reconstructing subdivision
                 connectivity",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-396",
  author =       "Gabriel Taubin",
  abstract =     "In this paper we introduce fast and efficient inverse
                 subdivision algorithms, with linear time and space
                 complexity, to detect and reconstruct uniform Loop,
                 Catmull-Clark, and Doo-Sabin subdivision structure in
                 irregular triangular, quadrilateral, and polygonal
                 meshes. We consider two main applications for these
                 algorithms. The first one is to enable interactive
                 modeling systems that support uniform subdivision
                 surfaces to use popular interchange file formats which
                 do not preserve the subdivision structure, such as
                 VRML, without loss of information. The second
                 application is to improve the compression efficiency of
                 existing lossless connectivity compression schemes, by
                 optimally compressing meshes with Loop subdivision
                 connectivity. Our Loop inverse subdivision algorithm is
                 based on global connectivity properties of the covering
                 mesh, a concept motivated by the covering surface from
                 Algebraic Topology. Although the same approach can be
                 used for other subdivision schemes, such as
                 Catmull-Clark, we present a Catmull-Clark inverse
                 subdivision algorithm based on a much simpler
                 graph-coloring algorithm and a Doo-Sabin inverse
                 subdivision algorithm based on properties of the dual
                 mesh. Straightforward extensions of these approaches to
                 other popular uniform subdivision schemes are also
                 discussed.",
  month =        aug,
  keywords =     "Inverse subdivision, 3D file formats, gemetry
                 compression, algorithms, graphics.",
  volume =       "18(5-6)",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-397,
  pages =        "368--381",
  year =         "2002",
  title =        "A feature-based approach for individualized human head
                 modeling",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-397",
  author =       "Y.-J. Liu and M. M.-F. Yuen and S. Xiong",
  abstract =     "We present a new feature-based approach to efficiently
                 model individualized human heads. First, we generate a
                 generic head model from a discrete data set using a
                 displaced butterfly subdivision scheme. Our generic
                 model describing fine details on the human head is
                 feature-based and semi-regular. We represent our
                 generic model using a feature mesh together with a
                 hierarchical detail set. To individualize the head
                 model, we deform the feature mesh by adjusting a set of
                 prescribed feature points; we then add the detail set
                 back to synthesize a smooth head model for individuals.
                 We show that using our technique we can achieve great
                 efficiency both in highly realistic head modeling and
                 in a wide range of downstream applications.",
  month =        aug,
  keywords =     "Facial modeling, deformable model, reverse
                 engineering, features, subdivision surfaces.",
  volume =       "18(5-6)",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-398,
  pages =        "382--403",
  year =         "2002",
  title =        "Taxonomy of interpolation constraints on recursive
                 subdivision surfaces",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-398",
  author =       "Ahmad H. Nasri and Malcolm A. Sabin",
  abstract =     "This is the second of two papers which describe and
                 classify situations which any complete study of
                 interpolation constraints for a recursive subdivision
                 surface needs to consider. It addresses surface
                 interpolation constraints, building upon the concepts
                 and categories introduced in the first paper, on
                 interpolation constraints on recursive subdivision
                 curves.",
  month =        aug,
  keywords =     "Recursive subdivision, interpolation constraints,
                 points, normals, curves, slopos, boundary control,
                 Sharpe features, b-Spline, surfaces.",
  volume =       "18(5-6)",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-399,
  pages =        "405--414",
  year =         "2002",
  title =        "A projectively invariant intersection test for
                 polyhedra",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-399",
  author =       "Federico Thomas and Carme Torras",
  abstract =     "Although intersection relations are projectively
                 invariant, most existing intersection detection tests
                 for arbitrary polyhedra can give different results
                 before and after a nonsingular arbitrary projective
                 transformation of the polyhedra under test. This paper
                 presents a projectively invariant intersection test for
                 general polyhedra whose only numerical part is the
                 computation of 424 determinants of homogeneous vertex
                 coordinates. Degeneracies are resolved using a
                 technique of symbolic infinitesimals which also reduces
                 to the computation of 424 determinants. This greatly
                 simplifies the implementation of the test in hardware.
                 Moreover, its projective invariance permits applying it
                 at any point in the graphics pipeline. Since no
                 auxiliary geometric entities need to be computed, the
                 presented test can be concisely expressed as a Boolean
                 formula, instead of a procedure.",
  month =        nov,
  keywords =     "Intersection detection, projective invariance,
                 degenerate configurations, 4 x 4 determinant method .",
  volume =       "18(7)",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InProceedings{EVL-2002-4,
  year =         "2002",
  title =        "Smooth Brushing for Focus+Context Visualization of
                 Simulation Data in 3{D}",
  author =       "H. Doleisch and H. Hauser",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-4",
  abstract =     "We present the usage of a non-discrete degree of
                 interest (DOI) function, obtained by brushing
                 multi-valued 3D simulation data in information
                 visualization views, to define opacity, color, and
                 geometrical transfer functions for 3D rendering in a
                 scientific visualization view via linking. To reflect
                 the smooth nature of features in flow simulation data,
                 smooth brushing was chosen. Different available views
                 and interaction methods of a prototype system are
                 discussed, and examples from 3D flow simulation are
                 shown.",
  editor =       "V. Skala",
  keywords =     "F+C Visualization, Linking & Brushing, Information
                 Visualization, Scientific Visualization, Transfer
                 Function Modulation",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-40,
  year =         "2002",
  title =        "Real-Time View Morphing for Web Applications",
  author =       "M. Terasawa and Y. Yamaguchi and K. Odaka",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-40",
  abstract =     "In this paper, real-time view morphing that is an
                 extension of view morphing is proposed for web
                 applications such as on-line shopping and remote
                 instruction. Real-time view morphing is an image-based
                 rendering method that generates an image of an
                 intermediate view from two or more photographs in
                 real-time without 3D models. The method is combined
                 with conventional view morphing and 2D polygon
                 rendering with texture mapping for real-time
                 processing. Techniques to avoid discontinuity of
                 texture and artifacts at contours without generating
                 holes are proposed to keep the quality of original
                 images. The advantages of the method are small data
                 size, high image quality and real-time rendering that
                 are important for web applications. Users can change
                 object-centered viewpoints interactively in a web
                 browser on a local machine that is connected to the
                 narrow band Internet. The real-time view morphing
                 program also runs in banner advertisements and desktop
                 accessories. An editor is developed for preparing the
                 data such as corresponding points, faces, and face
                 order manually or semi-automatically using the epipolar
                 constraint.",
  editor =       "V. Skala",
  keywords =     "Image-based rendering, view morphing, epipolar
                 geometry",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InCollection{EVL-2002-400,
  pages =        "415--436",
  year =         "2002",
  title =        "Smooth multiple {B}-spline surface fitting with
                 Catmull-Clark subdivision surfaces for xtraordinary
                 corner patches",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-400",
  author =       "Weiyin Ma and Nailiang Zhao",
  abstract =     "This paper presents an algorithm for simultaneously
                 fitting smoothly connected multiple surfaces from
                 unorganized measured data. A hybrid mathematical model
                 of B-spline surfaces and Catmull-Clark subdivision
                 surfaces is introduced to represent objects with
                 general quadrilateral topology. The interconnected
                 multiple surfaces are G2 continuous across all surface
                 boundaries except at a finite number of extraordinary
                 corner points where G1 continuity is obtained. The
                 algorithm is purely a linear least-squares fitting
                 procedure without any constraint for maintaining the
                 required geometric continuity. In case of general
                 uniform knots for all surfaces, the final fitted
                 multiple surfaces can also be exported as a set of
                 Catmull-Clark subdivision surfaces with global C^{2}
                 continuity and local C^{1} continuity at extraordinary
                 corner points.",
  month =        nov,
  keywords =     "B-spline surfaces, Catmull-Clark subdivision surfaces,
                 Geometric continuity, surface fitting.",
  volume =       "18(7)",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-401,
  pages =        "437--444",
  year =         "2002",
  title =        "Minimal area for surface reconstruction from cross
                 sections",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-401",
  author =       "Dmitri Berzin and Ichiro Hagiwara",
  abstract =     "Surface reconstruction from cross-sectional data is
                 important in a variety of applications. It is usually
                 possible to generate a surface in many ways, but only
                 reasonable ones are acceptable. A surface of minimal
                 area has been considered as one of the most natural
                 optimal criteria for the original tiling method of
                 surface reconstruction from cross sections. In the
                 paper, we consider minimal surfaces for continuous
                 generalization of the tiling approach and in the
                 general situation of reconstruction from cross
                 sections. We show that in these cases the minimal area
                 criterion leads to defective surfaces and is thus
                 unacceptable.",
  month =        nov,
  keywords =     "Geometric modeling, optimal shape from slices,
                 interpolation, homotopy .",
  volume =       "18(7)",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-402,
  pages =        "445--467",
  year =         "2002",
  title =        "Image-based animation of facial expressions",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-402",
  author =       "Gideon Moiza and Ayellet Tal and Ilan Shimshoni and et
                 al.",
  abstract =     "We present a novel technique for creating realistic
                 facial animations given a small number of real images
                 and a few parameters for the in-between images. This
                 scheme can also be used for reconstructing facial
                 movies where the parameters can be automatically
                 extracted from the images. The in-between images are
                 produced without ever generating a three-dimensional
                 model of the face. Since facial motion due to
                 expressions are not well defined mathematically our
                 approach is based on utilizing image patterns in facial
                 motion. These patterns were revealed by an empirical
                 study which analyzed and compared image motion patterns
                 in facial expressions. The major contribution of this
                 work is showing how parameterized 'ideal' motion
                 templates can generate facial movies for different
                 people and different expressions, where the parameters
                 are extracted automatically from the image sequence. To
                 test the quality of the algorithm, image sequences (one
                 of which was taken from a TV news broadcast) were
                 reconstructed, yielding movies hardly distinguishable
                 from the originals.",
  month =        nov,
  keywords =     "Facial animation, facial expression reconstruction,
                 image morphing.",
  volume =       "18(7)",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-403,
  pages =        "469--480",
  year =         "2002",
  title =        "A volume-preserving approach for modeling and
                 animating water flows generated by metaballs",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-403",
  author =       "Ruofeng Tong and Kazufumi Kaneda and Hideo Yamashita",
  abstract =     "This paper presents a volume-preserving approach for
                 animating liquid flows modeled by metaballs. A volume
                 of liquid can be adjusted to a previous volume by using
                 the influence radius and the maximum density of
                 metaballs as volume-controlling parameters. Recursive
                 subdivision is used to efficiently calculate the volume
                 of implicit surfaces. The criterion for subdivision is
                 obtained by using the concept of interval analysis and
                 the common property of metaball density functions.
                 Providing a sequence of parameters, the
                 volume-compensation region can be controlled according
                 to the substance making up the object, resulting in
                 local preservation of the volume. Set partition is used
                 for determining isolated surfaces in order to apply
                 local-volume preservation.",
  month =        dec,
  keywords =     "Volume preserving, metaballs, recursive subdivision,
                 interval analysis, graph theory.",
  volume =       "18(8)",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-404,
  pages =        "481--492",
  year =         "2002",
  title =        "Texture-based volume rendering of adaptive mesh
                 refinement data",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-404",
  author =       "Ralf K{\"{a}}hler and Hans-Christian Hege",
  abstract =     "Many phenomena in nature and engineering happen
                 simultaneously on rather diverse spatial and temporal
                 scales. In other words, they exhibit a multi-scale
                 character. A special numerical multilevel technique
                 associated with a particular hierarchical data
                 structure is adaptive mesh refinement (AMR). This
                 scheme achieves locally very high spatial and temporal
                 resolutions. Due to its popularity, many scientists are
                 in need of interactive visualization tools for AMR
                 data. In this article, we present a 3D texture-based
                 volume-rendering algorithm for AMR data that directly
                 utilizes the hierarchical structure. Thereby fast
                 rendering performance is achieved even for
                 high-resolution data sets. To avoid multiple rendering
                 of regions that are covered by grids of different
                 levels of resolution, we propose a space partitioning
                 scheme to decompose the volume into axis-aligned
                 regions of equal-sized cells. Furthermore the problems
                 of interpolation artifacts, opacity corrections, and
                 texture memory limitations are addressed.",
  month =        dec,
  keywords =     "Scalar field visualization, multi-resolution volume
                 rendering, AMR data, 3D texture mapping.",
  volume =       "18(8)",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-405,
  pages =        "493--510",
  year =         "2002",
  title =        "{B}-spline free-form deformation of polygonal object
                 as trimmed {B}{\'{e}}zier surfaces",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-405",
  author =       "Jieqing Feng and Tomoyuki Nishita and Xiaogang Jin and
                 et al.",
  abstract =     "Free-form deformation is a powerful shape modification
                 tool. How to approximate or compute the real
                 deformation of a polygonal object is still problematic.
                 In this paper, a new solution is proposed for this
                 problem. First, a special initial B-spline volume is
                 defined whose Jacobian is an identity matrix. The
                 accurate deformation is as trimmed tensor-product
                 B{\~{A}}zier surfaces. The description of the trimmed
                 surfaces is consistent with the B{\'{e}}zier surfaces
                 are lower than the theoretical results. Compared with
                 previous algorithms, the proposed algorithm has the
                 advantages of both storage and run-time.",
  month =        dec,
  keywords =     "Free-form deformation, b-spline, polygons,
                 B{\'{e}}zier surface, trimmed surface.",
  volume =       "18(8)",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-406,
  pages =        "511--529",
  year =         "2002",
  title =        "Optimistic parallel Delaunay triangulation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-406",
  author =       "Ivana Kolingerov{\'{a}} and Josef Kohout",
  abstract =     "The paper describes a new parallel algorithm of
                 Delaunay triangulation based on randomized incremental
                 insertion. The algorithm is practical, simple and can
                 be modified also for constrained triangulation or
                 tetrahedralization. It was developed for architectures
                 with a lower degree of parallelism, such as
                 several-processor workstations, and tested on up to 8
                 processors.",
  month =        dec,
  keywords =     "Computer graphics, computational geometry, Delaunay
                 triangulation, Parallelization, incremental insertion",
  volume =       "18(8)",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2002-407,
  pages =        "530--546",
  year =         "2002",
  title =        "Convolution surfaces for arcs and quadratic curves
                 with a varying kernel",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-407",
  author =       "Xiaogang Jin and Chiew-Lan Tai",
  abstract =     "A convolution surface is an isosurface in a scalar
                 field defined by convolving a skeleton, comprising of
                 points, curves, surfaces, or volumes, with a potential
                 function. While convolution surfaces are attractive for
                 modeling natural phenomena and objects of complex
                 evolving topology, the analytical evaluation of
                 integrals of convolution models still poses some open
                 problems. This paper presents some novel analytical
                 convolution solutions for arcs and quadratic spline
                 curves with a varying kernel. In addition, we
                 approximate planar higher-degree polynomial spline
                 curves by optimal arc splines within a prescribed
                 tolerance and sum the potential functions of all the
                 arc primitives to approximate the field for the entire
                 spline curve.",
  month =        dec,
  volume =       "18(8)",
  keywords =     "Geometric modeling, convolution surface, analytical,
                 quadratic curve.",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@Article{EVL-2002-408,
  title =        "Scale-invariant segmentation of dynamic
                 contrast-enhanced perfusion {MR} images with inherent
                 scale selection",
  month =        feb,
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  publisher =    "John Wiley & Sons. Ltd.",
  pages =        "1--19",
  year =         "2002",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-408",
  author =       "J. P. Janssen and M. Egmont-Petersen and E. A.
                 Hendriks and M. J. T. Reinders and R. J. van der Geest
                 and P. C. W. Hogendoorn and J. H. C. Reiber",
  abstract =     "Selection of the best set of scales is problematic
                 when developing signal-driven approaches for
                 pixel-based image segmentation. Often, different
                 possibly conflicting criteria need to be fulfilled in
                 order to obtain the best trade-off between uncertainty
                 (variance) and location accuracy. The optimal set of
                 scales depends on several factors: the noise level
                 present in the image material, the prior distribution
                 of the different types of segments, the
                 class-conditional distributions associated with each
                 type of segment as well as the actual size of the
                 (connected) segments. We analyse, theoretically and
                 through experiments, the possibility of using the
                 overall and class-conditional error rates as criteria
                 for selecting the optimal sampling of the linear and
                 morphological scale spaces. It is shown that the
                 overall error rate is optimized by taking the prior
                 class distribution in the image material into account.
                 However, a uniform (ignorant) prior distribution
                 ensures constant class-conditional error rates.
                 Consequently, we advocate for a uniform prior class
                 distribution when an uncommitted, scale-invariant
                 segmentation approach is desired. Experiments with a
                 neural net classifier developed for segmentation of
                 dynamic magnetic resonance (MR) images, acquired with a
                 paramagnetic tracer, support the theoretical results.
                 Furthermore, the experiments show that the addition of
                 spatial features to the classifier, extracted from the
                 linear or morphological scale spaces, improves the
                 segmentation result compared to a signal-driven
                 approach based solely on the dynamic MR signal. The
                 segmentation results obtained from the two types of
                 features are compared using two novel quality measures
                 that characterize spatial properties of labelled
                 images.",
  keywords =     "Scale selection, linear scale space, dynamic
                 contrast-enhanced MR imaging, non-linear morphological
                 filtering, morphological scale space, scale-invariant
                 segmentation.",
  volume =       "13(1)",
  journal =      "Journal of Visualization and Computer Animation",
}

@Article{EVL-2002-409,
  title =        "A survey of interactive mesh-cutting techniques and a
                 new method for implementing generalized interactive
                 mesh cutting using virtual tools",
  month =        feb,
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  publisher =    "John Wiley & Sons. Ltd.",
  pages =        "21--42",
  year =         "2002",
  author =       "Cynthia Bruyns and Steven Senger and Anil Menon and
                 Kevin Montgomery and Simon Wildermuth and Richard
                 Boyle",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-409",
  abstract =     "In our experience, mesh-cutting methods can be
                 distinguished by how their solutions address the
                 following major issues: definition of the cut path,
                 primitive removal and re-meshing, number of new
                 primitives created, when re-meshing is performed, and
                 representation of the cutting tool. Many researches
                 have developed schemes for interactive mesh cutting
                 with the goals of reducing the number of new primitives
                 created, creating new primitives with good aspect
                 ratios, avoiding a disconnected mesh structure between
                 primitives in the cut path, and representing the path
                 traversed by the tool as accurately as possible. The
                 goal of this paper is to explain how, by using a very
                 simple framework, one can build a generalized cutting
                 scheme. This method allows for any arbitrary cut to be
                 made within a virtual object, and can simulate cutting
                 surface, layered surface or tetrahedral objects using a
                 virtual scalpel, scissors, or loop cautery tool. This
                 method has been implemented in a real-time, haptic-rate
                 surgical simulation system allowing arbitrary cuts to
                 be made on high-resolution patient-specific models.",
  keywords =     "Modeling, simulation, procedural simulation and
                 training, haptic interface",
  volume =       "13(1)",
  journal =      "Journal of Visualization and Computer Animation",
}

@InProceedings{EVL-2002-41,
  year =         "2002",
  title =        "Full-View Panoramic Navigation Using Orhogonal Cross
                 Cylinder",
  author =       "S.-T. Ryoo and K.-H. Yoon",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-41",
  abstract =     "Orthogonal Cross Cylinder (OCC) is an object created
                 by intersecting the cylinder of Y-axis and the cylinder
                 of the Z-axis. OCC mapping is a new method for
                 effectively mapping the environment. This method
                 eliminates the singularity effect caused in the
                 environment maps and shows an almost even amount of
                 area for the environment occupied by a single texel.
                 The surrounding environment can also be stored more
                 effectively through more accurate sampling. Improvement
                 is also achieved in the rendering time of the OCC
                 mapping method and octahedral mapping method based on
                 OCC mapping. Therefore, the OCC mapping method is
                 suitable to be applied on environment navigation
                 systems due to its effective storage of the environment
                 and faster sampling time.",
  editor =       "V. Skala",
  keywords =     "Sampling, Environment Mapping, Image Based Rendering",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@Article{EVL-2002-410,
  title =        "Building 3{D} anatomical scenes on the Web",
  month =        feb,
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  publisher =    "John Wiley & Sons. Ltd.",
  pages =        "43--52",
  year =         "2002",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-410",
  author =       "F. Evesque and Sebastian Gerlach and Roger D. Hersch",
  abstract =     "We propose a new service for building user-defined 3D
                 anatomical structures on the Web. The Web server is
                 connected to a database storing more than 1000 3D
                 anatomical models reconstructed from the Visible Human.
                 Users may combine existing models as well as planar
                 oblique slices in order to create their own structured
                 anatomical scenes. Furthermore, they may record
                 sequences of scene construction and visualization
                 actions. These actions enable the server to construct
                 high-quality video animations, downloadable by the
                 user. Professionals and students in anatomy, medicine
                 and related disciplines are invited to use the server
                 and create their own anatomical scenes.",
  keywords =     "Visible Human, anatomy, anatomical models; interactive
                 construction of 3D scenes, volume visualization,
                 surface reconstruction, applet-based rendering engine,
                 Java.",
  volume =       "13(1)",
  journal =      "Journal of Visualization and Computer Animation",
}

@Article{EVL-2002-411,
  title =        "The creation of a high-fidelity finite element model
                 of the kidney for use in trauma research",
  month =        feb,
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  publisher =    "John Wiley & Sons. Ltd.",
  pages =        "53--64",
  year =         "2002",
  author =       "J. G. Snedeker and Michael Bajka and J. M. Hug and
                 G{\'{a}}bor Sz{\'{e}}kely and P. Niederer",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-411",
  abstract =     "A detailed finite element model of the human kidney
                 for trauma research has been created directly from the
                 National Library of Medicine Visible Human Female (VHF)
                 Project data set. An image segmentation and organ
                 reconstruction software package has been developed and
                 employed to transform the 2D VHF images into a 3D
                 polygonal representation. Non-uniform rational B-spline
                 (NURBS) surfaces were then mapped to the polygonal
                 surfaces, and were finally utilized to create a robust
                 3D hexahedral finite element mesh within a commercially
                 available meshing software. The model employs a
                 combined viscoelastic and hyperelastic material model
                 to successfully simulate the behaviour of biological
                 soft tissues. The finite element model was then
                 validated for use in biomechanical research.",
  keywords =     "Model, finite element analysis, automatic mesh
                 generation, deformable body, physically based
                 animation.",
  volume =       "13(1)",
  journal =      "Journal of Visualization and Computer Animation",
}

@Article{EVL-2002-412,
  title =        "Lung metastasis detection and visualization on {CT}
                 images: a knowledge-based method",
  month =        feb,
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  publisher =    "John Wiley & Sons. Ltd.",
  pages =        "65--76",
  year =         "2002",
  author =       "Neculai Archip and Pierre-Jean Erard and Jean-Marie
                 Haefliger and Jean-Francois Germond",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-412",
  abstract =     "A solution to the problem of lung metastasis detection
                 on computed tomography (CT) scans of the thorax is
                 presented. A knowledge-based top-down approach for
                 image interpretation is used. The method is inspired by
                 the manner in which a radiologist and radiotherapist
                 interpret CT images before radiotherapy is planned. A
                 two-dimensional followed by a three-dimensional
                 analysis is performed. The algorithm first detects the
                 thorax contour, the lungs and the ribs, which further
                 help the detection of metastases. Thus, two types of
                 tumors are detected: nodules and metastases located at
                 the lung extremities. A method to visualize the
                 anatomical structures segmented is also presented. The
                 system was tested on 20 patients (988 total images)
                 from the Oncology Department of La Chaux-de-Fonds
                 Hospital and the results show that the method is
                 reliable as a computer-aided diagnostic tool for
                 clinical purpose in an oncology department.",
  keywords =     "Medical imaging, lung metastases, image
                 interpretation, knowledge representation,
                 visualization.",
  volume =       "13(1)",
  journal =      "Journal of Visualization and Computer Animation",
}

@Article{EVL-2002-413,
  pages =        "77--83",
  year =         "2002",
  title =        "State-of-the-art in orthopaedic surgical navigation
                 with a focus on medical image modalities",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-413",
  author =       "Frank Langlotz",
  month =        feb,
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  volume =       "13(1)",
  journal =      "Journal of Visualization and Computer Animation",
  publisher =    "John Wiley & Sons. Ltd.",
}

@Article{EVL-2002-414,
  title =        "New paradigms for interactive 3{D} volume
                 segmentation",
  month =        feb,
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  publisher =    "John Wiley & Sons. Ltd.",
  pages =        "85--95",
  year =         "2002",
  author =       "Matthias Harders and Simon Wildermuth and G{\'{a}}bor
                 Sz{\'{e}}kely",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-414",
  abstract =     "We present a new virtual reality-based interaction
                 metaphor for semi-automatic segmentation of medical 3D
                 volume data. The mouse-based, manual initialization of
                 deformable surfaces in 3D represents a major bottleneck
                 in interactive segmentation. In our multi-modal system
                 we enhance this process with additional sensory
                 feedback. A 3D haptic device is used to extract the
                 centreline of a tubular structure. Based on the
                 obtained path a cylinder with varying diameter is
                 generated, which in turn is used as the initial guess
                 for a deformable surface.",
  keywords =     "Haptic interaction, interactive segmentation, model
                 initialization.",
  volume =       "13(1)",
  journal =      "Journal of Visualization and Computer Animation",
}

@Article{EVL-2002-415,
  title =        "Realistic face animation for speech",
  month =        may,
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  publisher =    "John Wiley & Sons. Ltd.",
  pages =        "97--106",
  year =         "2002",
  author =       "Gregor A. Kalberer and Luc J. Van Gool",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-415",
  abstract =     "Realistic face animation is especially hard as we are
                 all experts in the perception and interpretation of
                 face dynamics. One approach is to simulate facial
                 anatomy. Alternatively, animation can be based on first
                 observing the visible 3D dynamics, extracting the basic
                 modes, and putting these together according to the
                 required performance. This is the strategy followed by
                 the paper, which focuses on speech. The approach
                 follows a kind of bootstrap procedure. First, 3D shape
                 statistics are learned from a talking face with a
                 relatively small number of markers. A 3D reconstruction
                 is produced at temporal intervals of 1/25 seconds. A
                 topological mask of the lower half of the face is
                 fitted to the motion. Principal component analysis
                 (PCA) of the mask shapes reduces the dimension of the
                 mask shape space. The result is twofold. On the one
                 hand, the face can be animated; in our case it can be
                 made to speak new sentences. On the other hand, face
                 dynamics can be tracked in 3D without markers for
                 performance capture.",
  keywords =     "Face animation, speech, visemes, eigen space,
                 realism.",
  volume =       "13(2)",
  journal =      "Journal of Visualization and Computer Animation",
}

@Article{EVL-2002-416,
  title =        "Physiological gait controls with a neural pattern
                 generator",
  month =        may,
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  publisher =    "John Wiley & Sons. Ltd.",
  pages =        "107--119",
  year =         "2002",
  author =       "Shigeru Kuriyama and Yoshimi Kurihara and Yusuke Irino
                 and Toyohisa Kaneko",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-416",
  abstract =     "This paper proposes a control methodology for human
                 gait with a pattern generator. The pattern generator
                 generates cyclic signals via a couple of mutually
                 inhibited neurons, and drives a proportional derivative
                 controller that supplies joint angles of a virtual
                 human. The state of the pattern generator is entrained
                 by the signal of the controller, and such mutual
                 feedback stabilizes the generation of rhythmic signals
                 for variable conditions. Legs and arms can
                 automatically synchronize their periodical movements
                 without using a central supervisor because the
                 corresponding neural oscillators mutually feed their
                 output signals. Our system generates various gaits in a
                 common mechanism with a small number of parameters,
                 which is well suited for real-time, interactive and
                 on-the-fly controls. Moreover, the movements obtained
                 from motion capture data can be controlled by
                 introducing adjustable non-linear filters.",
  keywords =     "Gait control, pattern generator, neural oscillator,
                 motion fitting, real-time animation, virtual human",
  volume =       "13(2)",
  journal =      "Journal of Visualization and Computer Animation",
}

@Article{EVL-2002-417,
  title =        "Planning characters' behaviour in interactive
                 storytelling",
  month =        may,
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  publisher =    "John Wiley & Sons. Ltd.",
  pages =        "121--131",
  year =         "2002",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-417",
  author =       "Marc Cavazza and Fred Charles and Steven J. Mead",
  abstract =     "n this paper, we describe a method for implementing
                 the behaviour of artificial actors in the context of
                 interactive storytelling. We have developed a fully
                 implemented prototype based on the Unreal
                 Tournament[tm] game engine, and carried experiments
                 with a simple sitcom-like scenario. We discuss the
                 central role of artificial actors in interactive
                 storytelling and how real-time generation of their
                 behaviour participates in the creation of a dynamic
                 storyline. We follow previous work describing the
                 behaviour of artificial actors through AI planning
                 formalisms, and adapt it to the context of narrative
                 representation. In this context, the narrative
                 equivalent of a character's behaviour consists of its
                 role. The set of possible roles for a given actor is
                 represented as a hierarchical task network (HTN). The
                 system uses HTN planning to dynamically generate the
                 character roles, by interleaving planning and
                 execution, which supports dynamic interaction between
                 actors, as well as user intervention in the unfolding
                 plot. Finally, we present several examples of short
                 plots and situations generated by the system from the
                 dynamic interaction of artificial actors.",
  keywords =     "Interactive storytelling, AI-based animation, HTN
                 planning, autonomous characters, virtual humans.",
  volume =       "13(2)",
  journal =      "Journal of Visualization and Computer Animation",
}

@Article{EVL-2002-418,
  title =        "Animating real-time explosions",
  month =        may,
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  publisher =    "John Wiley & Sons. Ltd.",
  pages =        "133--145",
  year =         "2002",
  author =       "Claude Martins and John W. Buchanan and John
                 Amanatides",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-418",
  abstract =     "Any sufficiently powerful explosion in air creates an
                 expanding blast wave that propagates outwards from the
                 source. The paper explores the physically based
                 simulation of a blast wave impact on surrounding
                 objects. The emphasis is on simplifying the underlying
                 physical and chemical governing equations in order to
                 achieve a visually believable result that performs in
                 real time. A connected voxel model is used to represent
                 objects, so that realistic solid debris is generated
                 instead of flat polygons. The model permits arbitrary
                 voxel shapes, which allow the creation of more complex
                 objects with a lower number of voxels when compared to
                 models using uniform voxel shapes. This model also
                 overcomes certain limitations of the spring-mass
                 particle model when it comes to representing rigid
                 bodies. The paper also explores auxiliary visual
                 effects caused by the blast wave, such as flame, smoke
                 and dust. Each of these cues increases the visual
                 plausibility of the explosion being simulated without
                 being rigorously physically based or computationally
                 intensive.",
  keywords =     "Explosions, real-time simulation, connected voxels,
                 visual believability.",
  volume =       "13(2)",
  journal =      "Journal of Visualization and Computer Animation",
}

@Article{EVL-2002-419,
  title =        "Improving realism of a surgery simulator: linear
                 anisotropic elasticity, complex interactions and force
                 extrapolation",
  month =        jul,
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  publisher =    "John Wiley & Sons. Ltd.",
  pages =        "147--167",
  year =         "2002",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-419",
  author =       "Guillaume Picinbono and Jean-Christophe Lombardo and
                 Herve Delingette and Nicholas Ayache",
  abstract =     "In this article, we describe the latest developments
                 of the minimally invasive hepatic surgery simulator
                 prototype developed at INRIA. The goal of this
                 simulator is to provide a realistic training test bed
                 to perform laparoscopic procedures. Therefore, its main
                 functionality is to simulate the action of virtual
                 laparoscopic surgical instruments for deforming and
                 cutting tridimensional anatomical models. Throughout
                 this paper, we present the general features of this
                 simulator including the implementation of several
                 biomechanical models and the integration of two
                 force-feedback devices in the simulation platform. More
                 precisely, we describe three new important developments
                 that improve the overall realism of our simulator.
                 First, we have developed biomechanical models, based on
                 linear elasticity and finite element theory, that
                 include the notion of anisotropic deformation. Indeed,
                 we have generalized the linear elastic behaviour of
                 anatomical models to `transversally isotropic'
                 materials, i.e. materials having a different behaviour
                 in a given direction. We have also added to the
                 volumetric model an external elastic membrane
                 representing the `liver capsule', a rather stiff skin
                 surrounding the liver, which creates a kind of `surface
                 anisotropy'. Second, we have developed new contact
                 models between surgical instruments and soft tissue
                 models. For instance, after detecting a contact with an
                 instrument, we define specific boundary constraints on
                 deformable models to represent various forms of
                 interactions with a surgical tool, such as sliding,
                 gripping, cutting or burning. In addition, we compute
                 the reaction forces that should be felt by the user
                 manipulating the force-feedback devices. The last
                 improvement is related to the problem of haptic
                 rendering. Currently, we are able to achieve a
                 simulation frequency of 25 Hz (visual real time) with
                 anatomical models of complex geometry and behaviour.
                 But to achieve a good haptic feedback requires a
                 frequency update of applied forces typically above 300
                 Hz (haptic real time). Thus, we propose a force
                 extrapolation algorithm in order to reach haptic real
                 time.",
  keywords =     "Surgery simulation, anisotropic elasticity, finite
                 element method, real time, force feedback,
                 extrapolation.",
  volume =       "13(3)",
  journal =      "Journal of Visualization and Computer Animation",
}

@InProceedings{EVL-2002-42,
  year =         "2002",
  title =        "Monitoring and Correction of Geometric Distortion in
                 Projected Displays",
  author =       "R. Matt Steele and Stephen Webb and Christopher
                 Jaynes",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-42",
  abstract =     "Off-axis placement of light projectors induces
                 significant planar parallax on the display surface.
                 Although commodity solutions exist for removing this
                 distortion, they involve iterative, menu-driven user
                 interaction or physical alignment of the projector, and
                 in either case interrupt the use of the display. User
                 interaction is infeasible in a number of scenarios
                 including mechanically aligned multi-projector displays
                 that are subject to mechanical drift and situations in
                 which projectors are often reconfigured. We present a
                 general technique for continuous rectification of
                 arbitrary off-axis distortions that does not require
                 user interaction. A camera automatically detects when
                 the projector's orientation has changed, without
                 requiring explicit fiducials or targets in the world.
                 The method runs in concert with interactive display
                 applications and has minimal impact on framerate. An
                 initial rectifying transform is recovered automatically
                 by projecting target points and observing them in the
                 camera. The display is then warped and passively
                 monitored for calibration error and motion of the
                 projector. The technique distinguishes between
                 distortions due to miscalibration and intentional
                 framebuffer changes. A consistency score is measured by
                 generating a predicted view based on the current
                 framebuffer contents and correlating this prediction
                 with the camera's captured image. Poor correlation
                 scores indicate that the projector has moved and
                 re-calibration and geometric correction is required.
                 Initial experiments show that the calibration
                 consistency measures are sufficiently robust to
                 distinguish small motion of the projector from
                 continuously changing imagery.",
  editor =       "V. Skala",
  keywords =     "Display calibration, projection, homography",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@Article{EVL-2002-420,
  title =        "A language to model animation out of
                 behaviour-embedded graphical components",
  month =        jul,
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  publisher =    "John Wiley & Sons. Ltd.",
  pages =        "169--185",
  year =         "2002",
  author =       "Prabir K. Pal and Biswajit Sarkar",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-420",
  abstract =     "lmost all entities-animate or inanimate-that we see
                 around us change with time. The changes are brought
                 about by changes in the values of their attributes. By
                 using a set of parameters to represent the variable
                 attributes of an entity, and by suitably manipulating
                 their values at run time, the behaviour of an entity
                 can be broadly mimicked in animation. The majority of
                 entities, however, are all too complex to animate
                 directly. They are better described in terms of nested
                 layers of smaller and simpler entities, which we call
                 components. Each component is structurally and
                 behaviourally complete and can be described independent
                 of its application. In the present paper, we propose a
                 scheme for 3D animation that broadly follows this line.
                 The keystone of this scheme is a language, nicknamed
                 `V', which defines the structural and visual attributes
                 of each component of the scene and associates a
                 parameterized behaviour with it, if necessary, in the
                 form of a program script. Thereafter, wherever such a
                 component appears, it does so with a built-in
                 behaviour, which can nevertheless be regulated by its
                 higher-level component through its parameters. The
                 advantage is that an entire animation can be modelled
                 in a declarative fashion in terms of nested components
                 with embedded behaviour. Besides, each component is
                 easy to write, alter and reuse. The effort for
                 development, debugging and maintenance of animation
                 modelled in this way is much less as the concerns are
                 almost always local.",
  keywords =     "Animation, behaviour, component, graphical, language,
                 mechanism.",
  volume =       "13(3)",
  journal =      "Journal of Visualization and Computer Animation",
}

@Article{EVL-2002-421,
  title =        "A novel progressive modelling algorithm for 3{D}
                 models",
  month =        jul,
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  publisher =    "John Wiley & Sons. Ltd.",
  pages =        "187--198",
  year =         "2002",
  author =       "Shu-Kai Yang and Chin-Chen Chang and Ding-Zhou Duan
                 and Ming-Fen Lin",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-421",
  abstract =     "This paper presents a novel progressive modelling
                 algorithm for 3D models to generate progressive meshes.
                 We propose a forest clustering simplification method to
                 generate a progressive mesh of a model with the
                 efficient and smooth transitions between meshes at
                 different resolutions. Our approach can also integrate
                 and balance the appearance attributes to preserve
                 features of a model in the simplification process. We
                 have applied our progressive modelling technique to
                 several different kinds of input models and results
                 show that our approach only generates efficient and
                 smooth progressive meshes of a given model, but also
                 preserves the features. The proposed method is very
                 suitable for progressive transmission and real-time
                 rendering of 3D models in networked virtual
                 environments.",
  keywords =     "Graphics compression, multi-resolution modelling,
                 progressive mesh, mesh simplification, fuzzy
                 reasoning.",
  volume =       "13(3)",
  journal =      "Journal of Visualization and Computer Animation",
}

@Article{EVL-2002-422,
  title =        "Visual modelling: from images to images",
  month =        sep,
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  publisher =    "John Wiley & Sons. Ltd.",
  pages =        "199--209",
  year =         "2002",
  author =       "Marc Pollefeys and Luc J. Van Gool",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-422",
  abstract =     "This paper contains two parts. In the first part an
                 automatic processing pipeline is presented that
                 analyses an image sequence and automatically extracts
                 camera motion, calibration and scene geometry. The
                 system combines state-of-the-art algorithms developed
                 in computer vision, computer graphics and
                 photogrammetry. The approach consists of two stages.
                 Salient features are extracted and tracked throughout
                 the sequence to compute the camera motion and
                 calibration and the 3D structure of the observed
                 features. Then a dense estimate of the surface geometry
                 of the observed scene is computed using stereo
                 matching. The second part of the paper discusses how
                 this information can be used for visualization.
                 Traditionally, a textured 3D model is constructed from
                 the computed information and used to render new images.
                 Alternatively, it is also possible to avoid the need
                 for an explicit 3D model and to obtain new views
                 directly by combining the appropriate pixels from
                 recorded views. It is interesting to note that even
                 when there is an ambiguity on the reconstructed
                 geometry, correct new images can often still be
                 generated.",
  keywords =     "3D reconstruction, structure from motion, 3D
                 modelling, image-based rendering.",
  volume =       "13(4)",
  journal =      "Journal of Visualization and Computer Animation",
}

@Article{EVL-2002-423,
  title =        "A perspective factorization method for Euclidean
                 reconstruction with uncalibrated cameras",
  month =        sep,
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  publisher =    "John Wiley & Sons. Ltd.",
  pages =        "211--223",
  year =         "2002",
  author =       "Mei Han and Takeo Kanade",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-423",
  abstract =     "Structure from motion (SFM), which is recovering
                 camera motion and scene structure from image sequences,
                 has various applications, such as scene modelling,
                 robot navigation, object recognition and virtual
                 reality. Most of previous research on SFM requires the
                 use of intrinsically calibrated cameras. In this paper
                 we describe a factorization-based method to recover
                 Euclidean structure from multiple perspective views
                 with uncalibrated cameras. The method first performs a
                 projective reconstruction using a bilinear
                 factorization algorithm, and then converts the
                 projective solution to a Euclidean one by enforcing
                 metric constraints. The process of updating a
                 projective solution to a full metric one is referred as
                 normalization in most factorization-based SFM methods.
                 We present three normalization algorithms which enforce
                 Euclidean constraints on camera calibration parameters
                 to recover the scene structure and the camera
                 calibration simultaneously, assuming zero skew cameras.
                 The first two algorithms are linear, one for dealing
                 with the case that only the focal lengths are unknown,
                 and another for the case that the focal lengths and the
                 constant principal point are unknown. The third
                 algorithm is bilinear, dealing with the case that the
                 focal lengths, the principal points and the aspect
                 ratios are all unknown. The results of experiments are
                 presented.",
  keywords =     "Structure from motion, 3D modelling, camera
                 calibration, Euclidean reconstruction, computer
                 vision.",
  volume =       "13(4)",
  journal =      "Journal of Visualization and Computer Animation",
}

@Article{EVL-2002-424,
  title =        "Single-view modelling of free-form scenes",
  month =        sep,
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  publisher =    "John Wiley & Sons. Ltd.",
  pages =        "225--235",
  year =         "2002",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-424",
  author =       "Li Zhang and Guillaume Dugas-Phocion and
                 Jean-Sebastien Samson and Steven M. Seitz",
  abstract =     "This paper presents a novel approach for
                 reconstructing free-form, texture-mapped, 3D scene
                 models from a single painting or photograph. Given a
                 sparse set of user-specified constraints on the local
                 shape of the scene, a smooth 3D surface that satisfies
                 the constraints is generated. This problem is
                 formulated as a constrained variational optimization
                 problem. In contrast to previous work in single-view
                 reconstruction, our technique enables high-quality
                 reconstructions of free-form curved surfaces with
                 arbitrary reflectance properties. A key feature of the
                 approach is a novel hierarchical transformation
                 technique for accelerating convergence on a
                 non-uniform, piecewise continuous grid. The technique
                 is interactive and updates the model in real time as
                 constraints are added, allowing fast reconstruction of
                 photorealistic scene models. The approach is shown to
                 yield high-quality results on a large variety of
                 images.",
  keywords =     "Shape reconstruction, hierarchical transformation,
                 discontinuities, pictorial relief, free-from modelling,
                 variational surfaces",
  volume =       "13(4)",
  journal =      "Journal of Visualization and Computer Animation",
}

@Article{EVL-2002-425,
  title =        "Augmenting panoramas with object movies by generating
                 novel views with disparity-based view morphing",
  month =        sep,
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  publisher =    "John Wiley & Sons. Ltd.",
  pages =        "237--247",
  year =         "2002",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-425",
  author =       "Yi-Ping Hung and Chu-Song Chen and Yu-Pao Tsai and
                 Szu-Wei Lin",
  abstract =     "Our goal is to augment a panorama with object movies
                 in a visually 3D-consistent way. Notice that a panorama
                 is recorded as one single 2D image and an object movie
                 (OM) is composed of a set of 2D images taken around a
                 3D object. The challenge is how to integrate the above
                 two sources of 2D images in a 3D-consistent way so that
                 the user can easily manipulate object movies in a
                 panorama. To solve this problem, we adopt a purely
                 image-based approach that does not have to reconstruct
                 the geometric models of the 3D objects to be inserted
                 in the panorama. A critical issue of this method is how
                 to generate the novel views required for showing an OM
                 in different places of a panorama, and we have proposed
                 a view morphing technique, called t-DBVM, to solve this
                 problem. Our experiments have shown that this purely
                 image-based approach can effectively generate visually
                 convincing OM-augmented panoramas. This method has
                 great potential for many applications that require
                 integration of panoramas and object movies, such as
                 virtual malls, virtual museum, and interior design.",
  keywords =     "Panorama, object movie, augmented reality, image-based
                 rendering, novel view generation, disparity-based view
                 morphing.",
  volume =       "13(4)",
  journal =      "Journal of Visualization and Computer Animation",
}

@Article{EVL-2002-426,
  title =        "Layered lumigraph with {LOD} control",
  month =        sep,
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  publisher =    "John Wiley & Sons. Ltd.",
  pages =        "249--261",
  year =         "2002",
  author =       "Xin Tong and Jinxiang Chai and Heung-Yeung Shum",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-426",
  abstract =     "The rendering performance of an image-based rendering
                 (IBR) system is determined by the number of images and
                 the amount of geometrical information used. In this
                 paper, we propose a layered lumigraph representation
                 that is configured for optimized rendering performance
                 based on the rendering platform (e.g., processor speed,
                 memory) and output image resolution. The layered
                 lumigraph is produced by classifying all pixels into a
                 number of depth layers. Based on prior work on
                 plenoptic sampling analysis, the layered lumigraph is
                 constructed to achieve the same rendering quality along
                 the minimum sampling curve by balancing the number of
                 images and depth layers. For a given rendering
                 platform, the best rendering performance can be
                 obtained by choosing the optimal number of images and
                 depth layers. Moreover, the layered lumigraph is
                 capable of level-of-detail (LOD) control using the same
                 image geometry trade-off. Therefore, the layered
                 lumigraph fully exploits the inherent constraints
                 between the number of images, depth complexity, and
                 output resolution. Finally, a backward warping
                 technique is designed to efficiently render the layered
                 lumigraph by taking advantage of texture mapping
                 hardware.",
  keywords =     "Image-based rendering, lumigraph, plenoptic sampling,
                 LOD.",
  volume =       "13(4)",
  journal =      "Journal of Visualization and Computer Animation",
}

@Article{EVL-2002-427,
  title =        "A programming environment for behavioural animation",
  month =        dec,
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  publisher =    "John Wiley & Sons. Ltd.",
  pages =        "263--274",
  year =         "2002",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-427",
  author =       "Fr{\'{e}}d{\'{e}}ric Deviller and St{'{e}}phane
                 Donikan and Fabrice Lamarche and Jean-Fran{\c{c}}ois
                 Taille",
  abstract =     "Behavioural models offer the ability to simulate
                 autonomous agents like organisms and living beings.
                 Psychological studies have shown that human behaviour
                 can be described by a perception-decision-action loop,
                 in which the decisional process should integrate
                 several programming paradigms such as real time,
                 concurrency and hierarchy. Building such systems for
                 interactive simulation requires the design of a
                 reactive system treating flows of data to and from the
                 environment, and involving task control and preemption.
                 Since a complete mental model based on vision and image
                 processing cannot be constructed in real time using
                 purely geometrical information, higher levels of
                 information are needed in a model of the virtual
                 environment. For example, the autonomous actors of a
                 virtual world would exploit the knowledge of the
                 environment topology to navigate through it.
                 Accordingly, in this paper we present our programming
                 environment for real-time behavioural animation which
                 is compounded of a general animation and simulation
                 platform, a behavioural modelling language and a
                 scenario-authoring tool. Those tools has been used for
                 different applications such as pedestrian and car
                 driver interaction in urban environments, or a virtual
                 museum populated by a group of visitors.",
  keywords =     "Believability, synthetic agents, agent architectures,
                 behavioural animation, scenario authoring.",
  volume =       "13(5)",
  journal =      "Journal of Visualization and Computer Animation",
}

@Article{EVL-2002-428,
  title =        "Multiple animated characters motion fusion",
  month =        dec,
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  publisher =    "John Wiley & Sons. Ltd.",
  pages =        "275--285",
  year =         "2002",
  author =       "Zhongxiang Luo and Yueting Zhuang and Feng Liu and
                 Yunhe Pan",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-428",
  abstract =     "One of the major problems of the motion capture-based
                 computer animation technique is the relatively high
                 cost of equipment and low reuse rate of data. To
                 overcome this problem, many motion-editing methods have
                 been developed. However, most of them can only handle
                 one character whose motions are preset, and hence
                 cannot interact with its environment automatically. In
                 this paper, we construct a new architecture of multiple
                 animated character motion fusion, which not only
                 enables the characters to perceive and respond to the
                 virtual environment, but also allows them to interact
                 with each other. We will also discuss in detail the key
                 issues, such as motion planning, coordination of
                 multiple animated characters and generation of vivid
                 continuous motions. Our experimental results will
                 further testify to the effectiveness of the new
                 methodology.",
  keywords =     "Animation, motion fusion, motion editing, motion
                 collaboration.",
  volume =       "13(5)",
  journal =      "Journal of Visualization and Computer Animation",
}

@Article{EVL-2002-429,
  title =        "Eye movements and attention for behavioural
                 animation",
  month =        dec,
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  publisher =    "John Wiley & Sons. Ltd.",
  pages =        "287--300",
  year =         "2002",
  author =       "M. F. P. Gillies and Neil A. Dodgson",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-429",
  abstract =     "This paper describes a simulation of attention
                 behaviour aimed at computer-animated characters.
                 Attention is the focusing of a person's perception on a
                 particular object. This is useful for computer
                 animation as it determines which objects the character
                 is aware of: information that can be used in the
                 simulation of the character's behaviour in order to
                 automatically animate the character. The simulation of
                 attention also determines where the character is
                 looking and so is used to produce gaze behaviour.",
  keywords =     "Computer animation, autonomous characters.",
  volume =       "13(5)",
  journal =      "Journal of Visualization and Computer Animation",
}

@InProceedings{EVL-2002-43,
  year =         "2002",
  title =        "Surface-Based Efficient Cloud Visualisation for
                 Animation Applications",
  author =       "A. Trembilski and A. Bro{\ss{}}ler",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-43",
  abstract =     "For the local TV presentation of weather forecast data
                 it is important to have high-quality and fast
                 visualisation of clouds. In this paper we present
                 surface-based methods for the high performance
                 visualisation of clouds from data produced by a routine
                 meteorological weather simulation. Isosurfaces, which
                 are originally too coarse because of the data grid
                 resolution are refined and deformed. The refined
                 geometry is used for a light simulation and
                 transparency computation.",
  editor =       "V. Skala",
  keywords =     "Meteorological visualisation, cloud modelling and
                 visualisation, surface refinement",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@Article{EVL-2002-430,
  title =        "Subtleties of facial expressions in embodied agents",
  month =        dec,
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  publisher =    "John Wiley & Sons. Ltd.",
  pages =        "301--312",
  year =         "2002",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-430",
  author =       "Catherine Pelachaud and Isabella Poggi",
  abstract =     "Our goal is to develop a believable embodied agent
                 able to dialogue with a user. In particular, we aim at
                 making an agent that can also combine facial
                 expressions in a complex and subtle way, just like a
                 human agent does. We first review a taxonomy of
                 communicative functions that our agent is able to
                 express non-verbally; but we point out that, due to the
                 complexity of communication, in some cases different
                 information can be provided at once by different parts
                 and actions of an agent's face. In this paper we are
                 interested in assessing and treating what happens, at
                 the meaning and signal levels of behaviour, when
                 different communicative functions have to be displayed
                 at the same time and necessarily have to make use of
                 the same expressive resources. In some of these cases
                 the complexity of the agent's communication can give
                 rise to conflicts between the parts or movements of the
                 face. In this paper, we propose a way to manage the
                 possible conflicts between different modalities of
                 communication through the tool of belief networks, and
                 we show how this tool allows us to combine facial
                 expressions of different communicative functions and to
                 display complex and subtle expressions.",
  keywords =     "Embodied conversational agent, facial expression,
                 emotion, performative, communicative act, believable
                 agent.",
  volume =       "13(5)",
  journal =      "Journal of Visualization and Computer Animation",
}

@Article{EVL-2002-431,
  title =        "Gaze and task performance in shared virtual
                 environments",
  month =        dec,
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  publisher =    "John Wiley & Sons. Ltd.",
  pages =        "313--320",
  year =         "2002",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-431",
  author =       "Jeremy N. Bailenson and Andrew C. Beall and Jim
                 Blascovich",
  abstract =     "Non-verbal behaviour, particularly gaze direction,
                 plays a crucial function in regulating conversations
                 and providing critical social information. In the
                 current set of studies, we represented interactants in
                 a shared immersive virtual environment. Interactants
                 sat in physically remote rooms, entered a common
                 virtual room and played games of 20 questions. The
                 interactants were represented by one of three types of
                 avatars: (1) human forms with head movements rendered
                 in real time; (2) human forms without head movements
                 rendered; or (3) human voice only (i.e., a conference
                 call). The data demonstrated that interactants in the
                 rendered head movement condition rated a higher level
                 of co-presence, liked each other more, looked at each
                 other's heads more, and spoke for a lower percentage of
                 time during the game, compared to the other two
                 conditions. We discuss implications for the design of
                 shared virtual environments, the study of non-verbal
                 behaviour and the goal of facilitating efficient task
                 performance.",
  keywords =     "Mutual gaze, presence, copresence, video conferencing,
                 organizational behaviour, avatars.",
  volume =       "13(5)",
  journal =      "Journal of Visualization and Computer Animation",
}

@InProceedings{EVL-2002-44,
  year =         "2002",
  title =        "Multiresolution Modelling Using Connectivity
                 Information",
  author =       "O. Belmonte and I. Remolarn and J. Ribelles and M.
                 Chover and C. Rebollo and M. Fern{\'{a}}ndez",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-44",
  abstract =     "Triangles meshes are the most popular standard model
                 to represent polygonal surfaces in Computer Graphics.
                 Drawing these meshes as a set of independent triangles
                 involves sending a vast amount of information sent to
                 the graphic engine. The use of primitives such as fan
                 and strip of triangles, which make use of the
                 connectivity information between the triangles in the
                 mesh, reduces dramatically the amount of information
                 sent to the graphic engine. The Multiresolution
                 Triangle Strips scheme takes advantage of this
                 characteristic in order to represent a multiresolution
                 model as a set of multiresolution triangle strips. A
                 multiresolution triangle strip is made of the original
                 strips and all of its Levels of Detail. Each of these
                 multiresolution strips is represented as a graph that
                 is traversed to recover the demanded LoD. A
                 Multiresolution Triangle Strip model uses the triangle
                 strip primitive both in the data structure as in the
                 rendering stage. The Multiresolution Triangle Strip is
                 compared against the Progressive Meshes multiresolution
                 model, one of the best multiresolution models probably
                 known. The performance of the MTS models in visualising
                 improves drastically PM models.",
  editor =       "V. Skala",
  keywords =     "Multiresolution, triangle strip, real time rendering,
                 computer graphics",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-45,
  year =         "2002",
  title =        "Level of Motion Detail in Virtual Reality",
  author =       "R. Berka",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-45",
  abstract =     "Our paper presents an optimization technique which
                 modulates the computation complexity of the animation
                 in virtual reality (VR). As this technique is based on
                 approaches commonly used in the domain of LOD, we call
                 it LOmD (Level of motion Detail). We extend the
                 classical LOD mechanism based on geometry removal
                 according to observer's distance from a target object,
                 velocity of the model, and position of the model in the
                 periphery of the visual field. The LOmD technique is
                 based on the idea that our visual system is not able to
                 recognize differences in the quality of motions
                 produced by different animation techniques (e.g. simple
                 linear interpolation vs. physically based simulation)
                 under different visual conditions (e.g. distance or
                 eccentricity). Varying the motion detail we can balance
                 the workload of VR system in such a way that the only
                 motions important for the user's view are refined using
                 more complex simulation whereas other motions are
                 linearly interpolated to quarantee the motion
                 continuity. In order to achieve automatic behavior of
                 LOmD mechanism we designed the visual acuity model
                 based on visual perception which links the viewing
                 conditions to the appropriate level of motion detail.
                 The proposed method has been tested on implementation
                 of a simple VR model. The results are presented at the
                 section 5 of the paper.",
  editor =       "V. Skala",
  keywords =     "Computer Animation, Virtual Reality, Level of Detail,
                 Virtual Environments",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-46,
  year =         "2002",
  title =        "Representation of Polyhedral Objects Using
                 {SP}-Octrees",
  author =       "P. Cano and J. C Torres",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-46",
  abstract =     "Extensions to classical Octrees that add new types of
                 terminal nodes have been proposed for the exact
                 representation of polyhedral objects. In this work, we
                 present a new solid representation scheme using Octrees
                 which include boundary information of the represented
                 object in the internal nodes of the tree. In this way,
                 basic operations with the model will be accelerated and
                 we are able to represent polyhedral objects exactly
                 with smaller storage cost.",
  editor =       "V. Skala",
  keywords =     "Solid modelling, Geometric modelling, Hierarchical
                 modelling, Octrees, BSP, Visualisation, Polyhedra",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-47,
  year =         "2002",
  title =        "Compressed Adaptive Multiresolution Encoding",
  author =       "M. Grabner",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-47",
  abstract =     "A new data structure compressed adaptive
                 multiresolution encoding (CAME) for efficient storage
                 of adaptive multiresolution non-manifold triangle
                 meshes is presented. Unlike previous methods, CAME
                 offers both data compression and view-dependent
                 simplification. Triangle vertices are referenced by
                 their relative path through the vertex hierarchy,
                 therefore no neighborhood relations need to be stored
                 to perform local mesh transformations (vertex split and
                 edge collapse). Mesh dependencies are shown to be
                 highly redundant and can be encoded with little
                 overhead. CAME is built upon the meta-node tree
                 recently introduced by El-Sana and Chiang (External
                 Memory View-Dependent Simplification, in Proceedings
                 Eurographics 2000), but compresses this data structure
                 by a factor of 17. The new method also offers external
                 memory scene navigation, progressive transmission, and
                 asynchronous access to the scene database",
  editor =       "V. Skala",
  keywords =     "Multiresolution, adaptive LOD selection, compression",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-48,
  year =         "2002",
  title =        "Evaluation of Attentional Control in Active Vision
                 Systems Using a 3{D} Simulation Framework",
  author =       "G. Backer and B. Mertsching",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-48",
  abstract =     "In active vision systems, attentional control is used
                 to determine the relevant parts of a scene and to
                 direct perception towards these parts. To test and
                 evaluate active vision systems, we have implemented a
                 3D simulation framework capable of simulating a broad
                 scope of environments from simple block worlds to
                 complex photorealistic scenes. The simulator allows
                 full control of all aspects of the simulation, acting
                 and moving inside virtual environments. In this paper,
                 we demonstrate its use for evaluating our attentional
                 control system. The attention model is based on a novel
                 two-stage selection mechanism and especially focuses on
                 the dynamic and three-dimensional aspects of its
                 environment.",
  editor =       "V. Skala",
  keywords =     "Active vision, virtual reality, attentional control,
                 3D simulation",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@{,
}

@InProceedings{EVL-2002-5,
  year =         "2002",
  title =        "Redistributing Light",
  author =       "M. Contensin",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-5",
  abstract =     "We propose strategies for reducing the number of light
                 sources in a scene preserving the illumination obtained
                 with the full set of light sources. This reduction
                 comes as a post processing to a mathematical phase of
                 an inverse lighting method we developed. The method
                 allows to graphically define a targeted effect in a
                 scene with fixed geometry, the computer producing
                 causes that lead to the desired effect i.e. a lighting
                 configuration (number of light sources, their position
                 and self exitances). Of course our reduction strategies
                 may also be used in the case of direct lighting.",
  editor =       "V. Skala",
  keywords =     "Energy conservation, inverse lighting, radiosity,
                 global illumination",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-50,
  year =         "2002",
  title =        "Real-Time Segmentation for Advanced Disparity
                 Estimation in Immersive Videoconference Applications",
  author =       "I. Feldmannand S. Askar and N. Brandenburg and P.
                 Kauff and O. Schreer",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-50",
  abstract =     "We present an advanced disparity estimation algorithm
                 developed for real-time immersive teleconferencing. In
                 order to improve the disparity maps in the case of
                 occlusions a segmentation-driven disparity post
                 processing is applied. We introduce a novel approach
                 for a segmentation algorithm, which uses the advantages
                 of HSV colour space without the need of an explicit
                 colour space transformation. This makes segmentation
                 very fast while still keeping the robustness of HSV
                 colour space especially to illumination changes and
                 shadows. Further on, we present an algorithm for
                 tracking the hands of a conferee. Finally, we introduce
                 an algorithm framework, which combines segmentation,
                 tracking of hands and disparity estimation to create
                 robust disparity map in real-time. We show the
                 improvement of results for image-based rendering.",
  editor =       "V. Skala",
  keywords =     "Disparity analysis, segmentation, colour space,
                 recursive block matching, real-time",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-51,
  year =         "2002",
  title =        "Line Segment Extraction in Panoramic Images",
  author =       "M. Fiala and A. Basu",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-51",
  abstract =     "Omni-directional sensors are useful in obtaining a 360
                 degree field of view of a scene for telepresence,
                 panoramic scene capture and machine vision. An approach
                 to obtain a panoramic view is to utilize a
                 radially-symmetric, non-planar mirror and a single
                 image sensor. There are several proposed profiles for
                 the mirror, but most violate the Single View-Point
                 criteria necessary to allow functional equivalence to
                 the standard perpective projection. This poses
                 challenges for feature extraction that must be met to
                 make use of such non-SVP mirror profiles (such as
                 spherical) that have other desireable properties. Such
                 a non-SVP optical system does not benefit from the
                 affine quality of straight line features being
                 represented as collinear points in the image plane. A
                 new method to recognize the salient features of
                 straight line segments with such optics is presented.
                 Previous work addressing this need saw the developement
                 of a modified Hough transform to facilitate the
                 detection of horizontal and vertical line feature
                 edges. Algorithms tailored to utilize this Panoramic
                 Hough transform to robustly extract horizontal and
                 vertical line segments are presented. Specifically a
                 robust method for using this Panoramic Hough transform
                 to sucessively identify and remove clusters that appear
                 in the parameter space which correspond to straight
                 line features is shown. Experimental results are
                 presented to validate this model.",
  editor =       "V. Skala",
  keywords =     "Panoramic, catadioptric, image segmentation, feature
                 extraction, line extraction, Hough transform, non-SVP",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-52,
  year =         "2002",
  title =        "An Interactive Vision-Based Tool for Model-Based Scene
                 Calibration of Augmented Reality Environments",
  author =       "P. Bayerl and G. Baratoff",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-52",
  abstract =     "Non-trivial Augmented Reality environments consist of
                 a reconfigurable set of objects whose spatial relations
                 need to be calibrated upon setup. Since manual
                 measurement is tedious, time-consuming, and error-prone
                 if not done carefully, fully or semi-automatic
                 procedures are needed. We have developed a
                 semi-automatic vision-based scene calibration tool
                 which allows a user to perform this task efficiently
                 and accurately. For each scene object to be calibrated,
                 the user interactively specifies its approximate pose
                 by aligning a 3D model of the object with its
                 projection in one or several camera image(s) of the
                 scene. Thereupon, the exact pose is automatically
                 computed by a combination of computer graphics and
                 computer vision techniques. The combined knowledge of
                 the object model and of the initial pose estimate
                 allows the system to significantly improve the feature
                 matching and pose estimation processes. Because the
                 latter is based on a robust estimation method, the
                 system performs well even in cluttered environments
                 where objects are partly occluded.",
  editor =       "V. Skala",
  keywords =     "Augmented reality, calibration, computer vision",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-53,
  year =         "2002",
  title =        "Inverse Simulation of Sunshine, Visibility and
                 Reflection in Architectural and Urban Spaces",
  author =       "S. Houpert",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-53",
  abstract =     "This paper presents an {"}inverse{"} reasoning to
                 solve problems of sunlighting, visibility and solar
                 reflection in architectural and urban spaces. We
                 propose a numerical model which enables to mix these
                 parameters. Inverse simulation considers the relation
                 between a given observer or an area and environmental
                 elements. This relation represents a volumetric
                 constraint. The CAD tool which is developed (SVR
                 software), helps the designers to display architectural
                 and urban constraints and also better take into account
                 solar and visual impact of urban projects. Our model
                 enables to find solutions in order to satisfy these
                 solar and visual constraints and to manipulate
                 geometrical volumes.",
  editor =       "V. Skala",
  keywords =     "Inverse simulation, CAD tools, visibility, sunlight,
                 solar reflection",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-54,
  year =         "2002",
  title =        "The Responsive Workbench Simulator: a Tool for
                 Application Development",
  author =       "M. Koutek and F. H. Post",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-54",
  abstract =     "In this paper we present a software environment for
                 visualization and interaction on the
                 ResponsiveWorkbench -RWB). Our main focus will be on
                 the RWB Simulator. We will also briefly describe the
                 architecture and the usage of the RWB Library. The RWB
                 Simulator is an excellent tool for development,
                 evaluation and analysis of the RWB applications. It is
                 a powerful introduction, learning and presentation tool
                 for the RWB. We will also present a novel method for
                 development of immersive VR applications. Finally we
                 will demonstrate the RWB Simulator on some
                 visualization applications.",
  editor =       "V. Skala",
  keywords =     "Virtual Reality, Responsive Workbench (RWB) Library,
                 RWB Simulator",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-55,
  year =         "2002",
  title =        "A Meshing Scheme for Real Time Surface Subdivision",
  author =       "E. J. Padr{\'{o}}n and M. Amor and R. Doallo and M.
                 B{\'{o}}o",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-55",
  abstract =     "Surface subdivision in real time is highly desirable
                 for computer graphics, geometric modeling, and
                 scientific visualization. In this paper we present a
                 parallelization of the Modified Butterfly algorithm
                 based on the subdivision of the original mesh into
                 small groups. The groups are sorted in decreasing order
                 of number of triangles per group, and the sorted groups
                 are cyclically distributed on the processors in order
                 to balance the load. So as to avoid cracking effects
                 among groups a slight modification of the Modified
                 Butterfly algorithm is used. Finally, we evaluate the
                 algorithm on a SGI Origin 2000 system.",
  editor =       "V. Skala",
  keywords =     "Surface subdivision, distributed memory
                 multiprocessor, grouping algorithm, parallel
                 implementation, Modified Butterfly",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-56,
  year =         "2002",
  title =        "Symbolic Conversation Modeling Used as Abstract Part
                 of the User Interface",
  author =       "N. Braun",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-56",
  abstract =     "The art of conversation is a well-known interaction
                 type between humans. Human-computer interfaces that
                 follow this metaphor struggle with complex problems of
                 speech understanding, speech generation and intelligent
                 conversational behavior in general. This paper presents
                 an approach that gives a simple, explicit symbolic
                 model of conversation between human and computer to be
                 used by interface designers as an abstract platform of
                 conversational interaction - without being forced to
                 regard the basic implementations of speech systems or
                 graphical anthropomorphic avatars or virtual humans and
                 therefore free from the problems of basic media
                 manipulation.",
  editor =       "V. Skala",
  keywords =     "Conversation, human-computer interaction, symbolic
                 modeling, artificial intelligence, computer games",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-57,
  year =         "2002",
  title =        "Dynamic Terrain Visualisation Using Page Management",
  author =       "M. Danaher",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-57",
  abstract =     "Landscape visualisation is the process of recreating a
                 natural environment and displaying it in an interactive
                 graphical simulation. Current systems that use large
                 datasets to represent the terrain have a number of
                 drawbacks including large storage requirements, low
                 level of detail and overcrowding in multiuser games. In
                 most systems when the landscape is stored to disk the
                 terrain area is quite small or conversely if the area
                 is large the detail is quite low. Here an approach is
                 described in which the terrain is procedurally
                 generated as required. The terrain is produced in the
                 form of blocks and displayed using an innovative page
                 management technique. This approach allows for the
                 generation of a detailed environment, participation by
                 a very large number of players in multiplayer games and
                 easy download of the environment generator via the
                 WWW.",
  editor =       "V. Skala",
  keywords =     "Web-based systems, games programming",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-58,
  year =         "2002",
  title =        "Including User Strategies in the Evaluation of Graphic
                 Design Interfaces for Browsing Documents",
  author =       "T. Mandl and M. Eibl",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-58",
  abstract =     "This article presents an analytical evaluation method
                 for innovative and graphically rich displays beyond the
                 common WIMP interfaces. This method is based on user
                 strategies and compares different algorithms for
                 creating 2D or 3D environments and leads to a
                 correlation measure which can be consulted in the
                 creation process of such environments. The results
                 suggest, that the graphical algorithm may have more
                 influence on the quality of maps than user strategies.
                 Therefore, the correct choice of appropriate arithmetic
                 algorithms is crucial. Furthermore, the article
                 discusses the extension of the evaluation method to 3D
                 environments for semantic organization of homogeneous
                 objects. By presenting this method and its results, an
                 example for rigid and user-oriented evaluation of
                 advanced graphical interfaces which are applied in the
                 internet is given.",
  editor =       "V. Skala",
  keywords =     "Topographic map, 2D maps, evaluation, visualization,
                 human computer interaction",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-59,
  year =         "2002",
  title =        "Interaction with Content-Augmented Video via
                 Off-Screen Hyperlinks for Direct Information
                 Retrieval",
  author =       "D. Balfanz and M. Finke",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-59",
  abstract =     "Video presentation systems currently available provide
                 users with only a few functionality options. With the
                 introduction of an Internet-based back channel, the way
                 is now open for wide-spread interactive video systems.
                 The convergence of the Internet with broadcast services
                 gives rise to a variety of new application types. It
                 extends the opportunity for a client to retrieve
                 additional video content-related information or to
                 affect the content of a video presentation itself,
                 whether it is a live broadcast or a video-on-demand.
                 The system presented in this paper represents such an
                 interactive application with a number of new options
                 concerning local and global functionalities. To
                 influence video content, a {"}off-screen{"} hyperlink
                 technique is introduced. This technique enables the
                 annotation of hyperlinks on a separate display from the
                 actual information with which it is linked. In the
                 following, a scenario is given demonstrating the
                 advantages of such a technique.",
  editor =       "V. Skala",
  keywords =     "Adaptive additional information, personalized
                 presentation, bi-directional remote control, dynamic
                 display, live content manipulation, {"}off-screen{"}
                 hyperlinks, Interactive video / TV",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-6,
  year =         "2002",
  title =        "A New Approach of Density Estimation for Global
                 Illumination",
  author =       "F. Lavignotte and M. Paulin",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-6",
  abstract =     "This paper presents a new approach to generate
                 view-independent global illumination solution using
                 kernel density estimation. Kernel density estimation
                 allows smooth reconstruction of the radiance from hit
                 points generated by shooting random walk or photon
                 tracing. The advantage of this method is that an
                 unbiased Monte-Carlo algorithm simulates light
                 transport and that light reconstruction introduces
                 error but this error is controllable and purely local.
                 We present an approach that does not require storing
                 the set of hit points generated by photon tracing
                 contrary to previous implementation. A method to reduce
                 error both from the light transport and the light
                 reconstruction is also presented.",
  editor =       "V. Skala",
  keywords =     "Global illumination, density estimation, Monte
                 Carlo.",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-60,
  year =         "2002",
  title =        "Image Morphing Based on Morphological Interpolation
                 Combined with Linear Filtering",
  author =       "M. Iwanowski",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-60",
  abstract =     "This paper describes a novel approach to color image
                 morphing which is based on the combination of
                 morphological image processing tools and linear
                 filtering. In the proposed method the morphing engine
                 is provided by the morphological interpolation by means
                 of the morphological median. By the successive
                 generation of morphological medians using an algorithm
                 proposed in the paper, the sequence transforming one
                 input image into another one is produced. The algorithm
                 makes use of the similarity measure between two
                 successive frames. Two versions of the algorithm are
                 proposed - in the first one the required parameter is
                 the number of frames of the final sequence, in the
                 second one the maximal acceptable error between two
                 consecutive frames. Three linear tools are proposed to
                 improve the visual quality of the morphing sequence:
                 the temporal linear filtering, the spatial linear
                 filtering and the auxiliary cross-dissolving. Contrary
                 to the traditional approaches to image morphing, the
                 proposed method doesn't require any control points. The
                 human operator is obliged to introduce only a few input
                 parameters. Two examples showing the results are also
                 presented in the paper.",
  editor =       "V. Skala",
  keywords =     "Image morphing, color image processing, mathematical
                 morphology, morphological interpolation",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-61,
  year =         "2002",
  title =        "Synthesis of Normal and Abnormal Human Walk
                 Animation",
  author =       "C. Jing and E. C. Prakash",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-61",
  abstract =     "The mechanics of gait animation for human normal
                 walking and abnormal walking has been investigated
                 using a novel hybrid approach with kinematic
                 determinants and biomedical constraints. The kinematic
                 determinants help to achieve efficient control of gait
                 synthesis whereas the masked constraints help in the
                 specification of biomedical correct postures. In the
                 proposed new masked constraints approach, a mask is
                 added to each constraint cone to indicate particular
                 subsets of abnormal postures. In summary, our gait
                 system is an attempt to adapt biomedical analysis of
                 human walking for synthesis of gait in human computer
                 animation.",
  editor =       "V. Skala",
  keywords =     "Animation, gait, walking, humans",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-63,
  year =         "2002",
  title =        "Linear-Time {CSG} Rendering of Intersected Convex
                 Objects",
  author =       "N. Stewart and G. Leach and S. John",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-63",
  abstract =     "The Sequenced Convex Subtraction (SCS) algorithm is a
                 hardware based multi-pass image-space algorithm for
                 general purpose Constructive Solid Geometry (CSG)
                 Rendering. Convex objects combined by volumetric
                 intersection, difference and union are rendered in
                 real-time without b-rep pre-processing. OpenGL stencil
                 and depth testing is used to determine the visible
                 surface for each pixel on the screen. This paper
                 introduces a specialised algorithm for CSG Rendering of
                 intersected convex objects, we call SCS-Intersect. This
                 new technique requires linear time with respect to the
                 number of intersections. SCS Intersect is primarily of
                 interest as an optimisation to the SCS algorithm for
                 rendering CSG trees of convex objects. A revised
                 formulation of the SCS CSG Rendering algorithm is
                 presented in this paper.",
  editor =       "V. Skala",
  keywords =     "CSG Rendering, Rendering Algorithms, Constructive
                 Solid Geometry, OpenGL, Solid Modelling, Numerical
                 Control (NC) Verification",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-64,
  year =         "2002",
  title =        "Direct 3{D} Pattern Matching in the Domain of Freeform
                 Shapes",
  author =       "J. S. M. Vergeest and S. Spanjaard",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-64",
  abstract =     "We have studied the problem of extracting shape
                 parameters from freeform features in full 3D. The
                 freeform features are typically encountered in
                 laser-scanned data from physical parts or in point
                 clouds from any source. Matching involves 1) the search
                 for optimal position and orientation of the template
                 shape and 2) the adjustment of a number (d) of
                 intrinsic shape parameters. The type and total number
                 of parameters (6+d), and hence the family of template
                 shapes is determined by the type of feature. We have
                 analyzed the robustness, accuracy and the efficiency of
                 Hausdorff-like shape distance measures. A number of
                 search strategies have been tested and were evaluated
                 against convergence and computational performance. The
                 practical relevance of the technique is addressed as
                 well.",
  editor =       "V. Skala",
  keywords =     "Freeform shape, freeform features, point cloud, shape
                 matching, Hausdorff distance, optimization",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-65,
  year =         "2002",
  title =        "Human Behaviour Visualisation and Simulation for
                 Automatic Video Understanding",
  author =       "V. T. Vu and F. Bremond and M. Thonnat",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-65",
  abstract =     "The objective of this work is the visualisation and
                 simulation for automatic video interpretation. We have
                 conceived a test framework that generates 3D animations
                 corresponding to behaviours recognised by an automatic
                 interpretation system or corresponding to behaviours
                 described by an expert. Conceiving this test framework
                 is essential in order to be able to develop and
                 validate the interpretation process. The objective of
                 our test framework is (1) to visualise the computation
                 of the interpretation, (2) to be flexible
                 (configurable) enough for testing the different
                 configurations of the interpretation and (3) to be
                 realist enough to understand what is interpreted. To
                 solve this problem we have defined six types of model
                 to represent all the information that is necessary for
                 the interpretation. First, we propose a model of the
                 scene context (containing the 3D geometry) and a model
                 for the virtual camera. Second, we propose an
                 articulated and hierarchical model for representing the
                 human body given its sub parts. We propose two other
                 hierarchical models for modelling human actions and
                 scenarios, and also a model of scene-scenarios that
                 gathers all previous models. We have defined a
                 description language for representing these models. The
                 obtained results are promising: we have developed a
                 test system for a given interpretation system and
                 started evaluating it by generating test animations.",
  editor =       "V. Skala",
  keywords =     "3D visualisation, 3D animation, simulation, video
                 understanding, modelling of the human body, human
                 behaviours and scenes",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-66,
  year =         "2002",
  title =        "EndoView: {A} Phantom Study of a Tracked Virtual
                 Bronchoscopy",
  author =       "D. Wagner and R. Wegenkittl and E. Gr{\"{o}}ller",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-66",
  abstract =     "Virtual endoscopy can be used for preoperative
                 planning, for training and intraoperatively. Surface
                 rendering displays the inner lumen very well. Volume
                 rendering has to be used if the external structures are
                 of interest. For certain applications, e.g. endoluminal
                 biopsy, it is of great advantage to be able to use both
                 techniques at once. In this work we describe an
                 approach that allows using these two methods in
                 combination on a low-end standard personal computer.
                 Since image generation is done in a preprocessing step,
                 any high quality volume or polygonal rendering
                 technique can be used and mixed together without any
                 loss in performance at run-time. This work extends a
                 previous image based rendering system for virtual
                 bronchoscopy to include tracking of a rigid or flexible
                 endoscope and finding one's way in the tracheal tree by
                 displaying the endoscope's position in a top-view map
                 of the trachea. Natural landmarks, i.e. bifurcations in
                 the bronchial tree, are used for registration.
                 Properties of the technique are explored on a phantom
                 data set.",
  editor =       "V. Skala",
  keywords =     "Medical visualization, virtual endoscopy,
                 registration, image based rendering",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-67,
  year =         "2002",
  title =        "Curvature Measures of 3{D} Vector Fields and their
                 Application",
  author =       "T. Weinkauf and H. Theisel",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-67",
  abstract =     "Tangent curves are a powerful tool for analyzing and
                 visualizing vector fields. In this paper two of their
                 most important properties are examined: their curvature
                 and torsion. Furthermore, the concept of normal
                 surfaces is introduced to the theory of 3D vector
                 fields, and their Gaussian and mean curvature are
                 analyzed. It is shown that those four curvature
                 measures tend to infinity near critical points of a 3D
                 vector field. Applications utilizing this behaviour for
                 the (topological) treatment of critical points are
                 discussed.",
  editor =       "V. Skala",
  keywords =     "Flow visualization, vector fields, tangent curves,
                 curvature, topology",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-68,
  year =         "2002",
  title =        "Image Rotation without Scaling on Spiral
                 Architecture",
  author =       "Q. Wu and X. He and T. Hintz",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-68",
  abstract =     "Spiral Architecture is a relatively new and powerful
                 approach to general purpose machine vision system. On
                 this novel architecture, image rotation is achieved by
                 Spiral Multiplication. However, the general image
                 rotation on Spiral Architecture has two effects. One is
                 scaling segmentation and the other is rotation. This
                 paper presents an algorithm to achieve image rotation
                 without scaling on Spiral Architecture, which improves
                 the Spiral Architecture?s usage in image processing.",
  editor =       "V. Skala",
  keywords =     "Image rotation, Spiral Architecture, image
                 segmentation, distributed image processing",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-69,
  year =         "2002",
  title =        "Insertion of Three-Dimensional Objects in
                 Architectural Photos",
  author =       "B. S. V. Alvarez and P. C. P. Carvalho and M.
                 Gattass",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-69",
  abstract =     "This paper proposes a simple and interactive system
                 that allows modifying a photographic picture of a
                 three-dimensional scene involving architectural
                 elements, so that the user can evaluate the aesthetic
                 effects and the impact such modifications in the real
                 environment would cause in other people. The method is
                 based on the existence, in architectural pictures, of
                 three main directions of interest, which are mutually
                 orthogonal. The identification of vanishing points of
                 such directions allows calibrating the camera used to
                 take the pictures and also inserting new elements into
                 the scene.",
  editor =       "V. Skala",
  keywords =     "Three-dimensional edition, camera calibration,
                 projection, pictures, vanishing points, orthogonal
                 directions.",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-7,
  year =         "2002",
  title =        "Real-Time Dynamic Radiosity Relighting of Virtual
                 Environments",
  author =       "K. H. Nielsen and N. J. Christensen",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-7",
  abstract =     "This paper describes a method for dynamic changing of
                 colours and intensities of light sources in a
                 radiosity-lit environment. We introduce a fast
                 radiosity sampling approach where energy is sorted with
                 respect to the emitting lights. The idea is to tag
                 energy with a light source identifier in order to
                 determine from which light source energy is coming
                 from, either directly or indirectly. Based on this
                 information the subsequent reconstruction allows for
                 interactive changing of light source emissions, as long
                 as the geometry in the environment remains static. We
                 illustrate this concept by developing a modified
                 progressive refinement algorithm that performs
                 efficient concurrent sampling of separate light source
                 solutions. We show that the result is useful for
                 real-time animation of realistic lighting in virtual
                 environments. Furthermore, we describe how the method
                 can be adapted to handle near real-time animation of
                 moving light",
  editor =       "V. Skala",
  keywords =     "Radiosity, progressive refinement, dynamic lighting",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-70,
  year =         "2002",
  title =        "A Framework to Investigate Behavioural Models",
  author =       "L. M. Barros and T. F. Evers and S. R. Musse",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-70",
  abstract =     "This paper presents a framework to investigate
                 behavioural models of multiple agents. The framework is
                 intended to deal with problems commonly found in
                 behavioural animation systems, most of which are caused
                 by excessive coupling between the system modules.
                 Hence, the framework is designed to be modular,
                 flexible and extensible. Behavioural animation models
                 based on this framework are clearly divided in modules
                 that can be independently designed and developed.
                 Furthermore, these modules can be easily substituted,
                 modified and reused. We present modules related to
                 crowd behaviour, intelligent camera and virtual
                 environment and how they are integrated using the
                 Python programming language. We also discuss
                 visualization aspects, which are addressed by yet
                 another module.",
  editor =       "V. Skala",
  keywords =     "Behavioural animation, autonomous agents, intelligent
                 camera",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-71,
  year =         "2002",
  title =        "A Rotor Platform Assisted System for 3{D} Hairstyles",
  author =       "Ch.-Y. Lee and W.-R. Chen and E. Leu and M. Ouhyoung",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-71",
  abstract =     "This paper presents an interactive system for creating
                 natural looking 3D hairstyles, by which users can cut,
                 comb and perm the hair model and generate realistic
                 hair images. The system contains three stages:
                 modeling, styling and rendering. In the first phrase,
                 the system produces a physical hair model using a
                 cantilever beam simulation with collision detection.
                 Then the styling phrase is a hair editing process,
                 performing styling operations to change the lengths,
                 positions and curvatures of hair strands. Seven
                 operations are developed for styling. A special
                 hardware rotor platform is developed to aid the hair
                 cut process, so that manipulation by two hands that
                 simulate the real styling is made possible. Users can
                 interact with tools and create various convincing
                 hairstyles. Our system together with the rotor platform
                 increases the ease of hairstyling 60% time saving and
                 can render natural hair images with shadow and
                 back-lighting effects.",
  editor =       "V. Skala",
  keywords =     "Hairstyle, virtual hair modeling, hair styling,
                 collision detection, 3D characters",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-72,
  year =         "2002",
  title =        "The Synthesis of Trees in Chinese Landscape Painting
                 Using Silhouette and Texture Strokes",
  author =       "Der-Lor Way and Yu-Ru Lin and Zen-Chung Shih",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-72",
  abstract =     "Practiced for more than three thousand years, Chinese
                 painting emphasizes {"}implicit meaning{"}, and
                 involves painters using a minimal number of brush
                 strokes to express their deepest feelings. Landscapes
                 are one of the most important themes in Chinese
                 painting. Trees are the essential painting objects.
                 This paper presents a set of novel methods to
                 automatically draw trees in Chinese ink painting from
                 3D polygonal models. Outline rendering and texture
                 generation uses the information of the silhouette,
                 shade and orientation of three-dimensional models
                 surface to draw a particular tree. Four reference maps
                 are established to analyze the information for the bark
                 texture. These methods can draw various styles of bark
                 texture by defining the texture patterns. Finally, this
                 paper demonstrates some results obtained with our
                 method.",
  editor =       "V. Skala",
  keywords =     "Non-Photorealistic Rendering (NPR), Chinese Landscape
                 Painting, TS'UN, Texture Strokes, Silhouette. Curvature
                 Map, Brush, Texture Generation",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-73,
  year =         "2002",
  title =        "Lipreading with Spiking Neurons - One Pass Learning",
  author =       "R. Seguier and N. Cladel and C. Foucher and D.
                 Mercier",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-73",
  abstract =     "We present in this article a lipreading system
                 implementing spiking neurons (STANs). A new
                 preprocessing is proposed in order to reduce as much as
                 possible the learning phase of the system. This
                 training is done in one pass: the user pronounces once
                 all of the words of the dictionary; the system is then
                 able to recognize these words throughout different
                 sessions during which the position and the chrominance
                 of the images of the speaker's mouth strongly change.",
  editor =       "V. Skala",
  keywords =     "HCI, Man Machine Interaction, Lipreading, Visual
                 Speech, Visual Speech Recognition, Neural Network,
                 Spiking Neuron",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-74,
  year =         "2002",
  title =        "Storyworld Creation: Authoring For Interactive
                 Storytelling",
  author =       "O. Schneider",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-74",
  abstract =     "Storytelling - humankinds universal choice for content
                 transmission - is becoming of great importance in the
                 field of computer graphics, as the human ability to
                 keep track of information in the information society of
                 the 21st century is dependent on the quality of the
                 information providing systems. Basically, the first
                 steps towards storytelling systems have been taken;
                 everyone today has the possibility to step into
                 enfolding 3D worlds and become immersed in extensive
                 loads of data. However, there is still a great backlog
                 on the human-like organization of the associated data.
                 The reason for this is the absence of the basic
                 authoring systems for interactive storytelling. This
                 position paper presents an approach to new authoring
                 methods for interactive storytelling. It considers the
                 authors view of the tools to be used and introduces a
                 coherent environment that does not restrict the
                 creative process and lets the author feel comfortable,
                 leading him to create well-narrated, interactive
                 non-linear stories.",
  editor =       "V. Skala",
  keywords =     "Authoring, non-linear story narration, human computer
                 interaction, computer games",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-75,
  year =         "2002",
  title =        "Automatic Graphic User Interface Generation for
                 {VTK}",
  author =       "W. Lefer",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-75",
  abstract =     "VTK (The Visualization Toolkit) has become one of the
                 most popular modular visualization environments. It is
                 an open source software, which has evolved rapidly, new
                 tools being constinuously integrated and a new (minor)
                 release being produced daily. This rapid evolution
                 makes it difficult to develop a graphic user interface
                 (GUI) while maintaining software integrity, that is
                 coherence between interface and code. In this case
                 traditionnal GUI production tools, such as application
                 builders, are not appropriate. This paper proposes a
                 re-engineering approach for automatically generating
                 GUIs for VTK and gives solutions for most of the issues
                 that have to be addressed. We take advantage of the
                 object-oriented feature of VTK to propose a source code
                 analysis method that generates a software components
                 database. Then the rich information contained in this
                 database is used to build a GUI for VTK using a
                 specific GUI technology. This involves a fine analysis
                 of the components of the VTK source and the
                 relationships between them in order to select the
                 components that should be included in the GUI. Then the
                 GUI is generated, which includes a run-time environment
                 to generate and execute the code corresponding to the
                 applications designed by the users. Although VTK has
                 been used to implement our software, the concepts and
                 solutions proposed in this paper are general and could
                 be applied to any object-oriented visualization
                 toolkit.",
  editor =       "V. Skala",
  keywords =     "Visualization Modular Environments, Graphic User
                 Interfaces, Re-engineering Approaches, Object-Oriented
                 Code Analysis, VTK",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-76,
  year =         "2002",
  title =        "Stylized Silhouette Rendering using Progressive
                 Meshes",
  author =       "S. S. Kim and S. K. Choe",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-76",
  abstract =     "Silhouette information has been used to enhance
                 artistic rendering of 3D objects.We present a new
                 method for progressive silhouette rendering of triangle
                 mesh of arbitrary topology by using parameterized brush
                 functions in various styles. The proposed progressive
                 silhouette rendering framework is consist of two major
                 steps; one is mesh simplification for silhouette
                 feature preservation and the other is the stylized
                 silhouette edge rendering. We also improve the mesh
                 simplification algorithm that can preserve silhouette
                 and volume of arbitrary mesh for silhouette rendering.
                 First, for a given mesh, we can obtain progressive
                 mesh(PM) through our proposed mesh simplification
                 algorithm at the preprocessing step. Then, we can
                 render silhouette edges by various kinds of effects
                 progressively by performing the refinement of a given
                 PM from a base mesh. Results demonstrate that
                 progressive silhouette rendering which use the
                 progressive mesh and brush functions can cause effect
                 that a person sketches an arbitrary object gradually.",
  editor =       "V. Skala",
  keywords =     "Non-photorealistic rendering, mesh simplification,
                 progressive sketching, silhouette rendering",
  volume =       "10(3)",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-77,
  year =         "2002",
  title =        "Scan Converting Spirals",
  author =       "F. Taponecco and M. Alexa",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-77",
  abstract =     "Scan-conversion of Archimedes' spiral (a straight line
                 in polar coordinates) is investigated. It is shown that
                 an exact algorithm requires transcendental functions
                 and, thus, cannot have a fast and exact integer
                 implementation. Piecewise polynomial approximations are
                 discussed and a simple algorithm based on piecewise
                 circular approximation is derived. Variations of the
                 algorithms allow to scan convert other types of
                 spirals.",
  editor =       "V. Skala",
  keywords =     "Scan conversion, polar coordinates, linear forms,
                 piecewise approximation",
  volume =       "10(3)",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-78,
  year =         "2002",
  title =        "Fast Algorithms of Plant Computation Based on
                 Substructure Instances",
  author =       "H.-P. Yan and J. F. Barczi and P. de Reffye and B. Hu
                 and M. Jaeger and J. Le Roux",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-78",
  abstract =     "Fast rendering and botanically faithful description of
                 plants are a real challenge in computer graphics.
                 Usually, plant production is computed using the method
                 internode by internode, while there exist a lot of buds
                 in an individual tree, therefore, this approach is
                 quite time-consuming even for a medium-size tree. In
                 this paper, we present a new algorithm based on
                 substructure instances to quickly compute plants
                 production, and then, for certain plant architectural
                 models, combine with the geometrical rules to create a
                 substructure library. Finally, we construct 3D virtual
                 plants using 3D organs. Compared with the classical
                 method in computing and constructing plant structures,
                 the algorithm described in this paper is much faster
                 while keeping botanical nature of plant. The algorithm
                 can be generalized to most plant species.",
  editor =       "V. Skala",
  keywords =     "Plant, Substructure, Fast algorithms",
  volume =       "10(3)",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-79,
  year =         "2002",
  title =        "Ray Interpolants for Fast Ray-Tracing Reflections and
                 Refractions",
  author =       "F. B. Atalay and D. M. Mount",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-79",
  abstract =     "To render an object by ray tracing, one or more rays
                 are shot from the viewpoint through every pixel of the
                 image plane. For reflective and refractive objects,
                 especially for multiple levels of reflections and/or
                 refractions, this requires many expensive intersection
                 calculations. This paper presents a new method for
                 accelerating ray tracing of reflective and refractive
                 objects by substituting accurate-but-slow intersection
                 calculations with approximate-but-fast interpolation
                 computations. Our approach is based on modeling the
                 reflective/refractive object as a function that maps
                 input rays entering the object to output rays exiting
                 the object. We are interested in computing the output
                 ray without actually tracing the input ray through the
                 object. This is achieved by adaptively sampling rays
                 from multiple viewpoints in various directions, as a
                 preprocessing phase, and then interpolating the
                 collection of nearby samples to compute an approximate
                 output ray for any input ray. In most cases, object
                 boundaries and other discontinuities are handled by
                 applying various heuristics. In cases where we cannot
                 find sufficient evidence to interpolate, we perform ray
                 tracing as a last resort. We provide performance
                 studies to demonstrate the efficiency of this method.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Ray tracing, rendering reflections and refractions,
                 interpolation",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-8,
  year =         "2002",
  title =        "A Study about the Form Factors Kernel Function",
  author =       "E. Zeghers and Ch.Renaud",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-8",
  abstract =     "This paper presents a study of the form factors (FF)
                 function kernel. The accuracy of FF estimate is known
                 as a difficult problem when simulating radiative energy
                 exchanges between objects inside an enclosure. By
                 carefully studying the FF function between two polygons
                 we are able to propose a very interesting
                 characterization of its behaviour according to the
                 relative distance between those polygons (general form
                 of the function, location and height of its unique
                 maximum, effect of polygons orientation and distance,
                 ...). According to the results of this study we
                 estimate the FFs between any two polygons by
                 distinguishing the areas where the kernel has smooth
                 variations from the those where it changes quickly. A
                 fine integration is thus performed for the more varying
                 parts of the kernel whereas the other parts are
                 computed more easily. We show that even a very simple
                 implementation of our approach provides accurate
                 estimates of the FF close to the results provided by
                 the Schroeder formula in a time 8 up to 10 times
                 faster. Moreover our approach does not suffer from lack
                 of accuracy when surfaces are very closed from each
                 other thus outperforming classical methods.",
  editor =       "V. Skala",
  keywords =     "Form factors, kernel function, integration",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-80,
  year =         "2002",
  title =        "Objects Recognition by Means of Projective Invariants
                 Considering Corner-points",
  author =       "M. A. Vicente and P. Gil and O. Reinoso and F.
                 Torres",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-80",
  abstract =     "This paper presents an object recognition technique
                 based on projective geometry for industrial pieces that
                 satisfy geometric properties. First at all, we consider
                 some methods of corner detection which are useful for
                 the extraction of interest points in digital images.
                 For object recognition by means of projective
                 invariants, an excessive number of points to be
                 processed supposes a greater complexity of the
                 algorithm We present a method that allows to reduce the
                 points extracted by different corner detection
                 techniques, based on the elimination of non-significant
                 points, using the estimation of the straight lines that
                 contain those points. Secondly, these groups of points
                 are then used to build projective invariants which
                 allow us to distinguish one object from another.
                 Experiments with different pieces and real images in
                 grey-scale show the validity of this approach.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Object recognition, corner detector, projective
                 invariants, projective geometry",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-81,
  year =         "2002",
  title =        "Real-time Visualization of Clouds",
  author =       "P. Heinzlreiter and G. Kurka and J. Volkert",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-81",
  abstract =     "Rendering realistic cloud images is a challenging
                 computational intensive task. The high computational
                 demand makes physics-based on-the-fly rendering
                 impossible for real-time applications on low-cost
                 workstations. We present an approach to overcome this
                 problem by using alpha-blended billboard textures.
                 During a pre-processing step a series of pre-calculated
                 images is generated for each cloud object of the scene.
                 The images are showing each cloud object from different
                 view points. For a given camera position on the ground
                 the final cloud depiction is composed by an appropriate
                 subset of alpha-blended images, assigned to billboard
                 textures. In so doing, we are able to create a smooth
                 transition between arbitrary camera positions on the
                 ground.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Clouds, textures, billboarding, interactive
                 visualization",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-82,
  year =         "2002",
  title =        "The Multi-{LDI}: an Image Based Rendering Approach for
                 Interaction, Navigation, and Visualization in Complex
                 Vitrual Environment",
  author =       "S. L. Stoev and I. Peter and W. Strasser",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-82",
  abstract =     "In this paper, we present a new data structure for
                 image-based rendering: the multi LDI. The multi LDI
                 consists of a number of Layered Depth Images (LDI)
                 covering a hemisphere of possible viewing angles. It
                 allows compact image-based storage and fast rendering
                 of large and complex scenes, while supporting rendering
                 from large range of viewing directions. Since the
                 internal occlusion in each LDI is very small, and only
                 one of the LDIs in the multi LDI is rendered at a time,
                 the rendering cost is significantly reduced compared to
                 geometry-based rendering and even compared to other
                 image-based rendering methods. Moreover, the single
                 LDIs in the multi LDI can be generated on demand using
                 a number of depth images rendered with an offscreen
                 renderer. We also discuss a comparison of the
                 geometry-based rendering and our image-based method and
                 present some measured rendering times. Furthermore, we
                 describe the utilization of this technique in a complex
                 Virtual Environment (VE) for realizing navigation,
                 visualization, and interaction aids. In particular, we
                 present a multiple viewport technique providing two
                 important features: (1) A sort of history during the
                 modeling process, whereas a live 3D copy of the scene
                 is displayed in a window in front of the user. (2)
                 Different live views of the scene, seen from arbitrary
                 viewpoints, in order to display details occluded in the
                 normal view.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Image Based Depth Rendering, Layered Depth Images,
                 Virtual Environments, Interactive Techniques",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-83,
  year =         "2002",
  title =        "Prefetching Policies for Remote Walkthroughs",
  author =       "C. Zach and K. Karner",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-83",
  abstract =     "We present a 3D data streaming approach for remote
                 walkthroughs, that integrates local optimization
                 techniques for realtime rendering with prefetching
                 techniques for remote scene graphs. Especially culling
                 methods, that don't possess frame to frame coherence,
                 can successfully be combined with remote scene
                 databases, if the prefetching algorithm is adapted
                 accordingly. We present a quantitative transmission
                 policy, that takes the limited bandwidth of the network
                 and the limited memory available at the client computer
                 into account.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Distributed/network graphics, 3D data streaming,
                 remote walkthrough, realtime rendering",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-84,
  year =         "2002",
  title =        "Fast Algorithm for Creating Image-Based Stereo
                 Images",
  author =       "P. Kozankiewicz",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-84",
  abstract =     "The process that creates stereo images typically takes
                 from 1.5 to 2 times longer than the algorithm for mono
                 images. This paper presents a fast image-based
                 algorithm for computing stereo images, that needs a
                 little more time than the algorithm for mono images.
                 The presented algorithm uses a single image with depth
                 information (e.g. z-buffer) as an input and produces
                 two images for left and right eye. This algorithm is a
                 simplification of the 3D warping algorithm.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Stereo-vision, image-based rendering, warping",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-85,
  year =         "2002",
  title =        "Interactive Visualization of Volumetric Vector Fields
                 Using Texture Based Particles",
  author =       "S. Guthe and S. Gumhold and W. Strasser",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-85",
  abstract =     "This paper introduces a new approach to the
                 visualization of volumetric vector fields with an
                 adaptive distribution of animated particles that show
                 properties of the underlying steady flow. The shape of
                 the particles illustrates the direction of the vector
                 field in a natural way. The particles are transported
                 along streamlines and their velocity reflects the local
                 magnitude of the vector field. Further physical
                 quantities of the underlying flow can be mapped to the
                 emissive color, the transparency and the length of the
                 particles. A major effort has been made to achieve
                 interactive frame rates for the animation of a large
                 number of particles while minimizing the error of the
                 computed streamlines. There are three main advantages
                 of the new method. Firstly, the animation of the
                 particles diminishes the inherent occlusion problem of
                 volumetric vector field visualization, as the human eye
                 can trace an animated particle even if it is highly
                 occluded. The second advantage is the variable
                 resolution of the visualization method. More particles
                 are distributed in regions of interest. We present a
                 method to automatically adjust the resolution to
                 features of the vector field. Finally, our method is
                 scalable to the computational and rasterization power
                 of the visualization system by simply adjusting the
                 number of visualized particles.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Flow visualization, vector field visualization, flow
                 animation, steady flow, splatting",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-86,
  year =         "2002",
  title =        "Dynamic Visualization of the Combustion Processes in
                 Boilers",
  author =       "M. Gayer and F. Hrdli{\`{e}}ka and P. Slav{\'{i}}k",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-86",
  abstract =     "This paper focuses on the simulation and visualisation
                 of coal combustion in the pulverised coal boilers. It
                 is important to find optimal boiler configurations
                 (both for the ecological and economical reasons),
                 determine appropriate combustibles, optimize process of
                 combustion, etc. These tasks are typically solved using
                 traditional Computational Fluid Dynamics (CFD) methods
                 that are in general computationally very expensive. Our
                 work is based on a different approach. We use
                 simplified methods for determining direction and speed
                 of air stream in particular places in the boiler.
                 Further we use simplified methods for the simulation of
                 combustion processes and heat transfer as well. A
                 particle system is used to simulate and visualise the
                 behaviour of the coal particles and air streams in
                 voxelized boiler space. We developed concept of virtual
                 particles - they represent certain amount of coal, air,
                 ash and other materials in a voxel under
                 investigation.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "FLUENT, visualisation, fluid, CFD, combustion,
                 pulverized coal",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-87,
  year =         "2002",
  title =        "3{D} Design and Simulation of Men Garments",
  author =       "U. Cugini and C. Rizzi",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-87",
  abstract =     "This paper outlines a 3D graphic environment to design
                 and simulate men garments according to fabric
                 properties. The aim is to permit the design in 3D of
                 men base garments, in particular jackets, together with
                 evaluation of their styles and automatic generation of
                 2D patterns from the 3D representation. 3D garment
                 design has been based on the use of MAYA{\^{O}}
                 (Alias/Wavefront) Deformers, while simulation relies on
                 particle-based approach. Main modules of the system are
                 described as well as methodologies and techniques
                 adopted. The prototype has been experimented by
                 end-user; results and final considerations are
                 reported.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Clothing design and simulation, industrial
                 application, particle-based model",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-88,
  year =         "2002",
  title =        "Real-Time Recursive Specular Reflections on Planar and
                 Curved Surfaces using Graphics Hardware",
  author =       "K. H. Nielsen and N. J. Christensen",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-88",
  abstract =     "Real-time rendering of recursive reflections have
                 previously been done using different techniques.
                 However, a fast unified approach for capturing
                 recursive reflections on both planar and curved
                 surfaces, as well as glossy reflections and
                 interreflections between such primitives, have not been
                 described. This paper describes a framework for
                 efficient simulation of recursive specular reflections
                 in scenes containing both planar and curved surfaces.
                 We describe and compare two methods that utilize
                 texture mapping and environment mapping, while having
                 reasonable memory requirements. The methods are
                 texture-based to allow for the simulation of glossy
                 reflections using image-filtering. We show that the
                 methods can render recursive reflections in static and
                 dynamic scenes in real-time on current consumer
                 graphics hardware. The methods make it possible to
                 obtain a realism close to ray traced images at
                 interactive frame rates.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Real-time rendering, recursive specular reflections,
                 texture, environment mapping",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-89,
  year =         "2002",
  title =        "Vector Field Metrics Based on Distance Measures of
                 First Order Critical Points",
  author =       "H. Theisel and T. Weinkauf",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-89",
  abstract =     "Topological methods have been proven to be useful both
                 for the visualization and the definition of distance
                 measures of vector fields. This paper introduces and
                 assesses a new distance measure for first order
                 critical points of 2D vector fields. This distance
                 measure forms the foundation of the definition of
                 vector field metrics. Based on this we give an advanced
                 and complete classification of all first order critical
                 points.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Flow visualization, vector field topology, first oder
                 critical point, distance measure",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-9,
  year =         "2002",
  title =        "Direct Pattern Tracking On Flexible Geometry",
  author =       "I. Guskov and L. Zhukov",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-9",
  abstract =     "We introduce a robust tracking procedure for a regular
                 pattern marked on a flexible moving surface such as
                 cloth. A video of an actor performing a range of
                 motions is processed with our algorithm to yield a
                 dynamic geometric representation. The system is capable
                 of maintaining the tracked grid structure for long
                 periods of time without quality deterioration, and
                 requires minimal user interaction. It has been tested
                 on videos of an actor dressed in a specially marked
                 T-shirt and behaves favorably with the presence of
                 self-occlusions, self-shadowing and folding of the
                 cloth. The focus of this paper is on single camera
                 video sequence processing, even though 3D shape
                 reconstruction with multiple cameras is the motivating
                 goal.",
  editor =       "V. Skala",
  keywords =     "Pattern analysis, template matching, dynamic
                 geometry",
  volume =       "10",
  booktitle =    "Journal of WSCG",
}

@InProceedings{EVL-2002-90,
  year =         "2002",
  title =        "Computer-Aided Detection and Segmentation of Objects
                 on Medical Images",
  author =       "T. Belikova and R. Palenichka and I. Ivasenko",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-90",
  abstract =     "Series of methods for improved detecting and
                 segmenting objects, situated on a complex background,
                 have been developed. Model-based detection was applied
                 for automatic detection and segmentation of the objects
                 of interest on initial images and images after optimal
                 filtering. The optimal linear filter was used to
                 improve imaging of the object (its details and margin)
                 on the observed image. Filtering of small-size details
                 to improve false alarm and misdetection rates then
                 followed the segmentation procedure. Developed series
                 of methods were tested on test images and real medical
                 images (lung tomograms) with small solitary nodules. A
                 comparison of segmentation results obtained before and
                 after optimal filtering showed that optimal filtering
                 allows to outline the object region on medical images
                 better and helps to identify more precisely the object
                 margin. The developed series of methods can be useful
                 for computer-assisted detection, segmentation, and
                 analysis of low contrast flaws (lesions) on a complex
                 image background that is important for solving of
                 numerous medical tasks and for technical tasks of
                 material inspection.",
  editor =       "V. Skala",
  volume =       "10(3)",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-91,
  year =         "2002",
  title =        "Multicomputer System {DEDAL}-2 for Local Landscape
                 Monitoring",
  author =       "I. V. Gribkov and P. P. Koltsov and N. V. Kotovich and
                 A. A. Kravchenko and A. S. Kutsaev and V. K. Nikolaev
                 and A. V. Zakharov",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-91",
  abstract =     "The paper contains the description of a multicomputer
                 system for terrestrial surface automatized monitoring.
                 The system is able to detect moving objects on the
                 terrain considered, to locate static objects which
                 appear/disappear on terrain as well as to recognize
                 such objects. The system uses photosnapshot the terrain
                 and a set of reference images for recognition.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Image processing, Pattern recognition, Motion
                 analysis, Contour extracting",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-92,
  year =         "2002",
  title =        "Measuring Isotropic Local Contrast: {A} Circular Mask
                 Based Approach",
  author =       "B. Montrucchio and F. Lamberti and A. Sanna and P.
                 Montuschi",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-92",
  abstract =     "Many image processing tasks depend on contrast
                 measures, which can be used to compare and improve
                 contrast enhancement algorithms. Contrast definitions
                 are not always suitable for all situations. In
                 particular an isotropic local contrast measure, that
                 produces a flat response to sinusoidal gratings, can be
                 difficult to obtain. In this paper we review the main
                 existing contrast measures, and propose a new approach,
                 denoted as Circular Mask Metric (CMM). It is based on
                 band-pass filters and circular mask based local
                 contrast computations. This approach has been applied
                 on different test images and with three contrast
                 enhancement methods, in order to show its
                 potentialities for contrast enhancement algorithm
                 testing and improving.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Isotropic local contrast, contrast enhancement
                 comparing, circular mask based approach",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-93,
  year =         "2002",
  title =        "A Multi-Scale Approach to Corner Tracking",
  author =       "F. Mohanna and F. Mokhtarian",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-93",
  abstract =     "This paper presents a multi-scale corner tracking
                 algorithm based on a multi-scale corner detector. To
                 extract corners from each frame of video sequences, the
                 enhanced CSS corner detector using different scales of
                 smoothing is applied. In the matching stage two-frame
                 correspondence combined with three-frame based
                 monitoring is considered. We monitor tracked corners
                 from the third frame of input sequence in matching
                 stage. Proposed three-frame monitoring helps to ensure
                 that the number of tracked corners and their tracked
                 positions among frames become more robust. Since the
                 proposed corner tracker has enough robust corners based
                 on multi-scale corner detector, it is practical and
                 efficient. In matching stage, among similarity
                 functions, standard cross-correlation, zero-mean
                 cross-correlation, sum of squared differences, and
                 x2-test measurements are tested. Well-known real video
                 databases depicting translation, scaling, rotation and
                 affine transformation with different lighting and
                 different camera motions are used as experiments. All
                 experiments confirm that the performance of the
                 proposed tracker is high and reliable due to monitoring
                 matched corners among frames.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Corner detection, curvature scale space, Canny edge
                 detector, corner matching, correspondence",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-94,
  year =         "2002",
  title =        "Free Form Shape Representation Using {NURBS}
                 Modeling",
  author =       "K. M. Liang and M. Rajeswari and B. E. Khoo",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-94",
  abstract =     "The representation, matching and analysis of objects
                 of interest are of prime importance in shape-based
                 retrieval systems. Considering that these systems
                 involve analysis of various complex shapes, an accurate
                 representation of free form shape is required. A simple
                 and accurate shape representation procedure would
                 ensure meaningful results from the shape-based
                 retrieval systems. Motivated by this factor, this paper
                 presents a free form shape representation technique
                 using Non-Uniform Rational B-Spline (NURBS) modelling.
                 The free form shapes are modelled using control points
                 and weights. NURBS posses attractive properties such as
                 spatial uniqueness, bounded and continuous, local shape
                 controllability and shape invariance under
                 transformation. Furthermore, NURBS based shape
                 descriptor allows accurate reconstruction of the shape
                 boundary from the NURBS features used to describe it.
                 This paper presents the details of deriving a set of
                 NURBS features using the boundary of the object. The
                 accuracy and data reduction properties using NURBS are
                 examined by carrying out an experiment on two sets of
                 images: geometric and free form. Accuracy of the
                 representation is evaluated by using centroid-radii
                 error function, which computes the cumulative distance
                 between the intersection points by radii lines on the
                 boundary of the original image and the reconstructed
                 image. The data reduction property is shown by the
                 ratio computation between the number of control points
                 and the boundary points. The overall experiment results
                 show that NURBS is an accurate shape descriptor and a
                 potential candidate for use in shape-based image
                 retrieval systems.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Shape Representation, NURBS, Shape-Based Image
                 Retrieval",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-95,
  year =         "2002",
  title =        "An Intelligent Hybrid Approach for
                 Design-by-Features",
  author =       "L. Ding and Y. Yue",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-95",
  abstract =     "This paper presents a new methodology for
                 design-by-features. After a brief background study of
                 design-by-features, a architecture with a feature
                 library, feature-based model, feature library
                 management and feature-based model management is
                 introduced. A standard feature class is defined for
                 feature library. Automatic feature-based model
                 management covering interactive functions,
                 identification of feature interaction and maintenance
                 of the model validity is described. Finally,
                 conclusions are drawn and further research
                 summarised.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Design-by-features, feature-based model, feature
                 interaction, feature library, validity constraints.",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-96,
  year =         "2002",
  title =        "Simulating Virtual Character's Learning Behaviour as
                 An Evolutionary Process Using Genetic Algorithms",
  author =       "T. R. Wan and W. Tang",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-96",
  abstract =     "In this paper, we describe a genetic algorithm
                 approach to simulate complex virtual character's
                 learning behaviours as an evolutionary process. The
                 method presented here enables virtual character to have
                 abilities to learn for specific assigned tasks. The
                 skill for the task can be developed and evolved through
                 the experiences of performing the task. The animation
                 system presented here has two tightly coupled
                 simulation units, which are an artificial brain unit
                 for learning and controlling and a physics-based motion
                 simulation unit driven by simulated muscle forces",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Autonomous virtual learning characters, motion
                 control, genetic algorithms, virtual environment",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-97,
  year =         "2002",
  title =        "Interactive Information Visualization of
                 Entity-Relationship-Data",
  author =       "T. Rieger and F. Taponecco",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-97",
  abstract =     "This work presents methods for interactive analysis of
                 unknown data and relations. It supports the selection
                 of relevant parts of the data and the visualization of
                 relations using different layout strategies for 2d
                 visualizations and for 3d visualizations. Moreover, the
                 user can select additional mappings to display extra
                 information, with the help of supplementary visual
                 variables in an easy way. Hereby the user can
                 interactively create new visualizations and new sights
                 and sift through the data in order to reveal
                 discrepancies, to uncover trends or to provide vital
                 operational insights.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Data Mining, KDDB, DBMS, Entity-Relationship-Data,
                 Spiral, Layout, Mapper, 3d Space",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-98,
  year =         "2002",
  title =        "A Graphical User Interface Framework for Digital
                 Television",
  author =       "C. Pable and V. Petri",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-98",
  abstract =     "Currently, the number of non-PC devices used for
                 interactive applications is increasing. Digital
                 television set-top boxes, PDAs, and mobile phones are
                 typical examples. Interactive applications are
                 controlled via a Graphical User Interface (GUI).
                 Consequently, a GUI framework is required. The
                 objective is a unified GUI framework for all these new
                 devices. Since one of the new devices is digital
                 television, an implementation of a digital television
                 GUI framework is presented. It has been developed
                 following the HAVi specifications. Its main
                 characteristics are use of Java, separation of look and
                 feel, and lightweight widgets. The implementation is
                 tested with a digital television application. The main
                 conclusion proposed is that new devices should use a
                 device-oriented GUI framework implementation. Moreover,
                 specific implementations can be obtained by modifying
                 the look or feel of the widgets.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Digital television, DVB-MHP, GUI, HAVi, Java",
  booktitle =    "Journal of WSCG 2002",
}

@InProceedings{EVL-2002-99,
  year =         "2002",
  title =        "An Approach to Real-Time Plant Generation",
  author =       "M. Danaher and W. Creemers",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2002-99",
  abstract =     "In this paper methods are presented for the
                 visualisation of plant life for games and other
                 graphics simulations in real time. Current systems
                 generally use a very limited number of models of plants
                 that are created in advance and loaded into the system
                 at execution time. Real-time generation saves disk
                 space and allows for a great variety of plants to be
                 used in a game. The methods described here will allow
                 the creation of interesting and varied plant life and
                 thus produce a far richer, more appealing and
                 engrossing environment for users.",
  editor =       "V. Skala",
  volume =       "10(3)",
  keywords =     "Plant life, real-time, visualisation",
  booktitle =    "Journal of WSCG 2002",
}
