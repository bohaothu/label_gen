@STRING{colt93	= "Proceedings of the Sixth Annual ACM Conference on
		  Computational Learning Theory" }
@STRING{jacm	= "Journal of the Association for Computing Machinery" }
@STRING{jma	= "Journal of Multivariate Analysis" }
@STRING{lncs	= "Lecture Notes of Computer Science, Springer" }
@STRING{lncs	= "Lecture Notes in Computer Science" }
@STRING{nips	= "Advances in Neural Information Processing Systems" }
@STRING{pecs	= "Colloquia Mathematica Societatis Janos Bolai, 57.\ Limit
		  Theorem in Probability and Statistics, Pecs (Hungary)" }
@STRING{spl	= "Statistics \& Probability Letters" }

@Article{A:Circle-Homogen,
  author	= {P. Auer},
  title		= {The circle homogeneously covered by random walk on
		  {Z}$^2$},
  journal	= spl,
  year		= 1990,
  pages		= {403--407},
  volume	= 9
}

@InProceedings{A:CombinationTheories,
  author	= {P. Auer},
  booktitle	= {Word Equations and Related Topics},
  pages		= {177--186},
  publisher	= {Lecture Notes of Computer Science 677, Springer},
  title		= {Unification in the Combination of Disjoint Theories},
  year		= {1991}
}

@InProceedings{A:Hitting-Prob,
  author	= {P. Auer},
  booktitle	= pecs,
  pages		= {9--25},
  title		= {Some Hitting Probabilities of Random Walks on {Z}$^2$},
  year		= 1989
}

@InProceedings{A:Relative-Frequ,
  author	= {P. Auer and P. R\'{e}v\'{e}sz},
  booktitle	= pecs,
  pages		= {27--33},
  title		= {On the Relative Frequency of Points Visited by random Walk
		  on {Z}$^2$},
  year		= 1989
}

@InProceedings{A:WordEquations,
  author	= {P. Auer},
  booktitle	= {Word Equations and Related Topics},
  key		= {A:WordEquations},
  pages		= {103--132},
  publisher	= {Lecture Notes of Computer Science 677, Springer},
  title		= {Solving String Equations with Constant Restrictions},
  year		= {1991}
}

@InProceedings{AC94,
  author	= {P. Auer and N. C{esa-Bianchi}},
  booktitle	= {Algorithmic Learning Theory, AII'94, ALT'94},
  editor	= {Setsuo Arikawa and Klaus P. Jantke},
  pages		= {229--247},
  publisher	= {Lecture Notes in Artificial Intelligence 872, Springer},
  title		= {On-line Learning with Malicious Noise and the Closure
		  Algorithm},
  year		= {1994}
}

@Article{AC94j,
  author	= {P. Auer and N. C{esa-Bianchi}},
  journal	= {Annals of Mathematics and Artificial Intelligence},
  title		= {On-line Learning with Malicious Noise and the Closure
		  Algorithm},
  year		= {1998},
  volume	= {23},
  pages		= {83--99},
  note		= {A preliminary version has appeared in {\em Lecture Notes
		  in Artificial Intelligence} 872, Springer}
}

@InProceedings{AC96,
  author	= {P. Auer and P. Caianiello and N. Cesa-Bianchi},
  booktitle	= {Proceedings of the 15th Annual ACM Symposium on Principles
		  of Distributed Computing},
  note		= {Abstract},
  pages		= {312},
  title		= {Tight Bounds on the Cumulative Profit of Distributed
		  Voters},
  year		= {1996}
}

@InProceedings{ACFS95,
  author	= {P. Auer and N. Cesa-Bianchi and Y. Freund and R. E.
		  Schapire},
  booktitle	= {Proceedings of the 36th Annual Symposium on Foundations of
		  Computer Science},
  pages		= {322--331},
  publisher	= {IEEE Computer Society Press, Los Alamitos, CA},
  title		= {Gambling in a Rigged Casino: The Adversarial Multi-Armed
		  Bandit Problem},
  year		= {1995}
}

@Article{AH94gL,
  author	= {P. Auer and K. Hornik},
  journal	= {Journal of Multivariate Analysis},
  pages		= {37--51},
  title		= {The Number of Points of an Empirical or {Poisson} Process
		  Covered by Unions of Sets},
  volume	= {57},
  year		= {1996}
}

@Article{AH94jma,
  author	= {P. Auer and K. Hornik},
  journal	= jma,
  number	= {1},
  pages		= {115--156},
  title		= {On the Number of Points of a Homogeneous {P}oisson
		  Process},
  volume	= {48},
  year		= {1994}
}

@Article{AH96,
  author	= {P. Auer and K. Hornik},
  journal	= {Studia Scientiarum Mathematicarum Hungarica},
  pages		= {1--13},
  title		= {Limit Laws for the Maximal and Minimal Increments of the
		  {P}oisson Process},
  volume	= {31},
  year		= {1996}
}

@Article{AHR91,
  author	= {P. Auer and K. Hornik and P. R\'{e}v\'{e}sz},
  journal	= spl,
  pages		= {91--96},
  title		= {Some Limit Theorems for the Homogeneous {P}oisson
		  Process},
  volume	= 12,
  year		= 1991
}

@InCollection{AHW95,
  author	= {P. Auer and M. Herbster and M. K. Warmuth},
  booktitle	= {Advances in Neural Information Processing Systems 8},
  editor	= {D. S. Touretzky and M. C. Mozer and M. E. Hasselmo},
  pages		= {316--322},
  publisher	= {MIT Press},
  title		= {Exponentially Many Local Minima for Single Neurons},
  year		= {1996}
}

@Article{AL93,
  author	= {P. Auer and P. M. Long},
  title		= {Structural Results About On-line Learning Models With and
		  Without Queries},
  journal	= {Machine Learning},
  year		= {1999},
  volume	= {36},
  pages		= {147--181},
  note		= {A preliminary version has appeared in {\em Proceedings of
		  the 26th ACM Symposium on the Theory of Computing}}
}

@InProceedings{AL94,
  author	= {P. Auer and P. M. Long},
  booktitle	= {Proceedings of the 26th Annual ACM Symposium on the Theory
		  of Computing},
  pages		= {263--272},
  publisher	= {ACM Press},
  title		= {Simulating access to hidden information while learning},
  year		= {1994}
}

@InProceedings{ALS97,
  author	= {P. Auer and P. M. Long and A. Srinivasan},
  booktitle	= {Proc.\ 29th Ann.\ Symp.\ Theory of Computing},
  month		= {May},
  pages		= {314--323},
  publisher	= {ACM},
  title		= {Approximating Hyper-Rectangles: Learning and Pseudo-random
		  Sets},
  year		= {1997}
}

@Article{ALS97j,
  author	= {P. Auer and P. M. Long and A. Srinivasan},
  title		= {Approximating Hyper-Rectangles: Learning and Pseudorandom
		  Sets},
  journal	= {Journal of Computer and System Sciences},
  year		= {1998},
  volume	= {57},
  number	= {3},
  pages		= {376--388},
  note		= {A preliminary version has appeared in {\em Proc.\ 29th
		  Ann.\ Symp.\ Theory of Computing}}
}

@InProceedings{AW95,
  author	= {P. Auer and M. K. Warmuth},
  booktitle	= {Proceedings of the 36th Annual Symposium on Foundations of
		  Computer Science},
  pages		= {312--321},
  publisher	= {IEEE Computer Society Press},
  title		= {Tracking the Best Disjunction},
  year		= {1995}
}

@Article{AW95j,
  author	= {P. Auer and M. K. Warmuth},
  title		= {Tracking the Best Disjunction},
  journal	= {Machine Learning},
  year		= {1998},
  volume	= {32},
  pages		= {127--150},
  note		= {A preliminary version has appeared in {\em Proceedings of
		  the 36th Annual Symposium on Foundations of Computer
		  Science}}
}

@InProceedings{Aue93,
  author	= {P. Auer},
  booktitle	= {Proceedings of the Sixth Annual ACM Conference on
		  Computational Learning Theory},
  pages		= {253--261},
  publisher	= {ACM Press, New York, NY},
  title		= {On-line Learning of Rectangles in Noisy Environments},
  year		= {1993}
}

@InProceedings{Aue95,
  author	= {P. Auer},
  booktitle	= {6th International Workshop, ALT`95, Proceedings},
  editor	= {Klaus P. Jantke and Takeshi Shinohara and Thomas
		  Zeugmann},
  note		= {LNAI 997},
  pages		= {123--137},
  publisher	= {Springer},
  title		= {Learning Nested Differences in the Presence of Malicious
		  Noise},
  year		= {1995}
}

@Article{Aue95j,
  author	= {P. Auer},
  title		= {Learning Nested Differences in the Presence of Malicious
		  Noise},
  journal	= {Theoretical Computer Science},
  year		= {1997},
  volume	= {185},
  pages		= {159--175},
  note		= {A preliminary version has appeared in {\em Proceedings of
		  the 6th International Workshop on Algorithmic Learning
		  Theory, ALT`95.}}
}

@InProceedings{Aue96,
  author	= {P. Auer},
  booktitle	= {Proc.\ 14th Int.\ Conf.\ Machine Learning},
  editor	= {D. H. Fisher},
  pages		= {21--29},
  publisher	= {Morgan Kaufmann},
  title		= {On Learning from Multi-Instance Examples: Empirical
		  Evaluation of a Theoretical Approach},
  year		= {1997}
}

@InProceedings{AuerETAL:01,
  author	= {P. Auer and H. Burgsteiner and W. Maass},
  title		= {Reducing Communication for Distributed Learning in Neural
		  Networks},
  booktitle	= {<a
		  href="http://www.springer.de/comp/lncs/index.html">Proc. of
		  the International Conference on Artificial Neural Networks
		  -- ICANN 2002</a>},
  series	= {Lecture Notes in Computer Science},
  editor	= {Jos\'{e} R. Dorronsoro},
  pages		= {123--128},
  volume	= {2415},
  year		= {2002},
  publisher	= {Springer},
  keywords	= {learning algorithm, perceptrons, parallel, aVLSI },
  abstract	= {A learning algorithm is presented for circuits consisting
		  of a single layer of perceptrons. We refer to such circuits
		  as parallel perceptrons. In spite of their simplicity,
		  these circuits are universal approximators for arbitrary
		  boolean and continuous functions. In contrast to backprop
		  for multi-layer perceptrons, our new learning algorithm -
		  the parallel delta rule (p-delta rule) - only has to tune a
		  single layer of weights, and it does not require the
		  computation and communication of analog values with high
		  precision. This distinguishes our new learning rule also
		  from other learning rules for such circuits such as
		  MADALINE with far higher communication. Our algorithm also
		  provides an interesting new hypothesis for the organization
		  of learning in biological neural systems. A theoretical
		  analysis shows that the p-delta rule does in fact implement
		  gradient descent - with regard to a suitable error measure
		  - although it does not require to compute derivatives.
		  Furthermore it is shown through experiments on common
		  real-world benchmark datasets that its performance is
		  competitive with that of other learning approaches from
		  neural networks and machine learning.}
}

@Article{AuerETAL:01a,
  author	= {P. Auer and H. Burgsteiner and W. Maass},
  title		= {A learning rule for very simple universal approximators
		  consisting of a single layer of perceptrons},
  journal	= {Neural Networks},
  note		= {in press},
  year		= {2007},
  abstract	= {A learning algorithm is presented for circuits consisting
		  of a single layer of perceptrons (= threshold gates, or
		  equivalently gates with a Heaviside activation function).
		  We refer to such circuits as parallel perceptrons. In spite
		  of their simplicity, these circuits can compute any boolean
		  function if one views the majority of the binary perceptron
		  outputs as the binary outputs of the parallel perceptron,
		  and they are universal approximators for arbitrary
		  continuous functions with values in [0,1] if one views the
		  fraction of perceptrons that output 1 as the analog output
		  of the parallel perceptron. For a long time one has thought
		  that there exists no competitive learning algorithms for
		  these extremely simple circuits consisting of gates with
		  binary outputs, which also became known as committee
		  machines. It is commonly believed that one has to replace
		  the hard threshold gates by sigmoidal gates and that one
		  has to tune the weights on at least two successive layers
		  in order to get satisfactory learning results. We show that
		  this is not true by exhibiting a simple learning algorithm
		  for parallel perceptrons - the parallel delta rule (p-delta
		  rule), whose performance is comparable to that of backprop
		  for multilayer networks consisting of sigmoidal gates. In
		  contrast to backprop, the p-delta rule does not require the
		  computation and communication of analog values with high
		  precision, although it does in fact implement gradient
		  descent - with regard to a suitable error measure.
		  Therefore it provides an interesting new hypothesis for the
		  organization of learning in biological neural systems.}
}

@InProceedings{AuerETAL:93,
  author	= {P. Auer and P. M. Long and W. Maass and G. J.
		  W\"{o}ginger},
  booktitle	= {Proceedings of the 5th Annual ACM Conference on
		  Computational Learning Theory},
  pages		= {392--401},
  title		= {On the complexity of function learning},
  year		= {1993}
}

@Article{AuerETAL:93j,
  author	= {P. Auer and P. M. Long and W. Maass and G. J.
		  W\"{o}ginger},
  title		= {On the complexity of function learning},
  journal	= {Machine Learning},
  note		= {Invited paper in a special issue of Machine Learning},
  year		= {1995},
  volume	= {18},
  pages		= {187--230}
}

@InProceedings{AuerETAL:95,
  author	= {P. Auer and R. C. Holte and W. Maass},
  booktitle	= {Proc. of the 12th International Machine Learning
		  Conference, Tahoe City (USA)},
  publisher	= {Morgan Kaufmann (San Francisco)},
  pages		= {21--29},
  title		= {Theory and applications of agnostic {PAC}-learning with
		  small decision trees},
  year		= {1995}
}

@InProceedings{AuerETAL:96,
  author	= {P. Auer and S. Kwek and W. Maass and M. K. Warmuth},
  booktitle	= {Proc. of the 9th Conference on Computational Learning
		  Theory 1996},
  pages		= {333--343},
  publisher	= {ACM-Press (New York)},
  title		= {Learning of depth two neural nets with constant fan-in at
		  the hidden nodes},
  year		= {1996}
}

@Article{AuerMaass:98,
  author	= {P. Auer and W. Maass},
  title		= {Introduction to the Special Issue on Computational
		  Learning Theory},
  journal	= {Algorithmica},
  year		= {1998},
  volume	= {22},
  number	= {1/2},
  pages		= {1--2}
}

@Article{HSWA,
  author	= {K. Hornik and M. Stinchcombe and H. White and P. Auer},
  journal	= {Neural Computation},
  pages		= {1262--1275},
  title		= {Degree of approximation results for feedforward networks
		  approximating unknown mappings and their derivatives},
  volume	= {6},
  year		= {1994}
}

@Article{KWA97,
  author	= {J. Kivinen and M. K. Warmuth and P. Auer},
  title		= {The Perceptron algorithm vs. {Winnow}: linear vs.
		  logarithmic mistake bounds when few input variables are
		  relevant},
  journal	= {Artificial Intelligence},
  year		= {1997},
  pages		= {325--343}
}

@Article{a-lai-97,
  author	= {P. Auer},
  title		= {On Learning from Ambiguous Information},
  journal	= {Periodica Polytechnica Electrical Engineering},
  year		= {1998},
  volume	= {42},
  number	= {1},
  pages		= {115-122}
}

@InProceedings{a-srlfa-99,
  author	= {P. Auer},
  title		= {An Improved On-line Algorithm for Learning Linear
		  Evaluation Functions},
  booktitle	= {Proc. 13th Ann. Conf. Computational Learning Theory},
  pages		= {118--125},
  year		= {2000},
  publisher	= {Morgan Kaufmann}
}

@InProceedings{a-tnnb-98,
  author	= {P. Auer},
  title		= {Some thoughts on Boosting and Neural Networks},
  booktitle	= {Beitr\"{a}ge zum 3.~Cottbuser Workshop `Aspekte des
		  Neuronalen Lernens' CoWAN'98},
  editor	= {L. Cromme and T. Kolb and H. Koch},
  optvolume	= {},
  optnumber	= {},
  optseries	= {},
  year		= {1998},
  optorganization={},
  publisher	= {Shaker Verlag},
  address	= {Cottbus, Germany},
  month		= {October},
  pages		= {11--28},
  note		= {Invited paper}
}

@Article{a-ucbeeto-2002,
  author	= {P. Auer},
  title		= {Using Confidence Bounds for Exploitation-Exploration
		  Trade-offs},
  journal	= {J. Machine Learning Research},
  year		= {2002},
  volume	= {3(Nov)},
  pages		= {397--422},
  note		= {A preliminary version has appeared in {\em Proc. of the
		  41th Annual Symposium on Foundations of Computer Science}}
}

@InProceedings{a-uucbol-00,
  author	= {P. Auer},
  title		= {Using Upper Confidence Bounds for Online Learning},
  booktitle	= {Proceedings of the 41th Annual Symposium on Foundations of
		  Computer Science},
  pages		= {270--293},
  year		= {2000},
  publisher	= {IEEE Computer Society}
}

@Article{a-wsdaq-02,
  author	= {P. Auer},
  title		= {Why Students Don't Ask Questions},
  journal	= {TELEMATIK},
  year		= {2002},
  pages		= {21--23},
  volume	= {8},
  number	= {1},
  note		= {Special Issue on Foundations of Information Processing for
		  the 21st Century},
  optannote	= {}
}

@Article{acbfs-nsmabp-2002,
  author	= {P. Auer and N. Cesa-Bianchi and Y. Freund and R. E.
		  Schapire },
  title		= {The Nonstochastic Multiarmed Bandit Problem},
  journal	= {SIAM Journal on Computing},
  year		= {2002},
  volume	= {32},
  number	= {1},
  pages		= {48--77},
  note		= {A preliminary version has appeared in {\em Proceedings of
		  the 36th Annual Symposium on Foundations of Computer
		  Science}}
}

@Article{acbg-ascolla-2003,
  author	= {P. Auer and N. Cesa-Bianchi and C. Gentile},
  title		= {Adaptive and Self-Confident On-Line Learning Algorithms},
  journal	= {JCSS},
  year		= {2002},
  volume	= {64},
  number	= {1},
  pages		= {48--75},
  note		= {A preliminary version has appeared in {\em Proc. 13th Ann.
		  Conf. Computational Learning Theory}}
}

@Article{acf-ftamabp-02,
  author	= {P. Auer and N. Cesa-Bianchi and P. Fischer},
  title		= {Finite Time Analysis of the Multiarmed Bandit Problem},
  journal	= {Machine Learning},
  year		= {2002},
  volume	= {47},
  number	= {2/3},
  pages		= {235--256},
  note		= {A preliminary version has appeared in {\em Proc. of the
		  15th International Conference on Machine Learning}}
}

@InProceedings{acf-ftamabp-99,
  author	= {P. Auer and N. Cesa-Bianchi and P. Fischer},
  title		= {Finite Time Analysis of the Multiarmed Bandit Problem},
  booktitle	= {IT Workshop on Decision, Estimation, Classification and
		  Imaging},
  year		= {1999},
  optorganization={},
  optpublisher	= {},
  address	= {Santa Fe},
  month		= {Feb}
}

@InProceedings{ag-asola-00,
  author	= {P. Auer and C. Gentile},
  title		= {Adaptive and Self-Confident On-Line Learning Algorithms},
  booktitle	= {Proc. 13th Ann. Conf. Computational Learning Theory},
  year		= {2000},
  pages		= {107--117},
  publisher	= {Morgan Kaufmann}
}

@Article{aksb-isve-2002,
  author	= {K. Andrews and W. Kienreich and V. Sabol and J. Becker and
		  G. Droschl and F. Kappe and M. Granitzer and P. Auer and K.
		  Tochtermann},
  title		= {The {InfoSky} visual explorer: exploiting hierarchical
		  structure and document similarities},
  journal	= {Information Visualization},
  year		= {2002},
  volume	= {1},
  pages		= {166--181}
}
