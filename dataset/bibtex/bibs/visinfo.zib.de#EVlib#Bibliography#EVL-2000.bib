%%% ----------------------------------------------------------------------
%%% BibTeX-file {
%%%    author	 = "{Electronic Visualization Library Service}",
%%%    filename  = "EVL-2000.bib",
%%%    address   = "Konrad-Zuse-Zentrum f{\"u}r
%%%                 Informationstechnik Berlin (ZIB)
%%%                 Scientific Visualization Department
%%%                 Takustr. 7
%%%                 14195 Berlin
%%%                 Germany",
%%%    URL       = "http://visinfo.zib.de/EVlib/",
%%%    email     = "davis@zib.de",
%%%    supported = "yes",
%%%    docstring = "This file contains the complete bibliography of
%%%                 references submitted to the 
%%%                 Electronic Visualization Library for the year 2000.",
%%% }


@InProceedings{EVL-2000-10,
  pages =        "222--233",
  year =         "2000",
  title =        "Visual shape retrieval using multiscale term
                 distributions",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-10",
  author =       "B. J. Super",
  organization = "SPIE",
  month =        jan,
  editor =       "M. M. Yeung and B.-L. Yeo and C. A. Bouman",
  volume =       "3972",
  keywords =     "shape retrieval, scale space representation,
                 content-based image retrieval, visual information
                 retrieval, shape database, histograms, term frequency
                 vectors",
  booktitle =    "Proceedings of SPIE: Storage and Retrieval for Media
                 Databases 2000",
}

@InProceedings{EVL-2000-100,
  year =         "2000",
  title =        "Automatic Generation of Virtual Woodblocks and
                 Multicolor Woodblock Printing",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-100",
  author =       "S. Mizuno and A. Kasaura and S. Yamamoto and M. Okada
                 and J. Toriwaki",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-101,
  year =         "2000",
  title =        "{LCTS}: Ray Shooting using Longest Common Traversal
                 Sequence",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-101",
  author =       "V. Havran and J. Bittner",
  abstract =     "We describe two new techniques of ray shooting
                 acceleration that exploit the traversal coherence of a
                 spatial hierarchy. The first technique determines a
                 sequence of adjacent leaf-cells of the hierarchy that
                 is pierced by all rays contained within a certain
                 convex shaft. This sequence is used to accelerate ray
                 shooting for all remaining rays within the shaft. The
                 second technique establishes a cut of the hierarchy
                 that contains nodes where the hierarchy traversal can
                 no longer be predetermined for all rays contained
                 within a given shaft. This cut is used to initiate the
                 traversal for all remaining rays contained in the
                 shaft. The description of the methods is followed by
                 results evaluated by their practical implementation.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-102,
  pages =        "1--10",
  year =         "2000",
  title =        "Modelling Virtual Cities Dedicated To Behavioural
                 Animation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-102",
  author =       "G. Thomas and S. Donikian",
  abstract =     "In order to populate virtual cities, it is necessary
                 to specify the behaviour of dynamic entities such as
                 pedestrians or car drivers. Since a complete mental
                 model based on vision and image processing cannot be
                 constructed in real time using purely geometrical
                 information, higher levels of information are needed in
                 a model of the virtual environment. For example, the
                 autonomous actors of a virtual world would exploit the
                 knowledge of the environment topology to navigate
                 through it. In this article, we present a model of
                 virtual urban environments using structures and
                 information suitable for behavioural animations. Thanks
                 to this knowledge, autonomous virtual actors can behave
                 like pedestrians or car drivers in a complex city
                 environment. A city modeler has been designed, using
                 this model of urban environment, and enables complex
                 urban environments for behavioural animation to be
                 automatically produced.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-103,
  year =         "2000",
  title =        "Binding Virtual Environments to Toolkit Capabilities",
  author =       "S. Smith and D. Duke",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-103",
  abstract =     "There are many toolkits and development environments
                 that aid the process of constructing virtual
                 environment applications. Many of these development
                 environments encourage customising a virtual
                 environment's design while rapid prototyping within the
                 confines of a toolkit's capabilities. Thus the choice
                 of the technology and its associated support has been
                 made independent of the end-use requirements of the
                 final system. This can bias a virtual environment's
                 design by implementation based constraints. We propose
                 that an alternative approach is the consideration of
                 virtual environment requirements in the context of an
                 inspectable design model, to identify the requirements
                 that a toolkit will need to support. In the context of
                 an example, we present a selection of design
                 requirements that we consider important for virtual
                 environment design in general. We explore how these
                 requirements might be mapped to different capabilities
                 using Virtual Reality Modelling Language (VRML) as a
                 concrete example of a platform technology.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-104,
  year =         "2000",
  title =        "Collaboration between Heterogeneous Stand-alone 3-{D}
                 Graphical Applications",
  author =       "B. Zeleznik and L. Holden and M. Capps and H. Abrams
                 and T. Miller",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-104",
  abstract =     "We describe the Scene-Graph-As-Bus technique (SGAB),
                 the first step in a staircase of solutions for sharing
                 software components for virtual environments. The goals
                 of SGAB are to allow, with minimal effort,
                 independently designed applications to share component
                 functionality; and for multiple users to share
                 applications designed for single users. This paper
                 reports on the SGAB design for transparently conjoining
                 different applications by unifying the state
                 information contained in their scene graphs. SGAB
                 monitors and maps changes in the local scene graph of
                 one application to a neutral scene graph representation
                 (NSG), distributes the NSG changes over the network to
                 remote peer applications, and then maps the NSG changes
                 to the local scene graph of the remote application. The
                 fundamental contribution of SGAB is that both the local
                 and remote applications can be completely unaware of
                 each other; that is, both applications can interoperate
                 without code or binary modification despite each having
                 no knowledge of networking or interoperability.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-105,
  pages =        "99--108",
  year =         "2000",
  title =        "A Novel Approach Makes Higher Order Wavelets Really
                 Efficient For Radiosity",
  author =       "F. Cuny and L. Alonso and N. Holzschuch",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-105",
  abstract =     "Since wavelets were introduced in the radiosity
                 algorithm, surprisingly little research has been
                 devoted to higher order wavelets and their use in
                 radiosity algorithms. A previous study has shown that
                 wavelet radiosity, and especially higher order wavelet
                 radiosity was not bringing significant improvements
                 over hierarchical radiosity and was having a very
                 important extra memory cost, thus prohibiting any
                 effective computation. In this paper, we present a new
                 implementation of wavelets in the radiosity algorithm,
                 that is substantially different from previous
                 implementations in several key areas (refinement
                 oracle, link storage, resolution algorithm). We show
                 that, with this implementation, higher order wavelets
                 are actually bringing an improvement over standard
                 hierarchical radiosity and lower order wavelets.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-106,
  year =         "2000",
  title =        "Physically-Based Patination for Underground Objects",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-106",
  author =       "Y.-X. Chang and Z.-C. Shih",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-107,
  year =         "2000",
  title =        "Real Time, Accurate, Multi-Featured Rendering of Bump
                 Mapped Surfaces",
  author =       "M. Tarini and P. Cignoni and C. Rocchini and R.
                 Scopigno",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-107",
  abstract =     "We present a new technique to render in real time
                 objects which have part of their high frequency
                 geometric detail encoded in bump maps. It is based on
                 the quantization of normal-maps, and achieves excellent
                 result both in rendering time and rendering quality,
                 with respect to other alternative methods. The method
                 proposed also allows to add many interesting visual
                 effects, even for object with large bumb maps,
                 including non-s rendering, chrome effects, shading
                 under multiple lights, rendering of different materials
                 within a single object, specular reflections and
                 others. Moreover, the implementation of the method is
                 not complex and can be eased by software reuse.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-108,
  year =         "2000",
  title =        "Interpolatory sqrt(3)-Subdivision",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-108",
  author =       "U. Labsik and G. Greiner",
  abstract =     "We present a new interpolatory subdivision scheme for
                 triangle meshes. Instead of splitting each edge and
                 performing a 1-to-4 split for every triangle we compute
                 a new vertex for every triangle and retriangulate the
                 old and the new vertices. Using this refinement
                 operator the number of triangles only triples in each
                 step. New vertices are computed with a Butterfly like
                 scheme. In order to obtain overall smooth surfaces
                 special rules are necessary in the neighborhood of
                 extraordinary vertices. The scheme is suitable for
                 adaptive refinement by using an easy forward strategy.
                 No temporary triangles are produced here which allows
                 simpler data structures and makes the scheme easy to
                 implement.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-109,
  year =         "2000",
  title =        "External Memory View-Dependent Simplification",
  author =       "J. El-Sana and Y.-J. Chiang",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-109",
  abstract =     "In this paper, we propose a novel external-memory
                 algorithm to support view-dependent simplification for
                 datasets much larger than main memory. In the
                 preprocessing phase, we use a new spanned sub-meshes
                 simplification technique to build view-dependence trees
                 I/O-efficiently, which preserves the correct edge
                 collapsing order and thus assures the run-time image
                 quality. We further process the resulting
                 view-dependence trees to build the meta-node trees,
                 which can facilitate the run-time level-of-detail
                 rendering and is kept in disk. During run-time
                 navigation, we keep in main memory only the portions of
                 the meta-node trees that are necessary to render the
                 current level of details, plus some prefetched portions
                 that are likely to be needed in the near future. The
                 prefetching prediction takes advantage of the nature of
                 the run-time traversal of the meta-node trees, and is
                 both simple and accurate. We also employ the implicit
                 dependencies for preventing incorrect foldovers, as
                 well as main-memory buffer management and parallel
                 processes scheme to separate the disk accesses from the
                 navigation operations, all in an integrated manner. The
                 experiments show that our approach scales well with
                 respect to the main memory size available, with
                 encouraging preprocessing and run-time rendering speeds
                 and without sacrificing the image quality.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-11,
  year =         "2000",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-11",
  organization = "SPIE",
  month =        jan,
  editor =       "M. M. Yeung and B.-L. Yeo and C. A. Bouman",
  volume =       "3972",
  booktitle =    "Proceedings of SPIE: Storage and Retrieval for Media
                 Databases 2000",
}

@InProceedings{EVL-2000-110,
  year =         "2000",
  title =        "Subdivision Surface Tesselation on the Fly using a
                 versatile Mesh Data Structure",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-110",
  author =       "K. M{\"{u}}ller and S. Havemann",
  abstract =     "Subdivision surfaces have become a standard technique
                 for freeform shape modeling. They are intuitive to use
                 and permit designers to flexibly add detail. But with
                 larger control meshes, efficient adaptive rendering
                 techniques are indispensable for interactive
                 visualization and shape modeling. In this paper, we
                 present a realization of tesselation-on-the-fly for
                 Loop subdivision surfaces as part of a framework for
                 interactive visualization.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-111,
  pages =        "161--168",
  year =         "2000",
  title =        "Augmented Reality with Back-Projection Systems using
                 Transflective Surfaces",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-111",
  author =       "O. Bimber and L. M. Encarna{\c{c}}{\~{a}}o and D.
                 Schmalstieg",
  abstract =     "In this paper, we introduce the concept of Extended VR
                 (extending viewing space and interaction space of
                 back-projection VR systems), by describing the use of a
                 hand-held semi-transparent mirror to support augmented
                 reality tasks with back-projection systems. This setup
                 overcomes the problem of occlusion of virtual objects
                 by real ones linked with such display systems. The
                 presented approach allows an intuitive and effective
                 application of immersive or semi-immersive virtual
                 reality tasks and interaction techniques to an
                 augmented surrounding space. Thereby, we use the
                 tracked mirror as an interactive image-plane that
                 merges the reflected graphics, which are displayed on
                 the projection plane, with the transmitted image of the
                 real environment. In our implementation, we also
                 address traditional augmented reality problems, such as
                 real-object registration and virtual-object occlusion.
                 The presentation is complemented by a hypothesis of
                 conceivable further setups that apply transflective
                 surfaces to support an Extended VR environment.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-112,
  pages =        "169--178",
  year =         "2000",
  title =        "Haptic Cues for Image Disambiguation",
  author =       "G. Faconti and M. Massink and M. Bordegoni and F. De
                 Angelis and S. Booth",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-112",
  abstract =     "Haptic interfaces represent a revolution in human
                 computer interface technology since they make it
                 possible for users to touch and manipulate virtual
                 objects. In this work we describe a cross-model
                 interaction experiment to study the effect of adding
                 haptic cues to visual cues when vision is not enough to
                 disambiguate the images. We relate the results to those
                 obtained in experimental psychology as well as to more
                 recent studies on the subject.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-113,
  pages =        "179--188",
  year =         "2000",
  title =        "Priority-Driven Acoustic Modeling for Virtual
                 Environments",
  author =       "P. Min and T. Funkhouser",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-113",
  abstract =     "Geometric acoustic modeling systems spatialize sounds
                 according to reverberation paths from a sound source to
                 a receiver to give an auditory impression of a virtual
                 3D environment. These systems are useful for concert
                 hall design, teleconferencing, training and simulation,
                 and interactive virtual environments. In many cases,
                 such as in an interactive walkthrough program, the
                 reverberation paths must be updated within strict
                 timing constraints - e.g., as the sound receiver moves
                 under interactive control by a user. In this paper, we
                 describe a geometric acoustic modeling algorithm that
                 uses a priority queue to trace polyhedral beams
                 representing reverberation paths in best-first order up
                 to some termination criteria (e.g., expired
                 time-slice). The advantage of this algorithm is that it
                 is more likely to find the highest priority
                 reverberation paths within a fixed time-slice, avoiding
                 many geometric computations for lower-priority beams.
                 Yet, there is overhead in computing priorities and
                 managing the priority queue. The focus of this paper is
                 to study the trade-offs of the priority-driven beam
                 tracing algorithm with different priority functions.
                 During experiments computing reverberation paths
                 between a source and a receiver in a 3D building
                 environment, we find that priority functions
                 incorporating more accurate estimates of
                 source-to-receiver path length are more likely to find
                 early reverberation paths useful for spatialization,
                 especially in situations where the source and receiver
                 cannot reach each other through trivial reverberation
                 paths. However, when receivers are added to the
                 environment such that it becomes more densely and
                 evenly populated, this advantage diminishes.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-114,
  pages =        "189--198",
  year =         "2000",
  title =        "Robust Motion Watermarking based on Multiresolution
                 Analysis",
  author =       "T. -H. Kim and J. Lee and S. Y. Shin",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-114",
  abstract =     "Digital watermarking is one of commonly used solutions
                 for copyright protection. A watermark should be
                 imperceptible and robust to various attacks. In this
                 paper, we address watermarking for motion data. Our
                 watermarking scheme is based on two well-known ideas,
                 so called multiresolution representation and spread
                 spectrum. We embed a watermark into a motion signal by
                 perturbing large detail coefficients of its
                 multiresolution representation, and extract the
                 watermark by analyzing perturbation of coefficients
                 from a suspected signal. For more effective watermark
                 extraction, we align suspected motion data to the
                 original using dynamic time warping. Our scheme has
                 merits of spread spectrum such as the resilience to
                 common signal processing as well as the robustness to
                 time warping.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-115,
  pages =        "1990208",
  year =         "2000",
  title =        "Towards Blind Detection of Robust Watermarks in
                 Polygonal Models",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-115",
  author =       "O. Benedens and C. Busch",
  abstract =     "We describe a Digital Watermarking system dedicated
                 for embedding watermarks into 3D polygonal models. The
                 system consists of three watermarking algorithms, one
                 named Vertex Flood Algorithm (VFA) suitable for
                 embedding fragile public readable watermarks with high
                 capacity and offering a way of model authentication,
                 one realizing affine invariant watermarks, named Affine
                 Invariant Embedding (AIE) and a third one, named Normal
                 Bin Encoding (NBE) algorithm, realizing watermarks with
                 robustness against more complex operations, most
                 noticeably polygon reduction. The watermarks generated
                 by these algorithms are stackable. We shortly discuss
                 the implementation of the system, which is realized as
                 a 3D Studio MAX plugin",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-116,
  pages =        "209--218",
  year =         "2000",
  title =        "Context-based Space Filling Curves",
  author =       "R. Dafner and D. Cohen-Or and Y. Matias",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-116",
  abstract =     "A context-based scanning technique for images is
                 presented. An image is scanned along a context-based
                 space filling curve that is computed so as to exploit
                 inherent coherence in the image. The resulting
                 one-dimensional representation of the image has
                 improved autocorrelation compared with universal scans
                 such as the Peano-Hilbert space filling curve. An
                 efficient algorithm for computing context-based space
                 filling curves is presented. We also discuss the
                 potential of improved autocorrelation of context-based
                 space filling curves for image and video lossless
                 compression.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-117,
  pages =        "219--228",
  year =         "2000",
  title =        "Realistic Collision Avoidance of Upper Limbs Based on
                 Neuroscience Models",
  author =       "J.-C. Nebel",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-117",
  abstract =     "When articulated figures interact in a 3D environment,
                 collisions are highly likely and must often be avoided.
                 We present a method automatically producing realistic
                 collision-free animation of the upper arms. Based on
                 the latest models of collision avoidance provided by
                 neuroscience, our method allows realistic interpolation
                 of keyframes at interactive speed. In order to validate
                 our scheme we compared computer generated motions with
                 motions performed by a sample of ten humans. These
                 motions were defined by start and final postures and by
                 an obstacle which had to be passed. In each case the
                 generated positions are the same as those chosen by 30%
                 of real humans, we therefore consider our method
                 provides realistic motions. Moreover, the
                 collision-free paths are automatically generated in a
                 few seconds. Hence, our method can be very beneficial
                 to animators by reducing the level of detail needed to
                 define motions of articulated figures. It can also be
                 used for the automatic generation of realistic
                 animations for virtual reality applications.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-118,
  pages =        "229--238",
  year =         "2000",
  title =        "The Impulse Graph: {A} New Dynamic Structure for
                 Global Collisions",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-118",
  author =       "G. Baciu and S. K Wong",
  abstract =     "In interactive virtual environments and dynamic
                 simulations, collisions between complex objects and
                 articulated bodies may occur simultaneously at multiple
                 points or regions of interference. Many solutions to
                 the collision response problem are formulated based on
                 the local pair-wise contact dynamics. In this article,
                 we present a new solution to the global interactions
                 and dynamic response between multiple structures in a
                 three-dimensional environment. This is based on a new
                 dynamic impulse graph that tracks the reaction forces
                 through the entire system and gives a global view of
                 all the interactions in a multibody system.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-119,
  pages =        "239--248",
  year =         "2000",
  title =        "Graceful Degradation of Collision Handling Physically
                 Based Animation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-119",
  author =       "J. Dingliana and C. O'Sullivan",
  abstract =     "Interactive simulation is made possible in many
                 applications by simplifying or culling the finer
                 details that would make real-time performance
                 impossible. This paper examines detail simplification
                 in the specific problem of collision handling for rigid
                 body animation. We present an automated method for
                 calculating consistent collision response at different
                 levels of detail. The mechanism works closely with a
                 system which uses a pre-computed hierarchical volume
                 model for collision detection.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-12,
  pages =        "450--460",
  year =         "2000",
  title =        "A Wavelet Based Image Retrieval Algorithm via Mutual
                 Information",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-12",
  author =       "V. Kasarabada and E. Simsek and T. C. Tran",
  organization = "SPIE",
  month =        jan,
  editor =       "M. M. Yeung and B.-L. Yeo and C. A. Bouman",
  keywords =     "image algoriths, image database, image retrieval,
                 wavelet transform, mutual information",
  volume =       "3972",
  booktitle =    "Proceedings of SPIE: Storage and Retrieval for Media
                 Databases 2000",
}

@InProceedings{EVL-2000-120,
  pages =        "249--260",
  year =         "2000",
  title =        "Multiresolution Shape Deformations for Meshes with
                 Dynamic Vertex Connectivity",
  author =       "L. Kobbelt and T. Bareuther and H.-P. Seidel",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-120",
  abstract =     "Multiresolution shape representation is a very
                 effective way to decompose surface geometry into
                 several levels of detail. Geometric modeling with such
                 representations enables flexible modifications of the
                 global shape while preserving the detail information.
                 Many schemes for modeling with multiresolution
                 decompositions based on splines, polygonal meshes and
                 subdivision surfaces have been proposed recently. In
                 this paper we modify the classical concept of
                 multiresolution representation by no longer requiring a
                 global hierarchical structure that links the different
                 levels of detail. Instead we represent the detail
                 information implicitly by the geometric difference
                 between independent meshes. The detail function is
                 evaluated by shooting rays in normal direction from one
                 surface to the other without assuming a consistent
                 tesselation. In the context of multiresolution shape
                 deformation, we propose a dynamic mesh representation
                 which adapts the connectivity during the modification
                 in order to maintain a prescribed mesh quality.
                 Combining the two techniques leads to an efficient
                 mechanism which enables extreme deformations of the
                 global shape while preventing the mesh from
                 degenerating. During the deformation, the detail is
                 reconstructed in a natural and robust way. The key to
                 the intuitive detail preservation is a transformation
                 map which associates points on the original and the
                 modified geometry with minimum distortion. We show
                 several examples which demonstrate the effectiveness
                 and robustness of our approach including the editing of
                 multiresolution models and models with texture.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-121,
  pages =        "261--270",
  year =         "2000",
  title =        "Direct Manipulation and Interactive Sculpting of {PDE}
                 Surfaces",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-121",
  author =       "H. Du and H. Qin",
  abstract =     "This paper presents an integrated approach and a
                 unified algorithm that combine the benefits of PDE
                 surfaces and powerful physics-based modeling techniques
                 within one single modeling framework, in order to
                 realize the full potential of PDE surfaces. We have
                 developed a novel system that allows direct
                 manipulation and interactive sculpting of PDE surfaces
                 at arbitrary location, hence supporting various
                 interactive techniques beyond the conventional boundary
                 control. Our prototype software affords users to
                 interactively modify point, normal, curvature, and
                 arbitrary region of PDE surfaces in a predictable way.
                 We employ several simple, yet effective numerical
                 techniques including the finite-difference
                 discretization of the PDE surface, the multigrid-like
                 subdivision on the PDE surface, the mass-spring
                 approximation of the elastic PDE surface, etc. to
                 achieve real-time performance. In addition, our dynamic
                 PDE surfaces can also be approximated using standard
                 bivariate B-spline finite elements, which can
                 subsequently be sculpted and deformed directly in
                 real-time subject to intrinsic PDE constraints. Our
                 experiments demonstrate many attractive advantages of
                 our dynamic PDE formulation such as intuitive control,
                 real-time feedback, and usability to the general
                 public.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-122,
  pages =        "271--282",
  year =         "2000",
  title =        "A Multiresolution Model for Soft Objects Supporting
                 Interactive Cuts and Lacerations",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-122",
  author =       "F. Ganovelli and P. Cignoni and C. Montani and R.
                 Scopigno",
  abstract =     "Performing a really interactive and physically-based
                 simulation of complex soft objects is still an open
                 problem in computer animation/simulation. Given the
                 application domain of virtual surgery training, a
                 complete model should be quite realistic, interactive
                 and should enable the user to modify the topology of
                 the objects. Recent papers propose the adoption of
                 multiresolution techniques to optimize time performance
                 by representing at high resolution only the object
                 parts considered more important or critical. The speed
                 up obtainable at simulation time are counterbalanced by
                 the need of a preprocessing phase strongly dependent on
                 the topology of the object, with the drawback that
                 performing dynamic topology modification becomes a
                 prohibitive issue. In this paper we present an approach
                 that couples multiresolution and topological
                 modifications, based on the adoption of a particle
                 systems approach to the physical simulation. Our
                 approach is based on a tetrahedral decomposition of the
                 space, chosen both for its suitability to support a
                 particle system and for the ready availability of many
                 techniques recently proposed for the simplification and
                 multiresolution management of 3D simplicial
                 decompositions. The multiresolution simulation system
                 is designed to ensure the required speedup and to
                 support dynamic changes of the topology, e.g. due to
                 cuts or lacerations of the represented tissue.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-123,
  pages =        "283--290",
  year =         "2000",
  title =        "Color Distribution - {A} New Approach to Texture
                 Compression",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-123",
  author =       "D. Ivanov and Y. Kuzmin",
  abstract =     "Texture compression is recently one of the most
                 important topics of 3D scene rendering techniques,
                 because it allows rendering more complicated
                 high-resolution scenes. However, because of some
                 special requirements for these type of techniques, the
                 commonly used block decomposition approach may
                 introduce visual degradation of image details due to
                 lack of colors. We present here a new approach to
                 texture compression, which allows sharing of one color
                 by several blocks providing a larger number of unique
                 colors in each particular block and the best
                 compression ratio. We also present an iterative
                 algorithm for obtaining distributed colors on a
                 texture, and discuss some advantages of our approach.
                 The paper concludes with comparison of our technique
                 with S3TC and other block decomposition methods.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-124,
  pages =        "291--300",
  year =         "2000",
  title =        "An Adaptive Spectral Rendering with a Perceptual
                 Control",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-124",
  author =       "J.-C. Lehl and B. Peroche",
  abstract =     "In this paper, we present a spectral rendering method
                 based on a ray tracing algorithm and guided by a
                 perceptual control of the error made. An adaptive
                 representation of spectral data for light sources and
                 materials is used and induces, for each pixel, the
                 evaluation of an algebraic expression. For each visible
                 wavelength, the computations of complex spread in
                 refractive and dispersive materials, based on several
                 photon maps, are locally restricted by an adaptive
                 evaluation of the expression. This method allows to
                 simulate high quality physically-based pictures and, in
                 particular, some specific phenomena like dispersion in
                 transparent objects, scattered caustics, ...",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-125,
  pages =        "301--312",
  year =         "2000",
  title =        "Tone Reproduction for Interactive Walkthroughs",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-125",
  author =       "A. Scheel and M. Stamminger and H.-P. Seidel",
  abstract =     "When a rendering algorithm has created a pixel array
                 of radiance values the task of producing an image is
                 not yet completed. In fact, to visualize the result the
                 radiance values still have to be mapped to luminances,
                 which can be reproduced by the used display. This step
                 is performed with the help of tone reproduction
                 operators. These tools have mainly been applied to
                 still images, but of course they are just as necessary
                 for walkthrough applications, in which several images
                 are created per second. In this paper we illuminate the
                 physiological aspects of tone reproduction for
                 interactive applications. It is shown how tone
                 reproduction can also be introduced into interactive
                 radiosity viewers, where the tone reproduction
                 continuously adjusts to the current view of the user.
                 The overall performance is decreased only moderately,
                 still allowing walkthroughs of large scenes.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-126,
  pages =        "313--320",
  year =         "2000",
  title =        "Integration of Multidimensional Interaction Devices in
                 Real-Time Computer Graphics Applications",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-126",
  author =       "T. Fr{\"{o}}hlich and M. Roth",
  abstract =     "Modern CAD/CAM and Virtual Reality applications cannot
                 be imagined without the new class of interaction
                 devices allowing the user direct interaction with
                 computer generated scenes. Integrating such devices
                 into existing or newly developed software is a complex
                 task for a number of reasons. The set of devices is
                 very heterogeneous in functionality and data formats.
                 Most devices are difficult to handle by inexperienced
                 users or need careful handling and calibration. After
                 reviewing a number of existing systems, a novel
                 approach to this problem is presented. A device
                 interface that allows the flexible, hardware
                 independent configuration and error robust operation,
                 even reconfiguration and exchanges of interaction
                 devices during operation, will be introduced. The
                 system structure is discussed and novel communication
                 protocols reducing latency are invented.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-127,
  pages =        "321--330",
  year =         "2000",
  title =        "Web-Based Remote Rendering with {IBRAC} (Image-Based
                 Rendering Acceleration and Compression)",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-127",
  author =       "I. Yoon and U. Neumann",
  abstract =     "Recent advances in Internet and computer graphics
                 stimulate intensive use and development of 3D graphics
                 on the World Wide Web. To increase efficiency of
                 systems using 3D graphics on the web, the presented
                 method utilizes previously rendered and transmitted
                 images to accelerate the rendering and compression of
                 new synthetic scene images. The algorithm employs ray
                 casting and epipolar constraints to exploit spatial and
                 temporal coherence between the current and previously
                 rendered images. The reprojection of color and
                 visibility data accelerates the computation of new
                 images. The rendering method intrinsically computes a
                 residual image, based on a user specified error
                 tolerance that balances image quality against
                 computation time and bandwidth. Encoding and decoding
                 uses the same algorithm, so the transmitted residual
                 image consists only of significant data without
                 addresses or offsets. We measure rendering speed-ups of
                 four to seven without visible degradation. Compression
                 ratios per frame are a factor of two to ten better than
                 MPEG2 in our test cases. There is no transmission of 3D
                 scene data to delay the first image. The efficiency of
                 the server and client generally increases with scene
                 complexity or data size since the rendering time is
                 predominantly a function of image size. This approach
                 is attractive for remote rendering applications such as
                 web-based scientific visualization where a client
                 system may be a relatively low-performance machine and
                 limited network bandwidth makes transmission of large
                 3D data impractical.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-128,
  pages =        "331--340",
  year =         "2000",
  title =        "Virtual Dunhuang Mural Restoration System in
                 Collaborative Network Environment",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-128",
  author =       "X. Li and D. Lu and Y. Pan and Z. Hua",
  abstract =     "This paper introduces a virtual Dunhuang mural
                 restoration system in collaborative network
                 environment. It describes the style of Dunhuang mural,
                 analyzes the reasons of mural spoilage, and presents
                 the necessity to develop a collaborative mural
                 restoration GroupWare. It describes the components and
                 the workflow of mural restoration in detail, solves
                 some key technologies in the system. In the end, it
                 introduces the system architecture, and presents the
                 system interface and some restored results.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-129,
  pages =        "341--350",
  year =         "2000",
  title =        "Interactive High-Quality Maximum Intensity
                 Projection",
  author =       "L. Mroz and H. Hauser and E. Gr{\"{o}}ller",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-129",
  abstract =     "Maximum Intensity Projection (MIP) is a volume
                 rendering technique which is used to visualize
                 high-intensity structures within volumetric data. At
                 each pixel the highest data value, which is encountered
                 along a corresponding viewing ray is depicted. MIP is,
                 for example, commonly used to extract vascular
                 structures from medical data sets (angiography). Due to
                 lack of depth information in MIP images, animation or
                 interactive variation of viewing parameters is
                 frequently used for investigation. Up to now no MIP
                 algorithms exist which are of both interactive speed
                 and high quality. In this paper we present a
                 high-quality MIP algorithm (trilinear interpolation
                 within cells), which is up to 50 times faster than
                 brute-force MIP and at least 20 times faster than
                 comparable optimized techniques. This speed-up is
                 accomplished by using an alternative storage scheme for
                 volume cells (sorted by value) and by removing cells
                 which do not contribute to any MIP projection
                 (regardless of the viewing direction) in a
                 preprocessing step. Also, a fast maximum estimation
                 within cells is used to further speed up the
                 algorithm.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-13,
  pages =        "461--470",
  year =         "2000",
  title =        "Image Indexing and Retrieval Techniques: Past,
                 Present, and Next",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-13",
  author =       "J. Shanbehazadeh and A. M. E. Moghadam and F.
                 Mahmoudi",
  organization = "SPIE",
  month =        jan,
  editor =       "M. M. Yeung and B.-L. Yeo and C. A. Bouman",
  volume =       "3972",
  keywords =     "image retrieval, image indexing, image processing",
  booktitle =    "Proceedings of SPIE: Storage and Retrieval for Media
                 Databases 2000",
}

@InProceedings{EVL-2000-130,
  pages =        "351--358",
  year =         "2000",
  title =        "Gradient Estimation in Volume Data using 4{D} Linear
                 Regression",
  author =       "L. Neumann and B. Cs{\'{e}}bfalvi and A. K{\"{o}}nig
                 and E. Gr{\"{o}}ller",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-130",
  abstract =     "In this paper a new gradient estimation method is
                 presented which is based on linear regression. Previous
                 contextual shading techniques try to fit an approximate
                 function to a set of surface points in the neighborhood
                 of a given voxel. Therefore, a system of linear
                 equations has to be solved using the computationally
                 expensive Gaussian elimination. In contrast, our method
                 approximates the density function itself in a local
                 neighborhood with a 3D regression hyperplane. This
                 approach also leads to a system of linear equations but
                 we will show that it can be solved with an efficient
                 convolution. Our method provides at each voxel location
                 the normal vector and the translation of the regression
                 hyperplane which are considered as a gradient and a
                 filtered density value respectively. Therefore, this
                 technique can be used for surface smoothing and
                 gradient estimation at the same time.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-131,
  pages =        "359--368",
  year =         "2000",
  title =        "Fast Volume Rendering and Data Classification Using
                 Multiresolution Min-Max Octrees",
  author =       "F. Dong and M. A. Krokos and G. J. Clapworthy",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-131",
  abstract =     "Large-sized volume datasets have recently become
                 commonplace and users are now demanding that
                 volume-rendering techniques to visualize such data
                 provide acceptable results on relatively modest
                 computing platforms. The widespread use of the Internet
                 for the transmission and/or rendering of volume data is
                 also exerting increasing demands on software providers.
                 Multiresolution can address these issues in an elegant
                 way. One of the fastest volume-rendering algorithms is
                 that proposed by Lacroute & Levoy, which is based on
                 shear-warped factorization and min-max octrees (MMOs).
                 Unfortunately, since an MMO captures only a single
                 resolution of a volume dataset, this method is
                 unsuitable for rendering datasets in multiresolution
                 form. This paper adapts the above algorithm to
                 multiresolution volume rendering to enable
                 near-real-time interaction to take place on a standard
                 PC. It also permits the user to modify classification
                 functions and/or resolution during rendering with no
                 significant loss of rendering speed. A newly-developed
                 data structure based on the MMO is employed, the
                 multiresolution min-max octree, M3O, which captures the
                 spatial coherence for datasets at all resolutions.
                 Speed is enhanced by the use of multiresolution opacity
                 transfer functions for rapidly determining and
                 discarding transparent data set regions. Some
                 experimental results on sample volume datasets are
                 presented.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  keywords =     "Scientific Visualization, Volume Rendering, Shear-Warp
                 Factorization, Data Classification. Levels-of-Detail
                 (LoDs), Multiresolution Min-Max Octree (M3O).",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-132,
  pages =        "369--378",
  year =         "2000",
  title =        "Reshaping the Coliseum in Rome",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-132",
  author =       "M. Gaiani and M. Balzani and F. Uccelli",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-133,
  pages =        "379--390",
  year =         "2000",
  title =        "Collaborative Virtual Simulation Environment of
                 Radiotherapy Treatment Planning",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-133",
  author =       "W. Cai and S. Walter and G. Karangelis and G. Sakas",
  abstract =     "The simulation of Radiotherapy Treatment Planning
                 (RTP) is a normal procedure in oncology clinics carried
                 out on a Simulator machine. The Virtual Simulation of
                 RTP replaces the real Simulator machine with a virtual
                 one by using the CT data sets of a patient instead of
                 the real patient. In this paper, we present a
                 collaborative virtual simulation environment of RTP,
                 named EU-VIRTUOSO, which is based on volume rendering
                 and telecommunication techniques. The RTP procedure is
                 visualised on a virtual patient, which is created by
                 using the CT data of the patient. Different volume
                 rendering and volume interaction techniques, such as
                 DRR, MIP, gradient surface, and iso-surface, supply
                 physicians with high quality rendering images to
                 simulate the real working environment of the Simulator
                 machine. In the collaborative environment, physicians
                 distributed at different locations can work together
                 via network to plan the treatment or to validate the
                 treatment plan on-line by a collaborative application
                 sharing approach. Both concepts virtualised planning
                 and collaborative planning improve the efficiency and
                 accuracy of a radiotherapy treatment while reducing the
                 effort for an individual patient.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-134,
  year =         "2000",
  title =        "A Video-Based 3{D}-Reconstruction of Soccer Game",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-134",
  author =       "T. Bebie and H. Bieri",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-135,
  year =         "2000",
  title =        "Video-based Approach to Human Animation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-135",
  author =       "Z. Lao",
  abstract =     "A method based on computer vision technologies is
                 presented to determine the 3-D spatial locations of
                 joints or feature points of a human body from human
                 motion video. The proposed method first applies the
                 geometric projection theory to obtain a set of feasible
                 postures in some key frames according to predefined 2D
                 video features and 3D-model features correspondence.
                 Next it makes use of the available skeleton controlled
                 human model to get a feasible posture for each key
                 frame. The method is applied to a series of video
                 images to animate artificial 3D human models.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-136,
  pages =        "411--426",
  year =         "2000",
  title =        "Representing Animations by Principal Components",
  author =       "M. Alexa and W. M{\"{u}}ller",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-136",
  abstract =     "In this paper, we present a representation for
                 three-dimensional geometric animation sequences.
                 Different from standard key-frame techniques, this
                 approach is based on the determination of principal
                 animation components and decouples the animation from
                 the underlying geometry. The new representation
                 supports progressive animation compression with
                 spatial, as well as temporal, level-of-detail and high
                 compression ratios. The distinction of animation and
                 geometry allows for mapping animations onto other
                 objects.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  keywords =     "Geometric animations, polyhedral morphing,
                 multiresolution/progressive representation.",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-138,
  pages =        "427--436",
  year =         "2000",
  title =        "Real Time Local Approximation of Deformations using
                 Rotations",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-138",
  author =       "J. Maillot",
  abstract =     "Additional realism can be achieved in computer
                 generated images using smooth and increasingly complex
                 deformations. Though significant effort has been spent
                 on improving these deformations, no general method has
                 been proposed yet to deal with rigid pieces connected
                 to soft objects. This paper proposes a general
                 framework to solve this problem. We will present
                 several types of applications, such as flowing small
                 objects in a deformation field, animating rigid
                 features connected to some deformed object, or smoothly
                 attached limbs to a deforming body. All the
                 calculations presented here can be applied to any type
                 of deformation, provided that the deformation at each
                 point only depends on the point itself. Even though we
                 can directly compute the result for some analytical
                 deformation fields, we will show that a good sampling
                 of the deformation in the area of interest is generally
                 enough. One intermediate result consists of a practical
                 method to find the best rotation that approximates a
                 linear transformation. The proposed method is a
                 superset of the Gram-Schmidt orthonormalization
                 process, and is much easier to compute than global
                 methods based on Taylor series.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-139,
  pages =        "437--446",
  year =         "2000",
  title =        "Motion Balance Filtering",
  author =       "S. Tak and O.-Y. Song and H.-S. Ko",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-139",
  abstract =     "Motion balance filtering is a new technique which
                 corrects an unbalanced motion to a balanced one while
                 preserving the original motion characteristics as much
                 as possible. Differently from previous approaches that
                 deal only with the balance of static posture, we solve
                 the problem of balancing a dynamic motion. We achieve
                 dynamic balance by analyzing and controlling the
                 trajectory of the zero moment point (ZMP). Our
                 algorithm consists of three steps. First, it analyzes
                 the ZMP trajectory to find out the duration in which
                 dynamic balance is violated. Dynamic imbalance is
                 identified by the ZMP trajectory segments lying out of
                 the supporting area. Next, the algorithm modifies the
                 ZMP trajectory by projecting it into the supporting
                 area. Finally, it generates the balanced motion that
                 satisfies the new ZMP constraint. This process is
                 formulated as a constrained optimization problem so
                 that the new motion resembles the original motion as
                 much as possible. Experiments prove that our motion
                 balance filtering algorithm is a useful method to add
                 physical realism to a kinematically edited motion.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-14,
  pages =        "471--482",
  year =         "2000",
  title =        "Efficient image retrieval approaches for different
                 similarity requirements",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-14",
  author =       "C.-Y. Tsai and A. L. P. Chen and K. Essig",
  organization = "SPIE",
  month =        jan,
  editor =       "M. M. Yeung and B.-L. Yeo and C. A. Bouman",
  volume =       "3972",
  keywords =     "image retrieval, region-based approach and
                 partition-based approach, representative color,
                 similarity measures",
  booktitle =    "Proceedings of SPIE: Storage and Retrieval for Media
                 Databases 2000",
}

@InProceedings{EVL-2000-140,
  year =         "2000",
  title =        "Generating Consistent Motion Transition via Decoupled
                 Framespace Interpolation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-140",
  author =       "G. Ashraf and K. C. Wong",
  abstract =     "The framespace interpolation algorithm abstracts
                 motion sequences as 1D signal, and interpolates between
                 them to create higher dimension signals, with weights
                 drawn from a user specified curve in a bounded region.
                 We reformulate the algorithm to achieve motion-state
                 based transition via dynamic warping of framespaces and
                 automatic transition timing via framespace frequency
                 interpolation. Basis motions displaying diverse
                 coordination configurations between upper and lower
                 body-halves, cannot be consistently corresponded at a
                 macro level. We address this problem here, through
                 decoupled blending of these halves to achieve true
                 consistency, and eliminate accumulated phase
                 differences via cosine phase warp functions. This
                 generalization enables interpolation of motions with
                 diverse coordinations between the upper and lower
                 bodies",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-141,
  year =         "2000",
  title =        "Automatic surface reconstruction from point sets in
                 space",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-141",
  author =       "M. Attene and M. Spagnuolo",
  abstract =     "In this paper an algorithm is proposed that takes as
                 input a generic set of unorganized points, sampled on a
                 real object, and returns a closed interpolating
                 surface. Specifically, this method generates a closed
                 2-manifold surface made of triangular faces, without
                 limitations on the shape or genus of the original
                 solid. The reconstruction method is based on generation
                 of the Delaunay tetrahedralization of the point set,
                 followed by a sculpturing process constrained to
                 particular criteria. The main applications of this tool
                 are in medical analysis and in reverse engineering
                 areas. It is possible, for example, to reconstruct
                 anatomical parts starting from surveys based on TACs or
                 magnetic resonance.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-142,
  year =         "2000",
  title =        "Surface Reconstruction Based on Lower Dimensional
                 Localized Delaunay Triangulation",
  author =       "M. Gopi and S. Krishnan and C. T. Silva",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-142",
  abstract =     "We present a fast, memory efficient algorithm that
                 generates a manifold triangular mesh S passing through
                 a set of unorganized points P of R3. Nothing is assumed
                 about the geometry, topology or presence of boundaries
                 in the data set except that P is sampled from a real
                 manifold surface. The speed of our algorithm is derived
                 from a projection-based approach we use to determine
                 the incident faces on a point. We define our sampling
                 criteria to sample the surface and guarantee a
                 topologically correct mesh after surface reconstruction
                 for such a sampled surface. We also present a new
                 algorithm to find the normal at a vertex, when the
                 surface is sampled according our given criteria. We
                 also present results of our surface reconstruction
                 using our algorithm on unorganized point clouds of
                 various models.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-143,
  pages =        "479--487",
  year =         "2000",
  title =        "An interactive approach to point cloud triangulation",
  author =       "L. P. Kobbelt and M. Botsch",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-143",
  abstract =     "We present an interactive system for the generation of
                 high quality triangle meshes that allows us to handle
                 hybrid geometry (point clouds, polygons, . . . ) as
                 input data. In order to be able to robustly process
                 huge data sets, we exploit graphics hardware features
                 like the raster manager and the z-buffer for specific
                 sub-tasks in the overall procedure. By this we
                 significantly accelerate the stitching of mesh patches
                 and obtain an algorithm for subsampling the data points
                 in linear time. The target resolution and the triangle
                 alignment in sub-regions of the resulting mesh can be
                 controlled by adjusting the screen resolution and
                 viewing transformation. An intuitive user interface
                 provides a flexible tool for application dependent
                 optimization of the mesh.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-144,
  pages =        "489--498",
  year =         "2000",
  title =        "Efficient Algorithms for Computing Conservative Portal
                 Visibility Information",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-144",
  author =       "W. F. H. Jimenez and C. Esperan{\c{c}}a and A. A. F.
                 Oliveira",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-145,
  pages =        "499--506",
  year =         "2000",
  title =        "Integrating Occlusion Culling with Levels of Detail
                 through Hardly-Visible Sets",
  author =       "C. Adujar and C. Saona-Vazquez and I. Navazo and P.
                 Brunet",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-145",
  abstract =     "Occlusion culling and level-of-detail rendering have
                 become two powerful tools for accelerating the handling
                 of very large models in real-time visualization
                 applications. We present a framework that combines both
                 techniques to improve rendering times. Classical
                 occlusion culling algorithms compute potentially
                 visible sets (PVS), which are supersets of the sets of
                 visible polygons. The novelty of our approach is to
                 estimate the degree of visibility of each object of the
                 PVS using synthesized coarse occluders. This allows to
                 arrange the objects of each PVS into several
                 Hardly-Visible Sets (HVS) with similar occlusion
                 degree. According to image accuracy and frame rate
                 requirements, HVS provide a way to avoid sending to the
                 graphics pipeline those objects whose pixel
                 contribution is low due to partial occlusion. The image
                 error can be bounded by the user at navigation time. On
                 the other hand, as HVS offer a tighter estimation of
                 the pixel contribution for each scene object, it can be
                 used for a more convenient selection of the
                 level-of-detail at which objects are rendered. In this
                 paper, we describe the new framework technique, provide
                 details of its implementation using a visibility octree
                 as the chosen occlusion culling data structure and show
                 some experimental results on the image quality.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-146,
  pages =        "507--516",
  year =         "2000",
  title =        "Directional Discretized Occluders for Accelerated
                 Occlusion Culling",
  author =       "F. Bernardini and J. El-Sana and J. T. Klosowski",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-146",
  abstract =     "We present a technique for accelerating the rendering
                 of high depth-complexity scenes. In a preprocessing
                 stage, we approximate the input model with a
                 hierarchical data structure and compute simple
                 view-dependent polygonal occluders to replace the
                 complex input geometry in subsequent visibility
                 queries. When the user is inspecting and visualizing
                 the input model, the computed occluders are used to
                 avoid rendering geometry which cannot be seen. Our
                 method has several advantages which allow it to perform
                 conservative visibility queries efficiently and it does
                 not require any special graphics hardware. The
                 preprocessing step of our approach can also be used
                 within the framework of other visibility culling
                 methods which need to pre-select or pre-render
                 occluders. In this paper, we describe our technique and
                 its implementation in detail, and provide experimental
                 evidence of its performance. In addition, we briefly
                 discuss possible extensions of our algorithm.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-147,
  pages =        "419--426",
  year =         "2000",
  title =        "A Vector-based Representation For Image Warping",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-147",
  author =       "M. Froumentin and F. Labrosse and P. Willis",
  abstract =     "A method for image analysis, representation and
                 re-synthesis is introduced. Unlike other schemes it is
                 not pixel based but rather represents a picture as
                 vector data, from which an altered version of the
                 original image can be rendered. Representing an image
                 as vector data allows performing operations such as
                 zooming, retouching or colourising, avoiding common
                 problems associated with pixel image manipulation. This
                 paper brings together methods from the areas of
                 computer vision, image compositing and image based
                 rendering to prove that this type of image
                 representation is a step towards accurate and efficient
                 image manipulation.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-148,
  pages =        "373--380",
  year =         "2000",
  title =        "New Techniques for Topologically Correct Surface
                 Reconstruction",
  author =       "Udo Adamy and Joachim Giesen and Matthias John",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-148",
  abstract =     "We present a new approach to surface reconstruction
                 based on the Delaunay complex. First we give a simple
                 and fast algorithm that picks locally a surface at each
                 vertex. For that, we introduce the concept of
                 lambda-intervals. It turns out that for smooth regions
                 of the surface this method works very well and at
                 difficult parts of the surface yields an output
                 well-suited for postprocessing. As a postprocessing
                 step we propse a topological clean up and a new
                 technique based on linear programming in order to
                 establish a topologically correct surface. These
                 techniques should be useful also for many ohter
                 reconstruction schemes.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Surface reconstruction, Gabriel graph, linear
                 programming, topology",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-149,
  pages =        "389--396",
  year =         "2000",
  title =        "Bicubic Subdivision-Surface Wavelets for Large-Scale
                 Isosurface Representation and Visualization",
  author =       "Martin Bertram and Mark A. Duchaineau and Bernd Hamann
                 and Kenneth I. Joy",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-149",
  abstract =     "We introduce a new subdivision-surface wavelet
                 transform for arbitrary two-manifolds with boundary
                 that is the first to use simple lifting-style filtering
                 operations with bicubic precision. We also describe a
                 conversion process for re-mapping large-scale
                 isosurfaces to have subdivision connectivity and fair
                 parameterizations so that the new wavelet transform can
                 be used for compression and visualization. The main
                 idea enabling our wavelet transform is the circular
                 symmetrization of the filters in irregular
                 neighborhoods, which replaces the traditional
                 separation of filters into two 1-D passes. Our wavelet
                 transform uses polygonal base meshes to represent
                 surface topology, from which a Catmull-Clark-style
                 subdivision hierarchy is generated. The details between
                 these levels of resolution are quickly computed and
                 compactly stored as wavelet coefficients. The
                 isosurface conversion process begins with a contour
                 triangulation computed using conventional techniques,
                 which we subsequently simplify with a variant
                 edge-collapse procedure, followed by an edge-removal
                 process. This provides a coarse initial base mesh,
                 which is subsequently refined, relaxed and attracted in
                 phases to converge to the contour. The conversion is
                 designed to produce smooth, untangled and minimally-
                 skewed parameterizations, which improves the subsequent
                 compression after applying the transform. We have
                 demonstrated our conversion and transform for an
                 isosurface obtained from a high-resolution
                 turbulent-mixing hydrodynamics simulation, showing the
                 potential for compression and level-of-detail
                 visualization.",
  organization = "IEEE Computer Society Technical Committe on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Compression Algorithms, Geometric Modeling,
                 Iso-surfaces, Multiresolution Methods, Wavelets",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-15,
  pages =        "12--20",
  year =         "2000",
  title =        "Content-based retrieval system for image using human
                 face information",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-15",
  author =       "H.-S. Oh and J.-S. Park and D.-H. Chang and G.-R. Oh",
  organization = "SPIE",
  month =        jan,
  editor =       "M. M. Yeung and B.-L. Yeo and C. A. Bouman",
  volume =       "3972",
  booktitle =    "Proceedings of SPIE: Storage and Retrieval for Media
                 Databases 2000",
}

@InProceedings{EVL-2000-150,
  pages =        "267--273",
  year =         "2000",
  title =        "Isosurfacing in Higher Dimensions",
  author =       "Praveen Bhaniramka and Rehpael Wenger and Roger
                 Crawfis",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-150",
  abstract =     "Visualization algorithms have seen substantial
                 improvements in the past several years. However, very
                 few algorithms have been developed for directly
                 studying data in dimensions higher than three. Most
                 algorithms require a sampling in three-dimensions
                 before applying any visualization algorithms. This
                 sampling typically ignores vital features that may be
                 present when examined in oblique cross-sections, and
                 places an undo burden on system resources when
                 animation through additional dimensions is desired. For
                 time-varying data of large data sets, smooth animation
                 is desired at interactive rates. This paper provides a
                 fast Marching Cubes like algorithm for hypercubes of
                 any dimension. To support this, we have developed a new
                 algorithm to automatically generate the isosurface and
                 triangulation tables for any dimension. This allows the
                 efficient calculation of 4D isosurfaces, which can be
                 interactively sliced to provide smooth animation or
                 slicing through oblique hyperplanes. The former allows
                 for smooth animation in a very compressed format. The
                 latter provide better tools to study time-evolving
                 features as they move downstream. We also provide
                 examples in using this technique to show interval
                 volumes or the sensitivity of a particular isovalue
                 threshold.",
  organization = "IEEE Comupter Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-151,
  pages =        "45--52",
  year =         "2000",
  title =        "{CEASAR}: {A} Smooth, Accurate and Robust Centerline
                 Extraction Algorithm",
  author =       "Ingmar Bitter and Mie Sato and Michael Bender and
                 Kevin T. McDonnell and Arie Kaufmann and Ming Wan",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-151",
  abstract =     "We present ceasar, a centerline extraction algorithm
                 that delivers smooth, accurate, and robust results.
                 Centerlines are needed for accurate measurements of
                 length along winding tubular structures. Centerlines
                 are also required in automatic virtual navigation
                 through human organs, such as the colon or the aorta,
                 as they are used to control movement and orientation of
                 the virtual camera. We introduce a concise but general
                 definition of a centerline, and provide an algorithm
                 that finds the centerline accurately and rapidly. Our
                 algorithm is provably correct for general geometries.
                 Our solution is fully automatic, which frees the user
                 from having to engage in data preprocessing. For a
                 number of test datasets, we show the smooth and
                 accurate centerlines computed by our ceasar algorithm
                 on a single 194 MHz MIPS R10000 CPU within five
                 minutes.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-152,
  pages =        "381--387",
  year =         "2000",
  title =        "Polyhedral Modeling",
  author =       "Georges-Pierre Bonneau and and Stefanie Hahmann",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-152",
  abstract =     "Polyhedral meshes are used for visualization, computer
                 graphics or geometric modeling purposes and result from
                 many applications like iso-surface extraction, surface
                 reconstruction or CAD/CAM. The present paper introduces
                 a method for constructing smooth surfaces from a
                 triangulated polyhedral mesh of arbitrary topology. It
                 presents a new algorithm which generalizes and improves
                 the triangle 4-split method in the crucial point of
                 boundary curve network construction. This network is
                 then filled-in by a visual smooth surface from which an
                 explicit closed form parametrization is given.
                 Furthermore, the method becomes now completely local
                 and can interpolate normal vector input at the mesh
                 vertices.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Triangular meshes, visual continuity, arbitrary
                 topology, visualization.",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-153,
  pages =        "367--372",
  year =         "2000",
  title =        "Constructing Material Interfaces From Data Sets With
                 Volume-Fraction Information",
  author =       "Kathleen S. Bonnell and Daniel R. Schikore and Kenneth
                 I. Joy and Mark Duchaineau and Bernd Hamann",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-153",
  abstract =     "We present a new algorithm for material boundary
                 interface reconstruction from data sets containing
                 volume fractions. We transform the reconstruction
                 problem to a problem that analyzes the dual dataset,
                 where each vertex in the dual mesh has an associated
                 barycentric coordinate tuple that represents the
                 fraction of each material present. After constructing
                 the dual tetrahedral mesh from the original mesh, we
                 construct material boundaries by mapping a tetrahedron
                 into barycentric space and calculating the
                 intersections with Voronoi cells in barycentric space.
                 These intersections are mapped back to the original
                 physical space and triangulated to form the boundary
                 surface approximation. This algorithm can be applied to
                 any grid structure and can treat any number of
                 materials per element/vertex.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  keywords =     "Eulerian flow, material boundary surface, barycentric
                 coordinates, volume fraction, Voronoi diagram.",
  editors =      "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-154,
  pages =        "77--84",
  year =         "2000",
  title =        "Procedural Annotation of Uncertain Information",
  author =       "Andrej Cedilnik and Penny Rheingans",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-154",
  abstract =     "In many applications of scientific visualization, a
                 large quantity of data is being processed and displayed
                 in order to enable a viewer to make informed and
                 effective decisions. Since little data is perfect,
                 there is almost always some degree of associated
                 uncertainty. This uncertainty is an important part of
                 the data and should be taken into consideration when
                 interpreting the data. Uncertainty, however, should not
                 overshadow the data values. Many methods that address
                 the problem of visualizing data with uncertainty can
                 distort the data and emphasize areas with uncertain
                 values. We have developed a method for showing the
                 uncertainty information together with data with minimal
                 distraction. This method uses procedurally generated
                 annotations which are deformed according to the
                 uncertainty information. As another possible technique
                 we propose distorting glyphs according to the
                 uncertainty information.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Procedural generation, Uncertainty visualization,
                 Annotation, Glyphs.",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-155,
  pages =        "327--333",
  year =         "2000",
  title =        "Toward a Compelling Sensation of Telepresence:
                 Demonstrating a portal to a distant (static) office",
  author =       "Wei-Wao Chen and and Herman Towles and Lars Nyland and
                 Greg Welch and Henry Fuchs",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-155",
  abstract =     "In 1998 we introduced the idea for a project we call
                 the Office of the Future. Our long-term vision is to
                 provide a better every-day working environment, with
                 high-fidelity scene reconstruction for life-sized 3D
                 tele-collaboration. In particular, we want a true sense
                 of presence with our remote collaborator and their real
                 surroundings. The challenges related to this vision are
                 enormous and involve many technical tradeoffs. This is
                 true in particular for scene reconstruction.
                 Researchers have been striving to achieve real-time
                 approaches, and while they have made respectable
                 progress, the limitations of conventional technologies
                 relegate them to relatively low resolution in a
                 restricted volume. In this paper we present a
                 significant step toward our ultimate goal, via a
                 slightly different path. In lieu of low-fidelity
                 dynamic scene modeling we present an exceedingly high
                 fidelity reconstruction of a real but static office. By
                 assembling the best of available hardware and software
                 technologies in static scene acquisition, modeling
                 algorithms, rendering, tracking and stereo projective
                 display, we are able to demonstrate a portal to a real
                 office, occupied today by a mannequin, and in the
                 future by a real remote collaborator. We now have both
                 a compelling sense of just how good it could be, and a
                 framework into which we will later incorporate dynamic
                 scene modeling, as we continue to head toward our
                 ultimate goal of 3D collaborative, telepresence.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Telepresence, Tele-Immersion, Virtual Reality,
                 Collaborative Visualization, Immersive Display,
                 Augmented Reality, Human-Computer Interface.",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-156,
  pages =        "125--130",
  year =         "2000",
  title =        "Automatic Alignment Of High-Resolution Multi-Projector
                 Displays Using An Un-Calibrated Camerara",
  author =       "Yuqun Chen and Douglas W. Clark and Adam Finkelstein
                 and Timothy C. Housel and Kai Li",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-156",
  abstract =     "A scalable, high-resolution display may be constructed
                 by tiling many projected images over a single display
                 surface. One fundamental challenge for such a display
                 is to avoid visible seams due to misalignment among the
                 projectors. Traditional methods for avoiding seams
                 involve sophisticated mechanical devices and expensive
                 CRT projectors, coupled with extensive human effort for
                 fine-tuning the projectors. This paper describes an
                 automatic alignment method that relies on an
                 inexpensive, uncalibrated camera to measure the
                 relative mismatches between neighboring projectors, and
                 then correct the projected imagery to avoid seams
                 without significant human effort.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  keywords =     "Seamless tiling, automatic alignment, projective
                 mapping, simulated annealing.",
  editors =      "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-157,
  pages =        "85--92",
  year =         "2000",
  title =        "Simplification of Tetrahedral Meshes with Accurate
                 Error Evaluation",
  author =       "P. Cignoni and D. Constanza and C. Montani and C.
                 Rocchini and R. Scopigno",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-157",
  abstract =     "The techniques for reducing the size of a volume
                 dataset by preserving both the geometrical/topological
                 shape and the information encoded in an attached scalar
                 field are attracting growing interest. Given the
                 framework of incremental 3D mesh simplification based
                 on edge collapse, the paper proposes an approach for
                 the integrated evaluation of the error introduced by
                 both the modification of the domain and the
                 approximation of the field of the original volume
                 dataset. We present and compare various techniques to
                 evaluate the approximation error or to produce a sound
                 prediction. A flexible simplification tool has been
                 implemented, which provides different degree of
                 accuracy and computational efficiency for the selection
                 of the edge to be collapsed. Techniques for preventing
                 a geometric or topological degeneration of the mesh are
                 also presented.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Simplicial Complexes, Mesh Simplification, Volume
                 Visualization, Unstructured Grids.",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-158,
  pages =        "397--405",
  year =         "2000",
  title =        "Anisotropic Geometric Diffusion in Surface
                 Processing",
  author =       "U. Clarenz and U. Diewald and M. Rumpf",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-158",
  abstract =     "A new multiscale method in surface processing is
                 presented here which combines the image processing
                 methodology based on nonlinear diffusion equations and
                 the theory of geometric evolution problems. Its aim is
                 to smooth discretized surfaces while simultaneously
                 enhancing geometric features such as edges and corners.
                 This is obtained by an anisotropic curvature evolution,
                 where time is the multiscale parameter. Here, the
                 diffusion tensor depends on the shape operator of the
                 evolving surface. A spatial finite element
                 discretization on arbitrary unstructured triangular
                 meshes and a semi-implicit finite difference
                 discretization in time are the building blocks of the
                 easy to code algorithm presented here. The systems of
                 linear equations in each time step are solved by
                 appropriate, preconditioned iterative solvers.
                 Different applications underline the efficiency and
                 flexibility of the presented type of surface processing
                 tool.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Image Processing, Geometric Modeling, Numerical
                 Analysis",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-159,
  pages =        "319--326",
  year =         "2000",
  title =        "Geometric Compression For Interactive Transmission",
  author =       "Olivier Devillers and Pierre-Marie Gandoin",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-159",
  abstract =     "The compression of geometric structures is a
                 relatively new field of data compression. Since about
                 1995, several articles have dealt with the coding of
                 meshes, using for most of them the following approach:
                 the vertices of the mesh are coded in an order that
                 partially contains the topology of the mesh. In the
                 same time, some simple rules attempt to predict the
                 position of each vertex from the positions of its
                 neighbors that have been previously coded. In this
                 article, we describe a compression algorithm whose
                 principle is completely different: the coding order of
                 the vertices is used to compress their coordinates, and
                 then the topology of the mesh is reconstructed from the
                 vertices. This algorithm achieves compression ratios
                 that are slightly better than those of the currently
                 available algorithms, and moreover, it allows
                 progressive and interactive transmission of the
                 meshes.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Geometry, compression, coding, interactivity, mesh,
                 reconstruction, terrain models",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-16,
  pages =        "32--42",
  year =         "2000",
  title =        "Combining fast search and learning for fast similarity
                 search",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-16",
  author =       "H. Vassef and C.-S. Li and V. Castelli",
  organization = "SPIE",
  month =        jan,
  editor =       "M. M. Yeung and B.-L. Yeo and C. A. Bouman",
  volume =       "3972",
  booktitle =    "Proceedings of SPIE: Storage and Retrieval for Media
                 Databases 2000",
}

@InProceedings{EVL-2000-160,
  pages =        "195--202",
  year =         "2000",
  title =        "Volume Illustration: Non-Photorealistic Rendering of
                 Volume Models",
  author =       "David Ebert and Penny Rheingans",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-160",
  abstract =     "Accurately and automatically conveying the structure
                 of a volume model is a problem not fully solved by
                 existing volume rendering approaches. Physics-based
                 volume rendering approaches create images which may
                 match the appearance of translucent materials in
                 nature, but may not embody important structural
                 details. Transfer function approaches allow flexible
                 design of the volume appearance, but generally require
                 substantial hand tuning for each new data set in order
                 to be effective. We introduce the volume illustration
                 approach, combining the familiarity of a physics based
                 illumination model with the ability to enhance
                 important features using non-photorealistic rendering
                 techniques. Since features to be enhanced are defined
                 on the basis of local volume characteristics rather
                 than volume sample value, the application of volume
                 illustration techniques requires less manual tuning
                 than the design of a good transfer function. Volume
                 illustration provides a flexible unified framework for
                 enhancing structural perception of volume models
                 through the amplification of features and the addition
                 of illumination effects.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Volume rendering, non-photorealistic rendering,
                 illustration, lighting models, shading,
                 visualization.",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-161,
  pages =        "335--342",
  year =         "2000",
  title =        "Multi-User View-Dependent Rendering",
  author =       "Jihad El-Sana",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-161",
  abstract =     "In this paper we are presenting a novel architecture
                 which allows rendering of large-shared dataset at
                 interactive rates on an in expensive workstation. The
                 idea is based on view-dependent rendering on a
                 client-server network. The server stores the large
                 dataset and manages the selection of the various levels
                 of detail while the inexpensive clients receive a
                 stream of update operations that generate the
                 appropriate level of detail in an incremental fashion.
                 These update operations are based on changes in the
                 clients' view-parameters. Our approach dramatically
                 reduces the amount of memory needed by each client and
                 the entire computing system since the dataset is stored
                 only once on the server's local memory. In addition, it
                 decreases the load on the network as results of the
                 incremental update contributed by view-dependent
                 rendering.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-162,
  pages =        "259--266",
  year =         "2000",
  title =        "Topology Preserving and Controlled Topology
                 Simplifying Multiresolution Isosurface Extraction",
  author =       "Thomas Gerstner and Renato Pajarola",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-162",
  abstract =     "Multiresolution methods are becoming increasingly
                 important tools for the interactive visualization of
                 very large data sets. Multiresolution isosurface
                 visualization allows the user to explore volume data
                 using simplified and coarse representations of the
                 isosurface for overview images, and finer resolution in
                 areas of high interest or when zooming into the data.
                 Ideally, a coarse isosurface should have the same
                 topological structure as the original. The topological
                 genus of the isosurface is one important property which
                 is often neglected in multiresolution algorithms. This
                 results in uncontrolled topological changes which can
                 occur whenever the level-of-detail is changed. The
                 scope of this paper is to propose an efficient
                 technique which allows preservation of topology as well
                 as controlled topology simplification in
                 multiresolution isosurface extraction.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Tetrahedral grid refinement, implicit surface
                 approximation, level-of-detail, topological genus,
                 critical points.",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-163,
  pages =        "139--146",
  year =         "2000",
  title =        "Six Degree-of-Freedom Haptic Display of Polygonal
                 Models",
  author =       "Arthur Gregory and Ajith Mascarenhas and Stephen
                 Ehmann and Ming Lin and Dinesh Manocha",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-163",
  abstract =     "We present an algorithm for haptic display of
                 moderately complex polygonal models with a six degree
                 of freedom (DOF) force feedback device. We make use of
                 incremental algorithms for contact determination
                 between convex primitives. The resulting contact
                 information is used for calculating the restoring
                 forces and torques and thereby used to generate a sense
                 of virtual touch. To speed up the computation, our
                 approach exploits a combination of geometric locality,
                 temporal coherence, and predictive methods to compute
                 object-object contacts at kHz rates. The algorithm has
                 been implemented and interfaced with a 6-DOF PHANToM
                 Premium 1.5. We demonstrate its performance on force
                 display of the mechanical interaction between
                 moderately complex geometric structures that can be
                 decomposed into convex primitives",
  organization = "IEEE Computer Society technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Haptics, virtual reality, force-feedback devices,
                 interactive computer graphics",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-164,
  pages =        "29--36",
  year =         "2000",
  title =        "A Visibility Determination Algorithm for Interactive
                 Virtual Endoscopy",
  author =       "Rami Hietala and Jarkko Oikarinen",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-164",
  abstract =     "We present a new visibility determination algorithm
                 for interactive virtual endoscopy. The algorithm uses a
                 modified version of template-based ray casting to
                 extract a view dependent set of potentially visible
                 voxels from volume data. The voxels are triangulated by
                 Marching Cubes and the triangles are rendered onto the
                 display by a graphics accelerator. Early ray
                 termination and space leaping are used to accelerate
                 the ray casting step and a quadtree subdivision
                 algorithm is used to reduce the number of cast rays.
                 Compared to other recently proposed rendering
                 algorithms for virtual endoscopy, our rendering
                 algorithm does not require a long preprocessing step or
                 a high-end graphics workstation, but achieves
                 interactive frame rates on a standard PC equipped with
                 a low-cost graphics accelerator",
  organization = "IEEE Computer Society Tecjnical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Volume Visualization, Template, Visibility, Isosurface
                 Extraction, Surface Rendering",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-165,
  pages =        "311--318",
  year =         "2000",
  title =        "Visualizing Geodesics",
  author =       "Ingrid Hotz and Hans Hagen",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-165",
  abstract =     "One of the main research topics in scientific
                 visualization is to {"}visualize the appropriate
                 features{"} of a certain structure or data set.
                 Geodesics are very important in geometry and physics,
                 but there is one major problem which prevents
                 scientists from using them as a visualization tool: The
                 differential equations for geodesics are very
                 complicated and in most cases numerical algorithms must
                 be used. There is always a certain approximation error
                 involved. How can you be sure to visualize the features
                 and not only the approximation quality. We present here
                 an algorithm to overcome this problem. This paper
                 consists of two parts. In the first, a geometric method
                 for the construction of geodesics of arbitrary surfaces
                 is introduced. This method is based on the fundamental
                 property that geodesics are a generalization of
                 straight lines on plains. In the second part these
                 geodesics are used to generate local nets on the
                 surfaces.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Geodesics, visualization features",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-166,
  year =         "2000",
  title =        "Visual Cues For Imminent Object Contact In Realistic
                 Virtual Environments",
  author =       "Helen H. Hu and Amy A. Gooch and William B. Thompson
                 and Brian E. Smits and John J. Rieser and Peter
                 Shirley",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-166",
  abstract =     "Distance judgments are difficult in current virtual
                 environments, limiting their effectiveness in conveying
                 spatial information. This problem is apparent when
                 contact occurs while a user is manipulating objects. In
                 particular, the computer graphics used to support
                 current generation immersive interfaces does a poor job
                 of providing the visual cues necessary to perceive when
                 contact between objects is about to occur. This
                 perception of imminent contact is important in human
                 motor control. Its absence prevents a sense of
                 naturalness in interactive displays which allow for
                 object manipulation. This paper reports results from an
                 experiment evaluating the effectiveness of binocular
                 disparity, cast shadows, and diffuse inter-reflections
                 in signaling imminent contact in a manipulation task.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  pagges =       "179--185",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Virtual Reality, Head Mounted Displays, Human Visual
                 Perception",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-167,
  pages =        "219--226",
  year =         "2000",
  title =        "FastSplats: Optimized Splatting on Rectilinear Grids",
  author =       "Jian Huang and Klaus Mueller and Naeem Sharef and
                 Roger Crawfi",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-167",
  abstract =     "Splatting is widely applied in many areas, including
                 volume, point-based, and image-based rendering.
                 Improvements to splatting, such as eliminating popping
                 and color bleeding, occlusion-based acceleration,
                 post-rendering classification and shading, have all
                 been recently accomplished. These improvements share a
                 common need for efficient framebuffer accesses. We
                 present an optimized software splatting package, using
                 a newly designed primitive, called FastSplat, to
                 scan-convert footprints. Our approach does not use
                 texture mapping hardware, but supports the whole
                 pipeline in memory. In such an integrated pipeline, we
                 are then able to study the optimization strategies and
                 address image quality issues. While this research is
                 meant for a study of the inherent trade-off of
                 splatting, our renderer, purley in software, achieves 3
                 to 5 times speedups over a top-end texture hardware
                 (for opaque data sets) implementation. We further
                 propose a way of efficient occlusion culling using a
                 summed area table of opacity. 3D solid texturing and
                 bump mapping capabilities are demonstrated to show the
                 flexibility of such an integrated rendering pipeline. A
                 detailed numerical error analysis, in addition to the
                 performance and storage issues, is also presented. Our
                 approach requires low storage and uses simple
                 operations. Thus, it is easily implementable in
                 hardware.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-168,
  pages =        "407--414",
  year =         "2000",
  title =        "Fairing Of Non-Manifolds For Visualization",
  author =       "Andreas Hubeli and Markus Gross",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-168",
  abstract =     "The concept of fairing applied to irregular triangular
                 meshes has become more and more important. Previous
                 contributions constructed better fairing operators, and
                 applied them both to multiresolution editing tools and
                 to multiresolution representations of meshes. In this
                 paper, we generalize these powerful techniques to
                 handle non-manifold models. Our framework computes a
                 multilevel fairing of models by fairing both the
                 two-manifold surfaces that define the model, the
                 so-called two-features, and all the boundary and
                 intersection curves of the model, the so-called
                 one-features. In addition we introduce two extensions
                 that can be used in our framework as well as in
                 manifold fairing concepts: an exact local volume
                 preservation strategy and a method for feature
                 preservation. Our framework works with any of the
                 manifold fairing operators for meshes.",
  organization = "IEEE Computer Society Technical Committe on Computer
                 Graphics",
  keywords =     "Boundary Representations, Surface Representations,
                 Non-manifold, Fairing, Geometric Modeling, Triangle
                 Decimation, Multiresolution Models.",
  editors =      "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-169,
  pages =        "53--60",
  year =         "2000",
  title =        "Creating Reusable Visualizations with the Relational
                 Visualization Notation",
  author =       "Matthew C. Humphrey and Ph.D.",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-169",
  abstract =     "Richly expressive information visualizations are
                 difficult to design and rarely found. Few software
                 tools can generate multidimensional visualizations at
                 all, let alone incorporate artistic detail. Although,
                 it is a great efficiency to reuse these visualizations
                 with new data, the associated artistic detail is rarely
                 reusable. The Relational Visualization Notation is a
                 new technique and toolkit for specifying highly
                 expressive graphical representations of data without
                 traditional programming. We seek to discover the
                 accessible power of this notation - both its graphical
                 expressiveness and its ease of re-use. Towards this end
                 we have used the system to reconstruct Minard's
                 visualization of Napoleon's Russian campaign of 1812.
                 The resulting image is strikingly similar to the
                 original, and the design is straightforward to
                 construct. Furthermore, the design permitted by the
                 notation can be directly reused to visualize Hitler's
                 WWII defeat before Moscow. This experience leads us to
                 believe that artistically expressive visualizations can
                 be made to be reusable.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Information visualization, graphic design, visual
                 design.",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-17,
  pages =        "43--54",
  year =         "2000",
  title =        "Bayesian representations and learning mechanisms for
                 content-based image retrieval",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-17",
  author =       "N. M. Vasconcelos and A. B. Lippman",
  organization = "SPIE",
  month =        jan,
  editor =       "M. M. Yeung and B.-L. Yeo and C. A. Bouman",
  volume =       "3972",
  booktitle =    "Proceedings of SPIE: Storage and Retrieval for Media
                 Databases 2000",
}

@InProceedings{EVL-2000-170,
  pages =        "243--250",
  year =         "2000",
  title =        "Uniform Frequency Images: Adding Geometry to Images to
                 Produce Space-Efficient Textures",
  author =       "Adam Hunter and Jonathan D. Cohen",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-170",
  abstract =     "We discuss the concept of uniform frequency images,
                 which exhibit uniform local frequency properties. Such
                 images make optimal use of space when sampled close to
                 their Nyquist limit. A warping function may be applied
                 to an arbitrary image to redistribute its local
                 frequency content, reducing its highest frequencies and
                 increasing its lowest frequencies in order to approach
                 this uniform frequency ideal. The warped image may then
                 be downsampled according to its new, reduced Nyquist
                 limit, thereby reducing its storage requirements. To
                 reconstruct the original image, the inverse warp is
                 applied. We present a general, top-down algorithm to
                 automatically generate a piecewise-linear warping
                 function with this frequency balancing property for a
                 given input image. The image size is reduced by
                 applying the warp and then downsampling. We store this
                 warped, downsampled image plus a small number of
                 polygons with texture coordinates to describe the
                 inverse warp. The original image is later reconstructed
                 by rendering the associated polygons with the warped
                 image applied as a texture map, a process which is
                 easily accelerated by current graphics hardware. As
                 compared to previous image compression techniques, we
                 generate a similar graceful space-quality tradeoff with
                 the advantage of being able to {"}uncompress{"} images
                 during rendering. We report results for several images
                 with sizes ranging from15,000 to 300,000 pixels,
                 achieving reduction rates of 70-90% with improved
                 quality over downsampling alone.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Texture mapping, Fourier analysis, sampling,
                 parameterization, visualization.",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-171,
  pages =        "69--76",
  year =         "2000",
  title =        "A Spreadsheet Interface for Visualization
                 Exploration",
  author =       "T. J. Jankun-Kelly and Kwan-Liu Ma",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-171",
  abstract =     "As the size and complexity of data sets continues to
                 increase, the development of user interfaces and
                 interaction techniques that expedite the process of
                 exploring that data must receive new attention.
                 Regardless of the speed of rendering, it is important
                 to coherently organize the visual process of
                 exploration: this information both grants insights
                 about the data to a user and can be used by
                 collaborators to understand the results. To fulfill
                 these needs, we present a spreadsheet-like interface to
                 data exploration. The interface displays a
                 2-dimensional window into visualization parameter space
                 which users manipulate as they search for desired
                 results. Through tabular organization and a clear
                 correspondence between parameters and results, the
                 interface eases the discovery, comparison and analysis
                 of the underlying data. Users can utilize operators and
                 the integrated interpreter to further explore and
                 automate the visualization process; using a method
                 introduced in this paper, these operations can be
                 applied to {"}cells{"} in different {"}stacks{"} of the
                 interface. Via illustrations using a variety of data
                 sets, we demonstrate the efficacy of this novel
                 interface.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Spreadsheets, user interfaces, knowledge
                 representation, scientific visualization, visualization
                 systems, volume rendering",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-172,
  pages =        "155--162",
  year =         "2000",
  title =        "Hardware-Accelerated Texture Advection",
  author =       "Bruno Jobard and Gordon Erlebacher and M. Yousuff
                 Hussaini",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-172",
  abstract =     "We present a novel hardware-accelerated texture
                 advection algorithm to visualize the motion of
                 two-dimensional unsteady flows. Making use of several
                 proposed extensions to the OpenGL-1.2 specification, we
                 demonstrate animations of over 65,000 particles at 2
                 frames/sec on an SGI Octane with EMXI graphics. High
                 image quality is achieved by careful attention to edge
                 effects, noise frequency, and image enhancement. We
                 provide a detailed description of the hardware
                 implementation, including temporal and spatial
                 coherence techniques, dye advection techniques, and
                 feature extraction.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "unsteady, vector field, pathlines, streakline,
                 advection, texture, hardware, OpenGL.",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-173,
  pages =        "297--302",
  year =         "2000",
  title =        "Visualization of Multi-Dimensional Data with
                 Vector-fusion",
  author =       "RR Johnson",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-173",
  abstract =     "Multi-dimensional entities are modeled, displayed, and
                 understood with a new algorithm vectorizing data of any
                 dimensionality. This algorithm is called SBP; it is a
                 vectorized generalization of parallel coordinates.
                 Classic geometries of any dimensionality can be
                 demonstrated to facilitate perception and understanding
                 of the shapes generated by this algorithm. SBP images
                 of a 4D line, a circle, and 3D and 4D spherical helices
                 are shown. A strategy for synthesizing
                 multi-dimensional models matching multi-dimensional
                 data is presented. Currrent applications include data
                 mining; modeling data-defined structures of scientific
                 interest such as protein structure and Calabi-Yau
                 figures as multi-dimensional geometric entities;
                 generating vector-fused data signature {"}finger
                 prints{"} of classic frequency spectra that identify
                 substances; and treating complex targets as
                 multi-dimensional entities for automatic target
                 recognition. SBP Vector Data Signatures apply to all
                 pattern recognition problems.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Multidimensional Visualization, Vector Data Fusion,
                 Multidimensional Geometry.",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-174,
  pages =        "37--44",
  year =         "2000",
  title =        "3{D} Digital Cleansing Using Segmentation Rays",
  author =       "Sarang Lakare and Ming Wan and Mie Sato and Arie
                 Kaufman",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-174",
  abstract =     "We propose a novel approach for segmentation and
                 digital cleansing of endoscopic organs. Our method can
                 be used for a variety of segmentation needs with little
                 or no modification. It aims at fulfilling the dual and
                 often conflicting requirements of a fast and accurate
                 segmentation and also eliminates the undesirable
                 partial volume effect which contemporary approaches
                 cannot. For segmentation and digital cleansing, we use
                 the peculiar characteristics exhibited by the
                 intersection of any two distinct-intensity regions. To
                 detect these intersections we cast rays through the
                 volume, which we call the segmentation rays as they
                 assist in the segmentation. We then associate a certain
                 task of reconstruction and classification with each
                 intersection the ray detects. We further use volumetric
                 contrast enhancement to reconstruct surface lost by
                 segmentation (if any), which aids in improving the
                 quality of the volume rendering.",
  organization = "IEEE Computer Society Technical Committee on omputer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Volume Segmentation, Segmentation Rays, Partial Volume
                 Voxels, Volume Rendering, Virtual Endoscopy, Virtual
                 Colonoscopy",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-175,
  pages =        "131--137",
  year =         "2000",
  title =        "Shock and Vortex Visualization Using a Combined
                 Visual/Haptic Interface",
  author =       "Dale A. Lawrence and Christopher D. Lee and Lucy Y.
                 Pao and Roman Y. Novoselov",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-175",
  abstract =     "Specific rendering modes are developed for a combined
                 visual/haptic interface to allow exploration and
                 understanding of fluid dynamics data. The focus is on
                 visualization of shock surfaces and vortex cores.
                 Advantages provided by augmenting traditional graphical
                 rendering modes with haptic rendering modes are
                 discussed. Particular emphasis is placed on synergistic
                 combinations of visual and haptic modes which enable
                 rapid, exploratory interaction with the data.
                 Implementation issues are also discussed",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Haptic, interface, vortex, shock, visualization, fluid
                 dynamics, virtual environment.",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-176,
  pages =        "343--350",
  year =         "2000",
  title =        "Topology Preserving Compression of 2{D} Vector
                 Fields",
  author =       "Suresh K. Lodha and Jose C. Renteria and Krishna M.
                 Roskin",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-176",
  abstract =     "We present an algorithm for compressing 2D vector
                 fields that preserves topology. Our approach is to
                 simplify the given data set using constrained
                 clustering. We employ different types of global and
                 local error metrics including the earth mover's
                 distance metric to measure the degradation in topology
                 as well as weighted magnitude and angular errors. As a
                 result, we obtain precise error bounds in the
                 compressed vector fields. Experiments with both
                 analytic and simulated data sets are presented. Results
                 indicate that one can obtain significant compression
                 with low errors without losing topology information.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Compression, topology, vector fields, error metrics,
                 clustering.",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-177,
  pages =        "117--124",
  year =         "2000",
  title =        "Achieving Color Uniformity Across Multi-Projector
                 Displays",
  author =       "Aditi Majumder and Zhu He and Herman Towles and Greg
                 Welch",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-177",
  abstract =     "Large area tiled displays are gaining popularity for
                 use in collaborative immersive virtual environments and
                 scientific visualization. While recent work has
                 addressed the issues of geometric registration,
                 rendering architectures, and human interfaces, there
                 has been relatively little work on photometric
                 calibration in general,and photometric non-uniformity
                 in particular. For example, as a result of differences
                 in the photometric characteristics of projectors, the
                 color and intensity of a large area display varies from
                 place to place. Further, the imagery typically appears
                 brighter at the regions of overlap between adjacent
                 projectors. In this paper we analyze and classify the
                 causes of photometric non-uniformity in a tiled
                 display. We then propose a methodology for determining
                 corrections designed to achieve uniformity, that can
                 correct for the photometric variations across a tiled
                 projector display in real time using per channel color
                 look-up-tables (LUT).",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Large Area Display, Tiled Displays, Projector
                 Graphics, Color Calibration.",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-178,
  pages =        "187--194",
  year =         "2000",
  title =        "Basic Research for Coloring Multichannel {MRI} Data",
  author =       "Shigeru Muraki and Toshiharu Nakai and Yasuyo Kita",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-178",
  abstract =     "This is basic research for assigning color values to
                 voxels of multichannel MRI volume data. The MRI volume
                 datasets obtained under different scanning conditions
                 are transformed to the components by independent
                 component analysis (ICA), which enhances physical
                 characteristics of the tissue. The transfer functions
                 for generating color values from independent components
                 are obtained using the radial basis function network, a
                 kind of neural net, by training the network with sample
                 data chosen from visible female data set. The resultant
                 color volume datasets correspond well with the
                 full-color cross-sections of the visible human
                 datasets.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Color MRI, Independent Component Analysis, Transfer
                 Function",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-179,
  pages =        "415--422",
  year =         "2000",
  title =        "Interior/Exterior Classification of Polygonal Models",
  author =       "F. S. Nooruddin and Greg Turk",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-179",
  abstract =     "We present an algorithm for automatically classifying
                 the interior and exterior parts of a polygonal model.
                 The need for visualizing the interiors of objects
                 frequently arises in medical visualization and CAD
                 modeling. The goal of such visualizations is to display
                 the model in a way that the human observer can easily
                 understand the relationship between the different parts
                 of the surface. While there exist excellent methods for
                 visualizing surfaces that are inside one another
                 (nested surfaces), the determination of which parts of
                 the surface are interior is currently done manually.
                 Our automatic method for interior classification takes
                 a sampling approach using a collection of direction
                 vectors. Polygons are said to be interior to the model
                 if they are not visible in any of these viewing
                 directions from a point outside the model. Once we have
                 identified polygons as being inside or outside the
                 model, these can be textured or have different
                 opacities applied to them so that the whole model can
                 be rendered in a more comprehensible manner. An
                 additional consideration for some models is that they
                 may have holes or tunnels running through them that are
                 connected to the exterior surface. Although an external
                 observer can see into these holes, it is often
                 desirable to mark the walls of such tunnels as being
                 part of the interior of a model. In order to allow this
                 modified classification of the interior, we use
                 morphological operators to close all the holes of the
                 model. An input model is used together with its closed
                 version to provide a better classification of the
                 portions of the original model.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Visibility, Surface Classification, Rendering,
                 Interior Surfaces",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-18,
  pages =        "55--63",
  year =         "2000",
  title =        "Indexing of image content in spine x rays",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-18",
  author =       "L. R. Long and G. R. Thoma",
  organization = "SPIE",
  month =        jan,
  editor =       "M. M. Yeung and B.-L. Yeo and C. A. Bouman",
  volume =       "3972",
  booktitle =    "Proceedings of SPIE: Storage and Retrieval for Media
                 Databases 2000",
}

@InProceedings{EVL-2000-180,
  pages =        "251--258",
  year =         "2000",
  title =        "Image Based Rendering With Stable Frame Rates",
  author =       "Huamin Qu and Ming Wan and Jiafa Qin and Arie
                 Kaufman",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-180",
  abstract =     "This paper presents an efficient keyframeless
                 image-based rendering technique. An intermediate image
                 is used to exploit the coherences among neighboring
                 frames. The pixels in the intermediate image are first
                 rendered by a ray-casting method and then warped to the
                 intermediate image at the current viewpoint and view
                 direction. We use an offset buffer to record the
                 precise positions of these pixels in the intermediate
                 image. Every frame is generated in three steps: warping
                 the intermediate image onto the frame, filling in
                 holes, and selectively rendering a group of {"}old{"}
                 pixels. By dynamically adjusting the number of those
                 {"}old{"} pixels in the last step, the workload at
                 every frame can be balanced. The pixels generated by
                 the last two steps make contributions to the new
                 intermediate image. Unlike occasional keyframes in
                 conventional image-based rendering which need to be
                 totally rerendered, intermediate images only need to be
                 partially updated at every frame. In this way, we
                 guarantee more stable frame rates and more uniform
                 image qualities. The intermediate image can be warped
                 efficiently by a modified incremental 3D warp
                 algorithm. As a specific application, we demonstrate
                 our technique with a voxel-based terrain rendering
                 system.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Image-based rendering, ray casting, voxel-based
                 modeling, terrain rendering.",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-181,
  pages =        "93--100",
  year =         "2000",
  title =        "Tetrahedron Based, Least Squares, Progressive Volume
                 Models with Application to Freehand Ultrasound Data",
  author =       "Tom Roxborough and Gregory M. Nielson",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-181",
  abstract =     "In this paper we present a new method for the modeling
                 of freehand collected three-dimensional ultrasound
                 data. The model is piece-wise linear and based upon
                 progressive tetrahedral domains created by a
                 subdivision scheme which splits a tetrahedron on its
                 longest edge and guarantees a valid tetrahedrization.
                 Least squares error is used to characterize the model
                 and an effective iterative technique is used to compute
                 the values of the model at the vertices of the
                 tetrahedral grid. Since the subdivision strategy is
                 adaptive, the complexity of the model conforms to the
                 complexity of the data leading to an extremely
                 efficient and highly compressed volume model. The model
                 is evaluated in real time using piece-wise linear
                 interpolation, and gives a medical professional the
                 chance to see images which would not be possible using
                 conventional ultrasound techniques.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-182,
  pages =        "171--178",
  year =         "2000",
  title =        "Enabling Level-of-Detail Matching for Exterior Scene
                 Synthesis",
  author =       "Randy K. Scoggins and Raghu Machiraju and Robert J.
                 Moorhead",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-182",
  abstract =     "This work presents a method to enable matching of
                 level-of-detail(LOD) models to image-plane resolution
                 over large variations in viewing distances often
                 present in exterior images. A relationship is developed
                 between image sampling rate, viewing distance, object
                 projection, and expected image error due to LOD
                 approximations. This is employed in an error metric to
                 compute error profiles for LOD models. Multirate
                 filtering in the frequency space of a reference object
                 image is utilized to approximate multiple distant views
                 over a range of orientations. An importance sampling
                 method is described to better characterize perspective
                 projection over view distance. A contrast sensitivity
                 function (CSF) is employed to approximate the response
                 of the vision system. Examples are presented for
                 multiresolution spheres and a terrain height field
                 feature. Future directions for extending this method
                 are described.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Multiresolution model, level-of-detail, rendering,
                 image metrics, perception, terrain visualization.",
  booktitle =    "Proceedings Visualization 2000",
}

@{,
}

@{,
}

@InProceedings{EVL-2000-185,
  pages =        "235--242",
  year =         "2000",
  title =        "Simplification Of Surface Annotations",
  author =       "Frank Suits and James T. Klosowski and William P. Horn
                 and G'erard Lecina",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-185",
  abstract =     "Geometric models are often annotated to provide
                 additional information during visualization. Maps may
                 be marked with rivers, roads, or topographical
                 information, and CAD data models may highlight the
                 underlying mesh structure. While this additional
                 information may be extremely useful, there is a
                 rendering cost associated with it. Texture maps have
                 often been used to convey this information at
                 relatively low cost, but they suffer from blurring and
                 pixelization at high magnification. We present a
                 technique for simplifying surface annotations based on
                 directed, asymmetric tolerance. By maintaining the
                 annotations as geometry, as opposed to textures, we are
                 able to simplify them while still maintaining the
                 overall appearance of the model over a wide range of
                 magnifications. Texture maps may still be used to
                 provide low-resolution surface detail, such as color.
                 We demonstrate a significant gain in rendering
                 performance while retaining the original appearance of
                 objects from many application domains.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Simplification, polygonal path, mesh, CAD/CAM, FEM,
                 cartography",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-186,
  pages =        "203--210",
  year =         "2000",
  title =        "Pen-and-Ink Rendering in Volume Visualisation",
  author =       "S. M. F. Treavett and M. Chen",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-186",
  abstract =     "This paper is concerned with the development of
                 non-photorealistic rendering techniques for volume
                 visualisation. In particular, we present two
                 pen-and-ink rendering methods, a 3D method based on
                 non-photorealistic solid textures, and a 2+D method
                 that involves two rendering phases in the object space
                 and image space respectively. As both techniques
                 utilize volume- and image-based data representations,
                 they can be built upon a traditional volume rendering
                 pipeline, and be integrated with photorealistic methods
                 available in such a pipeline. We demonstrate that such
                 an integration facilitates an effective mechanism for
                 enhancing visualisation and its interpretation.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Volume rendering, non-photorealistic rendering,
                 pen-and-ink rendering, 3D texture mapping",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-187,
  pages =        "359--366",
  year =         "2000",
  title =        "A Topology Simplification Method For 2{D} Vector
                 Fields",
  author =       "Xavier Tricoche and Gerik Scheuermann and Hans Hagen",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-187",
  abstract =     "Topology analysis of plane, turbulent vector fields
                 results in visual clutter caused by critical points
                 indicating vortices of finer and finer scales. A
                 simplification can be achieved by merging critical
                 points within a prescribed radius into higher order
                 critical points. After building clusters containing the
                 singularities to merge, the method generates a
                 piecewise linear representation of the vector field in
                 each cluster containing only one (higher order)
                 singularity. Any visualization method can be applied to
                 the result after this process. Using different maximal
                 distances for the critical points to be merged results
                 in a hierarchy of simplified vector fields that can be
                 used for analysis on different scales.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  keywords =     "Vector field topology, flow visualization, clustering,
                 simplification",
  editors =      "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-188,
  pages =        "163--170",
  year =         "2000",
  title =        "A Flow-guided Streamline Seeding Strategy",
  author =       "Vivek Verma1 and David Kao and Alex Pang",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-188",
  abstract =     "This paper presents a seed placement strategy for
                 streamlines based on flow features in the dataset. The
                 primary goal of our seeding strategy is to capture flow
                 patterns in the vicinity of critical points in the flow
                 field, even as the density of streamlines is reduced.
                 Secondary goals are to place streamlines such that
                 there is sufficient coverage in non-critical regions,
                 and to vary the streamline placements and lengths so
                 that the overall presentation is aesthetically pleasing
                 (avoid clustering of streamlines, avoid sharp
                 discontinuities across several streamlines, etc.). The
                 procedure is straight forward and non-iterative. First,
                 critical points are identified. Next, the flow field is
                 segmented into regions, each containing a single
                 critical point. The critical point in each region is
                 then seeded with a template depending on the type of
                 critical point. Finally, additional seed points are
                 randomly distributed around the field using a Poisson
                 disk distribution to minimize closely spaced seed
                 points. The main advantage of this approach is that it
                 does not miss the features around critical points.
                 Since the strategy is not image-guided, and hence not
                 view dependent, significant savings are possible when
                 examining flow fields from different viewpoints,
                 especially for 3D flow fields.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  keywords =     "Seed placement, streamline, critical point, Voronoi
                 diagram, Poisson disk distribution.",
  editors =      "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-189,
  pages =        "283--289",
  year =         "2000",
  title =        "Scanline Surfacing: Building Separating Surfaces from
                 Planar Contours",
  author =       "David Weinstein",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-189",
  abstract =     "A standard way to segment medical imaging datasets is
                 by tracing contours around regions of interest in
                 parallel planar slices. Unfortunately, the standard
                 methods for reconstructing three dimensional surfaces
                 from those planar contours tend to be either
                 complicated or not very robust. Furthermore, they fail
                 to consistently mesh abutting structures which share
                 portions of contours. In this paper we present a novel,
                 straight-forward algorithm for accurately and
                 automatically reconstructing surfaces from planar
                 contours. Our algorithm is based on scanline rendering
                 and separating surface extraction. By rendering the
                 contours as distinctly colored polygons and reading
                 back each rendered slice into a segmented volume, we
                 reduce the complex problem of building a surface from
                 planar contours to the much simpler problem of
                 extracting separating surfaces from a classified
                 volume. Our scanline surfacing algorithm robustly
                 handles complex surface topologies such as
                 bifurcations, embedded features, and abutting
                 surfaces.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Separating Surfaces, Planar Contours, Surface
                 Construction, Scanline",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-19,
  pages =        "64--75",
  year =         "2000",
  title =        "Framework for efficient processing of content-based
                 fuzzy Cartesian queries",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-19",
  author =       "C.-S. Li and Y.-C. Chang and J. R. Smith and L. D.
                 Bergman and V. Castelli",
  organization = "SPIE",
  month =        jan,
  editor =       "M. M. Yeung and B.-L. Yeo and C. A. Bouman",
  volume =       "3972",
  booktitle =    "Proceedings of SPIE: Storage and Retrieval for Media
                 Databases 2000",
}

@InProceedings{EVL-2000-190,
  pages =        "303--310",
  year =         "2000",
  title =        "Real-World Relativity: Image-Based Special
                 Relativistic Visualization",
  author =       "Daniel Weiskopf and Daniel Kobras and Hanns Ruder",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-190",
  abstract =     "This paper describes a novel rendering technique for
                 special relativistic visualization. It is an
                 image-based method which allows to render high speed
                 flights through real-world scenes filmed by a standard
                 camera. The relativistic effects on image generation
                 are determined by the relativistic aberration of light,
                 the Doppler effect, and the searchlight effect. These
                 account for changes of apparent geometry, color, and
                 brightness of the objects. It is shown how the
                 relativistic effects can be taken into account by a
                 modification of the plenoptic function. Therefore, all
                 known image-based non-relativistic rendering methods
                 can easily be extended to incorporate relativistic
                 rendering. Our implementation allows interactive
                 viewing of relativistic panoramas and the production of
                 movies which show super-fast travel. Examples in the
                 form of snapshots and film sequences are included.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Image-based rendering, plenoptic function, scientific
                 visualization, special relativity",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-191,
  pages =        "291--296",
  year =         "2000",
  title =        "Navigating High-dimensional Spaces to Support Design
                 Steering",
  author =       "Helen Wright and Ken Brodlie and Tim David",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-191",
  abstract =     "Throughout the design cycle, visualization, whether a
                 sketch scribbled on the back of a spare piece of paper
                 or a fully detailed drawing, has been the mainstay of
                 design: we need to see the product. One of the most
                 important stages of the design cycle is the initial, or
                 concept, stage and it is here that design variants
                 occur in large numbers to be vetted quickly. At this
                 initial stage the human element - the designer - is
                 crucial to the success of the product. In this paper we
                 describe an interactive environment for concept design
                 which recognises the needs of the designer, not only to
                 see the product and make rapid modifications, but also
                 to monitor the progress of their design towards some
                 preferred solution. This leads to the notion of a
                 design parameter space, typically high-dimensional,
                 which must also be visualized in addition to the
                 product itself. Using a module developed for IRIS
                 Explorer (TM), design steering is presented as a
                 navigation of this space in order to search for optimal
                 designs, either manually or by local optimisation.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Computational steering, design steering, concept
                 design, multidimensional visualization, scientific data
                 visualization.",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-192,
  pages =        "101--108",
  year =         "2000",
  title =        "On-the-Fly Rendering Of Losslessly Compressed
                 Irregular Volume Data",
  author =       "Chuan-kai Yang and Tulika Mitra and Tzi-cker Chiueh",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-192",
  abstract =     "Very large irregular-grid data sets are represented as
                 tetrahedral meshes and may incur significant disk I/O
                 access overhead in the rendering process. An effective
                 way to alleviate the disk I/O overhead associated with
                 rendering large tetrahedral mesh is to reduce the I/O
                 bandwidth requirement through compression. Existing
                 tetrahedral mesh compression algorithms focus only on
                 compression efficiency and cannot be readily integrated
                 into the mesh rendering process, and thus demand that a
                 compressed tetrahedral mesh be decompressed before it
                 can be rendered into a 2D image. This paper presents an
                 integrated tetrahedral mesh compression and rendering
                 algorithm called Gatun, which allows compressed
                 tetrahedral meshes to be rendered incrementally as they
                 are being decompressed, thus leading to an efficient
                 irregular grid rendering pipeline. Both compression and
                 rendering algorithms in Gatun exploit the same local
                 connectivity information among adjacent tetrahedra, and
                 thus can be tightly integrated into a unified
                 implementation framework. Our tetrahedral compression
                 algorithm is specifically designed to facilitate the
                 integration with irregular grid renderer without any
                 compromise in compression efficiency. A unique
                 performance advantage of Gatun is its ability to reduce
                 the runtime memory footprint requirement by releasing
                 memory allocated to tetrahedra as early as possible. As
                 a result, Gatun is able to decrease rendering time by
                 one or two orders of magnitude for very large
                 tetrahedral meshes whose size exceeds the amount of
                 physical memory. At the same time, the smaller working
                 set and better access locality of Gatun improve the
                 rendering performance by up to 30%, even when the input
                 tetrahedral mesh is entirely memory-resident.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Irregular Grids, Tetrahedral Compression, Volume
                 Rendering",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-193,
  pages =        "61--68",
  year =         "2000",
  title =        "{H}-{BLOB}: {A} Hierarchical Visual Clustering
                 Method",
  author =       "T. C. Sprenger and R. Brunella and M. H. Gross",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-193",
  abstract =     "In this paper, we present a new hierarchical
                 clustering and visualization algorithm called H-BLOB,
                 which groups and visualizes cluster hierarchies at
                 multiple levels-of-detail. Our method is fundamentally
                 different to conventional clustering algorithms, such
                 as C-means, K-means, or linkage methods that are
                 primarily designed to partition a collection of objects
                 into subsets sharing similar attributes. These
                 approaches usually lack an efficient level-of-detail
                 strategy that breaks down the visual complexity of very
                 large datasets for visualization. In contrast, our
                 method combines grouping and visualization in a two
                 stage process constructing a hierarchical setting. In
                 the first stage a cluster tree is computed making use
                 of an edge contraction operator. Exploiting the
                 inherent hierarchical structure of this tree, a second
                 stage visualizes the clusters by computing a hierarchy
                 of implicit surfaces. We believe that HBLOB is
                 especially suited for the visualization of very large
                 datasets and for visual decision making in information
                 visualization. The versatility of the algorithm is
                 demonstrated using examples from visual data mining.",
  organization = "IEEE Compuer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Clustering, categorization, partitioning, information
                 visualization, non-linear dimensionality reduction,
                 physics-based graph layout, cluster visualization,
                 multidimensional information visualization.",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-194,
  pages =        "227--234",
  year =         "2000",
  title =        "Texturing Techniques for Terrain Visualization",
  author =       "J{\"u}rgen D{\"o}llner and Konstantin Baumann and
                 Klaus Hinrichs",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-194",
  abstract =     "We present a new rendering technique for processing
                 multiple multiresolution textures of LOD terrain models
                 and describe its application to interactive, animated
                 terrain content design. The approach is based on a
                 multiresolution model for terrain texture which
                 cooperates with a multiresolution model for terrain
                 geometry. For each texture layer, an image pyramid and
                 a texture tree are constructed. Multiple texture layers
                 can be associated with one terrain model and can be
                 combined in different ways, e.g., by blending and
                 masking. The rendering algorithm traverses
                 simultaneously the geometry multiresolution model and
                 the texture multiresolution model, and takes into
                 account geometric and texture approximation errors. It
                 uses multi-pass rendering and exploits multitexturing
                 to achieve real-time performance. Applications include
                 interactive texture lenses, texture animation, and
                 topographic textures. These techniques offer an
                 enormous potential for developing new visualization
                 applications for presenting, exploring and manipulating
                 spatio-temporal data.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-195,
  pages =        "211--218",
  year =         "2000",
  title =        "Two-level volume rendering - fusing {MIP} and {DVR}",
  author =       "Helwig Hauser and Lukas Mroz and Gian-Italo Bischi and
                 M. Eduard Gr{\"o}ller",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-195",
  abstract =     "In this paper we present a two-level approach for
                 fusing direct volume rendering (DVR) and
                 maximum-intensity projection (MIP) within a joint
                 rendering method. Different structures within the
                 data-set are rendered locally by either MIP or DVR on
                 an object by-object basis. Globally all the results of
                 subsequent object renderings are combined in a merging
                 step (usually compositing in our case). This allows to
                 selectively choose the most suitable technique for
                 depicting each object within the data, while keeping
                 the amount of information contained in the image at a
                 reasonable level. This is especially useful when inner
                 structures should be visualized together with
                 semi-transparent outer parts, similar to the
                 focus-and-context approach known from information
                 visualization. We also present an implementation of our
                 approach, which allows to explore volumetric data using
                 two-level rendering at interactive frame rates.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Visualization, volume rendering, dynamical systems,
                 medical applications",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-196,
  pages =        "147--154",
  year =         "2000",
  title =        "A Level-Set Method for Flow Visualization",
  author =       "R{\"u}diger Westermann and Christopher Johnson and
                 Thomas Ertl",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-196",
  abstract =     "In this paper we propose a technique for visualizing
                 steady flow. Using this technique, we first convert the
                 vector field data into a scalar level-set
                 representation. We then analyze the dynamic behavior
                 and subsequent distortion of level-sets and
                 interactively monitor the evolving structures by means
                 of texture-based surface rendering. Next, we combine
                 geometrical and topological considerations to derive a
                 multiscale representation and to implement a method for
                 the automatic placement of a sparse set of graphical
                 primitives depicting homogeneous streams in the fields.
                 Using the resulting algorithms, we have built a
                 visualization system that enables us to effectively
                 display the flow direction and its dynamics even for
                 dense 3D fields.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Flow Visualization, Level-Sets, Feature Extraction,
                 Multiscale Representation, Texture Mapping",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-197,
  pages =        "109--116",
  year =         "2000",
  title =        "Hardware-Accelerated Volume And Isosurface Rendering
                 Based on Cell-Projection",
  author =       "Stefan R{\"o}ttger and Martin Kraus and Thomas Ertl",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-197",
  abstract =     "We present two beneficial rendering extensions to the
                 Projected Tetrahedra (PT) algorithm by Shirley and
                 Tuchman. These extensions are compatible with any cell
                 sorting technique, for example the BSP-XMPVO sorting
                 algorithm for unstructured meshes. Using 3D texture
                 mapping our first extension solves the long-standing
                 problem of hardware-accelerated but accurate rendering
                 of tetrahedral volume cells with arbitrary transfer
                 functions. By employing 2D texture mapping our second
                 extension realizes the hardware-accelerated rendering
                 of multiple shaded isosurfaces within the PT algorithm
                 without reconstructing the isosurfaces. Additionally,
                 two methods are presented to combine projected
                 tetrahedral volumes with isosurfaces. The time
                 complexity of all our algorithms is linear in the
                 number of tetrahedra and does neither depend on the
                 number of isosurfaces nor on the employed transfer
                 functions.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Volume Rendering, Isosurfaces, Unstructured Meshes,
                 Cell Projection, Graphics Hardware, Texture Mapping,
                 Compositing.",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-198,
  pages =        "275--282",
  year =         "2000",
  title =        "Semi-Regular Mesh Extraction from Volumes",
  author =       "Zo{\"e} J. Wood and Mathieu Desbrun and Peter
                 Schr{\"o}der and David Breen",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-198",
  abstract =     "We present a novel method to extract iso-surfaces from
                 distance volumes. It generates high quality
                 semi-regular multiresolution meshes of arbitrary
                 topology. Our technique proceeds in two stages. First,
                 a very coarse mesh with guaranteed topology is
                 extracted. Subsequently an iterative multi-scale
                 force-based solver refines the initial mesh into a
                 semi-regular mesh with geometrically adaptive sampling
                 rate and good aspect ratio triangles. The coarse mesh
                 extraction is performed using a new approach we call
                 surface wavefront propagation. A set of discrete
                 iso-distance ribbons are rapidly built and connected
                 while respecting the topology of the iso-surface
                 implied by the data. Subsequent multi-scale refinement
                 is driven by a simple force-based solver designed to
                 combine good iso-surface fit and high quality sampling
                 through reparameterization. In contrast to the Marching
                 Cubes technique our output meshes adapt gracefully to
                 the iso-surface geometry, have a natural
                 multiresolution structure and good aspect ratio
                 triangles, as demonstrated with a number of examples.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Semi-regular meshes, subdivision, volumes, surface
                 extraction, implicit functions, level set methods",
  booktitle =    "Proceedings Visualization 2000",
}

@InCollection{EVL-2000-199,
  pages =        "1--7",
  year =         "2000",
  title =        "Focusing in Algorithm Explanation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-199",
  author =       "B. Braune and R. Wilhelm",
  abstract =     "Algorithm Animation attempts to explain an algorithm
                 by visualizing interesting events of the execution of
                 the implemented algorithm on some sample input.
                 Algorithm Explanation describes the algorithm on some
                 adequate level of abstraction, states invariants,
                 explains how important steps of the algorithm preserve
                 the invariants, and abstracts from the input data up to
                 the relevant properties. It uses a small focus onto the
                 execution state. This paper is concerned with the
                 explanation of algorithms on linked data structures.
                 The thesis of the paper is that shape analysis of such
                 algorithms produces abstract representations of such
                 data structures, which focus on the {"}active{"} parts,
                 i.e., the parts of the data structures, which the
                 algorithm can access during it's next steps. The paper
                 presents a concept of visually executing an algorithm
                 on these abstract representations of data.",
  editor =       "Hans Hagen",
  keywords =     "Visualization of algorithms, shape analysis,
                 diagrammatic reasoning.",
  volume =       "6 (1)",
  booktitle =    "IEEE Transactions on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@Article{EVL-2000-2,
  pages =        "43--67",
  year =         "2000",
  title =        "Fractional splines and wavelets",
  author =       "M. Unser and T. Blu",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-2",
  abstract =     "We extend Schoenberg's family of polynomial splines
                 with uniform knots to all fractional degrees $\alpha >
                 -1$. These splines, which involve linear combinations
                 of the one-sided power functions $x_+^{\alpha} =
                 max(0,x)^\alpha$, belong to L1 and are
                 $\alpha$-H{\"o}lder continuous for $\alpha > 0$. We
                 construct the corresponding B-splines by taking
                 fractional finite differences and provide an explicit
                 characterization in both time and frequency domains. We
                 show that these functions satisfy most of the
                 properties of the traditional B-splines, including the
                 convolution property, and a generalized fractional
                 differentiation rule that involves finite differences
                 only. We characterize the decay of the B-splines which
                 are not compactly supported for non-integral
                 $\alpha$'s. Their most astonishing feature (in
                 reference to the Strang-Fix theory) is that they have a
                 fractional order of approximation $\alpha + 1$ while
                 they reproduce the polynomials of degree $[\alpha]$.
                 For $\alpha > 1/2$, they satisfy all the requirements
                 for a multiresolution analysis of L2 (Riesz bounds, two
                 scale relation) and may therefore be used to build new
                 families of wavelet bases with a continuously-varying
                 order parameter. Our construction also yields
                 symmetrized fractional B-splines which provide the
                 connection with Duchon's general theory of radial
                 (m,s)-splines (including thin-plate splines). In
                 particular, we show that the symmetric version of our
                 splines can be obtained as solution of a variational
                 problem involving the norm of a fractional
                 derivative.",
  volume =       "42",
  number =       "1",
  journal =      "SIAM Review",
}

@InProceedings{EVL-2000-20,
  pages =        "76--84",
  year =         "2000",
  title =        "Influence of data set splitting method on similarity
                 indexing performance",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-20",
  author =       "X. Bai and G. Xu and Y. Shi and S. Yang",
  organization = "SPIE",
  month =        jan,
  editor =       "M. M. Yeung and B.-L. Yeo and C. A. Bouman",
  volume =       "3972",
  booktitle =    "Proceedings of SPIE: Storage and Retrieval for Media
                 Databases 2000",
}

@InCollection{EVL-2000-200,
  pages =        "8--23",
  year =         "2000",
  title =        "A Functional Framework for Web-Based Information
                 Visualization Systems",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-200",
  author =       "M. Bender and R. Klein and A. Disch and A. Ebert",
  abstract =     "The accelerating evolution in information
                 visualization research in the last few years led to
                 several specific system implementations. The obvious
                 drawbacks of this development are highly dependent
                 software systems, which are only available for a
                 restricted number of users. Today, due to the
                 remarkable advances in hardware and software
                 technologies, not only very expensive graphics
                 workstations, but also low-cost PCs are capable of
                 running computational demanding visualization systems.
                 Furthermore, the rapid development of the medium World
                 Wide Web coming along with state-of-the-art internet
                 programming techniques led to a trend toward more
                 generally usable visualization systems. In this paper,
                 we propose a functional developer's framework for
                 general Web- based visualization systems which makes
                 intelligent use of application specific software and
                 hardware components on the server side, as well as of
                 Java's benefits on the client side. To demonstrate the
                 framework's abilities, we have applied it to two
                 practical visualization tasks and we will report on our
                 experience concerning practicability and pitfalls.",
  editor =       "Hans Hagen",
  keywords =     "Visualization system, World Wide Web, distributed
                 computing, molecular visualization, simulation
                 analysis.",
  volume =       "6 (1)",
  booktitle =    "IEEE Transactions on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2000-201,
  pages =        "24--43",
  year =         "2000",
  title =        "Graph Visualization and Navigation in Information
                 Visualization: {A} Survey",
  author =       "Herman and G. Melan{\c{c}}on and M. S. Marshall",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-201",
  abstract =     "This is a survey on graph visualization and navigation
                 techniques, as used in information visualization.
                 Graphs appear in numerous applications such as web
                 browsing, state-transition diagrams, and data
                 structures. The ability to visualize and to navigate in
                 these potentially large, abstract graphs is often a
                 crucial part of an application. Information
                 visualization has specific requirements, which means
                 that this survey approaches the results of traditional
                 graph drawing from a different perspective.",
  editor =       "Hans Hagen",
  volume =       "6 (1)",
  keywords =     "Information visualization, graph visualization, graph
                 drawing, navigation, focus+context, fish-eye,
                 clustering.",
  booktitle =    "IEEE Transactions on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2000-202,
  pages =        "44--58",
  year =         "2000",
  title =        "Visual Discovery and Analysis",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-202",
  author =       "S. G. Eick",
  abstract =     "We have developed a flexible software environment
                 called ADVIZOR for visual information discovery.
                 ADVIZOR complements existing assumptive-based analyses
                 by providing a discovery-based approach. ADVIZOR
                 consists of five parts: a rich set of flexible visual
                 components, strategies for arranging the components for
                 particular analyses, an in-memory data pool, data
                 manipulation components, and container applications.
                 Working together, ADVIZOR's architecture provides a
                 powerful production platform for creating innovative
                 visual query and analysis applications.",
  editor =       "Hans Hagen",
  keywords =     "Information visualization, data analysis, visual
                 design patterns, perspectives, linked views.",
  volume =       "6 (1)",
  booktitle =    "IEEE Transactions on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2000-203,
  pages =        "59--78",
  year =         "2000",
  title =        "Designing Pixel-Oriented Visualization Techniques:
                 Theory and Applications",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-203",
  author =       "D. A. Keim",
  abstract =     "Visualization techniques are of increasing importance
                 in exploring and analyzing large amounts of
                 multidimensional information. One important class of
                 visualization techniques which is particularly
                 interesting for visualizing very large multidimensional
                 data sets is the class of pixel-oriented techniques.
                 The basic idea of pixel-oriented visualization
                 techniques is to represent as many data objects as
                 possible on the screen at the same time by mapping each
                 data value to a pixel of the screen and arranging the
                 pixels adequately. A number of different pixel-oriented
                 visualization techniques have been proposed in recent
                 years and it has been shown that the techniques are
                 useful for visual data exploration in a number of
                 different application contexts. In this paper, we
                 discuss a number of issues which are of high importance
                 in developing pixel-oriented visualization techniques.
                 The major goal of this article is to provide a formal
                 basis of pixel-oriented visualization techniques and
                 show that the design decisions in developing them can
                 be seen as solutions of well-defined optimization
                 problems. This is true for the mapping of the data
                 values to colors, the arrangement of pixels inside the
                 subwindows, the shape of the subwindows, and the
                 ordering of the dimension subwindows. The paper also
                 discusses the design issues of special variants of
                 pixel-oriented techniques for visualizing large spatial
                 data sets. The optimization functions for the mentioned
                 design decisions are important for the effectiveness of
                 the resulting visualizations. We show this by
                 evaluating the optimization functions and comparing the
                 results to the visualizations obtained in a number of
                 different application.",
  editor =       "Hans Hagen",
  keywords =     "Information visualization, visualizing large data
                 sets, visualizing multidimensional and multivariate
                 data, visual data exploration, visual data mining.",
  volume =       "6 (1)",
  booktitle =    "IEEE Transactions on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2000-204,
  pages =        "79--93",
  year =         "2000",
  title =        "Compressed Progressive Meshes",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-204",
  author =       "R. Pajarola and J. Rossignac",
  abstract =     "Most systems that support visual interaction with 3D
                 models use shape representations based on triangle
                 meshes. The size of these representations imposes
                 limits on applications for which complex 3D models must
                 be accessed remotely. Techniques for simplifying and
                 compressing 3D models reduce the transmission time.
                 Multiresolution formats provide quick access to a crude
                 model and then refine it progressively. Unfortunately,
                 compared to the best nonprogressive compression
                 methods, previously proposed progressive refinement
                 techniques impose a significant overhead when the full
                 resolution model must be downloaded. The CPM
                 (Compressed Progressive Meshes) approach proposed here
                 eliminates this overhead. It uses a new technique,
                 which refines the topology of the mesh in batches,
                 which each increase the number of vertices by up to 50
                 percent. Less than an amortized total of 4 bits per
                 triangle encode where and how the topological
                 refinements should be applied. We estimate the position
                 of new vertices from the positions of their topological
                 neighbors in the less refined mesh using a new
                 estimator that leads to representations of vertex
                 coordinates that are 50 percent more compact than
                 previously reported progressive geometry compression
                 techniques",
  editor =       "Hans Hagen",
  keywords =     "Triangle mesh compression, geometry compression,
                 progressive meshes, multiresolution modeling.",
  volume =       "6 (1)",
  booktitle =    "IEEE Transactions on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2000-205,
  pages =        "97--107",
  year =         "2000",
  title =        "Accelerated Isosurface Extraction in Time-Varying
                 Fields",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-205",
  author =       "P. M. Sutton and C. D. Hansen",
  abstract =     "For large time-varying data sets, memory and disk
                 limitations can lower the performace of visualization
                 applications. Algorithms and data structures must be
                 explicitly designed to handle these data sets in order
                 to achieve more interactive rates. The Temporal
                 Branch-on-Need Octree (T-BON) extends the
                 three-dimensional branch-on-need octree for
                 time-varying isosurface extraction. This data structure
                 minimizes the impact of the I/O bottleneck by reading
                 from disk only those portions of the search structure
                 and data necessary to construct the current isosurface.
                 By performing a minimum of I/O and exploiting the
                 hierarchical memory found in modern CPUs, the T-BON
                 algorithm achieves high performance isosurface
                 extraction in time-varying fields. This paper extends
                 earlier work on the T-BON data structure by including
                 techniques for better memory utilization, out-of-core
                 isosurface extraction, and support for nonrectilinear
                 grids. Results from testing the T-BON algorithm on
                 large data sets show that its performance is similar to
                 that of the three-dimensional branch-on-need octree for
                 static data sets while providing substantial advantages
                 for time- varying fields.",
  editor =       "Hans Hagen and David S. Ebert",
  keywords =     "Isosurface, time-dependent scalar field visualization,
                 multiresolution methods, octree, bricking, unstructured
                 grid visualization, out-of-core visualization.",
  volume =       "6 (2)",
  booktitle =    "IEEE Transactions on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2000-206,
  pages =        "108--123",
  year =         "2000",
  title =        "The Prioritized-Layered Projection Algorithm for
                 Visible Set Estimation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-206",
  author =       "J. T. Klosowski and C. T. Silva",
  abstract =     "Prioritized-Layered Projection (PLP) is a technique
                 for fast rendering of high depth complexity scenes. It
                 works by estimating the visible polygons of a scene
                 from a given viewpoint incrementally, one primitive at
                 a time. It is not a conservative technique, instead PLP
                 is suitable for the computation of partially correct
                 images for use as part of time-critical rendering
                 systems. From a very high level, PLP amounts to a
                 modification of a simple view-frustum culling
                 algorithm, however, it requires the computation of a
                 special occupancy-based tessellation and the assignment
                 to each cell of the tessellation a solidity value,
                 which is used to compute a special ordering on how
                 primitives get projected. In this paper, we detail the
                 PLP algorithm, its main components, and implementation.
                 We also provide experimental evidence of its
                 performance, including results on two types of spatial
                 tessellation (using octree- and Delaunay-based
                 tessellations), and several datasets. We also discuss
                 several extensions of our technique.",
  editor =       "Hans Hagen and David S. Ebert",
  keywords =     "Visibility, time-critical rendering, occlusion
                 culling, visible set, spatial tessellation",
  volume =       "6 (2)",
  booktitle =    "IEEE Transactions on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2000-207,
  pages =        "124--138",
  year =         "2000",
  title =        "Strategies for Direct Volume Rendering of Diffusion
                 Tensor Fields",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-207",
  author =       "G. Kindlmann and D. Weinstein and D. Hart",
  abstract =     "Diffusion-weighted magnetic resonance imaging is a
                 relatively new modality capable of elucidating the
                 fibrous structure of certain types of tissue, such as
                 the white matter within the brain. One tool for
                 interpreting this data is volume rendering because it
                 permits the visualization of three dimensional
                 structure without a prior segmentation process. In
                 order to use volume rendering, however, we must develop
                 methods for assigning opacity and color to the data,
                 and create a method to shade the data to improve the
                 legibility of the rendering. Previous work introduced
                 three such methods: barycentric opacity maps, hue-balls
                 (for color), and lit-tensors (for shading). The current
                 paper expands on and generalizes these methods,
                 describing and demonstrating further means of
                 generating opacity, color, and shading from the tensor
                 information. We also propose anisotropic
                 reaction-diffusion volume textures as an additional
                 tool for visualizing the structure of diffusion data.
                 The patterns generated by this process can be
                 visualized on their own or they can be used to
                 supplement the volume rendering strategies described in
                 the rest of the paper. Finally, because interpolation
                 between data points is a fundamental issue in volume
                 rendering, we conclude with a discussion and evaluation
                 of three distinct interpolation methods suitable for
                 diffusion tensor MRI data",
  editor =       "Hans Hagen and David S. Ebert",
  keywords =     "Volume rendering, diffusion tensor, tensor
                 visualization, barycentric coordinates, anisotropy,
                 transfer function, reaction-diffusion texture, tensor
                 interpolation.",
  volume =       "6 (2)",
  booktitle =    "IEEE Transactions on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2000-208,
  pages =        "139--149",
  year =         "2000",
  title =        "Anisotropic Diffusion in Vector Field Visualization on
                 Euclidean Domains and Surfaces",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-208",
  author =       "U. Diewald and T. Preu{\ss{}}er and M. Rumpf",
  abstract =     "Vector field visualization is an important topic in
                 scientific visualization. Its aim is to graphically
                 represent field data on two and three-dimensional
                 domains and on surfaces in an intuitively
                 understandable way. Here, a new approach based on
                 anisotropic nonlinear diffusion is introduced. It
                 enables an easy perception of vector field data and
                 serves as an appropriate scale space method for the
                 visualization of complicated flow pattern. The approach
                 is closely related to nonlinear diffusion methods in
                 image analysis where images are smoothed while still
                 retaining and enhancing edges. Here, an initial noisy
                 image intensity is smoothed along integral lines,
                 whereas the image is sharpened in the orthogonal
                 direction. The method is based on a continuous model
                 and requires the solution of a parabolic PDE problem.
                 It is discretized only in the final implementational
                 step. Therefore, many important qualitative aspects can
                 already be discussed on a continuous level.
                 Applications are shown for flow fields in 2D and 3D, as
                 well as for principal directions of curvature on
                 general triangulated surfaces. Furthermore, the
                 provisions for flow segmentation are outlined.",
  editor =       "Hans Hagen and David S. Ebert",
  keywords =     "Flow visualization, multiscale, nonlinear diffusion,
                 segmentation.",
  volume =       "6 (2)",
  booktitle =    "IEEE Transactions on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2000-209,
  pages =        "150--159",
  year =         "2000",
  title =        "Structure-Based Brushes: {A} Mechanism for Navigating
                 Hierarchically Organized Data and Information Spaces",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-209",
  author =       "Y.-H. Fua and M. O. Ward and E. A. Rundensteiner",
  abstract =     "Interactive selection is a critical component in
                 exploratory visualization, allowing users to isolate
                 subsets of the displayed information for highlighting,
                 deleting, analysis, or focused investigation. Brushing,
                 a popular method for implementing the selection
                 process, has traditionally been performed in either
                 screen space or data space. In this paper, we introduce
                 an alternate, and potentially powerful, mode of
                 selection that we term structure-based brushing, for
                 selection in data sets with natural or imposed
                 structure. Our initial implementation has focused on
                 hierarchically structured data, specifically very large
                 multivariate data sets structured via hierarchical
                 clustering and partitioning algorithms. The
                 structure-based brush allows users to navigate
                 hierarchies by specifying focal extents and
                 level-of-detail on a visual representation of the
                 structure. Proximity-based coloring, which maps similar
                 colors to data that are closely related within the
                 structure, helps convey both structural relationships
                 and anomalies. We describe the design and
                 implementation of our structure-based brushing tool. We
                 also validate its usefulness using two distinct
                 hierarchical visualization techniques, namely
                 hierarchical parallel coordinates and tree-maps.
                 Finally, we discuss relationships between different
                 classes of brushes and identify methods by which
                 structure-based brushing could be extended to alternate
                 data structures.",
  editor =       "Hans Hagen and David S. Ebert",
  keywords =     "Brushing, hierarchical representation, interactive
                 selection, exploratory data analysis.",
  volume =       "6 (2)",
  booktitle =    "IEEE Transactions on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InProceedings{EVL-2000-21,
  pages =        "106--118",
  year =         "2000",
  title =        "Distance preservation in color image transforms",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-21",
  author =       "S. Santini",
  organization = "SPIE",
  month =        jan,
  editor =       "M. M. Yeung and B.-L. Yeo and C. A. Bouman",
  volume =       "3972",
  booktitle =    "Proceedings of SPIE: Storage and Retrieval for Media
                 Databases 2000",
}

@InCollection{EVL-2000-210,
  pages =        "160--180",
  year =         "2000",
  title =        "Tissue Classification Based on 3{D} Local Intensity
                 Structures for Volume Rendering",
  author =       "Y. Sato and C.-F. Westin and A. Bhalerao and S.
                 Nakajima and N. Shiraga and S. Tamura and R. Kikinis",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-210",
  abstract =     "This paper describes a novel approach to tissue
                 classification using three-dimensional (3D) derivative
                 features in the volume rendering pipeline. In
                 conventional tissue classification for a scalar volume,
                 tissues of interest are characterized by an opacity
                 transfer function defined as a one-dimensional (1D)
                 function of the original volume intensity. To overcome
                 the limitations inherent in conventional 1D opacity
                 functions, we propose a tissue classification method
                 that employs a multidimensional opacity function, which
                 is a function of the 3D derivative features calculated
                 from a scalar volume as well as the volume intensity.
                 Tissues of interest are characterized by explicitly
                 defined classification rules based on 3D filter
                 responses highlighting local structures, such as edge,
                 sheet, line, and blob, which typically correspond to
                 tissue boundaries, cortices, vessels, and nodules,
                 respectively, in medical volume data. The 3D local
                 structure filters are formulated using the gradient
                 vector and Hessian matrix of the volume intensity
                 function combined with isotropic Gaussian blurring.
                 These filter responses and the original intensity
                 define a multidimensional feature space in which
                 multichannel tissue classification strategies are
                 designed. The usefulness of the proposed method is
                 demonstrated by comparisons with conventional
                 single-channel classification using both synthesized
                 data and clinical data acquired with CT (computed
                 tomography) and MRI (magnetic resonance imaging)
                 scanners. The improvement in image quality obtained
                 using multichannel classification is confirmed by
                 evaluating the contrast and contrast-to-noise ratio in
                 the resultant volume-rendered images with variable
                 opacity values",
  editor =       "Hans Hagen",
  volume =       "6 (2)",
  keywords =     "Volume visualization, image enhancement, medical
                 image, 3D derivative feature, multiscale analysis,
                 multidimensional opacity function, multichannel
                 classification, partial volume effect.",
  booktitle =    "IEEE Transactions on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2000-211,
  pages =        "181--189",
  year =         "2000",
  title =        "Conformal Surface Parameterization for Texture
                 Mapping",
  author =       "S. Haker and S. Angenent and A. Tannenbaum and R.
                 Kikinis and G. Sapiro and M. Halle",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-211",
  abstract =     "In this paper, we give an explicit method for mapping
                 any simply connected surface onto the sphere in a
                 manner which preserves angles. This technique relies on
                 certain conformal mappings from differential geometry.
                 Our method provides a new way to automatically assign
                 texture coordinates to complex undulating surfaces. We
                 demonstrate a finite element method that can be used to
                 apply our mapping technique to a triangulated geometric
                 description of a surface.",
  editor =       "Hans Hagen",
  volume =       "6 (2)",
  keywords =     "Texture mapping, surface parametrization, conformal
                 geometry, finite elements, partial differential
                 equations.",
  booktitle =    "IEEE Transactions on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2000-212,
  pages =        "196--207",
  year =         "2000",
  title =        "Spectral Volume Rendering",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-212",
  author =       "H. J. Noordmans and H. T. M. van der Voort and and A.
                 W. M. Smeulders",
  abstract =     "Volume renderers for interactive analysis must be
                 sufficiently versatile to render a broad range of
                 volume images: unsegmented {"}raw{"} images as recorded
                 by a 3D scanner, labeled segmented images,
                 multimodality images, or any combination of these. The
                 usual strategy is to assign to each voxel a three
                 component RGB color and an opacity value a. This
                 so-called RGBa approach offers the possibility of
                 distinguishing volume objects by color. However, these
                 colors are connected to the objects themselves, thereby
                 bypassing the idea that in reality the color of an
                 object is also determined by the light source and light
                 detectors c.q. human eyes. The physically realistic
                 approach presented here models light interacting with
                 the materials inside a voxel causing spectral changes
                 in the light. The radiated spectrum falls upon a set of
                 RGB detectors. The spectral approach is investigated to
                 see whether it could enhance the visualization of
                 volume data and interactive tools. For that purpose, a
                 material is split into an absorbing part (the medium)
                 and a scattering part (small particles). The medium is
                 considered to be either achromatic or chromatic, while
                 the particles are considered to scatter the light
                 achromatically, elastically, or inelastically. It
                 appears that inelastic scattering particles combined
                 with an achromatic absorbing medium offer additional
                 visual features: Objects are made visible through the
                 surface structure of a surrounding volume object and
                 volume and surface structures can be made visible at
                 the same time. With one or two materials the method is
                 faster than the RGBa approach, with three materials the
                 performance is equal. The spectral approach can be
                 considered as an extension of the RGBa approach with a
                 greater visual flexibility and a better balance between
                 quality and speed.",
  editor =       "Hans Hagen",
  keywords =     "Volume rendering, light/matter interaction, light
                 spectra, physical realism, visual cues.",
  volume =       "6 (3)",
  booktitle =    "IEEE Transactions on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2000-213,
  pages =        "208--219",
  year =         "2000",
  title =        "Accessibility Analysis Using Computer Graphics
                 Hardware",
  author =       "S. N. Spitz and A. A. G. Requicha",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-213",
  abstract =     "Analyzing the accessibility of an object's surface to
                 probes or tools is important for many planning and
                 programming tasks that involve spatial reasoning and
                 arise in robotics and automation. This paper presents
                 novel and efficient algorithms for computing accessible
                 directions for tactile probes used in 3D digitization
                 with Coordinate Measuring Machines. The algorithms are
                 executed in standard computer graphics hardware. They
                 are a nonobvious application of rendering hardware to
                 scientific and technological areas beyond computer
                 graphics.",
  editor =       "Hans Hagen",
  volume =       "6 (3)",
  keywords =     "Accessibility analysis, dimensional inspection
                 planning, coordinate measuring machines, direction
                 cones, configuration space, spatial reasoning, CAD/CAM,
                 rasterizing computer graphics hardware, visibility,
                 visual inspection.",
  booktitle =    "IEEE Transactions on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2000-214,
  pages =        "220--235",
  year =         "2000",
  title =        "A Perceptually-Driven Parallel Algorithm for Efficient
                 Radiosity Simulation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-214",
  author =       "S. Gibson and R. J. Hubbold",
  abstract =     "We describe a novel algorithm for computing
                 view-independent finite-element radiosity solutions on
                 distributed shared-memory parallel architectures. Our
                 approach is based on the notion of a subiteration being
                 the transfer of energy from a single source to a subset
                 of the scene's receiver patches. By using an efficient
                 queue-based scheduling system to process these
                 subiterations, we show how radiosity solutions can be
                 generated without the need for processor
                 synchronization between iterations of the progressive
                 refinement algorithm. The only significant source of
                 interprocessor communication required by our method is
                 for visibility calculations. We also describe a
                 perceptually-driven approach to visibility estimation,
                 which employs an efficient volumetric grid structure
                 and attempts to reduce the amount of interprocessor
                 communication by approximating visibility queries
                 between distant patches. Our algorithm also eliminates
                 the need for dynamic load-balancing until the end of
                 the solution process and is shown to achieve a
                 super-linear speedup in many situations.",
  editor =       "Hans Hagen",
  keywords =     "Radiosity, progressive refinement, parallelism,
                 distributed shared memory, load balancing, tone
                 reproduction, visibility.",
  volume =       "6 (3)",
  booktitle =    "IEEE Transactions on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2000-215,
  pages =        "236--252",
  year =         "2000",
  title =        "Fast Ray-Tracing of Rectilinear Volume Data Using
                 Distance Transforms",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-215",
  author =       "M. Sramek and A. Kaufman",
  abstract =     "This paper discusses and experimentally compares
                 distance-based acceleration algorithms for ray-tracing
                 of volumetric data with an emphasis on the Chessboard
                 Distance (CD) voxel traversal. The acceleration of this
                 class of algorithms is achieved by skipping empty macro
                 regions, which are defined for each background voxel of
                 the volume. Background voxels are labeled in a
                 preprocessing phase by a value, defining the macro
                 region size, which is equal to the voxel distance to
                 the nearest foreground voxel. The CD algorithm exploits
                 the chessboard distance and defines the ray as a
                 nonuniform sequence of samples positioned at voxel
                 faces. This feature assures that no foreground voxels
                 are missed during the scene traversal. Further, due to
                 parallelepipedal shape of the macro region, it supports
                 accelerated visualization of cubic, regular, and
                 rectilinear grids. The CD algorithm is suitable for all
                 modifications of the ray tracing/ray casting techniques
                 being used in volume visualization and volume graphics.
                 However, when used for rendering based on local surface
                 interpolation, it also enables fast search of
                 intersections between rays and the interpolated
                 surface, further improving speed of the process.",
  editor =       "Hans Hagen",
  keywords =     "Volume visualization, volume graphics, volume
                 rendering, distance transforms, macro region, voxel
                 traversal, speed up techniques, subvoxel precision.",
  volume =       "6 (3)",
  booktitle =    "IEEE Transactions on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2000-216,
  pages =        "253--264",
  year =         "2000",
  title =        "Perturbation Methods for Interactive Specular
                 Reflections",
  author =       "M. Chen and J. Arvo",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-216",
  abstract =     "We describe a new approach for interactively
                 approximating specular reflections in arbitrary curved
                 surfaces. The technique is applicable to any smooth
                 implicitly defined reflecting surface that is equipped
                 with a ray intersection procedure; it is also extremely
                 efficient as it employs local perturbations to
                 interpolate point samples analytically. After ray
                 tracing a sparse set of reflection paths with respect
                 to a given vantage point and static reflecting
                 surfaces, the algorithm rapidly approximates
                 reflections of arbitrary points in 3-space by
                 expressing them as perturbations of nearby points with
                 known reflections. The reflection of each new point is
                 approximated to second-order accuracy by applying a
                 closed-form perturbation formula to one or more nearby
                 reflection paths. This formula is derived from the
                 Taylor expansion of a reflection path and is based on
                 first and second-order path derivatives. After
                 preprocessing, the approach is fast enough to compute
                 reflections of tessellated diffuse objects in arbitrary
                 curved surfaces at interactive rates using standard
                 graphics hardware. The resulting images are nearly
                 indistinguishable from ray traced images that take
                 several orders of magnitude longer to generate.",
  editor =       "Hans Hagen",
  volume =       "6 (3)",
  keywords =     "Animation systems, illumination effects, implicit
                 surfaces, matting and compositing, optics, ray
                 tracing.",
  booktitle =    "IEEE Transactions on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2000-217,
  year =         "2000",
  title =        "Dynamic Modeling of Butterfly Subdivision Surfaces",
  author =       "C. Mandal and H. Qin and B. C. Vemuri",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-217",
  abstract =     "In this paper, we develop integrated techniques that
                 unify physics-based modeling with geometric subdivision
                 methodology and present a scheme for dynamic
                 manipulation of the smooth limit surface generated by
                 the (modified) butterfly scheme using physics-based
                 {"}force{"} tools. This procedure-based surface model
                 obtained through butterfly subdivision does not have a
                 closed-form analytic formulation (unlike other
                 well-known spline-based models) and, hence, poses
                 challenging problems to incorporate mass and damping
                 distributions, internal deformation energy, forces, and
                 other physical quantities required to develop a
                 physics-based model. Our primary contributions to
                 computer graphics and geometric modeling include: 1) a
                 new hierarchical formulation for locally parameterizing
                 the butterfly subdivision surface over its initial
                 control polyhedron, 2) formulation of dynamic butterfly
                 subdivision surface as a set of novel finite elements,
                 and 3) approximation of this new type of finite
                 elements by a collection of existing finite elements
                 subject to implicit geometric constraints. Our new
                 physics-based model can be sculpted directly by
                 applying synthesized forces and its equilibrium is
                 characterized by the minimum of a deformation energy
                 subject to the imposed constraints. We demonstrate that
                 this novel dynamic framework not only provides a direct
                 and natural means of manipulating geometric shapes, but
                 also facilitates hierarchical shape and nonrigid motion
                 estimation from large range and volumetric data sets
                 using very few degrees of freedom (control vertices
                 that define the initial polyhedron).",
  editor =       "Hans Hagen",
  volume =       "6 (3)",
  keywords =     "Dynamic modeling, physics-based geometric design,
                 geometric modeling, CAGD, subdivision surfaces,
                 deformable models, finite elements, interactive
                 techniques.",
  booktitle =    "IEEE Transactions on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InProceedings{EVL-2000-218,
  pages =        "1--26",
  year =         "2000",
  title =        "Shadow volume reconstruction from depth maps",
  author =       "Michael D. McCool",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-218",
  abstract =     "Current graphics hardware can be used to generate
                 shadows using either the shadow volume or shadow map
                 techniques. However, the shadow volume technique
                 requires access to a representation of the scence as a
                 polygonal model, and handling the near plane clip
                 correctly and efficiently is difficult; conversely,
                 accurate shadow maps require high-precision texture map
                 data representations, but these are not widely
                 supported. We present a hybird of the shadow map and
                 shadow volume approaches which does not have these
                 difficulties and leverages high-performance polygon
                 rendering. The scene is rendered from the point of view
                 of the light source and a sampled depth map is
                 recovered. Edge detection and a template-based
                 reconstruction technique are used to generate a global
                 shadow volume boundary surface, after which the pixels
                 in shadow can be marked using only a one-bit stencil
                 buffer and a single-pass rendering of the shadow volume
                 boundary polygons. The simple form of our
                 template-based reconstruction scheme simplifies capping
                 the shadow volume after the near plane clip.",
  volume =       "19 (1)",
  keywords =     "Hardware accelerated image synthesis, hardware
                 accelerated image synthesis, illumination, image
                 processing, shadows",
  booktitle =    "ACM Transactions on Graphics",
}

@InProceedings{EVL-2000-219,
  pages =        "27--55",
  year =         "2000",
  title =        "Applications of the polynomial s-power basis in
                 geometry processing",
  author =       "Javier S{\'{a}}nchez-Reyes",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-219",
  abstract =     "We propose a unified methodology to tackle geometry
                 processing operations admitting explicit algebraic
                 expressions. This new approach is based on representing
                 and manipulating polynomials algebraically in a
                 recently basis, the symmetric analogue of the power
                 form (s-power basis for brevity), so called because it
                 is associated with a {"}Hermite two-point expansion{"}
                 instead of a Taylor expansion. Given the expression of
                 a polynomial in this basis over the unit interval u
                 [epsilon][0, 1], degree reduction is trivially obtained
                 by truncation, which yields the He many terms as
                 desired of the corresponding Hermite interpolant and
                 build {"}s-power series,{"} akin to Taylor series.
                 Applications include computing integral approximations
                 of rational polynomials, or approximations of offset
                 curves.",
  volume =       "19 (1)",
  keywords =     "Hermite interpolation, Taylor series, degree
                 reduction, geometry processing, offset curves and
                 surfaces, power basis, s-power basis",
  booktitle =    "ACM Transactions on Graphics",
}

@InProceedings{EVL-2000-22,
  pages =        "190--198",
  year =         "2000",
  title =        "Commercial imagery archive product development",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-22",
  author =       "A. Sakkas",
  organization = "SPIE",
  month =        jan,
  editor =       "M. M. Yeung and B.-L. Yeo and C. A. Bouman",
  keywords =     "image database, image archive",
  volume =       "3972",
  booktitle =    "Proceedings of SPIE: Storage and Retrieval for Media
                 Databases 2000",
}

@InProceedings{EVL-2000-220,
  pages =        "56--77",
  year =         "2000",
  title =        "Estimating tessellation parameter intervals for
                 rational curves and surfaces",
  author =       "Jianmin Zheng and Thomas W. Sederberg",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-220",
  abstract =     "This paper presents a method for determining a priori
                 a constant parameter interval for tessellating a
                 rational curve or surface such that the deviation of
                 the curve or surface from its piecewise linear
                 approximation is within a specified tolerance. The
                 parameter interval is estimated based on information
                 about second-order derivatives in the homogeneous
                 coordinates, instead of using affine coordinates
                 directly. This new step size can be found with roughly
                 the same amount of computation as the step size in
                 Cheng [1992], though it can be proven to always be
                 larger than Cheng's step size. In fact, numerical
                 experiments show the new step is typically orders of
                 magnitude larger than the step size in Cheng [1992].
                 Furthermore, for rational cubic and quartic curves, the
                 new step size is generally twice as large as the step
                 size found by computing bounds on the Bernstein
                 polynomial coefficients of the second derivatives
                 function.",
  volume =       "19 (1)",
  keywords =     "Derivative bounds, flatness, projection distance,
                 rational curves and surfaces, step size, tessellation",
  booktitle =    "ACM Transactions on Graphics",
}

@InProceedings{EVL-2000-221,
  pages =        "79--121",
  year =         "2000",
  title =        "Navigating through triangle meshes implemented as
                 linear quadtrees",
  author =       "Michael Lee and Hanan Samet",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-221",
  abstract =     "Techniques are presented for navigating between
                 adjacent triangles of greater or equal size in a
                 hierarchical triangle mesh where the triangles are
                 obtained by a recursive quadtree-like subdivision of
                 the underlying space into four equilateral triangles.
                 These techniques are useful in a number of
                 applications, including finite element analysis, ray
                 tracing, and the modeling of spherical data. The
                 operations are implemented in a manner analogous to
                 that used in a quadtree representation of data on the
                 two-dimensional plane where the underlying space is
                 tessellated into a square mesh. A new technique is
                 described for labeling the triangles, which is useful
                 in implementing the quadtree triangle mesh as a linear
                 quadtree (i.e., a pointer-less quadtree); the
                 navigation can then take place in this linear quadtree.
                 When the neighbors are of equal size, the algorithms
                 have a worst-case constant time complexity. The
                 algorithms are very efficient, as they make use of just
                 a few bit manipulation operations, and can be
                 implemented in hardware using just a few machine
                 language instructions. The use of these techniques when
                 modeling spherical data by projecting it onto the faces
                 of a regular solid whose faces are equilateral
                 triangles, which are represented as quadtree triangle
                 meshes, is discussed in detail. The methods are
                 applicable to the icosahedron, octahedron, and
                 tetrahedron. The difference lies in the way transitions
                 are made between the faces of the polyhedron. However,
                 regardless of the type of polyhedron, the computational
                 complexity of the methods is the same.",
  volume =       "19 (2)",
  keywords =     "Data structures, finite element analysis, hierarchical
                 methods, neighbor finding, ray tracing, spherical
                 modeling, triangle meshes",
  booktitle =    "ACM Transactions on Graphics",
}

@InProceedings{EVL-2000-222,
  pages =        "122--161",
  year =         "2000",
  title =        "Using the visual differences predictor to improve
                 performance of progressive global illumination
                 computation",
  author =       "Valdimir Volevich and Karol Myszkowski and Andrei
                 Khodulev and Edward A. Kopylov",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-222",
  abstract =     "A novel view-independent technique for progressive
                 global illumination computing that uses prediction of
                 visible differences to improve both efficiency and
                 effectiveness of physically-sound lighting solutions
                 has been developed. The technique is a mixture of
                 stochastic (density estimation) and deterministic
                 (adaptive mesh refinement) algorithms used in a
                 sequence and optimized to reduce the differences
                 between the intermediate and final images as perceived
                 by the human observer in the course of lighting
                 computation. The quantitive measurements of visibility
                 were obtained using the model of human vision captured
                 in the visible differences predictor (VDP) developed by
                 Daly [1993]. The VDP responses were used to support the
                 selection of the best component algorithms from a pool
                 of global illumination solutions, and to enhance the
                 selected algorithms for even better progressive
                 refinement of image quality. The VDP was also used to
                 determine the optimal sequential order of
                 component-algorithm execution, and to choose the points
                 at which switchover between algorithms should take
                 place. As the VDP is computationally expensive, it was
                 applied exclusively at the design and tuning stage of
                 the composite technique, and so perceptual
                 considerations are embedded into the resulting
                 solution, though no VDP calculations were performed
                 during lighting simulation. The proposed illumination
                 technique is also novel, providing intermediate image
                 solutions of high quality at unprecedented speeds, even
                 for complex scenes. One advantage of the technique is
                 that local estimates of global illumination are readily
                 available at the early stages of computing, making
                 possible the development of a more robust adaptive mesh
                 subdivision, which is guided by local contrast
                 information. Efficient object space filtering, also
                 based on stochastically-derived estimates of the local
                 illumination error, is applied to substantially reduce
                 the visible noise inherent in stochastic solutions.",
  volume =       "19 (2)",
  keywords =     "Monte Carlo photon tracing, adaptive mesh subdivision,
                 density estimation, human perception, progressive
                 refinement, view-independent solutions",
  booktitle =    "ACM Transactions on Graphics",
}

@InProceedings{EVL-2000-223,
  pages =        "164--184",
  year =         "2000",
  title =        "Texture potential {MIP} mapping, a new high-quality
                 texture antialiasing algorithm",
  author =       "R. J. Cant and P. A. Shrubsole",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-223",
  abstract =     "A refined version of the texture potential mapping
                 algorithm is introduced in which a one-dimensional MIP
                 map is incorporated. This has the effect of controlling
                 the maximum number of texture samples required. The new
                 technique is compared to existing texture antialiasing
                 mehtods in terms of quality and sample count. The new
                 method is shown to compare favorably with existing
                 techniques for producing high quality antialiased,
                 texturemapped images.",
  volume =       "19 (3)",
  keywords =     "Anisotropic filtering, antialiasing, texture mapping",
  booktitle =    "ACM Transactions on Graphics",
}

@InProceedings{EVL-2000-224,
  pages =        "185--203",
  year =         "2000",
  title =        "Grouping and parameterizing irregularly spaced points
                 for curve fitting",
  author =       "A. Ardeshir Goshtasby",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-224",
  abstract =     "Given a large set irregularly spaced points in the
                 plane, an algorithm for partitioning the points into
                 subsets and fitting a parametric curve to each subset
                 is described. The points could be measurements from a
                 physical phenomenon, and the objective in this process
                 could be to find patterns among the points and describe
                 the phenomenon analytically. The points could be
                 measurements from a geometric curves. The algorithm
                 proposed here can be used in various applications,
                 especially where given points are dense and noisy.
                 Examples demonstrating the behavior of the algorithm
                 under noise and density of the points are presented and
                 discussed.",
  volume =       "19 (3)",
  keywords =     "Irregularly spaced points, node estimation, noisy
                 point set, parametric curve",
  booktitle =    "ACM Transactions on Graphics",
}

@InProceedings{EVL-2000-225,
  pages =        "204--241",
  year =         "2000",
  title =        "Image-driven simplification",
  author =       "Peter Lindstrom and Greg Turk",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-225",
  abstract =     "We introduce the notion of image-driven
                 simplification, a framework that uses images to decide
                 which portions of a model to simplify. This is a
                 departure from approaches that make polygonal
                 simplification decisions based on geometry. As with
                 many methods, we use the edge collapse operator to make
                 incremental changes to a model. Unique to our approach,
                 however, is the use at comparisons between images of
                 the original model against those of a simplified model
                 to determine the cost of an ease collapse. We use
                 common graphics rendering hardware to accelerate the
                 creation of the required images. As expected, this
                 method produces models that are close to the original
                 model according to image differences. Perhaps more
                 surprising, however, is that the method yields models
                 that have high geometric fidelity as well. Our approach
                 also solves the quandary of how to weight the geometric
                 distance versus appearance properties such as normals,
                 color, and texture. All of these trade-offs are
                 balanced by the image metric. Benefits of this approach
                 include high fidelity silhouettes, extreme
                 simplification of hidden portions of a model, attention
                 to shading interpolation effects, and simplification
                 that is sensitive to the content of a texture. In order
                 to better preserve the appearance of textured models,
                 we introduce a novel technique for assigning texture
                 coordinates to the new vertices of the mesh. This
                 method is based on a geometric heuristic that can be
                 integrated with any edge collapse algorithm to produce
                 high quality textured surfaces.",
  volume =       "19 (3)",
  keywords =     "Image metrics, level-of-detail, polygonal
                 simplification, visual perception",
  booktitle =    "ACM Transactions on Graphics",
}

@InProceedings{EVL-2000-226,
  pages =        "351--358",
  year =         "2000",
  title =        "A Continuous Clustering Method for Vector Fields",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-226",
  author =       "H. Garcke and T. Preu{\ss}er and M. Rumpf and A. Telea
                 and U. Weikard and J. van Wijk",
  abstract =     "A new method for the simplification of flow fields is
                 presented. It is based on continuous clustering. A
                 well-know physical clustering model, the Cahn Hillard
                 model which describes phase separation, is modified to
                 reflect the properties of the data to be visualized.
                 Clusters are defined implicitly as connected components
                 of the positivity set of a density function. An
                 evaluation equation for this function is obtained as a
                 suitable gradient flow of an underlying anisotropic
                 energy functional. Here, time serves as the scale
                 parameter. The evolution is characterized by a
                 successive coarsening of patterns - the actual
                 clustering - and meanwhile the underlying simulation
                 data specifies preferable pattern boundaries. Here we
                 discuss the applicability of this new type of approach
                 mainly for flow fields, where the cluster energy
                 penalizes cross streamline boundaries, but the method
                 also carries provisions in other fields as well. The
                 clusters are visualized via iconic representations. A
                 skeletonization algorithm is used to find suitable
                 positions for the icons.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-227,
  pages =        "433--436",
  year =         "2000",
  title =        "Fast Visualization for Comparing Dynamics: {A} Case
                 Study in Combustion",
  author =       "Kay A. Robbins and Michael Gorman",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-227",
  abstract =     "Visualization can be an important tool for displaying,
                 categorizing and digesting large quantities of
                 inter-related information during laboratory and
                 simulation experiments. Summary visualizations that
                 compare and represent data sets in the context of a
                 collection are particularly valuable. Applicable
                 visualizations used in these settings must be fast
                 (near real time) and should allow the addition of data
                 sets as they are acquired without requiring rerendering
                 of the visualization. This paper examines several
                 visualization techniques for representing collections
                 of data sets in a combustion experiment including
                 spectral displays, tiling and geometric mappings of
                 symmetry. The application provides insight into how
                 such visualizations might be used in practical
                 real-time settings to assist in exploration and in
                 conducting parameter space surveys.",
  organization = "IEEE Computer Society Technical Committe on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Realtime visualization, steering, symmetry, tiling,
                 pat-tern formation, movies.",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-228,
  pages =        "437--440",
  year =         "2000",
  title =        "Mastering Interactive Surface Rendering for Java-Based
                 Diagnostic Applications",
  author =       "Lukas Mroz and Rainer Wegenkitt and Eduard
                 Gr{\"o}ller",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-228",
  abstract =     "The display of iso-surfaces in medical data sets is an
                 important visualization technique used by radiologists
                 for the diagnosis of volumetric density data sets. The
                 demands put by radiologists on such a display technique
                 are interactivity, multiple stacked transparent
                 surfaces and cutting planes that allow an interactive
                 clipping of the surfaces. This paper presents a Java
                 based, platform independent implementation of a very
                 fast surface rendering algorithm which combines the
                 advantages of explicit surface representation,
                 splatting, and shear-warp projection to fulfill all
                 these requirements. The algorithm is implemented within
                 the context of J-Vision, an application for viewing and
                 diagnosing medical images which is currently in use at
                 various hospitals.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Volume visualization, surface rendering, medical
                 applications. tomographic data",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-229,
  pages =        "441--444",
  year =         "2000",
  title =        "A Computational Steering System for Studying Microwave
                 Interactions with Missile Bodies",
  author =       "J. Edward Swan II and Marco Lanzagorta and Doug
                 Maxwell and Eddy Kou and Jeff Uhlmann and Wendell
                 Anderson and Haw-Jye Shyu and William Smith",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-229",
  abstract =     "This paper describes a computer modeling and
                 simulation system that supports computational steering,
                 which is an effort to make the typical simulation
                 workflow more efficient. Our system provides an
                 interface that allows scientists to perform all of the
                 steps in the simulation process in parallel and online.
                 It uses a standard network flow visualization package,
                 which has been extended to display graphical output in
                 an immersive virtual environment such as a CAVE. Our
                 system allows scientists to interactively manipulate
                 simulation parameters and observe the results. It also
                 supports inverse steering, where the user specifies the
                 desired simulation result, and the system searches for
                 the simulation parameters that achieve this result.
                 Taken together, these capabilities allow scientists to
                 more efficiently and effectively understand model
                 behavior, as well as to search through simulation
                 parameter space.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Modeling and Simulation, Scientific
                 Visualization,Computational Steering, Inverse Steering,
                 Virtual Reality.",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-23,
  pages =        "245--252",
  year =         "2000",
  title =        "Image clustering using fuzzy graph theory",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-23",
  author =       "H. Jafarkhani and V. Tarokh",
  organization = "SPIE",
  month =        jan,
  editor =       "M. M. Yeung and B.-L. Yeo and C. A. Bouman",
  volume =       "3972",
  keywords =     "Image retrieval, data representation, image database",
  booktitle =    "Proceedings of SPIE: Storage and Retrieval for Media
                 Databases 2000",
}

@InProceedings{EVL-2000-230,
  pages =        "445--448",
  year =         "2000",
  title =        "Four-Dimensional Non-Linear Ray Tracing as a
                 Visualization Tool for Gravitational Physics",
  author =       "Daniel Weiskopf",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-230",
  abstract =     "In this paper, general relativistic ray tracing is
                 presented as a tool for gravitational physics. It is
                 shown how standard three-dimensional ray tracing can be
                 extended to allow for general relativistic
                 visualization. This visualization technique provides
                 images as seen by an observer under the influence of a
                 gravitational field and allows to probe spacetime by
                 null geodesics. Moreover, a technique is proposed for
                 visualizing the caustic surfaces generated by a
                 gravitational lens. The suitability of general
                 relativistic ray tracing is demonstrated by means of
                 two examples, namely the visualization of the rigidly
                 rotating disk of dust and the warp drive metric.",
  organization = "IEEE Computer Society Technical Committee on computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Differential geometry, four-dimensional spacetimes,
                 general relativity, ray tracing, scientific
                 visualization",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-231,
  pages =        "449--452",
  year =         "2000",
  title =        "Combining Local and Remote Visualization Techniques
                 for Interactive Volume Rendering in Medical
                 Applications",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-231",
  author =       "K. Engel and P. Hastreiter and B. Tomandl and K.
                 Eberhardt and T. Ertl",
  abstract =     "For a comprehensive understanding of tomographic image
                 data in medical routine, interactive and high--quality
                 direct volume rendering is an essential prerequisite.
                 This is provided by visualization using 3D texture
                 mapping which is still limited to high-end graphics
                 hardware. In order to make it available in a clinical
                 environment, we present a system which uniquely
                 combines local desktop computers and remote high-end
                 graphics hardware. In this context, we exploit the
                 standard visualization capabilities to a maximum which
                 are available in the clinical environment. For 3D
                 representations of high resolution and quality we
                 access the remote specialized hardware. Various tools
                 for 2D and 3D visualization are provided which meet the
                 requirements of a medical diagnosis. This is
                 demonstrated with examples from the field of
                 neuroradiology which show the value of our strategy in
                 practice.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-232,
  pages =        "453--456",
  year =         "2000",
  title =        "An Integrated Visualization And Design Toolkit For
                 Flexible Prosthetic Heart Valves",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-232",
  author =       "A. J. Fenlon and T. David",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-233,
  pages =        "457--460",
  year =         "2000",
  title =        "Immersive Virtual Reality for Visualizing Flow Through
                 an Artery",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-233",
  author =       "Andrew S. Forsberg and David H. Laidlaw and Andries
                 van Dam and Robert M. Kirkby and George E. Karniadakis
                 and Jonathan L. Elion",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-234,
  pages =        "461--464",
  year =         "2000",
  title =        "Mastering Interactive Virtual Bronchioscopy on a
                 Low-End {PC}",
  author =       "Rainer Wegenkitt and Anna Vilanova and Balint
                 Heged{\"{u}}s and Martin Wagner and Martin C. Freund
                 and Eduard M. Gr{\"{o}}ller",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-234",
  abstract =     "Virtual endoscopy presents the cross-sectional
                 acquired 3D-data of a computer tomograph as an
                 endoluminal view. The common approach for the
                 visualization of a virtual endoscopy is surface
                 rendering, yielding images close to a real endoscopy.
                 If external structures are of interest, volume
                 rendering techniques have to be used. These methods do
                 not display the exact shape of the inner lumen very
                 well. For certain applications, e.g. operation planning
                 of a trans-bronchial biopsy, both, the shape of the
                 inner lumen as well as outer structures like blood
                 vessels and the tumor have to be delineated. In this
                 paper a method is described, that allows a quick and
                 easy hybrid visualization using overlays of different
                 visualization methods like different surfaces or volume
                 renderings with different transfer functions in real
                 time on a low-end PC. To achieve real time frame rates,
                 image based rendering techniques have been used.",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  keywords =     "Medical visualization, virtual endoscopy,
                 visualization system.",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-235,
  pages =        "465--468",
  year =         "2000",
  title =        "Interactive Visualization of Protein Dynamics",
  author =       "Henk Huitema and Robert van Liere",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-235",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-236,
  pages =        "469--472",
  year =         "2000",
  title =        "Interactive Visualization of Particle-In-Cell
                 Simulations",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-236",
  author =       "Patric Ljung and Mark Dieckmann and Niclas Andersson
                 and Anders Ynnerman",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-237,
  pages =        "473--476",
  year =         "2000",
  title =        "Visualization of Time Dependent Confocal Microscopy
                 Data",
  author =       "Wim de Leeuw and Robert van Liere and Pernette
                 Verschure and Astrid Visser and Erik Manders and Roel
                 van Driel",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-237",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-238,
  pages =        "481--484",
  year =         "2000",
  title =        "A Methodology for Plume Visualization with Application
                 to Real-Time Acquisition and Navigation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-238",
  author =       "Karen G. Bemis and Deborah Silver and Peter A. Rona
                 and Chengwei Feng",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-239,
  pages =        "477--480",
  year =         "2000",
  title =        "Visual Data Fusion for Applications of High-Resolution
                 Numerical Wheather Prediction",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-239",
  author =       "Lloyd A. Treinish",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-24,
  pages =        "253--261",
  year =         "2000",
  title =        "Content-based image retrieval with scale-spaced object
                 trees",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-24",
  author =       "D. Dupplaw and P. H. Lewis",
  organization = "SPIE",
  month =        jan,
  editor =       "M. M. Yeung and B.-L. Yeo and C. A. Bouman",
  volume =       "3972",
  keywords =     "image retrieval, data representation, image database",
  booktitle =    "Proceedings of SPIE: Storage and Retrieval for Media
                 Databases 2000",
}

@InProceedings{EVL-2000-240,
  pages =        "485--488",
  year =         "2000",
  title =        "A Case Study of Visualizing Climate Modeling and
                 Simulation Data Sets",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-240",
  author =       "Pak Chung Wong and Harlan Foote and Ruby Leung and
                 Elizabeth Jurrus and Dan Adams and Jim Thomas",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-242,
  pages =        "489--492",
  year =         "2000",
  title =        "{WEAVE}: {A} System for Visually Linking 3-{D} and
                 Statistical Visualizations, Applied to Cardiac
                 Simulation and Measurement Data",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-242",
  author =       "D. L. Gresh and B. E. Rogowitz and R. L. Winslow and
                 D. F. Scollan and C. K. Yung",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-243,
  pages =        "493--496",
  year =         "2000",
  title =        "Visualizing High-Dimensional Predictive Model
                 Quality",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-243",
  author =       "Penny Rheingans and Marie desJardins",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-244,
  pages =        "497--500",
  year =         "2000",
  title =        "Visualizing Volume Data Using Physical Models",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-244",
  author =       "David R. Nadeau and Michael J. Bailey",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-245,
  pages =        "501--504",
  year =         "2000",
  title =        "Visualizing {DIII}-{D} Tokamek Magnetic Field Lines",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-245",
  author =       "Greg Schussman and Kwan-Liu Ma and David Schissel and
                 Todd Evans",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-246,
  pages =        "505--508",
  year =         "2000",
  title =        "Real-time Visualization of the Clear-up of a Former
                 {U}.{S}. Naval Base",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-246",
  author =       "Paul Chapman and Derek Wills and Peter Stevens and
                 Graham Brookes",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-247,
  pages =        "509--512",
  year =         "2000",
  title =        "Scientific Visualization of Water Quality in the
                 Chesapeake Bay",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-247",
  author =       "Robert Stein and Alan M. Shih and M. Pauline Baker",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-248,
  pages =        "513--516",
  year =         "2000",
  title =        "Multi-Resolution Visualization Techniques for Nested
                 Weather Models",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-248",
  author =       "Lloys A. Treinish",
  organization = "IEEE Computer Society Technical Committee on Computer
                 Graphics",
  editor =       "T. Ertl and B. Hamann and A. Varshney",
  booktitle =    "Proceedings Visualization 2000",
}

@InProceedings{EVL-2000-249,
  year =         "2000",
  title =        "Color-Table Animation of Fast Oriented Line Intgral
                 Convolution for Vector Field Visualization",
  author =       "Siegrun Berger and Eduard Gr{\"o}ller",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-249",
  abstract =     "Fast Oriented Line Integral Convolution (FROLIC),
                 which is a variant of LIC, illustrates 2D vector fields
                 by approximating a streamlet by a set of disks with
                 varying intensity. FROLIC does not only show the
                 direction of the flow but also its orientation. This
                 paper presents color-table animation of FROLIC images.
                 Various color-table compositions are discussed in
                 detail. When animating FROLIC images visual artifacts
                 (pulsation, synchronization) must be avoided. Several
                 strategies in this respect are dealt with. Color-table
                 animation of FROLIC has been implemented as a Visual
                 C++ application, whereby the calculation of the
                 dynamical system is performed with Mathematica. This
                 allows researchers from various disciplines to
                 conveniently explore and investigate analytically
                 defined 2D and 3D vector fields.",
  keywords =     "Oriented line integral convolution, color-table
                 animation.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-25,
  pages =        "262--270",
  year =         "2000",
  title =        "Indexing and searching structure for multimedia
                 database systems",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-25",
  author =       "S.-C. Chen",
  organization = "SPIE",
  month =        jan,
  editor =       "M. M. Yeung and B.-L. Yeo and C. A. Bouman",
  volume =       "3972",
  keywords =     "image retrieval, data representation, image database",
  booktitle =    "Proceedings of SPIE: Storage and Retrieval for Media
                 Databases 2000",
}

@InProceedings{EVL-2000-251,
  year =         "2000",
  title =        "Adaptive Visualization for Interactive Geometric
                 Modeling in Geoscience",
  author =       "Hong-Qian (Karen) Lu and Richard Hammersley",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-251",
  abstract =     "Many engineering disciplines can profitably use large
                 high-resolution geometric models whose computational
                 requirements exceed current computer hardware
                 capacities. This paper presents an adaptive
                 visualization solution for interactively building such
                 models. Whereas adaptive visualization techniques have
                 conventionally been applied to existing complete
                 models, our work permits adaptive visualization of
                 models while under construction. To achieve this, we
                 use a multiresolution surface representation for both
                 geometric computation and visualization. The paper
                 develops techniques that dynamically and adaptively
                 decimate models, adjusting to changing camera
                 positions. The decimation algorithm preserves
                 intersection curves between surfaces, and applies to
                 models whose surface triangulation is either globally
                 coherent or incoherent. We have embedded the technology
                 presented in this paper into a 3D geoscience geometric
                 modeling application framework that supports many
                 applications.",
  keywords =     "Computer graphics, adaptive visualization,
                 multiresolution, geometric modeling, decimation.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-252,
  year =         "2000",
  title =        "{PROSECO} - {A} Framework Architecture to Provide
                 Services for Economic Data",
  author =       "Miriam Lux and Ralf Stuckert and Stefan M{\"u}ller",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-252",
  abstract =     "The Internet now provides access to a number of
                 repositories from which large data volumes can be
                 available. Due to the huge amount of memory needed to
                 store the data and hardware requirements to visualize
                 them, there is a need for interactive visualization
                 services for online data exploration and analysis.
                 Therefore, we have investigated the requirements for a
                 user-friendly access to information. Based on the
                 resulting WWWW model, we have developed the system
                 PROSECO, an open scalable framework architecture to
                 easily provide and access any services needed for a
                 distributed visualization of abstract data. We
                 demonstrate the capabilities of our concepts by
                 integrationg services in-to PROSECO to provide the
                 workflow of an economist.",
  keywords =     "User-friendliness, distributed visualization, economic
                 data.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-253,
  year =         "2000",
  title =        "Visualization of the Nucleation and growth of
                 Particles",
  author =       "Darka Mioc and Francois Anton and Christopher M.
                 Gold",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-253",
  abstract =     "This article presents a method for the visualization
                 of the nucleation and growth of particles based on an
                 algorithm for the dynamic construction of additively
                 weighted Voronoi diagrams. We use the Poisson point
                 process in the dynamic additively Voronoi diagram to
                 generate the Johnson-Mehl tesselation. The Johnson-Mehl
                 model is a Poisson Voronoi growth model, in which
                 nuclei are generated asynchronously using a Poisson
                 point process, and grow at the same radial speed.
                 Growth models produce spatial patterns as a result of
                 simple growth processes and their visualization is
                 important in many technological processes.",
  keywords =     "Visualization of nucleation and growth of particles,
                 Johnson-Mehl tessellations, Voronoi diagrams, growth
                 models.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-255,
  year =         "2000",
  title =        "New Theory of Pattern Recognition on the Basis of
                 Stochastic Geometry",
  author =       "Nikolay Fedotov and Luydmila Shulga",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-255",
  abstract =     "The article offers a new approach towards the
                 construction of recognition features independent of
                 images' displacement or linear deformation. The
                 distinguishing characteristics of the group of features
                 under study is representing each of them as a
                 sequential composition of three functionals acting upon
                 the function of one variable. The process to construct
                 the new features suggested boasts of the advantages as
                 follows: a)a host of new features can be easily
                 constructed; b) the features obtained can be
                 structurized along with parallel computations. Great
                 many new features have been constructed to successfully
                 solve the task of recognizing coloured images in
                 biological systems, for instance, blood cells in
                 gematology.",
  keywords =     "http://wscg.zcu.cz/wscg2000/Papers_2000/Q47.pdf",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-256,
  year =         "2000",
  title =        "Real-Time Virtual Cables Based on Kinematic
                 Simulation",
  author =       "Elke Hergenr{\"o}ther and Patrick D{\"a}hne",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-256",
  abstract =     "We present an algorithm for the real-time simulation
                 of virtual cables using inverse kinematics. A cable is
                 modeled by consecutive cylinder segments of equal size.
                 The segments are connected by ball joints. At every
                 joint there is a spiral spring acting against the
                 excursion of the joint. Given a start and an end
                 position of the cable, the algorithm calculates the
                 shape of the cable that leads to minimal total energy.
                 The total energy is the sum of the potential energies
                 of the segments and the elastic energies of the
                 springs. First, the algorithm calculates a cable with
                 minimal total energy consisting of two segments. This
                 is taken as a starting basis for the computation of a
                 cable consisting of four segments. At each following
                 step, the number of segments is doubled and a new shape
                 of the cable is calculated based on the solution of the
                 previous step. The great advantage of this approach is
                 the easy accommodation of the solution exactness to the
                 available computation time. If the user of the VR
                 application is moving the cable, he gets a fast but
                 rough feedback. If he stops moving it, he/she gets an
                 exact shape.",
  keywords =     "Virtual Reality, simulation, deformable objects,
                 kinematic, springs, spline-like objects.",
  booktitle =    "WSCGWSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-257,
  year =         "2000",
  title =        "A {Z}-Buffer {CSF} Rendering Algorithm for Convex
                 Objects",
  author =       "Nigel Stewart and Geoff Leach and Sabu John",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-257",
  abstract =     "A new algorithm for image-space CSG rendering is
                 presented, based on subtraction of convex objects in a
                 specific sequence. The algorithm has been implemented
                 on OpenGL graphics hardware, as well as SGI
                 workstations. Advantages of the algorithm include
                 simpler implementation, closer affinity to hardware
                 capabilities and comparable performance to other CSG
                 image-space algorithms. The new algorithm is described,
                 and compared to previous algorithms, experimentally and
                 theoretically. Some graphics hardware issues related to
                 image-space CSG performance are also discussed.",
  keywords =     "Rendering, Algorithms, Constructive Solid Geometry,
                 OpenGL, Solid Modelling, Numerically Controlled
                 Verification.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-259,
  year =         "2000",
  title =        "A Morphological Approach to the Voxelization of
                 Solids",
  author =       "J. Andreas Baerentzen and Milos Sramek and Niels
                 Jorgen Christensen",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-259",
  abstract =     "In this paper we present a new, morphological
                 criterion for determining whether a geometric solid is
                 suitable for voxelization at a given resolution. The
                 criterion embodies two conditions, namely that the
                 curvature of the solid must be bounded and the critical
                 points of the distance field must be at a certain
                 distance from the boundary of the solid. For solids
                 that fulfill this criterion, we present an analytic and
                 an empirical bound for the trilinear reconstruction
                 error. Additionally, we give a theoretical argument as
                 to why the distance field approach to voxelization is
                 more sound than the prefiltering technique. The essence
                 of the argument is that while sampling and
                 interpolation must always introduce some error, the
                 latter method (but not the former) introduces an error
                 in the surface position independently of the
                 sampling.",
  keywords =     "Voxelization, Morphology, Geometric modeling,
                 Curvature, Hesse normal form.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-26,
  pages =        "284--292",
  year =         "2000",
  title =        "Midstream content access based on color visual pattern
                 coding",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-26",
  author =       "G. Schaefer",
  organization = "SPIE",
  month =        jan,
  editor =       "M. M. Yeung and B.-L. Yeo and C. A. Bouman",
  volume =       "3972",
  keywords =     "compression and compressed data processing",
  booktitle =    "Proceedings of SPIE: Storage and Retrieval for Media
                 Databases 2000",
}

@InProceedings{EVL-2000-260,
  year =         "2000",
  title =        "Incremental Conversion of 3{D} Wire Frame Models to
                 Polygonal Surface Models",
  author =       "J'er^ome Grosjean and Terii Stein and Sabine
                 Coquillart",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-260",
  abstract =     "Though a large variety of methods has been developed
                 to model 3D objects, most of them are based on the
                 construction of solid objects or curved surfaces. This
                 work is part of a sketch-based project for modeling
                 arbitrarily polygonal shapes. The method for modeling
                 3D objects is based on the user drawing or removing of
                 edges. This paper addresses the automatic computation
                 of the 3D polygonal surface model from the 3D wire
                 frame. A straightforward incremental algorithm is
                 proposed allowing an update of the surface model for
                 each modification of the 3D wire frame. Objects of any
                 genus, or topological type are handled by the method.",
  keywords =     "Geometric modeling, sketching, wireframe, surface
                 reconstruction.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-261,
  year =         "2000",
  title =        "Robust Incremental Polygon Triangulation for Surface
                 Rendering",
  author =       "Subodh Kumar",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-261",
  abstract =     "This paper presents a simple, robust and practical,
                 yet fast algorithm for triangulation of points on the
                 domain of trimmed Be'zier surfaces. These R2 points are
                 input to this algorithm by a surface sampler. A set of
                 polygons is formed from these samples, which are then
                 triangulated. We also show how to update the
                 triangulation when the samples, and hence the polygons,
                 are updated. The output is a set of triangle strips.
                 The algorithm includes heuristics to avoid long and
                 thin triangles. In addition, it also detects if the
                 sampling of the trimming curve forms any non-simple
                 polygons and corrects the triangulation by adding more
                 samples. The triangulation algorithm is more generally
                 applicable to polygons in a plane. We report an
                 implementation of the algorithm and its performance on
                 extensive surface-model walkthrough.",
  keywords =     "Surface rendering, CAD, Triangulation, Polygon, PSLG,
                 Computational geometry.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-262,
  year =         "2000",
  title =        "{GREEN}: {A} Tool for Modelling Natural Elements",
  author =       "J. Lluch and M. J. Vicent and R. Vivo and R. Quiros",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-262",
  abstract =     "In this article we present a prototype tool for the
                 modelling of natural elements based on procedural
                 modelling using Random L-systems, or RL-systems.
                 RL-systems are L-systems which are extended using
                 random variables, which permits us to obtain different
                 individuals of the same species based on the same
                 system. The proposed tool is flexible, easily
                 modifiable and extensible due to its implementation
                 using an object-oriented methodology which permits the
                 incorporation of system modules with diverse
                 functionality, such as the representation of specific
                 parts of the element, simulation of tropism or pruning
                 functions. Additionally, the proposed tool permits
                 different interpretations to obtain different file
                 formats depending on the desired viewer application,
                 which permits the connection to other applications for
                 modelling and visualisation of populations.",
  keywords =     "Image synthesis, procedural modelling, RL-systems.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-263,
  year =         "2000",
  title =        "Persistent Naming for Parametric Models",
  author =       "Dago Agbodan and David Marcheix and Guy Pierra",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-263",
  abstract =     "Nowadays, many commercial CAD systems support
                 history-based, constraint-based and feature-based
                 modelling. The use of these new capabilities raises the
                 issue of persistent naming which refers to the problem
                 of identifying entities in an initial parametric model
                 and matching them in the re-evaluated model. The goal
                 of this paper in to propose a naming mechanism and an
                 hierarchical structure enabling to identify topological
                 entities and to apprehend the {"}design intent{"}.",
  keywords =     "CAD/CAM, geometric modelling, parametrics, feature
                 taxonomy.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-264,
  year =         "2000",
  title =        "Faster {ASV} Decomposition for Orthogonal, Using the
                 Extreme Vertices Model ({EVM}) Polyhedra.",
  author =       "Antonio Aguilera and Dolors Ayala",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-264",
  abstract =     "The alternating sum of volumes (ASV) decomposition is
                 a widely used technique for converting a b-rep into a
                 CSG model, with all its implicit uses and advantages
                 -like form feature recognition, among others. The
                 obtained CSG tree has convex primitives at its leaf
                 nodes, while the contents of its internal nodes
                 alternate between the set-union and set-difference
                 operators. This paper first shows that the obtained CSG
                 tree T can also be expressed as the regularized
                 Exclusive-OR operation among all the convex primitives
                 at the leaf nodes of T , regardless the structure and
                 internal nodes of T . The importance of this result
                 becomes apparent, for example, with those solid
                 modeling schemes, for which the Exclusive-OR operation
                 can be performed much faster than both the set union
                 and set difference operators. This is the case for the
                 Extreme Vertices Model (EVM) for orthogonal polyhedra.
                 Therefore, this paper is then devoted for applying this
                 result to orthogonal polyhedra, using the Extreme
                 Vertices Model. It also includes a comparision of using
                 this result vs. not-using it when finding the ASV
                 decomposition of orthogonal polyhedra, as well as some
                 practical uses for the ASV decomposition of orthogonal
                 polyhedra.",
  keywords =     "Solid Modeling, Boundary representations (b-rep),
                 Constructive Solid Geometry (CSG), Boolean operations,
                 ASV decomposition, Form feature recognition.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-265,
  year =         "2000",
  title =        "Surface Flattening Based on Constraint Global
                 Optimizatiom",
  author =       "Phillip {N}. Azariadis and Niklas {A}. Aspragathos",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-265",
  abstract =     "In this paper, the problem of generating a planar
                 development of arbitrary three-dimensional surfaces is
                 addressed. A new method based on a global optimization
                 process under constraints is proposed. In this method
                 an initial planar development is derived which is
                 refined in order to satisfy certain criteria and
                 constraints. The refinement is formulated as a global
                 minimization problem. Using the proposed technique it
                 is not required to predetermine a mapping from the
                 three-dimensional surface to the plane in oder to
                 generate the planar development and it is possible to
                 control the local accuracy in the derived planar
                 development. Indicative applications are presented to
                 illustrate the effectiveness of the proposed
                 technique.",
  keywords =     "Planar development, doubly-curved surfaces,
                 computer-aided design, constrained optimization.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-266,
  year =         "2000",
  title =        "Using 3{D} Geometric Constraints in Architectural
                 Design Support Systems",
  author =       "B. de Vries and A. J. Jessurun and R. H. M. C.
                 Kelleners",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-266",
  abstract =     "To support 3D architectural modeling, geometric
                 constraints are introduced. Explicit and implicit
                 geometric relations between building elements can be
                 expressed by the designer and imposed on the 3D
                 geometry of the design. A complete set of constraint
                 types is defined. Constraints are satisfied through
                 Numerical Methods to achieve that the model responds to
                 the designers' actions in a user-intuitive way. Two
                 prototype systems demonstrate the application of
                 geometric constraints in the architectural domain.",
  keywords =     "CAD, Geometric constraints, Design systems.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-267,
  year =         "2000",
  title =        "{EFFIGI}: An Efficient Framework For Implementing
                 Global Illumination",
  author =       "William Leeson and Carol O'Sullivan and Steven
                 Collins",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-267",
  abstract =     "This paper presents a rendering framework called
                 EFFIGI (Efficient Framework For Implementing Global
                 Illumination) that uses interfaces which express both
                 geometric concepts and mathematical ones, using
                 object-oriented and component object methods. EFFIGI
                 accelerates the development of new techniques and the
                 implementation of existing ones, by providing a
                 flexible but comprehensive geometric and mathematical
                 architecture. The framework eliminates the need for
                 users to implement an entire system, enabling them to
                 focus only on those areas of particular interest.",
  keywords =     "Rendering Framework, Object-Oriented Design, Global
                 Illumination.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-268,
  year =         "2000",
  title =        "Algorithm for Generation of Reflections on 'Flat'
                 Elements for Visualization Purposes (e.g. Glass
                 Sheets)",
  author =       "Krzysztof T. Tytkowski",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-268",
  abstract =     "In real model inaccuracy connected with surface making
                 must be taken into account It has been assumed that
                 reflections from real surface will not be calculated
                 and thus only 'shifts' of a picture will be determined.
                 The suggested algorithm includes/ takes into
                 consideration the distance of an object and the
                 observer.",
  keywords =     "Reflection, real surface, rendering, visualisation.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-269,
  year =         "2000",
  title =        "Raytracing of Dispersion Effects in Transparent
                 Materials",
  author =       "Alexander Wilkie and Robert F. Tobler and Werner
                 Purgathofer",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-269",
  abstract =     "In this paper we present a stochastic add-on extension
                 to standard raytracing which makes it possible to
                 render dispersion effects more efficiently than
                 hitherto possible. Our method incurs less overhead than
                 previous proposals, is physically accurate and is
                 applicable to most of the currently feasible spectral
                 representations.",
  keywords =     "Spectral rendering, dispersion, raytracing.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-27,
  pages =        "293--300",
  year =         "2000",
  title =        "Compressed-domain video parsing using energy
                 histograms of the lower frequency {DCT} coefficients",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-27",
  author =       "O. Bao and J. A. Lay and L. Guan",
  organization = "SPIE",
  month =        jan,
  editor =       "M. M. Yeung and B.-L. Yeo and C. A. Bouman",
  volume =       "3972",
  keywords =     "compression and compressed data processing",
  booktitle =    "Proceedings of SPIE: Storage and Retrieval for Media
                 Databases 2000",
}

@InProceedings{EVL-2000-270,
  year =         "2000",
  title =        "Importance-Driven Hierarchical Stochastic Ray
                 Radiosity",
  author =       "Jan Prikryl and Philippe Beakert and Werner
                 Purgathofer",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-270",
  abstract =     "In this paper we present a hierarchical Monte-Carlo
                 radiosity algorithm driven by the view importance. The
                 algorithm makes to possible to concentrate the
                 computational effort on solution in the immediate
                 environment of the observer, trading the low solution
                 quality in invisible areas for better quality in areas
                 that are visible for the observer. This is achieved by
                 modifying the sampling probabilities of scene elements
                 so that more samples are concentrated in the area of
                 high importance and by extending the subdivision oracle
                 function so that the subdivision is coarser in areas of
                 low importance. This paper extends the previous work by
                 introducing a combination of hierarchical refinement
                 and view importance driven method for Monte-Carlo
                 radiosity.",
  keywords =     "Monte-Carlo, radiosity, hierarchy, hierarchical
                 refinement, view importance, view potential.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-271,
  year =         "2000",
  title =        "Bezier Curves Intersection Using Relief Perspective",
  author =       "Radoslav Hlusek",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-271",
  abstract =     "Presented Paper describes the method for finding the
                 intersection class space rational Bezier curves. The
                 problem curve/cure intersection belongs among basic
                 geometric problems and the aim of this article is to
                 solve the problem using relief perspective and Bezier
                 clipping.",
  keywords =     "Bezier curve, perspective collineation, Bezier
                 clipping.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-272,
  year =         "2000",
  title =        "Pierre-Francois Bonnefoi, Dimitri Plemenos",
  author =       "Parallel Generation for Hierarchical Declarative Scene
                 Modeling",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-272",
  abstract =     "Declarative modeling transforms deeply the task of
                 scene designing by adding to it flexibility, and more
                 creativity and by being more user-friendly. However
                 it's difficult to generalize its use, because it
                 requires too much processing time and memory. A
                 possible way for improving the efficiency of
                 declarative modeling is to parallelize the scene
                 generation process. In this paper, a method for
                 parallelizing the generation of the first solution is
                 presented and applied to hierarchical declarative
                 modeling. It is very important to get the first
                 solution as soon as possible because this solution
                 gives the user the possibility to interactively guide
                 the remaining of the resolution process.",
  keywords =     "Declarative Modeling, Constraint Logic Programming,
                 Object Oriented Programming, Parallel scene
                 generation.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-273,
  year =         "2000",
  title =        "Construction of Non-Uniform Basis Functions For Spline
                 Curves and Surfaces",
  author =       "Maria Kuklisova",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-273",
  abstract =     "Non-uniform basis functions for construction of
                 interpolating and approximating spline curves and
                 surfaces are presented. The construction is based on
                 the theory of B-splines and enables a continuous change
                 from interpolation to approximation of given data. It
                 is also possible to change the tension of the curves
                 and surfaces.",
  keywords =     "B-spline curves, geometric modelling, interpolation,
                 approximation, basis functions, tensorproduct surfaces,
                 spline-blended surfaces.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-274,
  year =         "2000",
  title =        "Simplified Procedures For Modelling",
  author =       "F. Smith",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-274",
  abstract =     "Polynomial representations, such as Bezier curves,
                 B-splines or NURBS, form the basis of numerous surface
                 modelling packages. Although they possess properties
                 that result in fast, efficient software, they have some
                 limitations in terms of the shapes that can be modelled
                 and the nature of the controls they offer the user.
                 This paper presents a new, point-based approach to
                 modelling that is guaranteed to produce high quality
                 surfaces whilst providing a simpler, more intuitive
                 user interface. These qualities make the method ideal
                 for such applications as graphical design or animation
                 where there is a need to produce pleasing images with
                 minimum time and effort.",
  keywords =     "Key words: Geometric modelling, computer graphics,
                 geometric control, curvature continuous.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-275,
  year =         "2000",
  title =        "Virtual Information Systems",
  author =       "M. Haindl and S. Kment and P. Slavik",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-275",
  abstract =     "The article advocates advantages of 3D virtual
                 information systems and suggests possible techniques
                 for their fast automatic acquisition from range and
                 color registered images together with solutions for
                 virtual space navigation problems. The proposed system
                 consists of five main parts - range image segmentation,
                 texture analysis, virtual model geometry inference,
                 texture synthesis, and the navigation in virtual
                 environments.",
  keywords =     "Virtual Reality Models, Range Images, Navigation.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-276,
  year =         "2000",
  title =        "The Design and Application of High-Resolution 3{D}
                 Stereoscopic Graphics Display on {PC}",
  author =       "Duoduo Liao and Shiaofen Fang",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-276",
  abstract =     "This paper describes methods and procedures for
                 real-time rendering of high-resolution 3D stereoscopic
                 graphics using an improved 3D OpenGL accelerator on PC
                 platform. The hardware architecture and software
                 development of the stereoscopic accelerator are first
                 analyzed, followed by in detail description of SDK of
                 stereo display control for Windows NT . Using a special
                 driver and the SDK, the high-resolution 3D stereoscopic
                 graphics is easy to program and control in real-time,
                 with a simple interface to stereo viewing devices. At
                 the end, a few extended stereo PC systems will be
                 discussed. These systems further improve the
                 stereoscopic capacities for low-cost industrial
                 graphics applications.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-277,
  year =         "2000",
  title =        "Visualizing Unsteady Flows by Adaptive Streaklines",
  author =       "A. Sannay and B. Montrucchioy and R. Arinaz",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-277",
  abstract =     "The visualization of unsteady flows is an attractive
                 field of research and texture based techniques seem to
                 provide satisfactory results. In this paper we propose
                 a texture-based method which follows streaklines in
                 order to produce an effective visualization of
                 time-dependent phenomena. The local vorticity of the
                 field allows to trace a number of streaklines according
                 to the flow characteristics; in this way, more
                 significant areas are denoted by a higher level of
                 detail. Moreover, different colors are assigned to
                 different vorticity levels to better denote flow
                 instabilities.",
  keywords =     "Scientific visualization, unsteady flows, adaptive
                 particle tracing, level of detail.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-278,
  year =         "2000",
  title =        "Evolutionary Identification of Active Particle
                 Systems",
  author =       "Bogdan Stanciulescu and Jean Louchet",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-278",
  abstract =     "This paper presents how it is possible to introduce
                 active motricity into particle-bond systems used in
                 applications such as image animation. We chose to add
                 into some neural network capabilities over the
                 classical approach, in order to obtain a system able to
                 model a larger class of behaviour. Therefore a new type
                 of binary bond enriched with a neural-based command
                 ability is proposed and tested in this paper. This
                 {"}active{"} bond acts like a controlled muscle in
                 order to produce motricity. An Evolutionary Strategy is
                 used to optimise the particle-bond system parameters
                 through evolving parameter sets. We tested our method
                 both on artificially generated data and on data
                 collected from real-life motion. Results and
                 comparisons between our method and other approaches
                 show the advantage of using active particle-bond
                 systems for image animation applications.",
  keywords =     "Computer animation, computer graphics, physically
                 based motion modelling, particle-based modelling,
                 evolutionary strategies, motion analysis, neural
                 networks, neural controllers.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-28,
  pages =        "301--310",
  year =         "2000",
  title =        "Compression of large binary images in digital spatial
                 libraries",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-28",
  author =       "E. I. Ageenko and P. Fr{\"a}nti",
  organization = "SPIE",
  month =        jan,
  editor =       "M. M. Yeung and B.-L. Yeo and C. A. Bouman",
  volume =       "3972",
  keywords =     "compression and compressed data processing",
  booktitle =    "Proceedings of SPIE: Storage and Retrieval for Media
                 Databases 2000",
}

@InProceedings{EVL-2000-280,
  year =         "2000",
  title =        "Ra{FS}i - {A} Fast Watershed Algorithm Based on
                 Rainfalling Simulation",
  author =       "Stanislav L. Stoev",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-280",
  abstract =     "In this paper, we present a fast watershed algorithm
                 based on the rainfalling simulation. We present the
                 various techniques and data structures utilized in our
                 approach. Throughout this work, the processing of large
                 data sets (images as well as volume data) is especially
                 emphasized. The results' correctness, the fast
                 execution time, and the memory requirements are
                 discussed in detail. First we introduce a sequential
                 algorithm and discuss the cases, where the known
                 algorithm pro-duces erroneous results. Afterwards, the
                 presented watershed algorithm is compared with
                 immersion based watershed algorithms with respect to
                 running time and memory requirements. Keywords:
                 watershed transformation, rainfalling simulation, image
                 segmentation, geodesic reconstruction, watersheds.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-281,
  year =         "2000",
  title =        "New Metrics for Evaluation of Collision Detection
                 Techniques",
  author =       "Evin Levey and Christopher Peters and Carol
                 O'Sullivan",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-281",
  abstract =     "In this paper we describe new metrics for the
                 evaluation of collision detection techniques. Through
                 careful study of common applications of these
                 techniques we have developed a series of comparative
                 tests that should be conducted when evaluating a
                 collision detection algorithm. We present a
                 comprehensive overview of the two most commonly used
                 collision detection algorithms, Enhanced GJK and
                 V-Clip, and analyse them using the new metrics.",
  keywords =     "Collision detection, computer graphics, computer
                 animation, performance metrics.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-282,
  year =         "2000",
  title =        "Towards a Unified Approach between Digitizations of
                 Linear Objects and Discrete Analytical Objects",
  author =       "C. Lincke and C. A. W{\"u}thrich",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-282",
  abstract =     "This paper compares the traditional digitization
                 method as used in Computer Graphics with the
                 arithmetical geometry approach. Digitizations are
                 interpreted as the set of grid points contained in the
                 dilation of a continuous object and a reflected basic
                 domain. We investigate the supercover and derive its
                 analytical description for analytical objects. We prove
                 that the supercover of a convex linear object is a
                 discrete analytical object and provide methods to
                 determine the inequalities defining the supercover.",
  keywords =     "Discrete geometry, n-dimensional raster graphics,
                 digitization, morphology, super- cover, arithmetical
                 geometry, discrete analytical objects, polyhedral sets,
                 convex linear objects.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-283,
  year =         "2000",
  title =        "Laziness, a Way to Improve Distributed Computation of
                 the Ray Tracing Algorithm",
  author =       "Olivier Poitou and Bernard Lecusan and Sebastian
                 Bermes",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-283",
  abstract =     "This paper raises the issue of computational workload
                 and memory load balancing to ray trace large scenes
                 efficiently on a network of workstations. The task
                 splitting is done on the image to be produced and not
                 on the scene data to obtain a high performance level.
                 To deal with the high memory requirements of such a
                 distribution strategy, laziness is added to the base
                 algorithm. This reduces the computing local memory
                 requirements to the locally computed part of the image.
                 It also reduces the sequential parts of the algorithm
                 by making the voxelization process parallel. Many
                 comparisons have been done using a manager/worker
                 distribution algorithm on different scenes computed on
                 a conventional network of workstations. Performance,
                 load imbalance, communication overhead, and memory
                 requirement results are given and discussed in this
                 paper. Furthermore, this paper demonstrates that the
                 proposed solution improves the results obtained with
                 conventional algorithms, no matter what network used or
                 however complex the image is.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-284,
  year =         "2000",
  title =        "The Multi-Dimensional Hartley Transform as a Basis for
                 Volume Rendering",
  author =       "Thomas Theussl and Robert F. Tobler and Eduard
                 Gr{\"o}ller",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-284",
  abstract =     "The Fast Hartley Transform (FHT), a discrete version
                 of the Hartley Transform (HT), has been studied in
                 various papers and shown to be faster and more
                 convenient to implement and handle than the
                 corresponding Fast Fourier Transform (FFT). As the HT
                 is not as nicely separable as the Fourier Transform
                 (FT), a multidimensional version of the HT needs to
                 perform a final correction step to convert the result
                 of separate HTs for each dimension into the final
                 multi-dimensional transform. Although there exist
                 algorithms for two and three dimensions, no
                 generalization to arbitrary dimensions can be found in
                 the literature. We demonstrate an easily comprehensible
                 and efficient implementation of the fast HT and its
                 multi-dimensional extension. By adapting this algorithm
                 to volume rendering by the projection-slice theorem and
                 by the use for filter analysis in frequency domain we
                 further demonstrate the importance of the HT in this
                 application area.",
  keywords =     "Hartley transform, Fourier transform, volume
                 rendering.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-285,
  year =         "2000",
  title =        "Dynamic Animation of {N}-Dimensional Deformable
                 Objects",
  author =       "Yannick Remion and Jean-Michel Nourrit and Olivier
                 Nocent",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-285",
  abstract =     "This paper presents a new, accurate, efficient and
                 unified method for dynamic animation of one, two or
                 three-dimensional deformable objects. The objects are
                 modelled as d-dimensional juxtapositions of
                 ddimensional patches defined as parametric blending of
                 a common d-dimensional mesh of 3D control points.
                 Animation of the object is achieved by dynamic
                 animation of its control points. This ensures that at
                 each time step the object shape conforms to its patches
                 definitions, and, thus, that every property implied by
                 the nature of the blending functions is verified.
                 Dynamic animation of these continuous models implies no
                 {"}matter discretising{"} as the control points are not
                 considered as material points but moreover as the
                 degrees of freedom of the continuous object . A generic
                 (both for blending functions nature and object
                 intrinsic dimension d) mechanical model reflecting this
                 idea is proposed. Then, according to this modelling
                 idea, a convenient generic dynamic animation engine is
                 built from Lagrangian Equations. This engine relies
                 upon an accurate and very efficient linear system.
                 Forces and constraints handling as well as numerical
                 resolution process are then briefly discussed in this
                 scheme.",
  keywords =     "Dynamic animation , Lagrangian equations, spline,
                 parametric surfaces, parametric volumes, deformable
                 objects.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-286,
  year =         "2000",
  title =        "Line Art Rendering of Triangulated Surfaces Using
                 Discrete Lines of Curvature",
  author =       "Christian R{\"o}ssl and Leif Kobbelt and Hans-Peter
                 Seidel",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-286",
  abstract =     "In recent years, several techniques have been proposed
                 for automatically producing line-art illustrations. In
                 this paper a new non photo-realistic rendering scheme
                 for triangulated surfaces is presented. In contrast to
                 prior approaches with parametric surfaces, there is no
                 global parameterization for triangle meshes. So a new
                 approach is made to automatically generate a direction
                 field for the strokes. Discrete curvature analysis on
                 such meshes allows to estimate differential parameters.
                 Lines of curvature are then constructed to be used as
                 strokes. Using triangulated surfaces allows to render
                 aesthetically pleasing line drawings from a huge class
                 of models. Besides, experiments show that even real
                 time visualization is possible.",
  keywords =     "Non photo-realistic rendering, line art drawings,
                 triangle meshes, discrete curvature analysis.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-287,
  year =         "2000",
  title =        "QteVtk - a Multi-Platform, Object-Oriented
                 Visualization Environment Extending {VTK}",
  author =       "Stanislav L. Stoev and Wolfgang Strasser",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-287",
  abstract =     "In this study, we present a new comprehensive
                 visualization environment, based on the VTK library. We
                 first introduce a window system independent graphical
                 interface for the VTK-classes and it's object-oriented
                 design, then we describe a set of viewer and editor
                 classes for displaying and editing different data types
                 available in the VTK-library. The described library
                 (QteVtk) provides a graphical user interface (GUI) to
                 ease creating VTK visualization pipelines with
                 graphical appearance. Furthermore, it implements
                 saving, loading, and adjusting of objects and object
                 parameters, while supporting VTK-concepts like object
                 oriented design and {"}demand driven{"} update of the
                 visualization pipeline for data-flow control. QteVtk
                 provides for the first time an easy to use combination
                 of a free object oriented visualization with
                 multi-platform GUI elements. The presented work came
                 into being, because in the authors' opinion the
                 visualization still lacks a free, well designed, in
                 terms of object oriented data structures and
                 algorithms, but powerful and easy to use visualization
                 library for implementing visualization applications
                 with the latter, as well as adding new data structures
                 and techniques to it.",
  keywords =     "Computer graphics, data visualization, object oriented
                 visualization, data flow, visual programming, vtk.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-288,
  year =         "2000",
  title =        "Visualization of Changes in Magnetic Resonance Image
                 Data",
  author =       "K. Suomi and J. Oikarinen",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-288",
  abstract =     "Computer assisted image fusion provides an easy and
                 accurate way to interpret and compare medical image
                 pairs. Subjective expectations of human interpretator
                 become less important when pixel-by-pixel-variations
                 are calculated by computer. The estimation of sizes and
                 locations of the differences also become more exact. We
                 introduce new methods to visualize changes between
                 images and present examples how they can be used to
                 highlight contrast medium trace and to follow growth of
                 brain tumor in MRI. The composite images created using
                 these methods provide an illustrative way to discover
                 faint or small-sized differences between separate
                 volumes.",
  keywords =     "Angiography, image fusion, medical imaging, MRI,
                 subtraction technique, tumor delineation.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-289,
  year =         "2000",
  title =        "Two Methods for Cloud Visualization from Weather
                 Simulation Data",
  author =       "Andrzej Trembilski",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-289",
  abstract =     "For the local TV presentation of weather forecast data
                 it is important to have high-quality and fast
                 visualisation of clouds. In this paper I present
                 methods for the visualisation of clouds from data
                 produced by a meteorological weather simulation.
                 Isosurfaces, which are originally too coarse because of
                 the data grid resolution are refined and deformed. The
                 resulting geometry is used for cloud visualisation.",
  keywords =     "Meteorological visualisation, cloud visualisation,
                 surface refinement.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-29,
  pages =        "312--320",
  year =         "2000",
  title =        "Content-based image retrieval in medical applications:
                 a novel multistep approach",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-29",
  author =       "T. M. Lehmann and B. B. Wein and J. Dahmen and J.
                 Bredno and F. Vogelsang and M. Kohnen",
  organization = "SPIE",
  month =        jan,
  editor =       "M. M. Yeung and B.-L. Yeo and C. A. Bouman",
  volume =       "3972",
  keywords =     "image database, image retrieval applications",
  booktitle =    "Proceedings of SPIE: Storage and Retrieval for Media
                 Databases 2000",
}

@InProceedings{EVL-2000-290,
  year =         "2000",
  title =        "2{D} Image Reconstruction Using Natural Neighbour
                 Interpolation",
  author =       "Francois Anton and Darka Mioc and Alain Fournier",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-290",
  abstract =     "In this paper, we explore image reconstruction from
                 irregularly spaced samples using natural neighbour
                 interpolation. We sample the image irregularly using
                 techniques based on the Laplacian or the derivative in
                 the direction of the gradient. Local coordinates based
                 on the Voronoi diagram are used in natural neighbour
                 interpolation to quantify the {"}neighbourliness{"} of
                 data sites. Then we use natural neighbour interpolation
                 in order to reconstruct the image. The main result is
                 that the image quality is always very good in the case
                 of the sampling techniques based on the Laplacian.",
  keywords =     "Image reconstruction, irregularly spaced samples,
                 natural neighbour interpolation, local coordinates.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-291,
  year =         "2000",
  title =        "Region-Based Fractal Compression for Still Images",
  author =       "Yung-Chin Chang and Bin-Kai Shyu and Jia-Shung Wang",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-291",
  abstract =     "Fractal image coding is a novel and attractive
                 technique for still image compression. By utilizing the
                 characteristic of self-similarity, an iterated function
                 system can automatically convert an image into a set of
                 affine transformation coefficients. However, the
                 conventional block-based segmentation methods
                 inadequately satisfy the natural image property and
                 thus can't achieve an efficient performance. In this
                 paper, we propose a thorough fractal image compression
                 system to approach the target of very low bit-rate. To
                 more efficiently utilize the property of natural
                 images, an image-dependent region-based segmentation
                 technique is proposed. This region-based process
                 consists of two steps: First, we improve the
                 performance of quadtree decomposition by utilizing the
                 adaptive threshold method. Second, a merging scheme is
                 introduced to the result of quadtree decomposition that
                 combines several similar blocks into a small number of
                 regions. We also provide a quadtree-based segmented
                 chain code to efficiently record the contours of the
                 region. Moreover, a post-processing algorithm is
                 applied according to region-based segmentation to
                 eliminate the blocking artifact. The experimental
                 results indicate that the proposed method has the
                 potential to achieve comparable extreme low bit rate
                 among the existing methods at the same level of
                 quality.",
  keywords =     "Fractal image compression, region-based method, very
                 low bit rate",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-292,
  year =         "2000",
  title =        "A Spline Approximation of a Large Set of Points",
  author =       "Jana Kostkova and Radim Halir",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-292",
  abstract =     "This paper presents a spline approximation method for
                 the representation of a large set of points. The
                 representation should be smooth with preserving
                 important shape characteristics given by the points.
                 Because of a large size of the set, the standard spline
                 interpolation cannot be used. The proposed method is
                 based on a least squares minimization of the distances
                 of the points from the spline function subject to the
                 conditions of smoothness of the representation. The
                 spline approximation produces accurate and suitable
                 representation of the points. The proposed approach has
                 been verified on both synthetic and real data sets of
                 points.",
  keywords =     "Spline approximation, fitting, least squares",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-293,
  year =         "2000",
  title =        "Information Contents of Fracture Lines",
  author =       "H. C. G. Leitao and J. tolfi",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-293",
  abstract =     "Reassembling unknown broken objects from a large
                 collection of fragments is a common problem in
                 archaeology and other fields. Computer tools have
                 recently been developed by the authors and by others,
                 which try to help locating pairs if fragments with
                 matching cutline shapes. These tools have been
                 successfully tested on small collections of fragments.
                 Here we address the question of whether such tools can
                 be expected to work for practical instances of the
                 problem (10^3 to 10^5 fragments). To that end we
                 describe here a method to measure average amount of
                 information contained in the shape of a fracture line
                 of given length. This parameter tells us how many false
                 matches we can expect to find for that fracture among a
                 given set of fragments; and we show that outline
                 comparison should give useful results even for large
                 instances.",
  keywords =     "Fractures, Pattern recognition, contour matching,
                 fractals.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-294,
  year =         "2000",
  title =        "A 3{D} Texture-Based Octree Volume Visualization
                 Algorithm",
  author =       "Imma Boada and Isabel Navazo and Roberto Scopignoz",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-294",
  abstract =     "Although 3D texture based volume rendering guarantees
                 to obtain image quality almost interactively, it is
                 difficult to maintain this interactivity when the
                 technique has to be exploited on large data sets. In
                 this paper, we propose a new texture memory management
                 policy that substitutes the classical assignation
                 policy of one texel per voxel, applied for the volume
                 representation in texture space, for a more synthetical
                 one that benefits of nearly homogeneous regions and
                 areas of no interest of the volume. Based on this new
                 policy a 3D texture based Octree Volume Visualization
                 algorithm, that combines 3D texture hardware and
                 hierarchical representation of volume data, is
                 presented. The algorithm allows multiresolution
                 renderings of very large data sets and guarantees high
                 image quality at regions of special interest. The
                 simplified representation applied to the
                 non-interesting regions of the volume improves
                 rendering speed.",
  keywords =     "3D Textures,Volume Visualization, Octrees.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-295,
  year =         "2000",
  title =        "Fast Surface Rendering of Volumetric Data",
  author =       "Balazs Csebfalvi and Andreas K{\"o}nig and Eduard
                 Gr{\"o}ller",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-295",
  abstract =     "In this paper a new direct volume-rendering method is
                 presented for fast display of iso-surfaces. In order to
                 reduce the data to be processed, the algorithm
                 eliminates those voxels which are invisible from a
                 specific domain of viewing directions. The remaining
                 surface points are stored in an appropriate data
                 structure optimized for fast shear-warp projection. The
                 proposed data structure also supports the application
                 of cutting planes in order to visualize the internal
                 part of the volume as well. Unlike many other surface
                 oriented techniques, the presented method does not
                 require any specialized hardware to achieve interactive
                 frame rates, thus it can be widely used in medical
                 imaging applications even on low end hardware.",
  keywords =     "Volume Rendering, Shear-Warp Factorization, Medical
                 Imaging.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-296,
  year =         "2000",
  title =        "{VIS}-{RT}: {A} Visualization System for {RT} Spatial
                 Data Structures",
  author =       "Vlastimil Havran and Libor Dachs and Jiri Zara",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-296",
  abstract =     "In this application paper we describe a system of
                 spatial data structures that are used to accelerate ray
                 shooting in global illumination. The system has been
                 implemented and further used to verify the correctness
                 of spatial data structures implementation, since for
                 large and complex scenes the verification is difficult
                 or even impossible.",
  keywords =     "Ray shooting, visualization, spatial data
                 structures.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-297,
  year =         "2000",
  title =        "Handling Cycles in Conformational Behaviour
                 Visualization",
  author =       "Ales Krenek",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-297",
  abstract =     "A simulation of conformational behaviour of molecules
                 produces series of rapidly changing shapes of a
                 particular molecule. Animated visualization of the
                 process requires continuous morphing from one shape
                 into another. Recently we proposed a method applicable
                 on acyclic structures, in this paper we focus on smooth
                 interpolation between different shapes of cycles.",
  keywords =     "Interpolation, conformational behaviour, cyclic
                 structures.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-298,
  year =         "2000",
  title =        "Optimizing Combined Volume and Surface Data Ray
                 Casting",
  author =       "M. R. M. Silva and C. M. S. Freitas",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-298",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-299,
  year =         "2000",
  title =        "Concept for Increased Security for Internet/Intranet",
  author =       "Lutz Vorwerk and Sergey Khludov and Christoph Meinel",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-299",
  abstract =     "In this paper, we will present an increased-security
                 concept for systems administering patient-data and
                 DICOM (digital imaging and communication in medicine)
                 images. The system presented here is an
                 intranet/internet based PACS and has been developed at
                 the institute of telematics (IT) [Hlu99]. The PACS is
                 based on standard network-protocols and has been
                 created using DICOM-standard. See [Nem94] and [Rad99]
                 for more information. The system components have been
                 designed in JAVA and have been distributed onto three
                 different computers. Two computers - equipped with
                 several relational databases administered by JAVA
                 servers - were assigned to the intranet-component while
                 the third computer is located on the internet and is
                 equipped with an user interface. The concept for
                 increased security developed at the IT aims at
                 protecting the intranet against the internet.
                 Interaction between the components on the internet and
                 within the intranet should take place via a secure
                 connection. Patient data can either be sent encoded
                 along with images or can be sent separately from the
                 raw image data. System users are entered into and
                 administered by an user database. A standard
                 {"}registry{"} will act as the user database, allowing
                 users to access data.",
  keywords =     "Internet, Intranet, PACS, Firewall, SSL, LDAP,
                 Registry, WWW, JAVA, DICOM.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@TechReport{EVL-2000-3,
  year =         "2000",
  title =        "{R}-Simp to {PR}-Simp: Parallelizing {A} Model
                 Simplification Algorithm",
  author =       "Dmitry Brodsky",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-3",
  abstract =     "As modelling and visualization applications
                 proliferate, there arises a need to simplify large
                 polygonal models at interactive rates. Unfortunately
                 existing polygon mesh simplification algorithms are not
                 well suited for this task because they are either too
                 slow (requiring pre-computation) or produce models that
                 are too poor in quality. Given a multi-processor
                 environment a common approach for obtaining the
                 required performance is to parallelize the algorithm.
                 Many non-trivial issues need to be taken into account
                 when parallelizing a sequential algorithm. We present
                 PR-Simp a parallel model simplification algorithm and
                 the issues involved in parallelizing R-Simp.",
  month =        feb,
  number =       "TR-00-02",
  institution =  "Department of Computer Science, University of British
                 Comlumbia",
}

@Article{EVL-2000-30,
  pages =        "82",
  year =         "2000",
  title =        "Treatment planning and simulation in craniofacial
                 surgery with virtual reality techniques",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-30",
  author =       "H. F. Zeilhofer and S. Zachow and J. D. Fairley and R.
                 Sader and P. Deuflhard",
  number =       "28 (Suppl 1)",
  journal =      "J. of Cranio-Maxillofacial Surgery",
}

@InProceedings{EVL-2000-300,
  year =         "2000",
  title =        "Embodied Modelling Tools in a 3{D} Environment",
  author =       "Luis Narvaez Porras",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-300",
  abstract =     "Most 3D modelling tools available today operate using
                 interfaces based on traditional static menus, which
                 implies that the user must go through a long training
                 period before he can use the modelling tool in a
                 productive manner. In this paper we explore the
                 definition and use of new embodied modelling tools
                 within a 3D environment. Each embodied tools works in
                 its own virtual 2D space that senses the action and
                 movements of the {"}mouse{"} and translates them into
                 operations over the elements of a 3D scene. We develop
                 embodied modelling tools covering the most common
                 operations of a traditional modelling program,
                 including creating, coloring, lighting and editing
                 object, as well as showing the internal hierarchy of
                 the scene. Lastly, we conclude by describing the
                 characteristics of the modelling tools that have been
                 shown to be useful in improving interaction.",
  keywords =     "Computer graphics, human-computer interaction, 3D
                 modelling, user interface design, transparency,
                 sketching.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-301,
  year =         "2000",
  title =        "The Multi{CAD} Project: Towards an Intelligent
                 Multimedia Information System for {CAD}",
  author =       "George Miaoulis and Dimitri Plemenos and Dimitri Magos
                 and Christos Skourlas",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-301",
  abstract =     "In this work, we present a set of proposals for the
                 definition of a generalised multimedia information
                 system. The system supports production of scenes using
                 techniques of the declarative modelling by hierarchical
                 decomposition. These proposals include a declarative
                 design process model, the corresponding user needs and
                 define information system framework. The resulting
                 software system architecture is also presented and a
                 prototype of it is implemented. The whole system named
                 MultiCAD is developed as a joint project between
                 laboratory MSI of the University of Limoges and the
                 Information systems and applications Group of the TEI
                 of Athens.",
  keywords =     "Computer graphics, CAD, conceptual modelling, design
                 process, design knowledge representation, multimedia
                 information systems, decision support systems.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-302,
  year =         "2000",
  title =        "Current Changes in Cartographic Visualization",
  author =       "Stanislav Frangres and Miljenko Lapaine and Vesna
                 Posloncec-Petric",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-302",
  abstract =     "The most important changes in cartography are
                 associated with the development of computer technology
                 (GIS), and regarding the function and usage of maps,
                 the accent has been given to cartographic
                 visualization. The paper emphasises the need for closer
                 collaboration of informatic experts, geodesists
                 geographers, spatial planners and others with
                 cartographers. The future of cartography is associated
                 with map production, GIS, visualization of spatial
                 databases, and the production of detailed
                 three-dimensional landscape presentations.",
  keywords =     "Cartographic visualisation, GIS, real and virtual
                 maps, current changes.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-303,
  year =         "2000",
  title =        "Information Extraction and Synchronization Control
                 Method for Multi-Human Animation",
  author =       "Kihyun Kim and Sangwook Kim",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-303",
  abstract =     "When movement of human is animated, motion information
                 of each body part needs to be synchronized adequately
                 in accordance with the motion type. In this paper, we
                 propose an advanced method with the goal of technology
                 supporting a more natural and intuitive interaction.
                 Motion data is extracted to synchronize each movement
                 of human. Synchronization method can provide an
                 important cue in controlling motion. Dynamic motion
                 editor is a tool that extracts motion data. It can
                 create motion data of human and define a various motion
                 by displaying the process of motion as real-time in
                 virtual environment. Also, such algorithms can apply a
                 collected motion data to a different movement of each
                 human and adequately control the motion information of
                 each human. Central to our approach is the use of Human
                 Motion Control Model which is based on analytically
                 synchronization method for various types of human
                 movements. It offers an easier motion animation and
                 control.",
  keywords =     "Motion animation, synchronization, motion data, step
                 control algorithm, knowledge-base.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-304,
  year =         "2000",
  title =        "Perceptually Realistic Flower Generation",
  author =       "Zhaoying Lu and Claire Willis and Derek Paddon",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-304",
  abstract =     "This paper describes a method for generating flower
                 growth animation in which a petal surface and shape can
                 be changed in real time. Most plant modelling currently
                 animates the plant development process by assuming a
                 time interval and the corresponding growth direction,
                 and cannot easily change the time step or deform the
                 shape. In the model presented here we use a graphical
                 representation for plant growth function, along with a
                 new description of plant growth rate, to enable the
                 user to obtain flexible parameters for surface control.
                 The model generates non-deterministic results which
                 give more realistic and varied petals than can be
                 obtained using pre-defined surfaces or interpolating
                 between given initial and final shapes.",
  keywords =     "Surface modelling, growth, animation.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-305,
  year =         "2000",
  title =        "Object-Based Image Coding for Cooperative 3{D}
                 Visualization",
  author =       "Jobst L{\"o}ffler",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-305",
  abstract =     "This articel presents a new approach to interaction
                 with 3D objects of virtual models in the context of
                 digital libraries, which was developed as part of the
                 author`s ongoing PhD research. Collaborative networked
                 environments support users in their work with shared
                 content. One way to provide the visual feedback a user
                 needs to interact with 3D models is to distribute image
                 streams of rendered objects in a
                 client-server-environment, which is described here.
                 Image streams are coded in an object-based way
                 according to the MPEG-4 international standard. As a
                 result, users in a heterogeneous and error-prone
                 network environment can cooperatively visualize complex
                 3D models. The use of coded video streams for
                 collaborative visualization offers flexible means of
                 user interaction for digital library applications.
                 Therefore, future work should aim at providing a
                 cooperative 3D visual interface for heterogeneous
                 documents in digital library systems.",
  keywords =     "Distributed visualization, object-based image coding,
                 model segmentation, digital libraries.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-306,
  year =         "2000",
  title =        "Solving Multiple Layer Containment Problems Using
                 Iterative Methods",
  author =       "Nuno Marques and Pedro Capela",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-306",
  abstract =     "The footwear industry's need for an automatic
                 containment algorithm is becoming increasingly
                 important within the manufacturing process. Irregular
                 containers, such as hides, have many different quality
                 regions and holes that must be taken into account when
                 containment is done because they represent an important
                 cost. Automatic containment processes should be aware
                 of these factors and still perform in practical time.
                 We present an iterative containment algorithm that uses
                 Minkowski operators and can be applicable to such
                 containment problems. Although the iterative solution
                 is not the optimal one, it can reach a solution in
                 practical running times and it can get results that
                 approximate the human made containment process.",
  keywords =     "Containment Problems, Minkowski Operators,
                 Evaluators.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-307,
  year =         "2000",
  title =        "An Efficient Parametric Algorithm for Octree
                 Traversal",
  author =       "J. Revelles and C. Urena and M. Lastra",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-307",
  abstract =     "An octree is a well known hierarchical spatial
                 structure which is widely used in Computer Graphics
                 algorithms. One of the most frequent operations is the
                 computation of the octree voxels intersected by a
                 straight line. This has a number of applications, such
                 as ray-object intersection tests speed-up and
                 visualisation of hierarchical density models by
                 ray-casting. Several methods have been proposed to
                 achieve this goal, which differ in the order in which
                 intersected voxels are visited. In this paper we
                 introduce a new top-down parametric method. The main
                 difference with previously proposed methods is related
                 to descent movements, that is, the selection of a child
                 sub-voxel from the current one. This selection, as the
                 algorithm, is based on the parameter of the ray and
                 comprises simple comparisons. The resulting algorithm
                 is easy to implement, and efficient when compared to
                 other related top-down and bottom-up algorithms for
                 octrees. Finally, a comparison with Kelvin's method for
                 binary trees is presented.",
  keywords =     "Octree, Binary tree, Ray Tracing, Acceleration
                 Techniques.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-308,
  year =         "2000",
  title =        "Adaptive Filtering for Progressive Monte Carlo Image
                 Rendering",
  author =       "Frank Suykens and Yves D. Willems",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-308",
  abstract =     "Image filtering is often applied as a post-process to
                 Monte Carlo generated pictures, in order to reduce
                 noise. In this paper we present an algorithm based on
                 density estimation techniques that applies an energy
                 preserving adaptive kernel filter to individual samples
                 during image rendering. The used kernel widths diminish
                 as the number of samples goes up, ensuring a reasonable
                 noise versus bias trade-off at any time. This results
                 in a progressive algorithm, that still converges
                 asymptotically to a correct solution. Results show that
                 general noise as well as spike noise can effectively be
                 reduced. Many interesting extensions are possible,
                 making this a very promising technique for Monte Carlo
                 image synthesis.",
  keywords =     "Global illumination, Monte Carlo, density estimation,
                 bidirectional path tracing, image filtering.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-309,
  year =         "2000",
  title =        "Development of Java User Interface for Digital
                 Television",
  author =       "Chengyuan Peng and Petri Vuorimaa",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-309",
  abstract =     "The digital television development is one of the most
                 important events in the history of television
                 broadcasting. This paper highlights the user interface
                 issue in digital television environment. We will not
                 discuss the usability of user interface design, but
                 rather the implementation of user interface for
                 interactive television services. The background of
                 Multimedia Home Platform (MHP) and Application
                 Programming Interface (API) is introduced. The paper
                 describes how to develop a Java user interface, which
                 includes not only graphics but also time-based media
                 (e.g., video). Many functions and effects behind the TV
                 visual image have to be implemented. The special
                 features of digital TV user interface are presented by
                 giving an example (i.e., screen information service for
                 ice hockey). Finally, the future possible research
                 topics are briefly addressed.",
  keywords =     "User interface, digital television, Java, application
                 programming interface, interactive television
                 service.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@Article{EVL-2000-31,
  pages =        "1--6",
  year =         "2000",
  title =        "A new nonlinear elliptic multilevel {FEM} applied to
                 regional hyperthermia",
  author =       "P. Deuflhard and M. Weiser and M. Seeba{\ss}",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-31",
  abstract =     "In the clinical cancer therapy of regional
                 hyperthermia nonlinear perfusion effects inside and
                 outside the tumor seem to play a not negligible role. A
                 stationary model of such effects leads to a nonlinear
                 Helmholtz term within an elliptic boundary value
                 problem. The present paper reports about the
                 application of a recently designed adaptive multilevel
                 FEM to this problem. For several 3D virtual patients,
                 nonlinear versus linear model is studied. Moreover, the
                 numerical efficiency of the new algorithm is compared
                 with a former application of an adaptive FEM to the
                 corresponding instationary model PDE.",
  volume =       "3",
  keywords =     "hyperthermia, nonlinear elliptic, multilevel FEM",
  journal =      "Comput. Visual. Sci.",
}

@InProceedings{EVL-2000-310,
  year =         "2000",
  title =        "Collaborate Visualization in Medicine",
  author =       "Isabel Harb Manssour and Carla Maria Dal Sasso
                 Freitas",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-310",
  abstract =     "One of the biggest areas of scientific visualization (
                 ViSC) application is Medicine: with the evolution of
                 image acquisition techniques the capacity and fidelity
                 of image diagnosis were extended. Due to the large
                 number of medical exams that output images, several
                 visualization systems have been developed dealing with
                 specific problems in this area in the last few years.
                 The growing of World Wide Web-based applications and
                 the modern trend of cooperative work in scientific
                 research gave rise to a new class of systems, the
                 so-called collaborative visualization systems. This
                 survey presents an overview of ViSC in Medicine
                 emphasizing the different approaches for collaborative
                 visualization, and discussing difficulties still found
                 for its real utilization.",
  keywords =     "Interactive Visualization, Visualization of Medical
                 Images, Collaborative Visualization.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-311,
  year =         "2000",
  title =        "Interactive Focus and Context Display of Large Raster
                 Images",
  author =       "Uwe Rauschenbach and Tino Weinkauf and Heidrun
                 Schumann",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-311",
  abstract =     "This paper presents the RECTANGULAR FISHEYE VIEW, an
                 interactive focus-and-context presentation technique
                 for large raster images on mobile computers with small
                 displays and limited processing power. Both the viewing
                 of locally available images and the demand-driven
                 display and transmission of remotely- stored images are
                 supported by the technique. The underlying geometry
                 calculations are explained, and the design decisions
                 for supporting rapid interactive feedback are
                 discussed. A scenario is described which demonstrates
                 the performance of the method.",
  keywords =     "Fish Eye View, Raster Images, Interactive Display,
                 Focus-and-Context Techniques, Mobile Computers.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-312,
  year =         "2000",
  title =        "{XML} Based Mobile Services",
  author =       "Outi Marttila and Petri Vuorimaa",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-312",
  abstract =     "The most remarkable trends in communication have been
                 the huge popularity of Internet and the growth of
                 digital cellular telephony usage. There is a strong
                 demand to combine these two in the form of mobile
                 Internet access. This paper discusses the service
                 implementation issues for the wireless environment. The
                 requirements placed on the services and service
                 development by the mobility are presented, and the
                 usage of the next generation, XML based modeling
                 languages in the wireless services is analyzed. The
                 results are based on the experiments gained from the
                 implementation of three demonstration services.",
  keywords =     "XML, XSL, SMIL, DOM, ECMAScript, mobile multimedia.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-313,
  year =         "2000",
  title =        "Overlapping Radiosiity: Using a New Function base with
                 Local Disk Support",
  author =       "Didier Arques and Sylvain Michelin and Benoit
                 Piranda",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-313",
  abstract =     "This paper focuses on a new radiosity approach. Using
                 a new geometrical model that describes any surface with
                 an atlas of {"}disk-like patches{"}, i.e. a set of
                 pieces covering the surface that can overlap each
                 other, we express the radiosity function in a new
                 function base. This leads to a new radiosity system
                 where overlapping areas are taken into account. The
                 classical radiosity approach appears now as a
                 particular limit case of this new {"}overlapping
                 radiosity{"}.",
  keywords =     "Complex surfaces, radiosity.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-314,
  year =         "2000",
  title =        "Improving Hierarchical Monte Carlo Radiosity
                 Algorithms",
  author =       "Jackson Pope and Alan Chalmers",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-314",
  abstract =     "Hierarchical subdivision techniques remove the need
                 for a-priori meshing of surfaces when approximating
                 global illumination. In addition they allow progressive
                 refinement of the solution. However, when such
                 sub-divison is based upon Monte-Carlo methods, due to
                 the stochastic nature of such techniques, sub-divison
                 decisions cannot be made unless a sufficiently large
                 number of samples have been considered. Shadow
                 boundaries are one of the main features such
                 sub-division algorithms are designed to detect, but
                 mesh elements that are in shadow receive less light,
                 and hence are slower to sub-divide. In this paper we
                 investigate methods for modifying the Monte Carlo
                 hierarchical sub-division algorithm to improve the
                 detection of shadow boundaries and caustics.",
  keywords =     "Radiosity, stochastic, Monte Carlo, hierarchical.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-315,
  year =         "2000",
  title =        "Improving Hierarchical Stochastic Monte Carlo
                 Radiosity Algorithms",
  author =       "Jackson Pope and Alan Chalmers",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-315",
  abstract =     "Hierarchical subdivision techniques remove the need
                 for a-priori meshing of surfaces when approximating
                 global illumination. In addition they allow progressive
                 refinement of the solution. However, when such
                 sub-divison is based upon Monte-Carlo methods, due to
                 the stochastic nature of such techniques, sub-divison
                 decisions cannot be made unless a sufficiently large
                 number of samples have been considered. Shadow
                 boundaries are one of the main features such
                 sub-division algorithms are designed to detect, but
                 mesh elements that are in shadow receive less light,
                 and hence are slower to sub-divide. In this paper we
                 investigate methods for modifying the Monte Carlo
                 hierarchical sub-division algorithm to improve the
                 detection of shadow boundaries and caustics.",
  keywords =     "Radiosity, stochastic, Monte Carlo, hierarchical.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-316,
  year =         "2000",
  title =        "Two-Level Iterative Shooting Methods with Groups",
  author =       "F. Rousselle and M. Leblond and C. Renaud",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-316",
  abstract =     "In this paper, we present an acceleration technique
                 for Progressive Radiosity based on group iterative
                 methods. This technique uses groups of shooting patches
                 to accelerate the diffusion of light. The quality of
                 the results depends on the amount of energy that is
                 exchanged between the patches of each group. We propose
                 two group-building techniques which guarantee a high
                 level of interaction between the shooting patches. The
                 resolution of sub-systems generated by the groups is
                 done rapidly thanks to a new technique of hybridization
                 applied to the Gauss-Seidel method. This new PR method
                 using groups is especially efficient in the case of
                 scenes having many occlusions.",
  keywords =     "Progressive radiosity, group resolution, iterative
                 solver, hybridization.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-317,
  year =         "2000",
  title =        "Computer Graphics, business, education, summer camp,
                 cooperative, internship.",
  author =       "Mark Bannatyne and William A. Ross",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-317",
  abstract =     "Professional educators cannot be isolated in their
                 professions as simply conveyers of information who
                 direct curriculum materials toward their students. The
                 fact is that within our profession teaching very often
                 occupies the smallest portion of our workday. In an
                 effort to maintain a high standard of technological
                 excellence in our programs we are responsible for
                 continually reviewing and updating curricula. Indeed,
                 our instructional materials must reflect the high
                 standards that business and industry will demand of our
                 students once they graduate and enter the world of
                 work. An effort must also be made to recruit and
                 encourage the perpetuation of our field by actively
                 seeking out students at the public school level as a
                 means of guiding future scholars toward a career in
                 computer graphics. All these efforts require
                 concentrated efforts and plans that have been well
                 thought out so our programs may continue to grow and
                 prosper. An idle approach to recruiting and securing
                 continual support from business and industry will sound
                 the death knell for any computer graphics program
                 regardless of how well its curriculum may be laid
                 out.",
  keywords =     "Computer graphics, business, education, summer camp,
                 cooperative, internship.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-318,
  year =         "2000",
  title =        "The Gait Sensing Disc - {A} Compact Locomotion Device
                 for the Virtual Environment",
  author =       "Jiung-yao Huang and Wen-hsin Chiu and Yung-ting Lin
                 and Ming-tien Tsai and Hua-hseng Bai",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-318",
  abstract =     "The locomotion device is an input interface, which can
                 sense the walking pace and direction of the user, for
                 the virtual reality system. This paper presents a new
                 type of locomotion device called Omni-direction
                 Ballbearing Disc Platform(OBDP), which allows the user
                 to walk naturally inside the virtual environment.
                 Instead of using the 3D tracker, arrays of ball-bearing
                 sensors on a disc are used to detect the pace and an
                 orbiting frame to identify the walking direction. No
                 other sensor, except the head tracker to detect the
                 user 's head rotation, is required on the user's body.
                 In addition, the ball-bearing on the sensor slips the
                 user's foot back to the center position of the disc. A
                 prototype of the overhead crane training simulator that
                 fully explores the advantage of the OBDP is also
                 designed and introduced in this paper.",
  keywords =     "Virtual Reality, Locomotion, Overhead crane, Gait
                 analysis, Ball-bearing sensor, Interactive visual
                 simulator.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-319,
  year =         "2000",
  title =        "Human Movement Instruction System that Utilizes
                 {ATAVAR} Overlays Using Stereoscopic Images",
  author =       "Masayuki Ihara and Yoshihiro Shimada and Kenichi Kida
                 and Shinichi Shiwa and Satoshi Ishibashi and Takeshi
                 Mizumori",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-319",
  abstract =     "In the Mixed Reality environment that combines the
                 real world and the virtual world it is important to
                 control the 'place' that comprises both real and
                 virtual objects. In this paper, we study the overlay of
                 humans and avatars in virtual space in the creation of
                 an immersive human movement instruction system that
                 works through a network. In this system, users wear
                 stereoscopic glasses and motion capture devices and
                 perfrom within an immersive virtual space experience
                 called CAVE^{TM}. A user can look at a stereoscopic
                 image of an avatar that is displayed over his or her
                 own body. In this project, the authors connected two
                 CAVE^{TM} systems to a network to develop a system that
                 enables model movement instructions and judgement of
                 movement skills to be implemented by people in remote
                 locations. This paper will introduce the setup and
                 configuration of this system.",
  keywords =     "Mixed Reality, control of 'place', human movement
                 instruction, overlay display, stereoscopic vision,
                 avatar.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InCollection{EVL-2000-32,
  pages =        "23--28",
  year =         "2000",
  title =        "Finite-Element Simulation of Soft Tissue Deformation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-32",
  author =       "S. Zachow and E. Gladiline and H.-C. Hege and P.
                 Deuflhard",
  editor =       "H. U. Lemke et al.",
  booktitle =    "Computer Assisted Radiology and Surgery (CARS)",
  publisher =    "Elsevier Science B.V.",
}

@InProceedings{EVL-2000-320,
  year =         "2000",
  title =        "Real-time Animation Technique for Flexible and Thin
                 Objects",
  author =       "Young-Min Kangy and Jeong-Hyeon Choiy and Hwan-Gue
                 Choy",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-320",
  abstract =     "In this paper, we propose an efficient technique for
                 the animation of flexible thin objects. Mass-spring
                 model was employed to represent the flexible objects.
                 Many techniques have used the mass-spring model to
                 generate plausible animation of soft objects. The
                 easiest approach to animation with mass-spring model is
                 explicit Euler method, but the explicit Euler method
                 has serious disadvantage that it suffers from
                 `instability problem'. The implicit integration method
                 is a possible solution to overcome the instability
                 problem. However, the most critical flaw of the
                 implicit method is that it involves a large linear
                 system. This paper presents a fast animation technique
                 for mass-spring model with approximated implicit
                 method. The proposed technique stably updates the state
                 of n mass-points in O(n) time when the number of total
                 springs are O(n). We also consider the interaction of
                 the flexible object and air in order to generate
                 plausible results.",
  keywords =     "Flexible object, mass-spring model, implicit method,
                 stability.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-321,
  year =         "2000",
  title =        "An Immersive Virtual Environment for Special
                 Relativity",
  author =       "Daniel Weiskopf",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-321",
  abstract =     "In this paper, an immersive virtual environment is
                 presented which allows the user to virtually explore
                 and experience special relativity, including phenomena
                 such as Lorentz contraction, time dilation, aberration,
                 and finite speed of light. The
                 relativistic-vehicle-control metaphor - a physically
                 based camera control technique - is introduced for
                 navigating at high velocities. Acceleration of the
                 relativistic observer is investigated. Furthermore,
                 tracking of both the position and velocity of the user
                 is considered. A geometric approach to relativistic
                 polygon rendering is described. The rendering pipeline
                 is extended to accomplish the relativistic
                 transformations in parallel. The implementation
                 supports multiprocessor and multipipe systems for fast
                 rendering and the same frame rates can be achieved for
                 relativistic visualization as for non-relativistic
                 rendering.",
  keywords =     "Special relativity, visualization, immersive virtual
                 environment.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-322,
  year =         "2000",
  title =        "Towards Calligraphic Interfaces: Sketching 3{D} Scenes
                 with Gestures and Context Icons",
  author =       "Joao P. Pereira and Joaquim A. Jorge and Vasco Branco
                 and F. Nunes Ferreira",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-322",
  abstract =     "GIDeS (Gesture-based Intuitive Design System) is a
                 gesture-based modeling system that addresses the known
                 ergonomic shortcomings of present-day CAD systems for
                 conceptual shape design. GIDeS uses a tablet and stylus
                 combination to combine the intuitive appeal of
                 gesture-based interfaces with context-based icons.
                 GIDeS draws on previous modeling work, using contextual
                 information and feedback to free users from remembering
                 detailed modeling gestures, allowing them to
                 concentrate on drawing, towards our end goal of
                 bridging the chasm between paper and pencil and CAD
                 interfaces in the early design stage.",
  keywords =     "Interaction Techniques, 3D Modeling, Gesture
                 Interfaces, Sketching, Calligraphic Interfaces.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-323,
  year =         "2000",
  title =        "Human Motion Synthesis Based on Iterated Function
                 Systems",
  author =       "Stephen Wang-Cheung Lam and Powis Lai-Yin Leung",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-323",
  abstract =     "This paper describes a novel approach to automatic
                 motion sequence generation. The basic algorithm
                 underlying our approach is the iterated function
                 systems (IFS) which have already found many
                 applications in image compression and pattern
                 generation. In our system, a set of key-frames are
                 first specified by the user. Subsequently, IFS based
                 interpolation scheme is employed to generate a sequence
                 of motions having self-similar characteristics. Our
                 ultimate purpose is to produce realistic repetitive
                 motion, which possesses a main theme but the details
                 varies over time. Our algorithm can find applications
                 in generating human motion like dancing or walking
                 which involves long sequence of repetitive movements of
                 a puppet's limbs and body.",
  keywords =     "http://wscg.zcu.cz/wscg2000/Papers_2000/R11.zip",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-324,
  year =         "2000",
  title =        "Two-Stage Multimodality Medical Volume Registration",
  author =       "M. Zapek and H. Trojanova",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-324",
  abstract =     "A semi-automatic, two-stage multimodality medical
                 volume registration is described. This registration
                 hinges on surface matching by using 3D chamfer matching
                 algorithm first and on global information-based
                 matching afterwards. Two stages are applied, because
                 information contents of registered volumes are
                 different and no single registration method works
                 satisfactorily so far. This approach is applied to MRI
                 (Magnetic Resonance Imaging), CT (Computed Tomography)
                 and SPECT (Single Photon Emission Computed Tomography)
                 data volumes. Pilot experiments prove satisfactory
                 results.",
  keywords =     "Multimodality volume registration, feature-based
                 registration, 3-D chamfer matching, global
                 information-based registration, mutual information.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-325,
  year =         "2000",
  title =        "Pyramidal Hemisphere Subdivision Radiosity. Definition
                 and Improvements",
  author =       "Vincent Jolivet and Dimitri Plemenos and Mateu Sbert",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-325",
  abstract =     "In this paper a complete presentation of Pyramidal
                 Hemisphere subdivision method is given. This method
                 improves Monte Carlo radiosity by sending more rays
                 towards selected directions. More precisely, we
                 determine regions of the scene where the distribution
                 of the energy must be done more accurately. The number
                 of rays sent in a direction is function of a pyramidal
                 region, defined by the center of the shooting patch and
                 a spherical triangle on the surface of a hemisphere
                 surrounding the patch, and the number of patches
                 contained in this region. Thus, the rays shot from a
                 patch have not all the same energy. This method allows
                 us not only to obtain fine details much sooner and with
                 lower cost, but also the overall efficiency is
                 considerably increased. Next we present a new way to
                 calculate the number of rays sent in a region by using
                 a dynamic estimation of the visible patches in this
                 region.",
  keywords =     "Monte Carlo radiosity, hemisphere subdivision,
                 heuristic search.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-326,
  year =         "2000",
  title =        "Visualization of Impulse Response of Virtual Acoustic
                 Environments",
  author =       "Adam J. Sporka and Pavel Slavik",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-326",
  abstract =     "There are many methods that allow generate realistic
                 3D acoustic scenes. By means of new technologies it is
                 possible to achieve a high level of realism. In many
                 applications, the pictures are enhanced by sounds
                 generated in 3D environment. This creates more
                 realistic impression for the user. There are many
                 methods that allow us to generate 3D sound and in such
                 a way create high degree of reality in synthetic
                 scenes. Nevertheless when generating sound in 3D
                 environment, it is necessary to have relatively
                 detailed information about the sound characteristics of
                 the scene. Due to the complexity of this information it
                 is necessary to visualize the sound distribution in the
                 space where the sound will be generated. This paper
                 describes a system of visualization of the impulse
                 response of given acoustic environment whose
                 development is one of our current research projects. We
                 notice here its purpose, principles of implementation
                 and basic applications.",
  keywords =     "Geometric algorithms, computer graphics,
                 visualization, virtual acoustics, impulse response.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-327,
  year =         "2000",
  title =        "Algorithms for Generation of Reflections on 'Flat'
                 Elements for Visualization Purposes (e.g. Glass
                 Sheets)",
  author =       "Krysztof T. Tytkowski",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-327",
  abstract =     "In real model inaccuracy connected with surface making
                 must be taken into account It has been assumed that
                 reflections from real surface will not be calculated
                 and thus only 'shifts' of a picture will be determined.
                 The suggested algorithm includes/ takes into
                 consideration the distance of an object and the
                 observer.",
  keywords =     "Reflection, real surface, rendering, visualisation.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@InProceedings{EVL-2000-328,
  year =         "2000",
  title =        "{ARKIS}: An Information System as a Tool for Analysing
                 and Representing Heterogeneous Data on an Architectural
                 Scale",
  author =       "Paolo Salonia and Antonella Negri",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-328",
  abstract =     "In the case of historical buildings and monumental
                 architecture, the analysis and understanding of
                 processes of decay call for an interpretative overview
                 encompassing data which stem from different areas of
                 study but are globally interrelated and constitute
                 essential elements for the purpose of assessing the
                 state of preservation. The study outlined here was
                 carried out to show how the integrated representation
                 of the monument?s geometry together with the morphology
                 and distribution of the damage, the component materials
                 and their physical characteristics, the
                 historico-architectonic analysis and environmental
                 factors can be used to facilitate our understanding of
                 degradation processes. Identifying the Information
                 Technology (IT) as being able to create environments
                 that are typically suitable for the aims pursued and to
                 use as an operating instrument, it was decided to
                 translate the theoretical disciplinary model into a
                 computer-based procedure in which the functions
                 specific to the GIS- Geographic Information Systems-
                 were transposed to an architectonic scale. To this end
                 an Information System is currently being configured for
                 development in an AVENUE programming language (by
                 ESRI). It is designed for the organisation,
                 representation and utilisation of knowledge of data
                 regarding the architectonic item in question, its
                 immediate context and its territorial location.
                 Experimental results obtained for some actual
                 applications are presented.",
  keywords =     "GIS, Historical Architectural Heritage Recovery, Decay
                 And Preservation, Data Base, Network.",
  booktitle =    "WSCG 2000 Conference Proceedings",
}

@MastersThesis{EVL-2000-329,
  year =         "2000",
  title =        "Kr{\"u}mmungsvisualisierung f{\"u}r
                 3{D}-Vektorfelder",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-329",
  author =       "Tino Weinkauf",
  abstract =     "Tangent curves are a powerful tool for analysing and
                 visualizing vector fields. For sufficiently complicated
                 vector fields they can only be implicitly described.
                 However, in this work two of their most important
                 properties will be studied: their curvature and
                 torsion. Both of them can be computed only by knowing
                 the partial derivates of a vector field. Furthermore,
                 the new concept of normal surfaces and their Gaussian
                 and mean curvature will be introduced to the theory of
                 vector fields. For curvature, torsion, Gaussian and
                 mean curvature it can be shown that at least one of the
                 scalar fields describing these measures tends to
                 infinity in the neighborhood around a critical point of
                 a linear vector field. Therefore, the visualization of
                 those scalar fields has a topological relevance.
                 Several visualization techniques for this purpose will
                 be discussed. Furthermore, it can be shown that the
                 mean curvature uniquely describes linear vector fields
                 in canonical form.",
  month =        jun,
  keywords =     "3D flow visualization, vector field topology, tangent
                 curves, curvature",
  school =       "University of Rostock, Department of Computer
                 Sciences, Institute of Computer Graphics",
}

@InProceedings{EVL-2000-33,
  year =         "2000",
  title =        "Visions of Numerical Relativity",
  author =       "W. Benger and H.-C. Hege and S. Heusler",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-33",
  abstract =     "We present visualizations of recent supercomputer
                 simulations from numerical relativity, exploiting the
                 progress in visualization techniques and numerical
                 methods also from an artistic point of view. The
                 sequences have been compiled into a video tape, showing
                 colliding black holes, orbiting and merging neutron
                 stars as well as collapsing gravitational waves. In
                 this paper we give some background information and
                 provide a glance at the presented sequences.",
  month =        feb,
  address =      "ETH Z{\"u}rich, Switzerland",
  keywords =     "General Relativity, Data Visualization, Numerical
                 Simulations",
  booktitle =    "Proc. Science and Art 2000 (SCART 2000) - 3rd Int.
                 Conf. on the Interaction of Art and Fluid Mechanics",
}

@InProceedings{EVL-2000-330,
  pages =        "3--12",
  year =         "2000",
  title =        "An Advanced Color Representation for Lossy Compression
                 of {CMYK} Prepress Images",
  author =       "P. De Neve and K. Denecker and W. Philips and I.
                 Lemahieu",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-330",
  abstract =     "CMYK color images are used extensively in prepress
                 applications. When compressing those color images one
                 has to deal with four different color channels. Usually
                 compression algorithms only take into account the
                 spatial redundancy that is present in the image data.
                 This approach does not yield an optimal data reduction
                 since there also exists a high correlation between the
                 different colors in natural images. This paper shows
                 that a significant gain in data reduction can be
                 achieved by exploiting this color redundancy. Some
                 popular transform coders, including DCT-based JPEG and
                 the SPIHT wavelet coder, were used for reducing the
                 spatial redundancy. The performance of the algorithms
                 was evaluated using a quality criterion based on human
                 perception like the mean CIEL&ast;a&ast;b&ast;&Delta;E
                 error.",
  organization = "Eurographics Association",
  editor =       "David Duke and Sabine Coquillart and Toby Howard",
  volume =       "19(1)",
  booktitle =    "Computer Graphics Forum",
}

@InProceedings{EVL-2000-331,
  pages =        "13--25",
  year =         "2000",
  title =        "Efficient Glossy Global Illumination with Interactive
                 Viewing",
  author =       "Marc Stamminger and Annette Scheel and Xavier Granier
                 and Frederic Perez-Cazorla and George Drettakis and
                 Fran{\c{c}}ois Sillion",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-331",
  abstract =     "The ability to perform interactive walkthroughs of
                 global illumination solutions including glossy effects
                 is a challenging open problem. In this paper we
                 overcome certain limitations of previous approaches. We
                 first introduce a novel, memory- and compute-efficient
                 representation of incoming illumination, in the context
                 of a hierarchical radiance clustering algorithm. We
                 then represent outgoing radiance with an adaptive
                 hierarchical basis, in a manner suitable for
                 interactive display. Using appropriate refinement and
                 display strategies, we achieve walkthroughs of glossy
                 solutions at interactive rates for non-trivial scenes.
                 In addition, our implementation has been developed to
                 be portable and easily adaptable as an extension to
                 existing, diffuse-only, hierarchical radiosity systems.
                 We present results of the implementation of glossy
                 global illumination in two independent global
                 illumination systems.",
  organization = "Eurographics Association",
  editor =       "David Duke and Sabine Coquillart and Toby Howard",
  volume =       "19(1)",
  booktitle =    "Computer Graphics Forum",
}

@InProceedings{EVL-2000-332,
  pages =        "27--49",
  year =         "2000",
  title =        "Observational Models of Graphite Pencil Materials",
  author =       "Mario Costa Sousa and John W. Buchanan",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-332",
  abstract =     "This paper presents models for graphite pencil,
                 drawing paper, blenders, and kneaded eraser that
                 produce realistic looking pencil marks, textures, and
                 tones. Our models are based on an observation of how
                 lead pencils interact with drawing paper, and on the
                 absorptive and dispersive properties of blenders and
                 erasers interacting with lead material deposited over
                 drawing paper. The models consider parameters such as
                 the particle composition of the lead, the texture of
                 the paper, the position and shape of the pencil
                 materials, and the pressure applied to them. We
                 demonstrate the capabilities of our approach with a
                 variety of images and compare them to digitized pencil
                 drawings. We also present image-based rendering results
                 implementing traditional graphite pencil tone rendering
                 methods.",
  organization = "Eurographics Association",
  editor =       "David Duke and Sabine Coquillart and Toby Howard",
  volume =       "19(1)",
  booktitle =    "Computer Graphics Forum",
}

@InProceedings{EVL-2000-333,
  pages =        "51--64",
  year =         "2000",
  title =        "Texture-based Dither Matrices",
  author =       "Oleg Veryovka and John Buchanan",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-333",
  abstract =     "Continuous tone images must be halftoned to be
                 displayed on binary output devices such as printers.
                 Halftoning algorithms at low resolutions of the output
                 hardware introduce textures into the resulting display.
                 In this work we control halftoning texture by
                 generating a threshold matrix from an image-based
                 texture. We demonstrate that processing textures by the
                 adaptive histogram equalization algorithm approximates
                 pixel distribution properties of traditional dither
                 screens. Ordered dithering with the resulting threshold
                 matrix enables us to define texture in the halftoned
                 image. We control the appearance of this texture by a
                 combination of the ordered dither algorithm with an
                 error diffusion process. We present applications of
                 texture-based dither screens to both photorealistic and
                 artistic rendering. In the case of photorealistic tone
                 reproduction our technique preserves textures and edges
                 of the original image. The ability to define an
                 arbitrary texture enables us to introduce a variety of
                 artistic effects, including embossing of images with
                 textures and text, and approximation of the appearance
                 of of conventional illustration media. We evaluate the
                 resulting halftoning using multi-scale edge distortion
                 measures. Our quantitative evaluation closely
                 corresponds to the visual observations.",
  organization = "Eurographics Association",
  editor =       "David Duke and Sabine Coquillart and Toby Howard",
  volume =       "19(1)",
  booktitle =    "Computer Graphics Forum",
}

@InProceedings{EVL-2000-334,
  pages =        "65--76",
  year =         "2000",
  title =        "Geometrically-Aware Interactive Object Manipulation",
  author =       "Min-Hyung Choi and James F. Cremer",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-334",
  abstract =     "This paper describes formulation and management of
                 constraints, and a nonlinear optimization algorithm
                 that together enable interactive geometrically aware
                 manipulation of articulated objects. Going beyond
                 purely kinematic or dynamic approaches, our solution
                 method directly employs geometric constraints to ensure
                 non-interpenetration during object manipulation. We
                 present the formulation of the inequality constraints
                 used to ensure nonpenetration, describe how to manage
                 the set of active inequality constraints as objects
                 move, and show how these results are combined with a
                 nonlinear optimization algorithm to achieve interactive
                 geometrically aware object manipulation. Our
                 optimization algorithm handles equality and inequality
                 constraints and does not restrict object topology. It
                 is an efficient iterative algorithm, quadratically
                 convergent, with each iteration bounded by O(nnz(L)),
                 where nnz(L) is the number of non-zeros in L, a
                 Cholesky factor of a sparse matrix.",
  organization = "Eurographics Association",
  editor =       "David Duke and Sabine Coquillart and Toby Howard",
  volume =       "19(1)",
  booktitle =    "Computer Graphics Forum",
}

@InProceedings{EVL-2000-335,
  pages =        "101--110",
  year =         "2000",
  title =        "Automatic Camera Placement for Image-Based Modeling",
  author =       "Shachar Fleishman and Daniel Cohen-Or and Dani
                 Lischinski",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-335",
  abstract =     "We present an automatic camera placement method for
                 generating image-based models from scenes with known
                 geometry. Our method first approximately determines the
                 set of surfaces visible from a given viewing area and
                 then selects a small set of appropriate camera
                 positions to sample the scene from. We define a quality
                 measure for a surface as seen, or covered, from the
                 given viewing area. Along with each camera position, we
                 store the set of surfaces which are best covered by
                 this camera. Next, one reference view is generated from
                 each camera position by rendering the scene. Pixels in
                 each reference view that do not belong to the selected
                 set of polygons are masked out. The image-based model
                 generated by our method, covers every visible surface
                 only once, associating it with a camera position from
                 which it is covered with quality that exceeds a
                 user-specified quality threshold. The result is a
                 compact non-redundant image-based model with controlled
                 quality. The problem of covering every visible surface
                 with a minimum number of cameras (guards) can be
                 regarded as an extension to the well-known Art Gallery
                 Problem. However, since the 3D polygonal model is
                 textured, the camera-polygon visibility relation is not
                 binary; instead, it has a weight &mdash; the quality of
                 the polygonAEs coverage.",
  organization = "Eurographics Association",
  editor =       "David Duke and Sabine Coquillart and Toby Howard",
  volume =       "19(2)",
  booktitle =    "Computer Graphics Forum",
}

@InProceedings{EVL-2000-336,
  pages =        "111--122",
  year =         "2000",
  title =        "Dynamic Polygon Visibility Ordering for Head-Slaved
                 Viewing in Virtual Environments",
  author =       "Amela Sadagic and Mel Slater",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-336",
  abstract =     "This paper presents an approach to visibility called
                 the Viewpoint Movement Space (VpMS) algorithm which
                 supports the concept of dynamic polygon visibility
                 orderings for head-slaved viewing in virtual
                 environments (VE). The central idea of the approach is
                 that the visibility, in terms of back-to-front polygon
                 visibility ordering, does not change dramatically as
                 the viewpoint moves. Moreover, it is possible to
                 construct a partition of the space into cells, where
                 for each cell the ordering is invariant. As the
                 viewpoint moves across a cell boundary typically only a
                 small and predictable change is made to the visibility
                 ordering. The cost to perform this operation represents
                 a notable reduction when compared with the cost of
                 resolving the visibility information from the BSP tree
                 where the classification of the viewpoint with every
                 node plane has to be performed. The paper demonstrates
                 how the subdivision into such cells can represent the
                 basic source for an acceleration of the rendering
                 process. We also discuss how the same supportive data
                 structure can be exploited to solve other tasks in the
                 graphics pipeline.",
  organization = "Eurographics Association",
  editor =       "David Duke and Sabine Coquillart and Toby Howard",
  volume =       "19(2)",
  booktitle =    "Computer Graphics Forum",
}

@InProceedings{EVL-2000-337,
  pages =        "123--134",
  year =         "2000",
  title =        "Real-Time Simulation of a Stretcher Evacuation in a
                 Large-Scale Virtual Environment",
  author =       "Roger Hubbold and Martin Keates",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-337",
  abstract =     "This paper presents a case study of navigation and
                 manipulation in a large, geometrically complex, virtual
                 environment representing an off-shore gas platform. Our
                 approach is based on a combined force-field navigation
                 and collision detection algorithm. After describing the
                 basic algorithm, we extend and apply it to a real-time
                 simulation of two avatars carrying a third avatar on a
                 stretcher. The extensions include a probing technique,
                 using a virtual foot and simulated gravity, to permit
                 ascending and descending stairs and ladders. A set of
                 constraints between the stretcher and avatars enforces
                 realistic lifting positions. The simulation is
                 controlled interactively with a hand-held 3D mouse. The
                 force fields assist the user in manoeuvring through
                 tight spaces, while collision detection guarantees that
                 neither the stretcher nor the avatars can pass through
                 obstructions, such as pipe-work or hand-rails. Results
                 are presented for a case study of a complete simulation
                 running on a PC with a moderately fast 3D graphics
                 card. These demonstrate that the method delivers a
                 useful frame rate for the off-shore gas platform.",
  organization = "Eurographics Association",
  editor =       "David Duke and Sabine Coquillart and Toby Howard",
  volume =       "19(2)",
  booktitle =    "Computer Graphics Forum",
}

@InProceedings{EVL-2000-338,
  pages =        "135--151",
  year =         "2000",
  title =        "Wavelet Radiative Transfer and Surface Interaction",
  author =       "Robert R. Lewis and Alain Fournier",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-338",
  abstract =     "Recently, there has been considerable interest in the
                 representation of radiance in terms of wavelet basis
                 functions. We will present a coordinate system called
                 Nusselt coordinates which, when combined with wavelets,
                 considerably simplifies computation of radiative
                 transport and surface interaction. It also provides
                 straightforward computation of the physical quantities
                 involved. We show how to construct a discrete
                 representation of the radiative transport operator
                 &Tgr; involving inner products of smoothing functions,
                 discuss the possible numerical integration techniques,
                 and present an application. We also show how surface
                 interaction can be represented as a kind of matrix
                 product of the wavelet projections of an incident
                 radiance and a bidirectional reflectance distribution
                 function (BRDF).",
  organization = "Eurographics Association",
  editor =       "David Duke and Sabine Coquillart and Toby Howard",
  volume =       "19(2)",
  booktitle =    "Computer Graphics Forum",
}

@InProceedings{EVL-2000-339,
  pages =        "153--163",
  year =         "2000",
  title =        "Conflict Neutralization on Binary Space Partitioning",
  author =       "A. James and A. M. Day",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-339",
  abstract =     "The Binary Space Partitioning (BSP) tree achieves fast
                 hidden surface removal for most practical applications
                 where an observer can move through a scene of static
                 objects. However, the BSP algorithm generally increases
                 the number of polygons in a scene due to its splitting
                 stage resulting in a detrimental effect on the priority
                 ordering and more significantly, the display
                 calculations (shading, lighting, shadows, etc.) of the
                 rendering pipeline. We present the Conflict
                 Neutralization algorithm which attempts to reduce the
                 number of splits more effectively than existing
                 techniques whilst maintaining the standardAE model of a
                 BSP tree. Our idea is similar to Conflict Minimization
                 proposed by Fuchs; the significant difference is that
                 our algorithm recognizes that a polygon suitable for
                 selection in the Minimization criterion may
                 subsequently stop the remainder of polygons achieving
                 some reductions in cuts - with Conflict Neutralization,
                 such a polygon is demoted.",
  organization = "Eurographics Association",
  editor =       "David Duke and Sabine Coquillart and Toby Howard",
  volume =       "19(2)",
  booktitle =    "Computer Graphics Forum",
}

@InProceedings{EVL-2000-34,
  year =         "2000",
  title =        "Progress towards a combined {MRI}/hyperthermia
                 system",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-34",
  author =       "P. Deuflhard and H.-C. Hege and M. Seeba{\ss}",
  abstract =     "Regional hyperthermia, a clinical cancer therapy, is
                 the main topic of the Sonderforschungsbereich
                 ``Hyperthermia: Scientific Methods and Clinical
                 Applications at Berlin. In recent years, technological
                 improvements towards a better concentration of heat to
                 the desired target region have been achieved. These
                 include a rather sophisticated integrated software
                 environment for therapy planning and a new hyperthermia
                 applicator. In a next step, a detailed closed loop
                 monitoring of the actual treatment is to be developed.
                 For this purpose the hyperthermia applicator is
                 combined with an MRI system, which will allow to check
                 the positioning of the patients and to measure
                 individual blood perfusion as well as the 3D
                 temperature distribution. The measurements will then be
                 employed for an on-line control of the whole treatment.
                 In this intended setting, new fast feedback control
                 algorithms will come into play.",
  address =      "Bochum",
  month =        feb,
  editor =       "W. W. Gr{\"o}nemeyer",
  keywords =     "hyperthermia, medical therapy planning, applicator
                 design, interventional MRI",
  booktitle =    "Proc. Second Int. Congress HIGH CARE 2000",
}

@InProceedings{EVL-2000-340,
  pages =        "165--171",
  year =         "2000",
  title =        "Computation of Irradiance from Triangles by Adaptive
                 Sampling",
  author =       "C. Ure{\~{n}}a",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-340",
  abstract =     "We introduce an algorithm for sample positioning in a
                 planar triangle, which can be used to make numerical
                 integration of an arbitrary function defined on it.
                 This algorithm has some interesting properties which
                 make it suitable for applications in the context of
                 realistic rendering. We use an adaptive triangle
                 partitioning procedure, driven by an appropriate
                 measure of the error. The underlying variance is shown
                 to be bounded, and in fact it can be controlled, so
                 that it approaches the minimum possible value. We show
                 results obtained when applying the method to irradiance
                 computation, in the context of final-gather algorithms.
                 We also describe a C++ class which offers all required
                 functionality, and we made available its source code.",
  organization = "Eurographics Association",
  editor =       "David Duke and Sabine Coquillart and Toby Howard",
  volume =       "19(2)",
  booktitle =    "Computer Graphics Forum",
}

@InProceedings{EVL-2000-341,
  pages =        "173--184",
  year =         "2000",
  title =        "Hierarchical Reconstruction of {BRDF}s using Locally
                 Supported Functions",
  author =       "N. No{\'{e}} and B. P{\'{e}}roche",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-341",
  abstract =     "BRDFs are the backbone of realistic rendering
                 algorithms. Analytical models are sometimes ineffective
                 since they frequently cannot represent very particular
                 material characteristics (retro-reflection, anisotropy,
                 off-specularity, &hellip;). Consequently one might want
                 to use measured BRDF data directly; this leads to
                 solving the problem of BRDF reconstruction. In this
                 paper, we propose a new solution which uses locally
                 supported functions that lead to a hierarchical
                 approach able to take irregular distributions of
                 sampled data into account. This method is not
                 computationally expensive and guarantees a physically
                 valid reconstruction. We also discuss the quality of
                 the reconstruction, introducing some new error
                 parameters.",
  organization = "Eurographics Association",
  editor =       "David Duke and Sabine Coquillart and Toby Howard",
  volume =       "19(2)",
  booktitle =    "Computer Graphics Forum",
}

@InProceedings{EVL-2000-342,
  pages =        "195--212",
  year =         "2000",
  title =        "Variable Resolution 4-k Meshes: Concepts and
                 Application",
  author =       "Luiz Velho and Jonas Gomes",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-342",
  abstract =     "In this paper we introduce variable resolution 4-k
                 meshes, a powerful structure for the representation of
                 geometric objects at multiple levels of detail. It
                 combines most properties of other related descriptions
                 with several advantages, such as more flexibility and
                 greater expressive power. The main unique feature of
                 the 4-k mesh structure lies in its variable resolution
                 capability, which is crucial for adaptive computation.
                 We also give an overview of the different methods for
                 constructing the 4-k mesh representation, as well as
                 the basic algorithms necessary to incorporate it in
                 modeling and graphics applications.",
  organization = "Eurographics Association",
  editor =       "David Duke and Sabine Coquillart and Toby Howard",
  volume =       "19(4)",
  booktitle =    "Computer Graphics Forum",
}

@InProceedings{EVL-2000-343,
  pages =        "213--221",
  year =         "2000",
  title =        "Automatic Creation of Object Hierarchies for Radiosity
                 Clustering",
  author =       "Gordon M{\"{u}}ller and Stephan Sch{\"{a}}fer and W.
                 Dieter Fellner",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-343",
  abstract =     "Using object clusters for hierarchical radiosity
                 greatly improves the efficiency and thus usability of
                 radiosity computations. By eliminating the quadratic
                 starting phase very large scenes containing about 100k
                 polygons can be handled efficiently. Although the main
                 algorithm extends rather easily to using object
                 clusters, the creation of 'good' object hierarchies is
                 a difficult task both in terms of construction time and
                 in the way how surfaces or objects are grouped to
                 clusters. The quality of an object hierarchy for
                 clustering depends on its ability to accurately
                 simulate the hierarchy of the energy flow in a given
                 scene. Additionally it should support visibility
                 computations by providing efficient ray acceleration
                 techniques. In this paper we will present a new
                 approach of building hierarchies of object clusters.
                 Our hybrid structuring algorithm provides accuracy and
                 speed by combining a highly optimized bounding volume
                 hierarchy together with uniform spatial subdivisions
                 for nodes with regular object densities. The algorithm
                 works without user intervention and is well suited for
                 a wide variety of scenes. First results of using these
                 hierarchies in a radiosity clustering environment are
                 very promising and will be presented here. The
                 combination of very deep hierarchies (we use a binary
                 tree) together with an efficient ray acceleration
                 structure shifts the computational effort away from
                 form factor and visibility calculation towards
                 accurately propagating the energy through the
                 hierarchy. We will show how an efficient single pass
                 gathering can be used to minimize traversal costs.",
  organization = "Eurographics Association",
  editor =       "David Duke and Sabine Coquillart and Toby Howard",
  volume =       "19(4)",
  booktitle =    "Computer Graphics Forum",
}

@InProceedings{EVL-2000-344,
  pages =        "223--230",
  year =         "2000",
  title =        "Filtered Jitter",
  author =       "R. Victor Klassen",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-344",
  abstract =     "Jitter is one popular way of generating samples for
                 stochastic sampling in computer graphics. The Poisson
                 disk distribution better approximates that of the human
                 photomosaic. In this paper we examine the spatial and
                 frequency space behaviour of a number of existing
                 algorithms for generating stochastic samples and
                 propose a new algorithm based on low pass filtering a
                 jittered set of displacements. The distribution is at
                 least as much like that of the human photomosaic as any
                 existing algorithm, while being fast to compute.",
  organization = "Eurographics Association",
  editor =       "David Duke and Sabine Coquillart and Toby Howard",
  volume =       "19(4)",
  booktitle =    "Computer Graphics Forum",
}

@InProceedings{EVL-2000-345,
  pages =        "231--242",
  year =         "2000",
  title =        "Versatile Tuning of Humanoid Agent Activity",
  author =       "Luc Emering and Ronan Boulic and Tom Molet and Daniel
                 Thalmann",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-345",
  abstract =     "In this paper, we present an integration framework for
                 heterogeneous motion generators. The objective is to
                 outline issues that are currently easily solved in
                 professional post-processing systems used in film and
                 game production but which cannot be transposed as is to
                 real-time systems with autonomous agents. We summarise
                 our approach for articulated agent-modelling and their
                 animation by combining heterogeneous motion generators,
                 such as real-time motion capturing, key-framing,
                 inverse kinematics, procedural walking. We propose an
                 agent/action-oriented framework. Activity properties
                 such as action simultaneity and motion blending,
                 spatial coherence, motion-flow update schemes, agent
                 attachments, and location corrections, are the main
                 topics handled by our generic animation framework.
                 Numerous examples throughout the paper illustrate our
                 approach and outline encountered problems and solutions
                 or open research directions.",
  organization = "Eurographics Association",
  editor =       "David Duke and Sabine Coquillart and Toby Howard",
  volume =       "19(4)",
  booktitle =    "Computer Graphics Forum",
}

@InProceedings{EVL-2000-346,
  pages =        "243--256",
  year =         "2000",
  title =        "A Hybrid Approach for Stroke-Based Letterform
                 Composition Including Outline-Based Methods",
  author =       "Uwe Schneider",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-346",
  abstract =     "For three decades a number of computer-aided systems
                 have been developed in order to assist in the design of
                 digital type. Even though some of them are used by
                 typographers in commercial type design, they are not
                 yet widely accepted. One reason is the lack of
                 appropriate design metaphors in systems which provide
                 low-level operations (e.g. the manipulation of
                 outlines). Another reason is the lack of essential
                 functionality in high-level approaches (not all
                 characters can be modeled). While these two reasons
                 correspond with the underlying paradigms of those
                 systems, namely the outline and the stroke approach,
                 the presented model provides a synthesis of both. By
                 exploring the high-level semantics of the stroke-based
                 paradigm, letterforms can be composed by individual
                 strokes. Properties like round corners at stroke
                 intersections, as they typically appear in the design
                 of Western type, can be modeled via outline segments
                 attached to the associated stroke elements. As a
                 consequence, Latin characters as well as characters
                 incorporating hand-written characters, like Kanji, can
                 be expressed using a single model. These two classes of
                 types are considered by the typographic community to be
                 fundamentaly different.",
  organization = "Eurographics Association",
  editor =       "David Duke and Sabine Coquillart and Toby Howard",
  volume =       "19(4)",
  booktitle =    "Computer Graphics Forum",
}

@InProceedings{EVL-2000-347,
  pages =        "257--270",
  year =         "2000",
  title =        "Morphing the BlobTree",
  author =       "Eric Galin and Antoine Leclercq and Samir Akkouche",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-347",
  abstract =     "Implicit surfaces have proved to be a particularly
                 well suited and efficient model for animating and
                 morphing shapes of arbitrary topologies. The BlobTree
                 model is characterized as a hierarchical combination of
                 skeletal primitives organized in a tree. The nodes hold
                 blending, boolean and warping operators, which allows
                 the design of complex objects. In this paper, we
                 address the metamorphosis of the BlobTree. This appears
                 a difficult task as the tree data-structures of the
                 initial and final shapes are completely different in
                 the general case, and consequently cannot be matched
                 easily. We propose an original technique that solves
                 the correspondence process and creates an intermediate
                 generic BlobTree model whose instances interpolate the
                 initial and final shapes. The animator may control the
                 correspondence between features and can specify both
                 the speed of transformation and the trajectory of the
                 nodes and the leaves of the generic BlobTree model.
                 This provides the end user with a tight control over
                 the transformation so as to achieve good visual
                 effects.",
  organization = "Eurographics Association",
  editor =       "David Duke and Sabine Coquillart and Toby Howard",
  volume =       "19(4)",
  booktitle =    "Computer Graphics Forum",
}

@InProceedings{EVL-2000-348,
  pages =        "271--279",
  year =         "2000",
  title =        "Perceptual Principles and Computer Graphics",
  author =       "Jon May",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-348",
  abstract =     "Now that technology allows us to present
                 photorealistic animations of scenically lit objects
                 acting in real-time, the problem of computer graphics
                 has changed from making displays recognisable, to
                 ensuring that users notice what they are intended to
                 see, without being distracted by irrelevant
                 information. Worse than that, the use of veridical
                 displays that are intended to be lifelike runs the risk
                 of introducing unpredictable sources of information,
                 that can lead users to infer all sorts of unwanted
                 details. Traditional visual theory, based upon
                 bottom-up models of feature extraction from the retinal
                 image, cannot inform us about these aspects of
                 perception. Broader based cognitive theories are
                 required that integrate visual perception with
                 attention, memory, emotion and inference. Theories such
                 as BarnardAEs Interacting Cognitive Subsystems enable
                 phenomena such as change blindness and the craft
                 principles of film editing to be interpreted within a
                 common framework, supporting extrapolation to computer
                 graphics.",
  organization = "Eurographics Association",
  editor =       "David Duke and Sabine Coquillart and Toby Howard",
  volume =       "19(4)",
  booktitle =    "Computer Graphics Forum",
}

@InProceedings{EVL-2000-349,
  pages =        "281--293",
  year =         "2000",
  title =        "Constructive Volume Geometry",
  author =       "Min Chen and John V. Tucker",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-349",
  abstract =     "We present an algebraic framework, called Constructive
                 Volume Geometryn (CVG), for modelling complex spatial
                 objects using combinational operations. By utilising
                 scalar fields as fundamental building blocks, CVG
                 provides high-level algebraic representations of
                 objects that are defined mathematically or built upon
                 sampled or simulated datasets. It models amorphous
                 phenomena as well as solid objects, and describes the
                 interior as well as the exterior of objects. We also
                 describe a hierarchical representation scheme for CVG,
                 and a direct rendering method with a new approach for
                 consistent sampling. The work has demonstrated the
                 feasibility of combining a variety of graphics data
                 types in a coherent modelling scheme.",
  organization = "Eurographics Association",
  editor =       "David Duke and Sabine Coquillart and Toby Howard",
  volume =       "19(4)",
  booktitle =    "Computer Graphics Forum",
}

@InCollection{EVL-2000-35,
  title =        "Efficient Distributed File {IO} for Visualization in
                 Grid Environments",
  editor =       "B. Engquist and L. Johnson and M. Hammill and F.
                 Short",
  series =       "Lecture Notes in Computational Science and
                 Engineering",
  booktitle =    "Simulation and Visualization on the Grid",
  publisher =    "Springer-Verlag",
  pages =        "1--16",
  year =         "2000",
  author =       "W. Benger and H.-C. Hege and A. Merzky and T. Radke
                 and E. Seidel",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-35",
  abstract =     "Large scale simulations running in metacomputing
                 environments face the problem of efficient file I/O.
                 For efficiency it is desirable to write data locally,
                 distributed across the computing environment, and then
                 to minimize data transfer, i.e. reduce remote file
                 access. Both aspects require I/O approaches which
                 differ from existing paradigms. For the data output of
                 distributed simulations, one wants to use fast local
                 parallel I/O for all participating nodes, producing a
                 single distributed logical file, while keeping changes
                 to the simulation code as small as possible. For
                 reading the data file as in postprocessing and file
                 based visualization, one wants to have efficient
                 partial access to remote and distributed files, using a
                 global naming scheme and efficient data caching, and
                 again keeping the changes to the postprocessing code
                 small. However, all available software solutions
                 require the entire data to be staged locally (involving
                 possible data recombination and conversion), or suffer
                 from the performance problems of remote or distributed
                 file systems. In this paper we show how to interface
                 the HDF5 I/O library via its flexible Virtual File
                 Driver layer to the Globus Data Grid. We show, that
                 combining these two toolkits in a suitable way provides
                 us with a new I/O framework, which allows efficient,
                 secure, distributed and parallel file I/O in a
                 metacomputing environment.",
  volume =       "13",
  keywords =     "Grid, Data Grid, Globus, HDF5, Cactus, CCTK, Amira,
                 VFD, Storage System",
}

@Book{EVL-2000-350,
  year =         "2000",
  title =        "Visualisierung im Dokument Retrieval - Theoretische
                 und praktische Zusammenf{\"{u}}hrung von
                 Softwareergonomie und Graphik Design",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-350",
  author =       "Maximilian Eibl",
  abstract =     "Ausgangspunkt der vorliegenden Arbeit ist die
                 Fragestellung, wie Anwender von Dokument
                 Retrievalsystemen bei der Formulierung einer Anfrage
                 unterst{\"{u}}tzt werden k{\"{o}}nnen. Bei der
                 Beantwortung dieser Frage gilt es zun{\"{a}}chst, die
                 verschiedenen Modelle des Dokument Retrieval auf ihre
                 St{\"{a}}rken und Schw{\"{a}}chen hin zu untersuchen.
                 Es werden hier drei exemplarische Retrievalmodelle
                 herausgegriffen, die sich in ihrer Recherchegrundlage
                 und Relevanzbehandlung stark voneinander unterscheiden:
                 das Boolesche, das probabilistische und das vage
                 Retrievalmodell. Um den Recherchezugang beim Einsatz
                 dieser Retrievalmodelle anwenderfreundlich zu gestalten
                 wird auf das Mittel der Visualisierung
                 zur{\"{u}}ckgegriffen. In ihr wird eine gute
                 M{\"{o}}glichkeit gesehen, mit komplexer Information
                 umzugehen, da sie im Gegensatz zu textbasierten
                 Pr{\"{a}}sentationsformen der optisch ausgerichteten
                 menschlichen Kognition sehr weit entgegenkommen kann.
                 Jedoch zeigen zahlreiche Beispiele, da{\ss{}}
                 Visualisierung keinesfalls als Allheilmittel gelten
                 kann, sondern im Gegenteil sogar zu einer
                 Komplexit{\"{a}}tssteigerung der Materie f{\"{u}}hren
                 kann. Eine genauere Analyse bereits bestehender
                 Ans{\"{a}}tze weist denn auch softwareergonomische
                 Probleme nach und l{\"{a}}{\ss{}}t die Neukonzeption
                 einer Visualisierung aus softwareergonomischer Sicht
                 notwendig erscheinen. Neben softwareergonomischen
                 {\"{U}}berlegungen flie{\ss{}}en auch Aspekte des
                 Graphik Design in die Konzeption der Visualisierung mit
                 ein. Dies ist insofern ein Novum, als beide Schulen
                 einander bislang weitgehend ignorierten. Mit Hilfe des
                 Graphik Design kann der Visualisierung eine
                 ansprechendere Gestaltung gegeben werden, die eine
                 erh{\"{o}}hte Anwenderakzeptanz bewirkt. Um die
                 Kooperation von Softwareergonomie und Graphik Design
                 auf eine allgemeing{\"{u}}ltige Basis stellen zu
                 k{\"{o}}nnen, wird auch eine theoretische
                 Zusammenf{\"{u}}hrung vorgeschlagen. Auf der Basis
                 dieser Vor{\"{u}}berlegungen wird eine Visualisierung
                 vorgestellt, welche Aspekte der drei Retrievalmodelle
                 integriert: In ihrer Grundkonzeption erm{\"{o}}glicht
                 sie Boolesche Recherche. In zwei Erweiterungen werden
                 ein probabilistisches Rankingverfahren sowie die
                 M{\"{o}}glichkeit der Erweiterung der Ergebnismenge
                 durch vage Methoden zur Verf{\"{u}}gung gestellt.
                 Optisch verfolgt die Visualisierung ein
                 minimalistisches Design. Es werden zu eingegebenen
                 Suchkriterien s{\"{a}}mtliche m{\"{o}}glichen
                 Kombinationen mit der entsprechenden Anzahl der
                 gefundenen Dokumente angezeigt. Die Codierung der
                 Kombinationen erfolgt dabei rein {\"{u}}ber die
                 Farbgebung, die durch die Farben der enthaltenen
                 Suchkriterien bestimmt wird. Je nachdem, welche
                 Erweiterung verwendet wird, ver{\"{a}}ndert sich die
                 Gestaltung der Visualisierung: Wird das
                 probabilistische Rankigverfahren eingesetzt, so wird
                 die Position der Kombinationen auf dem Bildschirm neu
                 berechnet. Wird vages Retrieval eingesetzt, so erhalten
                 die erweiterten Mengen ein neues graphisches Element.
                 Um die G{\"{u}}te der Visualisierung zu ermitteln, wird
                 sie in einem Nutzertest evaluiert. Es werden klassische
                 Retrievalma{\ss{}}e wie Recall und Precision ermittelt,
                 sowie in einem Fragebogen die Anwenderakzeptanz
                 eruiert. Die Ergebnisse des Tests untermauern die zwei
                 grundlegenden Thesen dieser Arbeit: Visualisierung ist
                 ein sinnvolles Mittel, die Schwierigkeiten der
                 Interaktion mit Dokument Retrievalsystemen zu
                 minimieren. Und die Integration von Softwareergonomie
                 und Graphik Design ist nicht nur sowohl theoretisch als
                 auch praktisch m{\"{o}}glich, sondern in der Tat auch
                 vorteilhaft.",
  address =      "Informationszentrum Sozialwissenschaften / Lennestr.
                 30 / 53113 Bonn / Germany",
  note =         "ISBN: 3-8206-0131-7",
  keywords =     "Visualisierung, Document Retrieval, Information
                 Retrieval, Graphik Design, HCI, Softwareergonomie,
                 usability",
  series =       "Forschungsberichte Band 3",
  publisher =    "IZ-Sozialwissenschaften, Bonn",
}

@InProceedings{EVL-2000-351,
  year =         "2000",
  title =        "Information Retrieval Design",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-351",
  author =       "Maximilian Eibl",
  month =        oct,
  booktitle =    "Social Science Methodology in the New Millenium -
                 Fifth International Conference on Logic and
                 Methodology",
  publisher =    "TT-Publikaties, ISBN 90-801073-8-7",
}

@InCollection{EVL-2000-352,
  pages =        "246--278",
  year =         "2000",
  title =        "Theory and application of specular path perturbation",
  author =       "Min Chen and James Arvo",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-352",
  abstract =     "In this paper we apply perturbation methods to the
                 problem of computing specular reflections in curved
                 surfaces. The key idea is to generate families of
                 closely related optical paths by expanding a given path
                 into a high-dimensional Taylor series. Our path
                 perturbation method is based on closed-form expressions
                 for linear and higher-order approximations of ray
                 paths, which are derived using Fermat's Variation
                 Principle and the Implicit Function Theorem (IFT). The
                 perturbation formula presented here holds for general
                 multiple-bounce reflection paths and provides a
                 mathematical foundation for exploiting path coherence
                 in ray tracing acceleration techniques and incremental
                 rendering. To illustrate its use, we describe an
                 algorithm for fast approximation of specular
                 reflections on curved surfaces; the resulting images
                 are highly accurate and nearly indistinguishable from
                 ray traced images.",
  volume =       "19(4)",
  keywords =     "Taylor series, implicit surfaces, optics, perturbation
                 theory, specular reflection",
  booktitle =    "ACM Transactions on Graphics",
  publisher =    "ACM Press",
}

@InCollection{EVL-2000-353,
  pages =        "279--301",
  year =         "2000",
  title =        "A variational method to model {G1} surfaces over
                 triangular meshes of arbitrary topology in {R3}",
  author =       "Ramon F. Sarraga G",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-353",
  abstract =     "This article presents a method for constructing a
                 G1-smooth surface, composed of independently
                 parametrized triangular polynomial B{\'{e}}zier
                 patches, to fit scattered data points triangulated in
                 R3 with arbitrary topology. The method includes a
                 variational technique to optimize the shape of the
                 surface. A systematic development of the method is
                 given, presenting general equations provided by the
                 theory of manifolds, explaining the heuristic
                 assumptions made to simplify calculations, and
                 analyzing the numerical results obtained from fitting
                 two test configurations of scattered data points. The
                 goal of this work is to explore an alternative G3
                 construction, inspired by the theory of manifolds, that
                 is subject to fewer application constraints than
                 approaches found in the technical literature; e.g.,
                 this approach imposes no artificial restrictions on the
                 tangents of patch boundary curves at vertex points of a
                 G1 surface. The constructed surface shapes fit all test
                 data surprisingly well for for a noniterative method
                 based on polynomial patches.",
  volume =       "19(4)",
  keywords =     "G1 smoothness, computer-aided geometric design,
                 mathematical manifolds, scattered data interpolation,
                 shape optimization, smoothing, surface modeling,
                 triangular B{\'{e}}zier patches, variational methods",
  booktitle =    "ACM Transactions on Graphics",
  publisher =    "ACM Press",
}

@InCollection{EVL-2000-354,
  pages =        "302--342",
  year =         "2000",
  title =        "Texture-based visibility for efficient lighting
                 simulation",
  author =       "Cyril Soler and F. X. Sillion",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-354",
  abstract =     "Lighting simulations using hierarchical radiosity with
                 clustering can be very slow when the computation of
                 fine and artifact-free shadows is needed. To avoid the
                 high cost of mesh refinement associated with fast
                 variations of visibility across receivers, we propose a
                 new hierarchical algorithm in which partial visibility
                 maps can be computed on the fly, using a convolution
                 technique for emitter-receiver configurations where
                 complex shadows are produced. Other configurations
                 still rely on mesh subdivision to reach the desired
                 accuracy in modeling energy transfer. In our system,
                 therefore, radiosity is represented as a combination of
                 textures and piecewise-constant or linear contributions
                 over mesh elements at multiple hierarchical levels. We
                 give a detailed description of the gather, push/pull,
                 and display stages of the hierarchical radiosity
                 algorithm, adapted to seamlessly integrate both
                 representations. A new refinement algorithm is
                 proposed, which chooses the most appropriate technique
                 to compute the energy transfer and resulting radiosity
                 distribution for each receiver/transmitter
                 configuration. Comprehensive error control is achieved
                 by subdividing either the source or receiver in a
                 traditional manner, or by using a blocker subdivision
                 scheme that improves the quality of shadow masks
                 without increasing the complexity of the mesh. Results
                 show that high-quality images are obtained in a matter
                 of seconds for scenes with tens of thousands of
                 polygons.",
  volume =       "19(4)",
  keywords =     "Convolution, global illumination, hierarchical
                 radiosity, texture-based visibility",
  booktitle =    "ACM Transactions on Graphics",
  publisher =    "ACM Press",
}

@InCollection{EVL-2000-355,
  pages =        "289--305",
  year =         "2000",
  title =        "Interactive Virtual Relighting of Real Scenes",
  author =       "C{\'{e}}line Loscos and George Drettakis and Luc
                 Robert",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-355",
  abstract =     "Computer augmented reality (CAR) is a rapidly emerging
                 field which enables users to mix real and virtual
                 worlds. Our goal is to provide interactive tools to
                 perform common illumination, i.e., light interactions
                 between real and virtual objects, including shadows and
                 relighting (real and virtual light source
                 modification). In particular, we concentrate on
                 virtually modifying real light source intensities and
                 inserting virtual lights and objects into a real scene;
                 such changes can be very useful for virtual lighting
                 design and prototyping. To achieve this, we present a
                 three-step method. We first reconstruct a simplified
                 representation of real scene geometry using
                 semiautomatic vision-based techniques. With the
                 simplified geometry, and by adapting recent
                 hierarchical radiosity algorithms, we construct an
                 approximation of real scene light exchanges. We next
                 perform a preprocessing step, based on the radiosity
                 system, to create unoccluded illumination textures.
                 These replace the original scene textures which
                 contained real light effects such as shadows from real
                 lights. This texture is then modulated by a ratio of
                 the radiosity (which can be changed) over a display
                 factor which corresponds to the radiosity for which
                 occlusion has been ignored. Since our goal is to
                 achieve a convincing relighting effect, rather than an
                 accurate solution, we present a heuristic correction
                 process which results in visually plausible renderings.
                 Finally, we perform an interactive process to compute
                 new illumination with modified real and virtual light
                 intensities. Our results show that we are able to
                 virtually relight real scenes interactively, including
                 modifications and additions of virtual light sources
                 and objects.",
  volume =       "6(4)",
  booktitle =    "IEEE Transactions on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2000-356,
  pages =        "306--318",
  year =         "2000",
  title =        "A {BRDF} Postprocess to Integrate Porosity on Rendered
                 Surfaces",
  author =       "St{\'{e}}phane M{\'{e}}rillou and Jean-Michel Dischler
                 and Djamchid Ghazanfarpour",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-356",
  abstract =     "The behavior of light interacting with materials is a
                 crucial factor in achieving a high degree of realism in
                 image synthesis. Local illumination processes,
                 describing the interactions between a point of the
                 surface and a shading ray, are evaluated by
                 Bidirectional Reflectance Distribution Functions
                 (BRDFs). Current theoretical BRDFs use surface models
                 restricted to roughness only, sometimes at different
                 scales. In this paper, we present a more complete
                 surface micro-geometry description, suitable for some
                 common surface defects, including porosity and
                 micro-cracks; both of them are crucial surface features
                 since they strongly influence light reflection
                 properties. These new features are modeled by holes
                 inserted in the surface profile, depending on two
                 parameters: the proportion of surface covered by the
                 defects and the mean geometric characteristic of these
                 defects. In order to preserve the advantages and
                 characteristics of existing BRDFs, a postprocessing
                 method is adopted (we integrate our technique into
                 existing models, instead of defining a completely new
                 one). Beyond providing graphical results closely
                 matching real behaviors, this method moreover opens the
                 way to various important new considerations in computer
                 graphics (for example, changes of appearance due to the
                 degree of humidity).",
  volume =       "6(4)",
  booktitle =    "IEEE Transactions on Visualization",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2000-357,
  pages =        "319--334",
  year =         "2000",
  title =        "Analysis of Head Pose Accuracy in Augmented Reality",
  author =       "William Hoff and Tyrone Vincent",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-357",
  abstract =     "A method is developed to analyze the accuracy of the
                 relative head-to-object position and orientation (pose)
                 in augmented reality systems with head-mounted
                 displays. From probabilistic estimates of the errors in
                 optical tracking sensors, the uncertainty in
                 head-to-object pose can be computed in the form of a
                 covariance matrix. The positional uncertainty can be
                 visualized as a 3D ellipsoid. One useful benefit of
                 having an explicit representation of uncertainty is
                 that we can fuse sensor data from a combination of
                 fixed and head-mounted sensors in order to improve the
                 overall registration accuracy. The method was applied
                 to the analysis of an experimental augmented reality
                 system, incorporating an optical see-through
                 head-mounted display, a head-mounted CCD camera, and a
                 fixed optical tracking sensor. The uncertainty of the
                 pose of a movable object with respect to the
                 head-mounted display was analyzed. By using both fixed
                 and head mounted sensors, we produced a pose estimate
                 that is significantly more accurate than that produced
                 by either sensor acting alone.",
  volume =       "6(4)",
  booktitle =    "IEEE Transactions on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2000-358,
  pages =        "335--345",
  year =         "2000",
  title =        "An Order of Magnitude Faster Isosurface Rendering in
                 Software on a {PC} than Using Dedicated, General
                 Purpose Rendering Hardware",
  author =       "George J. Grevera and Jayaram K. Udupa and Dewey
                 Odhner",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-358",
  abstract =     "The purpose of this work is to compare the speed of
                 isosurface rendering in software with that using
                 dedicated hardware. Input data consist of 10 different
                 objects from various parts of the body and various
                 modalities (CT, MR, and MRA) with a variety of surface
                 sizes (up to 1 million voxels/2 million triangles) and
                 shapes. The software rendering technique consists of a
                 particular method of voxel-based surface rendering,
                 called shell rendering. The hardware method is
                 OpenGL-based and uses the surfaces constructed from our
                 implementation of the ?Marching Cubes? algorithm. The
                 hardware environment consists of a variety of
                 platforms, including a Sun Ultra I with a Creator3D
                 graphics card and a Silicon Graphics Reality Engine II,
                 both with polygon rendering hardware, and a 300Mhz
                 Pentium PC. The results indicate that the software
                 method (shell rendering) was 18 to 31 times faster than
                 any hardware rendering methods. This work demonstrates
                 that a software implementation of a particular
                 rendering algorithm (shell rendering) can outperform
                 dedicated hardware. We conclude that, for medical
                 surface visualization, expensive dedicated hardware
                 engines are not required. More importantly, available
                 software algorithms (shell rendering) on a 300Mhz
                 Pentium PC outperform the speed of rendering via
                 hardware engines by a factor of 18 to 31.",
  volume =       "6(4)",
  booktitle =    "IEEE Transactions on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InCollection{EVL-2000-359,
  pages =        "346--359",
  year =         "2000",
  title =        "Calibration-Free Augmented Reality in Perspective",
  author =       "Yongduek Seo and Ki Sang Hong",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-359",
  abstract =     "This paper deals with video-based augmented reality
                 and proposes an algorithm for augmenting a real video
                 sequence with views of graphics objects without metric
                 calibration of the video camera by representing the
                 motion of the video camera in projective space. A
                 virtual camera, by which views of graphics objects are
                 generated, is attached to a real camera by specifying
                 image locations of the world coordinate system of the
                 virtual world. The virtual camera is decomposed into
                 calibration and motion components in order to make full
                 use of graphics tools. The projective motion of the
                 real camera recovered from image matches has the
                 function of transferring the virtual camera and makes
                 the virtual camera move according to the motion of the
                 real camera. The virtual camera also follows the change
                 of the internal parameters of the real camera. This
                 paper shows the theoretical and experimental results of
                 our application of nonmetric vision to augmented
                 reality.",
  volume =       "6(4)",
  booktitle =    "IEEE Transactions on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@Article{EVL-2000-36,
  pages =        "241--253",
  year =         "2000",
  title =        "Fast and Intuitive Generation of Geometric Shape
                 Transitions",
  author =       "Malte Z{\"o}ckler and Detlev Stalling and
                 Hans-Christian Hege",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-36",
  abstract =     "We describe a novel method for continuously
                 transforming two triangulated models of arbitrary
                 topology into each other. Equal global topology for
                 both objects is assumed, extensions for genus changes
                 during metamorphosis are provided. The proposed method
                 addresses the major challenge in 3D metamorphosis,
                 namely specifying the morphing process intuitively,
                 with minimal user interaction and sufficient detail.
                 Corresponding regions and point features are
                 interactively identified. These regions are
                 parametrized automatically and consistently, providing
                 a basis for smooth interpolation. Utilizing suitable 3D
                 interaction techniques a simple and intuitive control
                 over the whole morphing process is offered.",
  keywords =     "morphing, surface parametrization, shape transition",
  volume =       "16",
  number =       "5",
  journal =      "The Visual Computer",
}

@InCollection{EVL-2000-360,
  year =         "2000",
  title =        "Perception-Based Fast Rendering and Antialiasing of
                 Walkthrough Sequences",
  author =       "Karol Myszkowski and Przemyslaw Rokita and Takehiro
                 Tawara",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-360",
  abstract =     "In this paper, we consider accelerated rendering of
                 high quality walkthrough animation sequences along
                 predefined paths. To improve rendering performance, we
                 use a combination of a hybrid ray tracing and
                 Image-Based Rendering (IBR) technique and a novel
                 perception-based antialiasing technique. In our
                 rendering solution, we derive as many pixels as
                 possible using inexpensive IBR techniques without
                 affecting the animation quality. A perception-based
                 spatiotemporal Animation Quality Metric (AQM) is used
                 to automatically guide such a hybrid rendering. The
                 Image Flow (IF) obtained as a byproduct of the IBR
                 computation is an integral part of the AQM. The final
                 animation quality is enhanced by an efficient
                 spatiotemporal antialiasing which utilizes the IF to
                 perform a motion-compensated filtering. The filter
                 parameters have been tuned using the AQM predictions of
                 animation quality as perceived by the human observer.
                 These parameters adapt locally to the visual pattern
                 velocity.",
  volume =       "6(4)",
  booktitle =    "IEEE Transactions on Visualization and Computer
                 Graphics",
  publisher =    "IEEE Computer Society",
}

@InProceedings{EVL-2000-361,
  pages =        "3--10",
  year =         "2000",
  title =        "Multi-resolution Amplification Widgets",
  author =       "Kiril Vidimce and David Banks",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-361",
  abstract =     "We describe a 3D graphical interaction tool called an
                 amplification widget that allows a user to control the
                 position or orientation of an object at multiple
                 scales. Fine and coarse adjustments are available
                 within a single tool which gives visual feedback to
                 indicate the level of resolution being applied.
                 Amplification widgets have been included in
                 instructional modules of The Optics Project, designed
                 to supplement undergraduate physics courses. The user
                 evaluation is being developed by the Institute of the
                 Mid-South Educational Research Association under the
                 sponsorship of a 2-year grant from the National Science
                 Foundation.",
  keywords =     "3D widgets, user interface, interactive control",
  booktitle =    "Proceedings of Graphics Interface 2000",
}

@InProceedings{EVL-2000-362,
  pages =        "11--18",
  year =         "2000",
  title =        "Navigating Complex Information with the {ZT}ree",
  author =       "Lyn Bartram and Axel Uhl and Tom Calvert",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-362",
  abstract =     "This paper discusses navigation issues in large-scale
                 databases and proposes hypermap visualizations as
                 effective navigational views. We describe the ZTree, a
                 technique that allows users to explore both
                 hierarchical and relational aspects of the information
                 space. The ZTree uses a fisheye map layout that aids
                 the user in current navigational decisions and provides
                 a history of previous information retrieval paths.",
  keywords =     "Information visualization, interactive techniques",
  booktitle =    "Graphics Interface 2000",
}

@InProceedings{EVL-2000-363,
  pages =        "19--26",
  year =         "2000",
  title =        "The Effects of Feedback on Targeting Performance in
                 Visually Stressed Conditions",
  author =       "Julie Fraser and Carl Gutwin",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-363",
  abstract =     "In most graphical user interfaces, a substantial
                 proportion of the user's interaction involves targeting
                 screen objects with the mouse cursor. Targeting tasks
                 with small targets are visually demanding, and can
                 cause users difficulty in some circumstances. These
                 circumstances can arise either if the user has a visual
                 disability or if factors such as fatigue or glare
                 diminish acuity. One way of reducing the perceptual
                 demands of targeting is to add redundant feedback to
                 the interface that indicates when the user has
                 successfully acquired a target. Under optimal viewing
                 conditions, such feedback has not significantly
                 improved targeting performance. However, we
                 hypothesized that targeting feedback would be more
                 beneficial in a visually stressed situation. We carried
                 out an experiment in which normally-sighted
                 participants in a reduced-acuity environment carried
                 out targeting tasks with a mouse. We found that people
                 were able to select targets significantly faster when
                 they were given targeting feedback, and that they made
                 significantly fewer errors. People also greatly
                 preferred interfaces with feedback to those with none.
                 The results suggest that redundant targeting feedback
                 can improve the usability of graphical interfaces for
                 low-vision users, and also for normally-sighted users
                 in visually stressed environments.",
  keywords =     "Extraordinary HCI, accessibility, low-vision users,
                 targeting, redundant feedback",
  booktitle =    "Proceedings of Graphics Interface 2000",
}

@InProceedings{EVL-2000-364,
  pages =        "27--34",
  year =         "2000",
  title =        "Fast and Controllable Simulation of the Shattering of
                 Brittle Objects",
  author =       "Jeffrey Smith and Andrew Witkin and David Baraff",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-364",
  abstract =     "We present a method for the rapid and controllable
                 simulation of the shattering of brittle objects under
                 impact. An object to be broken is represented as a set
                 of point masses connected by distance-preserving linear
                 constraints. This use of constraints, rather than stiff
                 springs, gains us a significant advantage in speed
                 while still retaining fine control over the fracturing
                 behavior. The forces exerted by these constraints
                 during impact are computed using Lagrange multipliers.
                 These constraint forces are then used to determine when
                 and where the object will break, and to calculate the
                 velocities of the newly created fragments. We present
                 the details of our technique together with examples
                 illustrating its use.",
  keywords =     "Physically-based modeling, computer animation, impact,
                 brittle materials",
  booktitle =    "Proceedings of Graphics Interface 2000",
}

@InProceedings{EVL-2000-365,
  pages =        "35--42",
  year =         "2000",
  title =        "Skinning Characters using Surface Oriented Free-Form
                 Deformations",
  author =       "Karan Singh and Evangelos Kokkevis",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-365",
  abstract =     "Skinning geometry effectively continues to be one of
                 the more challenging and time consuming aspects of
                 character setup. While anatomic and physically based
                 approaches to skinning have been investigated, many
                 skinned objects have no physical equivalents. Geometric
                 approaches, which are more general and provide finer
                 control, are thus predominantly used in the animation
                 industry. Free-form deformations (FFD) are a powerful
                 paradigm for the manipulation of deformable objects.
                 Skinning objects indirectly using an FFD lattice
                 reduces the geometric complexity that needs to be
                 controlled by a skeleton. Many techniques have extended
                 the original box-shaped FFD lattices to more general
                 control lattice shapes and topologies, while preserving
                 the notion of embedding objects within a lattice
                 volume. This paper in contrast, proposes a
                 surface-oriented FFD, where the space deformed by the
                 control surface is defined by a distance function
                 around the surface. Surface-oriented control structures
                 bear a strong visual resemblance to the geometry they
                 deform and can be constructed from the deformable
                 geometry automatically. They also allow localization of
                 control lattice complexity and deformation detail,
                 making them ideally suited to the automated skinning of
                 characters. This approach has been successfully
                 implemented within the Maya2.0 animation system.",
  keywords =     "Character animation, skinning, deformers, free-form
                 deformations",
  booktitle =    "Proceedings of Graphics Interface 2000",
}

@InProceedings{EVL-2000-366,
  pages =        "45--52",
  year =         "2000",
  title =        "Dynamic Time Warp Based Framespace Interpolation for
                 Motion Editing",
  author =       "Ashraf Golam and Kok Cheong Wong",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-366",
  abstract =     "Motion capture (MOCAP) data clips can be visualized as
                 a sequence of densely spaced curves, defining the joint
                 angles of the articulated figure, over a specified
                 period of time. Current research has focussed on
                 frequency and time domain techniques to edit these
                 curves, preserving the original qualities of the motion
                 yet making it reusable in different spatio-temporal
                 situations. We refine Guo et. al.'s{\ci}te{Guo96}
                 framespace interpolation algorithm which abstracts
                 motion sequences as 1D signals, and interpolates
                 between them to create higher dimension signals. Our
                 method is more suitable for (though not limited to)
                 editing densely spaced MOCAP data, than the existing
                 algorithm. It achieves consistent motion transition
                 through motion-state based dynamic warping of
                 framespaces and automatic transition timing via
                 framespace frequency interpolation.",
  keywords =     "Motion editing, framespace interpolation, blending,
                 concatenation, motion correspondence",
  booktitle =    "Proceedings of Graphics Interface 2000",
}

@InProceedings{EVL-2000-367,
  pages =        "53--60",
  year =         "2000",
  title =        "Automatic Joint Parameter Estimation from Magnetic
                 Motion Capture Data",
  author =       "James O'Brien and Robert Bodenheimer and Gabriel
                 Brostow and Jessica Hodgins",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-367",
  abstract =     "This paper describes a technique for using magnetic
                 motion capture data to determine the joint parameters
                 of an articulated hierarchy. This technique makes it
                 possible to determine limb lengths, joint locations,
                 and sensor placement for a human subject without
                 external measurements. Instead, the joint parameters
                 are inferred with high accuracy from the motion data
                 acquired during the capture session. The parameters are
                 computed by performing a linear least squares fit of a
                 rotary joint model to the input data. A hierarchical
                 structure for the articulated model can also be
                 determined in situations where the topology of the
                 model is not known. Once the system topology and joint
                 parameters have been recovered, the resulting model can
                 be used to perform forward and inverse kinematic
                 procedures. We present the results of using the
                 algorithm on human motion capture data, as well as
                 validation results obtained with data from a simulation
                 and a wooden linkage of known dimensions.",
  keywords =     "Animation, Motion Capture, Kinematics, Parameter
                 Estimation, Joint Locations, Articulated Figure,
                 Articulated Hierarchy",
  booktitle =    "Proceedings of Graphics Interface 2000",
}

@InProceedings{EVL-2000-368,
  pages =        "61--68",
  year =         "2000",
  title =        "Animating Athletic Motion Planning By Example",
  author =       "Ronald Metoyer and Jessica Hodgins",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-368",
  abstract =     "Character animation is usually reserved for highly
                 skilled animators and computer programmers because few
                 of the available tools allow the novice or casual user
                 to create compelling animated content. In this paper,
                 we explore a partial solution to this problem which
                 lets the user coach animated characters by sketching
                 their trajectories on the ground plane. The details of
                 the motion are then computed with simulation. We create
                 memory-based control functions for the high-level
                 behaviors from examples supplied by the user and from
                 real-world data of the behavior. The control function
                 for the desired behavior is implemented through a
                 lookup table using a K-nearest neighbor approximation
                 algorithm. To demonstrate this approach, we present a
                 system for defining the behaviors of defensive
                 characters playing American football. The characters
                 are implemented using either point-masses or
                 dynamically simulated biped robots. We evaluate the
                 quality of the coached behaviors by comparing the
                 resulting trajectories to data from human players. We
                 also assess the influence of the user's coaching
                 examples by demonstrating that a user can construct a
                 particular style of play.",
  keywords =     "Animation, behavioral control, physical simulation,
                 machine learning",
  booktitle =    "Proceedings of Graphics Interface 2000",
}

@InProceedings{EVL-2000-369,
  pages =        "69--76",
  year =         "2000",
  title =        "Image-Based Virtual Camera Motion Strategies",
  author =       "\'Eric Marchand and Nicolas Courty",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-369",
  abstract =     "This paper presents an original solution to the camera
                 control problem in a virtual environment. Our objective
                 is to present a general framework that allows the
                 automatic control of a camera in a dynamic environment.
                 The proposed method is based on the image-based control
                 or visual servoing approach. It consists in positioning
                 a camera according to the information perceived in the
                 image. This is thus a very intuitive approach of
                 animation. To be able to react automatically to
                 modifications of the environment, we also considered
                 the introduction of constraints into the control. This
                 approach is thus adapted to highly reactive contexts
                 (virtual reality, video games). Numerous examples
                 dealing with classic problems in animation are
                 considered within this framework and presented in this
                 paper.",
  keywords =     "Automatic camera motion, Automatic cinematography,
                 Visual servoing, Animation",
  booktitle =    "Proceedings of Graphics Interface 2000",
}

@InProceedings{EVL-2000-37,
  pages =        "13--18",
  year =         "2000",
  title =        "Computer-Generated Pen-and-Ink Illustration of Trees",
  author =       "Oliver Deussen and Thomas Strothotte",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-37",
  abstract =     "We present a method for automatically rendering
                 pen-and-ink illustrations of trees. A given 3-d tree
                 model is illustrated by the tree skeleton and a visual
                 representation of the foliage using abstract drawing
                 primitives. Depth discontinuities are used to determine
                 what parts of the primitives are to be drawn; a hybrid
                 pixel-based and analytical algorithm allows us to deal
                 efficiently with the complex geometric data. Using the
                 proposed method we are able to generate illustrations
                 with different drawing styles and levels of
                 abstraction. The illustrations generated are spatial
                 coherent, enabling us to create animations of sketched
                 environments. Applications of our results are found in
                 architecture, animation and landscaping.",
  editor =       "Kurt Akeley",
  keywords =     "Biological Systems, Frame Buffer Tricks, Non-Realistic
                 Rendering",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-370,
  pages =        "77--86",
  year =         "2000",
  title =        "Analysis and Synthesis of Structural Textures",
  author =       "Laurent Lefebvre and Pierre Poulin",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-370",
  abstract =     "With the advent of image based modeling techniques, it
                 becomes easier to apply textures extracted from reality
                 onto virtual worlds. Many repetitive patterns
                 (structural textures) in human constructions can be
                 parametrized with procedural textures. These textures
                 offer a powerful alternative to traditional color
                 textures, but they require the artist to program the
                 desired effects. We present a system to automatically
                 extract from photographs values for parameters of
                 structural textures, giving the user the possibility to
                 guide the algorithms. Two common classes of procedural
                 textures are studied : rectangular tilings and wood.
                 The results demonstrate that synthesizing textures
                 similar to their real counterpart can be very
                 interesting for computer-augmented reality
                 applications.",
  keywords =     "Procedural textures, texture mapping, image based
                 modeling, feature extraction, wood texture, rectangular
                 tiling, brick layout, computer-augmented reality",
  booktitle =    "Proceedings of Graphics Interface 2000",
}

@InProceedings{EVL-2000-371,
  pages =        "87--94",
  year =         "2000",
  title =        "High-Quality Interactive Lumigraph Rendering Through
                 Warping",
  author =       "Hartmut Schirmacher and Wolfgang Heidrich and
                 Hans-Peter Seidel",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-371",
  abstract =     "We introduce an algorithm for high-quality,
                 interactive light field rendering from only a small
                 number of input images with dense depth information.
                 The algorithm bridges the gap between image warping and
                 interpolation from image databases, which represent the
                 two major approaches in image based rendering. By
                 warping and blending only the necessary parts of each
                 reference image, we are able to generate a single
                 view-corrected texture for every output frame at
                 interactive rates. In contrast to previous light field
                 rendering approaches, our warping-based algorithm is
                 able to fully exploit per-pixel depth information in
                 order to depth-correct the light field samples with
                 maximum accuracy. The complexity of the proposed
                 algorithm is nearly independent of the number of stored
                 reference images and of the final screen resolution. It
                 performs with only small overhead and very few visible
                 artifacts. We demonstrate the visual fidelity as well
                 as the performance of our method through various
                 examples.",
  keywords =     "Computer graphics, image based rendering, light
                 fields, Lumigraphs, image databases, image warping,
                 blending",
  booktitle =    "Proceedings of Graphics Interface 2000",
}

@InProceedings{EVL-2000-372,
  pages =        "95--102",
  year =         "2000",
  title =        "Effects of Gaze on Multiparty Mediated Communication",
  author =       "Roel Vertegaal and Gerrit van der Veer and Harro
                 Vons",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-372",
  abstract =     "We evaluated effects of gaze direction and other
                 non-verbal visual cues on multiparty mediated
                 communication. Groups of three participants (two
                 actors, one subject) solved language puzzles in three
                 audiovisual communication conditions. Each condition
                 presented a different selection of images of the actors
                 to subjects: (1) frontal motion video; (2) motion video
                 with gaze directional cues; (3) still images with gaze
                 directional cues. Results show that subjects used twice
                 as many deictic references to persons when head
                 orientation cues were present. We also found a linear
                 relationship between the amount of actor gaze perceived
                 by subjects and the number of speaking turns taken by
                 subjects. Lack of gaze can decrease turn-taking
                 efficiency of multiparty mediated systems by 25%. This
                 is because gaze conveys whether one is being addressed
                 or expected to speak, and is used to regulate social
                 intimacy. Support for gaze directional cues in
                 multiparty mediated systems is therefore recommended.",
  keywords =     "CSCW, videoconferencing, gaze direction",
  booktitle =    "Proceedings of Graphics Interface 2000",
}

@InProceedings{EVL-2000-373,
  pages =        "102--110",
  year =         "2000",
  title =        "Towards Seamless Support of Natural Collaborative
                 Interactions",
  author =       "Stacey D. Scott and Garth B. D. Shoemaker and Kori M.
                 Inkpen",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-373",
  abstract =     "In order to effectively support collaboration it is
                 important that computer technology seamlessly support
                 users? natural interactions instead of inhibiting or
                 constraining the collaborative process. The research
                 presented in this paper examines the human-human
                 component of computer supported cooperative work and
                 how the design of technology can impact how people work
                 together. In particular, this study examined chi-dren?s
                 natural interactions when working in a physical medium
                 compared to two computer-based environ-ments (a
                 traditional desktop computer and a system augmented to
                 provide each user with a mouse and a cursor). Results
                 of this research demonstrate that given the
                 opportunity, children will take advantage of the
                 ability to interact concurrently. In addition, users?
                 verbal interactions and performance can be constrained
                 when they are forced to interact sequentially, as in
                 the traditional computer setup. Supporting concurrent
                 interactions with multiple input devices is a first
                 step towards developing effective collaborative
                 environments that support users? natural collaborative
                 interactions.",
  keywords =     "Computer supported cooperative work (CCSCW), computer
                 supported collaborative learning (CSCL), single display
                 groupware (SDG), user interfaces, multiple mice, and
                 synchronous interaction",
  booktitle =    "Proceedings of Graphics Interface 2000",
}

@InProceedings{EVL-2000-374,
  pages =        "111--118",
  year =         "2000",
  title =        "The ChatterBox: Using Text Manipulation in an
                 Entertaining Information Display",
  author =       "Johan Redstr{\"{o}}m and Peter Ljungstrand and
                 Patricija Jaksetic",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-374",
  abstract =     "The ChatterBox is an attempt to make use of the
                 electronic ?buzz? that exists in a modern workplace:
                 the endless stream of emails, web pages, and electronic
                 documents which fills the local ether(-net). The
                 ChatterBox ?listens? to this noise, transforms and
                 recombines the texts in various ways, and presents the
                 results in a public place. The goal is to provide a
                 subtle reflection of the local activities and provide
                 inspiration for new, unexpected combinations and
                 thoughts. With the ChatterBox, we have tried to create
                 something in between a traditional application and a
                 piece of art: an entertaining and inspiring resource in
                 the workplace. This poses several interesting questions
                 concerning human-computer interaction design, e.g.,
                 information and display design. In this paper, we
                 present the ChatterBox, its current implementation and
                 experiences of its use.",
  keywords =     "Art, entertainment, awareness, ambient displays, text
                 transformation, calm technology",
  booktitle =    "Proceedings of Graphics Interface 2000",
}

@InProceedings{EVL-2000-375,
  pages =        "119--126",
  year =         "2000",
  title =        "Approximation of Glossy Reflection with Prefiltered
                 Environment Maps",
  author =       "Jan Kautz and Michael D. McCool",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-375",
  abstract =     "A method is presented that can render glossy
                 reflections with arbitrary isotropic bidirectional
                 reflectance distribution functions (BRDFs) at
                 interactive rates using texture mapping. This method is
                 based on the well-known environment map technique for
                 specular reflections. Our approach uses a single- or
                 multilobe representation of bidirectional reflectance
                 distribution functions, where the shape of each
                 radially symmetric lobe is also a function of view
                 elevation. This approximate representation can be
                 computed efficiently using local greedy fitting
                 techniques. Each lobe is used to filter specular
                 environment maps during a preprocessing step, resulting
                 in a three-dimensional environment map. For many BRDFs,
                 simplifications using lower-dimensional approximations,
                 coarse sampling with respect to view elevation, and
                 small numbers of lobes can still result in a convincing
                 approximation to the true surface reflectance.",
  keywords =     "Environment map, glossy reflection, texture mapping,
                 Bidirectional reflectance distribution function",
  booktitle =    "Proceedings of Graphics Interface 2000",
}

@InProceedings{EVL-2000-376,
  pages =        "137--144",
  year =         "2000",
  title =        "Multiscale Shaders for the Efficient Realistic
                 Rendering of Pine-Trees",
  author =       "Alexandre Meyer and Fabrice Neyret",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-376",
  abstract =     "The frame of our work is the efficient realistic
                 rendering of scenes containing a huge amount of data
                 for which an a priori knowledge is available. In this
                 paper, we present a new model able to render forests of
                 pine-trees efficiently in ray-tracing and free of
                 aliasing. This model is based on three scales of
                 shaders representing the geometry (i.e. needles) that
                 is smaller than a pixel size. These shaders are
                 computed by analytically integrating the illumination
                 reflected by this geometry using the a priori
                 knowledge. They include the effects of local
                 illumination, shadows and opacity within the concerned
                 volume of data.",
  keywords =     "Shaders, levels of details, natural scenes,
                 raytracing",
  booktitle =    "Proceedings of Graphics Interface 2000",
}

@InProceedings{EVL-2000-377,
  pages =        "145--152",
  year =         "2000",
  title =        "Anisotropic Feature-Preserving Denoising of Height
                 Fields and Bivariate Data",
  author =       "Mathieu Desbrun and Mark Meyer and Peter Schr{\"o}der
                 and Alan H. Barr",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-377",
  abstract =     "In this paper, we present an efficient way to denoise
                 bivariate data like height fields, color pictures or
                 vector fields, while preserving edges and other
                 features. Mixing surface area minimization, graph flow,
                 and nonlinear edge-preservation metrics, our method
                 generalizes previous anisotropic diffusion approaches
                 in image processing, and is applicable to data of
                 arbitrary dimension. Another notable difference is the
                 use of a more robust discrete differential operator,
                 which captures the fundamental surface properties. We
                 demonstrate the method on range images and height
                 fields, as well as greyscale or color images.",
  keywords =     "Anisotropic diffusion, Re-parametrization, Surface
                 flows, Edge preservation, Image processing, Surface
                 fairing",
  booktitle =    "Proceedings of Graphics Interface 2000",
}

@InProceedings{EVL-2000-378,
  pages =        "153--162",
  year =         "2000",
  title =        "A Fast, Space-Efficient Algorithm for the
                 Approximation of Images by an Optimal Sum of
                 Gaussians",
  author =       "Jeffrey Childs and Cheng-Chang Lu and Jerry Potter",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-378",
  abstract =     "Gaussian decomposition of images leads to many
                 promising applications in computer graphics. Gaussian
                 representations can be used for image smoothing, motion
                 analysis, and feature selection for image recognition.
                 Furthermore, image construction from a Gaussian
                 representation is fast, since the Gaussians only need
                 to be added together. The most optimal algorithms [3,
                 6, 7] minimize the number of Gaussians needed for
                 decomposition, but they involve nonlinear least-squares
                 approximations, e.g. the use of the Marquardt algorithm
                 [10]. This presents a problem, since, in the Marquardt
                 algorithm, enormous amounts of computations are
                 required and the resulting matrices use a lot of space.
                 In this work, a method is offered, which we call the
                 Quickstep method, that substantially reduces the number
                 of computations and the amount of space used. Unlike
                 the Marquardt algorithm, each iteration has linear time
                 complexity in the number of variables and no Jacobian
                 or Hessian matrices are formed. Yet, Quickstep produces
                 optimal results, similar to those produced by the
                 Marquardt algorithm.",
  keywords =     "Gaussian approximations, geometric algorithms, surface
                 fitting",
  booktitle =    "Proceedings of Graphics Interface 2000",
}

@InProceedings{EVL-2000-379,
  pages =        "163--170",
  year =         "2000",
  title =        "Oriented Sliver Textures: {A} Technique for Local
                 Value Estimation of Multiple Scalar Fields",
  author =       "Christopher Weigle and William G. Emigh and Geniva Liu
                 and Russell M. Taylor and James T. Enns and Christopher
                 G. Healey",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-379",
  abstract =     "This paper describes a texture generation technique
                 that combines orientation and luminance to support the
                 simultaneous display of multiple overlapping scalar
                 fields. Our orientations and luminances are selected
                 based on psychophysical experiments that studied how
                 the low-level human visual system perceives these
                 visual features. The result is an image that allows
                 viewers to identify data values in an individual field,
                 while at the same time highlighting interactions
                 between different fields. Our technique supports
                 datasets with both smooth and sharp boundaries. It is
                 stable in the presence of noise and missing values.
                 Images are generated in real-time, allowing interactive
                 exploration of the underlying data. Our technique can
                 be combined with existing methods that use perceptual
                 colours or perceptual texture dimensions, and can
                 therefore be seen as an extension of these methods to
                 further assist in the exploration and analysis of
                 large, complex, multidimensional datasets.",
  keywords =     "Computer graphics, human vision, luminance,
                 multidimensional, orientation, perception, texture,
                 scientific visualization",
  booktitle =    "Proceedings of Graphics Interface 2000",
}

@InProceedings{EVL-2000-38,
  pages =        "19--28",
  year =         "2000",
  title =        "A Simple, Efficient Method for Realistic Animation of
                 Clouds",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-38",
  author =       "Yoshinori Dobashi and Kazufumi Kaneda and Hideo
                 Yamashita and Tsuyoshi Okita and Tomoyuki Nishita",
  abstract =     "This paper proposes a simple and computationally
                 inexpensive method for animation of clouds. The cloud
                 evolution is simulated using cellular automaton that
                 simplifies the dynamics of cloud formation. The
                 dynamics are expressed by several simple transition
                 rules and their complex motion can be simulated with a
                 small amount of computation. Realistic images are then
                 created using one of the standard graphics APIs,
                 OpenGL. This makes it possible to utilize graphics
                 hardware, resulting in fast image generation. The
                 proposed method can realize the realistic motion of
                 clouds, shadows cast on the ground, and shafts of light
                 through clouds",
  editor =       "Kurt Akeley",
  keywords =     "Animation, Atmospheric Effects, Rendering, Graphics
                 Hardware, Volume Rendering",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-380,
  pages =        "171--178",
  year =         "2000",
  title =        "Using a 3{D} Puzzle as a Metaphor for Learning Spatial
                 Relations",
  author =       "Felix Ritter and Bernhard Preim and Oliver Deussen and
                 Thomas Strothotte",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-380",
  abstract =     "We introduce a new metaphor for learning spatial
                 relations-the 3D puzzle. With this metaphor users learn
                 spatial relations by assembling a geometric model
                 themselves. For this purpose, a 3D model of the subject
                 at hand is enriched with docking positions which allow
                 objects to be connected. Since complex 3D interactions
                 are required to compose 3D objects, sophisticated 3D
                 visualization and interaction techniques are included.
                 Among these techniques are specialized shadow
                 generation, snapping mechanisms, collision detection
                 and the use of two-handed interaction. The 3D puzzle,
                 similar to a computer game, can be operated at
                 different levels of difficulty. To simplify the task, a
                 subset of the geometry, e.g., the skeleton of an
                 anatomic model, can be given initially. Moreover,
                 textual information concerning the parts of the model
                 is provided to support the user. With this approach we
                 motivate students to explore the spatial relations in
                 complex geometric models and at the same time give them
                 a goal to achieve while learning takes place. A
                 prototype of a 3D puzzle, which is designed principally
                 for use in anatomy education, is presented.",
  keywords =     "Metaphors for spatial interaction, interactive system
                 design, 3D interaction",
  booktitle =    "Proceedings of Graphics Interface 2000",
}

@InProceedings{EVL-2000-381,
  pages =        "179--186",
  year =         "2000",
  title =        "Affordances: Clarifying and Evolving a Concept",
  author =       "Joanna McGrenere and Wayne Ho",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-381",
  abstract =     "The concept of affordance is popular in the HCI
                 community but not well understood. Donald Norman
                 appropriated the concept of affordances from James J.
                 Gibson for the design of common objects and both
                 implicitly and explicitly adjusted the meaning given by
                 Gibson. There was, however, ambiguity in Norman's
                 original definition and use of affordances which he has
                 subsequently made efforts to clarify. His definition
                 germinated quickly and through a review of the HCI
                 literature we show that this ambiguity has lead to
                 widely varying uses of the concept. Norman has recently
                 acknowledged the ambiguity, however, important
                 clarifications remain. Using affordances as a basis, we
                 elucidate the role of the designer and the distinction
                 between usefulness and usability. We expand Gibson's
                 definition into a framework for design.",
  keywords =     "Affordance, usefulness, usability, design",
  booktitle =    "Proceedings of Graphics Interface 2000",
}

@InProceedings{EVL-2000-382,
  pages =        "187--196",
  year =         "2000",
  title =        "Are We All In the Same 'Bloat'?",
  author =       "Joanna McGrenere and Gale Moore",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-382",
  abstract =     "{"}Bloat{"}, a term that has existed in the technical
                 community for many years, has recently received
                 attention in the popular press. The term has a negative
                 connotation implying that human, or system performance
                 is diminished in some way when {"}bloat{"} exists. Yet
                 {"}bloat{"} is seldom clearly defined and is often a
                 catch-all phrase to suggest that software is filled
                 with unnecessary features. However, to date there are
                 no studies that explore how users actually experience
                 complex functionality-filled software applications and
                 most importantly, the extent to which they experience
                 them in similar/different ways. The significance of
                 understanding users' experience is in the implications
                 this understanding has for design. Using both
                 quantitative and qualitative methods, we carried out a
                 study to gain a better understanding of the experiences
                 of 53 members of the general population who use a
                 popular word processor, Microsoft Word, Office 97. As a
                 result we are able to further specify the term
                 {"}bloat{"}, distinguishing an objective and subjective
                 dimension. It is the discovery of the subjective
                 dimension that opens the design space and raises new
                 challenges for interface designers. There is certainly
                 more to {"}bloat{"} than meets the eye.",
  keywords =     "Complex software, bloat, creeping featurism, user
                 experience, office applications, human-centred design,
                 user study, evaluation, personalization",
  booktitle =    "Proceedings of Graphics Interface 2000",
}

@InProceedings{EVL-2000-383,
  pages =        "202--212",
  year =         "2000",
  title =        "Incremental Triangle Voxelization",
  author =       "Frank Dachille IX and Arie Kaufman",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-383",
  abstract =     "We present a method to incrementally voxelize
                 triangles into a volumetric dataset with pre-filtering,
                 generating an accurate multivalued voxelization.
                 Multivalued voxelization allows direct volume rendering
                 of voxelized geometry as well as volumes with
                 intermixed geometry, accurate multiresolution
                 representations, and efficient antialiasing. Prior
                 voxelization methods either computed only a binary
                 voxelization or inefficiently computed a multivalued
                 voxelization. Our method develops incremental equations
                 to quickly decide which filter function to compute for
                 each voxel value. The method requires eight additions
                 per voxel of the triangle bounding box. Being simple
                 and efficient, the method is suitable for
                 implementation in a hardware volume rendering system.",
  keywords =     "Voxelization, volume filtering, hardware, incremental
                 algorithm, cut planes",
  booktitle =    "Proceedings of Graphics Interface 2000",
}

@InProceedings{EVL-2000-384,
  pages =        "213--220",
  year =         "2000",
  title =        "Dynamic Plane Shifting {BSP} Traversal",
  author =       "Stan Melax",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-384",
  abstract =     "Interactive 3D applications require fast detection of
                 objects colliding with the environment. One popular
                 method for fast collision detection is to offset the
                 geometry of the environment according to the dimensions
                 of the object, and then represent the object as a point
                 (and the object's movement as a line segment).
                 Previously, this geometry offset has been done in a
                 preprocessing step and therefore requires knowledge of
                 the object's dimensions before runtime. Furthermore, an
                 extra copy of the environment's geometry is required
                 for each shape used in the application. This paper
                 presents a variation of the BSP tree collision
                 algorithm that shifts the planes in order to offset the
                 geometry of the environment at runtime. To prevent
                 unwanted cases where offset geometry protrudes too
                 much, extra plane equations, which bevel solid cells of
                 space during expansion, are added by simply inserting
                 extra nodes at the bottom of the tree. A simple line
                 segment check can be used for collision detection of a
                 moving object of any size against the environment. Only
                 one BSP tree is needed by the application. This paper
                 also discusses successful application of this technique
                 within a commercial entertainment software product.",
  keywords =     "Collision detection, BSP tree, video games",
  booktitle =    "Proceedings of Graphics Interface 2000",
}

@InProceedings{EVL-2000-385,
  pages =        "221--228",
  year =         "2000",
  title =        "Model Simplification Through Refinement",
  author =       "Dmitry Brodsky and Benjamin Watson",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-385",
  abstract =     "As modeling and visualization applications
                 proliferate, there arises a need to simplify large
                 polygonal models at interactive rates. Unfortunately
                 existing polygon mesh simplification algorithms are not
                 well suited for this task because they are either too
                 slow (requiring the simplified model to be
                 pre-computed) or produce models that are too poor in
                 quality. These shortcomings become particularly acute
                 when models are extremely large. We present an
                 algorithm suitable for simplification of large models
                 at interactive speeds. The algorithm is fast and can
                 guarantee displayable results within a given time
                 limit. Results also have good quality. Inspired by
                 splitting algorithms from vector quantization
                 literature, we simplify models in reverse, beginning
                 with an extremely coarse approximation and refining it.
                 Approximations of surface curvature guide the
                 simplification process. Previously produced
                 simplifications can be further refined by using them as
                 input to the algorithm.",
  booktitle =    "Proceedings of Graphics Interface 2000",
}

@InCollection{EVL-2000-386,
  pages =        "3--14",
  year =         "2000",
  title =        "Interpolating meshes of boundary intersecting curves
                 by subdivision surfaces",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-386",
  author =       "Ahmad H. Nasri",
  abstract =     "Given a polyhedral network with a set of tagged
                 control polygons, a subdivision surface that smoothly
                 interpolates the curves of these control polygons can
                 be generated. The idea consists of constructing a set
                 of polygonal complexes, one for each tagged control
                 polygon, on the original or its subdivided network.
                 This paper describes how to construct such complexes to
                 interpolate meshes of curves intersecting at the
                 boundary of a surface, such as a boundary curve
                 intersecting an interior curve or another one. The
                 method can also be used to generate subdivision
                 surfaces through arbitrary meshes of curves with C^{0}
                 (creases) or C^{1} continuity across the interpolated
                 curves.",
  keywords =     "Recursive subdivision, Curve interpolation, B-spline,
                 Arbitrary networks, Creases",
  volume =       "16(1)",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-387,
  pages =        "15--25",
  year =         "2000",
  title =        "Extracting skeletal curves from 3{D} scattered data",
  author =       "Anne Verroust and Francis Lazarus",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-387",
  abstract =     "We introduce a method for extracting skeletal curves
                 from an unorganized collection of scattered data points
                 lying on a surface. These curves may have a treelike
                 structure to capture branching shapes such as blood
                 vessels. The skeletal curves can be used for various
                 applications ranging from surface reconstruction to
                 object recognition.",
  volume =       "16(1)",
  keywords =     "Visualization, Skeletal curves, Cylindrical
                 decomposition, Generalized cylinders, Reconstruction",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-388,
  pages =        "26--37",
  year =         "2000",
  title =        "Merging polyhedral shapes with scattered features",
  author =       "Marc Alexa",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-388",
  abstract =     "We introduce a method for extracting skeletal curves
                 from an unorganized collection of scattered data points
                 lying on a surface. These curves may have a treelike
                 structure to capture branching shapes such as blood
                 vessels. The skeletal curves can be used for various
                 applications ranging from surface reconstruction to
                 object recognition. 1. initial embeddings of the
                 polyhedra on unit spheres are computed, 2. the
                 embeddings are deformed so that user-defined features
                 (vertices) coincide on the spheres, and 3. an overlay
                 of the subdivisions is computed and the aligned
                 vertices are fused in the merged model.",
  volume =       "16(1)",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-389,
  pages =        "38--46",
  year =         "2000",
  title =        "Curvilinear displacement of free-form-based
                 deformation,",
  author =       "Romain Raffin and Marc Neveu and Fr{\'{e}}d{\'{e}}ric
                 Jaar",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-389",
  abstract =     "This paper presents an extension of a free-form
                 deformation method. This method can be used on any
                 object, whatever its geometrical description. It
                 consists in fixing displacement constraint on an object
                 and ensuring their satisfaction through the
                 deformation. The final object is a blend of the
                 deformation functions linked with the constraint. The
                 user can also modify the extent of the constraints
                 influences and the displacement of the constraint
                 points to obtain a desired shape. This method keeps its
                 initial properties and enables the deformation of the
                 whole space.",
  volume =       "16(1)",
  keywords =     "Geometric modelling, Free-form deformation,
                 Constrained deformation",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InProceedings{EVL-2000-39,
  pages =        "37--46",
  year =         "2000",
  title =        "Computer Modelling of Fallen Snow",
  author =       "Paul Fearing",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-39",
  abstract =     "In this paper, we present a new model of snow
                 accumulation and stability for computer graphics. Our
                 contribution is divided into two major components, each
                 essential for modelling the appearance of a thick layer
                 of snowfall on the ground. Our accumulation model
                 determines how much snowa particular surface receives,
                 allowing for such phenomena as flake flutter, flake
                 dusting and wind-blown snow. We compute snow
                 accumulation by shooting particles upwards towards the
                 sky, giving each source surface independent control
                 over its own sampling density, accuracy and computation
                 time. Importance ordering minimises sampling effort
                 while maximising visual information, generating
                 smoothly improving global results that can be
                 interrupted at any point. Once snow lands on the
                 ground, our stability model moves material away from
                 physically unstable areas in a series of small,
                 simultaneous avalanches. We use a simple local
                 stability test that handles very steep surfaces,
                 obstacles, edges, and wind transit. Our stability
                 algorithm also handles other materials, such as flour,
                 sand, and flowing water.",
  editor =       "Kurt Akeley",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InCollection{EVL-2000-390,
  pages =        "47--61",
  year =         "2000",
  title =        "Shape similarity by homotopic deformation",
  author =       "Yusaku Sako and Kikuo Fujimura",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-390",
  abstract =     "A method is presented for shape comparison using shape
                 deformation. Unlike many other approaches to shape
                 similarity comparison that use local characteristics,
                 our approach captures global features of shapes and is
                 less sensitive to nonuniform noise. The problem is cast
                 to polygon-to-polygon homotopic deformation and a new
                 shape signature based on deformation is introduced. A
                 polygon deformation algorithm runs in O(nk+n log n)
                 time, where n is the number of vertices in the
                 polygonal shapes and k is an index to indicate how the
                 target shape is convoluted. Experimental results show
                 the feasibility of our approach. Extending the method
                 for comparison of scenes with multiple objects is also
                 discussed.",
  volume =       "16(1)",
  keywords =     "Shape similarity, Deformation, Scene comparison",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-391,
  pages =        "62--78",
  year =         "2000",
  title =        "High-performance computing for surface modelling and
                 analysis",
  author =       "Andrea Clematis and Andrea Coda and Bianca Falcidieno
                 and Michela Spagnuolo",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-391",
  abstract =     "Real-time response and updating, and concurrent use of
                 complex models are problems which require a high
                 computational effort and might thus benefit from the
                 use of parallel processing. These problems typically
                 occur in surface analysis, a key tool for shape
                 understanding and processing. We survey different
                 applications,of parallel processing at different stages
                 of the shape-understanding process. The emphasis is on
                 parallel program portability and reuse of sequential
                 software. Results are provided for different
                 architectures like workstation networks and massively
                 parallel machines (Cray T3D).",
  volume =       "16(1)",
  keywords =     "Shape analysis, Parallel processing, Workstation
                 networks, Program portability",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-392,
  pages =        "79--90",
  year =         "2000",
  title =        "On latency compensation and its effects on head-motion
                 trajectories in virtual environments,",
  author =       "Jiann-Rong Wu and Ming Ouhyoung",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-392",
  abstract =     "We present experiments on latency and its compensation
                 methods in a virtual reality application using a
                 head-motion display (HMD) and a 3D-head tracker. Our
                 purpose is to compare, both in simulation and in a real
                 task, four tracker prediction methods: the grey system
                 theory-based prediction, Kalman filtering, a simple
                 linear extrapolation, and the basic method without
                 prediction. Typical motion trajectories of the four
                 methods in simulation are plotted, and jitter effects
                 are examined. Kalman filtering was found to have the
                 largest jitter among the four. An experiment is also
                 presented to simulate a real-world application:
                 following a tour guide in a walkthrough of a building.
                 An improvement of 120% was observed.",
  volume =       "16(2)",
  keywords =     "Motion prediction, Latency in HMD, Virtual reality
                 technology",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-393,
  pages =        "91--105",
  year =         "2000",
  title =        "Image representation by self-organizing conformal
                 network",
  author =       "Wen-Pin Tai and Cheng-Yuan Liou",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-393",
  abstract =     "Conformal mappings are incorporated into the
                 self-organization model to represent images
                 harmonically. This network is used to partition an
                 image into quadrilateral regions, where each region
                 contains similar features. We then map each region to a
                 corresponding square region to unify information
                 representation and facilitate computations. This
                 mapping is constructed to preserve spatial information
                 while complying with the conformal property of the
                 network. An approximated image in each square region
                 provides us with an effective representation of the
                 image in both modeling and compression applications.
                 This approach has been particularly developed for large
                 continues images.",
  volume =       "16(2)",
  keywords =     "Neural network, Image modeling, Self-organizing
                 network, Conformal mapping, Image compression",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-394,
  pages =        "106--115",
  year =         "2000",
  title =        "Wavelet shape blending",
  author =       "Yuefeng Zhang and Yu Huang",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-394",
  abstract =     "The intrinsic shape-blending algorithm proposed by
                 Sederberg et al. can produce better shape blends than
                 linear or cubic curve interpolation. The major
                 difficulty with this method is that it cannot handle
                 polygons with short edges and&sol;or duplicated
                 vertices. This paper presents a new algorithm that uses
                 the wavelet transform to avoid this difficulty by (1)
                 using wavelet decomposition to remove short edges
                 and/or duplicated vertices, (2) applying the intrinsic
                 shape-blending algorithm to blend the overall shapes of
                 the polygons, and (3) applying wavelet reconstruction
                 to reconstruct the inbetweening of the original
                 polygons.",
  volume =       "16(2)",
  keywords =     "Shape blending, Animation, Wavelet transform,
                 Algorithm",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-395,
  pages =        "116--133",
  year =         "2000",
  title =        "Multilevel sensitive reconstruction of polyhedral
                 surfaces from parallel slices",
  author =       "Gill Barequet and Daniel Shapiro and Ayellet Tal",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-395",
  abstract =     "We present an algorithm for reconstructing a solid
                 model from a series of planar cross-sections. In most
                 previous works the layers are assumed to be
                 independent: each layer is interpolated separately, and
                 the concatenation of the interpolated layers is
                 considered the solution to the whole problem. The
                 resulting surface can therefore exhibit abrupt changes.
                 The main contribution of this work is avoiding this
                 assumption. We use the slopes of triangles created in
                 the interpolation of neighboring layers to guide the
                 interpolation of the current layer. As a result,
                 consecutive layers are connected smoothly. We also
                 discuss various objective functions that aim to
                 optimize the reconstruction and evaluate these
                 functions using various criteria.",
  volume =       "16(2)",
  keywords =     "Surface reconstruction, Interpolation, Triangulation",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-396,
  pages =        "134--140",
  year =         "2000",
  title =        "Skinning-surface generation based on spine-curve
                 control",
  author =       "Yoshimasa Tokuyama",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-396",
  abstract =     "The skinning method for interpolation over
                 user-defined cross-sectional curves is one of the most
                 widely used tools for shape design in computer-aided
                 design. In practice, a spine curve may be used to
                 position and orient the cross-sectional curves in
                 space. The spine curve can also aid in shape control by
                 providing additional constraints, e.g., tangent
                 directions, for surface interpolation. This paper takes
                 into account the shape of a spine curve during the
                 skinning process and presents a boolean-sum approach to
                 the representation of the resulting skinned surface. As
                 a result, the resulting skinned surface is represented
                 by a B-spline or NURBS surface and has a longitudinal
                 surface shape resembling the spine curve.",
  volume =       "16(2)",
  keywords =     "CAD/CAM, Skinning, Spine curve, NURBS, B-spline",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-397,
  pages =        "142--150",
  year =         "2000",
  title =        "Discrete fairing and variational subdivision for
                 freeform surface design",
  author =       "Leif P. Kobbelt",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-397",
  abstract =     "The representation of free-form surfaces by
                 sufficiently refined polygonal meshes has become common
                 in many geometric modeling applications where
                 complicated objects have to be handled. While working
                 with triangle meshes is flexible and efficient,
                 prominent difficulties arise from the lack of
                 infinitesimal smoothness and the prohibitive complexity
                 of highly detailed 3D models. In this paper, we discuss
                 the generation of fair triangle meshes that are optimal
                 with respect to some discretized curvature energy
                 functional. The key issues are the proper definition of
                 discrete curvature, the smoothing of high-resolution
                 meshes by filter operators, and the efficient
                 generation of optimal meshes by solving a sparse linear
                 system that characterizes the global minimum of an
                 energy functional. Results and techniques from
                 differential geometry, variational surface design
                 (fairing), and numerical analysis are combined to find
                 efficient and robust algorithms that generate smooth
                 meshes of arbitrary topology that interpolate or
                 approximate a given set of data points.",
  volume =       "16(3/4)",
  keywords =     "Free-form surface design, Fairing, Variational
                 subdivisions, Geometric modeling",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-398,
  pages =        "159--176",
  year =         "2000",
  title =        "Interactive mesh dragging with an adaptive remeshing
                 technique",
  author =       "Hiromasa Suzuki and Yusuke Sakurai and Takashi Kanai
                 and Fumihiko Kimura",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-398",
  abstract =     "We propose a 3D mesh-dragging method useful for
                 intuitive, efficient geometric modeling of free-form
                 polygonal models. With our method, the user can drag a
                 part of a triangular mesh and change its position and
                 orientation. This method is based on an adaptive
                 remeshing procedure that evaluates the deformation of
                 faces by dragging and properly modifies them by
                 deleting or splitting with local topological
                 operations. Therefore, the mesh is automatically
                 adjusted for dragging, and irregularity caused by
                 dragging onto the mesh is no longer a concern. In
                 addition, this method is local to the dragged portion,
                 so its computation is efficient. In this paper we
                 describe our adaptive remeshing method and demonstrate
                 some dragging examples.",
  volume =       "16(3/4)",
  keywords =     "Mesh editing, Remeshing, Free-form modelling,
                 Geometric modeling",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-399,
  pages =        "177--186",
  year =         "2000",
  title =        "General matrix representations for {B}-splines",
  author =       "Kauhuai Qin",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-399",
  abstract =     "In this paper, the concept of the basis matrix of
                 B-splines is presented. A general matrix
                 representation, which results in an explicitly
                 recursive matrix formula, for nonuniform B-spline
                 curves of an arbitrary degree is also presented by
                 means of the Toeplitz matrix. New recursive matrix
                 representations for uniform B-spline curves and
                 B{\'{e}}zier curves of an arbitrary degree are obtained
                 as special cases of that for nonuniform B-spline
                 curves. The recursive formula for the basis matrix can
                 be substituted for de Boor-Cox's formula for B-splines,
                 and it has a better time complexity than de Boor-Cox's
                 formula when used for computation and conversion of
                 B-spline curves and surfaces between different CAD
                 systems. Finally, some applications of the matrix
                 representations are given in the paper.",
  volume =       "16(3/4)",
  keywords =     "B-splines, Matrix representations, Toeplitz matrix",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@TechReport{EVL-2000-4,
  year =         "2000",
  title =        "Enumeration of Equicolourable Trees",
  author =       "Nicholas Pippenger",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-4",
  abstract =     "A tree, being a connected acyclic graph, can be
                 bicoloured in two ways, which differ from each other by
                 exchange of the colours. We shall say that a tree is
                 equicolourable if these bicolourings assign the two
                 colours to equal numbers of vertices. Labelled
                 equicoloured trees have been enumerated several times
                 in the literature, and from this result it is easy to
                 enumerate labelled equicolourable trees. The result is
                 that the probability that a randomly chosen n-vertex
                 labelled tree is equicolourable is asymptotically just
                 twice the probability that its vertices would be
                 equicoloured if they were assigned colours by
                 independent unbiased coin flips. Our goal in this paper
                 is the enumeration of unlabelled equicolourable trees
                 (that is, trees up to isomorphism), both exactly (in
                 terms of generating functions) and asymptotically. We
                 treat both the rooted and unrooted versions of this
                 problem, and conclude that in either case the
                 probability that a randomly chosen n-vertex unlabelled
                 tree is equicolourable is asymptotically 1.40499...
                 times as large as the probability that it would be
                 equicoloured if its vertices were assigned colours by
                 independent unbiased coin flips.",
  month =        feb,
  number =       "TR-00-04",
  institution =  "Department of Computer Science, University of British
                 Comlumbia",
}

@InProceedings{EVL-2000-40,
  pages =        "47--54",
  year =         "2000",
  title =        "Time-Dependent Visual Adaptation for Realistic Image
                 Display",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-40",
  author =       "Sumanta N. Pattanaik and Jack E. Tumblin and Hector
                 Yee and Donald P. Greenberg.",
  abstract =     "Human vision takes time to adapt to large changes in
                 scene inten-sity, and these transient adjustments have
                 a profound effect on visual appearance. This paper
                 offers a new operator to include these appearance
                 changes in animations or interactive real-time
                 simulations, and to match a user's visual responses to
                 those the user would experience in a real-world scene.
                 Large, abrupt changes in scene intensities can cause
                 dramatic compression of visual responses, followed by a
                 gradual recovery of normal vision. Asymmetric
                 mechanisms govern these time-dependent adjustments, and
                 offer adaptation to increased light that is much more
                 rapid than adjustment to darkness. We derive a new tone
                 reproduction operator that simulates these mechanisms.
                 The operator accepts a stream of scene intensity frames
                 and creates a stream of color display images. All
                 operator components are derived from published
                 quantitative measurements from physiology,
                 psychophysics, color science, and photography. Kept
                 intentionally simple to allow fast computation, the
                 operator is meant for use with real-time walk-through
                 renderings, high dynamic range video cameras, and other
                 interactive applications. We demonstrate its
                 performance on both synthetically generated and
                 acquired `real-world' scenes with large dynamic
                 variations of illumination and contrast.",
  editor =       "Kurt Akeley",
  keywords =     "rendering, realistic image display, time course of
                 adaptation, background intensity, adaptation model",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InCollection{EVL-2000-400,
  pages =        "187--196",
  year =         "2000",
  title =        "Existence and computation of spherical rational
                 quartic curves for Hermite interpolation",
  author =       "Wenping Wang and Kaihuai Qin",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-400",
  abstract =     "We study the existence and computation of spherical
                 rational quartic curves that interpolate Hermite data
                 on a sphere, i.e. two distinct endpoints and tangent
                 vectors at the two points. It is shown that spherical
                 rational quartic curves interpolating such data always
                 exist, and that the family of these curves has n
                 degrees of freedom for any given Hermite data on S^{n},
                 n>=2. A method is presented for generating all
                 spherical rational quartic curves on S^{n}
                 interpolating given Hermite data.",
  volume =       "16(3/4)",
  keywords =     "Spherical rational guartic curves, Hermite
                 interpolation, Stereographic projection",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-401,
  pages =        "197--207",
  year =         "2000",
  title =        "Ray tracing deformed generalized cylinders",
  author =       "Erik de Voogt and Aadjan van der Helm and Willem F.
                 Bronsvoort",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-401",
  abstract =     "Generalized cylinders are objects defined by sweeping
                 a 2D contour along a 3D trajectory. We introduce
                 deformed generalized cylinders in which different
                 contours can be defined along the trajectory. The
                 representation of a deformed generalized cylinder is
                 suitable for directly ray tracing its shape; it need
                 not be converted into another representation. A
                 suitable algorithm and some resulting images are
                 presented.",
  volume =       "16(3/4)",
  keywords =     "Geometric modelling, Sweep objects, Generalized
                 cylinders, Parametric surfaces, Cross-sectional design,
                 Display algorithms, Ray tracing",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-402,
  pages =        "208--240",
  year =         "2000",
  title =        "Polygonal boundary approximation for a 2{D} general
                 sweep based on envelope and boolean operations",
  author =       "Joo-Haeng Lee and Sung Je Hong and Myung-Soo Kim",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-402",
  abstract =     "This paper presents an algorithm that approximates
                 (using polygons) the boundary of a general sweep for an
                 arbitrary 2D curved object (possibly with holes). Based
                 on set-theoretic properties of the general sweep, our
                 algorithm generates the polygonal sweep boundary
                 incrementally, where envelope approximations and union
                 operations are repeatedly applied to intermediate
                 boundaries of the sweep and consecutive instances of
                 the moving object at sampled locations of the motion.
                 For approximation, each instance of the object is
                 polygonized along the motion, where the object may
                 experience dynamic shape transformation with
                 topological changes such as creating and/or destroying
                 internal holes. The incremental nature of the proposed
                 algorithm makes the boundary construction of a general
                 sweep useful for applications in interactive shape
                 design, collision detection, and mechanical part
                 design. Our algorithm generates a precise approximation
                 of the boundary of a general sweep with real-time
                 performance in computing unsweeps, Minkowski sums and
                 differences, and constant radius offsets. Some
                 experimental results are also given in this paper.",
  volume =       "16(3/4)",
  keywords =     "General sweep, Unsweep, Minkowski sum and difference,
                 Offset, Interactive shape design",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-403,
  pages =        "254--270",
  year =         "2000",
  title =        "Creating and retargetting motion by the
                 musculoskeletal human body model",
  author =       "Taku Komura and Yoshihisa Shinagawa and Tosiyasu L.
                 Kunii",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-403",
  abstract =     "Recently, optimization has been used in various ways
                 to interpolate or retarget human body motions obtained
                 by motion-capturing systems. However, in such cases,
                 the inner structure of a human body has rarely been
                 taken into account, and hence there have been
                 difficulties in simulating physiological effects such
                 as fatigue or injuries. In this paper, we propose a
                 method to create/retarget human body motions using a
                 musculoskeletal human body model. Using our method, it
                 is possible to create dynamically and physiologically
                 feasible motions. Since a muscle model based on Hill's
                 model is included in our system, it is also possible to
                 retarget the original motion by changing muscular
                 parameters. For example, using the muscle fatigue
                 model, a motion where a human body gradually gets tired
                 can be simulated. By increasing the maximal force
                 exertable by the muscles, or decreasing it to zero,
                 training or displacement effects of muscles can also be
                 simulated. Our method can be used for biomechanically
                 correct inverse kinematics, interpolation of motions,
                 and physiological retargetting of the human body
                 motion.",
  volume =       "16(5)",
  keywords =     "Human animation, Muscle-based model, Motion
                 retargetting, Motion synthesis",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-404,
  pages =        "271--288",
  year =         "2000",
  title =        "A case study towards validation of global illumination
                 algorithms: progressive hierarchical radiosity with
                 clustering",
  author =       "Karol Myszkowski and Tosiyasu L. Kunii",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-404",
  abstract =     "In this paper, we present an efficient global
                 illumination technique, and then we discuss the results
                 of its extensive experimental validation. The technique
                 is a hybrid of cluster-based hierarchical and
                 progressive radiosity techniques, which does not
                 require storing links between interacting surfaces and
                 clusters. We tested our technique by applying a
                 multistage validation procedure, which we designed
                 specifically for global illumination solutions. First,
                 we experimentally validate the algorithm against
                 analytically derived and measured real-world data to
                 check how calculation speed is traded for lighting
                 simulation accuracy for various clustering and meshing
                 scenarios. Then we test the algorithm performance and
                 rendering quality by directly comparing the virtual and
                 real-world images of a complex environment.",
  volume =       "16(5)",
  keywords =     "Clustering, Hierarchical radiosity, Progressive
                 refinement, Experimental validation, Global
                 illumination",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-405,
  pages =        "289--304",
  year =         "2000",
  title =        "Computer-assisted coloring by matching line drawings",
  author =       "Hock Soon Seah and Tian Feng",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-405",
  abstract =     "An approach to automatically color line drawings based
                 on feature matching is proposed. The motivation is that
                 coloring 2D animation is still a labor-intensive
                 process in current cartoon film production. The
                 objective of our work is to investigate how to
                 automatically color an image in a cartoon sequence on
                 the basis of the previous frame. Our method first
                 establishes the matching relationship of two images,
                 after which it automatically paints one of them with
                 the color information of the other using a
                 region-matching algorithm. The region-matching
                 algorithm is based on feature correspondences. The
                 results show that the proposed algorithm can
                 straightforwardly and robustly realize our objective
                 and has a promising future for our next step to further
                 automate conventional animation.",
  volume =       "16(5)",
  keywords =     "Feature extraction, Line-drawing, Displacement vector,
                 Cel animation, Automated painting",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-406,
  pages =        "306--321",
  year =         "2000",
  title =        "Anatomic modeling of deformable human bodies",
  author =       "Luciana Porcher Nedel and Daniel Thalmann",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-406",
  abstract =     "In this paper, we propose a method to simulate human
                 bodies based on anatomy concepts. We believe that the
                 closer our model is to reality, the better our results
                 will be. Using this approach, we are developing our
                 human representation. Our model is divided into three
                 layers and presented in three steps: the concept of a
                 rigid body from a real skeleton, the muscle design and
                 deformation based on physical concepts, and skin
                 generation. Muscles are represented at two levels: the
                 action lines and the muscle shape. The action line
                 represents the force produced by a muscle on the bones,
                 while the muscle shapes used in the simulation consist
                 of surface-based models. To physically simulate
                 deformations, we used a mass-spring system with a new
                 kind of springs, called {"}angular springs,{"} which
                 were developed to control the muscle volume during
                 simulation. Integration aspects and results are also
                 presented.",
  volume =       "16(6)",
  keywords =     "Anatomic modeling, human body deformation, angular
                 springs, action lines",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-407,
  pages =        "322--338",
  year =         "2000",
  title =        "A component-based system for storing and manipulating
                 graphics objects of different representations",
  author =       "Andrey Collison and Hanspeter Bieri",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-407",
  abstract =     "This paper presents a new architecture of a database
                 system for the management of graphics objects. The
                 motivation for designing this architecture is to
                 improve the reuse of graphics objects and graphics
                 functionality. This shall be achieved by a
                 component-based approach that offers database
                 facilities to existing graphics applications and allows
                 graphics functionality of different origins to be
                 integrated. The system shall also be easily accessible
                 to remote users. Such a system has to cope with the
                 large variety of data representations typically found
                 in the graphics domain. The idea of the present
                 approach is to store the data in its original form,
                 without prior conversions, thus conserving the maximum
                 information content. A special type model, separating
                 semantics from implementation, ensures type safeness
                 and, at the same time, provides the flexibility and
                 extensibility needed to cope with multiple data
                 representations. Software components enable seamless
                 integration of the existing graphics operations offered
                 by various software packages. The components, together
                 with a composition mechanism, act as the data
                 manipulation language of the architecture. The
                 architecture to be presented has been implemented in a
                 prototype system called GSCOPE, which is accessible via
                 the Internet.",
  volume =       "16(6)",
  keywords =     "Graphics database, Reuse, Graphics objects,
                 Representations, Type model, Graphics system,
                 Components, GSCOPE",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-408,
  pages =        "339--356",
  year =         "2000",
  title =        "Construction of multiresolution triangular {B}-spline
                 surfaces using hexagonal filter",
  author =       "A. Dreger and M. H. Gross and J. Schlegel",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-408",
  abstract =     "We present multiresolution B-spline surfaces of
                 arbitrary order defined over triangular domains. Unlike
                 existing methods, the basic idea of our approach is to
                 construct the triangular basis functions from their
                 tensor-product relatives in the spirit of box splines
                 by projecting them onto the barycentric plane. The
                 scheme works for splines of any order where the
                 fundamental building blocks of the surface are
                 hierarchies of triangular B-spline scaling functions
                 and wavelets spanning the complement spaces between
                 levels of different resolution. Although our basis
                 functions have been deduced from the corresponding 3D
                 bases, our decomposition and reconstruction scheme
                 operates directly on the triangular mesh using
                 hexagonal filters. The resulting basis functions are
                 used to approximate triangular surfaces and possess
                 many useful properties, such as multiresolution
                 editing, local level of detail, continuity control,
                 surface compression, and many more. The performance of
                 our approach is illustrated by various examples,
                 including parametric and nonparametric surface editing
                 and compression.",
  volume =       "16(6)",
  keywords =     "Triangular B-spline wavelets, Box splines,
                 Multiresolution editing, Hierarchical surface
                 representation, Surface compression, Decomposition,
                 Reconstruction",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-409,
  pages =        "357--369",
  year =         "2000",
  title =        "Hierarchical tetrahedral-octahedral subdivision for
                 volume visualization",
  author =       "G{\"{u}}nther Greiner and Roberto Grosso",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-409",
  abstract =     "We present a method for discretizing 3D space in order
                 to make it accessible for handling numerical problems,
                 such as simulation or visualization. Our algorithm
                 generates a hierarchy of 3D meshes. It offers adaptive
                 subdivision, driven by a user-specified local error
                 control. Each 3D mesh consists of tetrahedra and
                 octahedra having minimal numbers of congruence classes.
                 Subdivision is based on a minimal set of rules for
                 regular and irregular refinement. Irregular elements
                 are stored as virtual elements and will be generated
                 only on demand. The hierarchy has a very compact
                 representation. The algorithm generates mesh
                 hierarchies used for efficient, interactive volume
                 visualization algorithms, e.g., isosurface extraction
                 and direct volume rendering. The meshes generated are
                 suited to multilevel, finite element computations as
                 well.",
  volume =       "16(6)",
  keywords =     "Volume visualization, 3D Mesh, Regular and irregular
                 refinement",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InProceedings{EVL-2000-41,
  pages =        "55--64",
  year =         "2000",
  title =        "Toward a Psychophysically-Based Light Reflection Model
                 for Image Synthesis",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-41",
  author =       "Fabio Pellacini and James A. Ferwerda and Donald P.
                 Greenberg",
  abstract =     "In this paper we introduce a new light reflection
                 model for image synthesis based on experimental studies
                 of surface gloss perception. To develop the model,
                 weve conducted two experiments that explore the
                 relationships between the physical parameters used to
                 describe the reflectance properties of glossy surfaces
                 and the perceptual dimensions of glossy appearance. In
                 the first experiment we use multidimensional scaling
                 techniques to reveal the dimensionality of gloss
                 perception for simulated painted surfaces. In the
                 second experiment we use magnitude estimation methods
                 to place metrics on these dimensions that relate
                 changes in apparent gloss to variations in surface
                 reflectance properties. We use the results of these
                 experiments to rewrite the parameters of a
                 physically-based light reflection model in perceptual
                 terms. The result is a new psychophysically-based light
                 reflection model where the dimensions of the model are
                 perceptually meaningful, and variations along the
                 dimensions are perceptually uniform. We demonstrate
                 that the model can facilitate describing surface gloss
                 in graphics rendering applications. This work
                 represents a new methodology for developing light
                 reflection models for image synthesis.",
  address =      "three-dimensional graphics and realism, human factors,
                 experimentation, light reflection models, gloss, visual
                 perception",
  editor =       "Kurt Akeley",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InCollection{EVL-2000-410,
  pages =        "371--378",
  year =         "2000",
  title =        "Simulation of three-dimensional cracks",
  author =       "Koichi Hirota and Yasuyuki Tanoue and Toyohisa
                 Kaneko",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-410",
  abstract =     "We describe a method for simulating the process of
                 cracking based on a 3D physical model. Cracks appear
                 when the stress caused by internal or external force
                 exceeds the tolerable amount. We applied a spring
                 network model to a simulation of cracks that appear on
                 drying clay. Clay contracts, or shrinks, as it dries.
                 Because the surface part dries more quickly than the
                 interior, the stretching stress acts on the surface
                 part, generating cracks. The process of drying changes
                 physical characteristics such as stiffness and maximum
                 strain. Our model introduces the properties of clay by
                 defining these parameters as functions of time on the
                 basis of measurement.",
  volume =       "16(7)",
  keywords =     "Crack pattern, Physical model, Simulation, Scientific
                 visualization, Animation techniques",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-411,
  pages =        "379--385",
  year =         "2000",
  title =        "Ray tracing four spheres at the vertices of a regular
                 tetrahedron",
  author =       "Kevin G. Suffern",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-411",
  abstract =     "By using ray tracing to simulate multiple reflections
                 of light rays between spheres with their centers at the
                 vertices of a regular tetrahedron, fractal images can
                 be produced that simulate, for artistic purposes, a
                 number of phenomena. These include the Sierpinski
                 gasket, an explosion, sea anemones, and a sunset.",
  volume =       "16(7)",
  keywords =     "Ray tracing, Spheres, Fractals, Chaos, Sierpinski
                 gasket",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-412,
  pages =        "386--395",
  year =         "2000",
  title =        "Surface approximation to scanned data",
  author =       "L. A. Piegl and W. Tiller",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-412",
  abstract =     "A method to approximate scanned data points with a
                 B-spline surface is presented. The data are assumed to
                 be organized in the form of Q_{i,j}, i=0...,n;
                 j=0...,mi, i.e., in a row-wise fashion. The method
                 produces a C^{(p-1, q-1)} continuous surface &lpar;p
                 and q are the required degrees&rpar; that does not
                 deviate from the data by more than a user-specified
                 tolerance. The parametrization of the surface is not
                 affected negatively by the distribution of the points
                 in each row, and it can be influenced by a
                 user-supplied knot vector.",
  volume =       "16(7)",
  keywords =     "Data approximation, Reverse engineering, B-splines,
                 Curves and surfaces, Algorithms",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-413,
  pages =        "396--410",
  year =         "2000",
  title =        "Using vanishing points for camera calibration and
                 coarse 3{D} reconstruction from a single image",
  author =       "E. Guillou and D. Meneveaux and E. Maisel and K.
                 Bouatouch",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-413",
  abstract =     "In this paper, we show how to calibrate a camera and
                 to recover the geometry and the photometry (textures)
                 of objects from a single image. The aim of this work is
                 to make it possible walkthrough and augment reality in
                 a 3D model reconstructed from a single image. The
                 calibration step does not need any calibration target
                 and makes only four assumptions: (1) the single image
                 contains at least two vanishing points, (2) the length
                 (in 3D space) of one line segment (for determining the
                 translation vector) in the image is known, (3) the
                 principle point is the center of the image, and (4) the
                 aspect ratio is fixed by the user. Each vanishing point
                 is determined from a set of parallel lines. These
                 vanishing points help determine a 3D world coordinate
                 system R_{o}. After having computed the focal length,
                 the rotation matrix and the translation vector are
                 evaluated in turn for describing the rigid motion
                 between R_{o} and the camera coordinate system R_{c}.
                 Next, the reconstruction step consists in placing,
                 rotating, scaling, and translating a rectangular 3D box
                 that must fit at best with the potential objects within
                 the scene as seen through the single image. With each
                 face of a rectangular box, a texture that may contain
                 holes due to invisible parts of certain objects is
                 assigned. We show how the textures are extracted and
                 how these holes are located and filled. Our method has
                 been applied to various real images (pictures scanned
                 from books, photographs) and synthetic images.",
  volume =       "16(7)",
  keywords =     "Calibration, Reconstruction, Rendering, Texture
                 extraction",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-414,
  pages =        "411--436",
  year =         "2000",
  title =        "Whole-body modelling of people from multiview images
                 to populate virtual worlds",
  author =       "Adrian Hilton and Daniel Beresford and Thomas Gentils
                 and Raymond Smith and Wei Sun and John Illingworth",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-414",
  abstract =     "In this paper a new technique is introduced for
                 automatically building recognisable, moving 3D models
                 of individual people. A set of multiview colour images
                 of a person is captured from the front, sides and back
                 by one or more cameras. Model-based reconstruction of
                 shape from silhouettes is used to transform a standard
                 3D generic humanoid model to approximate a person's
                 shape and anatomical structure. Realistic appearance is
                 achieved by colour texture mapping from the multiview
                 images. The results show the reconstruction of a
                 realistic 3D facsimile of the person suitable for
                 animation in a virtual world. The system is inexpensive
                 and is reliable for large variations in shape, size and
                 clothing. This is the first approach to achieve
                 realistic model capture for clothed people and
                 automatic reconstruction of animated models. A
                 commercial system based on this approach has recently
                 been used to capture thousands of models of the general
                 public.",
  volume =       "16(7)",
  keywords =     "Avatar, Virtual human, Whole-body modelling, 3D
                 vision, VRML",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-415,
  pages =        "437--452",
  year =         "2000",
  title =        "A hybrid elastic model for real-time cutting,
                 deformations, and force feedback for surgery training
                 and simulation",
  author =       "St{\'{e}}phane Cotin and Herv{\'{e}} Delingette and
                 Nicholas Ayache",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-415",
  abstract =     "We propose three physical models based on linear
                 elasticity theory and finite-element modeling that are
                 well-suited for surgery simulation. The first model
                 combines pre-computed deformations to deform large size
                 meshes in real-time, but cannot make any topological
                 changes to the mesh. The second model is similar to the
                 spring-mass models where volumetric deformations and
                 cutting operations can be simulated on small meshes in
                 real time. Finally, we have developped a third method,
                 combining the previous two solutions into a hybrid
                 model that simulates deformations and cutting on
                 complex anatomical structures.",
  volume =       "16(8)",
  keywords =     "Surgery simulation, Finite elements, Linear
                 elasticity, Spring-mass models, Soft tissue modeling",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-416,
  pages =        "453--468",
  year =         "2000",
  title =        "Cost-effective shadowing method using the {ED}-buffer
                 on an adaptive light cube",
  author =       "Tsuyoshi Isshiki and Makoto Ishikawa and Hiroaki
                 Kunieda",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-416",
  abstract =     "As the current graphics-accelerator hardware provides
                 the capability of generating 3D graphics images at
                 interactive rates (30-60 frames/s), there is a strong
                 need for a good-quality shadowing algorithm that maps
                 well to the current graphics hardware architecture and
                 is capable of producing shadowed images at the same
                 interactive rate. Our proposed shadowing method applies
                 the traditional, two-step Z-buffer approach, which
                 takes full advantage of the resources already provided
                 in current graphics hardware. We employ a modified data
                 structure on the light screen's Z-buffer, which
                 dramatically increases the shadowing accuracy. This
                 data structure, the ED-buffer, also simplifies the
                 shadow testing calculations considerably, needing only
                 a couple of fixed-point multiplications and additions
                 per shadow test. This is ideal for hardware
                 implementation. We also present a technique for
                 optimizing the use of the fixed memory resource in
                 order to maximize the accuracy of shadowing when the
                 scene is projected from the lighting point of view on
                 the six faces of a cube surrounding the light source.",
  editor =       "16(8)",
  keywords =     "Shadowing, Z-buffer, ED-buffer, Light cube, Hardware
                 implementation",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-417,
  pages =        "469--480",
  year =         "2000",
  title =        "Practical volumetric sculpting",
  author =       "Eric Ferley and Marie-Paule Cani and Jean-Dominique
                 Gascuel",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-417",
  abstract =     "We present a sculpture metaphor for rapid shape
                 prototyping. The sculpted shape is the isosurface of a
                 scalar field spatially sampled. The user can deposit
                 material wherever he desires in space and then
                 iteratively refine it, using a tool to add, remove,
                 paint, or smooth some material. We allow the use of
                 free-form tools that can be designed inside the
                 application. We also propose a technique to mimic local
                 deformations so that we can use the tool as a stamp to
                 make imprints on an existing shape. We focus on the
                 rendering quality too, exploiting lighting variations
                 and environment textures that simulate good-quality
                 highlights on the surface. Both greatly enhance the
                 shape estimation, which is a crucial step in this
                 iterative design process, in our opinion. The use of
                 stereo also greatly eases the understanding of spatial
                 relationships. Our current implementation is based on
                 GLUT and can run the application both on Unix-based
                 systems, such as Irix and Linux, and on Windows
                 systems. We obtain interactive response times, strongly
                 related to the size of the tool. The performance issues
                 and limitations are discussed.",
  volume =       "16(8)",
  keywords =     "Sculpture metaphor, Discrete implicit surfaces, Local
                 deformations, Balanced binary trees, Hash tables",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@InCollection{EVL-2000-418,
  pages =        "481--500",
  year =         "2000",
  title =        "Radiosity for scenes with many mirror reflections",
  author =       "Sze-Yao Li and Shi-Nine Yang",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-418",
  abstract =     "This paper introduces an effective and efficient
                 approach to synthesize images of environments with many
                 mirror reflections. According to existing two-pass
                 algorithms for non-perfectly diffuse environments, the
                 computational complexity increases in proportion to the
                 number of mirror reflections. We propose an improved
                 two-pass algorithm based on a reflection tree data
                 structure to manage complicated energy interactions due
                 to interreflections of multiple mirrors. Techniques in
                 radiosity computation such as progressive refinement
                 and hierarchical radiosity, and techniques in
                 visibility computation such as bounding volume
                 hierarchy, are used to accelerate the computation of
                 the first pass. In the second pass, a multilayered
                 clip-and-paste method is introduced to replace the
                 time-consuming ray tracing method. In addition,
                 problems and solutions in realizing multilayered
                 clip-and-paste are also addressed. The complexity of
                 the proposed algorithm is analyzed. Empirical tests are
                 given and shown to be in accord with the analysis.",
  volume =       "16(8)",
  keywords =     "Global illumination, Mirror reflection, Radiosity,
                 Two-pass method",
  booktitle =    "The Visual Computer",
  publisher =    "Springer",
}

@Article{EVL-2000-419,
  pages =        "1--12",
  year =         "2000",
  title =        "VolumePro 500 - graphical accelerator for volume
                 rendering",
  author =       "P. Felkel",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-419",
  month =        jul,
  note =         "In Czech.",
  number =       "30",
  journal =      "Elektrorevue - \v{C}asopis pro elektroniku",
}

@InProceedings{EVL-2000-42,
  pages =        "65--74",
  year =         "2000",
  title =        "A Microfacet-based {BRDF} Generator",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-42",
  author =       "Michael Ashikhmin and Simon Premoze and Peter
                 Shirley",
  abstract =     "A method is presented that takes as an input a 2D
                 microfacet orientation distribution and produces a 4D
                 bidirectional reflectance distribution function (BRDF).
                 This method differs from previous microfacet-based BRDF
                 models in that it uses a simple shadowing term which
                 allows it to handle very general microfacet
                 distributions while maintaining reciprocity and energy
                 conservation. The generator is shown on a variety of
                 material types.",
  editor =       "Kurt Akeley",
  keywords =     "Reflectance & Shading Models, Rendering",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@TechReport{EVL-2000-420,
  pages =        "39",
  year =         "2000",
  title =        "Segmentation of Vessels in Peripheral {CTA} Datasets",
  type =         "VRVis Technical report",
  author =       "P. Felkel",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-420",
  address =      "Donau-City-Stra\ss{}e 1, A-1220~Vienna, Austria,
                 \textit{www.vrvis.at}",
  month =        dec,
  number =       "TR-VRVis-2000-008",
  institution =  "VRVis Center",
}

@InProceedings{EVL-2000-421,
  pages =        "7--13",
  year =         "2000",
  title =        "Level-of-detail volume rendering via 3{D} textures",
  author =       "Manfred Weiler and R{\"{u}}diger Westermann and Chuck
                 Hansen and Kurt Zimmermann and Thomas Ertl",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-421",
  abstract =     "In this paper we present an adaptive approach to
                 volume rendering via 3D textures at arbitrary levels of
                 detail. The algorithm has been designed to enable
                 interactive exploration of large-scale data sets while
                 providing user-adjustable resolution levels. A texture
                 map hierarchy is constructed in a way that minimizes
                 the amount of texture memory with respect to the
                 power-of-two restriction imposed by OpenGL
                 implementations. In addition, our hierarchical
                 level-of-detail representation guarantees consistent
                 interpolation between different resolution levels.
                 Special attention has been paid to the fixing of
                 rendering artifacts that are introduced by
                 non-corrected opacities at level transitions. By
                 adapting the sample slice distance with regard to the
                 desired level-of-detail, the number of texture lookups
                 is reduced significantly.",
  booktitle =    "Proceedings of the 2000 IEEE symposium on Volume
                 visualization",
}

@InProceedings{EVL-2000-422,
  pages =        "43--48",
  year =         "2000",
  title =        "Fast {CSG} Voxelization by Frame Buffer Pixel
                 Mapping",
  author =       "Shiaofen Fang and Duoduo Liao",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-422",
  abstract =     "This paper describes a fast algorithm for the volume
                 conversion and rendering of CSG models constructed from
                 both geometric and volumetric primitives. Using 3D
                 texture mapping and frame buffer pixel operations, the
                 algorithm can interactively generate a binary volume of
                 the CSG model. The result can be used for volume
                 rendering and other applications. Boolean operations
                 are implicitly computed by a Point-Classification Map,
                 and implemented by a hardware assisted frame buffer
                 pixel map. The algorithm can be applied to any regions
                 of interest of the model, thus provides a
                 multi-resolution rendering solution through dynamic
                 voxelization of the viewing regions. Since no
                 pre-processing is required for any change of the CSG
                 tree, it can be used as an effective rendering tool in
                 a volumetric CSG modeling environment.",
  keywords =     "Voxelization, CSG modeling, volume rendering, 3D
                 texture mapping",
  booktitle =    "Proceedings of the 2000 IEEE symposium on Volume
                 visualization",
}

@InProceedings{EVL-2000-423,
  pages =        "49--56",
  year =         "2000",
  title =        "Volume Scene Graphs",
  author =       "David R. Nadeau",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-423",
  abstract =     "This paper discusses volume scene graphs - a flexible
                 hierarchical structure for composing scenes containing
                 volume data sets and space-filling functions. Scene
                 graph nodes are functions that, when evaluated at a
                 point in space and time, compute and return a value.
                 Typical nodes return values sampled from volume data
                 sets, compute values using procedural texture
                 algorithms, or filter and composite values returned by
                 one or more other scene graph functions. Voxelization
                 of a scene graph repeatedly evaluates the graph's
                 functions over a gridded region of space. Examples are
                 shown that compose scenes containing multiple volume
                 data sets of differing resolutions and modalities.",
  keywords =     "Scene graphs, volume graphics, volume visualization",
  booktitle =    "Proceedings of the 2000 IEEE symposium on Volume
                 visualization",
}

@InProceedings{EVL-2000-424,
  pages =        "81--90",
  year =         "2000",
  title =        "A practical evaluation of popular volume rendering
                 algorithms",
  author =       "Michael Mei{\ss{}}ner and Jian Huang and Dirk Bartz
                 and Klaus Mueller and Roger Crawfis",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-424",
  abstract =     "This paper evaluates and compares four volume
                 rendering algorithms that have become rather popular
                 for rendering datasets described on uniform rectilinear
                 grids: raycasting, splatting, shear-warp, and
                 hardware-assisted 3D texture-mapping. In order to
                 assess both the strengths and the weaknesses of these
                 algorithms in a wide variety of scenarios, a set of
                 real-life benchmark datasets with different
                 characteristics was carefully selected. In the
                 rendering, all algorithm-independent image synthesis
                 parameters, such as viewing matrix, transfer functions,
                 and optical model, were kept constant to enable a fair
                 comparison of the rendering results. Both image quality
                 and computational complexity were evaluated and
                 compared, with the aim of providing both researchers
                 and practitioners with guidelines on which algorithm is
                 most suited in which scenario. Our analysis also
                 indicates the current weaknesses in each algorithm's
                 pipeline, and possible solutions to these as well as
                 pointers for future research are offered.",
  booktitle =    "Proceedings of the 2000 IEEE symposium on Volume
                 visualization",
}

@InProceedings{EVL-2000-425,
  pages =        "71--79",
  year =         "2000",
  title =        "The UltraVis System",
  author =       "Gunter Knittel",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-425",
  abstract =     "This paper describes architecture and implementation
                 of the UltraVis system, a pure software solution for
                 versatile and fast volume rendering. It provides
                 perspective raycasting, tri-linear interpolation, on-
                 the-fly classification using look-up tables, gradient
                 shading (both diffuse and specular reflection), four
                 light sources, and alpha blending. For high frame
                 rates, early ray termination and empty space skipping
                 are implemented. Furthermore, subsampling during motion
                 is provided. The system accepts raw data sets of 8-bit
                 voxels as well as pre-segmented data sets containing up
                 to 16 different materials. For gradient shading, the
                 gradients are precomputed and included in 32-bit
                 voxels. Additionally, the system supports volume
                 animation, i.e., the display of a sequence of data
                 sets. The system was specifically designed for Pentium
                 III CPUs, and makes extensive use of MMX and Streaming
                 SIMD instructions. It is a multi-threaded application
                 and thus takes advantage of multiprocessor platforms.
                 Time-critical portions of the code have been
                 hand-optimized in assembler. As a result, the system
                 can achieve interactive to real-time performance.
                 UltraVis runs on the Windows NT 4.0 operating system on
                 standard PCs.",
  booktitle =    "Proceedings of the 2000 IEEE symposium on Volume
                 visualization",
}

@InProceedings{EVL-2000-426,
  pages =        "91--99",
  year =         "2000",
  title =        "{ZSWEEP}: an efficient and exact projection algorithm
                 for unstructured volume rendering",
  author =       "Ricardo Farias and Joseph S. B. Mitchell and
                 Cl{\'{a}}udio T. Silva",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-426",
  abstract =     "We present a simple new algorithm that performs fast
                 and memory-efficient cell projection for (exact)
                 rendering of unstructured datasets. The main idea of
                 the {"}ZSweep{"} algorithm is very simple; it is based
                 on sweeping the data with a plane parallel to the
                 viewing plane, in order of increasing z, projecting the
                 faces of cells that are incident to vertices as they
                 are encountered by the sweep plane. The efficiency
                 arises from the fact that the algorithm exploits the
                 implicit (approximate) global ordering that the
                 z-ordering of the vertices induces on the cells that
                 are incident on them. The algorithm projects cells by
                 projecting each of their faces, with special care taken
                 to avoid double projection of internal faces and to
                 assure correctness in the projection order. The
                 contribution for each pixel is computed in stages,
                 during the sweep, using a short list of ordered face
                 intersections, which is known to be correct and
                 complete at the instant that each stage of the
                 computation is completed. The ZSweep algorithm is
                 simple enough to be readilyad aptable to general
                 (non-tetrahedral) cell formats. It is memory efficient,
                 since its auxiliary data structures have only to store
                 partial information taken from a small number of
                 {"}slices{"} of the dataset. We also introduce a simple
                 technique of data sparsification, which may be of
                 interest in its own right. Our implementation is
                 hardware-independent and handles datasets containing
                 tetrahedral and/or hexahedral cells. We give
                 experimental evidence that our method is competitive,
                 upto 5 times faster than the best previously-known
                 exact algorithms that use comparable amounts of memory,
                 while using much less memory than ray-casting.",
  booktitle =    "Proceedings of the 2000 IEEE symposium on Volume
                 visualization",
}

@InProceedings{EVL-2000-427,
  pages =        "101--108",
  year =         "2000",
  title =        "Mastering windows: improving reconstruction",
  author =       "Thomas Theu{\ss{}}l and Helwig Hauser and Eduard
                 Gr{\"{o}}ller",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-427",
  abstract =     "Ideal reconstruction filters, for function or
                 arbitrary derivative reconstruction, have to be bounded
                 in order to be practicable since they are infinite in
                 their spatial extend. This can be accomplished by
                 multiplying them with windowing functions. In this
                 paper, we discuss and assess the quality of commonly
                 used windows and show that most of them are
                 unsatisfactory in terms of numerical accuracy.
                 Particularly useful are the Kaiser and Gaussian windows
                 since both have a parameter to control the shape of the
                 window, which, on the other hand, requires to find
                 appropriate values for these parameters. We show how to
                 derive optimal parameter values for Kaiser and Gaussian
                 windows using a Taylor series expansion of the
                 convolution sum.",
  keywords =     "Ideal reconstruction, windowing, frequency response,
                 Taylor series expansion",
  booktitle =    "Proceedings of the 2000 IEEE symposium on Volume
                 visualization",
}

@InProceedings{EVL-2000-428,
  pages =        "109--117",
  year =         "2000",
  title =        "Volumetric Backprojection",
  author =       "Frank Dachille IX and Klaus Mueller and Arie
                 Kaufman.",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-428",
  abstract =     "Volumetric energy backprojection captures the effects
                 of myriad physical processes including global
                 illumination and reconstruction. We present a method to
                 perform efficient volumetric backprojection in
                 software. We develop a new method for global
                 illumination based on iterated volumetric
                 backprojection. We demonstrate how computed tomography
                 and visible light reconstruction can be implemented
                 using volumetric backprojection. Our new form of opaque
                 reconstruction is insensitive to shading and includes
                 the partial volume effect. Finally, we suggest small
                 modifications to volume rendering hardware which
                 permits efficient, scalable volumetric
                 backprojection.",
  keywords =     "Global illumination, radiosity. radiative transport,
                 volume rendering, reconstruction, opaque
                 reconstruction",
  booktitle =    "Proceedings of the 2000 IEEE symposium on Volume
                 visualization",
}

@InProceedings{EVL-2000-429,
  pages =        "119--137",
  year =         "2000",
  title =        "Accelerating time-varying hardware volume rendering
                 using {TSP} trees and color-based error metrics",
  author =       "David Ellsworth and Ling-Jen Chiang and Han-Wei Shen",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-429",
  abstract =     "This paper describes a new hardware volume rendering
                 algorithm for time-varying data. The algorithm uses the
                 Time-Space Partitioning (TSP) tree data structure to
                 identify regions within the data that have spatial or
                 temporal coherence. By using this coherence, the
                 rendering algorithm can improve performance when the
                 volume data are larger than the texture memory capacity
                 by decreasing the amount of textures required. This
                 coherence can also allow improved speed by
                 appropriately rendering flat-shaded polygons instead of
                 textured polygons, and by not rendering transparent
                 regions. To reduce the polygonization overhead caused
                 by the use of the hierarchical data structure, we use a
                 fast incremental polygon slicing algorithm. The paper
                 also introduces new color-based error metrics, which
                 more accurately identify coherent regions compared to
                 the earlier scalar-based metrics. By showing
                 experimental results from runs using different data
                 sets and error metrics, we demonstrate that the new
                 methods give substantial improvements in volume
                 rendering performance.",
  keywords =     "Scalar field visualization, volume visualzation,
                 volume rendering, time-varying fields, graphics
                 hardware",
  booktitle =    "Proceedings of the 2000 IEEE symposium on Volume
                 visualization",
}

@InProceedings{EVL-2000-43,
  pages =        "75--84",
  year =         "2000",
  title =        "Monte Carlo Evaluation Of Non-Linear Scattering
                 Equations For Subsurface Reflection",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-43",
  author =       "Matt Pharr and Pat Hanrahan",
  abstract =     "We describe a new mathematical framework for solving a
                 wide variety of rendering problems based on a
                 non-linear integral scattering equation. This framework
                 treats the scattering functions of complex aggregate
                 objects as first-class rendering primitives; these
                 scattering functions accurately account for all
                 scattering events inside them. We also describe new
                 techniques for computing scattering functions from the
                 composition of scattering objects. We demonstrate that
                 solution techniques based on this new approach can be
                 more efficient than previous techniques based on
                 radiance transport and the equation of transfer and we
                 apply these techniques to a number of problems in
                 rendering scattering from complex surfaces.",
  editor =       "Kurt Akeley",
  keywords =     "Rendering, Illumination, Monte Carlo Techniques,
                 Reflectance and Shading Models, Scattering Function,
                 Invariant Imbedding, Principles of Invariance, Equation
                 of Transfer, Adding Equations, Chandrasehkars
                 Equation",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Procedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman.",
}

@InProceedings{EVL-2000-430,
  pages =        "129--137",
  year =         "2000",
  title =        "4{D} Volume rendering with the Shear Warp
                 factorisation",
  author =       "Kostas Anagnostou and Tim J. Atherton and Andrew E.
                 Waterfall",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-430",
  abstract =     "A novel approach for rendering time-varying data based
                 on theShear-Warp factorisation is presented. Reduction
                 in storage space is achieved by detecting the changed
                 areas within each volume and compressing them.
                 Time-coherence is exploited by detecting and rendering
                 the changes in every volume while spatial-coherence is
                 exploited by utilising a data structure that allows
                 easy volume update and stores information about the
                 empty space within each volume.",
  keywords =     "Change detection, shear-warp factorisation,
                 time-varying data, volume rendering",
  booktitle =    "Proceedings of the 2000 IEEE symposium on Volume
                 visualization",
}

@InProceedings{EVL-2000-431,
  pages =        "3--16",
  year =         "2000",
  title =        "Human Walking Animation Based on Foot Reaction Force
                 in the Three-dimensional Virtual World",
  author =       "Ken Tsutsuguchi and Satoshi Shimada and Yasuhito
                 Suenaga and Noboru Sonehara and Sakuichi Ohtsuka",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-431",
  abstract =     "This paper introduces a method that can generate
                 continuous human walking motion automatically on an
                 arbitrary path in a three-dimensional (3D) modelled
                 scene. The method is based on a physical approach that
                 solves the boundary value problem. In the motion
                 generation stage, natural-looking walking motion, which
                 includes plane walking, walking upstairs and downstairs
                 and walking on a curved path, is created by applying
                 dynamics and kinematics. The human body is approximated
                 as a simple rigid skeleton model, and dynamic motion is
                 created based on the ground reaction force of the human
                 foot. To adapt to the 3D environment, the 3D walking
                 path is divided into steps which are tagged with the
                 parameters needed for motion generation, and
                 step-by-step motion is connected end-to-end. Additional
                 features include fast calculation and a reduced need
                 for user control. The proposed method can produce
                 interesting human motion and can create realistic
                 computer animation scenes.",
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  volume =       "11(1)",
  keywords =     "Computer animation; human walking, foot reaction
                 force, dynamics, terrain-adaptive walking",
  booktitle =    "The Journal of Visualization and Computer Animation",
  publisher =    "John Wiley & Sons, Ltd.",
}

@InProceedings{EVL-2000-432,
  pages =        "17--26",
  year =         "2000",
  title =        "A Dynamic Animation Engine for Generic Spline
                 Objects",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-432",
  author =       "Yannick R{\'{e}}mion and Jean-Michel Nourrit and
                 Didier Gillard",
  abstract =     "This paper introduces an accurate and efficient engine
                 whose purpose is the dynamic animation of curvilinear
                 objects which are modelled as successions of splines.
                 At each time step the object shape conforms to its
                 spline definitions, thus ensuring that each property
                 implied by the chosen spline models is verified. This
                 is achieved by animating spline control points.
                 However, these control points are not considered as
                 material points but rather as the degrees of freedom of
                 the continuous object. The chosen dynamic equations
                 (Lagrangian formalism) reflect this modelling scheme
                 and yield an exact and very proficient linear system.
                 In the chosen formalism, forces are introduced by
                 either their potential energy or their power ratings in
                 the virtual movements instilled by the degrees of
                 freedom. Both methods are carried out in three cases:
                 gravity, viscosity and generic force. Suitable and
                 classical methods for constraint handling and numerical
                 resolution are briefly discussed. Finally, this
                 animation engine is applied to knitted patterns",
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  keywords =     "Dynamic animation, Lagrange equations, spline
                 animation",
  volume =       "11(1)",
  booktitle =    "The Journal of Visualization and Computer Animation",
  publisher =    "John Wiley & Sons, Ltd.",
}

@InProceedings{EVL-2000-433,
  pages =        "27--37",
  year =         "2000",
  title =        "On Modelling and Rendering Ocean Scenes",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-433",
  author =       "Jean-Christophe Gonzato and Bertrand Le Sa{\"{e}}c",
  abstract =     "This paper is devoted to ocean images. First we
                 propose a complete geometrical model accounting for
                 refraction, diffraction, reflection, transmission and
                 multiwave trains. Then we describe a specific algorithm
                 for the rendering of coastal scenes.",
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  keywords =     "Ocean, dynamic wave tracing. optical phenomena,
                 displacement mapping, illumination, ray tracing",
  volume =       "11(1)",
  booktitle =    "The Journal of Visualization and Computer Animation",
  publisher =    "John Wiley & Sons, Ltd.",
}

@InProceedings{EVL-2000-434,
  pages =        "39--49",
  year =         "2000",
  title =        "An Efficient Voxel-based Visualization System from an
                 Implicit Skeletal Surface Characterization",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-434",
  author =       "St{\'{e}}phanie Pr{\'{e}}vost and Laurent Lucas",
  abstract =     "This paper presents a new algorithm of volume
                 rendering based on a dual representation of data. The
                 algorithm improves both the image generation speed and
                 its quality. Two shape descriptors are used to
                 characterize the object: a Euclidean distance transform
                 (EDT) and a digital Euclidean skeleton. The EDT is used
                 at one point in time to accelerate the image generation
                 and compute the skeleton of the shape, whilst the
                 skeleton is used as an initialization of the processing
                 of the implicit surface. The goal is to build an
                 interactive system of visualization for the analysis of
                 volumetric data, either in the setting of a qualitative
                 exploration or as a guide for qualitative measurements.
                 The speed of treatment together with good visualization
                 should give the feasibility to achieve a 3D survey of a
                 natural object in an interactive manner. The method has
                 been successfully applied to both synthetic and real
                 data.",
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  keywords =     "Volume rendering, implicit surface, EDT, morphologic
                 skeleton",
  volume =       "11(1)",
  booktitle =    "The Journal of Visualization and Computer Animation",
  publisher =    "John Wiley & Sons, Ltd.",
}

@InProceedings{EVL-2000-435,
  pages =        "51--65",
  year =         "2000",
  title =        "Simulators for Medical Training: Application to
                 Vascular Ultrasound Imaging",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-435",
  author =       "Jocelyne Troccaz and Delphine Henry and Noureddine
                 Laieb and Guillaume Champleboux and Jean-Luc Bosson and
                 Olivier Pichot",
  abstract =     "Whilst computers are more and more used in the medical
                 and surgical domains, medical education is still very
                 conservative. However, new information technology could
                 bring a lot to this area. In particular, simulators are
                 of paramount interest: they would allow one both to
                 experiment with surgical or imaging techniques for a
                 wide range of pathologies without the need for patients
                 and to quantitatively evaluate the trainees'
                 performances. Ultrasound imaging is a typical area
                 where virtual reality may change educational uses. This
                 paper describes an ultrasound imaging simulator
                 dedicated to the training of physicians for the
                 detection of deep venous thromboses of the lower limbs.
                 Like this one, a lot of other pathologies of soft
                 tissue are diagnosed using ultrasound imaging. Because
                 this examination is difficult and operator-dependent,
                 developing a simulator is very useful to give common
                 databases of pathological samples on which physicians
                 can both experiment with image acquisition and evaluate
                 their understanding of clinical cases. Real-time
                 simulation is mandatory. An ultrasound imaging
                 simulator has been developed and is being tested. This
                 paper presents the hardware and software components of
                 the simulator and describes the status of this
                 project.",
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  keywords =     "Medical training, simulation, echography,
                 interpolation, deformable models",
  volume =       "11(1)",
  booktitle =    "The Journal of Visualization and Computer Animation",
  publisher =    "John Wiley & Sons, Ltd.",
}

@InProceedings{EVL-2000-436,
  pages =        "69--82",
  year =         "2000",
  title =        "Computing Swept Volumes",
  author =       "Steven Abrams and Peter K. Allen",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-436",
  abstract =     "The swept volume problem is practical, difficult and
                 interesting enough to have received a great deal of
                 attention over the years, and the literature contains
                 much discussion of methods for computing swept volumes
                 in many situations. The method presented here permits
                 an arbitrary polyhedral object (given in a typical
                 boundary representation) to be swept through an
                 arbitrary trajectory. A polyhedral approximation to the
                 volume swept by this moving object is computed and
                 output in a typical boundary representation. A number
                 of examples are presented demonstrating the
                 practicality of this method.",
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  volume =       "11(2)",
  booktitle =    "The Journal of Visualization and Computer Animation",
  publisher =    "John Wiley & Sons, Ltd.",
}

@InProceedings{EVL-2000-437,
  pages =        "83--94",
  year =         "2000",
  title =        "A framework for interactive responsive animation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-437",
  author =       "Hanqiu Sun and Mark Green",
  abstract =     "The availability of high-performance 3D workstations
                 has increased the range of application for interactive
                 real-time animation. In these applications the user can
                 directly interact with the objects in the animation and
                 direct the evolution of their motion, rather than
                 simply watching a pre-computed animation sequence.
                 Interactive real-time animation has fast-growing
                 applications in virtual reality, scientific
                 visualization, medical training and distant learning.
                 Traditional approaches to computer animation have been
                 based on the animator having complete control over all
                 aspects of the motion. In interactive animation the
                 user can interact with any of the objects, which
                 changes the current motion path or behaviour in real
                 time. The objects in the animation must be capable of
                 reacting to the user's actions and not simply replay a
                 canned motion sequence. This paper presents a framework
                 for interactive animation that allows the animator to
                 specify the reactions of objects to events generated by
                 other objects and the user. This framework is based on
                 the concept of relations that describe how an object
                 reacts to the influence of a dynamic environment. Each
                 relation specifies one motion primitive triggered by
                 either its enabling condition or the state of the
                 environment. A collection of the relations is
                 structured through several hierarchical layers to
                 produce responsive behaviours and their variations.
                 This framework is illustrated by several room-based
                 dancing examples that are modelled by relations.",
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  keywords =     "Interactive animation, 3D motion specification,
                 behavioural animation",
  volume =       "11(2)",
  booktitle =    "The Journal of Visualization and Computer Animation",
  publisher =    "John Wiley & Sons, Ltd.",
}

@InProceedings{EVL-2000-438,
  pages =        "95--104",
  year =         "2000",
  title =        "Realistic rendering with turbulent flows",
  author =       "Didier Arqu{\`{e}}s and Eric Felgines and Sylvain
                 Michelin and Karine Zampieri",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-438",
  abstract =     "This paper focuses on realistic rendering of scenes
                 which include turbulent flows. In this respect we
                 suggest solving the Navier-Stokes equations through a
                 simple approach which offers better steadiness than
                 classical methods. Then we adapt a ray-tracing
                 algorithm to treat convection motions by deflecting ray
                 paths: we obtain effects of rendering through heat.",
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  volume =       "11(2)",
  keywords =     "Realistic rendering, heat transfer convection,
                 numerical simulation",
  booktitle =    "The Journal of Visualization and Computer Animation",
  publisher =    "John Wiley & Sons, Ltd.",
}

@InProceedings{EVL-2000-439,
  pages =        "105--112",
  year =         "2000",
  title =        "Psychological Evidence for Unconscious Processing of
                 Detail in Real-time Animation of Multiple Characters",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-439",
  author =       "Markus Oesker and Heiko Hecht and Bernhard Jung",
  abstract =     "Detailed animation of 3D articulated body models is in
                 principle desirable but is also a highly
                 resource-intensive task. Resource limitations are
                 particularly critical in 3D visualizations of multiple
                 characters in real-time game sequences. We investigated
                 to what extent observers perceptually process the level
                 of detail in naturalistic character animations. Only if
                 such processing occurs would it be justified to spend
                 valuable resources on richness of detail. An experiment
                 was designed to test the effectiveness of 3D body
                 animation. Observers had to judge the level of overall
                 skill exhibited by four simulated soccer teams. The
                 simulations were based on recorded RoboCup simulation
                 league games. Thus objective skill levels were known
                 from the teams' placement in the tournament. The
                 animations' level of detail was varied in four
                 increasing steps of modelling complexity. Results
                 showed that observers failed to notice the differences
                 in detail. Nonetheless, clear effects of character
                 animation on perceived skill were found. We conclude
                 that character animation co-determines perceptual
                 judgements even when observers are completely unaware
                 of these manipulations",
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  keywords =     "Interactive visualization, human character animation,
                 perceptual processing",
  volume =       "11(2)",
  booktitle =    "The Journal of Visualization and Computer Animation",
  publisher =    "John Wiley & Sons, Ltd.",
}

@InProceedings{EVL-2000-44,
  pages =        "85--94",
  year =         "2000",
  title =        "Displaced Subdivision Surfaces",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-44",
  author =       "Aaron Lee and Henry Moreton and Hugues Hoppe",
  abstract =     "In this paper we introduce a new surface
                 representation, the displaced subdivision surface. It
                 represents a detailed surface model as a scalar-valued
                 displacement over a smooth domain surface. Our
                 representation defines both the domain surface and the
                 displacement function using a unified subdivision
                 framework, allowing for simple and efficient evaluation
                 of analytic surface properties. We present a simple,
                 automatic scheme for converting detailed geometric
                 models into such a representation. The challenge in
                 this conversion process is to find a simple subdivision
                 surface that still faithfully expresses the detailed
                 model as its offset. We demonstrate that displaced
                 subdivision surfaces offer a number of benefits,
                 including geometry compression, editing, animation,
                 scalability, and adaptive rendering. In particular, the
                 encoding of fine detail as a scalar function makes the
                 representation extremely compact",
  editor =       "Kurt Akeley",
  keywords =     "geometry compression, multiresolution geometry,
                 displacement maps, bump maps, multiresolution editing,
                 animation",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-440,
  pages =        "115--127",
  year =         "2000",
  title =        "Realistic Surface Reconstruction of 3{D} Scenes from
                 Uncalibrated Image Sequences",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-440",
  author =       "Reinhard Koch and Marc Pollefeys and Luc Van Gool",
  abstract =     "This contribution addresses the problem of obtaining
                 3D models from image sequences. A 3D surface
                 description of the scene is extracted completely from a
                 set of uncalibrated camera images of the scene. No
                 prior knowledge about the scene or about the camera is
                 needed to build the 3D models. The only assumptions are
                 the rigidity of the scene objects and opaque object
                 surfaces. The modelling system described here uses a
                 three-step approach. First, the camera pose and
                 intrinsic parameters are calibrated by tracking salient
                 feature points throughout the sequence. Next,
                 consecutive images of the sequence are treated as
                 stereoscopic image pairs, and dense correspondence maps
                 are computed by area matching. Finally, dense and
                 accurate depth maps are computed by linking together
                 all correspondences over the viewpoints. The depth maps
                 are converted to triangular surfaces meshes that are
                 texture mapped for photo-realistic appearance. The
                 feasibility of the approach has been tested on both
                 real and synthetic data and is illustrated here on
                 several outdoor image sequences.",
  editor =       "Franz-Erich Wolter and Nicholas M. Patrikalakis",
  keywords =     "Image sequence analysis, 3D scene reconstruction,
                 camera calibration, photo-realistic 3D modeling",
  volume =       "11(3)",
  booktitle =    "The Journal of Visualization and Computer Animation",
  publisher =    "John Wiley & Sons, Ltd.",
}

@InProceedings{EVL-2000-441,
  pages =        "129--143",
  year =         "2000",
  title =        "{R}-Trees for Organizing and Visualizing 3{D} {GIS}
                 Databases",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-441",
  author =       "Michael Kofler and Michael Gervautz and Michael
                 Gruber",
  abstract =     "With the migration from 2D to 3D geographical
                 information systems (GISs), the amounts of data to
                 manage grow substantially. At the same time, 3D
                 real-time rendering is necessary to provide a
                 convenient user interface. Traditional GIS data
                 management functions are too slow for this purpose,
                 while computer graphics algorithms fail to deal with
                 the sheer amount of data efficiently. In this paper we
                 present LOD-R-trees, a new data structure which
                 elegantly combines R-trees with LODs (levels of
                 detail). Two applications demonstrate the versatility
                 of our approach. With the Vienna Walkthrough System one
                 can virtually walk through Vienna, the capital of
                 Austria. The geometric model consists of about 20,000
                 blocks of buildings, covering about 75% of Vienna (150
                 km2 out of 200 km2). With the Styria Flyover System one
                 can virtually fly over Styria, a province of Austria.
                 The digital model covers Styria and parts of its
                 adjoining provinces (30,000 km2); it is based on a
                 digital terrain model (DTM) consisting of more than 23
                 million triangles and of 50 Mbyte texture data
                 (satellite images). Both applications provide
                 progressive rendering and dynamic performance
                 adjustment. On an SGI 02 they deliver about 10 frames
                 per second. Our approach demonstrates that efficient
                 algorithms make a fast 3D GIS user interface possible
                 without spending a fortune on hardware.",
  editor =       "Franz-Erich Wolter and Nicholas M. Patrikalakis",
  keywords =     "Geographical information systems, R-trees, 3D
                 rendering, levels of detail",
  volume =       "11(3)",
  booktitle =    "The Journal of Visualization and Computer Animation",
  publisher =    "John Wiley & Sons, Ltd.",
}

@InProceedings{EVL-2000-442,
  pages =        "145--154",
  year =         "2000",
  title =        "Creation of Flexible Anthropomorphic Models for 3{D}
                 Videoconferencing Using Shape from Silhouettes",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-442",
  author =       "S. Weik and J. Wingberm{\"{u}}hle and W. Niem",
  abstract =     "This contribution describes the semi-automatic
                 creation of highly realistic flexible 3D models of
                 participants for distributed 3D videoconferencing
                 systems. The proposed technique uses a flexible mesh
                 template surrounding an interior skeleton structure
                 which is based on a simplified human skeleton. The
                 vertices of this template are arranged in rigid rings
                 along the bones of the skeleton. Using 3D data obtained
                 by a shape from silhouettes approach, the size and
                 shape of the mesh template are adapted to the real
                 person. Texture mapping of the adapted mesh using real
                 camera images leads to a natural impression. The mesh
                 organization in rigid rings allows an efficient surface
                 deformation according to the skeleton movements. Once
                 the resulting model is transmitted, it can be animated
                 subsequently using the simple parameter set of the
                 interior skeleton structure. Results obtained with real
                 image data confirm the eligibility of the animated
                 person models in terms of realism and efficiency for 3D
                 videoconferencing applications.",
  editor =       "Franz-Erich Wolter and Nicholas M. Patrikalakis",
  keywords =     "Anthropomorphic modelling, flexible deformation, shape
                 from silhouettes",
  volume =       "11(3)",
  booktitle =    "The Journal of Visualization and Computer Animation",
  publisher =    "John Wiley & Sons, Ltd.",
}

@InProceedings{EVL-2000-443,
  pages =        "155--166",
  year =         "2000",
  title =        "Virtual 3{D} Sculpting",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-443",
  author =       "Janis P. Y. Wong and Rynson W. H. Lau and Lizhuang
                 Ma",
  abstract =     "This paper presents a virtual sculpting method for
                 interactive 3D object deformation. The method is based
                 on the use of an electronic glove. A parametric control
                 hand surface defined by an open-uniform B-spline tensor
                 product surface is first created to model the hand
                 gesture. The geometric attributes of the object in the
                 Euclidean 3D space are then mapped to the parametric
                 domain of the control hand surface through a ray
                 projection method. By maintaining the distances between
                 the mapped pairs, change of hand gesture can be
                 efficiently transferred to control the deformation of
                 the object.",
  editor =       "Franz-Erich Wolter and Nicholas M. Patrikalakis",
  keywords =     "Virtual reality, CyberGlove, 3D sculpting, free-form
                 deformation",
  volume =       "11(3)",
  booktitle =    "The Journal of Visualization and Computer Animation",
  publisher =    "John Wiley & Sons, Ltd.",
}

@InProceedings{EVL-2000-444,
  pages =        "169--183",
  year =         "2000",
  title =        "Evolving Performance Control Systems for Digital
                 Puppetry",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-444",
  author =       "Andrew Gildfind and Michael A. Gigante and Ghassan
                 Al-Qaimari",
  abstract =     "We describe a new approach for creating performance
                 control systems for digital puppetry. Genetic
                 programming with fitness values specified directly by
                 the puppeteer is used. A generic device and model
                 representation combined with the inherent domain
                 independence of the genetic programming paradigm allows
                 this approach to create control systems for arbitrary
                 combinations of input devices and models. In addition,
                 a number of unique interaction techniques have been
                 developed to support the user-directed search. In this
                 paper we introduce the approach, describe the
                 implementation and user interface and present the
                 results from a comprehensive evaluation with expert
                 users. We show that a search-based approach can provide
                 an effective alternative to manually designing
                 performance control systems and an elegant mechanism
                 for unifying low-level input devices with a broad range
                 of model control modes.",
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  keywords =     "Performance animation, motion capture, performance
                 control systems, puppetry, adaptive user interfaces,
                 genetic programming",
  volume =       "11(4)",
  booktitle =    "The Journal of Visualization and Computer Animation",
  publisher =    "John Wiley & Sons, Ltd.",
}

@InProceedings{EVL-2000-445,
  pages =        "185--195",
  year =         "2000",
  title =        "Illumination and Acceleration in the Visualization of
                 Special Relativity: {A} Comment on Fast Rendering of
                 Relativistic Objects",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-445",
  author =       "Daniel Weiskopf and Ute Kraus and Hanns Ruder",
  abstract =     "We address the issue of illumination and acceleration
                 in special relativistic visualization. Betts (J.
                 Visual. Comput. Animat. 1998; 9: 17-31) presents an
                 incorrect derivation of the transformation of the
                 Rayleigh-Jeans radiation, which we compare to the
                 correct transformation of radiance in the framework of
                 special relativity. His rendering algorithm can be
                 modified to correctly account for the relativistic
                 effects on illumination. Furthermore, we show how
                 acceleration can be included in special relativistic
                 visualization by calculating the trajectory of
                 accelerating objects, which is a prerequisite for a
                 physically based camera model. Therefore interaction
                 and animation in special relativistic visualization are
                 possible.",
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  keywords =     "Special relativity, simulation, illumination,
                 animation, acceleration",
  volume =       "11(4)",
  booktitle =    "The Journal of Visualization and Computer Animation",
  publisher =    "John Wiley & Sons, Ltd.",
}

@InProceedings{EVL-2000-446,
  pages =        "197--208",
  year =         "2000",
  title =        "A deformable body model for surgical simulation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-446",
  author =       "P. Meseure and C. Chaillou",
  abstract =     "We propose a deformable body model in order to
                 simulate the dynamic behaviour of human organs in
                 surgical simulators. It is based on a spring surface
                 mesh, fitted with a virtual rigid component which does
                 not interact with the environment and provides the
                 structure with a rigid behaviour. This specific
                 structure is intended to be physically based and
                 interactive but also to support dynamic alteration such
                 as incisions, under several constraints: mechanical
                 realism, robustness and real time. Moreover,
                 interactions are taken into account by a 4D collision
                 detection algorithm between polygonal objects, and
                 reponse is computed analytically.",
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  keywords =     "Physically based animation, deformable body,
                 collisions, surgical simulation",
  volume =       "11(4)",
  booktitle =    "The Journal of Visualization and Computer Animation",
  publisher =    "John Wiley & Sons, Ltd.",
}

@InProceedings{EVL-2000-447,
  pages =        "209--219",
  year =         "2000",
  title =        "An Improved Rendering Technique for Ray Tracing
                 {B}{\'{e}}zier and {B}-Spline Surfaces",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-447",
  author =       "Shyue-Wu Wang and Zen-Chung Shih and Ruei-Chuan
                 Chang",
  abstract =     "Both numerical and subdivision methods are widely used
                 approaches for ray tracing parametric surfaces.
                 However, the expense of finding the ray-surface
                 intersection points is a major drawback. Thus, simpler
                 and less memory-intensive strategies are needed to
                 improve these methods without further complicating
                 them. This work presents an efficient algorithm for
                 enhancing the performance of both numerical and
                 subdivision methods. The proposed technique can be
                 extended to most applications based on these two
                 methods. The computational time of both approaches is
                 improved by 16-40%.",
  editor =       "Nadia Magnenat-Thalmann and Daniel Thalmann",
  keywords =     "Ray tracing, Newton's method, B{\'{e}}zier clipping,
                 parametric surfaces, B{\'{e}}zier surfaces",
  volume =       "11(4)",
  booktitle =    "The Journal of Visualization and Computer Animation",
  publisher =    "John Wiley & Sons, Ltd.",
}

@InProceedings{EVL-2000-448,
  pages =        "223--235",
  year =         "2000",
  title =        "Online Motion Retargetting",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-448",
  author =       "Kwang-Jin Choi and Hyeong-Seok Ko",
  abstract =     "This paper presents a method to retarget the motion of
                 a character to another in real time. The technique is
                 based on inverse rate control, which computes the
                 changes in joint angles corresponding to the changes in
                 end-effector position. While tracking the multiple
                 end-effector trajectories of the original subject or
                 character, our online motion retargetting also
                 minimizes the joint angle differences by exploiting the
                 kinematic redundancies of the animated model. This
                 method can apply a captured motion to another
                 anthropometry so that it can perform slightly different
                 motion, while preserving the original motion
                 characteristics. Because the above is done online, a
                 real-time performance can be mapped to other
                 characters. Moreover, if the method is used
                 interactively during motion capture session, the
                 feedback of retargetted motion on the screen provides
                 more chances to get satisfactory results. As a
                 by-product, our algorithm can be used to reduce
                 measurement errors in restoring captured motion. The
                 data enhancement improves the accuracy in both joint
                 angles and end-effector positions. Experimental results
                 show that our retargetting algorithm preserves
                 high-frequency details of the original motion quite
                 accurately.",
  editor =       "Myung-Soo Kim and Hans-Peter Seidel",
  keywords =     "Character animation, motion retargetting, motion
                 editing, inverse kinematics",
  volume =       "11(5)",
  booktitle =    "The Journal of Visualization and Computer Animation",
  publisher =    "John Wiley & Sons, Ltd.",
}

@InProceedings{EVL-2000-449,
  pages =        "237--248",
  year =         "2000",
  title =        "A Motion Generator Approach to Translating Human
                 Motion from Video to Animation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-449",
  author =       "Tsukasa Noma and Kyoji Oishi and Hiroshi Futsuhara and
                 Hiromi Baba and Takeshi Ohashi and Toshiaki Ejima",
  abstract =     "This paper proposes a motion generator approach to
                 translating human motion from video image sequences to
                 computer animations in real time. In this approach, a
                 motion generator makes inferences about the current
                 human motion and/or posture from the data obtained by
                 processing the source video images, and then generates
                 a set of joint angles for the target human body model.
                 Compared with conventional motion capture methods, our
                 approach is more robust, and tolerant of broader
                 environmental and postural conditions. Experiments on a
                 prototype system show that an animated virtual human
                 can walk, sit, and lie as the real human performs
                 without special illumination control.",
  editor =       "Myung-Soo Kim and Hans-Peter Seidel",
  keywords =     "Motion generator approach; human body tracking, human
                 body animation, motion capture, video processing,
                 surveillance",
  volume =       "11(5)",
  booktitle =    "The Journal of Visualization and Computer Animation",
  publisher =    "John Wiley & Sons, Ltd.",
}

@InProceedings{EVL-2000-45,
  pages =        "103--112",
  year =         "2000",
  title =        "sqrt(3) Subdivision",
  author =       "Leif Kobbelt",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-45",
  abstract =     "A new stationary subdivision scheme is presented which
                 performs slower topological refinement than the usual
                 dyadic split operation. The number of triangles
                 increases in every step by a factor of 3 instead of 4.
                 Applying the subdivision operator twice causes a
                 uniform refinement with tri-section of every original
                 edge (hence the name sqrt(3)-subdivision) while two
                 dyadic splits would quad-sect every original edge.
                 Besides the finer gradation of the hierarchy levels,
                 the new scheme has several important properties: The
                 stencils for the subdivision rules have minimum size
                 and maximum symme-try. The smoothness of the limit
                 surface is C2 everywhere except for the extraordinary
                 points where it is C1. The convergence analysis of the
                 scheme is presented based on a new general technique
                 which also applies to the analysis of other subdivision
                 schemes. The new splitting operation enables locally
                 adaptive refinement under built-in preservation of the
                 mesh consistency without temporary crack-fixing between
                 neighboring faces from different refinement levels. The
                 size of the surrounding mesh area which is affected by
                 selective refinement is smaller than for the dyadic
                 split operation. We further present a simple extension
                 of the new subdivision scheme which makes it applicable
                 to meshes with boundary and allows us to generate sharp
                 feature lines.",
  editor =       "Kurt Akeley",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-450,
  pages =        "249--25249--259",
  year =         "2000",
  title =        "A Method to Generate Wet and Broken-up Animal Fur",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-450",
  author =       "Armin Bruderlin",
  abstract =     "This paper describes part of the pipeline which we
                 have implemented for the creation of hair and fur for
                 the motion picture Stuart Little. In particular, we
                 discuss the two effects of producing wet fur and
                 broken-up dry fur. We assume that our animal models
                 consist of a connected set of NURBS patches, which
                 define the skin onto which the individual hairs are
                 placed. A wet fur look is achieved by clumping together
                 of neighboring hairs within certain clumping areas on
                 the skin. The definition of these clumping areas can be
                 either static or animated, the latter to simulate
                 spouts of water hitting parts of the fur coat, making
                 it increasingly wet. A broken-up fur look is generated
                 by breaking of hairs along certain fur-tracks on the
                 skin.",
  editor =       "Myung-Soo Kim and Hans-Peter Seidel",
  keywords =     "Computer animation, hair, fur, natural phenomena,
                 special effects",
  volume =       "11(5)",
  booktitle =    "The Journal of Visualization and Computer Animation",
  publisher =    "John Wiley & Sons, Ltd.",
}

@InProceedings{EVL-2000-451,
  pages =        "261--277",
  year =         "2000",
  title =        "Thickening: An Operation for Animation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-451",
  author =       "Sylvain Brandel and Dominique Bechmann and Yves
                 Bertrand",
  abstract =     "In this paper, we present a modelling operation
                 dedicated to animation. This operation, called
                 thickening, is a generalization of the extrusion
                 operation. It allows to build from a graph 3-D objects
                 with circular section and 4-D objects with spherical or
                 toric section. Moreover, the date and the number of
                 mergings and splittings in the associated animation are
                 perfectly controlled, and the trajectory of each of the
                 animated objects is completely established. Several
                 types of thickening are presented in this paper, to
                 build a surface or a volume, starting from a graph
                 drawn in a surface or in a volume.",
  editor =       "Myung-Soo Kim and Hans-Peter Seidel",
  keywords =     "Animation, topologically based modelling, 4-D objects,
                 thickening",
  volume =       "11(5)",
  booktitle =    "The Journal of Visualization and Computer Animation",
  publisher =    "John Wiley & Sons, Ltd.",
}

@InProceedings{EVL-2000-452,
  pages =        "279--293",
  year =         "2000",
  title =        "Modeling and Rendering of Gaseous Phenomena Using
                 Particle Maps",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-452",
  author =       "Neeharika Adabala and Swami Manohar",
  abstract =     "Any modeling scheme for gaseous phenomena in graphics
                 has to capture three aspects: the fuzzy geometry of the
                 gas, the dynamics, characterized by the presence of
                 vortices, and the interaction of light with the gaseous
                 volume. We represent the gaseous volume as a particle
                 system and apply Vortex Element Methods (VEM) to model
                 the dynamics. A Lagrangian formulation that is gridless
                 and hence ideal for unbounded flows is used. A gridless
                 approach to ray tracing the particle systems is
                 developed using particle maps. These maps are used to
                 estimate densities within a gaseous volume analogous to
                 the way volume photon maps are used to estimate
                 radiance during Monte Carlo ray tracing. A technique is
                 proposed to merge particle and volume photon maps to
                 obtain an effective method for simulating multiple
                 scattering in a dynamic inhomogeneous participating
                 medium. Our method for modeling and rendering gaseous
                 phenomena is conceptually simple and grid free.
                 Particle maps play an effective role, as the nearest
                 neighbor information obtained during the rendering
                 phase is exploited during the dynamics computation. We
                 preset results that demonstrate the effectiveness of
                 our approach.",
  editor =       "Myung-Soo Kim and Hans-Peter Seidel",
  keywords =     "Computational fluid dynamics, physically based
                 animation, ray tracing, space-time ray tracing,
                 participating media, vortex methods",
  volume =       "11(5)",
  booktitle =    "The Journal of Visualization and Computer Animation",
  publisher =    "John Wiley & Sons, Ltd.",
}

@InProceedings{EVL-2000-453,
  pages =        "109--116",
  year =         "2000",
  title =        "Hardware-Accelerated Volume And Isosurface Rendering
                 Based On Cell-Projection",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-453",
  author =       "Stefan R{\"o}ttger and Martin Kraus and Thomas Ertl",
  abstract =     "We present two beneficial rendering extensions to the
                 Projected Tetrahedra (PT) algorithm by Shirley and
                 Tuchman. These extensions are compatible with any cell
                 sorting technique, for example the BSP-XMPVO sorting
                 algorithm for unstructured meshes. Using 3D texture
                 mapping our first extension solves the long-standing
                 problem of hardware-accelerated but accurate rendering
                 of tetrahedral volume cells with arbitrary transfer
                 functions. By employing 2D texture mapping our second
                 extension realizes the hardware-accelerated rendering
                 of multiple shaded isosurfaces within the PT algorithm
                 without reconstructing the isosurfaces. Additionally,
                 two methods are presented to combine projected
                 tetrahedral volumes with isosurfaces. The time
                 complexity of all our algorithms is linear in the
                 number of tetrahedra and does neither depend on the
                 number of isosurfaces nor on the employed transfer
                 functions.",
  keywords =     "Volume Rendering, Isosurfaces, Unstructured Meshes,
                 Cell Projection, Graphics Hardware, Texture Mapping,
                 Compositing.",
  booktitle =    "Proc. of the 11th Ann. IEEE Visualization Conference
                 (Vis) 2000",
}

@InProceedings{EVL-2000-454,
  pages =        "147--154",
  year =         "2000",
  title =        "A Level-Set Method for Flow Visualization",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-454",
  author =       "R{\"u}diger Westermann and Christopher Johnson and
                 Thomas Ertl",
  abstract =     "In this paper we propose a technique for visualizing
                 steady flow. Using this technique, we first convert the
                 vector field data into a scalar level-set
                 representation. We then analyze the dynamic behavior
                 and subsequent distortion of level-sets and
                 interactively monitor the evolving structures by means
                 of texture-based surface rendering. Next, we combine
                 geometrical and topological considerations to derive a
                 multiscale representation and to implement a method for
                 the automatic placement of a sparse set of graphical
                 primitives depicting homogeneous streams in the fields.
                 Using the resulting algorithms, we have built a
                 visualization system that enables us to effectively
                 display the flow direction and its dynamics even for
                 dense 3D fields.",
  keywords =     "Flow Visualization, Level-Sets, Feature Extraction,
                 Multiscale Representation, Texture Mapping",
  booktitle =    "Proc. of the 11th Ann. IEEE Visualization Conference
                 (Vis) 2000",
}

@InProceedings{EVL-2000-455,
  pages =        "275--282",
  year =         "2000",
  title =        "Semi-Regular Mesh Extraction from Volumes",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-455",
  author =       "Zo{\"{e}} J. Wood and Mathieu Desbrun and Peter
                 Schr{\"o}der and David Breen",
  abstract =     "We present a novel method to extract iso-surfaces from
                 distance volumes. It generates high quality
                 semi-regular multiresolution meshes of arbitrary
                 topology. Our technique proceeds in two stages. First,
                 a very coarse mesh with guaranteed topology is
                 extracted. Subsequently an iterative multi-scale
                 force-based solver refines the initial mesh into a
                 semi-regular mesh with geometrically adaptive sampling
                 rate and good aspect ratio triangles. The coarse mesh
                 extraction is performed using a new approach we call
                 surface wavefront propagation. A set of discrete
                 iso-distance ribbons are rapidly built and connected
                 while respecting the topology of the iso-surface
                 implied by the data. Subsequent multi-scale refinement
                 is driven by a simple force-based solver designed to
                 combine good iso-surface fit and high quality sampling
                 through reparameterization. In contrast to the Marching
                 Cubes technique our output meshes adapt gracefully to
                 the iso-surface geometry, have a natural
                 multiresolution structure and good aspect ratio
                 triangles, as demonstrated with a number of examples.",
  keywords =     "Semi-regular meshes, subdivision, volumes, surface
                 extraction, implicit functions, level set methods.",
  booktitle =    "Proc. of the 11th Ann. IEEE Visualization Conference
                 (Vis) 2000",
}

@InProceedings{EVL-2000-456,
  pages =        "227--234",
  year =         "2000",
  title =        "Texturing Techniques for Terrain Visualization",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-456",
  author =       "J{\"u}rgen D{\"o}llner and Konstantin Baumann and
                 Klaus Hinrichs",
  abstract =     "We present a new rendering technique for processing
                 multiple multiresolution textures of LOD terrain models
                 and describe its application to interactive, animated
                 terrain content design. The approach is based on a
                 multiresolution model for terrain texture which
                 cooperates with a multiresolution model for terrain
                 geometry. For each texture layer, an image pyramid and
                 a texture tree are constructed. Multiple texture layers
                 can be associated with one terrain model and can be
                 combined in different ways, e.g., by blending and
                 masking. The rendering algorithm traverses
                 simultaneously the geometry multiresolution model and
                 the texture multiresolution model, and takes into
                 account geometric and texture approximation errors. It
                 uses multi-pass rendering and exploits multitexturing
                 to achieve real-time performance. Applications include
                 interactive texture lenses, texture animation, and
                 topographic textures. These techniques offer an
                 enormous potential for developing new visualization
                 applications for presenting, exploring and manipulating
                 spatio-temporal data.",
  keywords =     "Terrain Rendering, Texture Mapping,Multiresolution,
                 Level of Detail, 3D Maps.",
  booktitle =    "Proc. of the 11th Ann. IEEE Visualization Conference
                 (Vis) 2000",
}

@InProceedings{EVL-2000-457,
  pages =        "351--358",
  year =         "2000",
  title =        "A Continuous Clustering Method for Vector Fields",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-457",
  author =       "M. Garcke and T. Preu{\ss}er and M. Rumpf and A. Telea
                 and U. Weikard and J. van Wijk",
  abstract =     "A new method for the simplification of flow fields is
                 presented. It is based on continuous clustering. A
                 well-known physical clustering model, the Cahn Hillard
                 model which describes phase separation, is modified to
                 reflect the properties of the data to be visualized.
                 Clusters are defined implicitly as connected components
                 of the positivity set of a density function. An
                 evolution equation for this function is obtained as a
                 suitable gradient flow of an underlying anisotropic
                 energy functional. Here, time serves as the scale
                 parameter. The evolution is characterized by a
                 successive coarsening of patterns - the actual
                 clustering - and meanwhile the underlying simulation
                 data specifies preferable pattern boundaries. Here we
                 discuss the applicability of this new type of approach
                 mainly for flow fields, where the cluster energy
                 penalizes cross streamline boundaries, but the method
                 also carries provisions in other fields as well. The
                 clusters are visualized via iconic representations. A
                 skeletonization algorithm is used to find suitable
                 positions for the icons.",
  booktitle =    "Proc. of the 11th Ann. IEEE Visualization Conference
                 (Vis) 2000",
}

@InProceedings{EVL-2000-458,
  pages =        "211--218",
  year =         "2000",
  title =        "Two-level volume rendering - fusing {MIP} and {DVR}",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-458",
  author =       "Helwig Hauser and Likas Mroz and Gian-Italo Bischi and
                 Eduard M. Gr{\"o}ller",
  abstract =     "In this paper we present a two-level approach for
                 fusing direct volume rendering (DVR) and
                 maximum-intensity projection (MIP) within a joint
                 rendering method. Different structures within the
                 data-set are rendered locally by either MIP or DVR on
                 an object by-object basis. Globally all the results of
                 subsequent object renderings are combined in a merging
                 step (usually compositing in our case). This allows to
                 selectively choose the most suitable technique for
                 depicting each object within the data, while keeping
                 the amount of information contained in the image at a
                 reasonable level. This is especially useful when inner
                 structures should be visualized together with
                 semi-transparent outer parts, similar to the
                 focus-and-context approach known from information
                 visualization. We also present an implementation of our
                 approach, which allows to explore volumetric data using
                 two-level rendering at interactive frame rates.",
  keywords =     "Visualization, volume rendering, dynamical
                 systems,medical applications.",
  booktitle =    "Proc. of the 11th Ann. IEEE Visualization Conference
                 (Vis) 2000",
}

@InProceedings{EVL-2000-459,
  pages =        "3--9",
  year =         "2000",
  title =        "To Gesture or Not to Gesture: What is the Question?",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-459",
  author =       "Norman I. Badler and Monica Costa and Liwei Zhao and
                 Diane M. Chi",
  abstract =     "Computer synthesized characters are expected to make
                 appropriate face, limb, and body gestures during
                 communicative acts. We focus on non-facial movements
                 and try to elucidate what is intended with the notions
                 of &ldquo;gesture&rdquo; and &ldquo;naturalness&rdquo;.
                 We argue that looking only at the psychological notion
                 of gesture and gesture type is insufficient to capture
                 movement qualities needed by an animated character.
                 Movement observation science, specifically Laban
                 Movement Analysis and its Effort and Shape components
                 with motion phrasing provide essential gesture
                 components (I. Bartenieff and D. Lewis, 1980). We
                 assert that the expression of movement qualities from
                 the Effort dimensions are needed to make a gesture
                 naturally crystallize out of abstract movements.
                 Finally, we point out that nonfacial gestures must
                 involve the rest of the body to appear natural and
                 convincing. A system called EMOTE has been implemented
                 which applies parameterized Effort and Shape qualities
                 to movements and thereby forms improved synthetic
                 gestures.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-46,
  pages =        "95--102",
  year =         "2000",
  title =        "Normal Meshes",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-46",
  author =       "Igor Guskov and Kiril Vidimce and Wim Sweldens and
                 Peter Schr{\"{o}}der",
  abstract =     "Normal meshes are new fundamental surface descriptions
                 inspired by differential geometry. A normal mesh is a
                 multiresolution mesh where each level can be written as
                 a normal offset from a coarser version. Hence the mesh
                 can be stored with a single float per vertex. We
                 present an algorithm to approximate any surface
                 arbitrarily closely with a normal semi-regular mesh.
                 Normal meshes can be useful in numerous applications
                 such as compression, filtering, rendering, texturing,
                 and modeling.",
  editor =       "Kurt Akeley",
  keywords =     "Meshes, subdivision, irregular connectivity, surface
                 parameterization, multiresolution, wavelets",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-460,
  pages =        "11--17",
  year =         "2000",
  title =        "An Animation Toolkit Based on Motion Mapping",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-460",
  author =       "Myeong W. Lee and Min-Geun Lee",
  abstract =     "We present a character animation toolkit for
                 generating animation sequences interactively. It is
                 based on a motion mapping technique that an object's
                 motion can be applied to another object interactively.
                 The toolkit generates the mesh for an object from
                 several feature points on photo images automatically.
                 An object's motion is defined and manipulated
                 independently of modeling data. The motion generated
                 once is applied to any object by the mapping technique
                 according to an animation hierarchical data structure.
                 The animation toolkit is appropriate for generating
                 character animation that needs interactive motion
                 modification and reuse rather than accurate modeling.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-461,
  pages =        "19--28",
  year =         "2000",
  title =        "LaTex Human Motion Planning Based on Recursive
                 Dynamics and Optimal Control Techniques",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-461",
  author =       "Gang Huang and Dimitris N. Metaxas and Janzen Lo",
  abstract =     "The 3D simulation of human activity based on physics,
                 kinematics, and dynamics in terrestrial and space
                 environments, is becoming increasingly important.
                 Virtual humans may be used to design tasks in
                 terrestrial environments and analyze their physical
                 workload to maximize success and safety without
                 expensive physical mockups. Previously (J. Lo and D.
                 Metaxas, 1999), we presented an efficient optimal
                 control and recursive dynamics based animation system
                 for simulating and controlling the motion of
                 articulated figures, and implemented the approach to
                 several experiments where the simplified articulated
                 models which has serial/closed-loop chain structures
                 with only small degree-of-freedom (less than seven)
                 each. The computation time is from a few minutes up to
                 4 hours based on the complexity of the model and how
                 close the initial guess of the motion trajectory is to
                 the optimal solution. The paper presents an improved
                 method which can deal with more complicated kinematic
                 chains (tree structures), as well as larger
                 degree-of-freedom serial/closed-loop chain structures.
                 Motion planning is done by first solving the inverse
                 kinematic problem to generate possible trajectories,
                 which gives us a better initial guess of the motion
                 trajectory than the previous one, and then by solving
                 the resulting nonlinear optimal control problem. For
                 example, minimization of the torques during a
                 simulation under certain constraints is often applied
                 and has its origin in the biomechanics literature.
                 Examples of activities shown are chinup and dipdown in
                 different terrestrial environments as well as
                 zero-gravity self orientation and ladder traversal.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-462,
  pages =        "29--36",
  year =         "2000",
  title =        "Hand Gesture Animation from Static Postures Using an
                 Anatomy-Based Model",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-462",
  author =       "Horace Ho-Shing Ip and Sam C. S. Chan and Maria S. W.
                 Lam",
  abstract =     "Automatic interpretation and animation of human motion
                 has become an important research topic among
                 researchers in virtual reality and computer animation.
                 One major problem encountered during hand motion
                 analysis is the large amount of data that need to be
                 captured and analyzed. Even for a human hand, although
                 only a small part of the body is involved, there are
                 about 30 motion parameters for each hand posture. The
                 authors present an approach to hand motion animation
                 using only static images of the set of target gestures.
                 We achieve naturalistic hand motion animation by the
                 use of an anatomy based hand model and a hand gesture
                 coding system, which we called Hand Action Coding
                 System (HACS). This allows complex sequences of hand
                 gestures to be animated based only on the static image
                 of the hand gestures to be animated. This approach
                 greatly simplifies motion data acquisition and the
                 process of motion analysis and synthesis.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-463,
  pages =        "37--41",
  year =         "2000",
  title =        "Neural Network-based Violinist's Hand Animation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-463",
  author =       "Junhwan Kim and Frederic Cordier and Nadia
                 Magnenat-Thalmann",
  abstract =     "We present a system for the animation of a human hand
                 that plays violin. A neural network controls the hand
                 movement. We make use of an optimization method to
                 generate examples for the neural network training. The
                 musical decision of which finger to use is
                 automatically made by best first search. We show that
                 the movements of the violinist's hands are physically
                 and musically feasible, and that the musical decisions
                 are consistent with those recommended in the violin
                 pedagogy. A description of the system, the results of
                 the decisions, and the animations are presented.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-464,
  pages =        "45--53",
  year =         "2000",
  title =        "The Digital Ocean",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-464",
  author =       "Nicholas M. Patrikalakis and Stephen L. Abrams and J.
                 G. Bellingham and W. Cho and K. P. Mihanetzis and Allan
                 R. Robinson and Henrik Schmidt and Pubudu C. H.
                 Wariyapola",
  abstract =     "he ocean, is fundamentally important to many areas of
                 modern society and thus improved knowledge of the ocean
                 is essential. Ocean scientists have made remarkable
                 progress in observation technology, modeling and
                 assimilation in physical oceanography, acoustics, and
                 biology. To some extent, such advances have been
                 confined to each discipline. Therefore a great demand
                 has arisen for a modern distributed computing and
                 networking infrastructure within which we bring
                 together advanced modeling, observation tools and field
                 estimation methods. The paper describes a knowledge
                 network of distributed heterogeneous data and software
                 resources for multidisciplinary ocean research.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-465,
  pages =        "81--86",
  year =         "2000",
  title =        "Visualization of Eclipses and Planetary Conjunction
                 Events: The Interplay between Model Coherence, Scaling
                 and Animation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-465",
  author =       "Walter Oberschelp and Alexander Hornung and Horst
                 Samulowitz",
  abstract =     "The problem of an instructive and realistic animation
                 and visualization of the shadow and color-conditions
                 during conjunctions of actively and passively
                 illuminated cosmic objects has found only partially
                 satisfying solutions so far. As an example we study a
                 total solar eclipse. There are didactic shortcomings of
                 specialized astronomical software, even though
                 solutions have been given, which are very impressive
                 for experts. Using the possibilities of commercial 3D
                 animation software we present an object oriented
                 partial solution. In order to get correct astronomical
                 representations, we model (for different tasks) the
                 object space under cinematic aspects with parameters
                 for spatial and temporal scaling, for illumination and
                 coloring under couplings of varying strength. The
                 adaptation of the parameters to optimal acceptance of
                 the spectator must be done a posteriori.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-466,
  pages =        "89--97",
  year =         "2000",
  title =        "Homological Invariants and HolorGraphic
                 Representations of Topological i Structures in Cellular
                 Spaces",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-466",
  author =       "George Baciu and Tosiyasu L. Kunii",
  abstract =     "Geometric modeling and computational representations
                 of shapes have been subject to intense research for
                 more than three decades. Interestingly, these subjects
                 are still at the heart of a continuous activity of
                 research and development in computer graphics, virtual
                 environments, image-based rendering, computer-aided
                 geometric design and physical simulations. Currently,
                 geometric and physically-based modeling still face two
                 main challenges: (1) the identification of topological
                 features, and (2) the representation of the modes of
                 interaction between them, both in static and dynamic
                 environments. Current methods have offered many
                 different forms of associating abstract structures with
                 analytical expressions. The variety of modeling tools,
                 from combinational methods to analytic algebraic
                 geometry, not only reflects the richness of ideas in
                 this domain of study but also the desire to improve,
                 enhance and simplify. It is within this realm that we
                 introduce a new framework, called holorgraphic
                 geometric modeling (HGM). This framework combines the
                 advantages of the graph-theoretic representation of
                 combinatorial structures with the analytical
                 flexibility, expressional power and scalability of
                 higher-order, multi-dimensional variables and operators
                 in the form of holors. HGM not only complements the
                 combinatorial structures in geometric modeling but also
                 enhances and reveals new concepts and ideas in the
                 process of developing robust, flexible and scalable
                 domains of formulation for simplicial complexes,
                 cellular spaces, and homotopy in general.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-467,
  pages =        "99--104",
  year =         "2000",
  title =        "Using an Enhanced {LBG} Algorithm to Reduce the
                 Codebook Error in Vector Quantization.",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-467",
  author =       "J{\"{o}}rg Haber and Hans-Peter Seidel",
  abstract =     "Presents a modification of the well-known LBG (Linde,
                 Buzo and Gray, 1980) algorithm for the generation of
                 codebooks in vector quantization. Our algorithm, which
                 we call the ILBG (iterated LBG) algorithm, reduces the
                 codebook error of the LBG algorithm drastically in
                 typical applications. In our experiments, we were able
                 to achieve up to a 75% reduction of the codebook error
                 in only a few additional iteration steps. In the
                 context of lossy image compression, this error
                 reduction in turn leads to an increase of 2-3 dB in the
                 peak signal-to-noise ratio (PSNR).",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-468,
  pages =        "105--113",
  year =         "2000",
  title =        "Real-Time Collision Detection and Response for Complex
                 Environments",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-468",
  author =       "Bernhard Geiger",
  abstract =     "Presents a method for collision detection that is well
                 suited to complex environments, such as those obtained
                 from medical imaging and for objects that are in
                 permanent contact. The method is based on a
                 point-in-tetrahedral-mesh query. Spatial and temporal
                 coherence are used to achieve interactive speed. In
                 addition to collision detection, the system calculates
                 a force and torque that can be used for collision
                 response. Experimental results show that it performs
                 well compared to the RAPID (Robust and Accurate Polygon
                 Interference Detection) collision detection library,
                 which is a standard in the field.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-469,
  pages =        "55--64",
  year =         "2000",
  title =        "Modeling Murex cabritii Sea Shell with a Structured
                 Implicit Surface Modeler",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-469",
  author =       "Callum Galbraith and Przemyslaw Prusinkiewicz and
                 Brian Wyvill",
  abstract =     "Implicit surface modeling systems have been used since
                 the mid-1980's for the generation of cartoon like
                 characters. Recently implicit models combined with
                 constructive solid geometry (CSG) have been used to
                 build engineering models with automatic blending. This
                 work is built on a structured implicit modeling system
                 which includes CSG, warping, 2D texture mapping and
                 operations based on the BlobTree, and its application
                 to the generation of a complex and visually accurate
                 biological model of the sea shell Murex cabritii. Since
                 the model is purely procedurally defined and does not
                 rely on polygon mesh operations, it is resolution
                 independent and can be rendered directly using ray
                 tracing. An interface has been built to the BlobTree
                 using an interpreted programming language (Python). The
                 language interface readily allows a user to
                 procedurally describe the shell based on numeric data
                 taken from the actual object.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-47,
  pages =        "113--120",
  year =         "2000",
  title =        "Piecewise Smooth Subdivision Surfaces with Normal
                 Control",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-47",
  author =       "Henning Biermann and Adi Levin and Denis Zorin",
  abstract =     "In this paper we introduce improved rules for
                 Catmull-Clark and Loop subdivision that overcome
                 several problems with the original schemes, namely,
                 lack of smoothness at extraordinary boundary vertices
                 and folds near concave corners. In addition, our
                 approach to rule modification allows the generation of
                 surfaces with prescribed normals, both on the boundary
                 and in the interior, which considerably improves
                 control of the shape of surfaces.",
  editor =       "Kurt Akeley",
  keywords =     "Subdivision surfaces, boundary control",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-470,
  pages =        "65--72",
  year =         "2000",
  title =        "Ocean Waves Synthesis using a Spectrum-Based
                 Turbulence Function",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-470",
  author =       "Sebastien Thon and Jean-Michel Dischler and Djamchid
                 Ghazanfarpour",
  abstract =     "The representation of ocean waves is not a resolved
                 problem in computer graphics yet. There is still no
                 existing method that allows one to simply describe an
                 agitated surface of any size that is visually
                 sufficiently realistic, without using entirely physical
                 models that are usually very complex. We present a
                 simple method to represent and animate an ocean surface
                 in deep water by considering it as a procedural
                 texture. This texture is defined by a combination of
                 two levels of detail. The first one is a superposition
                 of 2D trochoids whose parameters are determined by
                 ocean wave characteristics infrequency domain. In order
                 to increase the visual complexity of this model and to
                 reduce computation, we incorporate a 3D turbulence
                 function to provide a second level of detail. This
                 turbulence function is also determined by frequency
                 characteristics of ocean waves. Since our synthesized
                 ocean waves spectrum approaches a real ocean waves
                 spectrum, we obtain realistic water waves in the
                 spatial domain. The animation of our model is performed
                 by shifting the phase of the trochoids and by moving
                 into the 3D turbulence function. Since our definition
                 is procedural and continuous, it permits us to obtain
                 any size of water surface with any level of detail as
                 well as a simple, direct, antialiasing method. Our
                 model can be used to generate ocean waves using 2D
                 textures or bump maps as well as 3D textures.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-471,
  pages =        "75--80",
  year =         "2000",
  title =        "{VISJET} - {A} Computer Ocean Outfall Modeling
                 System",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-471",
  author =       "S. K. B. Cheung and D. Y. L Leung and W. Wang and J.
                 H. W. Lee and V. Cheung",
  abstract =     "Sewage and industrial effluents from coastal cities
                 are often discharged into the adjacent sea after some
                 land-based treatment. In modern design, the wastewater
                 is often discharged in buoyant jet groups from risers
                 mounted on a submarine outfall on the seabed to achieve
                 rapid mixing of effluents with tidal flow. A
                 mathematical model for buoyant jets in currents based
                 on the Lagrangian models, called JETLAG, was developed.
                 The paper presents a system called VISJET, for
                 visualizing the ocean sewage discharge system based on
                 the JETLAG model. We discuss the features of VISJET
                 system and show how computer visualization can be used
                 to help with the design of an ocean sewage discharge
                 system.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-472,
  pages =        "117--125",
  year =         "2000",
  title =        "A Homotopy Model for Cup Lifting",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-472",
  author =       "Kenji Ohmori and Tosiyasu L. Kunii",
  abstract =     "Introduces two new theoretical tools - homotopy and
                 cellular structured spaces - for visualization. Any
                 object is represented by a filtration space, which is a
                 sequence of skeletons that are topological spaces.
                 Using an attaching function that attaches n-1
                 dimensional balls to the boundaries of n-dimensional
                 balls, a filtration space is composed inductively and
                 step-by-step, by increasing the dimensions. The space
                 obtained by this process is called a cellular
                 structured space, which is composed of cells. The
                 cellular structured space preserves invariant
                 properties of entities. On the other hand, traditional
                 polygonalization has difficulty in preserving invariant
                 properties. A change from one situation represented by
                 a cellular structured space to another situation of a
                 cellular structured space is represented by a homotopy
                 if the change is continuous. Using homotopy and
                 cellular structured spaces, invariant properties are
                 preserved while very large data compression is
                 achieved.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-473,
  pages =        "127--134",
  year =         "2000",
  title =        "{X}_Machines + {L}_Systems = {XL}_Systems",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-473",
  author =       "Salim K. Vanak",
  abstract =     "A. Lindenmayer (1968) developed a type of formal
                 language called an L-system. Similar to formal
                 languages, L-systems define a method by which a string
                 of symbols can be rewritten or parsed into another
                 string using a set of rewrite rules. X-machines are
                 generalised state automata. This paper takes another
                 look at this way of generating plants and provides a
                 convenient way of taking component L-systems that
                 exhibit some property and combining them using an
                 X-machine so that each L-system contributes its
                 properties or behaviour. The result is a plant which
                 has some characteristics of each of its components.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-474,
  pages =        "137--151",
  year =         "2000",
  title =        "Local and Global Geometric Methods for Analysis
                 Interrogation, Reconstruction, Modification and Design
                 of Shape",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-474",
  author =       "Franz-Erich Wolter and K.-I. Friese",
  abstract =     "Gives an overview of some recent methods useful for
                 local and global shape analysis and for the design of
                 solids. These methods include, as new tools for global
                 and local shape analysis, the spectra of the Laplace
                 and Laplace-Beltrami operators and the concept of
                 stable umbilical points, i.e. stable singularities of
                 the &ldquo;principal curvature line&rdquo; wire-frame
                 model of the solid's boundary surface. Most of the
                 material in this paper deals with the medial axis
                 transform as a tool for shape interrogation,
                 reconstruction, modification and design. We show that
                 it appears to be possible to construct an intuitive
                 user interface that allows one to mould shapes by
                 employing the medial axis transform. We also explain
                 that the medial axis and Voronoi diagram can also be
                 defined and computed on free surfaces in a setting
                 where the geodesic distance between two points p and q
                 on a surface S is defined by the shortest surface path
                 on S joining the two points p, q. This leads to the
                 natural and computable generalized concepts of the
                 geodesic medial axis and geodesic Voronoi diagram on
                 free-form surfaces. Both can be computed with a
                 reasonable speed and with high accuracy (of about 12
                 digits when double floating-point arithmetic is used
                 for the computations)",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-475,
  pages =        "153--162",
  year =         "2000",
  title =        "Crack Pattern Simulation Based on 3{D} Surface
                 Cellular Automaton",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-475",
  author =       "St{\'{e}}phane Gobron and Norishige Chiba",
  abstract =     "escribes a method for modeling the propagation of
                 cracks on any 3D surface. Taking a previous cellular
                 automata model of the authors (1999) as the basis, this
                 method allows just about any type of cracks on any type
                 of triangulated 3D object. Our model's main advantage
                 is that it proposes a semi-physical solution, making it
                 at the same time user-controllable and easily
                 extendable. After summarizing works in the literature,
                 we make a brief and simple description of what cracks
                 are physically, and how they are generated. Based on
                 this idea, we detail our model of crack propagation. We
                 first introduce the general development of cracks. We
                 then propose an original model of spectrum stress. This
                 is followed by a description of the mutual interaction
                 between cracks and stresses. Finally, a set of
                 graphical examples, together with their respective
                 parameters, concludes this paper.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-476,
  pages =        "163--170",
  year =         "2000",
  title =        "Reconstruction of {B}-spline Surfaces from Scattered
                 Data Points",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-476",
  author =       "Benjamin F. Gregorski and Bernd Hamann and Kenneth I.
                 Joy",
  abstract =     "We present a new approach for reconstructing a smooth
                 surface from a set of scattered points in 3D space. Our
                 algorithm first decomposes a given point set into a
                 quadtree-like data structure known as a strip tree. The
                 strip tree is used to fit a set of least squares
                 quadratic surfaces to the data points. These quadratic
                 surfaces are then degree-elevated to bi-cubic surfaces
                 and blended together to form a set of B-spline surfaces
                 that approximates the given point set.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-477,
  pages =        "173--182",
  year =         "2000",
  title =        "{SQUEEZE}: Fast and Progressive Decompression of
                 Triangle Meshes",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-477",
  author =       "Renato Pajarola and Jarek Rossignac",
  abstract =     "n ideal triangle mesh compression technology would
                 simultaneously support the following objectives: (1)
                 progressive refinements of the received mesh during
                 decompression, (2) nearly optimal compression ratios
                 for both geometry and connectivity, and (3) in-line,
                 real-time decompression algorithms for hardware or
                 software implementations. Because these three
                 objectives impose contradictory constraints, previously
                 reported efforts have focused primarily on one
                 (sometimes two) of these objectives. The SQUEEZE
                 technique introduced in this paper addresses all three
                 constraints simultaneously, and attempts to provide the
                 best possible compromise. For a mesh of T triangles,
                 SQUEEZE compresses the connectivity to 3.7T bits, which
                 is competitive with the best progressive compression
                 techniques reported so far. The geometric prediction
                 error encoding technique introduced in this paper leads
                 to a geometry compression that is improved by 20% over
                 that of previous schemes. Our initial implementation on
                 a 300-MHz CPU achieved a decompression rate of up to
                 46,000 triangles per second. SQUEEZE downloads a model
                 through a number of successive refinement stages,
                 providing the benefit of progressivity.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-478,
  pages =        "183--191",
  year =         "2000",
  title =        "Enabling Cuts on Multiresolution Representation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-478",
  author =       "Fabio Ganovelli and Paolo Cignoni and Claudio Montani
                 and Roberto Scopigno",
  abstract =     "Multi-resolution representations are widely used in
                 many data visualization contexts and applications. The
                 adoption of a multi-resolution approach provides the
                 optimal management of a data representation, using at
                 each instant of time a level of detail that is more
                 adequate for the given action or task to be performed.
                 Recently, multi-resolution has also been introduced
                 into the interactive physically-based simulation of
                 deformable objects (e.g. in virtual surgery
                 applications). In these applications, the processing
                 resources available are often insufficient and pose a
                 critical constraint. The adoption of multi-resolution
                 allows one to improve the accuracy of the simulation in
                 the proximity of the action focus while maintaining
                 computations under a given bound. In this particular
                 context, the user should be able to perform cuts in the
                 object. The problem is that most multi-resolution
                 models need a pre-processing phase in which the data
                 structure is constructed. Such a construction strictly
                 depends on the topology of the object, which is
                 supposed to be invariable. We propose a new approach
                 for the dynamic topological modification of a
                 multi-resolution model, which allows easy updating of
                 the multi-resolution data structure (based on the
                 multi-resolution triangulation framework), and
                 efficient decomposition of the cells intersected by the
                 cut. With respect to previous methods, our solution
                 supports a much lower degree of fragmentation of the
                 decomposition and very short processing times, due to
                 the design of a lookup table (LUT) based splitting
                 solution.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-479,
  pages =        "195--200",
  year =         "2000",
  title =        "The Challenges of Digital Media: Research Issues and
                 Future Directions",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-479",
  author =       "Rae A. Earnshaw",
  abstract =     "A recent report by a panel of experts that advise the
                 US President (Information Technology Advisory
                 Committee), concluded that federal research on
                 information technology (IT) is seriously inadequate. It
                 urged spending on IT research to be increased by US1.4
                 billion by 2004, focussing on longer-term
                 &ldquo;visionary and high risk&rdquo; projects that
                 industry is unwilling to support itself. This
                 Information Technology for the 21st century initiative
                 (IT2) concentrates on long-term IT research (software,
                 human computer interfaces, information management,
                 scalable information, and high end computing), advanced
                 computing for science and engineering with emphasis on
                 multidisciplinarity, and research on social aspects of
                 the information revolution. It is clear that there are
                 significant issues to be addressed in many key areas of
                 information technology. The paper examines some of the
                 research issues in the area of digital media.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-48,
  year =         "2000",
  title =        "Environment Matting Extensions: Towards Higher
                 Accuracy and Real-Time Capture",
  author =       "Yung-Yu Chuang and Douglas E. Zongker and Joel
                 Hindorff and Brian Curless and David H. Salesin and
                 Richard Szeliski",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-48",
  abstract =     "Environment matting is a generalization of traditional
                 bluescreen matting. By photographing an object in front
                 of a sequence of struc-tured light backdrops, a set of
                 approximate light-transport paths through the object
                 can be computed. The original environment mat-ting
                 research chose a middle ground",
  editor =       "Kurt Akeley",
  keywords =     "Alpha channel, augmented reality, blue-screen matting,
                 blue spill, clip art, colored transparency, environment
                 map, environment matte, image-based rendering,
                 real-time capture, reflection, refraction",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-480,
  pages =        "201--207",
  year =         "2000",
  title =        "Fuzzy-Based Person Tracking in Real-Time",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-480",
  author =       "Michael Hoch and Sven Mann",
  abstract =     "The implementation of a system for person tracking is
                 often a compromise between sophisticated tracking
                 algorithms and simplicity (to achieve the desired frame
                 rate on standard PCs). We propose a fuzzy based rule
                 system for tracking people using simple segmentation
                 algorithms. The system allows integration of heuristics
                 in the tracking algorithm, adjusted by means of
                 weighting functions. It also combines several segmented
                 features in an intuitive way. The result is a stable
                 system that can not be achieved using the single
                 extracted features alone.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-481,
  pages =        "209--217",
  year =         "2000",
  title =        "Interactive Human Motion Acquisition from Video
                 Sequences",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-481",
  author =       "Jiang Yu Zheng and Shigeru Suezaki and Yasuhiro
                 Shiota",
  abstract =     "Human motion modeling for animation and VR has reached
                 a level of capturing real motion data from people using
                 various visual and non-visual sensors. However, most of
                 the available systems require special devices and
                 environments, or even attachments of extra things on an
                 actor. To realize a personal system, we developed a
                 general type software to acquire arbitrary motion from
                 a video sequence. A 3D articulated human model with
                 changeable size, color and surface shape is constructed
                 and personalized to fit with a focused figure in the
                 video. The personal model is then driven either
                 automatically or manually to match with the moving body
                 in consecutive image frames. This matching starts from
                 key frames that contain key poses. A smooth motion is
                 then interpolated in between key frames. The evaluation
                 of the generated motion is enhanced by image
                 correlation. We provide various methods to make the
                 matching feasible in order to reduce the modeling time.
                 This approach is suitable for personal use to meet wide
                 needs of human motion acquisition.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-482,
  pages =        "221--226",
  year =         "2000",
  title =        "Head Detection and Tracking by 2-{D} and 3-{D}
                 Ellipsoid Fitting",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-482",
  author =       "Nikos Grammalidis and Michael G. Strintzis",
  abstract =     "A novel procedure for segmenting a set of scattered 3D
                 data obtained from a head and shoulders multiview
                 sequence is presented. The procedure consists of two
                 steps. In the first step, two ellipses corresponding to
                 the head and the body of the person are identified
                 based on ellipse fitting of the outline of the person
                 in each image. The fitting is based on a fast direct
                 least squares method using the constraint that forces a
                 general conic to be an ellipse. In order to achieve
                 head/body segmentation, a K-means algorithm is used to
                 minimise the fitting error between the points and the
                 two ellipsoids. In the second step, a 3D ellipsoid
                 model corresponding to the head of the person is
                 identified using an extension of the above method.
                 Robustness and outlier removal can be achieved if a 3D
                 ellipsoid model estimation technique is used in
                 conjunction with the Median of Least Squares (MedLS)
                 technique, which minimises the median of the errors
                 corresponding to each 3D point. An interesting
                 application of the proposed method is the combination
                 of the 3D ellipsoid model with a generic face model
                 which is adapted to the face images to provide
                 information only for the high-detail front art of the
                 head while the 3D ellipsoid is used for the back of the
                 head, which is usually not visible.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-483,
  pages =        "227--235",
  year =         "2000",
  title =        "Visualization of Dominant Region in Team Games and Its
                 Application to Teamwork Analysis",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-483",
  author =       "Tsuyoshi Taki and Jun-ichi Hasegawa",
  abstract =     "The authors present a method for visualization of an
                 invisible feature in human group motion. This feature
                 called &ldquo;dominant region&rdquo; is a kind of
                 dynamic sphere of influence. A dominant region is
                 defined as a region in where the person can arrive
                 earlier than any other persons and can be formulated by
                 replacing the distance function in the Voronoi region
                 with a time function. As an application of the dominant
                 region, a motion analysis system of team ball games was
                 developed. In this system, the dominant region is used
                 for quantitative evaluation of basic teamwork. From the
                 experiments using actual soccer game scenes, it was
                 shown that inferior or superior areas for each player
                 and each team in the game can be observed visually and
                 that some basic factor for teamwork can be evaluated
                 quantitatively by using the dominant region. These
                 evaluation results almost correspond with those by some
                 professionals.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-484,
  pages =        "239--245",
  year =         "2000",
  title =        "Simulated Patient for Orthognathic Surgery",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-484",
  author =       "Horace Ho-Shing Ip and Christy S. B. Kot and James
                 Xia",
  abstract =     "Orthognathic surgery corrects a wide range of minor
                 and major facial and jaw irregularities. This surgery
                 will improve the patients' ability to chew, speak and
                 breathe. In many cases, a better appearance will also
                 result. With the recent advances in virtual reality
                 (VR) and three-dimensional (3D) medical imaging
                 technology, orthognathic surgery simulations typically
                 requires costly volumetric data acquisition modalities
                 such CT or MRI imaging for patient modeling. The
                 authors present an approach for constructing 3D hard
                 and soft tissue models of a patient based on colour
                 portraits and conventional radiographs. This allows
                 patient modeling to be done efficiently on low-cost
                 platforms. Specifically, we extend the techniques
                 developed by the author (H.S.H Ip and Lijin Yin, 1996)
                 to hard tissue modeling. The extended technique employs
                 a user-assisted approach to obtain the 3D coordinates
                 of the feature points of the human face and jaw
                 respectively from conventional photographs and
                 radiographs. Then the displacement vectors of the
                 feature points are computed by correspondence matching
                 and interpolation against a generic head model and jaw
                 bone model. The resulting combined hard and soft tissue
                 models can be used for orthognathic surgical planning
                 on a low-cost, PC based platform.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-485,
  pages =        "247--255",
  year =         "2000",
  title =        "Fast and Stable Animation of Cloth with an
                 Approximated Implicit Method",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-485",
  author =       "Young-Min Kang and Jeong-Hyeon Choi and Hwan-Gue Cho
                 and Chan-Jong Park",
  abstract =     "Realistic animation of soft objects such as cloth is
                 essential for plausible character animation. Many
                 techniques have been proposed for the simulation of
                 soft objects, and most of them are based on numerical
                 integration. Among the techniques, the implicit
                 integration method is the most likely technique for
                 real time environments, since it allows large time
                 steps for cloth simulation by ensuring the stability of
                 systems. However the most critical flaw of the implicit
                 method is that it involves a large linear system. The
                 paper presents a fast animation technique for animating
                 soft objects based on a mass-spring model with an
                 approximated implicit method which does not involve
                 linear system solving. The proposed technique stably
                 updates the state of n mass-points in O(n) time when
                 the number of total springs are O(n). Because the
                 mass-spring model shows a superelastic effect, the
                 excessively deformed springs (i.e., super-elongated
                 springs) should be adjusted for reality. The paper
                 presents an efficient inverse dynamics process to
                 adjust the super-elongated springs.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-486,
  pages =        "257--266",
  year =         "2000",
  title =        "Implementing Fast Cloth Simulation with Collision
                 Response",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-486",
  author =       "Pascal Volino and Nadia Magnenat-Thalmann",
  abstract =     "The article details and implements efficient
                 techniques for cloth simulation, both in the area of
                 numerical simulation and the area of collision
                 detection and response. Emphasis is put on the
                 efficient implementation of implicit numerical methods
                 with many improvements toward better realism, as well
                 as computation simplicity. A constraint based collision
                 response scheme is adapted to this scheme in order to
                 provide an accurate and stable collision response.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-487,
  pages =        "269--278",
  year =         "2000",
  title =        "Hybridization Techniques for Fast Radiosity Solvers",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-487",
  author =       "Michel Leblond and Fran{\c{c}}ois Rouselle and
                 Christophe Renaud",
  abstract =     "The authors study, both theoretically and
                 experimentally some properties of classical linear
                 systems solvers, according to the radiosity
                 assumptions. We prove important properties for some of
                 these solvers which allow the user to choose the best
                 one. We then introduce a new technique, so called
                 hybridization, whose purpose is to increase the
                 convergence speed of iterative methods. It provides
                 very efficient results for the well-known Gauss-Seidel
                 solver. This technique has been successfully applied to
                 both a group progressive radiosity approach and a
                 full-matrix radiosity method which has been
                 specifically designed for plant growth simulation.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-488,
  pages =        "279--286",
  year =         "2000",
  title =        "Orientation Lightmaps for Photon Tracing in Complex
                 Environments",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-488",
  author =       "A. Wilkie and Robert F. Tobler and Werner
                 Purgathofer",
  abstract =     "We present a method that makes the use of photon
                 tracing methods feasible for complex scenes when a
                 totally accurate solution is not essential. This is
                 accomplished by using orientation lightmaps, which
                 average the illumination of complex objects depending
                 on the surface normal. Through this averaging, they
                 considerably reduce the variance of the stochastic
                 solution. In order to use these specialised lightmaps,
                 which consume comparatively small amounts of memory, no
                 changes have to be made to the basic photon tracing
                 algorithm. Also, they can be freely mixed with normal
                 lightmaps. This gives the user good control over the
                 amount of inaccuracy he introduces by their
                 application. The area computations necessary for their
                 insertion are performed using a stochastic sampling
                 method that performs well for highly complex objects.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-489,
  pages =        "287--291",
  year =         "2000",
  title =        "Hair Rendering by Jittering and Pseudo Shadow",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-489",
  author =       "Waiming Kong and Masayuki Nakajima",
  abstract =     "Proposes two properties of hair that we believe are
                 essential to realistic hair rendering. To satisfy these
                 two properties of hair, we introduce the
                 &ldquo;jittering and pseudo-hair model&rdquo;. The
                 jittering and pseudo-shadows are achieved through the
                 use of a shadow factor. Experimental results show that,
                 with the incorporation of these two properties, hair
                 images look more natural than images do without these
                 properties, thus proving that these two properties do
                 indeed improve the realism of hair images.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-49,
  pages =        "131--144",
  year =         "2000",
  title =        "The Digital Michelangelo Project: 3{D} Scanning of
                 Large Statues",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-49",
  author =       "Marc Levoy and Kari Pulli and Brian Curless and Szymon
                 Rusinkiewicz and David Koller and Lucas Pereira and
                 Matt Ginzton and Sean Anderson and James Davis and
                 Jeremy Ginsberg and Jonathan Shade and Duane Fulk",
  abstract =     "We describe a hardware and software system for
                 digitizing the shape and color of large fragile objects
                 under non-laboratory conditions. Our system employs
                 laser triangulation rangefinders, laser time-of-flight
                 rangefinders, digital still cameras, and a suite of
                 software for acquiring, aligning, merging, and viewing
                 scanned data. As a demonstration of this system, we
                 digitized 10 statues by Michelangelo, including the
                 well-known figure of David, two building interiors, and
                 all 1,163 extant fragments of the Forma Urbis Romae, a
                 giant marble map of ancient Rome. Our largest single
                 dataset is of the David - 2 billion polygons and 7,000
                 color images. In this paper,we discuss the challenges
                 we faced in building this system, the solutions we
                 employed, and the lessons we learned. We focus in
                 particular on the unusual design of our laser
                 triangulation scanner and on the algorithms and
                 software we developed for handling very large scanned
                 models.",
  editor =       "Kurt Akeley",
  keywords =     "3D scanning, rangefinding, sensor fusion, range
                 images, mesh generation, reflectance and shading
                 models, graphics systems, cultural heritage",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-490,
  pages =        "295--302",
  year =         "2000",
  title =        "Haptics Issues in Virtual Environments",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-490",
  author =       "Grigore C. Burdea",
  abstract =     "Haptics is a recent enhancement to virtual
                 environments, allowing users to &ldquo;touch&rdquo; and
                 feel the simulated objects they interact with. Current
                 commercial products allow tactile feedback through
                 desktop interfaces (such as the FEELItTM mouse or the
                 PHANToMTM arm) and dextrous tactile and force feedback
                 at the fingertips through haptic gloves (such as the
                 CyberTouchTM and the CyberGraspTM). Virtual reality
                 haptic programming requires good physical modeling of
                 user interactions, primarily through collision
                 detection, and of object responses, such as surface
                 deformation, hard-contact simulation, slippage, etc. It
                 is at present difficult to simulate complex virtual
                 environments that have a realistic behavior. This task
                 is added to by the recent introduction of haptic
                 toolkits (such as GhostTM or VPS). Current technology
                 suffers from a number of limitations, which go beyond
                 the higher production cost of haptic interfaces. These
                 technical drawbacks include the limited workspace of
                 desktop interfaces, the large weight of force-feedback
                 gloves, the lack of force feedback to the body, safety
                 concerns, etc. Not to be neglected is the high
                 bandwidth requirement of haptics, which is not met by
                 current Internet technology. As a result, it is not
                 possible at present to have a large number of remote
                 participants interacting haptically in a shared virtual
                 space.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-491,
  pages =        "303--307",
  year =         "2000",
  title =        "Augmented Reality for Real and Virtual Humans",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-491",
  author =       "Selim Balcisoy and Remy Torre and Michal Ponder and
                 Pascal Fua and Daniel Thalmann",
  abstract =     "Current virtual reality technologies provide many ways
                 to interact with virtual humans. Most of those
                 techniques, however, are limited to synthetic elements
                 and require cumbersome sensors. We have combined a
                 real-time simulation and rendering platform with a
                 real-time, non-invasive vision-based recognition system
                 to investigate interactions in a mixed environment with
                 real and synthetic elements. In this paper, we present
                 the resulting system, the example of a checkers game
                 between a real person and an autonomous virtual human
                 to demonstrate its performance.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-492,
  pages =        "309--315",
  year =         "2000",
  title =        "{VPARK} - {A} Windows {NT} Software Platform for a
                 Virtual Networked Amusement Park",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-492",
  author =       "Hyewon Seo and Chris Joslin and Uwe Berner and Nadia
                 Magnenat-Thalmann and Maja Jovovic and Joaquim Esmerado
                 and Daniel Thalmann and Ian Palme",
  abstract =     "Presents the VPARK (Virtual Park) system, which
                 includes a networked virtual environment (NVE) system
                 called W-VLNET and an &ldquo;attraction building
                 system&rdquo; that is able to create and modify the
                 attractions used in the NVE. Both systems have been
                 developed in the Windows NT environment. The paper
                 outlines the techniques for communication, scene
                 management, facial and body animation, and general user
                 interaction modules. The use of VRML97 and MPEG-4 SHNC
                 is overviewed for the purpose of outlining the
                 compatability of the system with other similar virtual
                 reality systems. The software provides realistic
                 virtual actors as well as sets of high-level actions
                 that are applicable to them in real-time. Related
                 issues on obtaining actor models and animating them in
                 real time are presented. The creation process of an
                 attraction incorporates assembling animation units
                 through a timeline. Using this software, the users are
                 able to bring their own scenario-based applications
                 into a shared virtual environment.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-493,
  pages =        "319--323",
  year =         "2000",
  title =        "Visualization of Biomedical Processes: Local
                 Quantitative Physiological Functions in Living Human
                 Body",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-493",
  author =       "David Dagan Feng and Weidong Cai",
  abstract =     "Functional imaging with dynamic positron emission
                 tomography (PET) has been playing a crucial and
                 expanding role in biomedical research and clinical
                 diagnosis, providing image-wide quantitative and
                 qualitative physiological functions in the human body,
                 and supporting visualization of the distribution of
                 these functions corresponding to anatomical structures.
                 A number of parametric imaging algorithms have been
                 developed. We give a brief study on some existing and
                 our recently, developed techniques for generating
                 parametric images. An integrated system for functional
                 image data processing and visualization, and a
                 Web-based application are presented.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-494,
  pages =        "325--334",
  year =         "2000",
  title =        "Dynamic 3{D} Maps and Their Texture-Based Design",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-494",
  author =       "J{\"{u}}rgen D{\"{o}}llner and Klaus Hinrichs",
  abstract =     "Three-dimensional maps are fundamental tools for
                 presenting, exploring, and manipulating geo data. This
                 paper describes multiresolution concepts for 3D maps
                 and their texture-based design. In our approach, 3D
                 maps are based on a hybrid, multiresolution terrain
                 model composed of data sets having different
                 topological structure, for example a coarse regular
                 grid combined with by triangulated microstructure. Any
                 number of texture layers can be associated with the
                 terrain model. For each texture layer, the
                 multiresolution structure builds a texture tree which
                 is linked to geometry patches of the multiresolution
                 terrain model. The terrain model together with multiple
                 texture layers can be rendered in real-time, in
                 particular if multitexturing is available. Texture
                 layers can be combined by high-level operations such us
                 blending and masking and can be rebuilt at run-time.
                 This mechanism simplifies the implementation of visual
                 exploration tools and of procedural, automated map
                 designs. 3D maps facilitate the visual simulation of
                 environmental issues in spatial support systems,
                 virtual reality applications, real-time GIS, and
                 interactive cartography.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-495,
  pages =        "335--341",
  year =         "2000",
  title =        "Molecular Dynamics Visualization with {XML} and
                 {VRML}",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-495",
  author =       "B. Arun and V. Chandru and A. D. Ganguly and Swami
                 Manohar",
  abstract =     "A new Extensible Markup Language (XML) application,
                 Molecular Dynamics Language (MoDL) has been developed.
                 MoDL provides a simple, but powerful tool for molecular
                 dynamics visualization and has been developed by
                 combining, for the first time, the strengths of XML and
                 the Virtual Reality Modeling Language. The details of
                 MoDL, its implementation and examples of its use are
                 presented in this paper.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International Proceedings",
}

@InProceedings{EVL-2000-496,
  pages =        "343--351",
  year =         "2000",
  title =        "Visual Simulation of Texture/Non-Texture Image
                 Synthesis",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-496",
  author =       "Hussein Karam and Aboul Ella Hassanien and Masayuki
                 Nakajima",
  abstract =     "We propose a new and effective image modeling dual
                 technique which is capable of simulating both texture
                 image synthesis and non-texture images like fractals.
                 The technique uses the algebraic approach of graph
                 grammars theory as a new simulation tool for both
                 texture and non-texture image synthesis via its graph
                 production, derivation and double-pushout construction.
                 Validation of our approach is given by discussion and
                 an illustration of some experimental results. An
                 investigation of the relationships between the
                 generated patterns and their corresponding graph
                 grammars is also discussed.",
  organization = "IEEE Computer Society",
  month =        jun,
  booktitle =    "Computer Graphics International 2000 Proceedings",
}

@InProceedings{EVL-2000-5,
  pages =        "21--29",
  year =         "2000",
  title =        "Access Method for image Databases",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-5",
  author =       "M. Iwasaki and N. Takahashi and K. Morozumi",
  organization = "SPIE",
  month =        jan,
  editor =       "M. M. Yeung and B.-L. Yeo and C. A. Bouman",
  volume =       "3972",
  keywords =     "image database, retrieval, hierarchical
                 classification, visualization, usability",
  booktitle =    "Proceedings of SPIE: Storage and Retrieval for Media
                 Databases 2000",
}

@InProceedings{EVL-2000-50,
  pages =        "145--156",
  year =         "2000",
  title =        "Acquiring the Reflectance Field of a Human Face",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-50",
  author =       "Paul Debevec and Tim Hawkins and Chris Tchou and
                 Haarm-Pieter Duiker and Westley Sarokin and Mark
                 Sagar",
  abstract =     "We present a method to acquire the reflectance field
                 of a human face and use these measurements to render
                 the face under arbitrary changes in lighting and
                 viewpoint. We first acquire images of the face from a
                 small set of viewpoints under a dense sampling of
                 incident illumination directions using a light stage.
                 We then construct a reflectance function image for each
                 observed image pixel from its values over the space of
                 illumination directions. From the reflectance
                 functions, we can directly generate images of the face
                 from the original viewpoints in any form of sampled or
                 computed illumination. To change the viewpoint, we use
                 a model of skin reflectance to estimate the appearance
                 of the reflectance functions for novel viewpoints. We
                 demonstrate the technique with synthetic renderings of
                 a person's face under novel illumination and
                 viewpoints.",
  editor =       "Kurt Akeley",
  keywords =     "facial animation; image-based modeling, rendering,
                 lighting",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-51,
  pages =        "157--164",
  year =         "2000",
  title =        "As-Rigid-As-Possible Shape Interpolation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-51",
  author =       "Marc Alexa and Daniel Cohen-Or and David Levin",
  abstract =     "We present an object-space morphing technique that
                 blends the interiors of given two- or three-dimensional
                 shapes rather than their boundaries. The morph is rigid
                 in the sense that local volumes are least-distorting as
                 they vary from their source to target configurations.
                 Given a boundary vertex correspondence, the source and
                 target shapes are decomposed into isomorphic simplicial
                 complexes. For the simplicial complexes, we find a
                 closed-form expression allocating the paths of both
                 boundary and interior vertices from source to target
                 locations as a function of time. Key points are the
                 identification of the optimal simplex morphing and the
                 appropriate definition of an error functional whose
                 minimization defines the paths of the vertices. Each
                 pair of corresponding simplices defines an affine
                 transformation, which is factored into a rotation and a
                 stretching transformation. These local transformations
                 are naturally interpolated over time and serve as the
                 basis for composing a global coherent least-distorting
                 transformation.",
  editor =       "Kurt Akeley",
  keywords =     "shape blending, vertex path problem, compatible
                 triangulatio",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-52,
  year =         "2000",
  title =        "Pose Space Deformations: {A} Unified Approach to Shape
                 Interpolation a nd Skeleton-Driven Deformation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-52",
  author =       "J. P. Lewis and Matt Cordner and Nickson Fong",
  abstract =     "Pose space deformation generalizes and improves upon
                 both shape interpolation and common skeleton-driven
                 deformation techniques. This deformation approach
                 proceeds from the observation that several types of
                 deformation can be uniformly represented as mappings
                 from a pose space, defined by either an underlying
                 skeleton or a more abstract system of parameters, to
                 displacements in the object local coordinate frames.
                 Once this uniform representation is identified,
                 previously disparate deformation types can be
                 accomplished within a single unified approach. The
                 advantages of this algorithm include improved
                 expressive power and direct manipulation of the desired
                 shapes yet the performance associated with traditional
                 shape interpolation is achievable. Appropriate
                 applications include animation of facial and body
                 deformation for entertainment, telepresence, computer
                 gaming, and other applications where direct sculpting
                 of deformations is desired or where real-time synthesis
                 of a deforming model is required.",
  editor =       "Kurt Akeley",
  keywords =     "Animation, Deformation, Facial Animation, Morphing,
                 Applications",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-53,
  pages =        "173--182",
  year =         "2000",
  title =        "The {EMOTE} Model for Effort and Shape",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-53",
  author =       "Diane M. Chi and Monica Costa and Liwei Zhao and
                 Norman I. Badler",
  abstract =     "Human movements include limb gestures and postural
                 attitude. Although many computer animation researchers
                 have studied these classes of movements, procedurally
                 generated movements still lack naturalness. We argue
                 that looking only at the psychological notion of
                 gesture is insufficient to capture movement qualities
                 needed by animated characters. We advocate that the
                 domain of movement observation science, specifically
                 Laban Movement Analysis (LMA) and its Effort and Shape
                 components, provides us with valuable parameters for
                 the form and execution of qualitative aspects of
                 movements. Inspired by some tenets shared among LMA
                 proponents, we also point out that Effort and Shape
                 phrasing across movements and the engagement of the
                 whole body are essential aspects to be considered in
                 the search for naturalness in procedurally generated
                 gestures. Finally, we present EMOTE (Expressive MOTion
                 Engine), a 3D character animation system that applies
                 Effort and Shape qualities to independently defined
                 underlying movements and thereby generates more natural
                 synthetic gestures",
  editor =       "Kurt Akeley",
  keywords =     "Animation systems, human body simulation, gestures,
                 procedural modeling, expression",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-54,
  pages =        "183--192",
  year =         "2000",
  title =        "Style Machines",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-54",
  author =       "Matthew Brand and Aaron Hertzmann",
  abstract =     "We approach the problem of stylistic motion synthesis
                 by learning motion patterns from a highly varied set of
                 motion capture sequences. Each sequence may have a
                 distinct choreography, performed in a distinct style.
                 Learning identifies common choreographic elements
                 across sequences, the different styles in which each
                 element is performed, and a small number of stylistic
                 degrees of freedom which span the many variations in
                 the dataset. The learned model can synthesize novel
                 motion data in any interpolation or extrapolation of
                 styles. For example, it can convert novice ballet
                 motions into the more graceful modern dance of an
                 expert. The model can also be driven by video, by
                 scripts, or even by noise to generate new choreography
                 and synthesize virtual motion-capture in many styles.",
  editor =       "Kurt Akeley",
  keywords =     "animation, behavior simulation, character behavior",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-55,
  pages =        "193--200",
  year =         "2000",
  title =        "Timewarp Rigid Body Simulation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-55",
  author =       "Brian Mirtich",
  abstract =     "The traditional high-level algorithms for rigid body
                 simulation work well for moderate numbers of bodies but
                 scale poorly to systems of hundreds or more moving,
                 interacting bodies. The problem is unnecessary
                 synchronization implicit in these methods. Jefferson's
                 timewarp algorithm [22] is a technique for alleviating
                 this problem in parallel discrete event simulation.
                 Rigid body dynamics, though a continuous process,
                 exhibits many aspects of a discrete one. With
                 modification, the timewarp algorithm can be used in a
                 uniprocessor rigid body simulator to give substantial
                 performance improvements for simulations with large
                 numbers of bodies. This paper describes the limitations
                 of the traditional high-level simulation algorithms,
                 introduces Jeffersons algorithm, and extends and
                 optimizes it for the rigid body case. It addresses
                 issues particular to rigid body simulation, such as
                 collision detection and contact group management, and
                 describes how to incorporate these into the time-warp
                 framework. Quantitative experimental results indicate
                 that the timewarp algorithm offers significant
                 performance improvements over traditional high-level
                 rigid body simulation algorithms, when applied to
                 systems with hundreds of bodies. It also helps pave the
                 way to parallel implementations, as the paper
                 discusses.",
  editor =       "Kurt Akeley",
  keywords =     "Physics Based Modeling, Animation",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-56,
  pages =        "201--208",
  year =         "2000",
  title =        "Interactive Control For Physically-Based Animation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-56",
  author =       "Joseph Laszlo and Michiel van de Panne and Eugene
                 Fiume",
  abstract =     "We propose the use of interactive, user-in-the-loop
                 techniques for controlling physically-based animated
                 characters. With a suitably designed interface, the
                 continuous and discrete input actions afforded by a
                 standard mouse and keyboard allow for the creation of a
                 broad range of motions. We apply our techniques to
                 interactively control planar dynamic simulations of a
                 bounding cat, a gymnastic desk lamp, and a human
                 character capable of walking, running, climbing, and
                 various gymnastic behaviors. The interactive control
                 techniques allows a performer's intuition and knowledge
                 about motion planning to be readily exploited. Video
                 games are the current target application of this
                 work.",
  editor =       "Kurt Akeley",
  keywords =     "physically based animation, user interfaces",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-57,
  pages =        "219--228",
  year =         "2000",
  title =        "Sampling Plausible Solutions to Multi-Body Constraint
                 Problems",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-57",
  author =       "Stephen Chenney and D. A. Forsyth",
  abstract =     "Traditional collision intensive multi-body simulations
                 are difficult to control due to extreme sensitivity to
                 initial conditions or model parameters. Furthermore,
                 there may be multiple ways to achieve any one goal, and
                 it may be difficult to codify a user's preferences
                 before they have seen the available solutions. In this
                 paper we extend simulation models to include plausible
                 sources of uncertainty, and then use a Markov chain
                 Monte Carlo algorithm to sample multiple animations
                 that satisfy constraints. A user can choose the
                 animation they prefer, or applications can take direct
                 advantage of the multiple solutions. Our technique is
                 applicable when a probability can be attached to each
                 animation, with {"}good{"} animations having high
                 probability, and for such cases we provide a definition
                 of physical plausibility for animations. We demonstrate
                 our approach with examples of multi-body rigid-body
                 simulations that satisfy constraints of various kinds,
                 for each case presenting animations that are true to a
                 physical model, are significantly different from each
                 other, and yet still satisfy the constraints.",
  editor =       "Kurt Akeley",
  keywords =     "plausible motion, Markov chain Monte Carlo, motion
                 synthesis, spacetime constraints",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-58,
  pages =        "209--218",
  year =         "2000",
  title =        "Interactive Manipulation of Rigid Body Simulations",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-58",
  author =       "Jovan Popovic and Steven M. Seitz and Michael Erdmann
                 and Zoran Popovic and Andrew Witkin",
  abstract =     "Physical simulation of dynamic objects has become
                 commonplace in computer graphics because it produces
                 highly realistic animations. In this paradigm the
                 animator provides few physical parameters such as the
                 objects' initial positions and velocities, and the
                 simulator automatically generates realistic motions.
                 The resulting motion, however, is difficult to control
                 because even a small adjustment of the input parameters
                 can drastically affect the subsequent motion.
                 Furthermore, the animator often wishes to change the
                 end-result of the motion instead of the initial
                 physical parameters. We describe a novel interactive
                 technique for intuitive manipulation of rigid
                 multi-body simulations. Using our system, the animator
                 can select bodies at any time and simply drag them to
                 desired locations. In response, the system computes the
                 required physical parameters and simulates the
                 resulting motion. Surface characteristics such as
                 normals and elasticity coefficients can also be
                 automatically adjusted to provide a greater range of
                 feasible motions, if the animator so desires. Because
                 the entire simulation editing process runs at
                 interactive speeds, the animator can rapidly design
                 complex physical animations that would be difficult to
                 achieve with existing rigid body simulators.",
  editor =       "Kurt Akeley",
  keywords =     "Physically Based Animation, Animation with
                 Constraint",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-59,
  pages =        "229--238",
  year =         "2000",
  title =        "Conservative Volumetric Visibility with Occluder
                 Fusion",
  author =       "Gernot Schaufler and Julie Dorsey and Xavier Decoret
                 and Fran{\c{c}}ois X. Sillion",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-59",
  abstract =     "Visibility determination is a key requirement in a
                 wide range of graphics algorithms. This paper
                 introduces a new approach to the computation of volume
                 visibility, the detection of occluded portions of space
                 as seen from a given region. The method is conservative
                 and classifies regions as occluded only when they are
                 guaranteed to be invisible. It operates on a discrete
                 representation of space and uses the opaque interior of
                 objects as occluders. This choice of occluders
                 facilitates their extension into adjacent opaque
                 regions of space, in essence maximizing their size and
                 impact. Our method efficiently detects and represents
                 the regions of space hidden by such occluders. It is
                 the first one to use the property that occluders can
                 also be extended into empty space provided this space
                 is itself occluded from the viewing volume. This proves
                 extremely effective for computing the occlusion by a
                 set of occluders, effectively realizing occluder
                 fusion. An auxiliary data structure represents
                 occlusion in the scene and can then be queried to
                 answer volume visibility questions. We demonstrate the
                 applicability to visibility preprocessing for real-time
                 walkthroughs and to shadow-ray acceleration for
                 extended light sources in ray tracing, with significant
                 acceleration in both cases.",
  editor =       "Kurt Akeley",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-6,
  pages =        "86--97",
  year =         "2000",
  title =        "Content-based image retrieval by scale-space object
                 boundary shape representation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-6",
  author =       "M. E. Hoffman and E. K. Wong",
  organization = "SPIE",
  month =        jan,
  editor =       "M. M. Yeung and B.-L. Yeo and C. A. Bouman",
  volume =       "3972",
  keywords =     "scale-space, content-based retrieval, shape, boundary,
                 contour stability over scale, image database, boundary
                 representation",
  booktitle =    "Proceedings of SPIE: Storage and Retrieval for Media
                 Databases 2000",
}

@InProceedings{EVL-2000-60,
  pages =        "239--248",
  year =         "2000",
  title =        "Conservative Visibility Preprocessing Using Extended
                 Projections",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-60",
  author =       "Fr{\'{e}}do Durand and George Drettakis and
                 Jo{\"{e}}lle Thollot and Claude Puech",
  abstract =     "Visualization of very complex scenes can be
                 significantly accelerated using occlusion culling. In
                 this paper we present a visibility preprocessing method
                 which efficiently computes potentially visible geometry
                 for volumetric viewing cells. We introduce novel
                 extended projection operators, which permits efficient
                 and conservative occlusion culling with respect to all
                 viewpoints within a cell, and takes into account the
                 combined occlusion effect of multiple occluders. We use
                 extended projection of occluders onto a set of
                 projection planes to create extended occlusion maps; we
                 show how to efficiently test occludees against these
                 occlusion maps to determine occlusion with respect to
                 the entire cell. We also present an improved projection
                 operator for certain specific but important
                 configurations. An important advantage of our approach
                 is that we can re-project extended projections onto a
                 series of projection planes (via an occlusion sweep),
                 and accumulate occlusion information from multiple
                 blockers. This new approach allows the creation of
                 effective occlusion maps for previously hard-to-treat
                 scenes such as leaves of trees in a forest. Graphics
                 hardware is used to accelerate both the extended
                 projection and reprojection operations. We present a
                 complete implementation demonstrating significant
                 speedup with respect to view-frustum culling only,
                 without the computational overhead of on-line occlusion
                 culling",
  editor =       "Kurt Akeley",
  keywords =     "Occlusion culling, visibility determination, PVS",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-61,
  pages =        "249--254",
  year =         "2000",
  title =        "Adaptively Sampled Distance Fields: {A} General
                 Representation of Shape for Computer Graphics",
  author =       "Sarah F. Frisken and Ronald N. Perry and Alyn P.
                 Rockwood and Thouis R. Jones",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-61",
  abstract =     "Adaptively Sampled Distance Fields (ADFs) are a
                 unifying representation of shape that integrate
                 numerous concepts in computer graphics including the
                 representation of geometry and volume data and a broad
                 range of processing operations such as rendering,
                 sculpting, level-of-detail management, surface
                 offsetting, collision detection, and color gamut
                 correction. Its structure is uncomplicated and direct,
                 but is especially effective for quality reconstruction
                 of complex shapes, e.g., artistic and organic forms,
                 precision parts, volumes, high order functions, and
                 fractals. We characterize one implementation of ADFs,
                 illustrating its utility on two diverse applications:
                 1) artistic carving of fine detail, and 2) representing
                 and rendering volume data and volumetric effects. Other
                 applications are briefly presented.",
  editor =       "Kurt Akeley",
  keywords =     "Distance fields, carving, implicit surfaces,
                 rendering, volume rendering, volume modeling, level of
                 detail, graphics",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-62,
  pages =        "255--258",
  year =         "2000",
  title =        "Patching Catmull-Clark Meshes",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-62",
  author =       "J{\"{o}}rg Peters",
  abstract =     "Named after the title, the PCCM transformation is a
                 simple, explicit algorithm that creates large, smoothly
                 joining bicubic Nurbs patches from a refined
                 Catmull-Clark subdivision mesh. The resulting patches
                 are maximally large in the sense that one patch
                 corresponds to one quadrilateral facet of the initial,
                 coarsest quadrilateral mesh before subdivision. The
                 patches join parametrically C2 and agree with the
                 Catmull-Clark limit surface except in the immediate
                 neighborhood of extraordinary mesh nodes; in such a
                 neighborhood they join at least with tangent continuity
                 and interpolate the limit of the extraordinary mesh
                 node. The PCCM transformation integrates naturally with
                 array-based implementations of subdivision surfaces.",
  editor =       "Kurt Akeley",
  keywords =     "CAD, Curves & Surfaces, Geometric Modeling",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-63,
  pages =        "259--262",
  year =         "2000",
  title =        "Out-of-Core Simplification of Large Polygonal Models",
  author =       "Peter Lindstrom",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-63",
  abstract =     "We present an algorithm for out-of-core simplification
                 of large polygonal datasets that are too complex to fit
                 in main memory. The algorithm extends the vertex
                 clustering scheme of Rossignac and Borrel [13] by using
                 error quadric information for the placement of each
                 cluster's representative vertex, which better preserves
                 fine details and results in a low mean geometric error.
                 The use of quadrics instead of the vertex grading
                 approach in [13] has the additional benefits of
                 requiring less disk space and only a single pass over
                 the model rather than two. The resulting linear time
                 algorithm allows simplification of datasets of
                 arbitrary complexity. In order to handle degenerate
                 quadrics associated with (near) flat regions and
                 regions with zero Gaussian curvature, we present a
                 robust method for solving the corresponding
                 underconstrained least-squares problem. The algorithm
                 is able to detect these degeneracies and handle them
                 gracefully. Key features of the simplification method
                 include a bounded Hausdorff error, low mean geometric
                 error, high simplification speed (up to 100,000
                 triangles/second reduction), output (but not input)
                 sensitive memory requirements, no disk space overhead,
                 and a running time that is independent of the order in
                 which vertices and triangles occur in the mesh.",
  editor =       "Kurt Akeley",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 20000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-64,
  pages =        "263--270",
  year =         "2000",
  title =        "Face Fixer: Compressing Polygon Meshes With
                 Properties",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-64",
  author =       "Martin Isenburg and Jack Snoeylink",
  abstract =     "Most schemes to compress the topology of a surface
                 mesh have been developed for the lowest common
                 denominator: triangulated meshes. We propose a scheme
                 that handles the topology of arbitrary polygon meshes.
                 It encodes meshes directly in their polygonal
                 representation and extends to capture face groupings in
                 a natural way. Avoiding the triangulation step we
                 reduce the storage costs for typical polygon models
                 that have group structures and property data.",
  editor =       "Kurt Akeley",
  keywords =     "Mesh compression, connectivity encoding",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-65,
  pages =        "271--278",
  year =         "2000",
  title =        "Progressive Geometry Compression",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-65",
  author =       "Andrei Khodakovsky and Peter Schr{\"{o}}der and Wim
                 Sweldens",
  abstract =     "We propose a new progressive compression scheme for
                 arbitrary topology, highly detailed and densely sampled
                 meshes arising from geometry scanning. We observe that
                 meshes consist of three distinct components: geometry,
                 parameter, and connectivity information. The latter two
                 do not contribute to the reduction of error in a
                 compression setting. Using semi-regular meshes,
                 parameter and connectivity information can be virtually
                 eliminated. Coupled with semi-regular wavelet
                 transforms, zerotree coding, and subdivision based
                 reconstruction we see improvements in error by a factor
                 four (12dB) compared to other progressive coding
                 schemes",
  editor =       "Kurt Akeley",
  keywords =     "Compression algorithms, signal processing, wavelets,
                 subdivision surfaces, semi-regular meshes, zerotree
                 coding, hierarchical representations",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-66,
  pages =        "279--286",
  year =         "2000",
  title =        "Spectral Compression of Mesh Geometry",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-66",
  author =       "Zachi Karni and Craig Gotsman",
  abstract =     "We show how spectral methods may be applied to 3D mesh
                 data to obtain compact representations. This is
                 achieved by projecting the mesh geometry onto an
                 orthonormal basis derived from the mesh topology. To
                 reduce complexity, the mesh is partitioned into a
                 number of balanced submeshes with minimal interaction,
                 each of which are compressed independently. Our methods
                 may be used for compression and progressive
                 transmission of 3D content, and are shown to be vastly
                 superior to existing methods using spatial techniques,
                 if slight loss can be tolerated.",
  editor =       "Kurt Akeley",
  keywords =     "Compression Algorithms, Signal Processing",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-67,
  pages =        "287--296",
  year =         "2000",
  title =        "Surface Light Fields for 3{D} Photography",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-67",
  author =       "Daniel N. Wood and Daniel I. Azuma and Ken Aldinger
                 and Brian Curless and Tom Duchamp and David H. Salesin
                 and Werner Stuetzle",
  abstract =     "A surface light field is a function that assigns a
                 color to each ray originating on a surface. Surface
                 light fields are well suited to constructing virtual
                 images of shiny objects under complex lighting
                 conditions. This paper presents a framework for
                 construction, compression, interactive rendering, and
                 rudimentary editing of surface light fields of real
                 objects. Generalizations of vector quantization and
                 principal component analysis are used to construct a
                 compressed representation of an object's surface light
                 field from photographs and range scans. A new rendering
                 algorithm achieves interactive rendering of images from
                 the compressed representation, incorporating
                 view-dependent geometric level-of-detail control. The
                 surface light field representation can also be directly
                 edited to yield plausible surface light fields for
                 small changes in surface geometry and reflectance
                 properties.",
  editor =       "Kurt Akeley",
  keywords =     "surface light fields, 3D photography, lumigraph, light
                 field, function quantization, principal function
                 analysis, view-dependent level-of-detail, image-based
                 rendering, wavelets",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-68,
  pages =        "297--306",
  year =         "2000",
  title =        "Dynamically Reparameterized Light Fields",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-68",
  author =       "Aaron Isaksen and Leonard McMillan and Steven J.
                 Gortler",
  abstract =     "This research further develops the light field and
                 lumigraph image-based rendering methods and extends
                 their utility. We present alternate parameterizations
                 that permit 1) interactive rendering of moderately
                 sampled light fields of scenes with significant,
                 unknown depth variation and 2) low-cost, passive
                 autostereoscopic viewing. Using a dynamic
                 reparameterization, these techniques can be used to
                 interactively render photographic effects such as
                 variable focus and depth-of-field within a light field.
                 The dynamic parameterization is independent of scene
                 geometry and does not require actual or approximate
                 geometry of the scene. We explore the frequency domain
                 and ray-space aspects of dynamic reparameterization,
                 and present an interactive rendering technique that
                 takes advantage of today's commodity rendering
                 hardware.",
  editor =       "Kurt Akeley",
  keywords =     "Image-based rendering, light field, lumigraph, ray
                 space analysis, frequency domain analysis,
                 autostereoscopic displays, synthetic aperture, depth of
                 field, multitexturing",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-69,
  pages =        "335--342",
  year =         "2000",
  title =        "Surfels: Surface Elements as Rendering Primitives",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-69",
  author =       "Hanspeter Pfister and Matthias Zwicker and Jeroen van
                 Baar and Markus Gross",
  abstract =     "Surface elements (surfels) are a powerful paradigm to
                 efficiently render complex geometric objects at
                 interactive frame rates. Unlike classical surface
                 discretizations, i.e., triangles or quadrilateral
                 meshes, surfels are point primitives without explicit
                 connectivity. Surfel attributes comprise depth, texture
                 color, normal, and others. As a pre-process, an
                 octree-based surfel representation of a geometric
                 object is computed. During sampling, surfel positions
                 and normals are optionally perturbed, and different
                 levels of texture colors are prefiltered and stored per
                 surfel. During rendering, a hierarchical forward
                 warping algorithm projects surfels to a z-buffer. A
                 novel method called visibility splatting determines
                 visible surfels and holes in the z-buffer. Visible
                 surfels are shaded using texture filtering, Phong
                 illumination, and environment mapping using per-surfel
                 normals. Several methods of image reconstruction,
                 including supersampling, offer flexible speed-quality
                 tradeoffs. Due to the simplicity of the operations, the
                 surfel rendering pipeline is amenable for hardware
                 implementation. Surfel objects offer complex shape, low
                 rendering cost and high image quality, which makes them
                 specifically suited for low-cost, real-time graphics,
                 such as games.",
  editor =       "Kurt Akeley",
  keywords =     "Rendering Systems, Texture Mapping",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-7,
  pages =        "98--105",
  year =         "2000",
  title =        "Content-based Object Retrieval Using Maximum Curvature
                 Points In Contour Images",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-7",
  author =       "A. Quddus and F. A. Cheikh and M. Gabbouj",
  organization = "SPIE",
  month =        jan,
  editor =       "M. M. Yeung and B.-L. Yeo and C. A. Bouman",
  volume =       "3972",
  keywords =     "Contour matching, object retrieval, indexing, image
                 database, content, boundary, high curvature points,
                 similarity measure, wavelet",
  booktitle =    "Proceedings of SPIE: Storage and Retrieval for Media
                 Databases 2000",
}

@InProceedings{EVL-2000-70,
  pages =        "307--318",
  year =         "2000",
  title =        "Plenoptic Sampling",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-70",
  author =       "Jin-Xiang Chai and Xin Tong and Shing-Chow Chan and
                 Heung-Yeung Shum",
  abstract =     "This paper studies the problem of plenoptic sampling
                 in image-based rendering (IBR). From a spectral
                 analysis of light field signals and using the sampling
                 theorem, we mathematically derive the analytical
                 functions to determine the minimum sampling rate for
                 light field rendering. The spectral support of a light
                 field signal is bounded by the minimum and maximum
                 depths only, no matter how complicated the spectral
                 support might be because of depth variations in the
                 scene. The minimum sampling rate for light field
                 rendering is obtained by compacting the replicas of the
                 spectral support of the sampled light field within the
                 smallest interval. Given the minimum and maximum
                 depths, a reconstruction filter with an optimal and
                 constant depth can be designed to achieve anti-aliased
                 light field rendering. Plenoptic sampling goes beyond
                 the minimum number of images needed for anti-aliased
                 light field rendering. More significantly, it utilizes
                 the scene depth information to determine the minimum
                 sampling curve in the joint image and geometry space.
                 The minimum sampling curve quantitatively describes the
                 relationship among three key elements in IBR systems:
                 scene complexity (geometrical and textural
                 information), the number of image samples, and the
                 output resolution. Therefore, plenoptic sampling
                 bridges the gap between image-based rendering and
                 traditional geometry-based rendering. Experimental
                 results demonstrate the effectiveness of our
                 approach.",
  editor =       "Kurt Akeley",
  keywords =     "sampling, plenoptic sampling, spectral analysis,
                 plenoptic functions, image-based rendering",
  series =       "Annual Conference Series",
  booktitle =    "Siggrapph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-71,
  pages =        "319--326",
  year =         "2000",
  title =        "An Autostereoscopic Display",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-71",
  author =       "Ken Perlin and Salvatore Paxia and Joel S. Kollin",
  abstract =     "We present a display device which solves a
                 long-standing problem: to give a true stereoscopic view
                 of simulated objects, without artifacts, to a single
                 unencumbered observer, while allowing the observer to
                 freely change position and head rotation. Based on a
                 novel combination of temporal and spatial multiplexing,
                 this technique will enable artifact-free stereo to
                 become a standard feature of display screens, without
                 requiring the use of special eyewear. The availability
                 of this technology may significantly impact CAD and CHI
                 applications, as well as entertainment graphics. The
                 underlying algorithms and system architecture are
                 described, as well as hardware and software aspects of
                 the implementation.",
  editor =       "Kurt Akeley",
  keywords =     "graphics hardware, hardware systems, object tracking,
                 optics, user interface hardware, virtual reality",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-72,
  pages =        "327--334",
  year =         "2000",
  title =        "Silhouette Clipping",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-72",
  author =       "Pedro V. Sander and Xianfeng Gu and Steven J. Gortler
                 and Hugues Hoppe and John Snyder",
  abstract =     "Approximating detailed models with coarse,
                 texture-mapped meshes results in polygonal silhouettes.
                 To eliminate this artifact, we introduce silhouette
                 clipping, a framework for efficiently clipping the
                 rendering of coarse geometry to the exact silhouette of
                 the original model. The coarse mesh is obtained using
                 progressive hulls, a novel representation with the
                 nesting property required for proper clipping. We
                 describe an improved technique for constructing texture
                 and normal maps over this coarse mesh. Given a
                 perspective view, silhouettes are efficiently extracted
                 from the original mesh using a precomputed search tree.
                 Within the tree, hierarchical culling is achieved using
                 pairs of anchored cones. The extracted silhouette edges
                 are used to set the hardware stencil buffer and alpha
                 buffer, which in turn clip and antialias the rendered
                 coarse geometry. Results demonstrate that silhouette
                 clipping can produce renderings of similar quality to
                 high-resolution meshes in less rendering time.",
  editor =       "Kurt Akeley",
  keywords =     "Level of Detail Algorithms, Rendering Algorithms,
                 Texture Mapping, Triangle Decimation",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-73,
  pages =        "343--352",
  year =         "2000",
  title =        "{QS}plat: {A} Multiresolution Point Rendering System
                 for Large Meshes",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-73",
  author =       "Szymon Rusinkiewicz and Marc Levoy",
  abstract =     "Advances in 3D scanning technologies have enabled the
                 practical creation of meshes with hundreds of millions
                 of polygons. Traditional algorithms for display,
                 simplification, and progressive transmission of meshes
                 are impractical for data sets of this size. We describe
                 a system for representing and progressively displaying
                 these meshes that combines a multiresolution hierarchy
                 based on bounding spheres with a rendering system based
                 on points. A single data structure is used for view
                 frustum culling, backface culling, level-of-detail
                 selection, and rendering. The representation is compact
                 and can be computed quickly, making it suitable for
                 large data sets. Our implementation, written for use in
                 a large-scale 3D digitization project, launches
                 quickly, maintains a user-settable interactive frame
                 rate regardless of object complexity or camera
                 position, yields reasonable image quality during
                 motion, and refines progressively when idle to a high
                 final image quality. We have demonstrated the system on
                 scanned models containing hundreds of millions of
                 samples.",
  editor =       "Kurt Akeley",
  keywords =     "Rendering systems, Spatial data structures, Level of
                 detail algorithms, Compression algorithms",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-74,
  pages =        "353--358",
  year =         "2000",
  title =        "A Fast Relighting Engine for Interactive Cinematic
                 Lighting Design",
  author =       "Reid Gershbein and Pat Hanrahan",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-74",
  abstract =     "We present new techniques for interactive cinematic
                 lighting design of complex scenes that use procedural
                 shaders. Deep-framebuffers are used to store the
                 geometric and optical information of the visible
                 surfaces of an image. The geometric information is
                 represented as collections of oriented points, and the
                 optical information is represented as bi-directional
                 reflection distribution functions, or BRDFs. The BRDFs
                 are generated by procedurally defined surface texturing
                 functions that spatially vary the surfaces'
                 appearances. The deep-framebuffer information is
                 rendered using a multi-pass algorithm built on the
                 OpenGL graphics pipeline. In order to han-dle both
                 physically-correct as well as non-realistic reflection
                 mod-els used in the film industry, we factor the BRDF
                 into independent components that map onto both the
                 lighting and texturing units of the graphics hardware.
                 A similar factorization is used to control the lighting
                 distribution. Using these techniques, lighting
                 calculations can be evaluated 2500 times faster than
                 previous methods. This allows lighting changes to be
                 rendered at rates of 20Hz in static environments that
                 contain millions of objects with dozens of unique
                 procedurally defined surface properties and scores of
                 lights.",
  editor =       "Kurt Akeley",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-75,
  pages =        "359--368",
  year =         "2000",
  title =        "Relief Texture Mapping",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-75",
  author =       "Manuel M. Oliveira and Gary Bishop and David
                 McAllister",
  abstract =     "We present an extension to texture mapping that
                 supports the representation of 3-D surface details and
                 view motion parallax. The results are correct for
                 viewpoints that are static or moving, far away or
                 nearby. Our approach is very simple: a relief texture
                 (texture extended with an orthogonal displacement per
                 texel) is mapped onto a polygon using a two-step
                 process: First, it is converted into an ordinary
                 texture using a surprisingly simple 1-D forward
                 transform. The resulting texture is then mapped onto
                 the polygon using standard texture mapping. The 1-D
                 warping functions work in texture coordinates to handle
                 the parallax and visibility changes that result from
                 the 3-D shape of the displacement surface. The
                 subsequent texture-mapping operation handles the
                 transformation from texture to screen coordinates.",
  editor =       "Kurt Akeley",
  keywords =     "Image-Based Rendering, Texture Mapping, Range Images,
                 Rendering",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-76,
  pages =        "369--374",
  year =         "2000",
  title =        "Image-Based Visual Hulls",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-76",
  author =       "Wojciech Matusik and Chris Buehler and Ramesh Raskar
                 and Steven J. Gortler and Leonard McMillan",
  abstract =     "In this paper, we describe an efficient image-based
                 approach to computing and shading visual hulls from
                 silhouette image data. Our algorithm takes advantage of
                 epipolar geometry and incremental computation to
                 achieve a constant rendering cost per rendered pixel.
                 It does not suffer from the computation complexity,
                 limited resolution, or quantization artifacts of
                 previous volumetric approaches. We demonstrate the use
                 of this algorithm in a real-time virtualized reality
                 application running off a small number of video
                 streams.",
  editor =       "Kurt Akeley",
  keywords =     "Computer Vision, Image-Based Rendering, Constructive
                 Solid Geometry, Miscellaneous Rendering Algorithms",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-77,
  pages =        "375--384",
  year =         "2000",
  title =        "Efficient Image-Based Methods for Rendering Soft
                 Shadows",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-77",
  author =       "Maneesh Agrawala and Ravi Ramamoorthi and Alan Heirich
                 and Laurent Moll",
  abstract =     "We present two efficient image-based approaches for
                 computation and display of high-quality soft shadows
                 from area light sources. Our methods are related to
                 shadow maps and provide the associated benefits. The
                 computation time and memory requirements for adding
                 soft shadows to an image depend on image size and the
                 number of lights, not geometric scene complexity. We
                 also show that because area light sources are localized
                 in space, soft shadow computations are particularly
                 well suited to image-based rendering techniques. Our
                 first approach - layered attenuation maps - achieves
                 interactive rendering rates, but limits sampling
                 flexibility, while our second method - coherence-based
                 raytracing of depth images - is not interactive, but
                 removes the limitations on sampling and yields high
                 quality images at a fraction of the cost of
                 conventional raytracers. Combining the two algorithms
                 allows for rapid previewing followed by efficient
                 high-quality rendering.",
  editor =       "Kurt Akeley",
  keywords =     "Shadows, Raytracing, Image-Based Rendering",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-78,
  pages =        "385--392",
  year =         "2000",
  title =        "Deep Shadow Maps",
  author =       "Tom Lokovic and Eric Veach",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-78",
  abstract =     "Abstract We introduce deep shadow maps, a technique
                 that produces fast, high-quality shadows for primitives
                 such as hair, fur, and smoke. Unlike traditional shadow
                 maps, which store a single depth at each pixel, deep
                 shadow maps store a representation of the fractional
                 visibility through a pixel at all possible depths. Deep
                 shadow maps have several advantages. First, they are
                 prefiltered, which allows faster shadow lookups and
                 much smaller memory footprints than regular shadow maps
                 of similar quality. Second, they support shadows from
                 partially transparent surfaces and volumetric objects
                 such as fog. Third, they handle important cases of
                 motion blur at no extra cost. The algorithm is simple
                 to implement and can be added easily to existing
                 renderers as an alternative to ordinary shadow maps.",
  editor =       "Kurt Akeley",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-79,
  pages =        "393--402",
  year =         "2000",
  title =        "Tangible Interaction + Graphical Interpretation: {A}
                 New Approach to 3{D} Modeling",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-79",
  author =       "David Anderson and James L. Frankel and Joe Marks and
                 Aseem Agarwala and Paul Beardsley and Jessica K.
                 Hodgins and Darren Leigh and Kathy Ryall and Eddie
                 Sullivan and Jonathan S. Yedidia",
  abstract =     "Construction toys are a superb medium for creating
                 geometric models. We argue that such toys, suitably
                 instrumented or sensed, could be the inspiration for a
                 new generation of easy-to-use, tangible modeling
                 systems - especially if the tangible modeling is
                 combined with graphical-interpretation techniques for
                 enhancing nascent models automatically. The three key
                 technologies needed to realize this idea are embedded
                 computation, vision-based acquisition, and graphical
                 interpretation. We sample these technologies in the
                 context of two novel modeling systems: physical
                 building blocks that self-describe, interpret, and
                 decorate the structures into which they are assembled;
                 and a system for scanning, interpreting, and animating
                 clay figures.",
  editor =       "Kurt Akeley",
  keywords =     "Embedded Computation, Tangible User Interfaces,
                 Perceptual User Interfaces, Transmedia",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-8,
  pages =        "210--214",
  year =         "2000",
  title =        "Approximate search in image database",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-8",
  author =       "A. Ferro and G. Gallo and R. Giugno",
  organization = "SPIE",
  month =        jan,
  editor =       "M. M. Yeung and B.-L. Yeo and C. A. Bouman",
  volume =       "3972",
  keywords =     "error tolerant search, wavelets transforms, image
                 database retrieval",
  booktitle =    "Proceedings of SPIE: Storage and Retrieval for Media
                 Databases 2000",
}

@InProceedings{EVL-2000-80,
  pages =        "403--410",
  year =         "2000",
  title =        "Accessible Animation and Customizable Graphics via
                 Simplicial Configuration Modeling",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-80",
  author =       "Tom Ngo and Doug Cutrell and Jenny Dana and Bruce
                 Donald and Lorie Loeb and Shunhui Zhu",
  abstract =     "Our goal is to embed free-form constraints into a
                 graphical model. With such constraints a graphic can
                 maintain its visual integrity - and break rules
                 tastefully - while being manipulated by a casual user.
                 A typical parameterized graphic does not meet these
                 needs because its configuration space contains nonsense
                 images in much higher proportion than desirable images,
                 and the casual user is apt to ruin the graphic on any
                 attempt to modify or animate it. We therefore model the
                 small subset of a given graphic's configuration space
                 that maps to desirable images. In our solution, the
                 basic building block is a simplicial complex - the most
                 practical data structure able to accommodate the
                 variety of topologies that can arise. The
                 configuration-space model can be built from a cross
                 product of such complexes. We describe how to define
                 the mapping from this space to the image space. We show
                 how to invert that mapping, allowing the user to
                 manipulate the image without understanding the
                 structure of the configuration-space model. We also
                 show how to extend the mapping when the original
                 parameterization contains hierarchy, coordinate
                 transformations, and other nonlinearities. Our software
                 implementation applies simplicial configuration
                 modeling to 2D vector graphics.",
  editor =       "Kurt Akeley",
  keywords =     "Animation with constraints, geometric modeling, weird
                 math, WWW applications",
  series =       "Annuall Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-81,
  pages =        "411--416",
  year =         "2000",
  title =        "Example-Based Hinting of TrueType Fonts",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-81",
  author =       "Douglas E. Zongker and Geraldine Wade and David H.
                 Salesin",
  abstract =     "Hinting in TrueType is a time-consuming manual process
                 in which a typographer creates a sequence of
                 instructions for better fitting the characters of a
                 font to a grid of pixels. In this paper, we propose a
                 new method for automatically hinting TrueType fonts by
                 transferring hints of one font to another. Given a
                 hinted source font and a target font without hints, our
                 method matches the outlines of corresponding glyphs in
                 each font, and then translates all of the individual
                 hints for each glyph from the source to the target
                 font. It also translates the control value table (CVT)
                 entries, which are used to unify feature sizes across a
                 font. The resulting hinted font already provides a
                 great improvement over the unhinted version. More
                 importantly, the translated hints, which preserve the
                 sound, hand-designed hinting structure of the original
                 font, provide a very good starting point for a
                 professional typographer to complete and fine-tune,
                 saving time and increasing productivity. We demonstrate
                 our approach with examples of automatically hinted
                 fonts at typical display sizes and screen resolutions.
                 We also provide estimates of the time saved by a
                 professional typographer in hinting new fonts using
                 this semi-automatic approach.",
  editor =       "Kurt Akeley",
  keywords =     "automatic hinting, digital typography, gridfitting,
                 shape matching",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-82,
  pages =        "417--424",
  year =         "2000",
  title =        "Image Inpainting",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-82",
  author =       "Marcelo Bertalmio and Guillermo Sapiro and Vicent
                 Caselles and Coloma Ballester",
  abstract =     "Inpainting, the technique of modifying an image in an
                 undetectable form, is as ancient as art itself. The
                 goals and applications of inpainting are numerous, from
                 the restoration of damaged paintings and photographs to
                 the removal/replacement of selected objects. In this
                 paper, we introduce a novel algorithm for digital
                 inpainting of still images that attempts to replicate
                 the basic techniques used by professional restorators.
                 After the user selects the regions to be restored, the
                 algorithm automatically fills-in these regions with
                 information surrounding them. The fill-in is done in
                 such a way that isophote lines arriving at the regions'
                 boundaries are completed inside. In contrast with
                 previous approaches, the technique here introduced does
                 not require the user to specify where the novel
                 information comes from. This is automatically done (and
                 in a fast way), thereby allowing to simultaneously
                 fill-in numerous regions containing completely
                 different structures and surrounding backgrounds. In
                 addition, no limitations are imposed on the topology of
                 the region to be inpainted. Applications of this
                 technique include the restoration of old photographs
                 and damaged film; removal of superimposed text like
                 dates, subtitles, or publicity; and the removal of
                 entire objects from the image like microphones or wires
                 in special effects.",
  editor =       "Kurt Akeley",
  keywords =     "Image restoration, inpainting, isophotes, anisotropic
                 diffusion",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-83,
  pages =        "425--432",
  year =         "2000",
  title =        "Interactive Multi-Pass Programmable Shading",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-83",
  author =       "Mark S. Peercy and Marc Olano and John Airey and P.
                 Jeffrey Ungar",
  abstract =     "Programmable shading is a common technique for
                 production animation, but interactive programmable
                 shading is not yet widely available. We support
                 interactive programmable shading on virtually any 3D
                 graphics hardware using a scene graph library on top of
                 OpenGL. We treat the OpenGL architecture as a general
                 SIMD computer, and translate the high-level shading
                 description into OpenGL rendering passes. While our
                 system uses OpenGL, the techniques described are
                 applicable to any retained mode interface with
                 appropriate extension mechanisms and hardware API with
                 provisions for recirculating data through the graphics
                 pipeline. We present two demonstrations of the method.
                 The first is a constrained shading language that runs
                 on graphics hardware supporting OpenGL 1.2 with a
                 subset of the ARB imaging extensions. We remove the
                 shading language constraints by minimally extending
                 OpenGL. The key extensions are color range (supporting
                 extended range and precision data types) and pixel
                 texture (using framebuffer values as indices into
                 texture maps). Our second demonstration is a renderer
                 supporting the RenderMan Interface and RenderMan
                 Shading Language on a software implementation of this
                 extended OpenGL. For both languages, our compiler
                 technology can take advantage of extensions and
                 performance characteristics unique to any particular
                 graphics hardware.",
  editor =       "Kurt Akeley",
  keywords =     "Graphics Hardware, Graphics Systems, Illumination,
                 Languages, Rendering, Interactive Rendering,
                 Non-Realistic Rendering, Multi-Pass Rendering,
                 Programmable Shading, Procedural Shading, Texture
                 Synthesis, Texture Mapping, OpenGL",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings,",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-84,
  pages =        "433--442",
  year =         "2000",
  title =        "The WarpEngine: An Architecture for the Post-Polygonal
                 Age",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-84",
  author =       "Voicu Popescu and John Eyles and Anselmo Lastra and
                 Joshua Steinhurst and Nick England and Lars Nyland",
  abstract =     "We present the WarpEngine, an architecture designed
                 for real-time image-based rendering of natural scenes
                 from arbitrary viewpoints. The modeling primitives are
                 real-world images with per-pixel depth. Currently they
                 are acquired and stored off-line; in the near future
                 real-time depth-image acquisition will be possible, and
                 WarpEngine is designed to render in immediate mode from
                 such data sources. The depth-image resolution is
                 locally adapted by interpolation to match the
                 resolution of the output image. 3D warping can occur
                 either before or after the interpolation; the resulting
                 warped/interpolated samples are forward-mapped into a
                 warp buffer, with the precise locations recorded using
                 an offset. Warping processors are integrated on-chip
                 with the warp buffer, allowing efficient, scalable
                 implementation of very high performance systems. Each
                 chip will be able to process 100 million samples per
                 second and provide 4.8GigaBytes per second of bandwidth
                 to the warp buffer. The WarpEngine is significantly
                 less complex than our previous efforts, incorporating
                 only a single ASIC design. Small configurations can be
                 packaged as a PC add-in card, while larger deskside
                 configurations will provide HDTV resolutions at 50 Hz,
                 enabling radical new applications such as 3D
                 television. WarpEngine will be highly programmable,
                 facilitating use as a test-bed for experimental IBR
                 algorithms.",
  editor =       "Kurt Akeley",
  keywords =     "Graphics hardware, image-based rendering",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-85,
  pages =        "443--454",
  year =         "2000",
  title =        "Pomegranate: {A} Fully Scalable Graphics
                 Architecture",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-85",
  author =       "Matthew Eldridge and Homan Igehy and Pat Hanrahan",
  abstract =     "Pomegranate is a parallel hardware architecture for
                 polygon rendering that provides scalable input
                 bandwidth, triangle rate, pixel rate, texture memory
                 and display bandwidth while maintaining an
                 immediate-mode interface. The basic unit of scalability
                 is a single graphics pipeline, and up to 64 such units
                 may be combined. Pomegranate's scalability is achieved
                 with a novel {"}sort-everywhere{"} architecture that
                 distributes work in a balanced fashion at every stage
                 of the pipeline, keeping the amount of work performed
                 by each pipeline uniform as the system scales. Because
                 of the balanced distribution, a scalable network based
                 on high-speed point-to-point links can be used for
                 communicating between the pipelines. Pomegranate uses
                 the network to load balance triangle and fragment work
                 independently, to provide a shared texture memory and
                 to provide a scalable display system. The architecture
                 provides one interface per pipeline for issuing
                 ordered, immediate-mode rendering commands and supports
                 a parallel API that allows multiprocessor applications
                 to exactly order drawing commands from each interface.
                 A detailed hardware simulation demonstrates performance
                 on next-generation workloads. Pomegranate operates at
                 8799% parallel efficiency with 64 pipelines, for a
                 simulated performance of up to 1.10 billion triangles
                 per second and 21.8 billion pixels per second.",
  editor =       "Kurt Akeley",
  keywords =     "Graphics Hardware, Parallel Computing",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-86,
  pages =        "455--464",
  year =         "2000",
  title =        "Illuminating Micro Geometry Based on Precomputed
                 Visibility",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-86",
  author =       "Wolfgang Heidrich and Katja Daubert and Jan Kautz and
                 Hans-Peter Seidel",
  abstract =     "Many researchers have been arguing that geometry, bump
                 maps, and BRDFs present a hierarchy of detail that
                 should be exploited for efficient rendering purposes.
                 In practice however, this is often not possible due to
                 inconsistencies in the illumination for these different
                 levels of detail. For example, while bump map rendering
                 often only considers direct illumination and no
                 shadows, geometry-based rendering and BRDFs will mostly
                 also respect shadowing effects, and in many cases even
                 indirect illumination caused by scattered light. In
                 this paper, we present an approach for overcoming these
                 inconsistencies. We introduce an inexpensive method for
                 consistently illuminating height fields and bump maps,
                 as well as simulating BRDFs based on precomputed
                 visibility information. With this information we can
                 achieve a consistent illumination across the levels of
                 detail. The method we propose offers significant
                 performance benefits over existing algorithms for
                 computing the light scattering in height fields and for
                 computing a sampled BRDF representation using a virtual
                 gonioreflectometer. The performance can be further
                 improved by utilizing graphics hardware, which then
                 also allows for interactive display. Finally, our
                 method also approximates the changes in illumination
                 when the height field, bump map, or BRDF is applied to
                 a surface with a different curvature.",
  editor =       "Kurt Akeley",
  keywords =     "Illumination Effects, Monte Carlo Techniques, Graphics
                 Hardware, Frame Buffer Tricks, Reflectance & Shading
                 Models, Texture Mapping",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-87,
  pages =        "479--488",
  year =         "2000",
  title =        "Fast Texture Synthesis Using Tree-Structured Vector
                 Quantization",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-87",
  author =       "Li-Yi Wei and Marc Levoy",
  abstract =     "Texture synthesis is important for many applications
                 in computer graphics, vision, and image processing.
                 However, it remains difficult to design an algorithm
                 that is both efficient and capable of generating high
                 quality results. In this paper, we present an efficient
                 algorithm for realistic texture synthesis. The
                 algorithm is easy to use and requires only a sample
                 texture as input. It generates textures with perceived
                 quality equal to or better than those produced by
                 previous techniques, but runs two orders of magnitude
                 faster. This permits us to apply texture synthesis to
                 problems where it has traditionally been considered
                 impractical. In particular, we have applied it to
                 constrained synthesis for image editing and temporal
                 texture generation. Our algorithm is derived from
                 Markov Random Field texture models and generates
                 textures through a deterministic searching process. We
                 accelerate this synthesis process using tree-structured
                 vector quantization.",
  editor =       "Kurt Akeley",
  keywords =     "Texture Synthesis, Compression Algorithms, Image
                 Processing",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-88,
  pages =        "465--470",
  year =         "2000",
  title =        "Lapped Textures",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-88",
  author =       "Emil Praun and Adam Finkelstein and Hugues Hoppe",
  abstract =     "We present a method for creating texture over an
                 arbitrary surface mesh using an example 2D texture. The
                 approach is to identify interesting regions (texture
                 patches) in the 2D example, and to repeatedly paste
                 them onto the surface until it is completely covered.
                 We call such a collection of overlapping patches a
                 lapped texture. It is rendered using compositing
                 operations, either into a traditional global texture
                 map during a preprocess, or directly with the surface
                 at runtime. The runtime compositing approach avoids
                 resampling artifacts and drastically reduces texture
                 memory requirements. Through a simple interface, the
                 user specifies a tangential vector field over the
                 surface, providing local control over the texture
                 scale, and for anisotropic textures, the orientation.
                 To paste a texture patch onto the surface, a surface
                 patch is grown and parametrized over texture space.
                 Specifically, we optimize the parametrization of each
                 surface patch such that the tangential vector field
                 aligns everywhere with the standard frame of the
                 texture patch. We show that this optimization is solved
                 efficiently as a sparse linear system.",
  editor =       "Kurt Akeley",
  keywords =     "Texture synthesis, texture mapping, parametrizations",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-89,
  pages =        "471--478",
  year =         "2000",
  title =        "Seamless Texture Mapping of Subdivision Surfaces by
                 Model Pelting and Texture Blending",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-89",
  author =       "Dan Piponi and George D. Borshukov",
  abstract =     "Subdivision surfaces solve numerous problems related
                 to the geometry of character and animation models.
                 However, unlike on parametrised surfaces there is no
                 natural choice of texture coordinates on subdivision
                 surfaces. Existing algorithms for generating texture
                 coordinates on non-parametrised surfaces often find
                 solutions that are locally acceptable but globally are
                 unsuitable for use by artists wishing to paint
                 textures. In addition, for topological reasons there is
                 not necessarily any choice of assignment of texture
                 coordinates to control points that can satisfactorily
                 be interpolated over the entire surface. We introduce a
                 technique, pelting, for finding both optimal and
                 intuitive texture mapping over almost all of an entire
                 subdivision surface and then show how to combine
                 multiple texture mappings together to produce a
                 seamless result.",
  editor =       "Kurt Akeley",
  keywords =     "Curves & Surfaces, Texture Mapping, Physically Based
                 Animation",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-9,
  pages =        "215--221",
  year =         "2000",
  title =        "A Fast Multi-Resolution Search Algorith for Optimal
                 Retrieval in Large Multimedia Databases",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-9",
  author =       "B. C. Song and M. J. Kim and J. B. Ra",
  organization = "SPIE",
  month =        jan,
  editor =       "M. M. Yeung and B.-L. Yeo and C. A. Bouman",
  volume =       "3972",
  keywords =     "image retrieval, multi-resolution feature, sum
                 pyramid, histogram",
  booktitle =    "Proceedings of SPIE: Storage and Retrieval for Media
                 Databases 2000",
}

@InProceedings{EVL-2000-90,
  pages =        "489--498",
  year =         "2000",
  title =        "Video Textures",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-90",
  author =       "Arno Sch{\"{o}}dl and Richard Szeliski and David H.
                 Salesin and Irfan Essa",
  abstract =     "This paper introduces a new type of medium, called a
                 video texture, which has qualities somewhere between
                 those of a photograph and a video. A video texture
                 provides a continuous infinitely varying stream of
                 images. While the individual frames of a video texture
                 may be repeated from time to time, the video sequence
                 as a whole is never repeated exactly. Video textures
                 can be used in place of digital photos to infuse a
                 static image with dynamic qualities and explicit
                 action. We present techniques for analyzing a video
                 clip to extract its structure, and for synthesizing a
                 new, similar looking video of arbitrary length. We
                 combine video textures with view morphing techniques to
                 obtain 3D video textures. We also introduce video-based
                 animation, in which the synthesis of video textures can
                 be guided by a user through high-level interactive
                 controls. Applica-tions of video textures and their
                 extensions include the display of dynamic scenes on web
                 pages, the creation of dynamic backdrops for special
                 effects and games, and the interactive control of
                 video-based animation.",
  editor =       "Kurt Akeley",
  keywords =     "Animation, image-based rendering, morphing,
                 multimedia, natural phenomena, texture synthesis,
                 video-based rendering, video-based animation, video
                 sprites, view morphing",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-91,
  pages =        "499--510",
  year =         "2000",
  title =        "Escherization",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-91",
  author =       "Craig S. Kaplan and David H. Salesin",
  abstract =     "This paper introduces and presents a solution to the
                 'Escherization' problem: given a closed figure in the
                 plane, find a new closed figure that is similar to the
                 original and tiles the plane. Our solution works by
                 using a simulated annealer to optimize over a
                 parameterization of the {"}isohedral{"} tilings, a
                 class of tilings that is flexible enough to encompass
                 nearly all of Escher's own tilings, and yet simple
                 enough to be encoded and explored by a computer. We
                 also describe a representation for isohedral tilings
                 that allows for highly interactive viewing and
                 rendering. We demonstrate the use of these tools -
                 along with several additional techniques for adding
                 decorations to tilings - with a variety of original
                 ornamental designs.",
  editor =       "Kurt Akeley",
  keywords =     "Tilings, tesselations, morphing, optimization,
                 simulated annealing, Escher",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-92,
  pages =        "511--516",
  year =         "2000",
  title =        "Shadows for Cel Animation",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-92",
  author =       "Lena Petrovic and Brian Fujito and Lance Williams and
                 Adam Finkelstein",
  abstract =     "We present a semi-automatic method for creating shadow
                 mattes in cel animation. In conventional cel animation,
                 shadows are drawn by hand, in order to provide visual
                 cues about the spatial relationships and forms of
                 characters in the scene. Our system creates shadow
                 mattes based on hand-drawn characters, given high-level
                 guidance from the user about depths of various objects.
                 The method employs a scheme for {"}inflating{"} a 3D
                 figure based on hand-drawn art. It provides simple
                 tools for adjusting object depths, coupled with an
                 intuitive interface by which the user specifies object
                 shapes and relative positions in a scene. Our system
                 obviates the tedium of drawing shadow mattes by hand,
                 and provides control over complex shadows falling over
                 interesting shapes.",
  editor =       "Kurt Akeley",
  keywords =     "Shadows, cel animation, inflation, sketching, NPR",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-93,
  pages =        "517--526",
  year =         "2000",
  title =        "Illustrating Smooth Surfaces",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-93",
  author =       "Aaron Hertzmann and Denis Zorin",
  abstract =     "We present a new set of algorithms for line-art
                 rendering of smooth surfaces. We introduce an
                 efficient, deterministic algorithm for finding
                 silhouettes based on geometric duality, and an
                 algorithm for segmenting the silhouette curves into
                 smooth parts with constant visibility. These methods
                 can be used to find all silhouettes in real time in
                 software. We present an automatic method for generating
                 hatch marks in order to convey surface shape. We
                 demonstrate these algorithms with a drawing style
                 inspired by A Topological Picturebook by G. Francis.",
  editor =       "Kurt Akeley",
  keywords =     "Non-photorealistic rendering, silhouettes, pen-and-ink
                 illustration, hatching, direction fields",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-94,
  pages =        "527--534",
  year =         "2000",
  title =        "Non-Photorealistic Virtual Environments",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-94",
  author =       "Allison W. Klein and Wilmot W. Li and Michael M.
                 Kazhdan and Wagner T. Correa and Adam Finkelstein and
                 Thomas A. Funkhouser",
  abstract =     "We describe a system for non-photorealistic rendering
                 (NPR) of virtual environments. In real time, it
                 synthesizes imagery of architectural interiors using
                 stroke-based textures. We address the four main
                 challenges of such a system  interactivity, visual
                 detail, controlled stroke size, and frame-to-frame
                 coherence  through image based rendering (IBR)
                 methods. In a preprocessing stage, we capture photos of
                 a real or synthetic environment, map the photos to a
                 coarse model of the environment, and run a series of
                 NPR filters to generate textures. At runtime, the
                 system re-renders the NPR textures over the geometry of
                 the coarse model, and it adds dark lines that emphasize
                 creases and silhouettes. We provide a method for
                 constructing non-photorealistic textures from
                 photographs that largely avoids seams in the resulting
                 imagery. We also offer a new construction, art-maps, to
                 control stroke size across the images. Finally, we show
                 a working system that provides an immersive experience
                 rendered in a variety of NPR styles.",
  editor =       "Kurt Akeley",
  keywords =     "Non-photorealistic rendering, image-based rendering,
                 texture mapping, interactive virtual environments",
  series =       "Annual Conference Series",
  booktitle =    "Siggraph 2000, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH / Addison Wesley Longman",
}

@InProceedings{EVL-2000-95,
  year =         "2000",
  title =        "Generating Animatable 3{D} Virtual Humans from
                 Photographs",
  author =       "W-S. Lee and J. Gu and N. Magnenat-Thalmann",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-95",
  abstract =     "We present an easy, practical and efficient full body
                 cloning methodology. This system utilizes photos taken
                 from the front, side and back of a person in any given
                 imaging environment without requiring a special
                 background or a controlled illuminating condition. A
                 seamless generic body specified in the VRML H-Anim 1.1
                 format is used to generate an individualized virtual
                 human. The system is composed of two major components:
                 face-cloning and body-cloning. The face-cloning
                 component uses feature points on front and side images
                 and then applies DFFD for shape modification. Next a
                 fully automatic seamless texture mapping is generated
                 for 360o coloring on a 3D polygonal model. The
                 body-cloning component has two steps: (i) feature
                 points specification, which enables automatic
                 silhouette detection in an arbitrary background (ii)
                 two-stage body modification by using feature points and
                 body silhouette respectively. The final integrated
                 human model has photo-realistic animatable face, hands,
                 feet and body. The result can be visualized in any VRML
                 compliant browser.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-96,
  year =         "2000",
  title =        "Using an Intermediate Skeleton and Inverse Kinematics
                 for Motion Retargeting",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-96",
  author =       "J.-S. Monzani and P. Baerlocher and R. Boulic and D.
                 Thalmann",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Compuuter Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-97,
  year =         "2000",
  title =        "Modeling the Motion of Dense Smoke in the Wind Field",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-97",
  author =       "M. J. Rudolf and J. Raczkowski",
  abstract =     "This paper presents a volumetric animation technique
                 for modeling the turbulent motion of very dense and
                 turbulent smoke such as one coming from a steam engine.
                 A new method of the wind field generation is proposed.
                 Gas motion is determined by the integration of two
                 independent vector layers. The first one is a
                 combination of flow primitives and the second is
                 created by stochastically generated turbulence. Special
                 attention is taken of the proper construction of the
                 turbulent layer. For the visualization purposes a
                 simple volume raytracer is applied. Many light sources
                 are taken into account to achieve photorealistic
                 effects. Finally some interesting animations are
                 overviewed. Computation times for a PC Pentium 200 and
                 an SGI O2 workstation are compared to demonstrate the
                 high efficiency of the method.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}

@InProceedings{EVL-2000-98,
  year =         "2000",
  title =        "Unsteady Flow Visualization by Animating Evenly-Spaced
                 Streamlines",
  author =       "B. Jobard and W. Lefer",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-98",
  abstract =     "In recent years the work on vector field visualization
                 has been concentrated on LIC-based methods. In this
                 paper we propose an alternative solution for the
                 visualization of unsteady flow fields. Our approach is
                 based on the computation of temporal series of
                 correlated images. While other methods are based on
                 pathlines and try to correlate successive images at the
                 pixel level, our approach consists in correlating
                 instantaneous visualizations of the vector field at the
                 streamline level. For each frame a feed forward
                 algorithm computes a set of evenly-spaced streamlines
                 as a function of the streamlines generated for the
                 previous frame. This is achieved by establishing a
                 correspondence between streamlines at successive time
                 steps. A cyclical texture is mapped onto every
                 streamline and textures of corresponding streamlines at
                 different time steps are correlated together so that,
                 during the animation, they move along the streamlines,
                 giving the illusion that the flow is moving in the
                 direction defined by the streamline. Our method gives
                 full control on the image density so that we are able
                 to produce smooth animations of arbitrary density,
                 covering the field of representations from sparse, that
                 is classical streamline-based images, to dense, that is
                 texture-like images.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Proceedings (Eurographics 2000)",
}

@InProceedings{EVL-2000-99,
  year =         "2000",
  title =        "Floating Points: {A} method for Computing Stipple
                 Drawings",
  author =       "O. Deussen and S. Hiller and C. van Overveld and T.
                 Strothotte",
  URL =          "http://visinfo.zib.de/EVlib/Show?EVL-2000-99",
  abstract =     "We present a method for computer generated pen-and-ink
                 illustrations by the simulation of stippling. In a
                 stipple drawing, dots are used to represent tone and
                 also material of surfaces. We create such drawings by
                 generating an initial dot set which is then processed
                 by a relaxation method based on Voronoi diagrams. The
                 point patterns generated are approximations of Poisson
                 disc distributions and can also be used for integrating
                 functions or the positioning of objects. We provide an
                 editor similar to paint systems for interactively
                 creating stipple drawings. This makes it possible to
                 create such drawings within a matter of hours, instead
                 of days or even weeks when the drawing is done
                 manually.",
  editor =       "M. Gross and F. R. A. Hopgood",
  volume =       "19(3)",
  booktitle =    "Computer Graphics Forum (Eurographics 2000)",
}
