<html><head>     
<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1">
<meta http-equiv="cache-control" content="no-cache">
<meta http-equiv="pragma" content="no-cache">
<META HTTP-EQUIV="EXPIRES" CONTENT="Mon, 22 Jul 2002 11:12:01 GMT">

<SCRIPT SRC="/wavemaster.internal/v2.6/tools-eg_bs/cookie.js"></SCRIPT>
 <STYLE TYPE="text/css"><!--
 .hw-annotation { text-decoration: none; color: black; background:#f3ca81; font-weight: bold; }
--></STYLE>
<META NAME="Author" VALUE="hwsystem">
<META NAME="DocumentType" VALUE="text">
<META NAME="GOid" VALUE="0x811bda11_0x000008dc">
<META NAME="HW_Checksum" VALUE="c1ba55c30f9b00eeb9d13d06ea938262">
<META NAME="HW_ChildAccess" VALUE="NO_ACCESS">
<META NAME="HW_EffectiveAccess" VALUE="READ_ACCESS">
<META NAME="HW_ObjectName" VALUE="cgf21.bib">
<META NAME="MimeType" VALUE="text/plain">
<META NAME="Name" VALUE="EG/DL/BibDB/cgf21.bib">
<META NAME="ObjectID" VALUE="0x0000000b">
<META NAME="PLACETemplate" VALUE="egnew/master">
<META NAME="Path" VALUE="DC0x00000755 0x00017e4c">
<META NAME="Rights" VALUE="R:a, g eg-pub eg-root everyone; W:a, g eg-pub eg-root; A:a">
<META NAME="TimeCreated" VALUE="2007/10/15 08:23:14">
<META NAME="TimeModified" VALUE="2008/01/16 09:54:48">
<META NAME="Title" VALUE="en:cgf21.bib">
<META NAME="Type" VALUE="Document">
<TITLE>cgf21.bib</TITLE>
<BASE HREF="http://diglib.eg.org/EG/DL/BibDB/cgf21.bib">

<style type="text/css">



body,td,p {
	color:#333333;
	font-size:15px;
	font-family: Trebuchet MS, Trebuchet,  Helvetica, Arial, sans-serif;
}

a { text-decoration:none; }

a:link { color:#0099ff; }

a:visited { color:#336699; }

a:active { color:#ff9900; }

a:hover {  color:#ff9900;  }


a.small:link { color:#0099ff;font-size:12px; }

a.small:visited { color:#336699;font-size:12px; }

a.small:active { color:#ff9900;font-size:12px; }

a.small:hover {  color:#ff9900;font-size:12px;  }

.small {
	font-family: Helvetica, Arial, sans-serif;
	font-size:12px;					
	color:#333333;
       }   
h1 {
	font-size: 21px;
	color:#ff9900;
	font-weight: bold;
}
h2 {
	font-size: 18px;
	color:#ff9900;
	font-weight: bold;
	margin-bottom: 0px;
}
h3 {
	margin-bottom: 0px;
	color:#ff9900;
	font-weight: bold;
}
strong {
	color:#666666;
}
.menu{
	background-color:#ffffff;
	font-size:13px;
	font-weight: bold;
	font-family: Trebuchet MS, Trebuchet,  Helvetica, Arial, sans-serif;
	text-align:center;
	line-height: 18px;
        }
.menuselected{
	background-color:#ff9900;
	font-size:13px;
	font-weight: bold;
	color:#000000;
	font-family: Trebuchet MS, Trebuchet, Helvetica, Arial, sans-serif;
	text-align:center;
	line-height: 18px;
        }

.menu a {color:#000000;
		}
.menu a:hover {  color:#ff9900;  
		}
.menu2{
	background-color:#ffffff;
	padding-left:13px; 
	font-size:12px;
	color:#ff9900;
	line-height: 24px;
	font-family: "Trebuchet MS", "Trebuchet", Arial, Helvetica, sans-serif;
        }
.menu2 a {color:#0099ff;
		}
.menu2 a:hover {  color:#ff9900;  
		}
.menu3{
	background-color:#ffffff;
	text-align:center; 
	font-size:13px;
	color:#ff9900;
	line-height: 24px;
	font-family: "Trebuchet MS", "Trebuchet", Arial, Helvetica, sans-serif;
        }
.box1{
	background-color:#ff9900;
	font-size:13px;
	font-weight: bold;
	font-family: Trebuchet MS, Trebuchet,  Helvetica, Arial, sans-serif;
	line-height: 19px;
	color:#ffffff;
	text-align:right;
        }
.box2{
	background-color:#66ccff;
	font-size:13px;
	font-weight: bold;
	font-family: Trebuchet MS, Trebuchet,  Helvetica, Arial, sans-serif;
	line-height: 19px;
	color:#ffffff;
	text-align:right;
        }
.boxtopic{
	text-align:right;
	padding-right:16px; 
        }
.boxcontent {
	font-family: Helvetica, Arial, sans-serif;
	font-size:12px;	
	color:#333333;
	text-align:left;
	padding:16px;
       }
.hr1{
	color:#ff9900;
        }
.hr2{
	color:#66ccff;
        }
.frame1{
	background-color:#ff9900;
        }
.frame2{
	background-color:#66ccff;
        }
.content {border:0; 
	padding-left:12px;
	padding-right:12px;
	}
	

.box3{
   background-color:#66ccff;
   font-size:13px;
   font-weight: bold;
   font-family: Trebuchet MS, Trebuchet,  Helvetica, Arial, sans-serif;
   line-height: 19px;
   color:#ffffff;
   text-align:center;
}

.box4{
   background-color:#66ccff;
   font-size:13px;
   font-weight: bold;
   font-family: Trebuchet MS, Trebuchet,  Helvetica, Arial, sans-serif;
   line-height: 19px;
   color:#ffffff;
   text-align:left;
}

.boxcontent2 {
	font-family: Helvetica, Arial, sans-serif;
	font-size:12px;	
	color:#333333;
	text-align:center;
	padding:10px;
}

.boxcontent3 {
   font-family: Helvetica, Arial, sans-serif;
   font-size:12px;
   color:#333333;
   text-align:right;
   padding:10px;
}

.boxcontent4 {
   font-family: Helvetica, Arial, sans-serif;
   font-size:12px;	
   color:#333333;
   text-align:left;
   padding:10px;
}

	
</style>

</HEAD>
<BODY   alink="#ff9900" bgcolor="#FFFFFF" link="#0099ff" text="#000000" vlink="#336699">






<table width="761" border="0" align="left" cellpadding="0" cellspacing="0">
  <!--DWLayoutTable-->
  <tr> 
    <!--The Logo will be shown next: -->


    <td>

    	<table width="144" border="0" cellspacing="0" cellpadding="1" class=frame1>

    		<tr>

    		<td width="142" align="center"><a href="http://www.eg.org/"><img src="http://diglib.eg.org/v2.6/graphics/new/logo.gif;internal&inline=true" alt="EG - Logo" width="142" height="110" border="0"></a></td>

    		</tr>

    	</table>

    </td>

    <td width="17"><img src="http://diglib.eg.org/v2.6/graphics/new/spacer.gif;internal&inline=true" width="17" height="1"></td>

    <td>

    	<table width="600" border="0" cellspacing="0" cellpadding="1" class=frame1>

    		<tr>

    		<td width="598"><img src="http://diglib.eg.org/v2.6/graphics/new/head.gif;internal&inline=true" alt="EuroGraphics" width="598" height="110"></td>

    		</tr>

    	</table>

    </td>

    

    

    

  </tr>
  <tr> 
    <td colspan="3" width="761" height="17"><img src="news-Dateien/spacer.gif" width="1" height="17"></td>
  </tr>
  <tr> 
    <td width="144" valign="top"> 
           
      <!--The Member Login Box will be shown next: -->
      <table width="100%" border="0" cellspacing="0" cellpadding="1" class=frame1>

<TBODY>
<TR>
   <TD>
            <TABLE border=0 cellPadding=0 cellSpacing=0 width="100%">
              <TBODY>
              <TR>
                <TD align=right bgColor=#cccccc class=box1><SPAN 
                  class=boxtopic>Members</SPAN></TD></TR>
              <TR>
                <TD bgColor=#ffffff>
                  <DIV class=boxcontent>
                  Please 

                  <A  HREF="http://www.eg.org/login">login</A> 
                  
                  
                  
                  <!--(note for <a href="/safari.html">Safari users</a>)-->
                  if you are a member or <a  href="/about/membership">read more</a> about the advantages of an EG membership.
                  <HR class=hr1 noShade SIZE=1>
                  <br>
                  
                  Not yet member? <A HREF="/join">Application</A><br>
                  <A HREF="https://www.eg.org/renew">Renewal</A>
                  <HR class=hr1 noShade SIZE=1>
                  Forgot your password? <A HREF="http://diglib.eg.org/EG/DL/BibDB/cgf21.bib;internal&action=forgot.password.action">Click  here!</A> 
                 </DIV></TD>  
                 </TR></TBODY></TABLE></TD></TR></TBODY>
      </table>
      <br> 
      <!--The New Box will be shown next: -->
      <table width="100%" border="0" cellspacing="0" cellpadding="1" class="frame2">
<tr>
	<td>
		<table border="0" cellpadding="0" cellspacing="0" width="100%">
        	<tbody><tr>
           		<td class="box2" align="right" bgcolor="#cccccc"><span class="boxtopic">EG 2009</span></td>
			</tr>
			<tr>
           		<td bgcolor="#ffffff">
				<div class="boxcontent">
				
                <a href="http://www.eurographics2009.de/">Eurographics 2009:</a> 30th of March to the 3rd of April 2009 in Munich (Germany).
				<hr noshade class="hr2" size="1" >
				<!--<a href="http://www.ics.forth.gr/eg2008/" target="_blank"><img src="/EG/images/eg2k8.png" border="0" height="23" width="103"></a>
			         EG08 will be from 14th to the 18th April 2008
                              <hr class="hr2" noshade="noshade" size="1">-->

                          <!--
                        Eurographics 2007: 3rd to the 7th September 2007 in Prague (Czech Republic).
				<hr noshade class="hr2" size="1" >
				Previous Event: <a href="http://www.cgg.cvut.cz/eg07/">Eurographics 2007</a>
				-->
                       <!-- Eurographics 2006: 4th - 8th of September 2006 in Vienna (Austria)<br>
                        <hr noshade class="hr2" size="1" >-->
			<!--    Previous Event: <a href="http://www.cg.tuwien.ac.at/events/EG06/index.html">Eurographics 2006</a>>-->
                                Previous Event: <a href="http://www.ics.forth.gr/eg2008/">Eurographics 2008</a>
				</div>
				</td>
			</tr>
		</tbody></table>
	</td>
</tr>
      </table>
      <br>

      
    </td>
    <td>&nbsp;</td>

	<td valign="top">

                <PRE>

@article{Denecker:2002:PEL,
author = {Denecker,K. and De Neve,P. and Van Assche,S.  and Van de Walle1,R.  and Lemahieu,I. and Philips,W.},
title = {Psychovisual Evaluation of Lossy {CMYK} Image Compression for Printing Applications},
journal = {Computer Graphics Forum},
volume = {21},
number = {1},
pages = {5-5},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue1/*.pdf},
abstract = { In the digital prepress workflow, images are represented in the {CMYK} colour space. Lossy image compression alleviates the need for high storage and bandwidth capacities, resulting from the high spatial and tonal resolution. After the image has been printed on paper, the introduced visual quality loss should not be noticeable to a human observer. Since visual image quality depends on the compression algorithm both quantitatively and qualitatively, and since no visual image quality models incorporating the end-to-end image reproduction process are satisfactory, an experimental comparison is the only viable way to quantify subjective image quality. This paper presents the results from an intensive psychovisual study based on a two-alternative forced-choice approach involving 164 people, with expert and non-expert observers distinguished. The primary goal is to evaluate two previously published adaptations of {JPEG} to {CMYK} images, and to determine a visually lossless compression ratio threshold for typical printing applications. The improvements are based on tonal decorrelation and overlapping block transforms. Results on three typical prepress test images indicate that the proposed adaptations are useful and that for the investigated printing configuration, compression ratios up to 20 can be used safely.  }}}
@article{Theisel:2002:EIM,
author = {Theisel,Holger},
title = {Exact Isosurfaces for Marching Cubes},
journal = {Computer Graphics Forum},
volume = {21},
number = {1},
pages = {19-19},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue1/560.pdf},
abstract = { In this paper we study the exact contours of a piecewise trilinear scalar field. We show how to represent these contours exactly as trimmed surfaces of triangular rational cubic Bezier patches. As part of this, we introduce an extension of the marching cubes algorithm which gives a topologically exact triangular approximation of the contours for any case. Finally, we modify the exact contours to be globally  G1 continuous without changing their topologies. We test the algorithm on both theoretical and practical data sets.  }}}
@article{Zhang:2002:ACC,
author = {Zhang,Dongliang and Yuen,Matthew},
title = {A Coherence-based Collision Detection Method for Dressed Human Simulation},
journal = {Computer Graphics Forum},
volume = {21},
number = {1},
pages = {33-33},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue1/561.pdf},
abstract = { In this paper, paper we present a coherence-based method to detect collisions between the garment and human model for dressed human simulations. Based on the property of coherence, collisions can be rapidly detected by tracking the movement of the most likely geometric elements to collide. The voxel technique is employed to quickly identify the potential collision region. Experimental results show that our method is very efficient.  }}}
@article{Duce:2002:W2D,
author = {Duce,David and Herman,Ivan and Hopgood,Bob},
title = {Web {2D} Graphics File Formats},
journal = {Computer Graphics Forum},
volume = {21},
number = {1},
pages = {43-43},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue1/562.pdf},
abstract = { The earliest Web browsers focussed on the display of textual information. When graphics were added, essentially only image graphics and image file formats were supported. For a significant range of applications, image graphics has severe limitations, for example in terms of file size, download time and inability to interact with and modify the graphics client-side. Vector graphics may be more appropriate in these cases, and this has become possible through the introduction of the WebCGM and Scalable Vector Graphics (SVG) formats, both of which are open standards, the former from {ISO}/IEC and {W3C} and the latter from {W3C}. This paper reviews the background to Web graphics, presents the WebCGM file format, and gives a more detailed exposition of the most recent format, {SVG}. The paper concludes with reflections on the current state of this area and future prospects.  }}}
@article{Adabala:2002:TFR,
author = {Adabala,Neeharika and Manohar,Swami},
title = {Techniques for Realistic Visualization of Fluids: A Survey},
journal = {Computer Graphics Forum},
volume = {21},
number = {1},
pages = {65-65},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue1/563.pdf},
abstract = { Visualization of fluids has wide applications in science, engineering and entertainment. Various methodologies of visualizing fluids have evolved which emphasize on capturing different aspects of the fluids accurately. In this survey the existing methods for realistic visualization of fluids are reviewed. The approaches are classified based on the key concept they rely on for fluid modeling. This classification allows for easy selection of the method to be adopted for visualization given an application. It also enables identification of alternative techniques for fluid modeling.  }}
@article{Surazhsky:2002:ASR,
author = {Surazhsky,Tatiana and Elber,Gershon},
title = {Artistic Surface Rendering Using Layout of Text},
journal = {Computer Graphics Forum},
volume = {21},
number = {2},
pages = {99-99},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue2/568.pdf},
abstract = { An artistic rendering method of free-form surfaces with the aid of half-toned text that is laid-out on the given surface is presented. The layout of the text is computed using symbolic composition of the free-form parametric surface  S(u, v)  with cubic or linear Bezier curve segments  C(t) = {cu (t), cv (t)} , comprising the outline of the text symbols. Once the layout is constructed on the surface, a shading process is applied to the text, affecting the width of the symbols as well as their color, according to some shader function. The shader function depends on the surface orientation and the view direction as well as the color and the direction or position of the light source.  }}
@article{Fei:2002:AAS,
author = {Fei,Guangzheng and Cai,Kangying and Guo,Baining and Wu,Enhua},
title = {An Adaptive Sampling Scheme for Out-of-Core Simplification},
journal = {Computer Graphics Forum},
volume = {21},
number = {2},
pages = {111-111},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue2/569.pdf},
abstract = { Current out-of-core simplification algorithms can efficiently simplify large models that are too complex to be loaded in to the main memory at one time. However, these algorithms do not preserve surface details well since adaptive sampling, a typical strategy for detail preservation, remains to be an open issue for out-of-core simplification. In this paper, we present an adaptive sampling scheme, called the balanced retriangulation (BR), for out-of-core simplification. A key idea behind {BR} is that we can use Garland's quadric error matrix to analyze the global distribution of surface details. Based on this analysis, a local retriangulation achieves adaptive sampling by restoring detailed areas with cell split operations while further simplifying smooth areas with edge collapse operations. For a given triangle budget, {BR} preserves surface details significantly better than uniform sampling algorithms such as uniform clustering. Like uniform clustering, our algorithm has linear running time and small memory requirement.  }}
@article{Samavati:2002:MSH,
author = {Samavati,Faramarz and Mahdavi-Amiri,Nezam and Bartels,Richard},
title = {Multiresolution Surfaces having Arbitrary Topologies by a Reverse Doo Subdivision Method},
journal = {Computer Graphics Forum},
volume = {21},
number = {2},
pages = {121-121},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue2/570.pdf},
abstract = { We have shown how to construct multiresolution structures for reversing subdivision rules using global least squares models (Samavati and Bartels, Computer Graphics Forum, 18(2):97-119, June 1999). As a result, semiorthogonal wavelet systems have also been generated. To construct a multiresolution surface of an arbitrary topology, however, biorthogonal wavelets are needed. In Bartels and Samavati (Journal of Computational and Applied Mathematics, 119:29-67, 2000) we introduced local least squares models for reversing subdivision rules to construct multiresolution curves and tensor product surfaces, noticing that the resulting wavelets were biorthogonal (under an induced inner product). Here, we construct multiresolution surfaces of arbitrary topologies by locally reversing the Doo subdivision scheme. In a Doo subdivision, a coarse surface is converted into a fine one by the contraction of coarse faces and the addition of new adjoining faces. We propose a novel reversing process to convert a fine surface into a coarse one plus an error. The conversion has the property that the subdivision of the resulting coarse surface is locally closest to the original fine surface, in the least squares sense, for two important face geometries. In this process, we first find those faces of the fine surface which might have been produced by the contraction of a coarse face in a Doo subdivision scheme. Then, we expand these faces. Since the expanded faces are not necessarily joined properly, several candidates are usually at hand for a single vertex of the coarse surface. To identify the set of candidates corresponding to a vertex, we construct a graph in such a way that any set of candidates corresponds to a connected component. The connected components can easily be identified by a depth first search traversal of the graph. Finally, vertices of the coarse surface are set to be the average of their corresponding candidates, and this is shown to be equivalent to local least squares approximation for regular arrangements of triangular and quadrilateral faces.  }}
@article{Bogomjakov:2002:URS,
author = {Bogomjakov,A. and Gotsman,C.},
title = {Universal Rendering Sequences for Transparent Vertex Caching of Progressive Meshes},
journal = {Computer Graphics Forum},
volume = {21},
number = {2},
pages = {137-137},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue2/571.pdf},
abstract = { We present methods to generate rendering sequences for triangle meshes which preserve mesh locality as much as possible. This is useful for maximizing vertex reuse when rendering the mesh using a {FIFO} vertex buffer, such as those available in modern {3D} graphics hardware. The sequences are universal in the sense that they perform well for all sizes of vertex buffers, and generalize to progressive meshes. This has been verified experimentally.  }}
@article{Bernardini:2002:T3D,
author = {Bernardini,Fausto and Rushmeier,Holly},
title = {The {3D} Model Acquisition Pipeline},
journal = {Computer Graphics Forum},
volume = {21},
number = {2},
pages = {149-149},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue2/572.pdf},
abstract = { Three-dimensional (3D) image acquisition systems are rapidly becoming more affordable, especially systems based on commodity electronic cameras. At the same time, personal computers with graphics hardware capable of displaying complex {3D} models are also becoming inexpensive enough to be available to a large population. As a result, there is potentially an opportunity to consider new virtual reality applications as diverse as cultural heritage and retail sales that will allow people to view realistic {3D} objects on home computers.   Although there are many physical techniques for acquiring {3D} data-including laser scanners, structured light and time-of-flight-there is a basic pipeline of operations for taking the acquired data and producing a usable numerical model. We look at the fundamental problems of range image registration, line-of-sight errors, mesh integration, surface detail and color, and texture mapping. In the area of registration we consider both the problems of finding an initial global alignment using manual and automatic means, and refining this alignment with variations of the Iterative Closest Point methods. To account for scanner line-of-sight errors we compare several averaging approaches. In the area of mesh integration, that is finding a single mesh joining the data from all scans, we compare various methods for computing interpolating and approximating surfaces. We then look at various ways in which surface properties such as color (more properly, spectral reflectance) can be extracted from acquired imagery. Finally, we examine techniques for producing a final model representation that can be efficiently rendered using graphics hardware.  }}
@article{Alexa:2002:RAI,
author = {Alexa,Marc},
title = {Recent Advances in Mesh Morphing},
journal = {Computer Graphics Forum},
volume = {21},
number = {2},
pages = {173-173},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue2/573.pdf},
abstract = { Meshes have become a widespread and popular representation of models in computer graphics. Morphing techniques aim at transforming a given source shape into a target shape. Morphing techniques have various applications ranging from special effects in television and movies to medical imaging and scientific visualization. Not surprisingly, morphing techniques for meshes have received a lot of interest lately.   This work sums up recent developments in the area of mesh morphing. It presents a consistent framework to classify and compare various techniques approaching the same underlying problems from different angles.  }}
@article{Howard:2002:BR,
author = {Howard,Toby},
title = {Book Reviews},
journal = {Computer Graphics Forum},
volume = {21},
number = {2},
pages = {197-197},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue2/576.pdf}}

@article{Allison:2002:ERMM,
key = {Eurographics Workshop on Multimedia 2002},
title = {6th Eurographics Workshop on Multimedia. Manchester, {UK}, 8-9 September, 2001},
journal = {Computer Graphics Forum},
volume = {21},
number = {2},
pages = {203-203},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue2/577.pdf}}

@article{Allison:2002:ERPGV,
key = {Eurographics Workshop on Parallel Graphics and Visualization 2002},
title = {3rd Eurographics Workshop on Parallel Graphics and Visualization. Girona, Spain, 28-29 September, 2000},
journal = {Computer Graphics Forum},
volume = {21},
number = {2},
pages = {204-204},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue2/577.pdf}}

@article{Allison:2002:RW,
key = {Eurographics Workshop on Rendering 2002},
title = {12th Eurographics Workshop on Rendering. London, {UK}, 25-27 June, 2001},
journal = {Computer Graphics Forum},
volume = {21},
number = {2},
pages = {205-205},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue2/577.pdf}}

@article{Terzopoulos:2002:AAA,
author = {Terzopoulos,Demetri},
title = {Artificial Animals and Humans: From Physics to Intelligence},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {xvii-xvii},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/*.pdf},
abstract = { Abstract  The confluence of virtual reality and artificial life, an emerging discipline that spans the computational and biological sciences, has yielded synthetic worlds inhabited by realistic, artificial flora and fauna. Artificial animals are complex synthetic organisms that possess functional biomechanical bodies, sensors, and brains with locomotion, perception, behavior, learning, and cognition centers. Artificial humans and other animals are of interest in computer graphics because they are self-animating characters that dramatically advance the state of the art of production animation and interactive game technologies. More broadly, these biomimetic autonomous agents in their realistic virtual worlds also foster deeper, computationally oriented insights into natural living systems. }}
@article{Ertl:2002:IVW,
author = {Ertl,Thomas},
title = {Interactive Visualization with Programmable Graphics Hardware},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {xviii-xviii},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/*.pdf},
abstract = { Abstract  One of the main scientific goals of visualization is the development of algorithms and appropriate data models which facilitate interactive visual analysis and direct manipulation of the increasingly large data sets which result from simulations running on massive parallel computer systems, from measurements employing fast high-resolution sensors, or from large databases and hierarchical information spaces.  This task can only be achieved with the optimization of all stages of the visualization pipeline: filtering, compression, and feature extraction of the raw data sets, adaptive visualization mappings which allow the users to choose between speed and accuracy, and exploiting new graphics hardware features for fast and high-quality rendering. The recent introduction of advanced programmability in widely available graphics hardware has already led to impressive progress in the area of volume visualization. However, besides the acceleration of the final rendering, flexible graphics hardware is increasingly being used also for the mapping and filtering stages of the visualization pipeline, thus giving rise to new levels of interactivity in visualization applications. The talk will present recent results of applying programmable graphics hardware in various visualization algorithms covering volume data, flow data, terrains, {NPR} rendering, and distributed and remote applications. }}
@article{Scopigno:2002:3DS,
author = {Scopigno,Roberto},
title = {{3D} Scanning Technology: Capabilities and Issues},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {xix-xix},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/*.pdf},
abstract = { Abstract  The recent evolution of graphics technology makes it possible to manage very complex models on inexpensive platforms. These impressive rendering capabilities should be paired with detailed and accurate digital models. The construction of high quality {3D} models is made easier by the increasing diffusion of automatic {3D} measuring devices (often called {3D} scanners). These allow to build highly accurate models of real {3D} objects in a cost- and time-effective manner. The talk will present the capabilities of this technology focusing mainly on a particular application context: the acquisition of Cultural Heritage artifacts. The peculiar requirements of this domain (high accuracy in the acquisition of both shape and surface appearance, expected low cost and easiness of use of the tools) make it a perfect application example. This talk aims also at presenting and discussing the main issues in the acquisition of accurate {3D} models, together with some limitations of current hardware and software tools. Some examples of the results of current projects will be shown. }}
@article{Desbrun:2002:IPO,
author = {Desbrun,Mathieu and Meyer,Mark and Alliez,Pierre},
title = {Intrinsic Parameterizations of Surface Meshes},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {209-209},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/CGF580.pdf},
abstract = { Abstract  Parameterization of discrete surfaces is a fundamental and widely-used operation in graphics, required, for instance, for texture mapping or remeshing. As {3D} data becomes more and more detailed, there is an increased need for fast and robust techniques to automatically compute least-distorted parameterizations of large meshes. In this paper, we present new theoretical and practical results on the parameterization of triangulated surface patches. Given a few desirable properties such as rotation and translation invariance, we show that the only admissible parameterizations form a two-dimensional set and each parameterization in this set can be computed using a simple, sparse, linear system. Since these parameterizations minimize the distortion of different intrinsic measures of the original mesh, we call them Intrinsic Parameterizations. In addition to this partial theoretical analysis, we propose robust, efficient and tunable tools to obtain least-distorted parameterizations automatically. In particular, we give details on a novel, fast technique to provide an optimal mapping without fixing the boundary positions, thus providing a unique Natural Intrinsic Parameterization. Other techniques based on this parameterization family, designed to ease the rapid design of parameterizations, are also proposed. }}
@article{Shlafman:2002:MOP,
author = {Shlafman,Shymon and Tal,Ayellet and Katz,Sagi},
title = {Metamorphosis of Polyhedral Surfaces using Decomposition},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {219-219},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/paper105},
abstract = { Abstract  This paper describes an algorithm for morphing polyhedral surfaces based on their decompositions into patches. The given surfaces need neither be genus-zero nor two-manifolds. We present a new algorithm for decomposing surfaces into patches. We also present a new projection scheme that handles topologically cylinder-like polyhedral surfaces. We show how these two new techniques can be used within a general framework and result with morph sequences that maintain the distinctive features of the input models.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.5 [Computational Geometry and Object Modeling]: Boundary representations I.3.7 [Three-Dimensional Graphics and Realism]: Animation }}
@article{Lee:2002:GSF,
author = {Lee,Y. and Lee,S.},
title = {Geometric Snakes for Triangular Meshes},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {229-229},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/CGF582.pdf},
abstract = { Abstract  Feature detection is important in various mesh processing techniques, such as mesh editing, mesh morphing, mesh compression, and mesh signal processing. In spite of much research in computer vision, automatic feature detection even for images still remains a difficult problem. To avoid this difficulty, semi-automatic or interactive techniques for image feature detection have been investigated. In this paper, we propose a geometric snake as an interactive tool for feature detection on a {3D} triangular mesh. A geometric snake is an extension of an image snake, which is an active contour model that slithers from its initial position specified by the user to a nearby feature while minimizing an energy functional. To constrain the movement of a geometric snake onto the surface of a mesh, we use the parameterization of the surrounding region of a geometric snake. Although the definition of a feature may vary among applications, we use the normal changes of faces to detect features on a mesh. Experimental results demonstrate that geometric snakes can successfully capture nearby features from user-specified initial positions. }}
@article{Martin:2002:F3D,
author = {Martin,D. and Fekete,J.D. and Torres,J. C.},
title = {Flattening {3D} objects using silhouettes},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {239-239},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/paper12},
abstract = { Abstract  An important research area in non-photorealistic rendering is the obtention of silhouettes. There are many methods to do this using {3D} models and raster structures, but these are limited in their ability to create stylised silhouettes while maintaining complete flexibility. These limitations do not exist in illustration, as each element is plane and the interaction between them can be eliminated by locating each one in a different layer. This is the approach presented in this paper: a {3D} model is flattened into plane elements ordered in space, which allows the silhouettes to be drawn with total flexibility.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.3 [Computer Graphics]: Line and Curve Generation }}
@article{Isenberg:2002:SSA,
author = {Isenberg,Tobias and Halper,Nick and Strothotte,Thomas},
title = {Stylizing Silhouettes at Interactive Rates: From Silhouette Edges to Silhouette Strokes},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {249-249},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/paper196},
abstract = { Abstract  A way to create effective stylized line drawings is to draw strokes that start and stop at visible portions along the silhouette of an object to be portrayed. In computer graphics to date, algorithms to extract silhouette edges are many, although putting these edges into a form such that stylized strokes may be applied to them has not been greatly covered, so that existing methods are either time-consuming or presented vaguely. In this paper, we introduce an algorithm that takes a set of silhouette edges originating from polygonal meshes and efficiently computes the visible parts of the edges before connecting them to form long smooth silhouette strokes to which stylization algorithms may be effectively applied. Features of our algorithm that gain efficiency and accuracy over existing methods is that we directly exploit the analytic connectivity information of the mesh in combination with the availablez-bufferinformation during rendering, and filter artifacts in connected edges during the process to improve the visual quality of strokes after stylization.  Categories and Subject Descriptors (according to {ACM} CCS):  1.3.3 [Computer Graphics]: Picture/Image Generation-Line and curve generation  1.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism-Hidden line/surface removal }}
@article{Takahashi:2002:MSP,
author = {Takahashi,Shigeo and Ohta,Naoya and Nakamura,Hiroko and Takeshima,Yuriko and Fujishiro,Issei},
title = {Modeling Surperspective Projection of Landscapes for Geographical Guide-Map Generation},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {259-259},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/paper111},
abstract = { It is still challenging to generate hand-drawn pictures because they differ from ordinary photographs in that they are often drawn as seen from multiple viewpoints. This paper presents a new approach for modeling such surperspective projection based on shape deformation techniques. Specifically, surperspective landscape images for guide-maps are generated from {3D} geographical elevation data. Our method first partitions a target geographical surface into feature areas to provide designers with landmarks suitable for editing. The system takes as input {2D} visual effects, which are converted to {3D} geometric constraints for geographical surface deformation. Using ordinary perspective projection, the deformed shape is then transformed into a target guide-map image where each landmark enjoys its own vista points. An algorithm for calculating such {2D} visual effects semi-automatically from the geographical shape features is also considered. }}
@article{Ar:2002:DSO,
author = {Ar,Sigal and Montag,Gil and Tal,Ayellet},
title = {Deferred, Self-Organizing {BSP} Trees},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {269-269},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/CGF586.pdf},
abstract = { Abstract  bsptrees and {KD} trees are fundamental data structures for collision detection in walkthrough environments. A basic issue in the construction of these hierarchical data structures is the choice of cutting planes. Rather than base these choices solely on the properties of the scene, we propose using information about how the tree is used in order to determine its structure. We demonstrate how this leads to the creation ofbsptrees that are small, do not require much preprocessing time, and respond very efficiently to sequences of collision queries.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.5 [Computer Graphics]: Computational Geometry and Object Modeling I.3.6 [Computer Graphics]: Graphics data structures and data types, Interaction techniques I.3.7 [Computer Graphics]: Virtual reality }}
@article{Redon:2002:FCC,
author = {Redon,Stephane and Kheddar,Abderrahmane and Coquillart,Sabine},
title = {Fast Continuous Collision Detection between Rigid Bodies},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {279-279},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/paper304},
abstract = { Abstract  This paper introduces a fast continuous collision detection technique for polyhedral rigid bodies. As opposed to most collision detection techniques, the computation of the first contact time between two objects is inherently part of the algorithm. The method can thus robustly prevent objects interpenetrations or collisions misses, even when objects are thin or have large velocities. The method is valid for general objects (polygon soups), handles multiple moving objects and acyclic articulated bodies, and is efficient in low and high coherency situations. Moreover, the method can be used to speed up existent continuous collision detection methods for parametric or implicit rigid surfaces. The collision detection algorithms have been successfully coupled to a real-time dynamics simulator. Various experiments are conducted that show the method's ability to produce high-quality interaction (precise objects positioning for example) between models up to tens of thousands of triangles, which couldn't have been performed with previous continuous methods.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.7 [Computer Graphics]: Animation - Virtual Reality }}
@article{Marchand:2002:VVS,
author = {Marchand,Eric and Chaumette,Francois},
title = {Virtual Visual Servoing: a framework for real-time augmented reality},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {289-289},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/paper199},
abstract = { Abstract  This paper presents a framework to achieve real-time augmented reality applications. We propose a framework based on the visual servoing approach well known in robotics. We consider pose or viewpoint computation as a similar problem to visual servoing. It allows one to take advantage of all the research that has been carried out in this domain in the past. The proposed method features simplicity, accuracy, efficiency, and scalability wrt. to the camera model as well as wrt. the features extracted from the image. We illustrate the efficiency of our approach on augmented reality applications with various real image sequences. }}
@article{Xu:2002:ASM,
author = {Xu,Songhua and Tang,Min and Lau,Francis and Pan,Yunhe},
title = {A Solid Model Based Virtual Hairy Brush},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {299-299},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/CGF589.pdf},
abstract = { Abstract  We present the detailed modeling of the hairy brush used typically in Chinese calligraphy. The complex model, which includes also a model for the ink and the paper, covers the various stages of the brush going through a calligraphy process. The model relies on the concept of writing primitives, which are the smallest units of hair clusters, to reduce the load on the simulation. Each such primitive is constructed through the general sweeping operation in {CAD} and described by a {NURBS} surface. The writing primitives dynamically adjust themselves during the virtual writing process, leaving an imprint on the virtual paper as they move. The behavior of the brush is an aggregation of the behavior of all the writing primitives. A software system based on the model has been built and tested. Samples of imitation artwork from using the system were obtained and found to be nearly indistinguishable from the real artwork.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.6 [Methodology and Techniques]: Interaction techniques I.3.5 [Computational Geometry and Object Modeling]: Physically based modeling I.3.4 [Graphics Utilities]: Paint systems }}
@article{Winnemoller:2002:GAT,
author = {Winnemoller,Holger and Bangay,Shaun},
title = {Geometric Approximations Towards Free Specular Comic Shading},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {309-309},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/paper115},
abstract = { Abstract  We extend the standard solution to comic rendering with a comic-style specular component. To minimise the computational overhead associated with this extension, we introduce two optimising approximations; the perspective correction angle and the vertex face-orientation measure. Both of these optimisations are generally applicable, but they are especially well suited for applications where a physically correct lighting simulation is not required. Using our optimisations we achieve performances comparable to the standard solution. As our approximations favour large models, we even outperform the standard approach for models consisting of 10,000 triangles or more, which we can render exceeding 40 frames per second, including the specular component.  Categories and Subject Descriptors (according to {ACM} CSS): I.3.3 [Computer Graphics] Picture/Image Generation: Display algorithms; I.3.7 [Computer Graphics] Three-Dimensional Graphics and Realism: Color, shading, shadowing, and texture; I.4.3 [Image Processing and Computer Vision] Enhancements: Geometric Correction. }}
@article{Diepstraten:2002:TII,
author = {Diepstraten,J. and Weiskopf,D. and Ertl,T.},
title = {Transparency in Interactive Technical Illustrations},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {317-317},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/CGF591.pdf},
abstract = { Abstract  This paper describes how technical illustrations containing opaque and non-opaque objects can be automatically generated. Traditional methods to show transparency in manual drawings are evaluated to extract a small and effective set of rules for computer-based rendering of technical illustrations, leading to a novel view-dependent transparency model. We propose a hardware-accelerated depth sorting algorithm in image-space which specifically meets the requirements of our transparency model. In this way, real-time rendering of semi-transparent technical illustrations is achieved. Finally, it is described how our approach can be combined with other methods in the field of non-photorealistic rendering in order to enhance the visual perception of technical illustrations.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.7 [Computer Graphics]: Color, shading, shadowing and texture }}
@article{Cordier:2002:RTA,
author = {Cordier,Frederic and Magnenat-Thalmann,Nadia},
title = {Real-time Animation of Dressed Virtual Humans},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {327-327},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/paper60},
abstract = { Abstract  In this paper, we describe a method for cloth animation in real-time. The algorithm works in a hybrid manner exploiting the merits of both the physical-based and geometric deformations. It makes use of predetermined conditions between the cloth and the body model, avoiding complex collision detection and physical deformations wherever possible. Garments are segmented into pieces that are simulated by various algorithms, depending on how they are laid on the body surface and whether they stick or flow on it. Tests show that the method is well suited to fully dressed virtual human models, achieving real-time performance compared to ordinary cloth-simulations. }}
@article{Oore:2002:LPM,
author = {Oore,Sageev and Terzopoulos,Demetri and Hinton,Geoffrey},
title = {Local Physical Models for Interactive Character Animation},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {337-337},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/paper318},
abstract = { Abstract  Our goal is to design and build a tool for the creation of expressive character animation. Virtual puppetry, also known as performance animation, is a technique in which the user interactively controls a character's motion. In this paper we introduce local physical models for performance animation and describe how they can augment an existing kinematic method to achieve very effective animation control. These models approximate specific physically-generated aspects of a character's motion. They automate certain behaviours, while still letting the user override such motion via a PD-controller if he so desires. Furthermore, they can be tuned to ignore certain undesirable effects, such as the risk of having a character fall over, by ignoring corresponding components of the force. Although local physical models are a quite simple approximation to real physical behaviour, we show that they are extremely useful for interactive character control, and contribute positively to the expressiveness of the character's motion. In this paper, we develop such models at the knees and ankles of an interactively-animated {3D} anthropomorphic character, and demonstrate a resulting animation. This approach can be applied in a straight-forward way to other joints.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism, Interaction Techniques }}
@article{Pai:2002:SIS,
author = {Pai,Dinesh K.},
title = {{STRANDS}: Interactive Simulation of Thin Solids using Cosserat Models},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {347-347},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/CGF594.pdf},
abstract = { Abstract  Strandsare thin elastic solids that are visually well approximated as smooth curves, and yet possess essential physical behaviors characteristic of solid objects such as twisting. Common examples in computer graphics include: sutures, catheters, and tendons in surgical simulation; hairs, ropes, and vegetation in animation. Physical models based on spring meshes or {3D} finite elements for such thin solids are either inaccurate or inefficient for interactive simulation. In this paper we show that models based on the Cosserat theory of elastic rods are very well suited for interactive simulation of these objects. The physical model reduces to a system of spatial ordinary differential equations that can be solved efficiently for typical boundary conditions. The model handles the important geometric non-linearity due to large changes in shape. We introduce Cosserat-type physical models, describe efficient numerical methods for interactive simulation of these models, and implementation results. }}
@article{Scheib:2002:EFA,
author = {Scheib,Vincent and Haber,Jorg and Lin,Ming C. and Seidel,Hans-Peter},
title = {Efficient Fitting and Rendering of Large Scattered Data Sets Using Subdivision Surfaces},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {353-353},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/CGF595.pdf},
abstract = { Abstract  We present a method to efficiently construct and render a smooth surface for approximation of large functional scattered data. Using a subdivision surface framework and techniques from terrain rendering, the resulting surface can be explored from any viewpoint while maintaining high surface fairness and interactive frame rates. We show the approximation error to be sufficiently small for several large data sets. Our system allows for adaptive simplification and provides continuous levels of detail, taking into account the local variation and distribution of the data.  Categories and Subject Descriptors (according to {ACM} CCS): G.1.2 [Approximation]: Approximation of surfaces, Least squares approximation, Piecewise polynomial approximation; I.3.3 [Picture/Image Generation]: Display algorithms, Viewing algorithms; I.3.5 [Computational Geometry and Object Modeling]: Surface representation. }}
@article{Giesen:2002:SRB,
author = {Giesen,Joachim and John,Matthias},
title = {Surface reconstruction based on a dynamical system},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {363-363},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/CGF596.pdf},
abstract = { Abstract  We present an efficient algorithm that computes a manifold triangular mesh from a set of unorganized sample points in . The algorithm builds on the observation made by several researchers that the Gabriel graph of the sample points provides a good surface description. However, this surface description is only one-dimensional. We associate the edges of the Gabriel graph with index 1 critical points of a dynamical system induced by the sample points. Exploiting also the information contained in the critical points of index 2 provides a two-dimensional surface description which can be easily turned into a manifold. }}
@article{Ohbuchi:2002:AFD,
author = {Ohbuchi,1Ryutarou and Mukaiyama,1Akio and Takahashi,2Shigeo},
title = {A Frequency-Domain Approach to Watermarking {3D} Shapes},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {373-373},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/CGF597.pdf},
abstract = { Abstract  This paper presents a robust watermarking algorithm with informed detection for {3D} polygonal meshes. The algorithm is based on our previous algorithm [22] that employs mesh-spectral analysis to modify mesh shapes in their transformed domain. This paper presents extensions to our previous algorithm so that (1) much larger meshes can be watermarked within a reasonable time, and that (2) the watermark is robust against connectivity alteration (e.g., mesh simplification), and that (3) the watermark is robust against attacks that combine similarity transformation with such other attacks as cropping, mesh simplification, and smoothing. Experiment showed that our new watermarks are resistant against mesh simplification and remeshing combined with resection, similarity transformation, and other operations.. }}
@article{Lee:2002:AAA,
author = {Lee,Haeyoung and Alliez,Pierre and Desbrun,Mathieu},
title = {Angle-Analyzer: A Triangle-Quad Mesh Codec},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {383-383},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/CGF598.pdf},
abstract = { Abstract  We present Angle-Analyzer, a new single-rate compression algorithm for triangle-quad hybrid meshes. Using a carefully-designed geometry-driven mesh traversal and an efficient encoding of intrinsic mesh properties, Angle-Analyzer produces compression ratios 40% better in connectivity and 20% better in geometry than the leading Touma and Gotsman technique for the same level of geometric distortion. The simplicity and performance of this new technique is demonstrated, and we provide extensive comparative tests to contrast our results with the current state-of-the-art techniques.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.3 [Computer Graphics]: Surface mesh compression, connectivity coding, geometry coding. }}
@article{Walter:2002:UPT,
author = {Walter,Bruce and Pattanaik,Sumanta N. and Greenberg,Donald P.},
title = {Using Perceptual Texture Masking for Efficient Image Synthesis},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {393-393},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/CGF599.pdf},
abstract = { Abstract  Texture mapping has become indispensable in image synthesis as an inexpensive source of rich visual detail. Less obvious, but just as useful, is its ability to mask image errors due to inaccuracies in geometry or lighting. This ability can be used to substantially accelerate rendering by eliminating computations when the resulting errors will be perceptually insignificant.  Our new method precomputes the masking ability of textures using aspects of the {JPEG} image compression standard. This extra information is stored as threshold elevation factors in the texture's mip-map and interpolated at image generation time as part of the normal texture lookup process. Any algorithm which uses error tolerances or visibility thresholds can then take advantage of texture masking. Applications to adaptive shadow testing, irradiance caching, and path tracing are demonstrated.  Unlike prior methods, our approach does not require that initial images be computed before masking can be exploited and incurs only negligible runtime computational overhead. Thus, it is much easier to integrate with existing rendering systems for both static and dynamic scenes and yields computational savings even when only small amounts of texture masking are present.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.7 [Computer Graphics]: Color, shading, shadowing, and texture }}
@article{Dischler:2002:TP,
author = {Dischler,J.-M. and Maritaud,K. and Levy*,B. and Ghazanfarpour,D.},
title = {Texture Particles},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {401-401},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/CGF600.pdf},
abstract = { Abstract  This paper presents an analytical extension of texture synthesis techniques based on the distribution of elementary texture components. Our approach is similar to the bombing, cellular, macrostructured and lapped textures techniques, but provides the user with more control on both the texture analysis and synthesis phases. Therefore, high quality results can be obtained for a large number of structured or stochastic textures (bricks, marble, lawn, etc.). The analysis consists in decomposing textures into elementary components - that we call ``texture particles'' - and for which we analyze their specific spatial arrangements. The synthesis then consists in recomposing similar textures directly on arbitrary surfaces by taking into account the previously computed arrangements, extended to {3D} surfaces. Compared to ``pixel-based'' analysis and synthesis methods, which have been recently generalized to arbitrary surfaces, our approach has three major advantages: (1) it is fast, which allows the user to interactively control the synthesis process. This further allows us to propose a large number of tools, granting a high degree of artistic freedom to the user. (2) It avoids the visual deterioration of the texture components by preserving their shapes as well as their spatial arrangements. (3) The texture particles can be not only images, but also {3D} geometric elements, which extends significantly the domain of application. }}
@article{Balmelli:2002:SOT,
author = {Balmelli,Laurent and Taubin,Gabriel and Bernardini,Fausto},
title = {Space-Optimized Texture Maps},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {411-411},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/paper297},
abstract = { Abstract  Texture mapping is a common operation to increase the realism of three-dimensional meshes at low cost. We propose a new texture optimization algorithm based on the reduction of the physical space allotted to the texture image. Our algorithm optimizes the use of texture space by computing a warping function for the image and new texture coordinates. Neither the mesh geometry nor its connectivity are modified by the optimization. Our method uniformly distributes frequency content of the image in the spatial domain. In other words, the image is stretched in high frequency areas, whereas low frequency regions are shrunk. We also take into account distortions introduced by the mapping onto the model geometry in this process. The resulting image can be resampled at lower rate while preserving its original details. The unwarping is performed by the texture mapping function. Hence, the space-optimized texture is stored as-is in texture memory and is fully supported by current graphics hardware. We present several examples showing that our method significantly decreases texture memory usage without noticeable loss in visual quality. }}
@article{Kim:2002:PTM,
author = {Kim,Dongho and Hahn,James K.},
title = {Projective Texture Mapping with Full Panorama},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {421-421},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/CGF602.pdf},
abstract = { Abstract  Projective texture mapping is used to project a texture map onto scene geometry. It has been used in many applications, since it eliminates the assignment of fixed texture coordinates and provides a good method of representing synthetic images or photographs in image-based rendering. But conventional projective texture mapping has limitations in the field of view and the degree of navigation because only simple rectangular texture maps can be used.  In this work, we propose the concept of panoramic projective texture mapping (PPTM). It projects cubic or cylindrical panorama onto the scene geometry. With this scheme, any polygonal geometry can receive the projection of a panoramic texture map, without using fixed texture coordinates or modeling many projective texture mapping. For fast real-time rendering, a hardware-based rendering method is also presented. Applications of {PPTM} include panorama viewer similar to QuicktimeVR and navigation in the panoramic scene, which can be created by image-based modeling techniques.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.3 [Computer Graphics]: Viewing Algorithms; I.3.7 [Computer Graphics]: Color, Shading, Shadowing, and Texture }}
@article{Ayasse:2002:SOD,
author = {Ayasse,Jorg and Muller,Heinrich},
title = {Sculpturing on Discrete Displacement Fields},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {431-431},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/CGF603.pdf},
abstract = { Abstract  A displacement field can be defined by a vector field and a height field on an orientable surfaceS, describing the direction and the amount of displacement to be applied toSin order to get a surface represented by the displacement field.Stogether with the vector field can also be considered as a representation of a volume by a ``surface crust''. The crust allows the application of sculpturing operations for designing detailed structure. For conventional height fields over the plane, sculpturing can be reduced to the task of finding the minimum or maximum of the height values of a surface and the height values stored. Over the plane, depth-buffering with parallel projection has been used for calculation. For displacement fields over curved surfaces the projection is more complicated. In this contribution, an efficient solution is presented for displacement fields over triangular meshes. The central task is to insert a triangle in space into the curved depth-buffer represented by the displacement field.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.5 [Computational Geometry and Object Modeling]: Curve, surface, solid, and object representations }}
@article{Winter:2002:ISV,
author = {Winter,Andrew S. and Chen,Min},
title = {Image-Swept Volumes},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {441-441},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/CGF604.pdf},
abstract = { Abstract  Many graphical objects can be represented by swept volumes (including its subset - generalised cylinders) by sweeping {2D} or {3D} templates along {3D} trajectories. In this paper, we present a new approach for constructing swept volumes using image templates. We utilise scalar fields as our underlying data type, and employ volume ray casting techniques for rendering swept volumes in their original sweeping specifications as well as in their voxelised approximations. In addition to some simple image-swept volumes, we also treat multi-channel image templates, video templates, generalised sweeps, and self-intersecting trajectories. This approach enables us to model swept volumes with heterogeneous interiors and amorphous effects. It also facilitates the use of constructive volume geometry for creating complex scenes in both modelling and rendering space. }}
@article{Pascucci:2002:SGS,
author = {Pascucci,V.},
title = {Slow Growing Subdivision (SGS) in Any Dimension: Towards Removing the Curse of Dimensionality},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {451-451},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/CGF605.pdf},
abstract = { Abstract  In recent years subdivision methods have been one of the most successful techniques applied to the multi-resolution representation and visualization of surface meshes. Extension these techniques to the volumetric case would enable their use in a broad class of applications including solid modeling, scientific visualization and mesh generation. Unfortunately, major challenges remain unsolved both in the generalization of the combinatorial structure of the refinement procedure and in the analysis of the smoothness of the limit mesh.  In this paper we mainly tackle the first part of the problem introducing a subdivision scheme that generalizes to {3D} and higher dimensional meshes without the excessive vertex proliferation typical of tensor-product refinements. The main four qualities of our subdivision procedure are: (i) the rate of refinement does not grow with the dimension of the mesh, (ii) adaptive refinement of the mesh is possible without introducing special temporary cell decompositions, (iii) the cells of the base meshes can have virtually unrestricted topology, and (iv) ``sharp'' features of different dimensions can be incorporated naturally.  We use a narrow averaging mask that is applied to the vertices of the mesh and/or to eventual functions defined on the mesh. The general study of the limit smoothness of the approach requires new analysis techniques that are beyond the scope of this paper.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.5 [Computer Graphics]: Curve, surface, solid, and object representations. Volumetric meshes, recursive subdivision methods. }}
@article{Ren:2002:OSE,
author = {Ren,Liu and Pfister,Hanspeter and Zwicker,Matthias},
title = {Object Space {EWA} Surface Splatting: A Hardware Accelerated Approach to High Quality Point Rendering},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {461-461},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/CGF606.pdf},
abstract = { Abstract  Elliptical weighted average (EWA) surface splatting is a technique for high quality rendering of point-sampled {3D} objects. {EWA} surface splatting renders water-tight surfaces of complex point models with high quality, anisotropic texture filtering. In this paper we introduce a new multi-pass approach to perform {EWA} surface splatting on modern {PC} graphics hardware, called object space {EWA} splatting. We derive an object space formulation of the {EWA} filter, which is amenable for acceleration by conventional triangle-based graphics hardware. We describe how to implement the object space {EWA} filter using a two pass rendering algorithm. In the first rendering pass, visibility splatting is performed by shifting opaque surfel polygons backward along the viewing rays, while in the second rendering pass view-dependent {EWA} prefiltering is performed by deforming texture mapped surfel polygons. We use texture mapping and alpha blending to facilitate the splatting process. We implement our algorithm using programmable vertex and pixel shaders, fully exploiting the capabilities of today's graphics processing units (GPUs). Our implementation renders up to 3 million points per second on recent {PC} graphics hardware, an order of magnitude more than a pure software implementation of screen space {EWA} surface splatting.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.3 [Computer Graphics]: Display Algorithms }}
@article{Hidalgo:2002:HGI,
author = {Hidalgo,Eduardo and Hubbold,Roger J.},
title = {Hybrid Geometric - Image Based Rendering},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {471-471},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/paper74},
abstract = { Abstract  We present a Hybrid Geometric-Image Based Rendering (HGIBR) system for displaying very complex geometrical models at interactive frame rates. Our approach replaces distant geometry with a combination of image-based representations and geometry, while rendering nearby objects from geometry. Reference images are computed on demand, which means that no pre-processing, or additional storage are necessary. We present results for a massive model of a whole offshore gas platform, to demonstrate that interactive frame rates can be maintained using the {HGIBR} approach. Our implementation runs on a pair of PCs, using commodity graphics hardware for fast {3D} warping. }}
@article{Wand:2002;MRR,
author = {Wand,M. and Strasser,W.},
title = {Multi-Resolution Rendering of Complex Animated Scenes},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {483-483},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/paper99},
abstract = { Abstract  We present a novel multi-resolution point sample rendering algorithm for keyframe animations. The algorithm accepts triangle meshes of arbitrary topology as input which are animated by specifying different sets of vertices at keyframe positions. A multi-resolution representation consisting of prefiltered point samples and triangles is built to represent the animated mesh at different levels of detail. We introduce a novel sampling and stratification algorithm to efficiently generate suitable point sample sets for moving triangle meshes. Experimental results demonstrate that the new data structure can be used to render highly complex keyframe animations like crowd scenes in real-time.  Categories and Subject Descriptors: I.3.3 [Computer Graphics]: Picture / Image Generation - Display Algorithms; I.3.6 [Computer Graphics]: Methodology and Techniques - Graphics data structures and data types; G.3 [Mathematics of Computing]: Probability and Statistics - Probabilistic algorithms. }}
@article{Cobzas:2002:DTF,
author = {Cobzas,Dana and Yerex,Keith and Jagersand,Martin},
title = {Dynamic Textures for Image-based Rendering of Fine-Scale {3D} Structure and Animation of Non-rigid Motion},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {493-493},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/paper311},
abstract = { Abstract  The problem of capturing real world scenes and then accurately rendering them is particularly difficult for fine-scale {3D} structure. Similarly, it is difficult to capture, model and animate non-rigid motion. We present a method where small image changes are captured as a time varying (dynamic) texture. In particular, a coarse geometry is obtained from a sample set of images using structure from motion. This geometry is then used to subdivide the scene and to extract approximately stabilized texture patches. The residual statistical variability in the texture patches is captured using a {PCA} basis of spatial filters. The filters coefficients are parameterized in camera pose and object motion. To render new poses and motions, new texture patches are synthesized by modulating the texture basis. The texture is then warped back onto the coarse geometry. We demonstrate how the texture modulation and projective homography-based warps can be achieved in real-time using hardware accelerated OpenGL. Experiments comparing dynamic texture modulation to standard texturing are presented for objects with complex geometry (a flower) and non-rigid motion (human arm motion capturing the non-rigidities in the joints, and creasing of the shirt).  Categories and Subject Descriptors (according to {ACM} CCS): I.3.3 [Computer Graphics]: Image Based Rendering }}
@article{Matsuoka:2002:ROP,
author = {Matsuoka,H. and Takeuchi,T. and Kitazawa,H. and Onozawa,A.},
title = {Representation of Pseudo Inter-reflection and Transparency by Considering Characteristics of Human Vision},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {503-503},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/CGF700.pdf},
abstract = { Abstract  We have succeeded in developing a quick and fully automated system that can generate photo-realistic {3D} {CG} data based on a real object. A major factor in this success comes from our findings through psychophysical experiments that human observers do not have an accurate idea of what should be actually reflected as inter-reflections on the surface of an object. Taking advantage of this characteristic of human vision, we propose a new inter-reflection representation technique in which inter-reflections are simulated by allowing the same quantity of reflection components as there are in the background to pass through the object. Since inter-reflection and transparency are calculated by the same algorithm, our system can capture {3D} {CG} data from various real objects having a strong inter-reflection, such as plastic and porcelain items or translucent glass and acrylic resin objects. The synthetic images from the {3D} {CG} data generated with this pseudo inter-reflection and transparency look very natural. In addition, the {3D} {CG} data and synthetic images are produced quickly at a lower cost. }}
@article{Lee:2002:AIO,
author = {Lee,Sung Chun and Jung,Soon Ki and Nevatia,Ram},
title = {Automatic Integration of Facade Textures into {3D} Building Models with a Projective Geometry Based Line Clustering},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {511-511},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/CGF701.pdf},
abstract = { Abstract  Visualization of city scenes is important for many applications including entertainment and urban mission planning. Models covering wide areas can be efficiently constructed from aerial images. However, only roof details are visible from aerial views; ground views are needed to provide details of the building facades for high quality 'fly-through' visualization or simulation applications. We present an automatic method of integrating facade textures from ground view images into {3D} building models for urban site modeling. We first segment the input image into building facade regions using a hybrid feature extraction method, which combines global feature extraction with Hough transform on an adaptively tessellated Gaussian Sphere and local region segmentation. We estimate the external camera parameters by using the corner points of the extracted facade regions to integrate the facade textures into the {3D} building models. We validate our approach with a set of experiments on some urban sites.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.3 [Computer Graphics]: Modeling packages }}
@article{Wang:2002:ISR,
author = {Wang,Jianning and Oliveira,Manuel M.},
title = {Improved Scene Reconstruction from Range Images},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {521-521},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/paper53},
abstract = { Abstract  The modeling of real scenes is a complex and challenging task for which the use of laser rangefinders is one of the most promising approaches. Unfortunately, in many situations, it is not possible or practical to guarantee appropriate sampling of all surfaces in the scene. For example, occlusions and accessibility limitations to certain regions of the scene may cause some areas not to be visible by the scanner, resulting in incomplete or incorrectly reconstructed models. This paper describes a pipeline and a system implementation for improving model reconstruction from incomplete information available from range images.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism, Virtual Reality }}
@article{Kelemen:2002:ASA,
author = {Kelemen,Csaba and Szirmay-Kalos,Laszlo and Antal,Gyorgy and Csonka,Ferenc},
title = {A Simple and Robust Mutation Strategy for the Metropolis Light Transport Algorithm},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {531-531},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/paper50},
abstract = { Abstract  This paper presents a new mutation strategy for the Metropolis light transport algorithm, which works in the unit cube of pseudo-random numbers instead of mutating in the path space. This transformation makes the integrand have lower variation and thus increases the acceptance probability of the mutated samples. Higher acceptance ratio, in turn, reduces the correlation of the samples, which increases the speed of convergence. We use both local mutations that choose a new random sample in the neighborhood of the previous one, and global mutations that make ``large steps'', and find the samples independently. Local mutations smooth out the result, while global mutations guarantee the ergodicity of the process. Due to the fact that samples are generated independently in large steps, this method can also be considered as a combination of the Metropolis algorithm with a classical random walk. If we use multiple importance sampling for this combination, the combined method will be as good at bright regions as the Metropolis algorithm and at dark regions as random walks. The resulting scheme is robust, efficient, but most importantly, is easy to implement and to combine with an arbitrary random-walk algorithm. }}
@article{Hey:2002:ARE,
author = {Hey,Heinrich and Purgathofer,Werner},
title = {Advanced Radiance Estimation For Photon Map Global Illumination},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {541-541},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/CGF704.pdf},
abstract = { Abstract  We present a new method to compute radiance in photon map based global illumination simulation for polygonal scenes with general bidirectional scattering distribution functions (BSDFs). Our new radiance estimation uses the actual geometry in the neighborhood of the illuminated point, and does not assume that the nearest neighbor photons lie in the same plane as the point, nor that they are distributed in a circular area around that point. This allows us to achieve accurate indirect illumination by direct visualization of the photon map - which is especially important for the simulation of caustics(LS+DS*Epaths) - even in the vicinity of edges and corners of objects, and on surfaces with differently oriented small geometric details. }}
@article{Scheel:2002:GBF,
author = {Scheel,Annette and Stamminger,Marc and Seidel,Hans-Peter},
title = {Grid Based Final Gather for Radiosity on Complex Clustered Scenes},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {547-547},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/CGF705.pdf},
abstract = { Abstract  Radiosity methods handle large scenes and complex objects using clustering techniques. To reconstruct a high quality image, usually a second very time consuming final gather pass is applied which exactly recomputes the last light transport before reaching the eye. We propose a new final gather technique which is especially suited for scenes with fine polygonal geometry. In such scenes, substantial parts of the incident illumination vary only smoothly across the surfaces and can be reconstructed on a much coarser structure. We therefore propose a final gather reconstruction based on an object-independent {3D} grid. The illumination of each sender is investigated separately: If it varies smoothly across a grid cell, it is interpolated between the vertices of the grid cell, or recomputed exactly, otherwise. We further reduce the number of required samples using view-dependent optimizations. So complex objects with a very detailed structure-plants are good example here-exhibit strong masking effects, which can be exploited by our method. Finally, the estimation of penumbra screen sizes can be used to further reduce costly visibility reevaluations.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.3 [Copmuter Graphics]: Picture/Image generation I.3.7 [Copmuter Graphics]: Three-Dimensional Graphics and Realism }}
@article{Kollig:2002:EMS,
author = {Kollig,Thomas and Keller,Alexander},
title = {Efficient Multidimensional Sampling},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {557-557},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/CGF706.pdf},
abstract = { Abstract  Image synthesis often requires the Monte Carlo estimation of integrals. Based on a generalized concept of stratification we present an efficient sampling scheme that consistently outperforms previous techniques. This is achieved by assembling sampling patterns that are stratified in the sense of jittered sampling and N-rooks sampling at the same time. The faster convergence and improved anti-aliasing are demonstrated by numerical experiments.  Categories and Subject Descriptors (according to {ACM} CCS): G.3 [Probability and Statistics]: Probabilistic Algorithms (including Monte Carlo); I.3.2 [Computer Graphics]: Picture/Image Generation; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism. }}
@article{Streit:2002:ABP,
author = {Streit,L. and Heidrich,W.},
title = {A Biologically-Parameterized Feather Model},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {565-565},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/paper301},
abstract = { Abstract  Feathers, unlike other cutaneous appendages such as hair, fur, or scales have a definite structure. Variation in feather structure creates a wide range of resulting appearances. Collectively, feather structure determines the appearance of the feather coat, which can largely affect the resulting look of a feathered object (bird). In this paper we define the structure of individual feathers using a parameterization based on biological structure and substructures of actual feathers. We show that our parameterization can generate a large variety of feathers at multiple levels of detail and provide an initial step to semi-automatically generating a wide range of feather coats. his is achieved by specifying an intuitive interpolation between different structures and ages of feathers. }}
@article{Daubert:2002:HBV,
author = {Daubert,Katja and Seidel,Hans-Peter},
title = {Hardware-Based Volumetric Knit-Wear},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {575-575},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/CGF708.pdf},
abstract = { Abstract  We present a hardware-based, volumetric approach for rendering knit wear at very interactive rates. A single stitch is represented by a volumetric texture with each voxel storing the main direction of the strands of yarn inside it. We render the knit wear in layers using an approximation of the Banks model. Our hardware implementation allows specular and diffuse material properties to change from one voxel to the next. This enables us to represent yarn made up of different components or render garments with complicated color patterns. Furthermore, our approach can handle self-shadowing of the stitches, and can easily be adapted to also include view-independent scattering. The resulting shader lends itself naturally to mip-mapping, and requires no reordering of the base geometry, making it versatile and easy to use.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.3 [Computer Graphics]: Hardware Applications Volumetric Textures }}
@article{Karpenko:2002:FFS,
author = {Karpenko,Olga and Hughes,John F. and Raskar,Ramesh},
title = {Free-form sketching with variational implicit surfaces},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {585-585},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/paper163},
abstract = { Abstract  With the advent of sketch-based methods for shape construction, there's a new degree of power available in the rapid creation of approximate shapes. Sketch [Zeleznik, 1996] showed how a gesture-based modeler could be used to simplify conventional CSG-like shape creation. Teddy [Igarashi, 1999] extended this to more free-form models, getting much of its power from its ``inflation'' operation (which converted a simple closed curve in the plane into a {3D} shape whose silhouette, from the current point of view, was that curve on the view plane) and from an elegant collection of gestures for attaching additional parts to a shape, cutting a shape, and deforming it.  But despite the powerful collection of tools in Teddy, the underlying polygonal representation of shapes intrudes on the results in many places. In this paper, we discuss our preliminary efforts at using variational implicit surfaces [Turk, 2000] as a representation in a free-form modeler. We also discuss the implementation of several operations within this context, and a collection of user-interaction elements that work well together to make modeling interesting hierarchies simple. These include ``stroke inflation'' via implicit functions, blob-merging, automatic hierarchy construction, and local surface modification via silhouette oversketching. We demonstrate our results by creating several models.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.5 [Computer Graphics]: Modeling packages I.3.6 [Computer Graphics]: Interaction techniques }}
@article{Theisel:2002:D2D,
author = {Theisel,H.},
title = {Designing {2D} Vector Fields of Arbitrary Topology},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {595-595},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/CGF710.pdf},
abstract = { Abstract  We introduce a scheme of control polygons to design topological skeletons for vector fields of arbitrary topology. Based on this we construct piecewise linear vector fields of exactly the topology specified by the control polygons. This way a controlled construction of vector fields of any topology is possible. Finally we apply this method for topology-preserving compression of vector fields consisting of a simple topology. }}
@article{Bordoloi:2002:HAI,
author = {Bordoloi,Udeepta and Shen,Han-Wei},
title = {Hardware Accelerated Interactive Vector Field Visualization: A level of detail approach},
journal = {Computer Graphics Forum},
volume = {21},
number = {3},
pages = {605-605},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue3/CGF711.pdf},
abstract = { Abstract  This paper presents an interactive global visualization technique for dense vector fields using levels of detail. We introduce a novel scheme which combines an error-controlled hierarchical approach and hardware acceleration to produce high resolution visualizations at interactive rates. Users can control the trade-off between computation time and image quality, producing visualizations amenable for situations ranging from high frame-rate previewing to accurate analysis. Use of hardware texture mapping allows the user to interactively zoom in and explore the data, and also to configure various texture parameters to change the look and feel of the visualization. We are able to achieve sub-second rates for dense LIC-like visualizations with resolutions in the order of a million pixels for data of similar dimensions.  Categories and Subject Descriptors (according to {ACM} CCS): I.3 [Computer Graphics]: Applications }}
@article{Bronsvoort:2002:FMV,
author = {Bronsvoort,Willem F. and Bidarra,Rafael and Noort,Alex},
title = {Feature Model Visualization},
journal = {Computer Graphics Forum},
volume = {21},
number = {4},
pages = {661-661},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue4/cgf624.pdf},
abstract = { Abstract  Feature modelling is now the predominant way of modelling products. Feature visualization is an important aspecthere that can still be considerably improved. In this paper, an integrated way of visualizing feature models ispresented, using new techniques for both the geometry and the structure of models. For the geometry of featuremodels, techniques are presented to visualize a selected subset of form features in a way that clearly distinguishesthem from the rest of the model, as well as functional information such as closure faces of subtractive form features.For the structure of features models, techniques are presented to visualize several types of graphs. The differentvisualization techniques are used in an integrated way. Implementation of some of the techniques requires a non-manifoldrepresentation of the geometry of the feature model. This representation, and some other implementationaspects, are briefly described. Throughout the paper, numerous examples of images of feature models are givenwhich show that the new visualization techniques can indeed improve the effectiveness of feature modelling.  {ACM} {CSS}: I.3.7 Three-Dimensional Graphics and Realism-visible line/surface algorithms, J.6 Computer-AidedEngineering-feature modelling }}
@article{Reinders:2002:VTA,
author = {Reinders,Freek and Sadarjoen,I. Ari and Vrolijk,Benjamin and Post,Frits H.},
title = {Vortex Tracking and Visualisation in a Flow Past a Tapered Cylinder},
journal = {Computer Graphics Forum},
volume = {21},
number = {4},
pages = {675-675},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue4/cgf625.pdf},
abstract = { Abstract  In this paper we explore a novel combined application of two of our existing visualisation techniques to thetracking of {3D} vortex tubes in an unsteady flow. The applied techniques are the winding-angle vortex extractiontechnique based on streamline geometry, and the attribute-based feature tracking technique. We have applied theseto the well-known case of an unsteady {3D} flow past a tapered cylinder.  First, {2D} vortices are detected in a number of horizontal slices for each time step, by means of the winding-anglevortex extraction method. For each {2D} vortex a number of attributes are calculated and stored. These vorticesare visualised by a special type of ellipse icons, showing the position, shape and rotational direction and speed ineach slice.  Next, for each time step, {3D} vortex tubes are constructed from the {2D} vortices by applying the feature trackingprocedure in a spatial dimension to connect the corresponding vortices in adjacent slices. The result is a graphattribute set with the {2D} vortex attributes in the nodes and the spatial correspondences as edges.  Finally, the {3D} vortex tubes are tracked in time using the same tracking procedure, for finding the correspondingtubes in successive time steps. The result is a description of the evolution of the {3D} vortices. An interactive, time-dependentvisualisation is generated using the temporal correspondences of each vortex tube. This analysis revealsa number of interesting patterns.  {ACM} {CSS}: I.3.8 Computer Graphics-Applications }}
@article{Huang:2002:AAF,
author = {Huang,Y. Q. and Liu,Y. K.},
title = {An algorithm for line clipping against a polygon based on shearing transformation},
journal = {Computer Graphics Forum},
volume = {21},
number = {4},
pages = {683-683},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue4/cgf626.pdf},
abstract = { Abstract  Line clipping against a polygon is widely used in computer graphics such as the hidden line problem. A newline-clipping algorithm against a general polygon is presented in this paper. The basic idea of this algorithm is tochange the line to be clipped into a horizontal line by shearing transformation. Then each edge of the polygonalwindow is transformed by a shearing transformation with the same parameters as those used to the line. Eachedge of the polygon is processed against a horizontal line, which makes the clipping process simpler. The result inthis paper shows that less calculation is needed for the new algorithm with a higher speed compared to existingalgorithms. }}
@article{Hisada:2002:ASB,
author = {Hisada,Masayuki and Belyaev,Alexander G. and Kunii,Tosiyasu L.},
title = {A Skeleton-based Approach for Detection of Perceptually Salient Features on Polygonal Surfaces},
journal = {Computer Graphics Forum},
volume = {21},
number = {4},
pages = {689-689},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue4/cgf627.pdf},
abstract = { Abstract  The paper presents a skeleton-based approach for robust detection of perceptually salient shape features. Given ashape approximated by a polygonal surface, its skeleton is extracted using a three-dimensional Voronoi diagramtechnique proposed recently by Amenta et al. [3]. Shape creases, ridges and ravines, are detected as curvescorresponding to skeletal edges. Salient shape regions are extracted via skeleton decomposition into patches.The approach explores the singularity theory for ridge and ravine detection, combines several filtering methodsfor skeleton denoising and for selecting perceptually important ridges and ravines, and uses a topological analysisof the skeleton for detection of salient shape regions.  {ACM} {CSS}: I.3.5 Computational Geometry and Object Modeling }}
@article{Iwasaki:2002:AEM,
author = {Iwasaki,Kei and Dobashi,Yoshinori and Nishita,Tomoyuki},
title = {An Efficient Method for Rendering Underwater Optical Effects Using Graphics Hardware},
journal = {Computer Graphics Forum},
volume = {21},
number = {4},
pages = {701-701},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue4/cgf628.pdf},
abstract = { Abstract  The display of realistic natural scenes is one of the most important research areas in computer graphics. Therendering of water is one of the essential components. This paper proposes an efficient method for renderingimages of scenes within water. For underwater scenery, the shafts of light and caustics are attractive and importantelements. However, computing these effects is difficult and time-consuming since light refracts when passingthrough waves. To address the problem, our method makes use of graphics hardware to accelerate the computation.Our method displays the shafts of light by accumulating the intensities of streaks of light by using hardware colorblending functions. Making use of a Z-buffer and a stencil buffer accelerates the rendering of caustics. Moreover,by using a shadow mapping technique, our method can display shafts of light and caustics taking account ofshadows due to objects.  {ACM} {CSS}: I. 3.1 Computer Graphics-Hardware Architecture, I. 3.7 Computer Graphics-Three-DimensionalGraphics and Realism }}
@article{McNeill:2002:ASD,
author = {McNeill,M.D.J. and Sayers,H. and Wilson,S. and Mc Kevitt,P.},
title = {A Spoken Dialogue System for Navigation in Non-Immersive Virtual Environments},
journal = {Computer Graphics Forum},
volume = {21},
number = {4},
pages = {713-713},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue4/cgf629.pdf},
abstract = { Abstract  Navigation is the process by which people control their movement in virtual environments and is a corefunctional requirement for all virtual environment (VE) applications. Users require the ability to move, controllingorientation, direction of movement and speed, in order to achieve a particular goal within a {VE}. Navigation israrely the end point in itself (which is typically interaction with the visual representations of data) but applicationsoften place a high demand on navigation skills, which in turn means that a high level of support for navigationis required from the application. On desktop systems navigation in non-immersive systems is usually supportedthrough the usual hardware devices of mouse and keyboard. Previous work by the authors shows that many usersexperience frustration when trying to perform even simple navigation tasks - users complain about getting lost,becoming disorientated and finding the interface `difficult to use'. In this paper we report on work in progressin exploiting natural language processing (NLP) technology to support navigation in non-immersive virtualenvironments. A multi-modal system has been developed which supports a range of high-level (spoken) navigationcommands and indications are that spoken dialogue interaction is an effective alternative to mouse and keyboardinteraction for many tasks. We conclude that multi-modal interaction, combining technologies such as {NLP} withmouse and keyboard may offer the most effective interaction with VEs and identify a number of areas where furtherwork is necessary.  {ACM} {CSS}: I.3.6 Computer Graphics Methodology and Techniques-Interaction and Techniques, I.3.7 Three-DimensionalGraphics and Realism-Virtual Reality, I.2.7 Natural Language Processing-Speech Recognitionand Synthesis }}
@article{O'Hara:2002:HIF,
author = {O'Hara,Noel},
title = {Hierarchical Impostors for the Flocking Algorithm in {3D}},
journal = {Computer Graphics Forum},
volume = {21},
number = {4},
pages = {723-723},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue4/cgf630.pdf},
abstract = { Abstract  The availability of powerful and affordable {3D} {PC} graphics boards has made the rendering of rich immersiveenvironments possible at interactive speeds. The scene update rate and the appropriate behaviour of objects withinthe world are central to this immersive feeling. This paper is concerned with the behaviour computations involvedin the flocking algorithm, which has been used extensively to emulate the flocking behaviour of creatures found innature. The main contribution of this paper is a new method for hierarchically combining portions of the flocksinto groups to reduce the cost of the behavioural computation, allowing far larger flocks to be updated in real-timein the world.  {ACM} {CSS}: I.3.7 Three-Dimensional Graphics and Realism-Animation }}
@article{OSullivan:2002:LOD,
author = {O'Sullivan,C. and Cassell,J. and Vilhjalmsson,H. and Dingliana,J. and Dobbyn,S. and McNamee,B. and Peters,C. and Giang,T.},
title = {Levels of Detail for Crowds and Groups},
journal = {Computer Graphics Forum},
volume = {21},
number = {4},
pages = {733-733},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue4/cgf631.pdf},
abstract = { Abstract  Work on levels of detail for human simulation has occurred mainly on a geometrical level, either by reducing the numbers of polygons representing a virtual human, or replacing them with a two-dimensional imposter. Approaches that reduce the complexity of motions generated have also been proposed. In this paper, we describe ongoing development of a framework for Adaptive Level Of Detail for Human Animation (ALOHA), which incorporates levels of detail for not only geometry and motion, but also includes a complexity gradient for natural behaviour, both conversational and social.  {ACM} {CSS}: I.3.7 Three-Dimensional Graphics and Realism-Animation }}
@article{Peters:2002:SVA,
author = {Peters,C. and O'Sullivan,C.},
title = {Synthetic Vision and Memory for Autonomous Virtual Humans},
journal = {Computer Graphics Forum},
volume = {21},
number = {4},
pages = {743-743},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue4/cgf632.pdf},
abstract = { Abstract  A memory model based on ``stage theory'', an influential concept of memory from the field of cognitive psychology,is presented for application to autonomous virtual humans. The virtual human senses external stimuli througha synthetic vision system. The vision system incorporates multiple modes of vision in order to accommodate aperceptual attention approach. The memory model is used to store perceived and attended object information atdifferent stages in a filtering process. The methods outlined in this paper have applications in any area wheresimulation-based agents are used: training, entertainment, ergonomics and military simulations to name but afew.  {ACM} {CSS}: I. 3.7 Computer Graphics--Virtual reality }}
@article{Tecchia:2002:VCI,
author = {Tecchia,Franco and Loscos,Celine and Chrysanthou,Yiorgos},
title = {Visualizing Crowds in Real-Time},
journal = {Computer Graphics Forum},
volume = {21},
number = {4},
pages = {753-753},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue4/cgf633.pdf},
abstract = { Abstract  Real-time crowd visualization has recently attracted quite an interest from the graphics community and, asinteractive applications become even more complex, there is a natural demand for new and unexplored applicationscenarios. However, the interactive simulation of complex environments populated by large numbers of virtualcharacters is a composite problem which poses serious difficulties even on modern computer hardware. In thispaper we look at methods to deal with various aspects of crowd visualization, ranging from collision detectionand behaviour modeling to fast rendering with shadows and quality shading. These methods make extensive useof current graphics hardware capabilities with the aim of providing scalability without compromising run-timespeed. Results from a system employing these techniques seem to suggest that simulations of reasonably complexenvironments populated with thousands of animated characters are possible in real-time.  {ACM} {CSS}: I.3.7 Three-Dimensional Graphics and Realism-Animation }}
@article{Ulicny:2002:TIR,
author = {Ulicny,Branislav and Thalmann,Daniel},
title = {Towards Interactive Real-Time Crowd Behavior Simulation},
journal = {Computer Graphics Forum},
volume = {21},
number = {4},
pages = {767-767},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue4/cgf634.pdf},
abstract = { Abstract  While virtual crowds are becoming common in non-real-time applications, the real-time domain is still relativelyunexplored. In this paper we discuss the challenges involved in creating such simulations, especially the needto efficiently manage variety. We introduce the concept of levels of variety. Then we present our work oncrowd behaviour simulation aimed at interactive real-time applications such as computer games or virtualenvironments. We define a modular behavioural architecture of a multi-agent system allowing autonomous andscripted behaviour of agents supporting variety. Finally we show applications of our system in a virtual realitytraining system and a virtual heritage reconstruction.  {ACM} {CSS}: I.3.7 Three-Dimensional Graphics and Realism-Animation, I.2.11 Distributed ArtificialIntelligence-Multi-agent systems }}
@article{Herman:2002:SVG,
author = {Herman,Ivan and Dardailler,Daniel},
title = {{SVG} Linearization and Accessibility},
journal = {Computer Graphics Forum},
volume = {21},
number = {4},
pages = {777-777},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue4/cgf635.pdf},
abstract = { Abstract  The usage of {SVG} (Scaleable Vector Graphics) creates new possibilities as well as new challenges for theaccessibility of Web sites. This paper presents a metadata vocabulary to describe the information content ofan {SVG} file geared towards accessibility. When used with a suitable tool, this metadata description can helpin generating a textual (``linear'') version of the content, which can be used for users with disabilities or withnon-visual devices.  Although this paper concentrates on {SVG}, i.e. on graphics on the Web, the metadata approach and vocabularypresented below can be applied in relation to other technologies, too. Indeed, accessibility issues have a muchwider significance, and have an effect on areas like {CAD}, cartography, or information visualization. Hence, theexperiences of the work presented below may also be useful for practitioners in other areas.  {ACM} {CSS}: I.3.4 Graphics Utilities-Graphics Packages, I.3.6 Methodology and Techniques-Graphics datastructures and data types, Standards, K.4.2 Social Issues-Assistive technologies for persons with disabilities }}
@article{Cecconi:2002:AZI,
author = {Cecconi,Alesandro and Galanda,Martin},
title = {Adaptive Zooming in Web Cartography},
journal = {Computer Graphics Forum},
volume = {21},
number = {4},
pages = {787-787},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue4/cgf636.pdf},
abstract = { Abstract  Beyond any doubt much of the current web mapping and web {GIS} applications lack cartographic quality. Thereasons aren't only the technical limitations related to Internet delivery, but also the neglect of one of the maincartographic principles of digital mapping, namely adaptive zooming. Adaptive zooming describes the adjustmentof a map, its contents and the symbolization to target scale in consequence of a zooming operation. The approachdescribed in this paper proposes the combination of two commonly known concepts: on the one hand levelsof detail (LoD) for those object classes, that require high computational cost for the automated generalizationprocess (e.g. buildings, road network); on the other hand an on-the-fly generalization for those object classeswhich can be generalized by less complex methods and algorithms (e.g. rivers, lakes). Realizing such interactiveand dynamic concept for web mapping requires the use of vector based visualization tools. The data format bestmeeting the criteria is the {W3C} standard Scalable Vector Graphics (SVG). Thus, it has been used to implementthe presented ideas in a prototype application for topographic web mapping based on the landscape modelVECTOR25 of the Swiss Federal Office of Topography. }}
@article{Surazhsky:2002:ERR,
author = {Surazhsky,Tatiana and Elber,Gershon},
title = {Erratum: Artistic Surface Rendering Using Layout of Text},
journal = {Computer Graphics Forum},
volume = {21},
number = {4},
pages = {801-801},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue4/cgf637.pdf}}

@article{Scheel:2002:EGCONF,
author = {Scheel,Annette},
title = {Eurographics 2002},
journal = {Computer Graphics Forum},
volume = {21},
number = {4},
pages = {803-803},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue4/cgf638.pdf}}

@article{Laycock:2002:SIG,
author = {Laycock,Stephen D. and Laycock,Robert G.},
title = {Siggraph 2002},
journal = {Computer Graphics Forum},
volume = {21},
number = {4},
pages = {805-805},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue4/cgf638.pdf}}

@article{Isern:2002:EG2002,
author = {Isern,Jordi Regincos},
title = {Eurographics Spain 11th Conference},
journal = {Computer Graphics Forum},
volume = {21},
number = {4},
pages = {807-807},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue4/cgf638.pdf}}

@article{OSullivan:2002:EGIreland,
author = {O'Sullivan,Carol},
title = {Eurographics Ireland 2002 Workshop},
journal = {Computer Graphics Forum},
volume = {21},
number = {4},
pages = {808-808},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue4/cgf638.pdf}}

@article{Bordegoni:2002:EGItaly,
author = {Bordegoni,Monica},
title = {Eurographics Italy 1st Conference},
journal = {Computer Graphics Forum},
volume = {21},
number = {4},
pages = {810-810},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue4/cgf638.pdf}}

@article{Marcos:2002:CG,
author = {Marcos,Aderito and Brunet,Pere and Jorge,Joaquim and Regincos,Jordi},
title = {1st Ibero-American Symposium in Computer Graphics},
journal = {Computer Graphics Forum},
volume = {21},
number = {4},
pages = {811-811},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue4/cgf638.pdf}}

@article{Debevec:2002:RW,
author = {Debevec,Paul and Gibson,Simon},
title = {13th Eurographics Workshop on Rendering},
journal = {Computer Graphics Forum},
volume = {21},
number = {4},
pages = {813-813},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue4/cgf638.pdf}}

@article{Max:2002:3DPVT,
author = {Max,Nelson},
title = {First International Symposium on {3DPVT} 2002},
journal = {Computer Graphics Forum},
volume = {21},
number = {4},
pages = {814-814},
year = {2002},
URL = {http://www.eg.org/EG/CGF/volume21/issue4/cgf638.pdf}}


</PRE>
	</td>


	</table>

 
<P>

</BODY>
</HTML>
