@article{BartlettTraskin2007,
  author = {Peter L.\ Bartlett and Mikhail Traskin},
  title = {AdaBoost is Consistent},
  journal = {Journal of Machine Learning Research},
  year = {2007},
  volume = {8},
  pages = {2347--2368},
  abstract = {The risk, or probability of error, of the classifier produced by
the AdaBoost algorithm is investigated. In particular, we consider the stopping
strategy to be used in AdaBoost to achieve universal consistency. We show that
provided AdaBoost is stopped after $n^{1-\varepsilon}$ iterations---for sample
size $n$ and $\varepsilon \in (0,1)$---the sequence of risks of the classifiers
it produces approaches the Bayes risk.}
  note = {(Was Department of Statistics, U.C.\ Berkeley Technical Report 722, 
2006)}
}
