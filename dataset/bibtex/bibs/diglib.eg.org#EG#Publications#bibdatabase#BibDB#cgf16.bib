<html><head>     
<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1">
<meta http-equiv="cache-control" content="no-cache">
<meta http-equiv="pragma" content="no-cache">
<META HTTP-EQUIV="EXPIRES" CONTENT="Mon, 22 Jul 2002 11:12:01 GMT">

<SCRIPT SRC="/wavemaster.internal/v2.6/tools-eg_bs/cookie.js"></SCRIPT>
 <STYLE TYPE="text/css"><!--
 .hw-annotation { text-decoration: none; color: black; background:#f3ca81; font-weight: bold; }
--></STYLE>
<META NAME="Author" VALUE="hwsystem">
<META NAME="DocumentType" VALUE="text">
<META NAME="GOid" VALUE="0x811bda11_0x000005b8">
<META NAME="HW_Checksum" VALUE="75ee97ab3f71812bb98007c1c73333cd">
<META NAME="HW_ChildAccess" VALUE="NO_ACCESS">
<META NAME="HW_EffectiveAccess" VALUE="READ_ACCESS">
<META NAME="HW_ObjectName" VALUE="cgf16.bib">
<META NAME="MimeType" VALUE="text/plain">
<META NAME="Name" VALUE="EG/DL/BibDB/cgf16.bib">
<META NAME="ObjectID" VALUE="0x0000000b">
<META NAME="PLACETemplate" VALUE="egnew/master">
<META NAME="Path" VALUE="DC0x00000431 0x0001319b">
<META NAME="Rights" VALUE="R:a, g eg-pub eg-root everyone; W:a, g eg-pub eg-root; A:a">
<META NAME="TimeCreated" VALUE="2007/10/15 08:20:47">
<META NAME="TimeModified" VALUE="2008/01/16 09:54:39">
<META NAME="Title" VALUE="en:cgf16.bib">
<META NAME="Type" VALUE="Document">
<TITLE>cgf16.bib</TITLE>
<BASE HREF="http://diglib.eg.org/EG/DL/BibDB/cgf16.bib">

<style type="text/css">



body,td,p {
	color:#333333;
	font-size:15px;
	font-family: Trebuchet MS, Trebuchet,  Helvetica, Arial, sans-serif;
}

a { text-decoration:none; }

a:link { color:#0099ff; }

a:visited { color:#336699; }

a:active { color:#ff9900; }

a:hover {  color:#ff9900;  }


a.small:link { color:#0099ff;font-size:12px; }

a.small:visited { color:#336699;font-size:12px; }

a.small:active { color:#ff9900;font-size:12px; }

a.small:hover {  color:#ff9900;font-size:12px;  }

.small {
	font-family: Helvetica, Arial, sans-serif;
	font-size:12px;					
	color:#333333;
       }   
h1 {
	font-size: 21px;
	color:#ff9900;
	font-weight: bold;
}
h2 {
	font-size: 18px;
	color:#ff9900;
	font-weight: bold;
	margin-bottom: 0px;
}
h3 {
	margin-bottom: 0px;
	color:#ff9900;
	font-weight: bold;
}
strong {
	color:#666666;
}
.menu{
	background-color:#ffffff;
	font-size:13px;
	font-weight: bold;
	font-family: Trebuchet MS, Trebuchet,  Helvetica, Arial, sans-serif;
	text-align:center;
	line-height: 18px;
        }
.menuselected{
	background-color:#ff9900;
	font-size:13px;
	font-weight: bold;
	color:#000000;
	font-family: Trebuchet MS, Trebuchet, Helvetica, Arial, sans-serif;
	text-align:center;
	line-height: 18px;
        }

.menu a {color:#000000;
		}
.menu a:hover {  color:#ff9900;  
		}
.menu2{
	background-color:#ffffff;
	padding-left:13px; 
	font-size:12px;
	color:#ff9900;
	line-height: 24px;
	font-family: "Trebuchet MS", "Trebuchet", Arial, Helvetica, sans-serif;
        }
.menu2 a {color:#0099ff;
		}
.menu2 a:hover {  color:#ff9900;  
		}
.menu3{
	background-color:#ffffff;
	text-align:center; 
	font-size:13px;
	color:#ff9900;
	line-height: 24px;
	font-family: "Trebuchet MS", "Trebuchet", Arial, Helvetica, sans-serif;
        }
.box1{
	background-color:#ff9900;
	font-size:13px;
	font-weight: bold;
	font-family: Trebuchet MS, Trebuchet,  Helvetica, Arial, sans-serif;
	line-height: 19px;
	color:#ffffff;
	text-align:right;
        }
.box2{
	background-color:#66ccff;
	font-size:13px;
	font-weight: bold;
	font-family: Trebuchet MS, Trebuchet,  Helvetica, Arial, sans-serif;
	line-height: 19px;
	color:#ffffff;
	text-align:right;
        }
.boxtopic{
	text-align:right;
	padding-right:16px; 
        }
.boxcontent {
	font-family: Helvetica, Arial, sans-serif;
	font-size:12px;	
	color:#333333;
	text-align:left;
	padding:16px;
       }
.hr1{
	color:#ff9900;
        }
.hr2{
	color:#66ccff;
        }
.frame1{
	background-color:#ff9900;
        }
.frame2{
	background-color:#66ccff;
        }
.content {border:0; 
	padding-left:12px;
	padding-right:12px;
	}
	

.box3{
   background-color:#66ccff;
   font-size:13px;
   font-weight: bold;
   font-family: Trebuchet MS, Trebuchet,  Helvetica, Arial, sans-serif;
   line-height: 19px;
   color:#ffffff;
   text-align:center;
}

.box4{
   background-color:#66ccff;
   font-size:13px;
   font-weight: bold;
   font-family: Trebuchet MS, Trebuchet,  Helvetica, Arial, sans-serif;
   line-height: 19px;
   color:#ffffff;
   text-align:left;
}

.boxcontent2 {
	font-family: Helvetica, Arial, sans-serif;
	font-size:12px;	
	color:#333333;
	text-align:center;
	padding:10px;
}

.boxcontent3 {
   font-family: Helvetica, Arial, sans-serif;
   font-size:12px;
   color:#333333;
   text-align:right;
   padding:10px;
}

.boxcontent4 {
   font-family: Helvetica, Arial, sans-serif;
   font-size:12px;	
   color:#333333;
   text-align:left;
   padding:10px;
}

	
</style>

</HEAD>
<BODY   alink="#ff9900" bgcolor="#FFFFFF" link="#0099ff" text="#000000" vlink="#336699">






<table width="761" border="0" align="left" cellpadding="0" cellspacing="0">
  <!--DWLayoutTable-->
  <tr> 
    <!--The Logo will be shown next: -->


    <td>

    	<table width="144" border="0" cellspacing="0" cellpadding="1" class=frame1>

    		<tr>

    		<td width="142" align="center"><a href="http://www.eg.org/"><img src="http://diglib.eg.org/v2.6/graphics/new/logo.gif;internal&inline=true" alt="EG - Logo" width="142" height="110" border="0"></a></td>

    		</tr>

    	</table>

    </td>

    <td width="17"><img src="http://diglib.eg.org/v2.6/graphics/new/spacer.gif;internal&inline=true" width="17" height="1"></td>

    <td>

    	<table width="600" border="0" cellspacing="0" cellpadding="1" class=frame1>

    		<tr>

    		<td width="598"><img src="http://diglib.eg.org/v2.6/graphics/new/head.gif;internal&inline=true" alt="EuroGraphics" width="598" height="110"></td>

    		</tr>

    	</table>

    </td>

    

    

    

  </tr>
  <tr> 
    <td colspan="3" width="761" height="17"><img src="news-Dateien/spacer.gif" width="1" height="17"></td>
  </tr>
  <tr> 
    <td width="144" valign="top"> 
           
      <!--The Member Login Box will be shown next: -->
      <table width="100%" border="0" cellspacing="0" cellpadding="1" class=frame1>

<TBODY>
<TR>
   <TD>
            <TABLE border=0 cellPadding=0 cellSpacing=0 width="100%">
              <TBODY>
              <TR>
                <TD align=right bgColor=#cccccc class=box1><SPAN 
                  class=boxtopic>Members</SPAN></TD></TR>
              <TR>
                <TD bgColor=#ffffff>
                  <DIV class=boxcontent>
                  Please 

                  <A  HREF="http://www.eg.org/login">login</A> 
                  
                  
                  
                  <!--(note for <a href="/safari.html">Safari users</a>)-->
                  if you are a member or <a  href="/about/membership">read more</a> about the advantages of an EG membership.
                  <HR class=hr1 noShade SIZE=1>
                  <br>
                  
                  Not yet member? <A HREF="/join">Application</A><br>
                  <A HREF="https://www.eg.org/renew">Renewal</A>
                  <HR class=hr1 noShade SIZE=1>
                  Forgot your password? <A HREF="http://diglib.eg.org/EG/DL/BibDB/cgf16.bib;internal&action=forgot.password.action">Click  here!</A> 
                 </DIV></TD>  
                 </TR></TBODY></TABLE></TD></TR></TBODY>
      </table>
      <br> 
      <!--The New Box will be shown next: -->
      <table width="100%" border="0" cellspacing="0" cellpadding="1" class="frame2">
<tr>
	<td>
		<table border="0" cellpadding="0" cellspacing="0" width="100%">
        	<tbody><tr>
           		<td class="box2" align="right" bgcolor="#cccccc"><span class="boxtopic">EG 2009</span></td>
			</tr>
			<tr>
           		<td bgcolor="#ffffff">
				<div class="boxcontent">
				
                <a href="http://www.eurographics2009.de/">Eurographics 2009:</a> 30th of March to the 3rd of April 2009 in Munich (Germany).
				<hr noshade class="hr2" size="1" >
				<!--<a href="http://www.ics.forth.gr/eg2008/" target="_blank"><img src="/EG/images/eg2k8.png" border="0" height="23" width="103"></a>
			         EG08 will be from 14th to the 18th April 2008
                              <hr class="hr2" noshade="noshade" size="1">-->

                          <!--
                        Eurographics 2007: 3rd to the 7th September 2007 in Prague (Czech Republic).
				<hr noshade class="hr2" size="1" >
				Previous Event: <a href="http://www.cgg.cvut.cz/eg07/">Eurographics 2007</a>
				-->
                       <!-- Eurographics 2006: 4th - 8th of September 2006 in Vienna (Austria)<br>
                        <hr noshade class="hr2" size="1" >-->
			<!--    Previous Event: <a href="http://www.cg.tuwien.ac.at/events/EG06/index.html">Eurographics 2006</a>>-->
                                Previous Event: <a href="http://www.ics.forth.gr/eg2008/">Eurographics 2008</a>
				</div>
				</td>
			</tr>
		</tbody></table>
	</td>
</tr>
      </table>
      <br>

      
    </td>
    <td>&nbsp;</td>

	<td valign="top">

                <PRE>
@article{Berg:1997:TAD,
   author = {Mark de Berg},
   title = {Trends and Developments in Computational Geometry},
   volume = {16},
   number = {1},
   journal = {Computer Graphics Forum},
   year = {1997},
   pages = {3-30},
   note = {{ISSN} 0167-7055},
   keywords = {computational geometry},
   annote = {This paper discusses some trends and achievements
in computational geometry during the past five years, with
emphasis on problems related to computer graphics. Furthermore,
a direction of research in computational geometry is discussed
that could help in bringing the fields of computational geometry
and computer graphics closer together. },
}
@article{Bloomenthal:1997:BEI,
   author = {Jules Bloomenthal},
   title = {Bulge Elimination in Convolution Surfaces},
   volume = {16},
   number = {1},
   journal = {Computer Graphics Forum},
   year = {1997},
   pages = {31-41},
   note = {{ISSN} 0167-7055},
   keywords = {blend, bulge, convolution, geometric modeling,
implicit surface, skeleton},
   annote = {The relationship between surface bulge and several
implicit blend techniques, particularly those based on
convolution of a skeleton, is discussed. An examination of
branching skeletons reveals that for two and three-dimensional
skeletons, the surface will be bulge-free if skeletal elements
are sufficiently large with respect to the convolution kernel.
},
}
@article{Notkin:1997:PPR,
   author = {Irena Notkin and Craig Gotsman},
   title = {Parallel Progressive Ray-tracing},
   volume = {16},
   number = {1},
   journal = {Computer Graphics Forum},
   year = {1997},
   pages = {43-55},
   note = {{ISSN} 0167-7055},
   keywords = {ray tracing, adaptive sampling, load balancing},
   annote = {A dynamic task allocation algoritm for ray-tracing
by progressive refinement on a distributed-memory parallel
computer is described. Paralleliztition of progressive
ray-tracing is difficult because of the inherent sequential
nature of the sample location generation process. which is
optimized (and different) for any given image. We report on
experimental results obtained.from our implementation of this
algorithm on a Meiko parallel computer. The three performance
measures of the algorithm, namely, load-balance, speedup, and
image quality, are shown to be good. },
}
@article{Jensen:1997:RCO,
   author = {Henrik Wann Jensen},
   title = {Rendering Caustics on Non-Lambertian Surfaces},
   volume = {16},
   number = {1},
   journal = {Computer Graphics Forum},
   year = {1997},
   pages = {57-64},
   note = {{ISSN} 0167-7055},
   keywords = {caustics, photon map, filtering, Monte Carlo ray
tracing, rendering},
   annote = {This paper presents a new technique for rendering
caustics on non-Lambertian surfaces. The method is based on an
extension of the photon map which removes previous restrictions
limiting the usage to Lambertian surfaces. We add information
about the incoming direction to the photons and this allows us
to combine the photon map with arbitrary reflectance functions.
By using a cone-filter we improve the quality of the radiance
estimate in particular at discontinuities. Furthermore we
introduce balancing of the photon map which not only reduces the
memory requirements but also significantly reduces the rendering
time. We have used the method to render caustics on surfaces
with reflectance functions varying from Lambertian to glossy
specular. },
}
@article{Havaldar:1997:SNV,
   author = {Parag Havaldar and Mi-Suen Lee and G{\'{e}}rard
Medioni},
   title = {Synthesizing Novel Views from Unregistered 2-D
Images},
   volume = {16},
   number = {1},
   journal = {Computer Graphics Forum},
   year = {1997},
   pages = {65-73},
   note = {{ISSN} 0167-7055},
   keywords = {image based rendering, projective invariants,
epipolar geometry},
   annote = {This paper presents a new technique for rendering
caustics on non-Lambertian surfaces. The method is based on an
extension of the photon map which removes previous restrictions
limiting the usage to Lambertian surfaces. We add information
about the incoming direction to the photons and this allows us
to combine the photon map with arbitrary reflectance functions.
By using a cone-filter we improve the quality of the radiance
estimate in particular at discontinuities. Furthermore we
introduce balancing of the photon map which not only reduces the
memory requirements but also significantly reduces the rendering
time. We have used the method to render caustics on surfaces
with reflectance functions varying from Lambertian to glossy
specular. },
}
@article{Hart:1997:IRO,
   author = {John C. Hart},
   title = {Implicit Representation of Rough Surfaces},
   volume = {16},
   number = {2},
   journal = {Computer Graphics Forum},
   year = {1997},
   pages = {91-99},
   note = {{ISSN} 0167-7055},
   annote = {Implicit surface techniques provide useful tools
for modeling and rendering smooth surfaces. Deriving implicit
formulations for fractal representations extends the scope of
implicit surface techniques to rough surfaces. Linear fractals
modeled by recurrent iterated function systems may be defined
implicitly using either geometric distance or escape time.
Random fractals modeled using Perlin's noisefunction are already
defined implicitly when described as &quot;hypertexture.&quot; Deriving
new implicit formulae is only the first step. Unlike their
smooth counterparts, rough implicit surfaces require special
rendering techniques that do not rely on continuous
differentiation of the defining function. Preliminary
experiments applying blending operations to rough surfaces have
succeeded in an initial attempt to overcome current challenges
in natural modeling. The grafting of a stem onto the base of a
linear fractal leaf continuously blends smooth detail into rough
detail. The blend of two textured cylinders interpolates
geometric bark across branching points in a tree. },
}
@article{Yao:1997:ARI,
   author = {Chengfu Yao and Jon G. Rokne},
   title = {Applying Roughing-Up Integral Linear Interpolation
to the Scan-Conversion of Filled Polygons},
   volume = {16},
   number = {2},
   journal = {Computer Graphics Forum},
   year = {1997},
   pages = {101-106},
   note = {{ISSN} 0167-7055},
   keywords = {integral linear interpolation, scan-conversion,
polygons},
   annote = {This paper is motivated by a special linear
interpolation problem encountered in scan-line algorithms for
scan-conversion of filled polygons. Rounding-up integral linear
interpolation is defined and its efficient computation is
discussed. The paper then incorporates rounding-up integral
linear interpolation into a scan-line algorithm forfilled
polygons, and it discusses the implementation of the algorithm.
This approach has the advantage of only requiring integer
arithmetic in the calculations. Furthermore, the approach
provides a unified treatment for calculating span extrema for
left and right edges of the polygon that guarantees the mutual
exclusiveness of the ownership of boundary pixels of two filled
polygons sharing an edge. },
}
@article{Shaw:1997:HRF,
   author = {Erin Shaw},
   title = {Hierarchical Radiosity for Dynamic Environments},
   volume = {16},
   number = {2},
   journal = {Computer Graphics Forum},
   year = {1997},
   pages = {107-118},
   note = {{ISSN} 0167-7055},
   keywords = {radiosity, dynamic environment, ghost link,
shadow link, mesh folding, motion volume},
   annote = {This paper extends the hierarchical radiosity
method to environments in which geometry and surface attributes
can be changed dynamically. New algorithms are presented for
maintaining an appropriately-sized mesh and speeding the
construction of the corresponding linear system. Mesh folding,
the unrefinement of a mesh, is used to optimize mesh size while
maintaining a specified error tolerance. Two new interactions
are introduced: shadow links guide local shadow clean up after a
change in geometry and ghost links guide global mesh folding
after a change in surface attributes. The algorithms stabilize
the memory requirements of dynamic scenes. Different types of
interactions are analyzed to determine how they are affected by
changes in geometry. A dynamic scene-partitioning scheme called
a motion volume, used in conjunction with a three-dimensional
clipping algorithm, provides a fast way to cull interactions
that do not need to be updated. The algorithms are demonstrated
on several sample scenes. },
}
@article{Zalik:1997:AEC,
   author = {Borut Zalik and Gordon Clapworthy and Crtomir
Oblonsek},
   title = {An Efficient Code-Based Voxel-Traversing Algorithm},
   volume = {16},
   number = {2},
   journal = {Computer Graphics Forum},
   year = {1997},
   pages = {119-128},
   note = {{ISSN} 0167-7055},
   keywords = {uniform space subdivision, voxel, voxel
traversing, ray tracing},
   annote = {The paper considers an efficient approach to
traversing a uniformly-subdivided space pierced by a line
segment. A voxel, as the basic constituent element of the
uniformly subdivided space, is restricted to having the form of
a cube. The algorithm works in two steps. In the first step, the
so-called Bresenham voxels are identified and, by comparing
their position codes, their type of connectivity is determined.
To achieve the required connectivity between neighbouring
voxels, the second step of the algorithm is applied to find the
missing voxels. In this way, the algorithm efficiently switches
between face-, edge- and vertex-connectivity. Although the
algorithm works with floating-point precision, it is extremely
computationally efficient, and tests of speed compared with the
Miller, Cleary \&amp; Wyvill, Amanatides },
}
@article{Gibson:1997:PR,
   author = {S. Gibson and R. J. Hubbold},
   title = {Perceptually-Driven Radiosity},
   volume = {16},
   number = {2},
   journal = {Computer Graphics Forum},
   year = {1997},
   pages = {129-141},
   note = {{ISSN} 0167-7055},
   keywords = {radiosity, visual perception, adaptation,
tone-reproduction, just-noticeable differences, adaptive
refinement, shadow detection, mesh optimisation},
   annote = {We present a new approach to radiosity simulation
that uses perceptually-based measures to control the generation
of view-independent radiosity solutions. This enables
computational effort to be moved away from areas that are deemed
to have a visually insignificant effect on the solution's
appearance, into those that are more noticeable. We achieve this
with an a-priori estimate of the real-world adaptation
luminance, and use a tone-reproduction operator to transform
luminance values to display colours during the solution process.
The distance between two colours in a perceptually-uniform
colour space is then used as a numerical measure of their
perceived difference. We describe an oracle that stops patch
refinement once the difference between successive levels of
elements becomes perceptually unnoticeable. We also show how the
perceived importance of any potential shadow falling across a
receiving element can be determined. This is then used to
control the number of rays that are cast during visibility
computations, giving reductions of almost 93% in the total
number of rays required for a solution without any significant
loss in image quality. Finally, we discuss how perceptual
knowledge can be used to optimise the element mesh for faster
interactive display and to save memory during computation. },
}
@article{Andres:1997:TS3,
   author = {E. Andr{\'{e}}s and P. Nehlig and J.
Fran{\c{c}}on},
   title = {Tunnel-Free Supercover {3D} Polygons and Polyhedra},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {3-14},
   note = {{ISSN} 1067-7055},
   keywords = {Discrete {3D} Modelling, Discrete Lines, Discrete
Planes, Discrete Polygons, Discrete Polyhedra, Supercover},
   annote = {A new discrete {3D} line and {3D} polygon, called
Supercover {3D} line and Supercover {3D} polygon, are introduced.
Analytical definitions are provided. The Supercover {3D} polygon
is a tunnel free plane segment defined by vertices and edges. An
edge is a Supercover {3D} line segment. Two different polygons can
share a common edge and if they do, the union of both polygons
is tunnelfree. This definition of discrete polygons has the
&quot;most&quot; properties in common with the continuous polygons. It is
particularly interesting for modeling of discrete scenes,
especially using tunnel-free discrete polyhedra. Algorithms for
computing Supercover {3D} Lines and Polygons are given and
illustrated. Proceedings of Eurographics '97. },
}
@article{Thurmer:1997:NCF,
   author = {G. Th{\&quot;{u}}rmer and C. A. W{\&quot;{u}}thrich},
   title = {Normal Computation for Discrete Surfaces in {3D}
Space},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {15-26},
   note = {{ISSN} 1067-7055},
   keywords = {normal computation, discrete shading, discrete
surfaces, visualization},
   annote = {Associating normal vectors to surfaces is essential
for many rendering algorithms. We introduce a new method to
compute normals on discrete surfaces in object space. Assuming
that the surface separates space locallv into two disjoint
subsets, each of these subsets contains implicitly information
about the surface inclination. Considering one of these subsets
in a small neighbourhood of a surface point enables us to derive
the surface normal from this set. We show that this leads to
exact results for C1 continuous surfaces in R3. Furthermore, we
show that good approximations can be obtained numerically by
sampling the considered area. Finally, we derive a method for
normal computation on surfaces in discrete space. Proceedings of
Eurographics '97. },
}
@article{Kazinnik:1997:ODO,
   author = {R. Kazinnik and G. Elber},
   title = {Orthogonal Decomposition of Non-Uniform Bspline
Spaces using Wavelets},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {27-38},
   note = {{ISSN} 1067-7055},
   annote = {We take advantage of ideas of an orthogonal wavelet
complement to produce multiresolution orthogonal decomposition
of nonuniform Bspline (NUB) spaces. The editing of {NUB} curves
and surfaces can be handled at different levels of resolutions.
Applying Multiresolution decomposition to possibly C1
discontintious surfaces, one can preserve the general shape on
one hand and local features on the other of the free-form
models, including geometric discontinuities. The Multiresolution
decomposition of the {NUB} tensor product surface is computed via
the symbolic computation of innerproducts of Bspline basis
functions. To find a closed form representationfor the
innerproduct of the Bspline basis functions, an equivalent
interpolation problem is solved. As an example for the strength
of the Multiresolution decomposition, a tool demonstrating the
Multiresolittion editing capabilities of {NUB} surfaces was
developed and is presented as part of this work, allowing
interactive {3D} editing of {NUB} free-form surfaces. Proceedings of
Eurographics '97. },
}
@article{Kuriyama:1997:PSM,
   author = {S. Kuriyama and K. Tachibana},
   title = {Polyhedral Surface Modeling with a Diffusion
System},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {39-46},
   note = {{ISSN} 1067-7055},
   keywords = {Curves and Surfaces, Diffusion Systems,
Polyhedral Surfaces, Tension Controls},
   annote = {This paper presents a method of generating
polyhedral surfaces by using a diffusion system that calculates
the positional and normal vectors on their vertices. The system
generates smooth shapes that satisfy the minimum norm property,
and can be extended to imitate the shape controls of curvature
continuous surfaces with bias and tension parameters. The shape
of a surface is determined by the stable state of nonlinear and
local calculations between vertices, and is easily controlled by
adding constraints on arbitrary vertices. Such bottom-up
calculation of surfaces enhances flexibility in the interactive
design of complicated free-form shapes. Proceedings of
Eurographics '97. },
}
@article{Li:1997:IRO,
   author = {F. W. B. Li and R. W. H. Lau and M. Green},
   title = {Interactive Rendering of Deforming {NURBS} Surfaces},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {47-56},
   note = {{ISSN} 1067-7055},
   annote = {Non-uniform rational B-splines (NURBS) has been
widely accepted as a standard tool for geometry representation
and design. Its rich geometric properties allow it to represent
both analytic shapes and free-form curves and surfaces
precisely. Moreover, a set of tools is available for shape
modification or more implicitly, object deformation. Existing
NURBS rendering methods include de Boor algorithm, Oslo
algorithm, Shantz's adaptive forward differencing algorithm and
Silbermann's high speed implementation of {NURBS}. However, these
methods consider only speeding up the rendering process of
individual frames. Recently, Kumar et al. proposed an
incremental method for rendering {NURBS} surfaces, but it is still
limited to static surfaces. In real-time applications such as
virtual reality, interactive display is needed If a virtual
environment contains a lot of deforming objects, these methods
cannot provide a good solution. In this paper we propose an
efficient method for interactive rendering of deformable objects
by maintaining a polygon model of each deforming {NURBS} surface
and adaptively refining the resolution of the polygon model. We
also took at how this method may be applied to multi-resolution
modelling. Proceedings of Eurographics '97. },
}
@article{Aubert:1997:ABD,
   author = {F. Aubert and D. Bechmann},
   title = {Animation by Deformation of Space-Time Objects},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {57-66},
   note = {{ISSN} 1067-7055},
   keywords = {Animation, Space deformation, Metamorphosis,
Space-time object, Fourth dimension, Geometric modelling, Motion
modelling},
   annote = {This article presents the properties of animation
with space-time objects. A space-time object means here a
geometrical object embedded in R4 with a volumic topology.
Resulting animations are obtained by deforming space-time
objects with a free-form deformation model. In this way
topological modifications, such as disconnecting or hole making,
as well as classical geometrical modifications, can be created
in an animated object. Proceedings of Eurographics '97. },
}
@article{Krishnan:1997:IBC,
   author = {S. Krishnan and M. Gopi and D. Manocha and M.
Mine},
   title = {Interactive Boundary Computation of Boolean
Combinations of Sculptured Solids},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {67-78},
   note = {{ISSN} 1067-7055},
   annote = {We present algorithms and systems for interactive
boundary computation of Boolean combinations of sculptured
solids. The algorithm is applicable to all spline solids and
computes an accurate boundary representation. To speed up the
computation, the algorithm exploits parallelism at all stages.
It has been implemented on a multi-processor {SGI} and takes one
second on average per boolean operation to compute the boundary
of high degree primitives. The system has also been integrated
with an immersive design and manipulation environment. The
resulting system is able to interactively evaluate boundaries of
the models, display them for model validation and place them at
appropriate position using collision detection algorithms.
Proceedings of Eurographics '97. },
}
@article{Nakamura:1997:RCO,
   author = {H. Nakamura and M. Higashi and M. Hosaka},
   title = {Robust Computation of Intersection Graph between Two
Solids},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {79-88},
   note = {{ISSN} 1067-7055},
   keywords = {solid model, Boolean operation, robust
algorithm},
   annote = {We propose a new robust algorithm for Boolean
operations on solid models. The algorithm produces a consistent
intersection graph between two input solids whose geometrical
data are represented in floating point numbers. In order to
prevent numerical calculation errors and inaccuracy of input
data from causing inconsistency of the output, we put higher
priority on symbolical connectivity of the edge-face
intersection points than their numerical nearness. Each
edge-face intersection point is symbolically represented using
face names, which generate connectivity relations between the
intersection points and the intersection line segments. The
symbols with the same connectivity are made into clusters. The
intersection line segments connected together at their end
clusters form the intersection graph of two solids.
Inconsistency of the connectivity of the clusters is detected
and the intersection graph is corrected automatically. We
describe the algorithm in detail for polyhedral solids, discuss
extension to curved solids, and show its effectiveness by some
examples of Boolean operations for two solids whose faces
intersect at a very small angle. Proceedings of Eurographics
'97. },
}
@article{Peters:1997:CVO,
   author = {J. Peters and A. Nasri},
   title = {Computing Volumes of Solids Enclosed by Recursive
Subdivision Surfaces},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {89-94},
   note = {{ISSN} 1067-7055},
   annote = {The volume of a solid enclosed by a recursive
subdivision surface can be approximated based on the closed-form
representation of regular parts of the subdivision surface and a
tight estimate of the local convex hull near extraordinary
points. The approach presented is efficient, i.e.
non-exponential, and robust in that it yields rapidly
contracting error bounding boxes. An extension to measuring
higher-order moments is sketched. Proceedings of Eurographics
'97. },
}
@article{Lippert:1997:CDV,
   author = {L. Lippert and M. H. Gross and C. Kurmann},
   title = {Compression Domain Volume Rendering for Distributed
Environments},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {95-108},
   note = {{ISSN} 1067-7055},
   keywords = {volume rendering, multiresolution, progressive
compression, splatting, wavelets, networks, distributed
applications},
   annote = {This paper describes a method for volume data
compression and rendering which bases on wavelet splats. The
underlying concept is especially designed for distributed and
networked applications, where we assume a remote server to
maintain large scale volume data sets, being inspected, browsed
through and rendered interactively by a local client. Therefore,
we encode the server's volume data using a newly designed
wavelet based volume compression method. A local client can
render the volumes immediately from the compression domain by
using wavelet footprints, a method proposed earlier In addition,
our setup features full progression, where the rendered image is
refined progressively as data comes in. Furthermore, frame rate
constraints are considered by controlling the quality of the
image both locally and globally depending on the current network
bandwidth or computational capabilities of the client. As a very
important aspect of our setup, the client does not need to
provide storage for the volume data and can be implemented in
terms of a network application. The underlying framework enables
to exploit all advantageous properties of the wavelet transform
and forms a basis for both sophisticated lossy compression and
rendering. Although coming along with simple illumination and
constant exponential decay, the rendering method is especially
suited for fast interactive inspection of large data sets and
can be supported easily by graphics hardware. Proceedings of
Eurographics '97. },
}
@article{Sadarjoen:1997:DST,
   author = {I. A. Sadarjoen and F. H. Post},
   title = {Deformable Surface Techniques for Field
Visualization},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {109-116},
   note = {{ISSN} 1067-7055},
   keywords = {scientific visualization, surface extraction,
deformable surface, feature extraction},
   annote = {Surface extraction from data fields is often used
in scientific visualization, as surfaces can represent
meaningful information and they are well suited for display.
This paper describes a general method for localized surface
extraction from scalar and vector fields. An initial polygonal
surface is placed within the field, and the shape of the surface
is adapted to the field by iterative displacement of surface
nodes according to a displacement criterion. To achieve a good
approximation of a smooth surface, the polygon mesh can be
locally refined during iteration. The type of surface extracted
depends on the displacement criterion, which can be any junction
of the available field variables. Techniques for displacement
and mesh refinement are discussed in detail. The results we show
are generation of a local isosurface and extraction of a vortex
tube. Finally, we will draw conclusions and discuss some issues
for further development. Proceedings of Eurographics '97. },
}
@article{Westermann:1997:AMA,
   author = {R. Westermann and T. Ertl},
   title = {A Multiscale Approach to Integrated Volume
Segmentation and Rendering},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {117-128},
   note = {{ISSN} 1067-7055},
   annote = {A number of techniques have been proposed for
rendering volumetric scalar data sets. Techniques have also been
proposed for analyzing the three dimensional information
contents of the underlying domain, but traditionally the data
analysis part is left as a post-processing step which only
involves the rendered two dimensional images. In this paper, we
describe a visualization method for scalar volume data which
integrates explicit knowledge of the underlying domain into the
rendering process. The key of this approach lies in a
hierarchical description of the discrete signal, which is
decomposed into a sequence of multiscale representations. We
describe a technique for the analysis of structures within the
data. This allows for the segmentation and classification of the
relevant features and can be used to improve their visual
sensation. We also address the problem of accelerating the final
rendering pass by integrating the extracted object space
information into the ray traversal process. Proceedings of
Eurographics '97. },
}
@article{Dischler:1997:APD,
   author = {J.-M. Dischler and D. Ghazanfarpour},
   title = {A Procedural Description of Geometric Textures by
Spectral and Spatial Analysis of Profiles},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {129-140},
   note = {{ISSN} 1067-7055},
   keywords = {Automatic textures synthesis, geometric textures,
bump mapping, hypertextures, spectral and spatial analysis},
   annote = {In this paper we describe a method for
automatically generating procedural &quot;geometric&quot; textures, using
a hybrid (spectral and spatial) analysis of profiles (1D
curves). The profile describes a certain height variation for a
certain abscissa. We call &quot;geometric&quot; textures a class of
textures including &quot;Bump&quot; textures and &quot;hypertextures.&amp; quot; In
dealing with this challenge (automatic synthesis), we introduce
two new key ideas. The first is to compute efficiently a compact
and procedural description of the texture, bv using a spectral
(Fourier transform based) and spatial (histogram based)
analytical approach of profiles. The resulting texture is
defined as a sum of elementary random functions. This sum is
generated according to the profile. The procedural description
allows the direct computation of the texture values at any
co-ordinates in the Euclidean space and the stochastic aspect of
the elementary functions also allows for the processing of
highly random textures, with no considerable increase of
computation time. The second key idea consists of using analysis
in the particular and more complex case of geometric textures.
For most analytical methods, underlying geometry is never
considered. Using profiles as models, the resulting geometric
texture is obtained bv extending this profile to {2D} or {3D} space.
The resulting texture directly matches the supplied {1D} model.
Hence, our method promises to be a verv useful tool for easily
and efficiently &quot;modelling&quot; any kind of geometric textures
including rocks, bumps, peaks, fur, cotton and so on.
Proceedings of Eurographics '97. },
}
@article{Baranoski:1997:AAR,
   author = {G. V. G. Baranoski and J. G. Rokne},
   title = {An Algorithmic Reflectance and Transmittance Model
for Plant Tissue},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {141-150},
   note = {{ISSN} 1067-7055},
   keywords = {Physically-Based Rendering, Biologically-Based
Rendering, {BRDF}, {BTDF}, {BDF}, Absorption},
   annote = {Recent developments in rendering have provided very
realistic images. However these images rarely show organic
objects. We believe that one of the main difficulties of
rendering these objects realistically is the lack of reflectance
and transmittance models oriented to organic materials. In this
paper an algorithmic reflectance and transmittance model for
plant tissue oriented to computer graphics applications is
presented. The model accounts for the three components of light
propagation in plant tissues, namely surface reflectance,
subsurface reflectance and transmittance, and mechanisms of
light absorption by pigments present in these tissues. The model
design is based on the available biological information, and it
is controlled by a small number of biologically meaningful
parameters. Its formulation, based on standard Monte Carlo
techniques, guarantees its easy incorporation into most
rendering systems. The spectral curves of reflectance and
transmittance computed by the model are compared with measured
curves from actual experiments. Proceedings of Eurographics '97.
},
}
@article{Walter:1997:GAA,
   author = {M. Walter and A. Fournier},
   title = {Growing and Animating Polygonal Models of Animals},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {151-158},
   note = {{ISSN} 1067-7055},
   keywords = {animal models, polygonal meshes, growth,
animation, shape evolution},
   annote = {While there exist many computer models of animal
bodies, as polygonal meshes and parametric surfaces, these are
difficult to modify to take growth into account, or to animate.
Growth data availablefrom the literature usually is expressed as
very sparse measurements over the body at various ages of the
animal. We present here basic techniques to transfer growth data
to computer models (especially polygonal meshes), which allows
animation of the growth as well as animation of the body, in the
traditional sense. The main technique consists of defining local
coordinate systems around the growing parts of the botv, each
one being transformed according to the relevant growth data
while maintaining their relationship with the adjoining parts
and the continuity of the surface. The local coordinates also
permit ordinary animation mainly as relative rotation such as in
articulated objects. We present examples with polygonal models
of horses and cows, groivth data from same, and motion from
Muybridge's classic photographic data. Proceedings of
Eurographics '97. },
}
@article{Stam:1997:SDS,
   author = {Jos Stam},
   title = {Stochastic Dynamics: Simulating the Effects of
Turbulence on Flexible Structures},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {159-164},
   note = {{ISSN} 1067-7055},
   annote = {This paper addresses the problem of realistically
simulating the motion of tree-branches subjected to turbulence.
Since the resulting motion is random in nature, we model it as a
stochastic process. We synthesize this process directly
byfiltering a white noise in the Fourier domain. The filter is
constructed by performing a modal analysis of the tree. We use a
sophisticated numerical technique which is able to compute the
first few significant modes of large trees, The main advantage
of our technique over previous methods is that we are able to
compute complicated motions without the necessity of integrating
dynamical equations over time. Consequently, a user can view and
manipulate tree-motions in real-time. Our technique can be
further extended to other flexible structures such as
two-dimensional plates. Proceedings of Eurographics '97. },
}
@article{Komura:1997:AMF,
   author = {T. Komura and Y. Shinagawa and T. L. Kunii},
   title = {A Muscle-based Feed-forward Controller of the Human
Body},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {165-176},
   note = {{ISSN} 1067-7055},
   annote = {There is an increasing demand for human body motion
data. Motion capture and physical animation have been used to
generate such data. It is, however, apparent that such methods
cannot automatically generate arbitrary human body motions. A
human body is a redundant multi-linked body controlled by a
number of muscles. For this reason, the muscles must work
appropriately and cooperatively for controlling the whole body.
It is well-known that the human body control system is composed
of two parts: The open-loop feed-forward control system and the
closed-loop feedback control system. Many researchers have
investigated the characteristics of the latter by analyzing the
response of a human body to various external perturbations.
However, for the former, very few studies have been done. This
paper proposes an open-loop feed-forward model of of the lower
extremities which includes postural control for accurate
animation of a human body. Assumptions are made here that the
feed-forward controller minimizes a certain objective value
while keeping the balance of the bodv stable. The actual human
motion data obtained using a motion capturing technique is
compared with the trajectory calculated using our method for
verification. The best criteria which is based on muscle
dynamics is proposed. Using our method, dynamically correct
human animation can be created by merely specifying a few key
postures. Proceedings of Eurographics '97. },
}
@article{Pandzic:1997:AFA,
   author = {I. S. Pandzic and T. K. Capin and E. Lee and N.
Magnenat Thalmann and D. Thalmann},
   title = {A Flexible Architecture for Virtual Humans in
Networked Collaborative Virtual Environments},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {177-188},
   note = {{ISSN} 1067-7055},
   keywords = {virtual humans, networked virtual environments,
virtual environment software architecture, experimental
evaluation},
   annote = {Complex virtual human representation provides more
natural interaction and communication among participants in
networked virtual environments, hence it is expected to increase
the sense of being together within the same virtual world. We
present a flexible framework for the integration of virtual
humans in networked collaborative virtual environments. A
modular architecture allows flexible representation and control
of the virtual humans, whether they are controlled by a physical
user using all sorts of tracking and other devices, or by an
intelligent control program turning them into autonomous actors.
The modularity of the system allows for fairly easy extensions
and integration with new techniques making it interesting also
as a testbed for various domains from &quot;classic&quot; {VR} to
psychological experiments. We present results in terms of
functionalities, example applications and measurements of
perforinance and network traffic with an increasing number
ofparticipants in the simulation. Proceedings of Eurographics
'97. },
}
@article{Mason:1997:AHL,
   author = {A. E. W. Mason and E. H. Blake},
   title = {Automatic Hierarchical Level of Detail Optimization
in Computer Animation},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {191-200},
   note = {{ISSN} 1067-7055},
   annote = {We show that the hierarchical level of detail
optimization problem is equivalent to a constrained version of
the Multiple Choice Knapsack Problem, and present a new
algorithm whose solution to it is at least half as good as the
optimal one. The advantage of the hierarchical algorithm is that
it allows the use of hierarchical level of detail descriptions
in which shared representations mav he provided for groups of
objects. Rendering cost mav then be saved to afford better
renderings of more important objects, and the algorithm is
capable of providing a complete representation of the visible
scene even when the visible scene complexity is very high. Our
algorithm has a worst case time complexity of O(n logn), and is
incremental so that it typically completes in only a few
iterations. We introduce the use of perceptual evaluation to
demonstrate the effectiveness of the use of representation for
groups of objects that our algorithm allows. Proceedings of
Eurographics '97. },
}
@article{Mann:1997:SPT,
   author = {Y. Mann and D. Cohen-Or},
   title = {Selective Pixel Transmission for Navigating in
Remote Virtual Environments},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {201-206},
   note = {{ISSN} 1067-7055},
   annote = {This paper presents a technique to improve the
performance of a walkthrough in remote virtual environments,
where a qcene is rendered jointly by the server and the client,
in order to reduce the network requirements as much as possible.
The client generates novel views by extrapolating a reference
view based on the locally available geometric model, while the
server transmits data necessary to prevent an accumulation of
errors. Within this concept, we show that by transmitting only a
selected subset of pixels, the quality of the extrapolated views
can be improved while requiring less bandwidth. We focus on the
selection process in which the visibility gaps between the
reference view and novel view are detected, packed and
transmitted compressed to the client. Proceedings of
Eurographics '97. },
}
@article{Sillion:1997:EIM,
   author = {Fran{\c{c}}ois X. Sillion and G. Drettakis and B.
Bodelet},
   title = {Efficient Impostor Manipulationfor Real-Time
Visualization of Urban Scenery},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {207-218},
   note = {{ISSN} 1067-7055},
   keywords = {Visualization of large datasets, Image-based
rendering, Image caching, Impostors, Urban scenes},
   annote = {Urban environments present unique challenges to
interactive visualization systems, because of the huge
complexity of the geometrical data and the widely varying
visibility conditions. This paper introduces a new framework for
real-time visualisation of such urban scenes. The central
concept is that of a dynamic segmentation of the dataset, into a
local three-dimensional model and a set of impostors used to
represent distant scenery. A segmentation model is presented,
based on inherent urban structure. A new impostor structure is
introduced, derived from the level-of-detail approach. Impostors
combine three-dimensional geometry to correctly model large
depth discontinuities and parallax, and textures to rapidly
display visual detail. We present the algorithms necessary for
the creation of accurate and efficient three-dimensional
impostors. The implementation of our algorithms allows
interactive navigation in complex urban databases, as required
by many applications. Proceedings of Eurographics '97. },
}
@article{Loscos:1997:IHS,
   author = {C. Loscos and G. Drettakis},
   title = {Interactive High-Quality Soft Shadows in Scenes with
Moving Objects},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {219-230},
   note = {{ISSN} 1067-7055},
   keywords = {Illumination, soft shadows, incremental update,
discontinuity meshing, backprojection, dynamic scenes},
   annote = {Interactive rendering of soft shadows (or penumbra)
in scenes with moving objects is a challenging problem. High
quality walkthrough rendering of static scenes with penumbra can
be achieved using pre-calculated discontinuity meshes, which
provide a triangulation well adapted to penumbral boundaries,
and backprojections which provide exact illumination computation
at vertices very efficiently. However recomputation of the
complete mesh and back-projection structures at eachframe is
prohibitively expensive in environments with changing geometry.
This recomputation would in any case be wasteful: only a limited
part of these structures actually needs to be recalculated. We
present a novel algorithm which uses spatial coherence of
movement as well as the rich visibility information existing in
the discontinuity mesh to avoid unnecessary recomputation after
object motion. In particular we isolate all modifications
requiredfor the update of the discontinuity mesh by using an
augmented spatial subdivision structure and we restrict
intersections of discontinuity surfaces with the scene. In
addition, we develop an algorithm which identifies visibility
changes by exploiting information contained in the planar
discontinuity mesh of each scene polygon, obviating the need for
many expensive searches in {3D} space. A full implementation of
the algorithm is presented, which allows interactive updates of
high-quality soft shadows for scenes of moderate complexity. The
algorithm can also be directly applied to global illumination.
Proceedings of Eurographics '97. },
}
@article{Tanaka:1997:FAS,
   author = {T. Tanaka and T. Takahashi},
   title = {Fast Analytic Shading and Shadowing for Area Light
Sources},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {231-240},
   note = {{ISSN} 1067-7055},
   keywords = {analytic rendering, shadowing, area light source,
local illumination, space subdivision, clipping, silhouette
generation, highlight generation, scanline algorithm},
   annote = {This paper describes a fast analytic algorithm that
generates exact highlights and soft shadows from area light
sources. In order to realize fast shadowing, we propose the
ray-oriented buffer which segments {3D} space by following light
rays from polygonal sources. Each cell of the buffer stores
objects that intersect a related subspace. Candidate objects
which may cast shadows onto a point are selected by referring to
the buffer. The candidates are then tested with their shadow
bounding volumes to suppress objects that never occlude light
sources. In addition, we propose the cross scanline clipping
algorithm. It quickly determines the exact regions of uncovered
area light sources with simple silhouette generation. Both
diffuse and specular reflections are computed by integrating
light rays from the uncovered sources. Experimental results
confirm the high performance of the proposed method. Proceedings
of Eurographics '97. },
}
@article{Gaddipatti:1997:SIG,
   author = {A. Gaddipatti and R. Machiraju and R. Yagel},
   title = {Steering Image Generation with Wavelet Based
Perceptual Metric},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {241-252},
   note = {{ISSN} 1067-7055},
   annote = {It is often the case that images generated by image
synthesis algorithms are judged by visual examination. The user
resorts to an iterative refinement process of inspection and
rendering until a satisfactory image is obtained. In this paper
we propose quantitative metrics to compare images that arise
from an image synthesis algorithm. The intent is to be able to
guide the refinement process inherent in image synthesis. The
Mean-Square-Error (MSE) has been traditionally employed to guide
this process. However it is not a viable metric for image
synthesis control. We propose the use of a wavelet based
perceptual metric which incorporates the frequency response of
the Human Visual System. A useful aspect of the wavelet based
metric is its ability to selectively measure the changes to
structures of different sizes and scales in specific locations.
Also, by resorting to the use of wavelets of various degrees of
regularity, one can seek different levels of smoothness in an
image. It is rare that such level of control can be obtained
from a metric other than a wavelet based metric. We show the
usefulness of our metric by examining it's effectiveness in
providing insights for common operations of an image synthesis
algorithm (e.g., blurring). We also provide some examples of
it's use in rendering algorithms frequently used in graphics.
Proceedings of Eurographics '97. },
}
@article{Tanaka:1997:PIE,
   author = {T. Tanaka and N. Ohnishi},
   title = {Painting-like Image Emphasis based on Human Vision
Svstems},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {253-260},
   note = {{ISSN} 1067-7055},
   keywords = {image emphasis, display technique, visual
processing, painting simulation, dynamic range compression},
   annote = {Regional image emphasis is often evident in
paintings and illustrations. This technique increases local
contrast while reducing global contrast by amplifying image
intensity on shadowed surfaces, reducing intensity on
illuminated surfaces, and then expanding contrast at intensity
edges. The effects are assumed to result from the visual
processing needed to interpolate the real world onto canvas.
Therefore, we propose an intensity emphasis method based on
human vision. This method simulates the adaptation of
photoreceptor cells and the lateral inhibition of receptive
fields. These attributes of a vision system are realized by
computation of relative intensity and differential intensity in
small areas. The proposed method can successfully generate
painting-like artifacts, which greatly improves the perception
of visual elements displayed in an image. Since the method
efficiently reduces the dynamic range of images, it can be used
for displaying highlighted images on standard graphic monitors.
Experiments on a computer-generated image and a photograph
confirm the advantages of our method. Proceedings of
Eurographics '97. },
}
@article{Neumann:1997:RWW,
   author = {L. Neumann and A. Neumann and P. Bekaert},
   title = {Radiosity with Well Distributed Ray Sets},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {261-270},
   note = {{ISSN} 1067-7055},
   annote = {In this paper we present a new radiosity algorithm,
based on the notion of a well distributed ray set (WDRS). A {WDRS}
is a set of rays, connecting mutually visible points and
patches, that forms an approximate representation of the
radiosity operator and the radiosity distribution. We propose an
algorithm that constructs an optimal {WDRS} for a given accuracy
and mesh. The construction is based on discrete importance
sampling as in previously proposed stochastic radiosity
algorithms, and on quasi Monte Carlo sampling. Quasi Monte Carlo
sampling leads to faster convergence rates and the fact that the
sampling is deterministic makes it possible to represent the
well distributed ray set very efficiently in computer memory.
Like previously proposed stochastic radiosity algorithms, the
new algorithm is well suited for computing the radiance
distribution in verv complex diffuse scenes, when it is not
feasible to explicitly compute and store form factors as in
classical radiosity algorithms. Experiments show that the new
algorithm is often more efficient than previously proposed Monte
Carlo radiosity, algorithms bv half an order of magnitude and
more. Proceedings of Eurographics '97. },
}
@article{Szirmay-Kalos:1997:AAO,
   author = {L. Szirmay-Kalos and T. F{\'{o}}ris and L. Neumann
and B. Cs{\'{e}}bfalvi},
   title = {An Analysis of Quasi-Monte Carlo Integration Applied
to the Transillumination Radiosity Method},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {271-282},
   note = {{ISSN} 1067-7055},
   annote = {This paper presents an enhanced transillumination
radiosity method that can provide accurate solutions at
relatively low computational cost. The proposed algorithm breaks
down the double integral of the gathered power to an area
integral that is computed analytically and to a directional
integral that is evaluated by quasi-Monte Carlo techniques.
Since the analytical integration results in a continuous
function of finite variation, the quasi-Monte Carlo integration
that follows the analytical integration will be efficient and
its error can be bounded by the Koksma-Hlawka inequality. The
paper also analyses the requirements of the convergence,
presents theoretical error bounds and proposes error reduction
techniques. The theoretical bounds are compared with simulation
results. Proceedings of Eurographics '97. },
}
@article{Yu:1997:ARE,
   author = {Y. Yu and H. Wu},
   title = {A Rendering Equation for Specular Transfers and Its
Integration into Global Illumination},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {283-292},
   note = {{ISSN} 1067-7055},
   keywords = {Rendering equation, Global illumination, Specular
transfer, Wavefront tracing, Radiosity, Ray tracing, Meshing},
   annote = {In this paper, we present a rigorous theoretical
formulation of the fundamental problem - indirect illumination
from area sources via curved ideal specular - surfaces.
Intensity and area factors are introduced to clarify this
problem and to rectify the radiance from these specular
surfaces. They take surface geometry, such as Gaussian
curvature, into account. Based on this formulation, an algorithm
for integrating ideal specular transfers into global
illumination is also presented. This algorithm can deal with
curved specular reflectors and transmitters. An implementation
is described based on wavefront tracing and progressive
radiosity. Sample images generated by this method are presented.
Proceedings of Eurographics '97. },
}
@article{Lalonde:1997:GRD,
   author = {P. Lalonde and A. Fournier},
   title = {Generating Reflected Directionsfrom {BRDF} Data},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {293-300},
   note = {{ISSN} 1067-7055},
   keywords = {Bidirectional reflectance distribution functions,
Wavelets, Monte Carlo path tracing, Reflection, Local
Illumination, Random deviates},
   annote = {Monte-Carlo path tracing algorithms for computer
graphics require that given an incident light ray at a surface
an outgoing direction can be computed with a distribution given
by the magnitude of the bidirectional reflectance distribution
function (BRDF). For analytic reflectance functions this can be
done using various techniques including inverting the function,
or tabulating some representation of the inverse. However
measured {BRDF} data sets are too large for this to be practical.
We present a method to generate reflection rays distributed
according to the magnitude of the {BRDF}. The method relies on a
wavelet-based representation of the {BRDF}. This representation is
efficient and compact, allowing large, anisotropic measured {BRDF}
data sets to be represented with afew thousand coefficients. In
particular we exploit the wavelet representation to quickly
compute integrals over ranges of the {BRDF}. Proceedings of
Eurographics '97. },
}
@article{Sbert:1997:OSS,
   author = {M. Sbert},
   title = {Optimal Source Selection in Shooting Random Walk
Monte Carlo Radiosity},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {301-308},
   note = {{ISSN} 1067-7055},
   keywords = {Rendering, Radiosity, Monte Carlo; Random Walk,
Importance},
   annote = {In this paper we study how to optimally select
between different sources in shooting random walk Monte Carlo
Radiosity. Until now the probability of selecting a source has
been made proportional to the importance of that source for the
region of interest. We will show here that, whenever the
transition probabilities are the form factors, this is not
optimal, and will consequently give the optimal case. This will
correspond to probabilities proportional to the square root of
importances, rather than to importances themselves. Proceedings
of Eurographics '97. },
}
@article{Stamminger:1997:BR,
   author = {M. Stamminger and P. Slusallek and H-P. Seidel},
   title = {Bounded Radiosity - Illumination on General Surfaces
and Clusters},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {309-318},
   note = {{ISSN} 1067-7055},
   annote = {Traditionally, Radiosity algorithms have been
restricted to scenes made from planar patches. Most algorithms
for computing form factors and the subdivision criterion for
hierarchical methods implicitly assume planar patches. In this
paper, we present a new radiosity algorithm that is solely based
on simple geometric information about surface elements, namely
their bounding boxes and cone of normals. Using this information
allows to compute efficient error bounds that can be used for
the subdivision oracle and for computing the energy transfer Due
to the simple interface to geometric objects, our algorithms not
only allows for computing illumination on general curved
surfaces, but it can also directly be applied to a hierarchy of
clusters. Several examples demonstrate the advantages of the new
approach. Proceedings of Eurographics '97. },
}
@article{Kakez:1997:VDE,
   author = {S. Kakez and V. Conan and P. Bisson},
   title = {Virtually Documented Environments: A New Interface
Paradigm for Task-oriented Access to Information},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {319-328},
   note = {{ISSN} 1067-7055},
   keywords = {Augmented Reality, Human-Computer Interaction,
Information retrieval, Video see-through, Registration},
   annote = {We present a suitable virtually documented
environment system providing the user with high level
interaction possibilities. The system is dedicated to
applications where the operator needs to have his hands free in
order to access information, carry out measurements andlor
operate on a device (e.g. maintenance, instruction). The system
merges video images acquired through a head-mounted video camera
with synthetic data (multimedia documents including {CAD} models
and text) and presents these merged images to the operator
Registration techniques allow the operator to visualise
information properly correlated to the real world: this is an
essential aspect in order to achieve a feeling of presence in a
real environment. We increase the sense of immersion through
high level Human-Computer Interaction (HCI) allowing hands-free
access to information through vocal commands as well as
multimodal interaction associating speech and gesture. In this
way, the user can access information and manipulate it in a very
natural manner. We discuss the construction of the documentation
system and the requested functionalities which led to the system
architecture. Proceedings of Eurographics '97. },
}
@article{Robinson:1997:AFF,
   author = {P. Robinson and D. Sheppard and R. Watts and R.
Harding and S. Lay},
   title = {A framework for interacting with paper},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {329-334},
   note = {{ISSN} 1067-7055},
   annote = {This paper reports on ways of using digitised video
from television cameras in user interfaces for computer systems.
The DigitalDesk is built around an ordinary physical desk and
can be used as such, but it has extra capabilities. A video
camera mounted above the desk, pointing down at the work
surface, is used to detect where the user is pointing and to
read documents that are placed on the desk. A computer-driven
projector is also mounted above the desk, allowing the system to
project electronic objects onto the work surface and onto real
paper documents. The animated paper documents project is
considering particular applications of the technology in
electronic publishing. The goal is to combine electronic and
printed documents to give a richer presentation than that
afforded by either separate medium. This paper describes the
framework that has been developed to assist with the preparation
and presentation of these mixed-media documents. The central
component is a registry that associates physical locations on
pieces ofpaper with actions. This is surrounded by a number of
adaptors that assist with the creation of new documents either
from scratch or by translating from conventional hypermedia, and
also allow the documents to be edited. Finally the DigitalDesk
itself identifies pieces of paper and animates them with the
actions described in the registry. Proceedings of Eurographics
'97. },
}
@article{Szalavari:1997:TPI,
   author = {Z. Szalav{\'{a}}ri and M. Gervautz},
   title = {The Personal Interaction Panel - a Two-Handed
Interface for Augmented Reality},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {335-346},
   note = {{ISSN} 1067-7055},
   keywords = {{3D} user interface, augmented reality, two handed
interaction},
   annote = {This paper describes the introduction of a new
interaction paradigm to augmented reality applications. The
everyday tool handling experience of working with pen and
notebooks is extended to create a three dimensional two-handed
interface, that supports easy-to-understand manipulation tasks
in augmented and virtual environments. In the design step we
take advantage from the freedom, given by our very low demands
on hardware and augment form and functionality to this device.
On the basis of examples from object manipulation, augmented
research environments and scientific visualization we show the
generality of applicability. Although being in thefirst stages
implementation, we consider the wide spectrum of suitability for
different purposes. Proceedings of Eurographics '97. },
}
@article{Kobbelt:1997:USO,
   author = {L. Kobbelt and M. Stamminger and H-P. Seidel},
   title = {Using Subdivision on Hierarchical Data to
Reconstruct Radiosity Distribution},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {347-356},
   note = {{ISSN} 1067-7055},
   annote = {Computing global illumination by finite element
techniques usually generates a piecewise constant approximation
of the radiosity distribution on surfaces. Directly, displaying
such scenes generates artifacts due to discretization errors. We
propose to remedy this drawback by considering the piecewise
constant output to be samples of a (piece-wise) smooth function
in object space and reconstruct this function by applying a
binary subdivision scheme. We design custom taylored subdivision
schemes with quadratic precision for the efficient refinement of
cell- or pixel-type data. The technique naturally allows to
reconstruct functions from non-uniform samples which result from
adaptive binary splitting of the original domain (quadtree).
This type of output is produced, e.g., by hierarchical radiosity
algorithms. The result of the subdivision process can be mapped
as a texture on the respective surface patch which allows to
exploit graphics hardware for considerable, accelerating the
display. Proceedings of Eurographics '97. },
}
@article{Nishita:1997:AMA,
   author = {T. Nishita and H. Iwasaki and Y. Dobashi and E.
Nakamae},
   title = {A Modeling and Rendering Method for Snow by Using
Metaballs},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {357-364},
   note = {{ISSN} 1067-7055},
   keywords = {snow, multiple scattering, Mie scattering,
metaball, volume rendering},
   annote = {The display of natural scenes such as mountains,
trees, the earth as viewed from space, the sea, and waves have
been attempted. Here a method to realistically display snow is
proposed. In order to achieve this, two important elements have
to be considered, namely the shape and shading model of snow,
based on the physical phenomenon. In this paper, a method for
displaying snow fallen onto objects, including curved surfaces
and snow scattered by objects, such as skis, is proposed. Snow
should be treated as particles with a density distribution since
it consists of water particles, ice particles, and air
molecules. In order to express the material property of snow,
the phase functions of the particles must be taken into account,
and it is well-known that the color of snow is white because of
the multiple scattering of light. This paper describes a
calculation method for light scattering due to snow particles
taking into account both multiple scattering and sky light, and
the modeling of snow. Proceedings of Eurographics '97. },
}
@article{Wang:1997:MTG,
   author = {L. Wang and D. Botta and C. Ellefson and A.
Fournier},
   title = {Modelling the Garden of Perfect Brightness},
   volume = {16},
   number = {3},
   journal = {Computer Graphics Forum},
   month = {August}, year = {1997},
   editor = {Dieter Fellner and L. Szirmay-Kalos},
   publisher = {Blackwell Publishers},
   pages = {365-369},
   note = {{ISSN} 1067-7055},
   keywords = {Yuan Ming Garden, Chinese culture, architecture,
landscape, natural phenomena},
   annote = {The Yuan Ming Yuan, the Garden of Perfect
Brightness, was the culmination of the art of Chinese Imperial
gardens. Covering 350 hectares (875 acres) northwest of Beijing,
it included 140 distinct sites, 2000 structures, thousands of
pieces offumiture and precious objects, countless plants. It was
almost totally destroyed in 1860 at the end of the second Opium
War by English and French troops in one of the worst acts of
cultural vandalism in recorded history. Rebuilding it has proven
impossible, but now computer technology, based on 130 fears of
scholarly, documentation makes it possible to build an accurate
and detailed model, and will allow us to experience at least
virtually the beauty and grandeur that was the Yuan Ming Yuan.
This paper describes a project to build such a model, and
details the main challenges and difficulties encountered. While
commercially available graphics workstations and modelling
software can take us most of the way in this task, they fall
short with the modelling of natural phenomena such as plants,
rocks and bodies of water In addition the sheer size of the
resulting database pushes rendering engines past their limits.
Proceedings of Eurographics '97. },
}
@article{Wang:1997:TOI,
   author = {D. Wang and I. Herman and G. J. Reynolds},
   title = {The Open Inventor Toolkit and the {PREMO} Standard},
   volume = {16},
   number = {4},
   journal = {Computer Graphics Forum},
   year = {1997},
   publisher = {Blackwell Publishers},
   pages = {159-176},
   note = {{ISSN} 1067-7055},
   keywords = {standards, {PREMO}, Open Inventor,
object-oriented},
   annote = {{PREMO} is an emerging international standard for the
presentations of multimedia objects including computer graphics.
Open Inventor(tm) is a commercially available &quot;defacto&quot; standard
for interactive computer graphics packaged as a library of
objects. In this paper, we consider whether the concepts and
objects of {PREMO} are sufficient to represent a professional
quality system, such as Open Inventor. By comparing {PREMO} with
Open Inventor, we hope to show that PREMO's computer graphics
environment model and event model can properly describe Open
Inventor's rendering action and event model. The scene graph is
very important in Open Inventor. Most Open Inventor functions
rely on various operations over scene graphs. The construction,
edition and traversal of the scene graphs are implemented as a
set of newly defined {PREMO} objects. Graphics rendering, event
handling and scene graphs constitute the fundamental parts of
Open Inventor, other Open Inventor functionalities can be
constructed from these. We conclude that since these three
fundamental parts of Open Inventor can be properly modelled and
implemented by means of {PREMO}, that the concepts and objects of
PREMO are sufficient to represent Open Inventor. },
}
@article{Guo:1997:SRU,
   author = {B. Guo and J. Menon and B. Willette},
   title = {Surface Reconstruction Using Alpha Shapes},
   volume = {16},
   number = {4},
   journal = {Computer Graphics Forum},
   year = {1997},
   publisher = {Blackwell Publishers},
   pages = {177-190},
   note = {{ISSN} 1067-7055},
   keywords = {Surface topology, alpha shapes, manifolds,
surface fitting},
   annote = {We describe a method for reconstructing an unknown
surface from a set of data points. The basic approach is to
extract the surface as a polygon mesh from an &gt;alpha&lt;-shape.
Even though alpha shapes are generalized polytopes having
complicated internal structures, we show that manifold surfaces,
with or without boundaries, can be efficiently generated, and
these surfaces completely describe the &gt;alpha&lt;-shapes to the
extent that they are visible from outside. Unlike the original
&gt;alpha&lt;-shapes, the polygonal surfaces can be easily simplified
to yield compact models suitable for a variety of geometric
modeling applications such as surface fitting. },
}
@article{Vassilev:1997:ISW,
   author = {T. I. Vassilev},
   title = {Interactive Sculpting with Deformable Nonuniform
B-Splines},
   volume = {16},
   number = {4},
   journal = {Computer Graphics Forum},
   year = {1997},
   publisher = {Blackwell Publishers},
   pages = {191-200},
   note = {{ISSN} 1067-7055},
   keywords = {nonuniform B-splines, curve and surface energy
minimization, interactive sculpting},
   annote = {This paper describes an efficient method for
manipulating deformable B-spline surfaces, based on minimizing
an energy Functional. The major benefit of the proposed new
fairness norm is that it preserves the natural representation of
the B-spline surface control points (a two dimensional array)
which has an efficiency advantage over other methods. The
designer uses forces as a main sculpting tool and is free to
specify a single force, a set of isolated forces, forces
situated on a line or curve or area of the deformable surface.
The user is allowed to modify several parameters and in this way
to change the physical properties of the object. },
}
@article{Jackel:1997:MAR,
   author = {D. Jack{\`{e}}l and B. Walter},
   title = {Modeling and Rendering of the Atmosphere Using
Mie-Scattering},
   volume = {16},
   number = {4},
   journal = {Computer Graphics Forum},
   year = {1997},
   publisher = {Blackwell Publishers},
   pages = {201-210},
   note = {{ISSN} 1067-7055},
   keywords = {particle scattering, atmospheric rendering,
Mie-scattering, outdoor scenes},
   annote = {This paper presents a method for rendering of the
atmosphere by means of Mie-scattering. The method is based on a
concentric atmospheric model, which is divided into four
stibmodels: for clear air, aerosol, ozone, and rain. In order to
simulate and visualize the various atmospheric effects, each of
these stibmodels can be parameterized by the user as desired.
The process of rendering an outdoor scene requires an enormous
amount of computing power. In order to make this method suitable
for efficient implementation, some simplifications and
approximations are discussed. In addition, a selection of the
rendering results are presented, and our further activities in
the field of atmospheric rendering are discussed. },
}
@article{Panne:1997:FFT,
   author = {M. van de Panne},
   title = {From Footprints to Animation},
   volume = {16},
   number = {4},
   journal = {Computer Graphics Forum},
   year = {1997},
   publisher = {Blackwell Publishers},
   pages = {211-224},
   note = {{ISSN} 1067-7055},
   annote = {A method of using footprints as a basis for
generating animated locomotion is proposed. An optimization
process is used to maximize the physical plausibility and
perceived comfort of a motion which is constrained to match
given footprint and timing information. The proposed method
creates plausible walking, turning, leaping, and running motions
for bipedal figures at interactive rates. Autonomous motions are
generated using a planning algorithm which dynamically generates
new footprints and the associated new motions. },
}
@article{Arad:1997:ITM,
   author = {Mur Arad},
   title = {Isometric Texture Mapping for Free-Form Surfaces},
   volume = {16},
   number = {5},
   journal = {Computer Graphics Forum},
   year = {1997},
   publisher = {Blackwell Publishers},
   pages = {247-256},
   note = {{ISSN} 1067-7055},
   annote = {Texture mapping is a frequently exploited technique
in computer graphics aimed at the emulation of high-resolution
details in surfaces. In this paper we present a distance-ratios
preservation method for bivariate raster texture mapping to
free-form surfaces in an arbitrarily precise manner. The
proposed method reduces the original general problem of
computing the inverse of a three-dimensional parametric surface
mapping into a problem of two-dimensional image warping. Several
examples that demonstrate the proposed approach are also
provided. },
}
@article{Chen:1997:MSL,
   author = {Jim X. Chen},
   title = {Multiple Segment Line Scan-Conversion},
   volume = {16},
   number = {5},
   journal = {Computer Graphics Forum},
   year = {1997},
   publisher = {Blackwell Publishers},
   pages = {257-268},
   note = {{ISSN} 1067-7055},
   annote = {We present a new method for scan-converting a
straight line. A scan-converted straight line may contain many
pixel segments of identical shapes. Therefore, instead of
scan-converting the whole line step by step, we can scan-convert
multiple segments of a line through copying and replicating.
With a few modifications to the existing algorithms, we can
significantly speed up the scan-conversion process. The
algorithm can be implemented in the hardware, further speeding
up the process. The hardware design for the new algorithm is
provided. We prove that we can speed up all existing line
scan-conversion algorithms on the average 3 times. },
}
@article{Hand:1997:ASO,
   author = {Chris Hand},
   title = {A Survey of {3D} Interaction Techniques},
   volume = {16},
   number = {5},
   journal = {Computer Graphics Forum},
   year = {1997},
   publisher = {Blackwell Publishers},
   pages = {269-281},
   note = {{ISSN} 1067-7055},
   annote = {Recent gains in the performance of {3D} graphics
hardware and rendering systems have not been matched by a
corresponding improvement in our knowledge of how to interact
with the virtual environments we create; therefore there is a
need to examine these further if we are to improve the overall
quality of our interactive {3D} systems. This paper examines some
of the interaction techniques which have been developed for
object manipulation, navigation and application control in {3D}
virtual environments. The use of both mouse-based techniques and
3D input devices is considered, along with the role of feedback
and some aspects of tools and widgets. },
}
@article{Ferley:1997:SRO,
   author = {Eric Ferley and Marie-Paule Cani-Gascuel and
Dominique Attali},
   title = {Skeletal Reconstruction of Branching Shapes},
   volume = {16},
   number = {5},
   journal = {Computer Graphics Forum},
   year = {1997},
   publisher = {Blackwell Publishers},
   pages = {283-293},
   note = {{ISSN} 1067-7055},
   annote = {We present a new method to reconstruct an implicit
representation of a branching object from a set of data points
scattered on its surface. The method is based on the computation
of a geometric skeleton inside the data set. This skeleton is
simplified in order to filter noise and converted into skeletal
elements - a graph of interconnected curves - that generate an
implicit surface. We use B{\'{e}}zier triangles as extra
skeletal elements to perform bulge free blends between branches
while controlling the blend extent. The result is a smooth
reconstruction of the object, that can be computed whatever its
topology. The skeleton offers compact storage, and provides an
underlying structure for the reconstructed object, making it
easier to edit in a modeling or animation environment. },
}
@article{Rangan:1997:IVO,
   author = {Haripriya Rangan and Matthias Ruhl and Dietmar
Saupe},
   title = {Interactive Visualization of Implicit Surfaces with
Singularities},
   volume = {16},
   number = {5},
   journal = {Computer Graphics Forum},
   year = {1997},
   publisher = {Blackwell Publishers},
   pages = {295-306},
   note = {{ISSN} 1067-7055},
   annote = {This paper presents work on two methods for
interactive visualization of implicit surfaces: physically-based
sampling using particle systems and polygonization followed by
physically-based mesh improvement which explicitly makes use of
the surface-defining equation. While most previous work applied
to bounded manifolds without singularities and without boundary
(topological spheres) we broaden the scope of the methods to
include surfaces with such features, in particular cusp points
and surface self-intersections. These aspects are not (yet)
essential for computer graphics modelling with implicit surfaces
but they naturally occur in simulations of interest in
mathematical visualization. In this paper we use the Kummer
family of algebraic surfaces as an example. },
}

</PRE>
	</td>


	</table>

 
<P>

</BODY>
</HTML>
