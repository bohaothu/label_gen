%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Tim Furche at 2006-03-09 12:43:57 +0100 


%% Saved with string encoding Western (ASCII) 


@STRING{bncod = " Proc. British National Conf. on Databases"}

@STRING{edbt = " Proc. Extending Database Technology"}

@STRING{icde = " Proc. Intl. Conf. on Data Engineering"}

@STRING{icdt = " Proc. Intl. Conf. on Database Theory"}

@STRING{iclp = " Proc. Intl. Conf. on Logic Programming"}

@STRING{iswc = " Proc. Intl. Semantic Web Conf."}

@STRING{lpar = " Proc. Intl. Conf. on Logic for Programming, Artificial Intelligence and Reasoning"}

@STRING{odbase = " Proc. Intl. Conf. on Ontologies, Databases,   and Applications of Semantics for Large Scale Information Systems"}

@STRING{pods = " Proc. ACM Symposium on Principles of Database Systems"}

@STRING{ppswr = " Proc. Workshop on Principles and Practice of Semantic Web Reasoning"}

@STRING{sac = " Proc. Symposium of Applied Computing"}

@STRING{sigmod = " Proc. ACM SIGMOD Conf."}

@STRING{vldb = " Proc. Intl. Conf. on Very Large Databases"}

@STRING{www = " Proc. Intl. World Wide Web Conf."}


@inproceedings{Lu_TwigDewey_VLDB_2005,
	Author = {Lu, Jiaheng and Ling, Tok Wang and Chan, Chee-Yong and Chen, Ting},
	Booktitle = {Proc. Int'l. Conf. on Very Large Data Bases},
	Date-Added = {2006-03-09 12:42:22 +0100},
	Date-Modified = {2006-03-09 12:43:55 +0100},
	Isbn = {1-59593-154-6},
	Keywords = {XML query optimization evaluation twig holistic joins dewey tree encoding},
	Location = {Trondheim, Norway},
	Pages = {193--204},
	Publisher = {VLDB Endowment},
	Title = {{From Region Encoding to Extended Dewey: On Efficient Processing of XML Twig Pattern Matching}},
	Year = {2005},
	Abstract = {Finding all the occurrences of a twig pattern in an XML database is a core operation for efficient evaluation of XML queries. A number of algorithms have been proposed to process a twig query based on region encoding labeling scheme. While region encoding supports efficient determination of structural relationship between two elements, we observe that the information within a single label is very limited. In this paper, we propose a new labeling scheme, called extended Dewey. This is a powerful labeling scheme, since from the label of an element alone, we can derive all the elements names along the path from the root to the element. Based on extended Dewey, we design a novel holistic twig join algorithm, called TJFast. Unlike all previous algorithms based on region encoding, to answer a twig query, TJFast only needs to access the labels of the leaf query nodes. Through this, not only do we reduce disk access, but we also support the efficient evaluation of queries with wildcards in branching nodes, which is very difficult to be answered by algorithms based on region encoding. Finally, we report our experimental results to show that our algorithms are superior to previous approaches in terms of the number of elements scanned, the size of intermediate results and query performance.}}

@article{Bry_XChange_JWE_2006,
	Author = {Bry, Fran{\c c}ois and Eckert, Michael and P{\u a}tr{\^a}njan, Paula-Lavinia},
	Date-Added = {2006-03-06 17:37:10 +0100},
	Date-Modified = {2006-03-06 17:38:10 +0100},
	Journal = {Journal of Web Engineering},
	Number = {1},
	Pages = {3--24},
	Title = {{Reactivity on the Web: Paradigms and Applications of the Language XChange}},
	Url = {http://www.pms.ifi.lmu.de/publikationen#PMS-FB-2006-3},
	Volume = {5},
	Year = {2006},
	Abstract = {Reactivity on the Web is an emerging research issue covering: updating data on the Web, exchanging information about events (such as executed updates) between Web sites, and reacting to combinations of such events. Reactivity plays an important role for upcoming Web systems such as online marketplaces, adaptive Web and Semantic Web systems, as well as Web services and Grids. This article introduces the paradigms upon which the high-level language XChange for programming reactive behaviour and distributed applications on the Web relies. Then, it briefly presents the main syntactical constructs of XChange and their declarative and operational semantics.}}

@inproceedings{Bry_TenTheses_RLI_2005,
	Author = {Bry, Fran{\c c}ois and Marchiori, Massimo},
	Booktitle = {Proc. of W3C Workshop on Rule Languages for Interoperability},
	Date-Added = {2006-03-06 17:33:00 +0100},
	Date-Modified = {2006-03-06 17:35:22 +0100},
	Organization = {W3C},
	Title = {{Ten Theses on Logic Languages for the Semantic Web}},
	Url = {http://www.pms.ifi.lmu.de/publikationen#PMS-FB-2005-7},
	Year = {2005},
	Abstract = {This articles discusses the logic, or logic-based, languages required for a full deployment of the Semantic Web. It presents ten theses addressing (1) the kinds of logic languages needed, (2) data and data processing, (3) semantics, and (4) engineering and rendering issues.}}

@mastersthesis{Linse_XQuery2Xcerpt_DA_2006,
	Author = {Linse, Benedikt},
	Date-Added = {2006-03-06 10:26:17 +0100},
	Date-Modified = {2006-03-06 10:28:43 +0100},
	Keywords = {XML XQuery Xcerpt translation nested construction},
	School = {Institute for Informatics, University of Munich},
	Title = {{Automatic Translation between XQuery and Xcerpt}},
	Type = {{Diplomarbeit/Master thesis}},
	Url = {http://www.pms.ifi.lmu.de/publikationen#DA_Benedikt.Linse},
	Year = {2006}}

@inproceedings{Regin_AllDifferent_AAAI_1994,
	Author = {R{\'e}gin, Jean-Charles},
	Booktitle = {Proc. Conf. on Artificial Intelligence},
	Date-Added = {2006-03-06 10:13:50 +0100},
	Date-Modified = {2006-03-06 10:17:53 +0100},
	Editor = {AAAI},
	Keywords = {evaluation optimiation CSP all-different},
	Pages = {362--367},
	Title = {{A Filtering Algorithm for Constraints of Difference in CSPs}},
	Year = {1994},
	Abstract = {Many real-life Constraint Satisfaction Problems (CSPs) involve some constraints similar to the alldifferent constraints. These constraints are called constraints of difference. They are defined on a subset of variables by a set of tuples for which the values occuring in the same tuple are all different. In this paper, a new filtering algorithm for these constraints is presented. It achieves the generalized arc-consistency condition for these non-binary constraints. It is based on matching theory and its complexity is low. In fact, for a constraint defined on a subset of p variables having domains of cardinality at most d, its space complexit is O(pd) and its time complexity is O(p2d2). This filtering algorithm has been successfully used in the system RESYN, to solve the subgraph isomorphism problem.}}

@book{Abiteboul_FoundationsDB_AW_1995,
	Address = {Boston, MA, USA},
	Author = {Abiteboul, Serge and Hull, Richard and Vianu, Victor},
	Date-Added = {2006-03-06 09:40:26 +0100},
	Date-Modified = {2006-03-06 09:42:35 +0100},
	Isbn = {0-201-53771-0},
	Keywords = {database theory complexity},
	Publisher = {Addison-Wesley},
	Title = {{Foundations of Databases}},
	Url = {http://db.bell-labs.com/user/hull/FoundDB.html},
	Year = {1995},
	Abstract = {This database theory book provides a focused presentation of the core material on relational databases, and presents a number of advanced topics in a unified framework. Some of the advanced material has never before been presented in book form. The style is rigorous, with detailed proofs and many exercises. The text and numerous examples highlight the intuition underlying the development. As a textbook, the book is aimed at graduate students and seniors who would use it as the main text in a database theory course, or as complementary material in a database systems course. It can also serve as a reference for database researchers and for other computer scientists interested in databases.},
	Annote = {Database theory is a relative newcomer to the field of computer science. Early data management systems were based on techniques from several classical areas of computer science, ranging from hardware and operating systems to data structures and programming languages. In the early seventies, a leap of abstraction from file systems produced relational databases and its accompanying theory, with logic as the catalyst. We believe that database theory has matured--that is has emerged as an elegant and robust part of science with its own identity. As such, it embodies its own peculiar brand of wisdom that deserves to be communicated not just to insiders, but to the computer science community at large.
In a nutshell, a database management system is a software system that enables the creation, maintenance, and use of large amounts of data. In contrast with many programming applications, the logical data structure--the "database schema"--used to structure a given data set is usually much smaller than the volume of that set. Furthermore, the data is persistent, evolving over time and surviving multiple invocations of the database management software. To increase usability, concurrent access to the data is usually supported with specialized protocols that guarantee a form of noninterference between interleaved transactions. Importantly, modern database management systems embody a distinction between the logical level and the physical level. The logical level focuses on an abstract representation of the data, along with languages to create, query and modify it; the physical level focuses on the underlying implementation, including the physical layout used to store the data, the indexing and clustering schemes, and the concurrency and recovery protocols.

Database theory has developed primarily around the logical level of database. (A notable exception is concurrency control, which is not addressed in this volume.) A core of fundamental material on the relational model has become well established. It consists primarily of three paradigms for query languages (algebraic, calculus-based, and deductive) and the theory of dependencies. The theory of query languages, including issues of expressiveness and complexity specific to databases, is well developed. The marriage between databases and logic programming produced deductive databases, with the main focus on the deductive query languages. Dependency theory focused initially on formalizing and applying the disparate integrity constraints that commonly arise in practice, and it went on to relate constraints with query optimization and to develop a unifying perspective for them.

As a field, database theory draws on several areas, including mathematical logic, complexity, and programming languages. But the database context brings with it different assumptions, perspectives, and emphases. Relations can be viewed as predicates in the sense of logic, and the relational calculus as a specialization of the first-order predicate calculus. However, the database area emphasizes finite structures and has developed the notions of "domain independence" and "safety" to capture intuitive properties related to this finitude. The questions and techniques in dependency theory borrow heavily from logic., with a focus on practically motivated, relatively weak classes of sentences. Query languages provide an interesting contrast with conventional, imperative programming languages. Query languages typically embody a set-at-a-time focus as opposed to an object-at-a-time focus. Also, they are largely declarative in nature, and failing that, are more applicative than imperative. Because of the emphasis on tractability in the face of large volumes of data, there is considerable interest in query languages that do not have full computational power, which gives rise to a rich interplay between query languages and complexity theory. Specialized notions of complexity have arisen, stemming from the practical reality of large volumes of data and the theoretical interest in different query languages. Also, the important notion of 'genericity," which captures a form of abstraction stemming from the separation of the logical and physical levels, has led to new perspectives on complexity theory, involving formalisms that circumvent the ordering of input data implicit in traditional Turing machines.

Exciting new research directions have continued to emerge in database theory, stemming primarily from unanswered questions about query languages and from an interest in expanding beyond the limitations of the relational model. Current research includes investigations motivated by connections with object-orientation, artificial intelligence, and graphics interfaces. And as the database field matures, it, in turn, influences adjacent areas in computer science, notably finite model theory, programming languages, and logic programming.}}

@mastersthesis{Schroeder_Algebra_DA_2005,
	Author = {Schroeder, Andreas},
	Date-Added = {2006-03-06 09:28:01 +0100},
	Date-Modified = {2006-03-06 17:49:59 +0100},
	Keywords = {XML Xcerpt optimization algebra efficicency},
	School = {Institute for Informatics, University of Munich},
	Title = {{An Algebra and Optimization Techniques for Simulation Unification}},
	Type = {{Diplomarbeit/Master thesis}},
	Url = {http://www.pms.ifi.lmu.de/publikationen#DA_Andreas.Schroeder},
	Year = {2005}}

@techreport{Pepper_RDFTM_W3C_2006,
	Author = {Pepper, Steve and Vitali, Fabio and Garshol, Lars Marius and Gessa, Nicola and Presutti, Valentina},
	Date-Added = {2006-03-03 08:20:34 +0100},
	Date-Modified = {2006-03-03 08:21:36 +0100},
	Institution = {W3C},
	Keywords = {RDF Topic Maps interoperability versatility conversion},
	Title = {{A Survey of RDF/Topic Maps Interoperability Proposals}},
	Type = {Working Group Note},
	Url = {http://www.w3.org/TR/rdftm-survey/},
	Year = {2006}}

@inproceedings{Furche_XMLRDF_GVD_2005,
	Author = {Furche, Tim and Bry, Fran{\c c}ois and Bolzer, Oliver},
	Booktitle = {Proc. Workshop on Grundlagen von Datenbanken},
	Date-Added = {2006-03-03 08:09:11 +0100},
	Date-Modified = {2006-03-03 08:10:05 +0100},
	Keywords = {XML RDF transformation integration veratility serialization},
	Organization = {GI},
	Title = {{XML Perspectives on RDF Querying: Towards integrated Access to Data and Metadata on the Web}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2005-13},
	Year = {2005}}

@inproceedings{Furche_MarriagesRDF_PPSWR_2005,
	Author = {Furche, Tim and Bry, Fran{\c c}ois and Bolzer, Oliver},
	Booktitle = {Proc. Intl. Workshop on Principles and Practice of Semantic Web Reasoning},
	Date-Added = {2006-03-03 07:44:33 +0100},
	Date-Modified = {2006-03-06 17:03:32 +0100},
	Keywords = {RDF XML versatility triple graphs logical view},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{Marriages of Convenience: Triples and Graphs, RDF and XML}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2005-38},
	Volume = {3703},
	Year = {2005}}

@article{Zloof_Query-by-Example-DataBase_IBMSJ_1977,
	Author = {Zloof, Moshe M.},
	Date-Added = {2006-03-03 06:43:18 +0100},
	Date-Modified = {2006-03-03 06:44:20 +0100},
	Journal = {IBM Systems Journal},
	Myurl = {http://www.research.ibm.com/j ournal/sj/164/ibmsj1604C.pdf},
	Number = {4},
	Pages = {324--343},
	Title = {{Query By Example: A Data Base Language}},
	Volume = {16},
	Year = {1977},
	Abstract = {Discussed is a high-level data base management language that provides the user with a convenient and unified interface to query, update, define, and control a data base. When the user performs an operation against the data base, he fills in an example of a solution to that operation in skeleton tables that can be associated with actual tables in the data base. The system is currently being used experimentally for various applications.}}

@techreport{Backett_Turtle_2005,
	Author = {Backett, Dave},
	Date-Added = {2006-03-02 17:44:30 +0100},
	Date-Modified = {2006-03-02 17:45:58 +0100},
	Institution = {W3C},
	Keywords = {RDF syntax text serialization},
	Title = {{Turtle---Terse RDF Triple Language}},
	Url = {http://www.w3.org/2001/sw/DataAccess/df1/},
	Year = {2005},
	Abstract = {he Resource Description Framework (RDF) is a general-purpose language for representing information in the Web.

This document defines a text syntax for RDF called Turtle as an extension of the N-Triples ([N-TRIPLES]) test case format carefully taking the most useful and appropriate things added from Notation 3 ([NOTATION3]) while keeping the syntax describing only RDF graphs.}}

@inproceedings{Beckett_Modernising_2004,
	Author = {Backett, Dave},
	Booktitle = {Proc XML Europe},
	Date-Added = {2006-03-02 17:40:54 +0100},
	Date-Modified = {2006-03-02 17:41:19 +0100},
	Keywords = {RDF serialization format RXR XML},
	Month = {April},
	Myurl = {http://www.idealliance.org/pa pers/dx_xmle04/papers/03-08-0 3/03-08-03.html},
	Title = {{Modernising Semantic Web Markup}},
	Year = {2004},
	Annote = {The Resource Description Framework (RDF) web metadata format has an XML syntax RDF/XML which has been described as a ugly and flawed, mainly as a consequence of it being an early XML format, dating from 1998. This presentation will describe the perceived and real problems and select appropriate modern XML and web best practices for improving RDF markup that can be better used with the latest XML technologies such as XSLT 2 and XQuery.

The presentation will distinguish a semantic web markup format rather than a format intended solely for software as one intended to be easier for end users to author and more clearly be appropriate for typical application areas of lightweight web metadata and authored web ontologies.

XML best practice in any area is a tricky subject to discuss and get agreement on but the XML technologies considered include XML Namespaces, XML QNames in content, omitting some darker corners of the XML specification along with use of clear user-friendly technologies such as the RELAXNG grammar-based XML schema language, part of the ISO DSDL work. The presentation will also discuss approaches starting from XHTML to generate semantic web data.}}

@techreport{Adida_RDFA_W3C_2006,
	Author = {Adida, Ben and Birbeck, Mark},
	Date-Added = {2006-03-02 17:38:01 +0100},
	Date-Modified = {2006-03-02 17:39:41 +0100},
	Institution = {W3C},
	Keywords = {RDF XHTML metadata embedding syntax serialization},
	Title = {{RDF/A Primer 1.0---Embedding RDF in XHTML}},
	Type = {Internal Draft},
	Url = {http://www.w3.org/2001/sw/BestPractices/HTML/2006-01-24-rdfa-primer},
	Year = {2006},
	Abstract = {This document introduces the RDF/A syntax for expressing RDF metadata within XHTML. The reader is expected to be fairly familiar with XHTML, and somewhat familiar with RDF.

This is an internal draft produced by the RDF-in-HTML task force [RDFHTML], a joint task force of the Semantic Web Best Practices and Deployment Working Group [SWBPD-WG] and HTML Working Group [HTML-WG].

This document is for internal review only and is subject to change without notice. This document has no formal standing within the W3C.}}

@techreport{W3C_RDFXML_Rec_2004,
	Author = {Beckett, Dave and McBride, Brian},
	Date-Added = {2006-03-02 17:35:56 +0100},
	Date-Modified = {2006-03-02 17:36:34 +0100},
	Institution = {W3C},
	Keywords = {RDF syntax RDF/XML serialization},
	Organization = {W3C},
	Title = {{RDF/XML Syntax Specification (Revised)}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/rdf-synt ax-grammar/},
	Year = {2004},
	Abstract = {The Resource Description Framework (RDF) is a general-purpose language for representing information in the Web.

This document defines an XML syntax for RDF called RDF/XML in terms of Namespaces in XML, the XML Information Set and XML Base. The formal grammar for the syntax is annotated with actions generating triples of the RDF graph as defined in RDF Concepts and Abstract Syntax. The triples are written using the N-Triples RDF graph serializing format which enables more precise recording of the mapping in a machine processable form. The mappings are recorded as tests cases, gathered and published in RDF Test Cases.}}

@techreport{W3C_XInclude_Rec_2004,
	Author = {Marsh, Jonathan and Orchard, David},
	Date-Added = {2006-03-02 15:37:08 +0100},
	Date-Modified = {2006-03-02 15:37:44 +0100},
	Institution = {W3C},
	Keywords = {XML inclusion transformation recommendation},
	Organization = {W3C},
	Title = {{XML Inclusions (XInclude) Version 1.0}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/xinclude/},
	Year = {2004},
	Abstract = {This document specifies a processing model and syntax for general purpose inclusion. Inclusion is accomplished by merging a number of XML information sets into a single composite infoset. Specification of the XML documents (infosets) to be merged and control over the merging process is expressed in XML-friendly syntax (elements, attributes, URI references).}}

@inproceedings{PatelSchneider_XMLSyntaxRDFSemantics_WWW_2002,
	Author = {Patel-Schneider, Peter and Simeon, Jerome},
	Booktitle = {Proc. Intl. World Wide Web Conference},
	Date-Added = {2006-03-02 13:25:38 +0100},
	Date-Modified = {2006-03-02 13:26:39 +0100},
	Keywords = {XML RDF data model semantics integration},
	Month = {May},
	Title = {{The Yin/Yang Web: XML Syntax and RDF Semantics}},
	Url = {http://www2002.org/CDROM/refereed/231/},
	Year = {2002},
	Abstract = {XML is the W3C standard document format for writing and exchanging information on the Web. RDF is the W3C standard model for describing the semantics and reasoning about information on the Web. Unfortunately, RDF and XML---although very close to each other---are based on two different paradigms. We argue that in order to lead the Semantic Web to its full potential, the syntax and the semantics of information needs to work together. To this end, we develop a model-theoretic semantics for the XML XQuery 1.0 and XPath 2.0 Data Model, which provides a unified model for both XML and RDF. This unified model can serve as the basis for Web applications that deal with both data and semantics. We illustrate the use of this model on a concrete information integration scenario. Our approach enables each side of the fence to benefit from the other, notably, we show how the RDF world can take advantage of XML query languages, and how the XML world can take advantage of the reasoning capabilities available for RDF.}}

@techreport{McGuiness_OWL_W3C_2004,
	Author = {McGuinness, Deborah L. and van Harmelen, Frank},
	Date-Added = {2006-03-02 13:18:42 +0100},
	Date-Modified = {2006-03-02 13:19:59 +0100},
	Institution = {W3C},
	Keywords = {OWL RDF ontology description logics W3C},
	Title = {{OWL Web Ontology Language---Overview}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/owl-features/},
	Year = {2004}}

@techreport{Brickley_RDFS_W3C_2004,
	Author = {Brickley, Dan and Guha, R.V.},
	Date-Added = {2006-03-02 13:11:40 +0100},
	Date-Modified = {2006-03-02 13:12:42 +0100},
	Institution = {W3C},
	Keywords = {RDF RDFS ontology schema vocabulary},
	Title = {{RDF Vocabulary Description Language}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/rdf-schema/},
	Year = {2004}}

@misc{Bry_ea_EfficientXcerpt_UNPUB2006,
	Author = {Bry, Fran{\c c}ois and Schroeder, Andreas and Furche, Tim and Linse, Benedikt},
	Date-Added = {2006-02-20 15:20:10 +0100},
	Date-Modified = {2006-03-06 16:42:08 +0100},
	Howpublished = {Submitted for publication},
	Title = {{Efficient Evaluation of n-ary Queries over Trees and Graphs}},
	Year = {2006}}

@inproceedings{Berger_ea_TypingXcerpt_PPSWR2005,
	Author = {Berger, Sacha and Coquery, Emmanuel and Drabent, W\lodzimierz and Wilk, Artur},
	Booktitle = {Proc. of Workshop on Principles and Practice of Semantic Web Reasoning},
	Date-Added = {2006-02-20 15:13:39 +0100},
	Date-Modified = {2006-03-06 17:03:16 +0100},
	Keywords = {XML xcerpt typing R2G2},
	Number = {3703},
	Organization = {REWERSE},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{Descriptive Typing Rules for Xcerpt}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2005-39},
	Year = {2005}}

@article{Gottlob_ComplexityAcyclic_JACM2001,
	Address = {New York, NY, USA},
	Author = {Gottlob, Georg and Leone, Nicola and Scarcello, Francesco},
	Date-Added = {2006-02-01 17:33:28 +0100},
	Date-Modified = {2006-02-01 17:39:49 +0100},
	Doi = {http://doi.acm.org/10.1145/382780.382783},
	Group = {Matrix Method},
	Issn = {0004-5411},
	Journal = {Journal of the ACM},
	Number = {3},
	Pages = {431--498},
	Publisher = {ACM Press},
	Title = {{The Complexity of Acyclic Conjunctive Queries}},
	Url = {http://portal.acm.org/citation.cfm?id=382783},
	Volume = {48},
	Year = {2001},
	Abstract = {This paper deals with the evaluation of acyclic Boolean conjunctive queries in relational databases. By well-known results of Yannakakis [1981], this problem is solvable in polynomial time; its precise complexity, however, has not been pinpointed so far. We show that the problem of evaluating acyclic Boolean conjunctive queries is complete for LOGCFL, the class of decision problems that are logspace-reducible to a context-free language. Since LOGCFL is contained in AC1 and NC2, the evaluation problem of acyclic Boolean conjunctive queries is highly parallelizable. We present a parallel database algorithm solving this problem with a logarithmic number of parallel join operations. The algorithm is generalized to computing the output of relevant classes of non-Boolean queries. We also show that the acyclic versions of the following well-known database and AI problems are all LOGCFL-complete: The Query Output Tuple problem for conjunctive queries, Conjunctive Query Containment, Clause Subsumption, and Constraint Satisfaction. The LOGCFL-completeness result is extended to the class of queries of bounded treewidth and to other relevant query classes which are more general than the acyclic queries.}}

@inproceedings{Filiot_ComposingMonadicQueries_PLANX2006,
	Author = {Filiot, Emmanuel and Niehren, Joachim and Talbot, Jean-Marc and Tison, Sophie},
	Booktitle = {Proc. Intl. Workshop on Programming Language Technologies for XML},
	Date-Added = {2006-02-01 17:27:01 +0100},
	Date-Modified = {2006-02-01 17:37:24 +0100},
	Group = {Matrix Method},
	Title = {{Composing Monadic Queries in Trees}},
	Url = {http://www.lifl.fr/~filiot/publiprivate/Plan-X-final-version.pdf},
	Year = {2006},
	Abstract = {Node selection in trees is a fundamental operation to XML databases, programming languages, and information extraction. We propose a new class of querying languages to define n-ary node selection queries as compositions of monadic queries. The choice of the underlying monadic querying language is parametric. We show that compositions of monadic MSO-definable queries capture n-ary MSO-definable queries, and distinguish an MSO-complete n-ary query language that enjoys an efficient query answering algorithm.}}

@inproceedings{Abraham.Chaudhari.ea_XMLQueryAlgebra_10C_2004,
	Author = {Abraham, Jacob and Chaudhari, Narendra S. and Prakash, Edmond C.},
	Booktitle = {IEEE Int. Region 10 Conference (TENCON)},
	Conference-Abbr = {TENCON},
	Keywords = {XML XQuery algebra operators implementation survey},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Abraham.Chaudhari.ea_XMLQueryAlgebra_TENCON_2004.pdf},
	Title = {{XML Query Algebra Operators, and Strategies for their Implementation}},
	Url = {http://www.ntu.edu.sg/home/asnarendra/lect_slides/SwatiFiles/TENCON04-Jacob.pdf},
	Year = {2004},
	Abstract = {For querying the XML data, XQuery is nowadays
	 accepted as the language of choice. However, no query algebra for XML
	 is not yet accepted widely. In this paper, we discuss the need for
	 and progress of query algebras as well as the specific requirements
	 of semi-structured data. Next, we introduce various algebras that
	 have been proposed to date with a particular emphasis on Niagara
	 Algebra. We discuss implementation of the operators in the Niagara
	 algebra. This paper proposes an improvement to the logical view of
	 the selection operator. We demonstrate the improvement due to our
	 implementation by experimental results. We find that the degree of
	 improvement depends on the nature of the XML data. The new operator is
	 particularly better at working with data that has a large number of elements
	 that need to be unnested in order to run a select. In addition, it
	 shows a significant improvement in situations where a large number of
	 elements must be evaluated to check if the selection criteria are met.}}

@inproceedings{AlKhalifa.Jagadish_MultiLevelOp_CIKM_2002,
	Address = {New York, NY, USA},
	Author = {Al-Khalifa, Shurug and Jagadish, H. V.},
	Booktitle = {Proc. Int. Conf. Information and Knowledge Management},
	Conference-Abbr = {CIKM},
	Doi = {http://doi.acm.org/10.1145/584792.584817},
	Isbn = {1-58113-492-4},
	Keywords = {XML XQuery algebra selection operators granularity},
	Location = {McLean, Virginia, USA},
	Pages = {134--141},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Al-Khalifa.Jagadish_Multi-levelOperatorCombination_CIKM_2002.pdf},
	Publisher = {ACM Press},
	Title = {{Multi-level Operator Combination in XML Query Processing}},
	Url = {http://www.eecs.umich.edu/db/timber/files/cikm02.pdf},
	Year = {2002},
	Abstract = {A core set of efficient access methods is central to the development of
	 any database system. In the context of an XML database, there has
	 been considerable effort devoted to defining a good set of primitive
	 operators and inventing efficient access methods for each individual
	 operator. These primitive operators have been defined either at the
	 macro-level (using a "pattern tree" to specify a selection, for example)
	 or at the micro-level (using multiple explicit containment joins
	 to instantiate a single XPath expression).In this paper we argue
	 that it is valuable to consider operations at each level. We do this
	 through a study of operator merging: the development of a new access
	 method to implement a combination of two or more primitive operators.
	 It is frequently the case that access methods for merged operators
	 are superior to a pipelined execution of separate access methods
	 for each operator. We show operator merging to be valuable at both
	 the micro-level and the macro-level. Furthermore, we show that the
	 corresponding merged operators are hard to reason with at the other
	 level.Specifically, we consider the influence of projections and set
	 operations on pattern-based selections and containment joins. We show,
	 through both analysis and extensive experimentation, the benefits of
	 considering these operations all together. Even though our experimental
	 verification is only with a native XML database, we have reason to believe
	 that our results apply equally to RDBMS-based XML query engines.}}

@inproceedings{Al-Khalifa.Jagadish.ea_StructJoins_ICDE_2002,
	Address = {Washington, DC, USA},
	Author = {Al-Khalifa, Shurug and Jagadish, H. V. and Koudas, Nick and Patel, Jignesh M. and Srivastava, Divesh and Wu, Yuqing},
	Booktitle = {Proc. Int. Conf. on Data Engineering},
	Conference-Abbr = {ICDE},
	Keywords = {XML join processing operators algebra query optimization},
	Pages = {141},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/StructuralJoins/Al-Khalifa.Jagadish.ea_StructJoins_ICDE_2002.pdf},
	Publisher = {IEEE Computer Society},
	Title = {{Structural Joins: A Primitive for Efficient XML Query Pattern Matching}},
	Url = {http://www.eecs.umich.edu/~jignesh/publ/xmljoin-ICDE.pdf},
	Year = {2002},
	Abstract = {XML queries typically specify patterns of selection predicates on multiple
	 elements that have some specified tree structured relationships.
	 The primitive tree structured relationships are parent-child and
	 ancestor-descendant, and finding all occurrences of these relationships in an
	 XML database is a core operation for XML query processing.In this
	 paper, we develop two families of structural join algorithms for this
	 task: tree-merge and stack-tree. The tree-merge algorithms are a
	 natural extension of traditional merge joins and the recently proposed
	 multi-predicate merge joins, while the stack-tree algorithms have no
	 counterpart in traditional relational join processing. We present
	 experimental results on a range of data and queries using the TIMBER
	 native XML query engine built on top of SHORE. We show that while, in
	 some cases, tree-merge algorithms can have performance comparable to
	 stack-tree algorithms, in many cases they are considerably worse.
	 This behavior is explained by analytical results that demonstrate
	 that, on sorted inputs, the stack-tree algorithms have worst-case I/O
	 and CPU complexities linear in the sum of the sizes of inputs and
	 output, while the tree-merge algorithms do not have the same guarantee.}}

@inproceedings{AmerYahia.Cho.ea_MinimizingTreePat_SIGMOD_2001,
	Address = {New York, NY, USA},
	Author = {Amer-Yahia, Sihem and Cho, SungRan and Lakshmanan, Laks V. S. and Srivastava, Divesh},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Doi = {http://doi.acm.org/10.1145/375663.375730},
	Isbn = {1-58113-332-4},
	Keywords = {XML tree pattern queries minimization},
	Location = {Santa Barbara, California, United States},
	Pages = {497--508},
	Pdf = {QueryEvaluation/XML/Containment/AmerYahia.Cho.ea_MinimizingTreePat_SIGMOD_2001.pdf},
	Publisher = {ACM Press},
	Title = {{Minimization of Tree Pattern Queries}},
	Url = {http://portal.acm.org/citation.cfm?id=375730},
	Year = {2001},
	Abstract = {Tree patterns form a natural
	 basis to query tree-structured data such as XML and LDAP. Since the
	 efficiency of tree pattern matching against a tree-structured database
	 depends on the size of the pattern, it is essential to identify and
	 eliminate redundant nodes in the pattern and do so as quickly as
	 possible. In this paper, we study tree pattern minimization both in the
	 absence and in the presence of integrity constraints (ICs) on the
	 underlying tree-structured database. When no ICs are considered, we
	 call the process of minizing a tree pattern, constraint-independent
	 minimization. We develop a polynomial time algorithm called CIM for this
	 purpose. CIM's efficiency stems from two key properties: (i) a node
	 cannot be redundant unless its children are, and (ii) the order of
	 elimination of redundant nodes is immaterial. When ICs are considered for
	 minimization, we refer to it as constraint-dependent minimization.
	 For tree-structured databases, required child/descendant andd type
	 co-occurrence ICs are very natural. Under such ICs, we show that the
	 minimal equivalent query is unique. We show the surprising result
	 that the algorithm obtained by first augmenting the tree pattern
	 using ICs, and then applying CIM, always finds the unique minimal
	 equivalent query; we refer to this algorithm as ACIM. While ACIM is
	 also polynomial time, it can be expensive in practice because of its
	 inherent non-locality. We then present a fast algorithm, CDM, that
	 identifies and eliminates local redundancies due to ICs, based on
	 propagating "information labels" up the tree pattern. CDM can be
	 applied prior to ACIM for improving the minimization efficiency. We
	 complement our analytical results with an experimental study that
	 shows the effectiveness of our tree pattern minimization techniques.}}

@inproceedings{Babcock.Chaudhuri_RobustOpti_SIGMOD_2005,
	__Markedentry = {0},
	Address = {New York, NY, USA},
	Author = {Babcock, Brian and Chaudhuri, Surajit},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of Dataime},
	Conference-Abbr = {SIGMOD},
	Doi = {http://doi.acm.org/10.1145/1066157.1066172},
	Isbn = {1-59593-060-4},
	Keywords = {query optimization query evaluation robustness},
	Location = {Baltimore, Maryland},
	Pages = {119--130},
	Pdf = {QueryEvaluation/Babcock.Chaudhuri_RobustOpti_SIGMOD_2005.pdf},
	Publisher = {ACM Press},
	Title = {{Towards a Robust Query Optimizer: A Principled and Practical Approach}},
	Url = {http://portal.acm.org/citation.cfm?id=1066157.1066172},
	Year = {2005},
	Abstract = {Research on query optimization has focused almost exclusively
	 on reducing query execution time, while important qualities such
	 as consistency and predictability have largely been ignored, even
	 though most database users consider these qualities to be at least as
	 important as raw performance. In this paper, we explore how the query
	 optimization process can be made more robust, focusing on the important
	 subproblem of cardinality estimation. The robust cardinality estimation
	 technique that we propose allows for a user- or application-specified
	 trade-off between performance and predictability, and it captures
	 multi-dimensional correlations while remaining space- and time-efficient.}}

@inproceedings{Babu.Bizarro.ea_ProactiveReopt_SIGMOD_2005,
	Author = {Babu, Shivnath and Bizarro, Pedro and DeWitt, David},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Keywords = {XML algebra query optimization query plan},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Babu.Bizarro.ea_ProactiveReopt_SIGMOD_2005.pdf},
	Title = {{Proactive Re-Optimization}},
	Url = {http://dbpubs.stanford.edu:8090/pub/2005-6},
	Year = {2005},
	Abstract = {Traditional query optimizers rely
	 on the accuracy of estimated statistics to choose good execution
	 plans. This design often leads to suboptimal plan choices for complex
	 queries, since errors in estimates for intermediate subexpressions
	 grow exponentially in the presence of skewed and correlated data
	 distributions. Re-optimization is a promising technique to cope with such
	 mistakes. Current re-optimizers first use a traditional optimizer
	 to pick a plan, and then react to estimation errors and resulting
	 suboptimalities detected in the plan during execution. The effectiveness of
	 this approach is limited because traditional optimizers choose plans
	 unaware of issues affecting re-optimization. We address this problem
	 using proactive re-optimization, a new approach that incorporates
	 three techniques: (1) the uncertainty in estimates of statistics is
	 computed in the form of bounding boxes around these estimates, (2) these
	 bounding boxes are used to pick plans that are robust to deviations
	 of actual values from their estimates, (3) accurate measurements
	 of statistics are collected quickly and efficiently during query
	 execution. We present an extensive evaluation of these techniques using
	 a prototype proactive re-optimizer named Rio. In our experiments
	 Rio outperforms current re-optimizers by up to a factor of three.}}

@inproceedings{BarYossef.Fontoura.ea_MemReqXPath_PODS_2004,
	Address = {New York, NY, USA},
	Author = {Bar-Yossef, Ziv and Fontoura, Marcus and Josifovski, Vanja},
	Booktitle = {Proc. ACM SIGMOD Symposium on Principles of Database Systems},
	Conference-Abbr = {PODS},
	Doi = {http://doi.acm.org/10.1145/1055558.1055584},
	Isbn = {158113858X/04/06},
	Keywords = {XML XPath memory complexity stream},
	Location = {Paris, France},
	Pages = {177--188},
	Pdf = {QueryEvaluation/XML/Comlexity/BarYossef.Fontoura.ea_MemReqXPath_PODS_2004.pdf},
	Publisher = {ACM Press},
	Title = {{On the Memory Requirements of XPath Evaluation over XML Streams}},
	Url = {http://www.ee.technion.ac.il/people/zivby/papers/xml/xmlfull.pdf},
	Year = {2004},
	Abstract = {The important challenge of evaluating XPath queries
	 over XML streams has sparked much interest in the past two years, A
	 number of algorithms have been proposed, supporting wider fragments of
	 the query language, and exhibiting better performance and memory
	 utilization. Nevertheless, all the algorithms known to date use a
	 prohibitively large amount of memory for certain types of queries. A natural
	 question then is whether this memory bottleneck is inherent or just
	 an artifact of the proposed algorithms.In this paper we initiate
	 the first systematic and theoretical study of lower bounds on the
	 amount of memory required to evaluate XPath queries over XML streams.
	 We present a general lower bound technique, which given a query,
	 specifies the minimum amount of memory that any algorithm evaluating the
	 query on a stream would need to incur. The lower bounds are stated in
	 terms of new graph-theoretic properties of queries. The proof is
	 based on tools from communication complexity.We then exploit insights
	 learned from the lower bounds to obtain a new algorithm for XPath
	 evaluation on streams. The algorithm uses space close to the optimum. Our
	 algorithm deviates from the standard paradigm of using automata or
	 transducers, thereby avoiding the need to store large transition tables.}}

@inproceedings{Bayardo.Gruhl.ea_BinaryXMLStream_WWW_2004,
	Author = {Bayardo, Roberto J. and Gruhl, Daniel and Josifovski, Vanja and Myllymaki, Jussi},
	Booktitle = {Proc. Int. World Wide Web Conf.},
	Conference-Abbr = {WWW},
	Doi = {http://doi.acm.org/10.1145/988672.988719},
	Isbn = {1-58113-844-X},
	Keywords = {XML XQuery stream binary encoding},
	Location = {New York, NY, USA},
	Pages = {345--354},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Bayardo.Gruhl.ea_BinaryXMLStream_WWW_2004.pdf},
	Publisher = {ACM Press},
	Title = {{An Evaluation of Binary XML Encoding Optimizations for fast Stream based XML Processing}},
	Url = {http://www.www2004.org/proceedings/docs/1p345.pdf},
	Year = {2004},
	Abstract = {This paper provides an objective evaluation of the performance
	 impacts of binary XML encodings, using a fast stream-based XQuery
	 processor as our representative application. Instead of proposing
	 one binary format and comparing it against standard XML parsers, we
	 investigate the individual effects of several binary encoding techniques
	 that are shared by many proposals. Our goal is to provide a deeper
	 understanding of the performance impacts of binary XML encodings in order to
	 clarify the ongoing and often contentious debate over their merits,
	 particularly in the domain of high performance XML stream processing.}}

@inproceedings{Beeri.Tzaban_SAL_WebDB_1999,
	Author = {Beeri, Catriel and Tzaban, Yariv},
	Booktitle = {Proc. Int. Workshop on the Web and Databases},
	Conference-Abbr = {WebDB},
	Keywords = {XML SAL algebra semi-structured XAL},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Beeri.Tzaban_SAL_WebDB_1999.pdf},
	Title = {{SAL: An Algebra for Semistructured Data and XML}},
	Url = {http://www-rocq.inria.fr/~cluet/WEBDB/beeri.ps},
	Year = {1999},
	Abstract = {--}}

@article{Berlea.Seidl_BinaryQueriesDocument_NJC_2004,
	Author = {Berlea, Alexandru and Seidl, Helmut},
	Journal = {Nordic Journal of Computing},
	Journal-Abbr = {NJC},
	Keywords = {XML query languages evluation binary queries fxt fxgrep},
	Number = {1},
	Pages = {41--71},
	Pdf = {QueryEvaluation/XML/Comlexity/Berlea.Seidl_BinaryQueriesDocument_NJC_2004.pdf},
	Title = {{Binary Queries for Document Trees}},
	Url = {http://atseidl2.informatik.tu-muenchen.de/~berlea/publications/njc/binaries.pdf},
	Volume = {11},
	Year = {2004},
	Abstract = {Motivated by XML applications, we address the problem of answering k-ary queries, i.e.
	 simultaneously locating k nodes of an input tree as specified by a given
	 relation. In particular, we discuss how binary queries can be used as a
	 means of navigation in XML document transformations. We introduce a
	 grammar-based approach to specifying k-ary queries. An efficient
	 tree-automata based implementation of unary queries is reviewed and the
	 extensions needed in order to implement k-ary queries are presented. In
	 particular, an efficient solution for the evaluation of binary queries
	 is provided and proven correct. We introduce fxgrep, a practical
	 implementation of unary and binary queries for XML. By means of fxgrep
	 and of the fxt XML transformation language we suggest how binary
	 queries can be used in order to increase expressivity of rule-based
	 transformations. We compare our work with other querying languages
	 and discuss how our ideas can be used for other existing settings.}}

@inproceedings{Beyer.Cochrane.ea_XQueryAnalytics_XIME-P_2004,
	Author = {Beyer, Kevin S. and Cochrane, Roberta and Colby, Latha S. and Ozcan, Fatma and Pirahesh, Hamid},
	Booktitle = {Proc. of Int. Workshop on XQuery Implementation, Experience and Perspectives ?XIME-P/?},
	Conference-Abbr = {XIME-P},
	Date-Modified = {2005-05-21 17:58:53 +0200},
	Keywords = {XQuery XML grouping analytics use cases group-by},
	Owner = {Tim Furche},
	Pages = {3-8},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/XQuery/Beyer.Cochrane.ea_XQueryAnalytics_XIME-P_2004.pdf},
	Title = {{XQuery for Analytics: Challenges and Requirements}},
	Url = {http://www-rocq.inria.fr/gemo/Gemo/Projects/XIME-P/CR/PDF/BeyerCR.pdf},
	Year = {2004},
	Abstract = {XML has emerged as the industry standard for
	 representing and exchanging data and is already predominant in several
	 applications today. Business, analytic, and structured data will
	 be exchanged as XML between applications and web services. XQuery
	 is a query language that is emerging as the standard for querying
	 XML data. The current version of the XQuery standard contains many
	 features for navigating the hierarchical and ordered content of XML
	 data. However, as compared to SQL, it lacks some key constructs which
	 makes it di cult to succinctly express and e ciently execute some
	 simple classes of analytic queries. In this paper, we describe some
	 of the limitations of the current XQuery language and argue that
	 extensions to XQuery are necessary to overcome these limitations.}}

@techreport{Boncz.Grust.ea_LoopStaircase_TR_2005,
	Author = {Boncz, Peter and Grust, Torsten and van Keulen, Maurice and Manegold, Stefan and Rittinger, Jan and Teubner, Jens},
	Institution = {CWI},
	Keywords = {XML staircase join structural join loop-lifting},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/StructuralJoins/Boncz.Grust.ea_LoopStaircase_TR_2005.pdf},
	Title = {{Loop-lifted Staircase Join: from XPath to XQuery}},
	Url = {http://www.inf.uni-konstanz.de/~rittinge/publications/INS-E0510.pdf},
	Year = {2005},
	Abstract = {Various techniques have been proposed for efficient evaluation of XPath expressions,
	 where the XPath location steps are rooted in a single sequence of
	 context nodes. Among these techniques, the staircase join allows
	 to evaluate XPath location steps along arbitrary axes in at most
	 one scan over the XML document, exploiting the XPath accelerator
	 encoding (aka. pre/post encoding). In XQuery, however, embedded XPath
	 sub-expressions occur in arbitrarily nested for-loops. Thus, they are rooted in
	 multiple sequences of context nodes (one per iteration). Consequently,
	 the previously proposed algorithms need to be applied repeatedly,
	 requiring multiple scans over the XML document encoding. In this
	 work, we present loop-lifted staircase join, an extension of the
	 staircase join that allows to efficiently evaluate XPath sub-expressions
	 in arbitrarily nested XQuery iteration scopes with only a single
	 scan over the document. We implemented the loop-lifted staircase
	 join in MonetDB/XQuery, that uses the XQuery-to-Relational Algebra
	 compiler Pathfinder on top of the extensible RDBMS MonetDB. Performance
	 results indicate that the proposed technique allows to build a system
	 that is capable of efficiently evaluating XQuery queries including
	 embedded XPath expressions, obtaining interactive query execution
	 times for all XMark queries even on multi-gigabyte XML documents.}}

@techreport{Boncz.Grust.ea_Pathfinder_TR_2005,
	Address = {Amsterdam, The Netherlands},
	Author = {Boncz, Peter and Grust, Torsten and Manegold, Stefan and Rittinger, Jan and Teubner, Jens},
	Institution = {CWI},
	Keywords = {XML Pathfinder joins relational implementation},
	Number = {INS-E0503},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Boncz.Grust.ea_Pathfinder_TR_2005.pdf},
	Title = {{Pathfinder: Relational XQuery Over Multi-Gigabyte XML Inputs In Interactive Time}},
	Url = {http://www.inf.uni-konstanz.de/~rittinge/publications/INS-E0503.pdf},
	Year = {2005},
	Abstract = {Pathfinder/MonetDB is a collaborative effort
	 of the University of Konstanz, the University of Twente, and the
	 Centrum voor Wiskunde en Informatica (CWI) in Amsterdam to develop
	 an XQuery compiler that targets an RDBMS back-end. The author of
	 this abstract is student at the University of Konstanz and spent
	 six months as an intern at the CWI, designing and implementing a
	 translation of XQuery Core to (a variant of) relational algebra. His
	 work continues in the research group at the University of Konstanz.}}

@inproceedings{Bothner_XQuery2Java_XIME-P_2004,
	Author = {Bothner, Per},
	Booktitle = {Proc. of Int. Workshop on XQuery Implementation, Experience and Perspectives <XIME-P/>},
	Conference-Abbr = {XIME-P},
	Keywords = {XML XQuery Bytecode Java translation},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Translating/Bothner_XQuery2Java_XIME-P_2004.pdf},
	Title = {{Compiling XQuery to Java Bytecodes}},
	Url = {http://per.bothner.com/papers/Qexo04/},
	Year = {2004},
	Abstract = {--}}

@inproceedings{Brantner.Helmer.ea_AlgebraicXPath_ICDE_2005,
	Address = {Washington, DC, USA},
	Author = {Brantner, Matthias and Helmer, Sven and Kanne, Carl-Christian and Moerkotte, Guido},
	Booktitle = {Proc. Inst. Conf. on Data Engineering},
	Conference-Abbr = {ICDE},
	Doi = {http://dx.doi.org/10.1109/ICDE.2005.69},
	Isbn = {0-7695-2285-8},
	Keywords = {XML native database algebra natix XPath},
	Pages = {705--716},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Brantner.Helmer.ea_Full-FledgedAlgebraicXPath_ICDE_2005.pdf},
	Publisher = {IEEE Computer Society},
	Title = {{Full-Fledged Algebraic XPath Processing in Natix}},
	Url = {http://pi3.informatik.uni-mannheim.de/publications/xpath_icde2005.pdf},
	Year = {2005},
	Abstract = {We present the first complete translation of XPath into an algebra, paving the way for a
	 comprehensive, state-of-the-art XPath (and later on, XQuery) compiler based
	 on algebraic optimization techniques. Our translation includes all
	 XPath features such as nested expressions, position-based predicates
	 and node-set functions. The translated algebraic expressions can
	 be executed using the proven, scalable, iterator-based approach,
	 as we demonstrate in form of a corresponding physical algebra in
	 our native XML DBMS Natix. A first glance at performance results
	 shows that even without further optimization of the expressions,
	 we provide a competitive evaluation technique for XPath queries.}}

@inproceedings{Brantner.Kanne.ea_CostReorderNavi_SIGMOD_2005,
	Author = {Brantner, Matthias and Kanne, Carl-Christian and Moerkotte, Guido},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Keywords = {XML XPath query optimization Natix navigational reordering},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Brantner.Kanne.ea_CostReorderNavi_SIGMOD_2005.pdf},
	Title = {{Cost-Sensitive Reordering of Navigational Primitives}},
	Url = {http://pi3.informatik.uni-mannheim.de/publications/xassembly_sigmod2005.pdf},
	Year = {2005},
	Abstract = {We present a method to evaluate path queries
	 based on the novel concept of partial path instances. Our method (1)
	 maximizes performance by means of sequential scans or asynchronous I/O,
	 (2) does not require a special storage format, (3) relies on simple
	 navigational primitives on trees, and (4) can be complemented by existing
	 logical and physical optimizations such as duplicate elimination,
	 duplicate prevention and path rewriting. We use a physical algebra which
	 separates those navigation operations that require I/O from those that do
	 not. All I/O operations necessary for the evaluation of a path are
	 isolated in a single operator, which may employ ef cient I/O scheduling
	 strategies such as sequential scans or asynchronous I/O. Performance
	 results for queries from the XMark benchmark show that reordering the
	 navigation operations can increase performance up to a factor of four.}}

@inproceedings{Bruno.Maitre.ea_ExtXQueryTransform_DocEng_2003,
	Author = {Bruno, Emmanuel and Maitre, Jacques Le and Murisasco, Elisabeth},
	Booktitle = {Proc. ACM symposium on Document Engineering},
	Conference-Abbr = {DocEng},
	Date-Modified = {2005-05-21 18:05:17 +0200},
	Doi = {http://doi.acm.org/10.1145/958220.958223},
	Isbn = {1-58113-724-9},
	Keywords = {XML XQuery transformations document engineering query languages},
	Location = {Grenoble, France},
	Pages = {1--8},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/XQuery/Bruno.Maitre.ea_ExtXQueryTransform_DocEng_2003.pdf},
	Publisher = {ACM Press},
	Title = {{Extending XQuery with Transformation Operators}},
	Url = {http://www.univ-tln.fr/~lemaitre/doceng2003.pdf},
	Year = {2003},
	Abstract = {In this paper, we propose to extend XQuery - the
	 XML query language - with a set of transformation operators which
	 will produce a copy of an XML tree in which some subtrees will be
	 inserted, replaced or deleted. These operators - very similar to the
	 ones proposed for updating an XML document - greatly simplify the
	 expression of some queries in making it possible to express only
	 the modified part of a tree instead of its whole reconstruction. We
	 compare the expressivity of XQuery extended in this way with XSLT.}}

@inproceedings{Bruno.Koudas.ea_HolisticTwigJoins_SIGMOD_2002,
	Address = {New York, NY, USA},
	Author = {Bruno, Nicolas and Koudas, Nick and Srivastava, Divesh},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Doi = {http://doi.acm.org/10.1145/564691.564727},
	Isbn = {1-58113-497-5},
	Keywords = {XML structural joins twig joins query optimization pattern matching},
	Location = {Madison, Wisconsin},
	Pages = {310--321},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/StructuralJoins/Bruno.Koudas.ea_HolisticTwigJoins_SIGMOD_2002.pdf},
	Publisher = {ACM Press},
	Title = {{Holistic Twig Joins: Optimal XML Pattern Matching}},
	Url = {http://www.research.att.com/~divesh/papers/bks2002-twigjoin.pdf},
	Year = {2002},
	Abstract = {XML employs a tree-structured data model, and, naturally, XML queries specify patterns of
	 selection predicates on multiple elements related by a tree structure.
	 Finding all occurrences of such a twig pattern in an XML database is a
	 core operation for XML query processing. Prior work has typically
	 decomposed the twig pattern into binary structural (parent-child and
	 ancestor-descendant) relationships, and twig matching is achieved by: (i) using
	 structural join algorithms to match the binary relationships against
	 the XML database, and (ii) stitching together these basic matches.
	 A limitation of this approach for matching twig patterns is that
	 intermediate result sizes can get large, even when the input and
	 output sizes are more manageable.In this paper, we propose a novel
	 holistic twig join algorithm, TwigStack, for matching an XML query twig
	 pattern. Our technique uses a chain of linked stacks to compactly
	 represent partial results to root-to-leaf query paths, which are
	 then composed to obtain matches for the twig pattern. When the twig
	 pattern uses only ancestor-descendant relationships between elements,
	 TwigStack is I/O and CPU optimal among all sequential algorithms
	 that read the entire input: it is linear in the sum of sizes of the
	 input lists and the final result list, but independent of the sizes
	 of intermediate results. We then show how to use (a modification
	 of) B-trees, along with TwigStack, to match query twig patterns in
	 sub-linear time. Finally, we complement our analysis with experimental
	 results on a range of real and synthetic data, and query twig patterns.}}

@article{Buneman.Fernandez.ea_UnQL_VLDBJ_2000,
	Address = {Secaucus, NJ, USA},
	Author = {Buneman, Peter and Fernandez, Mary and Suciu, Dan},
	Doi = {http://dx.doi.org/10.1007/s007780050084},
	Issn = {1066-8888},
	Journal = {VLDB Journal},
	Journal-Abbr = {VLDBJ},
	Keywords = {XML UnQL algebra query language query optimization structural recursion},
	Number = {1},
	Pages = {76--110},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/Buneman.Fernandez.ea_UnQL_VLDBJ_2000.pdf},
	Publisher = {Springer-Verlag New York, Inc.},
	Title = {{UnQL: a query language and algebra for semistructured data based on structural recursion}},
	Url = {http://portal.acm.org/citation.cfm?id=765224},
	Volume = {9},
	Year = {2000},
	Abstract = {This paper presents structural recursion as the basis of the syntax and semantics of query
	 languages for semistructured data and XML. We describe a simple and
	 powerful query language based on pattern matching and show that it can
	 be expressed using structural recursion, which is introduced as a
	 top-down, recursive function, similar to the way XSL is defined on XML
	 trees. On cyclic data, structural recursion can be defined in two
	 equivalent ways: as a recursive function which evaluates the data top-down
	 and remembers all its calls to avoid infinite loops, or as a bulk
	 evaluation which processes the entire data in parallel using only
	 traditional relational algebra operators. The latter makes it possible for
	 optimization techniques in relational queries to be applied to structural
	 recursion. We show that the composition of two structural recursion
	 queries can be expressed as a single such query, and this is used as
	 the basis of an optimization method for mediator systems. Several
	 other formal properties are established: structural recursion can be
	 expressed in first-order logic extended with transitive closure; its data
	 complexity is PTIME; and over relational data it is a conservative
	 extension of the relational calculus. The underlying data model is based
	 on value equality, formally defined with bisimulation. Structural
	 recursion is shown to be invariant with respect to value equality.}}

@inproceedings{Calvanese.Giacomo.ea_ContainCRPQI_KR_2000,
	Author = {Calvanese, Diego and Giacomo, Giuseppe De and Lenzerini, Maurizio and Vardi, Moshe Y.},
	Booktitle = {Proc. Int. Conf. on the Principles of Knowledge Representation and Reasoning},
	Conference-Abbr = {KR},
	Keywords = {query processing containment path expressions inverse conjunctive},
	Pages = {176--185},
	Pdf = {QueryEvaluation/XML/Containment/Calvanese.Giacomo.ea_ContainCRPQI_KR_2000.pdf},
	Title = {{Containment of Conjunctive Regular Path Queries with Inverse}},
	Url = {http://www.inf.unibz.it/%7ecalvanese/papers/calv-degi-lenz-vard-KR-2000.ps.gz},
	Year = {2000},
	Abstract = {Reasoning on queries is
	 a basic problem both in knowledge representation and databases. A
	 fundamental form of reasoning on queries is checking containment, i.e.,
	 verifying whether one query yields necessarily a subset of the result of
	 another query. Query containment is crucial in several contexts,
	 such as query optimization, knowledge base verification, information
	 integration, database integrity checking, and cooperative answering.
	 In this paper we address the problem of query containment in the
	 context of semistructured knowledge bases, where the basic querying
	 mechanism, namely regular path queries, asks for all pairs of objects
	 that are connected by a path conforming to a regular expression.
	 We consider conjunctive regular path queries with inverse, which
	 extend regular path queries with the possibility of using both the
	 inverse of binary relations, and conjunctions of atoms, where each atom
	 specifies that one regular path query with inverse holds between
	 two variables. We present a novel technique to check containment of
	 queries in this class, based on the use of two-way finite automata. The
	 technique shows the power of two-way automata in dealing with the inverse
	 operator and with the variables in the queries. We also characterize the
	 computational complexity of both the proposed algorithm and the problem.}}

@inproceedings{Calvanese.Giacomo.ea_ViewsRPQI_PODS_2000,
	Author = {Calvanese, Diego and Giacomo, Giuseppe De and Lenzerini, Maurizio and Vardi, Moshe Y.},
	Booktitle = {Proc. ACM SIGMOD Principles of Databases Symposium},
	Conference-Abbr = {PODS},
	Keywords = {conjunctive queries query languages regular path expressions inverse views optimization},
	Pages = {58--66},
	Pdf = {QueryEvaluation/XML/Containment/Calvanese.Giacomo.ea_ViewsRPQI_PODS_2000.pdf},
	Title = {{Query Processing using Views for Regular Path Queries with Inverse}},
	Url = {http://www.inf.unibz.it/%7ecalvanese/papers/calv-degi-lenz-vard-PODS-2000.ps.gz},
	Year = {2000},
	Abstract = {Query processing using views is the problem of
	 computing the answer to a query based on a set of materialized views,
	 rather than on the raw data in the database. The problem comes in
	 two different forms, called query rewriting and query answering,
	 respectively. In the first form, we are given a query and a set of view
	 definitions, and the goal is to reformulate the query into an expression
	 that refers only to the views. In the second form, besides the query
	 and the view definitions, we are also given the extensions of the
	 views and a tuple, and the goal is to check whether the knowledge on
	 the view extensions logically implies that the tuple satisfies the
	 query. In this paper we address the problem of query processing using
	 views in the context of semistructured data, in particular for the
	 case of regular path queries extended with the inverse operator.
	 Several authors point out that the inverse operator is one of the
	 fundamental extensions for making regular path queries useful in real
	 settings. We present a novel technique based on the use of two-way finite
	 automata. Our approach demonstrates the power of this kind of automata in
	 dealing with the inverse operator, allowing us to show that both query
	 rewriting and query answering with the inverse operator has the same
	 computational complexity as for the case of standard regular path queries.}}

@inproceedings{Catania.Wang.ea_LazyXML_SIGMOD_2005,
	Author = {Catania, Barbara and Wang, Wenqiang and Ooi, Beng Chin and Wang, Xiaoling},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Keywords = {XML updates structural join laziness query optimization},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/NestedQueries/Catania.Wang.ea_LazyXML_SIGMOD_2005.pdf},
	Title = {{Lazy XML Updates: Laziness as a Virtue of Update and Structural Join Efficiency}},
	Url = {http://www.comp.nus.edu.sg/~ooibc/sigmod386.pdf},
	Year = {2005},
	Abstract = {XML documents are normally stored as plain text files. Hence,
	 the natural and most convenient way to update XML documents is to
	 simply edit the text files. But efficient query evaluation algorithms
	 require XML documents to be in- dexed. Every element is given a unique
	 identifier based on its location in the document or its preorder-traversal
	 order, and this identifier is later used as (part of) the key in the
	 index. Reassigning orders of possibly a large number of elements is
	 therefore necessary when the original XML documents are updated.
	 Immutable dynamic labeling schemes have been proposed to solve this
	 problem, that, however, require very long labels and may decrease query
	 performance. If we con- sider a real-world scenario, we note that many
	 relatively small ad-hoc XML segments are inserted/deleted into/from an
	 existing XML database. In this paper, we start from this consideration
	 and we propose a new lazy approach to handle XML updates that also
	 improves query performance. The lazy approach: (i) completely avoids
	 reassigning existing el- ement orders after updates; (ii) improves
	 query processing by taking advantages from segments. Experimental
	 results show that our approach is much more efficient in handling
	 updates than using immutable labeling and, at the same time, it also
	 improves the performance of recently defined structural join algorithms.}}

@inproceedings{Chan.Fan.ea_TamingXPathQueries_VLDB_2004,
	Author = {Chan, Chee-Yong and Fan, Wenfei and Zeng, Yiming},
	Booktitle = {Proc. Int. Conf. on Very Large Databases},
	Conference-Abbr = {VLDB},
	Keywords = {XML query rewriting query optimization XPath},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Containment/Chan.Fan.ea_TamingXPathQueries_VLDB_2004.pdf},
	Title = {{Taming XPath Queries by Minimizing Wildcard Steps}},
	Url = {http://www.vldb.org/conf/2004/RS4P4.PDF},
	Year = {2004},
	Abstract = {This paper presents a novel and complementary
	 technique to optimize an XPath query by minimizing its wildcard steps.
	 Our approach is based on using a general composite axis called the
	 layer axis, to rewrite a sequence of XPath steps (all of which are
	 wildcard steps except for possibly the last) into a single layer-axis
	 step. We describe an efficient implementation of the layer axis and
	 present a novel and efficient rewriting algorithm to minimize both
	 non-branching as well as branching wildcard steps in XPath queries. We also
	 demonstrate the usefulness of wildcard-step elimination by proposing an
	 optimized evaluation strategy for wildcard-free XPath queries that
	 enables selective loading of only the relevant input XML data for
	 query evaluation. Our experimental results not only validate the
	 scalability and efficiency of our optimized evaluation strategy, but also
	 demonstrate the effectiveness of our rewriting algorithm for minimizing
	 wildcard steps in XPath queries. To the best of our knowledge, this
	 is the first effort that addresses this new optimization problem.}}

@inproceedings{Chen.Rundensteiner_XQueryVar_WWW_2005,
	Address = {New York, NY, USA},
	Author = {Chen, Li and Rundensteiner, Elke A.},
	Booktitle = {Proc. Int. World Wide Web Conf.},
	Conference-Abbr = {WWW},
	Doi = {http://doi.acm.org/10.1145/1060745.1060789},
	Isbn = {1-59593-046-9},
	Keywords = {XML containment XQuery variables},
	Location = {Chiba, Japan},
	Pages = {288--297},
	Pdf = {QueryEvaluation/XML/Containment/Chen.Rundensteiner_XQueryVar_WWW_2005.pdf},
	Publisher = {ACM Press},
	Title = {{XQuery Containment in Presence of Variable Binding Dependencies}},
	Year = {2005},
	Abstract = {Semantic caching is an important technology
	 for improving the response time of future user queries specified
	 over remote servers. This paper deals with the fundamental query
	 containment problem in an XQuery-based semantic caching system. To our best
	 knowledge, the impact of subtle differences in XQuery semantics caused
	 by different ways of specifying variables on query containment has
	 not yet been studied. We introduce the concept of variable binding
	 dependencies for representing the hierarchical element dependencies
	 preserved by an XQuery. We analyze the problem of XQuery containment in
	 the presence of such dependencies. We propose a containment mapping
	 technique for nested XQuery in presence of variable binding dependencies.
	 The implication of the nested block structure on XQuery containment
	 is also considered. We mention the performance gains achieved by a
	 semantic caching system we build based on the proposed technique.}}

@inproceedings{Chen.Rundensteiner_ACEXQ_WebDB_2002,
	Author = {Chen, Li and Rundensteiner, Elke A.},
	Booktitle = {Proc. Workshop on the Web and Databases},
	Conference-Abbr = {WebDB},
	Keywords = {XML XQuery views processing evaluation},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Containment/Chen.Rundensteiner_ACEXQ_WebDB_2002.pdf},
	Title = {{ACE-XQ: A CachE-aware XQuery Answering System}},
	Url = {http://www.cs.wpi.edu/~lichen/papers/webdb02-acexq.ps},
	Year = {2002},
	Abstract = {Caching popular queries and reusing results of these previously
	 computed queries to speed up query processing is one important query
	 optimization technique for distributed environments such as the Web.
	 However, exisiting query-based cache systems, based on query containment
	 and rewriting techniques developed for relational queries, are not
	 appropriate for supporting more powerful XML queries. We hence propose the
	 first solution for XML query processing using cached XQuery views.
	 In particular, we describe in this paper an XQuery-based semantic
	 caching system called ACE-XQ, that we have implemented to realize the
	 proposed containment mapping and query rewriting techniques. Preliminary
	 experiments confirm the feasibility of our approach and also illustrate the
	 performance gains achievable by ACE-XQ over the original XQuery engine.}}

@inproceedings{Chen.Lu.ea_BoostingHolism_SIGMOD_2005,
	Address = {New York, NY, USA},
	Author = {Chen, Ting and Lu, Jiaheng and Ling, Tok Wang},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Doi = {http://doi.acm.org/10.1145/1066157.1066209},
	Isbn = {1-59593-060-4},
	Keywords = {XML XPath holistic joins twig joins structural joins},
	Location = {Baltimore, Maryland},
	Pages = {455--466},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/StructuralJoins/Chen.Lu.ea_BoostingHolism_SIGMOD_2005.pdf},
	Publisher = {ACM Press},
	Title = {{On Boosting Holism in XML Twig Pattern Matching using Structural Indexing Techniques}},
	Url = {http://portal.acm.org/citation.cfm?id=1066157.1066209},
	Year = {2005},
	Abstract = {Searching for all occurrences of a twig pattern in
	 an XML document is an important operation in XML query processing.
	 Recently a holistic method TwigStack. [2] has been proposed. The
	 method avoids generating large intermediate results which do not
	 contribute to the final answer and is CPU and I/O optimal when twig
	 patterns only have ancestor-descendant relationships. Another important
	 direction of XML query processing is to build structural indexes
	 [3][8][13][15] over XML documents to avoid unnecessary scanning of
	 source documents. We regard XML structural indexing as a technique to
	 partition XML documents and call it streaming scheme in our paper.
	 In this paper we develop a method to perform holistic twig pattern
	 matching on XML documents partitioned using various streaming schemes.
	 Our method avoids unnecessary scanning of irrelevant portion of XML
	 documents. More importantly, depending on different streaming schemes
	 used, it can process a large class of twig patterns consisting of
	 both ancestor-descendant and parent-child relationships and avoid
	 generating redundant intermediate results. Our experiments demonstrate
	 the applicability and the performance advantages of our approach.}}

@inproceedings{Chen.Davidson.ea_BLAS_SIGMOD_2004,
	Address = {New York, NY, USA},
	Author = {Chen, Yi and Davidson, Susan B. and Zheng, Yifeng},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of data},
	Conference-Abbr = {SIGMOD},
	Doi = {http://doi.acm.org/10.1145/1007568.1007577},
	Isbn = {1-58113-859-8},
	Keywords = {XML XPath BLAS labelling indexing query optimization},
	Location = {Paris, France},
	Pages = {47--58},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/Chen.Davidson.ea_BLAS_SIGMOD_2004.pdf},
	Publisher = {ACM Press},
	Title = {{BLAS: An Efficient XPath Processing System}},
	Url = {http://www.cis.upenn.edu/~yicn/blas.pdf},
	Year = {2004},
	Abstract = {We present BLAS, a Bi-LAbeling based System, for efficiently processing
	 complex XPath queries over XML data. BLAS uses P-labeling to process
	 queries involving consecutive child axes, and D-labeling to process
	 queries involving descendant axes traversal. The XML data is stored in
	 labeled form, and indexed to optimize descendent axis traversals. Three
	 algorithms are presented for translating complex XPath queries to SQL
	 expressions, and two alternate query engines are provided. Experimental
	 results demonstrate that the BLAS system has a substantial performance
	 improvement compared to traditional XPath processing using D-labeling.}}

@inproceedings{Chen.Jagadish.ea_GeneralizedTreePats_VLDB_2003,
	Author = {Chen, Zhimin and Jagadish, H. V. and Lakshmanan, Laks V.S. and Paparizos, Stelios},
	Booktitle = {Proc. Int. Conf. on Very Large Databases},
	Conference-Abbr = {VLDB},
	Keywords = {XML XQuery optimization generalized tree patterns nested queries},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Chen.Jagadish.ea_GeneralizedTreePats_VLDB_2003.pdf},
	Title = {{From Tree Patterns to Generalized Tree Patterns: On Efficient Evaluation of XQuery}},
	Url = {http://www.vldb.org/conf/2003/papers/S08P03.pdf},
	Year = {2003},
	Abstract = {XQuery is the de facto standard XML
	 query language, and it is important to have e cient query evaluation
	 techniques available for it. A core operation in the evaluation of XQuery
	 is the nding of matches for speci ed tree patterns, and there has
	 been much work towards algorithms for nding such matches e ciently.
	 Multiple XPath expressions can be evaluated by computing one or more
	 tree pattern matches. However, relatively little has been done on
	 e - cient evaluation of XQuery queries as a whole. In this paper,
	 we argue that there is much more to XQuery evaluation than a tree
	 pattern match. We propose a structure called generalized tree pat-
	 tern (GTP) for concise representation of a whole XQuery expression.
	 Evaluating the query reduces to nding matches for its GTP. Using this
	 idea we develop e cient evaluation plans for XQuery expressions,
	 possibly involving join, quanti ers, grouping, aggregation, and nesting.
	 XML data often conforms to a schema. We show that using relevant
	 constraints from the schema, one can optimize queries signi cantly, and
	 give algorithms for automatically inferring GTP simpli cations given
	 a schema. Finally, we show, through a detailed set of experiments
	 using the TIMBER XML database system, that plans via GTPs (with or
	 without schema knowledge) signi cantly outperform plans based on
	 navigation and straightforward plans obtained directly from the query.}}

@article{Christophides.ea_QueryStructured_SIGR_1994,
	Address = {New York, NY, USA},
	Author = {Christophides, V. and Abiteboul, S. and Cluet, S. and Scholl, M.},
	Doi = {http://doi.acm.org/10.1145/191843.191901},
	Issn = {0163-5808},
	Journal = {SIGMOD Record},
	Journal-Abbr = {SIGR},
	Keywords = {XML semi-structured data query path expressions O2SQL path variables},
	Number = {2},
	Pages = {313--324},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/PathVariables/Christophides.Abiteboul.ea_StructuredDocsQuery_SIGR_1994.pdf},
	Publisher = {ACM Press},
	Title = {{From Structured Documents to Novel Query Facilities}},
	Url = {http://portal.acm.org/citation.cfm?id=191843.191901},
	Volume = {23},
	Year = {1994},
	Abstract = {Structured documents (e.g., SGML) can benefit a lot from
	 database support and more specifically from object-oriented database
	 (OODB) management systems. This paper describes a natural mapping
	 from SGML documents into OODB's and a formal extension of two OODB
	 query languages (one SQL-like and the other calculus) in order to
	 deal with SGML document retrieval.Although motivated by structured
	 documents, the extensions of query languages that we present are
	 general and useful for a variety of other OODB applications. A key
	 element is the introduction of paths as first class citizens. The new
	 features allow to query data (and to some extent schema) without
	 exact knowledge of the schema in a simple and homogeneous fashion.}}

@inproceedings{Cohen.Halperin.ea_Reachability2Hop_SODA_2002,
	Address = {Philadelphia, PA, USA},
	Author = {Cohen, Edith and Halperin, Eran and Kaplan, Haim and Zwick, Uri},
	Booktitle = {Proc. ACM Symposium on Discrete Algorithms},
	Conference-Abbr = {SODA},
	Isbn = {0-89871-513-X},
	Keywords = {transitive closure reachability graph 2-hop labelling indexing},
	Location = {San Francisco, California},
	Pages = {937--946},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/Cohen.Halperin.ea_Reachability2Hop_SODA_2002.pdf},
	Publisher = {Society for Industrial and Applied Mathematics},
	Title = {{Reachability and Distance Queries via 2-hop Labels}},
	Url = {http://portal.acm.org/citation.cfm?id=545381.545503},
	Year = {2002},
	Abstract = {Reachability and distance queries in graphs are fundamental to
	 numerous applications, ranging from geographic navigation systems to
	 Internet routing. Some of these applications involve huge graphs and
	 yet require fast query answering. We propose a new data structure
	 for representing all distances in a graph. The data structure is
	 distributed in the sense that it may be viewed as assigning labels to the
	 vertices, such that a query involving vertices u and v may be answered
	 using only the labels of u and v.Our labels are based on 2-hop covers
	 of the shortest paths, or of all paths, in a graph. For shortest
	 paths, such a cover is a collection S of shortest paths such that for
	 every two vertices u and v, there is a shortest path from u to v that
	 is a concatenation of two paths from S. We describe an efficient
	 algorithm for finding an almost optimal 2-hop cover of a given collection
	 of paths. Our approach is general and can be applied to directed
	 or undirected graphs, exact or approximate shortest paths, or to
	 reachability queries.We study the proposed data structure using a
	 combination of theoretical and experimental means. We implemented our
	 algorithm and checked the size of the resulting data structure on several
	 real-life networks from different application areas. Our experiments
	 show that the total size of the labels is typically not much larger
	 than the network itself, and is usually considerably smaller than an
	 explicit representation of the transitive closure of the network.}}

@inproceedings{Cohen.Kaplan.ea_LabelingDynamicXML_PODS_2002,
	Address = {New York, NY, USA},
	Author = {Cohen, Edith and Kaplan, Haim and Milo, Tova},
	Booktitle = {Proc. ACM SIGMOD Symposium on Principles of Database Systems},
	Conference-Abbr = {PODS},
	Doi = {http://doi.acm.org/10.1145/543613.543648},
	Isbn = {1-58113-507-6},
	Keywords = {XML labeling indexing dynamic 2-hop reachability},
	Location = {Madison, Wisconsin},
	Pages = {271--281},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/Cohen.Kaplan.ea_LabelingDynamicXML_PODS_2002.pdf},
	Publisher = {ACM Press},
	Title = {{Labeling Dynamic XML Trees}},
	Url = {http://portal.acm.org/citation.cfm?id=543648},
	Year = {2002},
	Abstract = {We present algorithms to
	 label the nodes of an XML tree which is subject to insertions and
	 deletions of nodes. The labeling is done such that (1) we label each node
	 immediately when it is inserted and this label remains unchanged, and (2)
	 from a pair of labels alone, we can decide whether one node is an
	 ancestor of the other. This problem arises in the context of XML
	 databases that support queries on the structure of the documents as
	 well us on the changes made to the documents over time. We prove
	 that our algorithms assign the shortest possible labels (up to a
	 constant factor) which satisfy these requirements.We also consider the
	 same problem when "clues" that provide guarantees on possible future
	 insertions are given together with newly inserted nodes. Such clues can be
	 derived from the DTD or from statistics on similar XML trees. We
	 present algorithms that use the clues to assign shorter labels. We also
	 prove that the length of our labels is close to the minimum possible.}}

@inproceedings{Cooper.Sample.ea_FastIndexSSD_VLDB_2001,
	Address = {San Francisco, CA, USA},
	Author = {Cooper, Brian and Sample, Neal and Franklin, Michael J. and Hjaltason, Gisli R. and Shadmon, Moshe},
	Booktitle = {Proc. Int. Conf. on Very Large Databases},
	Conference-Abbr = {VLDB},
	Isbn = {1-55860-804-4},
	Keywords = {XML semi-structured data index fast},
	Pages = {341--350},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/Cooper.Sample.ea_FastIndexSSD_VLDB_2001.pdf},
	Publisher = {Morgan Kaufmann Publishers Inc.},
	Title = {{A Fast Index for Semistructured Data}},
	Url = {http://www.vldb.org/conf/2001/P341.pdf},
	Year = {2001},
	Abstract = {Queries navigate semistructured data
	 via path expressions, and can be accelerated using an index. Our
	 solution encodes paths as strings, and inserts those strings into a
	 special index that is highly optimized for long and complex keys. We
	 describe the Index Fabric, an indexing structure that provides the
	 efficiency and flexibility we need. We discuss how "raw paths" are
	 used to optimize ad hoc queries over semistructured data, and how
	 "refined paths" optimize specific access paths. Although we can use
	 knowledge about the queries and structure of the data to create refined
	 paths, no such knowledge is needed for raw paths. A performance study
	 shows that our techniques, when implemented on top of a commercial
	 relational database system, outperform the more traditional approach of
	 using the commercial system?s indexing mechanisms to query the XML.}}

@inproceedings{DeHaan.Toman.ea_XQuery2SQL_SIGMOD_2003,
	Author = {DeHaan, David and Toman, David and Consens, Mariano P. and {\"O}zsu, M. Tamer},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Data Management},
	Conference-Abbr = {SIGMOD},
	Doi = {http://doi.acm.org/10.1145/872757.872832},
	Isbn = {1-58113-634-X},
	Keywords = {XML XQuery relational implementation tree encoding dynamic interval encoding},
	Location = {San Diego, California},
	Pages = {623--634},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Translating/DeHaan.Toman.ea_XQuery2SQL_SIGMOD_2003.pdf},
	Publisher = {ACM Press},
	Title = {{A Comprehensive XQuery to SQL Translation using Dynamic Interval Encoding}},
	Url = {http://db.uwaterloo.ca/~david/cs848/toman-et-al-sigmod.pdf},
	Year = {2003},
	Abstract = {The W3C XQuery language
	 recommendation, based on a hierarchical and ordered document model, supports a
	 wide variety of constructs and use cases. There is a diversity of
	 approaches and strategies for evaluating XQuery expressions, in many
	 cases only dealing with limited subsets of the language. In this
	 paper we describe an implementation approach that handles XQuery with
	 arbitrarily-nested FLWR expressions, element constructors and built-in
	 functions (including structural comparisons). Our proposal maps an XQuery
	 expression to a single equivalent SQL query using a novel dynamic interval
	 encoding of a collection of XML documents as relations, augmented with
	 information tied to the query evaluation environment. The dynamic
	 interval technique enables (suitably enhanced) relational engines to
	 produce predictably good query plans that do not preclude the use of
	 sort-merge join query operators. The benefits are realized despite the
	 challenges presented by intermediate results that create arbitrary
	 documents and the need to preserve document order as prescribed by
	 semantics of XQuery. Finally, our experimental results demonstrate
	 that (native or relational) XML systems can benefit from the above
	 technique to avoid a quadratic scale up penalty that effectively
	 prevents the evaluation of nested FLWR expressions for large documents.}}

@inproceedings{Deutsch.Papakonst.ea_NestedQueries_ICDE_2004,
	Author = {Deutsch, Alin and Papakonstantinou, Yannis and Xu, Yu},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {Proc. Int. Conf. on Data Engineering},
	Conference-Abbr = {ICDE},
	Crossref = {DBLP:conf/icde/2004},
	Ee = {http://csdl.computer.org/comp/proceedings/icde/2004/2065/00/20650839.pdf},
	Keywords = {XML XQuery query optimization algebra query unnesting},
	Pages = {839},
	Pdf = {QueryEvaluation/XML/NestedQueries/Deutsch.Papakonst.ea_NestedQueries_ICDE_2004.pdf},
	Title = {{Minimization and Group-By Detection for Nested XQueries}},
	Url = {http://www.db.ucsd.edu/CSE232BS03/nested-xquery-minimization.pdf},
	Year = {2004},
	Abstract = {We describe and evaluate a query minimization technique that applies to
	 XQueries, which are nested, perform arbi- trary joins, and freely mix
	 bag and set semantics. These features create key challenges that
	 fundamentally extend the problem of minimizing conjunctive queries
	 (no nesting, no mixed semantics) or tree pattern XPath expressions
	 (no nesting, no joins, no bag semantics). The technique detects and
	 removes redundant navigation across and within nested subqueries.
	 An important application of this technique is group-by detection.}}

@inproceedings{Deutsch.Papakonstantinou.ea_NEXT_VLDB_2004a,
	Author = {Deutsch, Alin and Papakonstantinou, Yannis and Xu, Yu},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {Proc. Int. Conf. on Very Large Databases},
	Conference-Abbr = {VLDB},
	Crossref = {DBLP:conf/vldb/2004},
	Ee = {http://www.vldb.org/conf/2004/RS4P5.PDF},
	Keywords = {XML XQuery algebra optimization tableaux NEXT},
	Pages = {168-179},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Deutsch.Papakonstantinou.ea_NEXT_VLDB_2004a.pdf},
	Title = {{The NEXT Logical Framework for XQuery}},
	Url = {http://www.vldb.org/conf/2004/RS4P5.PDF},
	Year = {2004},
	Abstract = {Classical logical optimization techniques rely on a logical
	 semantics of the query language. The adaptation of these techniques to
	 XQuery is precluded by its definition as a functional language with
	 operational semantics. We introduce Nested XML Tableaux which enable a
	 logical foundation for XQuery semantics and provide the logical plan
	 optimization framework of our XQuery processor. As a proof of concept, we
	 develop and evaluate a minimization algorithm for removing redundant
	 navigation within and across nested subqueries. The rich XQuery features
	 create key challenges that fundamentally extend the prior work on
	 the problems of minimizing conjunctive and tree pattern queries.}}

@inproceedings{Deutsch.Tannen_ContainmentXPath_KRDB_2001,
	Author = {Deutsch, Alin and Tannen, Val},
	Booktitle = {Proc. Int. Workshop on Knowledge Representation meets Databases},
	Conference-Abbr = {KRDB},
	Keywords = {XML XPath query containment fragments query languages},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Containment/Deutsch.Tannen_ContainmentXPath_KRDB_2001.pdf},
	Title = {{Containment and Integrity Constraints for XPath Fragments}},
	Url = {http://ceur-ws.org/Vol-45/01-deutsch.ps},
	Year = {2001},
	Abstract = {XPath is a W3C standard that plays a crucial role in several in uential query
	 transformation and schema standards for XML Motivated by the larger
	 challenge of XML query optimization we investigate the problem of
	 containment of XPath expressions under integrity constraints that
	 are in turn formulated with the help of XPath expressions Our core
	 formalism consists of a fragment of XPath that we call simple and a
	 corresponding class of of integrity constraints that we call simple
	 XPath integrity constraints SXIC SXIC s can express many database
	 style con straints including key and foreign key constraints speci
	 ed in the XML Schema standard proposal as well as many constraints
	 implied by DTDs We identify a subclass of bounded SXIC s under which
	 containment of simple XPath expres sions is decidable but we show that
	 even modest use of unbounded SXIC s makes the problem undecidable In
	 particular the addition of unbounded constraints implied by DTDs leads to
	 undecidability. We give tight P-bounds for the simple XPath containment
	 problem and tight NP bounds for the disjunction free subfragment while
	 even identifying a PTIME subcase We also show that decidability of
	 containment under SXIC s still holds if the expressions contain certain
	 additional features, e.g. wildcard although the complexity jumps to P even
	 for the disjunction free subfragment. We know that our results can
	 be extended to some but not all of the XPath features that depend
	 on document order The decidability of containment of simple XPath
	 expressions in the presence of DTDs only remains open although we can
	 show that the problem is PSPACE hard as well as the problem for full
	 edged XPath expressions even in the absence of integrity constraints.}}

@inproceedings{Diao.Florescu.ea_MemoizationXQuery_XSym_2004,
	Author = {Diao, Yanlei and Florescu, Daniela and Kossmann, Donald and Carey, Michael J. and Franklin, Michael J.},
	Booktitle = {Proc. Int. Database Symposium},
	Conference-Abbr = {XSym},
	Keywords = {XML XQuery memoization processor implementation},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Diao.Florescu.ea_MemoizationXQuery_XSym_2004.pdf},
	Title = {{Implementing Memoization in a Streaming XQuery Processor}},
	Url = {http://www.cs.berkeley.edu/~franklin/Papers/MemoXSym.pdf},
	Year = {2004},
	Abstract = {In this paper, we describe an approach to boosting the
	 performance of an XQuery engine by identifying and exploiting opportunities
	 to share processing both within and across XML queries. We first
	 explain where sharing opportunities arise in the world of XML query
	 processing. We then describe an approach to shared XQuery processing
	 based on memoization, providing details of an implementation that we
	 built by extending the streaming XQuery processor that BEA Systems
	 incorporates as part of their BEA WebLogic Integration 8.1 product. To
	 explore the potential performance gains offered by our approach, we
	 present results from an experimental study of its performance over a
	 collection of use-case-inspired synthetic query workloads. The performance
	 results show that significant overall gains are indeed available.}}

@inproceedings{Dong.Bailey_StaticAnalysisXSLT_ADC_2004,
	Author = {Dong, Ce and Bailey, James},
	Booktitle = {Proc. Australasian Database Conf.},
	Conference-Abbr = {ADC},
	Isbn = {1-111-11111-1},
	Keywords = {XML XSLT error checking typing query languages},
	Location = {Dunedin, New Zealand},
	Pages = {151--160},
	Pdf = {QueryEvaluation/XML/Containment/Dong.Bailey_StaticAnalysisXSLT_ADC_2004.pdf},
	Publisher = {Australian Computer Society, Inc.},
	Title = {{Static Analysis of XSLT Programs}},
	Url = {http://www.cs.mu.oz.au/~jbailey/papers/adc.pdf},
	Year = {2004},
	Abstract = {XML is becoming the dominant
	 standard for representing and exchanging data on the World Wide Web. The
	 ability to transform and present data in XML is crucial and XSLT
	 (Extensible Stylesheet Language Transformations) is the principal
	 programming language that supports this activity. Methods for analysis of
	 XSLT programs are currently an important open issue. In this paper,
	 we discuss new methods for analysing XSLT programs, which return
	 information about reachability, invalid calling relationships and
	 termination properties. Our methods are based on the determination of the
	 associations which can exist between components of an XSLT program,
	 refined by the knowledge from a DTD. Such analysis is important for
	 debugging and verification of XSLT programs and also their optimisation.}}

@inproceedings{El-Sayed.Dimitrova.ea_EfficientOrder_WIDM_2003,
	Address = {New York, NY, USA},
	Author = {El-Sayed, Maged and Dimitrova, Katica and Rundensteiner, Elke A.},
	Booktitle = {Proc. Int. Workshop on Web Information and Data Management},
	Conference-Abbr = {WIDM},
	Doi = {http://doi.acm.org/10.1145/956699.956731},
	Isbn = {1-58113-725-7},
	Keywords = {XML query processing order optimization operators},
	Location = {New Orleans, Louisiana, USA},
	Pages = {147--154},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/OrderDuplicates/El-Sayed.Dimitrova.ea_EfficientOrder_WIDM_2003.pdf},
	Publisher = {ACM Press},
	Title = {{Efficiently Supporting Order in XML Query Processing}},
	Url = {http://davis.wpi.edu/~dsrg/rainbow/publications/XMLorder_8-1-04.pdf},
	Year = {2003},
	Abstract = {Query processing over XML data sources has
	 emerged as a popular topic. XML is an ordered data model and XQuery
	 expressions return results that have a well-defined order. However
	 little work on how order is supported in XML query processing has
	 been done to date. In this paper we study the challenges related
	 to handling order in the XML context, namely challenges imposed by
	 the XML data model, by the variety of distinct XML operators and by
	 incremental view maintenance. We have proposed an efficient solution
	 that addresses these issues. We use a key encoding for XML nodes
	 that supports both node identity and node order. We have designed
	 order encoding rules based on the XML algebraic query execution data
	 model and on node encodings that does not require any actual sorting
	 for intermediate results during execution. Our approach supports
	 more efficient incremental view maintenance as it makes most XML
	 operators distributive with respect to bag union. Our approach is
	 implemented in the context of Rainbow [25], an XML data management system
	 developed at WPI. We prove the correctness of our order encoding
	 approach, namely that it ensures order handling for query processing and
	 for view maintenance. We also show, through experiments, that the
	 overhead of maintaining order in our approach is indeed neglectible.}}

@inproceedings{Fegaras.Levine.ea_QueryStreamedXML_CIKM_2002,
	Address = {New York, NY, USA},
	Author = {Fegaras, Leonidas and Levine, David and Bose, Sujoe and Chaluvadi, Vamsi},
	Booktitle = {Proc. Int. Conf. on Information and Knowledge Management},
	Conference-Abbr = {CIKM},
	Doi = {http://doi.acm.org/10.1145/584792.584816},
	Isbn = {1-58113-492-4},
	Keywords = {XML stream algebra query decorrelation non-blocking stream},
	Location = {McLean, Virginia, USA},
	Pages = {126--133},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Fegaras.Levine.ea_QueryStreamedXML_CIKM_2002.pdf},
	Publisher = {ACM Press},
	Title = {{Query Processing of Streamed XML Data}},
	Url = {http://lambda.uta.edu/cikm02.pdf},
	Year = {2002},
	Abstract = {We are addressing the efficient
	 processing of continuous XML streams, in which the server broadcasts
	 XML data to multiple clients concurrently through a multicast data
	 stream, while each client is fully responsible for processing the
	 stream. In our framework, a server may disseminate XML fragments from
	 multiple documents in the same stream, can repeat or replace fragments,
	 and can introduce new fragments or delete invalid ones. A client
	 uses a light-weight database based on our proposed XML algebra to
	 cache stream data and to evaluate XML queries against these data. The
	 synchronization between clients and servers is achieved through annotations
	 and punctuations transmitted along with the data streams. We are
	 presenting a framework for processing XML queries in XQuery form
	 over continuous XML streams. Our framework is based on a novel XML
	 algebra and a new algebraic optimization framework based on query
	 decorrelation, which is essential for non-blocking stream processing.}}

@inproceedings{Fernandez.Simeon.ea_Galax_VLDB_2003,
	Author = {Fern{\'a}ndez, Mary and Sim{\'e}on, J{\'e}r{\^o}me and Choi, Byron and Marian, Am{\'e}lie and Sur, Gargi},
	Booktitle = {Proc. Int. Conf. on Very Large Databases},
	Conference-Abbr = {VLDB},
	Keywords = {XML XQuery galax implementation query languages},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Fernandez.Simeon.ea_Galax_VLDB_2003.pdf},
	Title = {{Implementing XQuery 1.0 : The Galax Experience}},
	Url = {http://www.vldb.org/conf/2003/papers/S35P07.pdf},
	Year = {2003},
	Abstract = {Galax is a light-weight, portable, open-source
	 implementation of XQuery 1.0. Started in December 2000 as a small prototype
	 designed to test the XQuery static type system, Galax has now become a
	 solid implementation, aiming at full conformance with the family of
	 XQuery 1.0 specifi- cations. Because of its completeness and open
	 architecture, Galax also turns out to be a very convenient platform for
	 researchers interested in experimenting with XQuery optimization. We
	 demonstrate the Galax system as well as its most advanced features,
	 including support for XPath 2.0, XML Schema and static typechecking.
	 We also present some of our first experiments with optimization.
	 Notably, we demonstrate query rewriting capabilities in the Galax
	 compiler, and the ability to run queries on documents up to a Gigabyte
	 without the need for preindexing. Although early versions of Galax
	 have been shown in industrial conferences over the last two years,
	 this is the first time it is demonstrated in the database community.}}

@article{Fiebig.Moerkotte_AlgebraicXMLConstr_WWWJ_2001,
	Address = {Hingham, MA, USA},
	Author = {Fiebig, Thorsten and Moerkotte, Guido},
	Doi = {http://dx.doi.org/10.1023/A:1013831700817},
	Issn = {1386-145X},
	Journal = {World Wide Web},
	Journal-Abbr = {WWWJ},
	Keywords = {XML XQuery Natix construction algebraic},
	Number = {3},
	Pages = {167--187},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Fiebig.Moerkotte_AlgebraicXMLConstr_WWWJ_2001.pdf},
	Publisher = {Kluwer Academic Publishers},
	Title = {{Algebraic XML Construction and its Optimization in Natix}},
	Url = {http://portal.acm.org/citation.cfm?id=598761},
	Volume = {4},
	Year = {2001},
	Abstract = {While using an algebra that acts on sets of variable bindings for evaluating
	 XML queries, the problem of constructing XML from these bindings
	 arises. One approach is to define a powerful operator that is able to
	 perform a complex construction of a representation of the XML result
	 document. The drawback is that such an operator in its generality is
	 hard to implement and disables algebraic optimization since it has
	 to be executed last in the plan. Therefore we suggest to construct
	 XML documents by special query execution plans called construction
	 plans built from simple, easy to implement and efficient operators.
	 The paper proposes four simple algebraic operators needed for XML
	 document construction. Further, we introduce an optimizing translation
	 algorithm of construction clauses into algebraic expressions and
	 briefly point out algebraic optimizations enabled by our approach.}}

@article{Florescu.Hillery.ea_BEAXQuery_VLDBJ_2004,
	Author = {Florescu, Daniela and Hillery, Chris and Kossmann, Donald and Lucas, Paul and Riccardi, Fabio and Westmann, Till and Carey, Michael J. and Sundararajan, Arvind},
	Doi = {http://dx.doi.org/10.1007/s00778-004-0137-1},
	Issn = {1066-8888},
	Journal = {VLDB Journal},
	Journal-Abbr = {VLDBJ},
	Keywords = {XML XQuery query processing implementation query languages},
	Number = {3},
	Pages = {294--315},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Florescu.Hillery.ea_BEAXQuery_VLDBJ_2004.pdf},
	Publisher = {Springer-Verlag New York, Inc.},
	Title = {{The BEA Streaming XQuery Processor}},
	Url = {http://www-dbs.informatik.uni-heidelberg.de/publications/vldbj.pdf},
	Volume = {13},
	Year = {2004},
	Abstract = {This paper describes the design, implementation, and performance characteristics
	 of a commercial XQuery processing engine, the BEA streaming XQuery
	 processor. This XQuery engine was designed to provide high performance for
	 message-processing applications, i.e., for transforming XML data
	 streams. The engine is a central component of the 8.1 release of BEA?s
	 WebLogic Integration (WLI) product. The BEA XQuery engine is fully
	 compliant with the August 2002 draft of the W3C XML Query Language
	 specification and we are currently porting it to the latest version of the
	 XQuery language (July 2004). A goal of this paper is to describe how a
	 fully compliant yet efficient XQuery engine has been built from a
	 few relatively simple components and well-understood technologies.}}

@inproceedings{Fokoue.Rose.ea_XSLT2XQuery_WWW_2005,
	Address = {New York, NY, USA},
	Author = {Fokoue, Achille and Rose, Kristoffer and Simeon, Jerome and Villard, Lionel},
	Booktitle = {Proc. Int. World Wide Web Conf.},
	Conference-Abbr = {WWW},
	Doi = {http://doi.acm.org/10.1145/1060745.1060844},
	Isbn = {1-59593-046-9},
	Keywords = {XML XSLT XQuery translation compilation expressiveness},
	Location = {Chiba, Japan},
	Pages = {682--691},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Translating/Fokoue.Rose.ea_XSLT2XQuery_WWW_2005.pdf},
	Publisher = {ACM Press},
	Title = {Compiling XSLT 2.0 into XQuery 1.0},
	Url = {http://portal.acm.org/citation.cfm?id=1060745.1060844},
	Year = {2005},
	Abstract = {As XQuery is gathering momentum as the standard query language for XML, there
	 is a growing interest in using it as an integral part of the XML
	 application development infrastructure. In that context, one question
	 which is often raised is how well XQuery interoperates with other XML
	 languages, and notably with XSLT. XQuery 1.0 [16] and XSLT 2.0 [7]
	 share a lot in common: they share XPath 2.0 as a common sub-language
	 and have the same expressiveness. However, they are based on fairly
	 different programming paradigms. While XSLT has adopted a highly
	 declarative template based approach, XQuery relies on a simpler, and more
	 operational, functional approach.In this paper, we present an approach to
	 compile XSLT 2.0 into XQuery 1.0, and a working implementation of that
	 approach. The compilation rules explain how XSLT's template-based
	 approach can be implemented using the functional approach of XQuery and
	 underpins the tight connection between the two languages. The resulting
	 compiler can be used to migrate a XSLT code base to XQuery, or to
	 enable the use of XQuery runtimes (e.g., as will soon be provided
	 by most relational database management systems) for XSLT users. We
	 also identify a number of areas where compatibility between the two
	 languages could be improved. Finally, we show experiments on actual XSLT
	 stylesheets, demonstrating the applicability of the approach in practice.}}

@inproceedings{Frasincar.Houben.ea_XALAlgebra_CRPITS_2002,
	Address = {Darlinghurst, Australia, Australia},
	Author = {Frasincar, Flavius and Houben, Geert-Jan and Pau, Cristian},
	Booktitle = {Proc. Australasian Conf. on Database Technologies},
	Conference-Abbr = {CRPITS},
	Isbn = {0-909925-83-6},
	Keywords = {XML XQuery XAL XML algebra optimization},
	Location = {Melbourne, Victoria, Australia},
	Pages = {49--56},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Frasincar.Houben.ea_XALAlgebra_CRPITS_2002.pdf},
	Publisher = {Australian Computer Society, Inc.},
	Title = {{XAL: an Algebra for XML Query Optimization}},
	Url = {http://portal.acm.org/citation.cfm?id=563906.563912},
	Year = {2002},
	Abstract = {This paper proposes XAL, an XML
	 ALgebra. Its novelty is based on the simplicity of its data model
	 and its well-defined logical operators, which makes it suitable for
	 composability, optimizability, and semantics definition of a query
	 language for XML data. At the heart of the algebra resides the notion of
	 collection, a concept similar to the mathematician's monad or functional
	 programmer's comprehension. The operators are classified in three
	 clusters: extraction operators retrieve the needed information from XML
	 documents, meta-operators control the evaluation of expressions, and
	 construction operators build new XML documents from the extracted data. The
	 resulting algebra has optimization laws similar to the known laws for
	 transforming relational queries. As a consequence, we propose a heuristic
	 optimization algorithm similar to its relational algebra counterpart.}}

@techreport{Galanis.Viglas.ea_FollowingPathsof_TR_2002,
	Author = {Galanis, Leonidas and Viglas, Efstratios and Dewitt, David J. and Naughton, Jeffrey. F. and Maier, David},
	Institution = {University of Wisconsin},
	Keywords = {XML Quilt algebra xml query optimization niagara},
	Number = {363},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Galanis.Viglas.ea_FollowingPathsof_TR_2002.pdf},
	Title = {{Following the Paths of XML Data: An Algebraic Framework for XML Query Evaluation}},
	Url = {http://www.csd.uch.gr/~hy561/Papers/algebraicXMLframework01.pdf},
	Year = {2002},
	Abstract = {This paper introduces an algebraic framework for expressing
	 and evaluating queries over XML data. It presents the underlying
	 assumptions of the framework, describes the input and output of the
	 algebraic operators, and de nes these operators and their semantics. It
	 evaluates the framework with regard to other proposed XML query algebras.
	 Examples show that this framework is flexible enough to capture queries
	 expressed in Quilt, one of the dominant XML query languages. We have used
	 this algebra in the context of an Internet query engine, in which it
	 is used to formulate logical plans for XML-QL queries. We define
	 equivalence rules that provide opportunities for optimization, and
	 give example cases that point out the usefulness of these rules.}}

@inproceedings{Gottlob.Koch_MonadicDatalWeb_JACM_2004,
	Author = {Gottlob, Georg and Koch, Christoph},
	Booktitle = {Journal of the ACM},
	Conference-Abbr = {JACM},
	Editor = {51},
	Keywords = {XML query languages web extraction datalog complexity},
	Owner = {Tim Furche},
	Pages = {74--113},
	Pdf = {QueryEvaluation/XML/Comlexity/Gottlob.Koch_MonadicDatalWeb_JACM_2004.pdf},
	Title = {{Monadic Datalog and the Expressive Power of Languages for Web Information Extraction}},
	Url = {http://www-db.cs.uni-sb.de/~koch/download/0211020.pdf},
	Volume = {1},
	Year = {2004},
	Abstract = {Research on information extraction from
	 Web pages (wrapping) has seen much activity recently (particularly
	 systems implementations), but little work has been done on formally
	 studying the expressiveness of the formalisms proposed or on the
	 theoretical foundations of wrapping. In this paper, we first study
	 monadic datalog over trees as a wrapping language. We show that this
	 simple language is equivalent to monadic second order logic (MSO) in
	 its ability to specify wrappers. We believe that MSO has the right
	 expressiveness required for Web information extraction and propose
	 MSO as a yardstick for evaluating and comparing wrappers. Along the
	 way, several other results on the complexity of query evaluation and
	 query containment for monadic datalog over trees are established,
	 and a simple normal form for this language is presented. Using the
	 above results, we subsequently study the kernel fragment Elog? of the
	 Elog wrapping language used in the Lixto system (a visual wrapper
	 generator). Curiously, Elog? exactly captures MSO, yet is easier to use.
	 Indeed, programs in this language can be entirely visually specified.}}

@article{Gottlob.Koch.ea_ComplexityXPath_JACM_2005,
	Author = {Gottlob, Georg and Koch, Christoph and Pichler, Reinhard and Segoufin, Luc},
	Date-Modified = {2006-02-01 17:38:21 +0100},
	Group = {Matrix Method},
	Journal = {Journal of the ACM},
	Journal-Abbr = {JACM},
	Keywords = {XML XPath complexity querying typing},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Comlexity/Gottlob.Koch.ea_ComplexityXPath_JACM_2005.pdf},
	Title = {{The Complexity of XPath Query Evaluation and XML Typing}},
	Url = {http://www-db.cs.uni-sb.de/~koch/download/jacm2.pdf},
	Year = {2005},
	Abstract = {We study the complexity of two central XML processing problems. The rst is XPath 1.0 query processing, which has been shown to be in PTime in previous work. We prove that both the data complexity and the query complexity of XPath 1.0 fall into lower (highly parallelizable) complexity classes, while the combined complexity is PTime-hard. Subsequently, we study the sources of this hardness and identify a large and practically important fragment of XPath 1.0 for which the combined complexity is LogCFL-complete and, therefore, in the highly parallelizable complexity class NC2. The second problem is the complexity of validating XML documents against various typing schemes like Document Type De nitions (DTDs), XML Schema De nitions (XSDs), and tree automata, both with respect to data and to combined complexity. For data complexity, we prove that validation is in LogSpace and depends crucially on how XML data is represented. For the combined complexity, we show that the complexity ranges from LogSpace to LogCFL, depending on the typing scheme.}}

@inproceedings{Gottlob.Koch.ea_ConjunctiveQsTrees_PODS_2004,
	Author = {Gottlob, Georg and Koch, Christoph and Schulz, Klaus},
	Booktitle = {Proc. Symposium on Principles of Database Systems},
	Conference-Abbr = {PODS},
	Keywords = {Query Evaluation XML XPath Conjunctive Query Complexity REWERSE},
	Month = {6},
	Note = {I4},
	Owner = {Tim Furche},
	Pages = {189--200},
	Pdf = {QueryEvaluation/XML/Comlexity/Gottlob.Koch.ea_ConjunctiveQsTrees_PODS_2004.pdf},
	Title = {{Conjunctive Queries over Trees}},
	Url = {http://www.acm.org/sigmod/pods/proc04/pdf/P-19.pdf},
	Urldate = {2005/01/28},
	Year = {2004},
	Abstract = {We study the complexity and expressive power of conjunctive queries over unranked
	 labeled trees, where the tree structures are represented using ?axis
	 relations? such as ?child?, ?descendant?, and ?following? (we consider a
	 superset of the XPath axes) as well as unary relations for node labels.
	 (Cyclic) conjunctive queries over trees occur in a wide range of
	 data management scenarios related to XML, the Web, and computational
	 linguistics. We establish a framework for characterizing structures
	 representing trees for which conjunctive queries can be evaluated
	 efficiently. Then we completely chart the tractability frontier of
	 the problem for our axis relations, i.e., we nd all subsetmaximal
	 sets of axes for which query evaluation is in polynomial time. All
	 polynomial-time results are obtained immediately using the proof
	 techniques from our framework. Finally, we study the expressiveness of
	 conjunctive queries over trees and compare it to the expressive power of
	 fragments of XPath. We show that for each conjunctive query, there is an
	 equivalent acyclic positive query (i.e., a set of acyclic conjunctive
	 queries), but that in general this query is not of polynomial size.}}

@inproceedings{Grinev.Lizorkin_FunctionInlXQ_ADBIS_2004,
	Author = {Grinev, Maxim and Lizorkin, Dmitry},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {East-European Conf. on Advances in Databases and Information Systems},
	Conference-Abbr = {ADBIS},
	Ee = {http://www.sztaki.hu/conferences/ADBIS/4-Lizorkin.pdf},
	Keywords = {XML XQuery function inlining optimization rewriting},
	Pdf = {QueryEvaluation/XML/Compilation/Grinev.Lizorkin_FunctionInlXQ_ADBIS_2004.pdf},
	Title = {{XQuery Function Inlining for Optimizing XQuery Queries}},
	Url = {http://www.sztaki.hu/conferences/ADBIS/4-Lizorkin.pdf},
	Year = {2004}}

@inproceedings{Grinev.Pleshachkov_RewrTransf_IDEAS_2005,
	Author = {Grinev, Maxim and Pleshachkov, Peter},
	Booktitle = {Proc. Int. Database Engineering and Application Symposium},
	Conference-Abbr = {IDEAS},
	Keywords = {XML XQuery rewriting transformation query},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Containment/Grinev.Pleshachkov_RewrTransf_IDEAS_2005.pdf},
	Title = {{Rewriting-based Optimization for XQuery Transformational Queries}},
	Url = {http://www.ispras.ru/~grinev/mypapers/rewrite-transformation-ext.pdf},
	Year = {2005},
	Abstract = {The modern XML query language called XQuery includes
	 advanced facilities both to query and to transform XML data. An XQuery
	 query optimizer should be able to optimize any query. For ?querying?
	 queries almost all techniques inherited from SQLoriented DBMS may be
	 applied. The XQuery transformation facilities are XML-specific and
	 have no counterparts in other query languages. That is why XQuery
	 transformational queries need to be optimized with novel techniques.
	 In this paper two kinds of such techniques (namely push predicates
	 down XML element constructors and projection of transformation) are
	 considered. A subset of XQuery for which these techniques can be fully
	 implemented is identified. This subset seems to be the most intersting
	 from the practical viewpoint. Rewriting rules for this subset are
	 proposed and the correctness of these rules is formally justified. For
	 the rest of the language we propose solutions that works for the
	 most of common cases or consider the problems we have encountered.}}

@inproceedings{Grohe.Koch.ea_LowerBoundsMem_ICALP_2005,
	Author = {Grohe, Martin and Koch, Christoph and Schweikardt, Nicole},
	Booktitle = {Proc. Int. Colloquium on Automata, Languages, and Programming},
	Conference-Abbr = {ICALP},
	Keywords = {XML lower bounds memory streaming XPath},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Comlexity/Grohe.Koch.ea_LowerBoundsMem_ICALP_2005.pdf},
	Title = {{Tight Lower Bounds for Query Processing on Streaming and External Memory Data}},
	Url = {http://www.infosys.uni-sb.de/~koch/download/icalp05B075.pdf},
	Year = {2005},
	Abstract = {We study a clean machine model for external memory and stream
	 processing. We show that the number of scans of the external data induces a
	 strict hierarchy (as long as work space is su ciently small, e.g.,
	 polylogarithmic in the size of the input). We also show that neither joins
	 nor sorting are feasible if the product of the number r(n) of scans
	 of the external memory and the size s(n) of the internal memory bu
	 ers is su ciently small, e.g., of size o(p5 n). We also establish
	 tight bounds for the complexity of XPath evaluation and ltering.}}

@inproceedings{Grust_AcceleratingXPath_SIGMOD_2002,
	Author = {Grust, Thorsten},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Keywords = {XML XPath relational implementation location steps efficiency accelerating},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/Grust_AcceleratingXPath_SIGMOD_2002.pdf},
	Title = {{Accelerating XPath Location Steps}},
	Url = {http://www.in.tu-clausthal.de/~grust/files/xpath-accel.pdf},
	Year = {2002},
	Abstract = {This work is a proposal for a database index structure that
	 has been speci cally designed to support the evaluation of XPath
	 queries. As such, the index is capable to support all XPath axes
	 (including ancestor, following, precedingsibling, descendant-or-self,
	 etc.). This feature lets the index stand out among related work on XML
	 indexing structures which had a focus on regular path expressions (which
	 correspond to the XPath axes children and descendantor- self plus name
	 tests). Its ability to start traversals from arbitrary context nodes
	 in an XML document additionally enables the index to support the
	 evaluation of path traversals embedded in XQuery expressions. Despite
	 its exibility, the new index can be implemented and queried using
	 purely relational techniques, but it performs especially well if the
	 underlying database host provides support for R-trees. A performance
	 assessment which shows quite promising results completes this proposal.}}

@article{Grust.Keulen.ea_AcceleratingXPath_TODS_2004,
	Author = {Grust, Torsten and Keulen, Maurice Van and Teubner, Jens},
	Doi = {http://doi.acm.org/10.1145/974750.974754},
	Issn = {0362-5915},
	Journal = {ACM Transactions on Database Systems},
	Journal-Abbr = {TODS},
	Keywords = {XML XPath location steps relational implementation encoding},
	Number = {1},
	Pages = {91--131},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Translating/Grust.Keulen.ea_AcceleratingXPath_TODS_2004.pdf},
	Publisher = {ACM Press},
	Title = {{Accelerating XPath Evaluation in any RDBMS}},
	Url = {http://portal.acm.org/citation.cfm?id=974754},
	Volume = {29},
	Year = {2004},
	Abstract = {This article is a proposal for a database index
	 structure, the XPath accelerator, that has been specifically designed to
	 support the evaluation of XPath path expressions. As such, the index is
	 capable to support all XPath axes (including ancestor, following,
	 preceding-sibling, descendant-or-self, etc.). This feature lets the
	 index stand out among related work on XML indexing structures which
	 had a focus on the child and descendant axes only. The index has
	 been designed with a close eye on the XPath semantics as well as the
	 desire to engineer its internals so that it can be supported well
	 by existing relational database query processing technology: the
	 index (a) permits set-oriented (or, rather, sequence-oriented) path
	 evaluation, and (b) can be implemented and queried using well-established
	 relational index structures, notably B-trees and R-trees.We discuss the
	 implementation of the XPath accelerator on top of different database backends
	 and show that the index performs well on all levels of the memory
	 hierarchy, including disk-based and main-memory based database systems.}}

@inproceedings{Grust.Keulen.ea_StaircaseJoin_VLDB_2003,
	Author = {Grust, Torsten and van Keulen, Maurice and Teubner, Jens},
	Booktitle = {Proc. Int. Conf. on Very Large Databases},
	Conference-Abbr = {VLDB},
	Keywords = {XML staircase join structural join relational},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/StructuralJoins/Grust.Keulen.ea_StaircaseJoin_VLDB_2003.pdf},
	Title = {{Staircase Join: Teach A Relational DBMS to Watch its (Axis) Steps}},
	Url = {http://www.inf.uni-konstanz.de/~teubner/publications/watch-axis-steps.pdf},
	Year = {2003},
	Abstract = {Relational query processors derive much of their e ectiveness from
	 the awareness of speci c table properties like sort order, size, or
	 absence of duplicate tuples. This text applies (and adapts) this
	 successful principle to database-supported XML and XPath processing: the
	 relational system is made tree aware, i.e., tree properties like
	 subtree size, intersection of paths, inclusion or disjointness of
	 subtrees are made explicit. We propose a local change to the database
	 kernel, the staircase join, which encapsulates the necessary tree
	 knowledge needed to improve XPath performance. Staircase join operates on
	 an XML encoding which makes this knowledge available at the cost
	 of simple integer operations. We finally report on quite promising
	 experiments with a staircase join enhanced main-memory database kernel.}}

@inproceedings{Grust.Sakr.ea_XQueryOnSQL_VLDB_2004,
	Author = {Grust, Torsten and Sakr, Sherif and Teubner, Jens},
	Booktitle = {Proc. Int. Conf. on Very Large Databases},
	Conference-Abbr = {VLDB},
	Keywords = {XML XQuery relational implementation SQL},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Translating/Grust.Sakr.ea_XQueryOnSQL_VLDB_2004.pdf},
	Title = {{XQuery on SQL Hosts}},
	Url = {http://www.in.tu-clausthal.de/~grust/files/sql-mapping.pdf},
	Year = {2004},
	Abstract = {Relational database systems may be turned
	 into efficient XML and XPath processors if the system is provided
	 with a suitable relational tree encoding. This paper extends this
	 relational XML processing stack and shows that an RDBMS can also serve
	 as a highly efficient XQuery runtime environment. Our approach is
	 purely relational: XQuery expressions are compiled into SQL code which
	 operates on the tree encoding. The core of the compilation procedure
	 trades XQuery's notions of variable scopes and nested iteration (FLWOR
	 blocks) for equi-joins. The resulting relational XQuery processor
	 closely adheres to the language semantics, e.g., it obeys node identity
	 as well as document and sequence order, and can support XQuery's
	 full axis feature. The system exhibits quite promising performance
	 figures in experiments. Somewhat unexpectedly, we will also see that
	 the XQuery compiler can make good use of SQL's OLAP functionality.}}

@inproceedings{Grust.Teubner_RAXQuery_TDM_2004,
	Author = {Grust, Torsten and Teubner, Jens},
	Booktitle = {Proc. Twente Data Management Workshop on XML Databases and Information Retrieval},
	Conference-Abbr = {TDM},
	Date-Modified = {2006-02-01 17:29:59 +0100},
	Keywords = {XML XQuery relational algebra SQL translation},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Translating/Grust.Teubner_RAXQuery_TDM_2004.pdf},
	Title = {{Relational Algebra: Mother Tongue - XQuery: Fluent}},
	Url = {http://www.in.tu-clausthal.de/~grust/files/algebra-mapping.pdf},
	Year = {2004},
	Abstract = {This work may be seen as a further proof of the
	 versatility of the relational database model. Here, we add XQuery to the
	 catalog of languages which RDBMSs are able to "speak" fluently. Given
	 suitable relational encodings of sequences and ordered, unranked
	 trees the two data structures that form the backbone of the XML and
	 XQuery data models we describe a compiler that translates XQuery
	 expressions into a simple and quite standard relational algebra which
	 we expect to be efficiently implementable on top of any relational
	 query engine. The compilation procedure is fully compositional and
	 emits algebraic code that strictly adheres to the XQuery language
	 semantics: document and sequence order as well as node identity are
	 obeyed. We exercise special care in translating arbitrarily nested
	 XQuery FLWOR iteration constructs into equi-joins, an operation which
	 RDBMSs can perform particularly fast. The resulting purely relational
	 XQuery processor shows promising performance figures in experiments.}}

@inproceedings{Guo.Li.ea_ScalableXSLT_APWEB_2004,
	Author = {Guo, Zhimao and Li, Min and Wang, Xiaoling and Zhou, Aoying},
	Booktitle = {Proc. Asia Pacific Web Conference},
	Conference-Abbr = {APWEB},
	Keywords = {XML XSLT evaluation optimization query languages},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Streaming/Guo.Li.ea_ScalableXSLT_APWEB_2004.pdf},
	Title = {{Scalable XSLT Evaluation}},
	Url = {http://arxiv.org/abs/cs.DB/0408051},
	Year = {2004},
	Abstract = {XSLT is an increasingly
	 popular language for processing XML data. It is widely supported by
	 application platform software. However, little optimization effort has been
	 made inside the current XSLT processing engines. Evaluating a very
	 simple XSLT program on a large XML document with a simple schema may
	 result in extensive usage of memory. In this paper, we present a novel
	 notion of Streaming Processing Model (SPM) to evaluate a subset of
	 XSLT programs on XML documents, especially large ones. With SPM, an
	 XSLT processor can transform an XML source document to other formats
	 without extra memory buffers required. Therefore, our approach can not
	 only tackle large source documents, but also produce large results.
	 We demonstrate with a performance study the advantages of the SPM
	 approach. Experimental results clearly confirm that SPM improves
	 XSLT evaluation typically 2 to 10 times better than the existing
	 approaches. Moreover, the SPM approach also features high scalability.}}

@article{Hamilton.Selinger_ConversationwithPat_ACMQ_2005,
	Author = {Hamilton, James and Selinger, Pat},
	Journal = {ACM Queue},
	Journal-Abbr = {ACMQ},
	Keywords = {database vision metadata unstructured information},
	Month = {April},
	Number = {3},
	Owner = {Tim Furche},
	Title = {{A Conversation with Pat Selinger}},
	Url = {http://www.acmqueue.org/modules.php?name=Content&pa=showpage&pid=297&page=1},
	Volume = {3},
	Year = {2005},
	Abstract = {Take Pat Selinger of IBM and James Hamilton of Microsoft and put
	 them in a conversation together, and you may hear everything you
	 wanted to know about database technology and weren?t afraid to ask.}}

@inproceedings{Helmer.Kanne.ea_ParamTranslXPath_WISE_2002,
	Address = {Washington, DC, USA},
	Author = {Helmer, Sven and Kanne, Carl-Christian and Moerkotte, Guido},
	Booktitle = {Proc. Int. Conf. on Web Information Systems Engineering},
	Conference-Abbr = {WISE},
	Isbn = {0-7695-1766-8},
	Keywords = {XML XPath algebra Natix translation navgiation},
	Pages = {215--224},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Helmer.Kanne.ea_ParamTranslXPath_WISE_2002.pdf},
	Publisher = {IEEE Computer Society},
	Title = {{Optimized Translation of XPath into Algebraic Expressions Parameterized by Programs Containing Navigational Primitives}},
	Url = {http://www.csd.uch.gr/~hy561/Papers/XPath-Natix-wise02.pdf},
	Year = {2002},
	Abstract = {We propose a new approach for the efficient
	 evaluationof XPath expressions. This is important, since XPath is
	 notonly used as a simple, stand-alone query language, but isalso an
	 essential ingredient of XQuery and XSLT.The main idea of our approach
	 is to translate XPath intoalgebraic expressions parameterized with
	 programs. Theseprograms are mainly built from navigational primitives
	 likeaccessing the first child or the next sibling. The goals ofthe
	 approach are 1) to enable pipelined evaluation, 2) toavoid producing
	 duplicate (intermediate) result nodes, 3) tovisit as few document
	 nodes as possible, and 4) to avoidvisiting nodes more than once. This
	 improves the existingapproaches, because our method is highly efficient.}}

@inproceedings{Helmer.May.ea_QueryDecorrel_XSym_2003,
	Author = {Helmer, Sven and May, Norman and Moerkotte, Guido},
	Booktitle = {Proc. Int. XML Database Symposium},
	Conference-Abbr = {XSym},
	Keywords = {XQuery nested queries query decorrelation},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/NestedQueries/Helmer.May.ea_QueryDecorrel_XSym_2003.pdf},
	Title = {{Three Cases for Query Decorrelation in XQuery}},
	Url = {http://pi3.informatik.uni-mannheim.de/~norman/unnesting_xmlsym03.pdf},
	Year = {2003},
	Abstract = {We present algebraic equivalences that
	 allow to unnest nested algebraic expressions for order-preserving
	 algebraic operators. We illustrate how these equivalences can be applied
	 successfully to unnest nested queries given in the XQuery language.
	 Measurements illustrate the performance gains possible by unnesting.}}

@inproceedings{Hidders_SatisfiabilityXPath_DBPL_2003,
	Author = {Hidders, Jan},
	Booktitle = {Int. Workshop on Databse Programming Languages},
	Conference-Abbr = {DBPL},
	Keywords = {XML XPath satisfiability query languages theory},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Containment/Hidders_SatisfiabilityXPath_DBPL_2003.pdf},
	Title = {{Satisfiability of XPath Expressions}},
	Url = {http://plantijn.ruca.ua.ac.be/~adrem/biborb/bibs/ADReM/papers/hidders03xpathsat.pdf},
	Year = {2003},
	Abstract = {In this paper, we investigate the complexity of deciding the satisfiability
	 of XPath 2.0 expressions, i.e., whether there is an XML document
	 for which their result is nonempty. Several fragments that allow
	 certain types of expressions are classified as either in PTIME or
	 NP-hard to see which type of expression make this a hard problem.
	 Finally, we establish a link between XPath expressions and partial
	 tree descriptions which are studied in computational linguistics.}}

@inproceedings{Hung.Deng.ea_TOSS-TAX_SIGMOD_2004,
	Address = {New York, NY, USA},
	Author = {Hung, Edward and Deng, Yu and Subrahmanian, V. S.},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of data},
	Conference-Abbr = {SIGMOD},
	Doi = {http://doi.acm.org/10.1145/1007568.1007649},
	Isbn = {1-58113-859-8},
	Keywords = {XML query TAX algebra optimization ontologies similarity queries},
	Location = {Paris, France},
	Pages = {719--730},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Hung.Deng.ea_TOSS-TAX_SIGMOD_2004.pdf},
	Publisher = {ACM Press},
	Title = {{TOSS: An Extension of TAX with Ontologies and Similarity Queries}},
	Url = {http://portal.acm.org/citation.cfm?id=1007649},
	Year = {2004},
	Abstract = {TAX is perhaps the best known extension of the relational algebra to handle
	 queries to XML databases. One problem with TAX (as with many existing
	 relational DBMSs) is that the semantics of terms in a TAX DB are not
	 taken into account when answering queries. Thus, even though TAX
	 answers queries with 100% precision, the recall of TAX is relatively
	 low. Our TOSS system improves the recall of TAX via the concept of a
	 similarity enhanced ontology (SEO). Intuitively, an ontology is a
	 set of graphs describing relationships (such as isa, partof, etc.)
	 between terms in a DB. An SEO also evaluates how similarities between
	 terms (e.g. "J. Ullman", "Jeff Ullman", and "Jeffrey Ullman") affect
	 ontologies. Finally, we show how the algebra proposed in TAX can
	 be extended to take SEOs into account. The result is a system that
	 provides a much higher answer quality than TAX does alone (quality is
	 defined as the square root of the product of precision and recall).
	 We experimentally evaluate the TOSS system on the DBLP and SIGMOD
	 bibliographic databases and show that TOSS has acceptable performance.}}

@inproceedings{Iacob.Dekhtyar_TowardsQueryLanguage_WebDB_2005,
	Author = {Iacob, Ionut and Dekhtyar, Alex},
	Booktitle = {Proc. Int. Workshop on the Web and Databases},
	Conference-Abbr = {WebDB},
	Keywords = {XML XPath multi-hiearchy document-oriented information retrieval text ranges GODDAG},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/XPath/Iacob.Dekhtyar_TowardsQueryLanguage_WebDB_2005.pdf},
	Title = {{Towards a Query Language for Multihierarchical XML: Revisiting XPath}},
	Url = {http://dblab.csr.uky.edu/~eiaco0/publications/webdb05.pdf},
	Year = {2005},
	Abstract = {In recent years it has been argued that when XML encodings become complex,
	 DOM trees are no longer adequate for query processing. Alternative
	 representations of XML documents, such as multi-colored trees have
	 been proposed as a replacement for DOM trees for complex markup. In
	 this paper we consider the use of Generalized Ordered-Descendant
	 Directed Acyclic Graphs (GODDAGs) for the purpose of storing and
	 querying complex document- centric XML. GODDAGs are designed to store
	 multihierarchical XML markup over the shared PCDATA content. They support
	 representation of overlapping markup, which otherwise cannot be represented
	 easily in DOM. We describe how the semantics of XPath axes can be
	 modified to define path expressions over GODDAG, and enhance it with
	 the facilities to traverse and query overlapping markup. We provide
	 efficient algorithms for axis evaluation over GODDAG and describe the
	 implementation of the query processor based on our definitions and algorithms.}}

@article{Jagadish.Al-Khalifa.ea_TIMBER_VLDBJ_2002,
	Address = {Secaucus, NJ, USA},
	Author = {Jagadish, H. V. and Al-Khalifa, S. and Chapman, A. and Lakshmanan, L. V. S. and Nierman, A. and Paparizos, S. and Patel, J. M. and Srivastava, D. and Wiwatwattana, N. and Wu, Y. and Yu, C.},
	Doi = {http://dx.doi.org/10.1007/s00778-002-0081-x},
	Issn = {1066-8888},
	Journal = {VLDB Journal},
	Journal-Abbr = {VLDBJ},
	Keywords = {XML XQuery TIMBER native database XML TAX algebra},
	Number = {4},
	Pages = {274--291},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Jagadish.Al-Khalifa.ea_TIMBER_VLDBJ_2002.pdf},
	Publisher = {Springer-Verlag New York, Inc.},
	Title = {{TIMBER: A native XML Database}},
	Url = {http://www.eecs.umich.edu/db/timber/files/timber.pdf},
	Volume = {11},
	Year = {2002},
	Abstract = {This paper describes the overall design and architecture
	 of the Timber XML database system currently being implemented at
	 the University of Michigan. The system is based upon a bulk algebra
	 for manipulating trees, and natively stores XML. New access methods
	 have been developed to evaluate queries in the XML context, and new
	 cost estimation and query optimization techniques have also been
	 developed. We present performance numbers to support some of our design
	 decisions. We believe that the key intellectual contribution of this
	 system is a comprehensive set-at-a-time query processing ability in a
	 native XML store, with all the standard components of relational query
	 processing, including algebraic rewriting and a cost-based optimizer.}}

@inproceedings{Jagadish.Lakshmanan.ea_ColorfulXML_SIGMOD_2004,
	Address = {New York, NY, USA},
	Author = {Jagadish, H. V. and Lakshmanan, Laks V. S. and Scannapieco, Monica and Srivastava, Divesh and Wiwatwattana, Nuwee},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Doi = {http://doi.acm.org/10.1145/1007568.1007598},
	Isbn = {1-58113-859-8},
	Keywords = {XML XQuery multiple hiearchies colored trees graph data model},
	Location = {Paris, France},
	Pages = {251--262},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/XQuery/Jagadish.Lakshmanan.ea_ColorfulXML_SIGMOD_2004.pdf},
	Publisher = {ACM Press},
	Title = {{Colorful XML: One Hierarchy isn't enough}},
	Url = {http://www.research.att.com/~divesh/papers/jlssw2004-mct.pdf},
	Year = {2004},
	Abstract = {XML has a tree-structured data model, which is used to
	 uniformly represent structured as well as semi-structured data, and
	 also enable concise query specification in XQuery, via the use of
	 its XPath (twig) patterns. This in turn can leverage the recently
	 developed technology of structural join algorithms to evaluate the query
	 efficiently. In this paper, we identify a fundamental tension in XML data
	 modeling: (i) data represented as deep trees (which can make effective
	 use of twig patterns) are often un-normalized, leading to update
	 anomalies, while (ii) normalized data tends to be shallow, resulting in
	 heavy use of expensive value-based joins in queries.Our solution
	 to this data modeling problem is a novel multi-colored trees (MCT)
	 logical data model, which is an evolutionary extension of the XML data
	 model, and permits trees with multi-colored nodes to signify their
	 participation in multiple hierarchies. This adds significant semantic
	 structure to individual data nodes. We extend XQuery expressions to
	 navigate between structurally related nodes, taking color into account,
	 and also to create new colored trees as restructurings of an MCT
	 database. While MCT serves as a significant evolutionary extension
	 to XML as a logical data model, one of the key roles of XML is for
	 information exchange. To enable exchange of MCT information, we develop
	 algorithms for optimally serializing an MCT database as XML. We discuss
	 alternative physical representations for MCT databases, using relational
	 and native XML databases, and describe an implementation on top of
	 the Timber native XML database. Experimental evaluation, using our
	 prototype implementation, shows that not only are MCT queries/updates
	 more succinct and easier to express than equivalent shallow tree
	 XML queries, but they can also be significantly more efficient to
	 evaluate than equivalent deep and shallow tree XML queries/updates.}}

@inproceedings{Jagadish.Lakshmanan.ea_TAX_DBPL_2001,
	Author = {Jagadish, H. V. and Lakshmanan, Laks V. S. and Srivastava, Divesh and Thompson, Keith},
	Booktitle = {Proc. Int. Workshop on Database Programming Languages},
	Conference-Abbr = {DBPL},
	Keywords = {XML TAX algebra TIMBER optimization},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Jagadish.Lakshmanan.ea_TAX_DBPL_2001.pdf},
	Title = {{TAX: A Tree Algebra for XML}},
	Url = {http://www.cs.ubc.ca/~laks/tax-dbpl01-cr.pdf},
	Year = {2001},
	Abstract = {Querying XML has been the subject of much
	 recent investigation. A formal bulk algebra is essential for applying
	 database-style optimization to XML queries. We develop such an algebra,
	 called TAX (Tree Algebra for XML), for manipulating XML data, modeled
	 as forests of labeled ordered trees. Motivated both by aesthetic
	 considerations of intuitiveness, and by efficient computability and
	 amenability to optimization, we develop TAX as a natural extension of
	 relational algebra, with a small set of operators. TAX is complete for
	 relationl algebra extended with aggregation, and can express most queries
	 expressible in popular XML query langauges. It forms the basis for
	 the TIMBER XML database system currently under development by us.}}

@inproceedings{Jain.Mahajan.ea_TranslatXSLT2SQL_WWW_2002,
	Author = {Jain, Sushant and Mahajan, Ratul and Suciu, Dan},
	Booktitle = {Proc. Int. World Wide Web Conf.},
	Conference-Abbr = {WWW},
	Doi = {http://doi.acm.org/10.1145/511446.511526},
	Isbn = {1-58113-449-5},
	Keywords = {XML XSTL query processing relational implementation SQL},
	Location = {Honolulu, Hawaii, USA},
	Pages = {616--626},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Translating/Jain.Mahajan.ea_TranslatXSLT2SQL_WWW_2002.pdf},
	Publisher = {ACM Press},
	Title = {{Translating XSLT Programs to Efficient SQL Queries}},
	Url = {http://www2002.org/CDROM/refereed/226/},
	Year = {2002},
	Abstract = {We present an algorithm for translating XSLT
	 programs into SQL. Our context is that of virtual XML publishing,
	 in which a single XML view is defined from a relational database,
	 and subsequently queried with XSLT programs. Each XSLT program is
	 translated into a single SQL query and run entirely in the database
	 engine. Our translation works for a large fragment of XSLT, which we
	 define, that includes descendant/ancestor axis, recursive templates,
	 modes, parameters, and aggregates. We put considerable effort in
	 generating correct and efficient SQL queries and describe several
	 optimization techniques to achieve this efficiency. We have tested our
	 system on all 22 SQL queries of the TPC-H database benchmark which we
	 represented in XSLT and then translated back to SQL using our translator.}}

@inproceedings{Kaushik.Bohannon.ea_FBIndex_SIGMOD_2002,
	Address = {New York, NY, USA},
	Author = {Kaushik, Raghav and Bohannon, Philip and Naughton, Jeffrey F and Korth, Henry F},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Doi = {http://doi.acm.org/10.1145/564691.564707},
	Isbn = {1-58113-497-5},
	Keywords = {XML XPath XQuery index forward-backward branching tree},
	Location = {Madison, Wisconsin},
	Pages = {133--144},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/Kaushik.Bohannon.ea_FBIndex_SIGMOD_2002.pdf},
	Publisher = {ACM Press},
	Title = {{Covering indexes for Branching Path Queries}},
	Url = {http://portal.acm.org/citation.cfm?id=564691.564707},
	Year = {2002},
	Abstract = {In this paper, we ask if the
	 traditional relational query acceleration techniques of summary tables and
	 covering indexes have analogs for branching path expression queries
	 over tree- or graph-structured XML data. Our answer is yes --- the
	 forward-and-backward index already proposed in the literature can
	 be viewed as a structure analogous to a summary table or covering
	 index. We also show that it is the smallest such index that covers all
	 branching path expression queries. While this index is very general, our
	 experiments show that it can be so large in practice as to offer
	 little performance improvement over evaluating queries directly on the
	 data. Likening the forward-and-backward index to a covering index on
	 all the attributes of several tables, we devise an index definition
	 scheme to restrict the class of branching path expressions being
	 indexed. The resulting index structures are dramatically smaller and
	 perform better than the full forward-and-backward index for these
	 classes of branching path expressions. This is roughly analogous
	 to the situation in multidimensional or OLAP workloads, in which
	 more highly aggregated summary tables can service a smaller subset
	 of queries but can do so at increased performance. We evaluate the
	 performance of our indexes on both relational decompositions of XML and a
	 native storage technique. As expected, the performance benefit of
	 an index is maximized when the query matches the index definition.}}

@inproceedings{Koch.Scherzinger.ea_FluXQueryT_VLDB_2004,
	Author = {Koch, Christoph and Scherzinger, Stefanie and Schweikardt, Nicole and Stegmaier, Bernhard},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {Proc. Int. Conf. Very Large Databases},
	Conference-Abbr = {VLDB},
	Crossref = {DBLP:conf/vldb/2004},
	Ee = {http://www.vldb.org/conf/2004/RS6P2.PDF},
	Keywords = {XML streaming buffer minimization event scheduling FluXQuery},
	Pages = {228-239},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Streaming/Koch.Scherzinger.ea_FluXQueryT_VLDB_2004.pdf},
	Title = {{Schema-based Scheduling of Event Processors and Buffer Minimization for Queries on Structured Data Streams}},
	Url = {http://www.vldb.org/conf/2004/RS6P2.PDF},
	Year = {2004},
	Abstract = {We introduce an extension of the XQuery language, FluX, that supports
	 event-based query processing and the conscious handling of main memory bu
	 ers. Purely event-based queries of this language can be executed on
	 streaming XML data in a very direct way. We then develop an algorithm
	 that allows to e ciently rewrite XQueries into the event-based FluX
	 language. This algorithm uses order constraints from a DTD to schedule
	 event handlers and to thus minimize the amount of bu ering required
	 for evaluating a query. We discuss the various technical aspects of
	 query optimization and query evaluation within our framework. This
	 is complemented with an experimental evaluation of our approach.}}

@inproceedings{Koch_ComplexityNonRecXQ_PODS_2005,
	Author = {Koch, Christoph},
	Booktitle = {Proc. ACM SIGMOD Symposium on Principles of Database Systems},
	Conference-Abbr = {PODS},
	Keywords = {XML XQuery complexit non-recursive},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Comlexity/Koch_ComplexityNonRecXQ_PODS_2005.pdf},
	Title = {{On the Complexity of Nonrecursive XQuery and Functional Query Languages on Complex Values}},
	Url = {http://www.infosys.uni-sb.de/~koch/download/0503062.pdf},
	Year = {2005},
	Abstract = {This paper studies the
	 complexity of evaluating functional query languages for complex values
	 such as monad algebra and the recursion-free fragment of XQuery. We
	 show that monad algebra with equality restricted to atomic values is
	 complete for the class TA[2O(n),O(n)] of problems solvable in linear
	 exponential time with a linear number of alternations. The monotone
	 fragment of monad algebra with atomic value equality but without
	 negation is complete for nondeterministic exponential time. For monad
	 algebra with deep equality, we establish TA[2O(n),O(n)] lower and
	 exponential-space upper bounds. Then we study a fragment of XQuery, Core
	 XQuery, that seems to incorporate all the features of a query language
	 on complex values that are traditionally deemed essential. A close
	 connection between monad algebra on lists and Core XQuery (with ?child? as
	 the only axis) is exhibited, and it is shown that these languages
	 are expressively equivalent up to representation issues. We show
	 that Core XQuery is just as hard as monad algebra w.r.t. combined
	 complexity, and that it is in TC0 if the query is assumed fixed.}}

@inproceedings{Koch_CompositionXQuery_WebDB_2005,
	Author = {Koch, Christoph},
	Booktitle = {Proc. Int. Workshop on the Web and Databases},
	Conference-Abbr = {WebDB},
	Keywords = {XML XQuery composition expressiveness},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Comlexity/Koch_CompositionXQuery_WebDB_2005.pdf},
	Title = {{On the Role of Composition in XQuery}},
	Url = {http://www-db.cs.uni-sb.de/~koch/download/webdb2005.pdf},
	Year = {2005},
	Abstract = {Nonrecursive XQuery is known to be hard for nondeterministic exponential
	 time. Thus it is commonly believed that any algorithm for evaluating
	 XQuery has to require exponential amounts of working memory and doubly
	 exponential time in the worst case. In this paper we present a property
	 - the lack of a certain form of composition - that virtually all
	 real-world XQueries have and that allows for query evaluation in singly
	 exponential time and polynomial space. Still, we are able to show for an
	 important special case - our nonrecursive XQuery fragment restricted to
	 atomic value equality - that the composition-free language is just as
	 expressive as the language with composition. Thus, under widely-held
	 complexity-theoretic assumptions, the composition-free language is an
	 exponentially less succinct version of the language with composition.}}

@inproceedings{Koch.Scherzinger.ea_FluXQuery_VLDB_2004,
	Author = {Koch, Christoph and Scherzinger, Stefanie and Schweikardt, Nicole and Stegmaier, Bernhard},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {Proc. Int. Conf. on Very Large Databases},
	Conference-Abbr = {VLDB},
	Ee = {http://www.vldb.org/conf/2004/RS6P2.PDF},
	Keywords = {XML XQuery stream implementation FluXQuery},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Streaming/Koch.Scherzinger.ea_FluXQuery_VLDB_2004.pdf},
	Title = {{FluXQuery: An Optimizing XQuery Processor for Streaming XML Data}},
	Url = {http://www.wit.at/people/scherzinger/documents/demo.pdf},
	Year = {2004},
	Abstract = {--}}

@inproceedings{Krishnamurthy.Kaushik.ea_X2S_VLDB_2004,
	Author = {Krishnamurthy, Rajasekar and Kaushik, Raghav and Naughton, Jeffrey F.},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {Proc. Int. Conf. on Very Large Databases},
	Conference-Abbr = {VLDB},
	Crossref = {DBLP:conf/vldb/2004},
	Ee = {http://www.vldb.org/conf/2004/RS4P3.PDF},
	Keywords = {XML translation relational SQL},
	Pages = {144-155},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Translating/Krishnamurthy.Kaushik.ea_X2S_VLDB_2004.pdf},
	Title = {{Efficient XML-to-SQL Query Translation: Where to Add the Intelligence?}},
	Url = {http://www.vldb.org/conf/2004/RS4P3.PDF},
	Year = {2004},
	Abstract = {We consider the e ciency of queries generated by
	 XML to SQL translation. We rst show that published XML-to-SQL query
	 translation algorithms are suboptimal in that they often translate simple
	 path expressions into complex SQL queries even when much simpler
	 equivalent SQL queries exist. There are two logical ways to deal
	 with this problem. One could generate suboptimal SQL queries using a
	 fairly naive translation algorithm, and then attempt to optimize
	 the resulting SQL; or one could use a more intelligent translation
	 algorithm with the hopes of generating e cient SQL directly. We show that
	 optimizing the SQL after it is generated is problematic, becoming
	 intractable even in simple scenarios; by contrast, designing a translation
	 algorithm that exploits information readily available at translation
	 time is a promising alternative. To support this claim, we present a
	 translation algorithm that exploits translation time information to
	 generate e cient SQL for path expression queries over tree schemas.}}

@inproceedings{Krishnamurthy.Chakaravarthy.ea_X2S_ICDE_2004,
	Address = {Washington, DC, USA},
	Author = {Krishnamurthy, Rajasekar and Chakaravarthy, Venkatesan T. and Kaushik, Raghav and Naughton, Jeffrey F.},
	Booktitle = {Proc. Int. Conf. on Data Engineering},
	Conference-Abbr = {ICDE},
	Isbn = {0-7695-2065-0},
	Keywords = {XML translation XML query SQL recursive views},
	Pages = {42},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Translating/Krishnamurthy.Chakaravarthy.ea_X2S_ICDE_2004.pdf},
	Publisher = {IEEE Computer Society},
	Title = {{Recursive XML Schemas, Recursive XML Queries, and Relational Storage: XML-to-SQL Query Translation}},
	Url = {http://www.cs.wisc.edu/~sekar/research/recursiveqt.pdf},
	Year = {2004},
	Abstract = {We consider the problem of translating XML
	 queries intoSQL when XML documents have been stored in an RDBMSusing a
	 schema-based relational decomposition. Surprisingly,there is no published
	 XML-to-SQL query translationalgorithm for this scenario that handles
	 recursive XMLschemas. We present a generic algorithm to translate
	 pathexpression queries into SQL in the presence of recursionin the schema and
	 queries. This algorithm handles a generalclass of XML-to-Relational
	 mappings, which includesall techniques proposed in literature. Some of
	 the salientfeatures of this algorithm are: (i) It translates a path
	 expressionquery into a single SQL query, irrespective of howcomplex
	 the XML schema is, (ii) It uses the "with" clause inSQL99 to handle
	 recursive queries even over non-recursiveschemas, (iii) It reconstructs
	 recursive XML subtrees witha single SQL query and (iv) It shows that
	 the support forlinear recursion in SQL99 is sufficient for handling
	 pathexpression queries over arbitrarily complex recursive XMLschema.}}

@inproceedings{Krishnamurthy.Kaushik.ea_2SDupl_WebDB_2004,
	Address = {New York, NY, USA},
	Author = {Krishnamurthy, Rajasekar and Kaushik, Raghav and Naughton, Jeffrey F},
	Booktitle = {Proc. Int. Workshop on the Web and Databases},
	Conference-Abbr = {WebDB},
	Doi = {http://doi.acm.org/10.1145/1017074.1017088},
	Keywords = {XML translation SQL XML},
	Location = {Paris, France},
	Pages = {49--54},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Translating/Krishnamurthy.Kaushik.ea_2SDupl_WebDB_2004.pdf},
	Publisher = {ACM Press},
	Title = {{Unraveling the Duplicate-elimination Problem in XML-to-SQL Query Translation}},
	Url = {http://webdb2004.cs.columbia.edu/papers/4-2.pdf},
	Year = {2004},
	Abstract = {We consider the scenario where existing relational
	 data is exported as XML. In this context, we look at the problem of
	 translating XML queries into SQL. XML query languages have two different
	 notions of duplicates: node-identity based and value-based. Path
	 expression queries have an implicit node-identity based duplicate
	 elimination built into them. On the other hand, SQL only supports
	 value-based duplicate elimination. In this paper, using a simple
	 path expression query we illustrate the problems that arise when we
	 attempt to simulate the node-identity based duplicate elimination
	 using value-based duplicate elimination in the SQL queries. We show
	 how a general solution for this problem covering the class of views
	 considered in published literature requires a fairly complex mechanism.}}

@inproceedings{Lam.Shui.ea_SkippingStrucJ_DASFA_2004,
	Author = {Lam, Franky and Shui, William M. and Fisher, Damien K. and Wong, Raymond K.},
	Booktitle = {Int. Conf. on Database Systems for Advanced Applications},
	Conference-Abbr = {DASFA},
	Keywords = {XML XQuery structural joins algorithms efficient evaluation},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/StructuralJoins/Lam.Shui.ea_SkippingStrucJ_DASFA_2004.pdf},
	Title = {{Skipping Strategies for Efficient Structural Joins}},
	Url = {ftp://ftp.cse.unsw.edu.au/pub/doc/papers/UNSW/0320.pdf},
	Year = {2004},
	Abstract = {The structural join is considered a core operation in
	 processing and optimizing XML queries. Various techniques have been
	 proposed for efficiently finding structural relationships between a
	 list of potential ancestors and a list of potential descendants.
	 This paper presents a novel algorithm for efficiently processing
	 structural joins. Moreover, previous work which performs well usually
	 relies on external index structures such as a B-tree, which increases
	 both the storage and memory overheads. Our proposal in this paper
	 does not require any such data structures, and hence can be easily
	 implemented and incorporated in any existing system. Experiments
	 show that our method significantly outperforms previous algorithms.}}

@inproceedings{Lechner.Preuner.ea_XQuery2XSLT_DASWIS_2002,
	Address = {London, UK},
	Author = {Lechner, Stephan and Preuner, G{\"u}nter and Schrefl, Michael},
	Booktitle = {Proc. Int. Workshop on Data Semantics in Web Information Systems},
	Conference-Abbr = {DASWIS},
	Isbn = {3-540-44122-0},
	Keywords = {XML XQuery XSLT translation abstract machine},
	Pages = {239--252},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Translating/Lechner.Preuner.ea_XQuery2XSLT_DASWIS_2002.pdf},
	Publisher = {Springer-Verlag},
	Title = {{Translating XQuery into XSLT}},
	Url = {http://www.dke.jku.at/research/projects/xq2xsl/xq2xslDASWIS01.pdf},
	Year = {2002},
	Abstract = {The WWW Consortium (W3C) has recently presented a working draft of
	 XQuery, which is intended to serve as standardized query language for
	 XML. XQuery and other high-level query languages for XML documents
	 are not yet implemented by commercial products. Yet many browsers
	 have already built-in XSLT support for transforming XML documents.
	 XSLT is a standard way of performing structural rearrangement or
	 presentational transformation of XML documents, but formulating complex
	 queries is, compared to XQuery, difficult and error-prone. If XQuery
	 expressions could be translated into XSLT (e.g. by a translator written in
	 Java or XSLT itself), the benefits of Xquery would be immediately
	 available to a wide range of commercial products. This paper introduces a
	 process for translating queries formulated in XQuery syntax into XSL
	 stylesheets. The process is described independently from a particular
	 implementation by means of an ASM (Abstract State Machine). The ASM
	 traverses the parse tree of a particular query and translates each node
	 into corresponding XSLT commands. The result of this translation
	 process is an XSL stylesheet that can be applied to an XML document in
	 order to perform the given query. The presented ASM can be easily
	 coded in Java or XSLT to implement a prototype XQ2XSL translator.}}

@inproceedings{Li.Ferreira.ea_CompileXML_ICS_2003,
	Address = {New York, NY, USA},
	Author = {Li, Xiaogang and Ferreira, Renato and Agrawal, Gagan},
	Booktitle = {Proc. Int. Conf. on Supercomputing},
	Conference-Abbr = {ICS},
	Doi = {http://doi.acm.org/10.1145/782814.782823},
	Isbn = {1-58113-733-8},
	Keywords = {XML XQuery compiler support query optimization},
	Location = {San Francisco, CA, USA},
	Pages = {42--52},
	Publisher = {ACM Press},
	Title = {{Compiler Support for Efficient Processing of XML Datasets}},
	Url = {http://portal.acm.org/citation.cfm?id=782823},
	Year = {2003},
	Abstract = {Declarative, high-level, and/or
	 application-class specific languages are often successful in easing
	 application development. In this paper, we report our experiences
	 in compiling a recently developed XML Query Language, XQuery for
	 applications that process scientific datasets.Though scientific data
	 processing applications can be conveniently represented in XQuery,
	 compiling them to achieve efficient execution involves a number of
	 challenges. These are, 1) analysis of recursive functions to identify
	 reduction computations involving only associative and commutative
	 operations, 2) replacement of recursive functions with iterative
	 constructs, 3) parallelization of generalized reduction functions, which
	 particularly requires the synthesis of global reduction functions, 4)
	 application of data-centric transformations on the structure of XQuery,
	 and 5) translation of XQuery processing to an imperative language
	 like C/C++, which is required for using a middleware that offers
	 low-level functionality.This paper describes our solutions towards
	 these problems. By implementing the techniques in a compiler and
	 generating code for a runtime system called Active Data Repository
	 (ADR), we are able to achieve efficient processing of disk-resident
	 datasets and parallelization on a cluster of machines. Our experimental
	 results show that: 1) restructuring transformations, i.e. removing
	 recursion and applying data-centric execution, result in several-folds
	 improvement in performance, and 2) parallel versions achieve good
	 load-balance, and incur no significant overheads besides communication.}}

@inproceedings{Li.Yu.ea_Schema-FreeXQuery_VLDB_2004,
	Author = {Li, Yunyao and Yu, Cong and Jagadish, H. V.},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {Proc. Int. Conf. on Very Large Data Bases},
	Conference-Abbr = {VLDB},
	Ee = {http://www.vldb.org/conf/2004/RS2P3.PDF},
	Keywords = {XML XQuery schema-free lowest common ancestor approximate query},
	Pages = {72-83},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/XQuery/Li.Yu.ea_Schema-FreeXQuery_VLDB_2004.pdf},
	Title = {{Schema-Free XQuery}},
	Url = {http://www.vldb.org/conf/2004/RS2P3.PDF},
	Year = {2004},
	Abstract = {The widespread adoption of XML holds out the promise that document structure can be
	 exploited to specify precise database queries. However, the user may
	 have only a limited knowledge of the XML structure, and hence may
	 be unable to create a correct XQuery, particularly in the context
	 of a heterogeneous information collection. The default is to use
	 keyword-based search and we are all too familiar with how difficult
	 it is to obtain precise answers by these means. We seek to address
	 these problems by introducing the notion of Meaningful Lowest Common
	 Ancestor Structure (MLCAS) for finding related nodes within an XML
	 document. By automatically computing MLCAS and expanding ambiguous
	 tag names, we add new functionalities to XQuery and enable users to
	 take full advantage of XQuery in querying XML data precisely and
	 efficiently without requiring (perfect) knowledge of the document
	 structure. Such a Schema-Free XQuery is potentially of value not just in
	 casual users with partial knowledge of schema, but also in a data
	 integration or data evolution context where one would like a query
	 written once to apply ?forever? as the schema of the data source
	 changes. Our experimental evalua- tion found that it was possible
	 to express a wide variety of queries in a Schema-Free manner and
	 have them return correct results over a broad diversity of schemas.
	 Furthermore, the evaluation of a Schema-Free query is not expensive using a
	 novel stack-based algorithm we develop for computing MLCAS: from 1
	 to 4 times the execution time of an equivalent schema-aware query.}}

@inproceedings{Liu.Vincent_XSLT2SQL_DEAS_2003,
	Author = {Liu, Jixue and Vincent, Millist},
	Booktitle = {Proc. Int. Database Engineering and Applications Symposium},
	Conference-Abbr = {DEAS},
	Keywords = {XML XSLT relational implementation SQL query evaluation},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XSLT/Liu.Vincent_Querytranslationfrom_DEAS_2003.pdf},
	Title = {{Query Translation from XSLT to SQL}},
	Url = {http://intl.ieeexplore.ieee.org/xpl/abs_free.jsp?arNumber=1214914},
	Year = {2003},
	Abstract = {XML has been accepted as a universal
	 format for data interchange and publication. It can be applied in the
	 applications in which the data of a database needs to be viewed in
	 XML format so that the data being viewed takes more semantics and
	 is easily understood. In these applications, the user of the data
	 to be viewed sees only XML data, not the database. He may use XML
	 query languages such as XSLT to query data and the retrieved data is
	 presented in XML format to them. We are interested in the connection
	 between the data that the user sees and the data in the database. More
	 specifically, we are interested in translating XSLT queries to SQL queries.}}

@article{Lu.Yu.ea_BenchmarkXMLDB_TOIS_2005,
	Address = {New York, NY, USA},
	Author = {Lu, Hongjun and Yu, Jeffrey Xu and Wang, Guoren and Zheng, Shihui and Jiang, Haifeng and Yu, Ge and Zhou, Aoying},
	Doi = {http://doi.acm.org/10.1145/1052934.1052940},
	Issn = {1533-5399},
	Journal = {ACM Transactions on Internet Technologies},
	Journal-Abbr = {TOIS},
	Keywords = {XML benchmarking query optimization processor XML databases},
	Number = {1},
	Pages = {154--194},
	Pdf = {QueryEvaluation/XML/Lu.Yu.ea_BenchmarkXMLDB_TOIS_2005.pdf},
	Publisher = {ACM Press},
	Title = {{What Makes the Differences: Benchmarking XML Database Implementations}},
	Url = {http://www.cs.ust.hk/~jianghf/files/bencharmk.pdf},
	Volume = {5},
	Year = {2005},
	Abstract = {XML is emerging as a major standard for
	 representing data on the World Wide Web. Recently, many XML storage models
	 have been proposed to manage XML data. In order to assess an XML
	 database's abilities to deal with XML queries, several benchmarks have
	 also been proposed, including XMark and XMach. However, no reported
	 studies using those benchmarks were found that can provide users with
	 insights on the impacts of a variety of storage models on XML query
	 performance. In this article, we report our first set of results on
	 benchmarking a set of XML database implementations using two XML
	 benchmarks. The selected implementations represent a wide range of
	 approaches, including RDBMS-based systems with document-independent and
	 document-dependent XML-relational schema mapping approaches, and XML native
	 engines based on an Object-Oriented Model and the Document Object
	 Model. Comprehensive experiments were conducted to study relative
	 performance of different approaches and the important issues that affect
	 XML query performance, such as path expression query processing,
	 effectiveness of various partitioning, label-path, and indexing structures.}}

@inproceedings{Lu.Chen.ea_TwigsLA_CIKM_2004,
	Address = {New York, NY, USA},
	Author = {Lu, Jiaheng and Chen, Ting and Ling, Tok Wang},
	Booktitle = {Proc. Conf. on Information and Knowledge Management},
	Conference-Abbr = {CIKM},
	Doi = {http://doi.acm.org/10.1145/1031171.1031272},
	Isbn = {1-58113-874-1},
	Keywords = {XML query processing twig joins structural joins query optimization},
	Location = {Washington, D.C., USA},
	Pages = {533--542},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/StructuralJoins/Lu.Chen.ea_TwigsLA_CIKM_2004.pdf},
	Publisher = {ACM Press},
	Title = {{Efficient Processing of XML Twig Patterns with Parent Child Edges: A Look-ahead Approach}},
	Url = {http://portal.acm.org/citation.cfm?id=1031272},
	Year = {2004},
	Abstract = {With the growing importance of
	 semi-structure data in information exchange, much research has been done
	 to provide an effective mechanism to match a twig query in an XML
	 database. A number of algorithms have been proposed recently to process a
	 twig query holistically. Those algorithms are quite efficient for
	 quires with only ancestor-descendant edges. But for queries with mixed
	 ancestor-descendant and parent-child edges, the previous approaches
	 still may produce large intermediate results, even when the input and
	 output size are more manageable. To overcome this limitation, in
	 this paper, we propose a novel holistic twig join algorithm, namely
	 <i>TwigStackList</i>. Our main technique is to look-ahead read some
	 elements in input data steams and cache limited number of them to
	 <i>lists</i> in the main memory. The number of elements in any list is
	 bounded by the length of the longest path in the XML document. We
	 show that <i>TwigStackList</i> is I/O optimal for queries with only
	 ancestor-descendant relationships below branching nodes. Further, even when
	 queries contain parent-child relationship below branching nodes, the
	 set of intermediate results in <i>TwigStackList</i> is guaranteed
	 to be a subset of that in previous algorithms. We complement our
	 experimental results on a range of real and synthetic data to show
	 the significant superiority of <i>TwigStackList</i> over previous
	 algorithms for queries with <i>parent</i>-<i>child</i> relationships.}}

@inproceedings{Marx_FirstOrderPaths_ICDT_2005,
	Author = {Marx, Maarten},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {Proc. Int. Conf. on Database Theory},
	Conference-Abbr = {ICDT},
	Ee = {http://springerlink.metapress.com/openurl.asp?genre=article{\&}issn=0302-9743{\&}volume=3363{\&}spage=114},
	Keywords = {XML XPath completeness first-order logic conditional axes core xpath},
	Pages = {114-128},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/XPath/Marx_FirstOrderPaths_ICDT_2005.pdf},
	Title = {{First Order Paths in Ordered Trees}},
	Url = {http://staff.science.uva.nl/~marx/pub/recent/icdt05.pdf},
	Year = {2005},
	Abstract = {We give two sufficient conditions on XPath like languages for having first order
	 expressivity, meaning that every first order definable set of paths in
	 an ordered node-labeled tree is definable in that XPath language.
	 They are phrased in terms of expansions of navigational (sometimes
	 called ?Core?) XPath. Adding either complementation, or the more
	 elegant conditional paths is sufficient. A conditional path is an axis
	 relation of the form (one step axis::n[F])+, denoting the transitive
	 closure of the relation expressed by one step axis::n[F]. As neither is
	 expressible in navigational XPath we also give characterizations in
	 terms of first order logic of the answer sets and the sets of paths
	 navigational XPath can define. The first in terms of a suitable two
	 variable fragment, the second in terms of unions of conjunctive queries.}}

@inproceedings{Marx_ConditionalXPathFirst_PODS_2004,
	Author = {Marx, Maarten},
	Booktitle = {Proc. ACM Symposium on Principles of Database Systems},
	Conference-Abbr = {PODS},
	Keywords = {XPath Qualified Descendant Conditional Axes},
	Month = {6},
	Organization = {ACM},
	Owner = {Tim Furche},
	Pages = {13--22},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/XPath/Marx_ConditionalXPathFirst_PODS_2004.pdf},
	Title = {{Conditional XPath, the First Order Complete XPath Dialect}},
	Url = {http://turing.wins.uva.nl/~marx/pub/recent/pods04.pdf},
	Year = {2004},
	Abstract = {XPath is the W3C-standard node addressing
	 language for XML documents. XPath is still under development and
	 its technical aspects are intensively studied. What is missing at
	 present is a clear characterization of the expressive power of XPath,
	 be it either semantical or with reference to some well established
	 existing (logical) formalism. Core XPath (the logical core of XPath 1.0
	 defined by Gottlob et al.) cannot express queries with conditional
	 paths as exemplified by ?do a child step, while test is true at the
	 resulting node.? In a first-order complete extension of Core XPath,
	 such queries are expressible. We add conditional axis relations to
	 Core XPath and show that the resulting language, called conditional
	 XPath, is equally expressive as first-order logic when interpreted on
	 ordered trees. Both the result, the extended XPath language, and the
	 proof are closely related to temporal logic. Specifically, while Core
	 XPath may be viewed as a simple temporal logic, conditional XPath
	 extends this with (counterparts of) the since and until operators.}}

@inproceedings{Marx_XPathwithConditional_EDBT_2004,
	Author = {Marx, Maarten},
	Booktitle = {Proc. Extending Database Technology},
	Conference-Abbr = {EDBT},
	Keywords = {XPath Qualified Descendant Conditional Axes},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/XPath/Marx_XPathwithConditional_EDBT_2004.pdf},
	Title = {{XPath with Conditional Axis Relations}},
	Url = {http://turing.wins.uva.nl/~marx/pub/edbt04.pdf},
	Year = {2004},
	Abstract = {This paper is about the W3C standard
	 node-addressing language for XML documents, called XPath. XPath is still under
	 development. Version 2.0 appeared in 2001 while the theoretical foundations
	 of Version 1.0 (dating from 1998) are still being widely studied.
	 The paper aims at bringing XPath to a ?stable fixed point? in its
	 development: a version which is expressively complete, still manageable
	 computationally, with a user-friendly syntax and a natural semantics. We
	 focus on an important axis relation which is not expressible in XPath
	 1.0 and is very useful in practice: the conditional axis. With it
	 we can express paths specified by for instance ?do a child step,
	 while test is true at the resulting node?. We study the effect of
	 adding conditional axis relations to XPath on its expressive power
	 and the complexity of the query evaluation and query equivalence
	 problems. We define an XPath dialect XCPath which is expressively
	 complete, has a linear time query evaluation algorithm and for which
	 query equivalence given a DTD can be decided in exponential time.}}

@article{Marx.Rijke_SemanticCharacterizations_SIGR_2005,
	Author = {Marx, Maarten and de Rijke, Maarten},
	Journal = {ACM SIGMOD Record},
	Journal-Abbr = {SIGR},
	Keywords = {XML XPath completeness first-order logic conditional XPath core XPath},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/XPath/Marx.Rijke_SemanticCharacterizations_SIGR_2005.pdf},
	Title = {{Semantic Characterizations of Navigational XPath}},
	Url = {http://turing.wins.uva.nl/~marx/pub/recent/sigmod_record.pdf},
	Year = {2005},
	Abstract = {We give semantic characterizations of the
	 expressive power of navigational XPath (a.k.a. Core XPath) in terms of
	 first order logic. XPath can be used to specify sets of nodes and
	 sets of paths in an XML document tree. We consider both uses. For
	 sets of nodes, XPath is equally expressive as first order logic in
	 two variables. For paths, XPath can be defined using four simple
	 connectives, which together yield the class of first order definable
	 relations which are safe for bisimulation. Furthermore, we give a
	 characterization of the XPath expressible paths in terms of conjunctive queries.}}

@inproceedings{May.Helmer.ea_XQueryNatix_XIME-P_2004,
	Author = {May, Norman and Helmer, Sven and Kanne, Carl-Christian and Moerkotte, Guido},
	Booktitle = {Proc. of Int. Workshop on XQuery Implementation, Experience and Perspectives},
	Conference-Abbr = {XIME-P},
	Keywords = {XML XQuery Natix query optimization order processing},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/OrderDuplicates/May.Helmer.ea_XQueryNatix_XIME-P_2004.pdf},
	Title = {{XQuery Processing in Natix with an Emphasis on Join Ordering}},
	Url = {http://pi3.informatik.uni-mannheim.de/old/publications/ximep2004-joinorder.ps},
	Year = {2004},
	Abstract = {We give an overview on how XQuery processing works
	 in our native XML database system Natix. After a brief description
	 of the query compiler we focus on the aspect of join ordering when
	 generating query execution plans. Here we show that better plans
	 can be found when extending the search space of the plan generator.}}

@inproceedings{May.Helmer.ea_NestedQueries_ICDE_2004,
	Author = {May, Norman and Helmer, Sven and Moerkotte, Guido},
	Booktitle = {Proc. Int. Conf. on Data Engineering},
	Conference-Abbr = {ICDE},
	Keywords = {XML nested queries algebra query optimization},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/May.Helmer.ea_NestedQueries_ICDE_2004.pdf},
	Title = {{Nested Queries and Quantifiers in an Ordered Context}},
	Url = {http://pi3.informatik.uni-mannheim.de/old/publications/unnesting_icde2004.pdf},
	Year = {2004},
	Abstract = {We present algebraic equivalences that
	 allow to unnest nested algebraic expressions for order-preserving
	 algebraic operators. We illustrate how these equivalences can be applied
	 successfully to unnest nested queries given in the XQuery language.
	 Measurements illustrate the performance gains possible by unnesting.}}

@inproceedings{May.Helmer.ea_QuantifiersXQuery_WISE_2003,
	Author = {May, Norman and Helmer, Sven and Moerkotte, Guido},
	Booktitle = {Proc. Int. Conf. on Web Information Systems Engineering},
	Conference-Abbr = {WISE},
	Keywords = {XML XQuery quantifiers nested queries optimization rewriting},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/NestedQueries/May.Helmer.ea_QuantifiersXQuery_WISE_2003.pdf},
	Title = {{Quantifiers in XQuery}},
	Url = {http://pi3.informatik.uni-mannheim.de/~norman/unnesting_wise03.pdf},
	Year = {2003},
	Abstract = {We present algebraic equivalences that allow to unnest nested
	 algebraic expressions containing quantifiers for order-preserving
	 algebraic operators. We illustrate how these equivalences can be
	 applied successfully to unnest nested queries formulated in XQuery.
	 Measurements illustrate the performance gains possible by unnesting.}}

@article{McHugh.Abiteboul.ea_Lore-SSDBMS_SIGRec_1997,
	Author = {McHugh, Jason and Abiteboul, Serge and Goldman, Roy and Quass, Dallan and Widom, Jennifer},
	Journal = {SIGMOD Record},
	Journal-Abbr = {SIGRec},
	Keywords = {XML Lore semi-structured data database management algebra optimization graph-shaped},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/McHugh.Abiteboul.ea_Lore-SSDBMS_SIGRec_1997.pdf},
	Title = {{Lore: A Database Management System for Semistructured Data}},
	Url = {http://www-db.stanford.edu/lore/pubs/lore97.pdf},
	Year = {1997},
	Abstract = {Lore (for Lightweight Object Repository) is a
	 DBMS designed specifically for managing semistructured information.
	 Implementing Lore has required rethinking all aspects of a DBMS, including
	 storage management, indexing, query processing and optimization, and
	 user interfaces. This paper provides an overview of these aspects of
	 the Lore system, as well as other novel features such as dynamic
	 structural summaries and seamless access to data from external sources.}}

@article{Meuss.Schulz_CAAs_TOIS_2001,
	Author = {Meuss, Holger and Schulz, Klaus U.},
	Doi = {http://doi.acm.org/10.1145/382979.383042},
	Issn = {1046-8188},
	Journal = {ACM Transactions on Information Systems},
	Journal-Abbr = {TOIS},
	Keywords = {XML query languages visualization navigation browsing CAA complexity},
	Number = {2},
	Pages = {161--215},
	Pdf = {QueryEvaluation/XML/Comlexity/Meuss.Schulz_CAAs_TOIS_2001.pdf},
	Publisher = {ACM Press},
	Title = {{Complete Answer Aggregates for Treelike Databases: A Novel Approach to Combine Querying and Navigation}},
	Url = {http://www.cis.uni-muenchen.de/people/Meuss/Pub/TOIS01.pdf},
	Volume = {19},
	Year = {2001},
	Abstract = {The use of markup languages like SGML, HTML or XML
	 for encoding the strucutre of documents or linguistic data has lead
	 to many databases where entries are adequately described as trees.
	 In this context querying formalisms are interesting that offer the
	 possiblity to refer both to textual content and logical structure. We
	 consider models where the strucutre specified in a query is not only
	 used as a filter, but also for selecting and presenting different
	 parts of the data. If answers are formalized as mapping from query
	 nodes to the database, a simple enumeration of all mappings in the
	 answer set will often suffer from the effect that many answers have
	 common subparts. From a theoretical point of view this may lead to an
	 exponential time complexity of the computation and presentation of all
	 answers. Concentration on the language of so called tree queries?a
	 variant and extension of Kilpelinen's Tree Matching formalism?we
	 introduce the notion of a ?complete answer aggregate? for a given
	 query. This new data strucutre offers a compact view of the set of
	 all answer and supports active exploration of the ansewer space.
	 Since complete answer aggregates use a powerful structure-sharing
	 mechanism their maximal size is of order &sgr;(d?h?q) where d and q
	 respectively denote the size of the database and the query, and h is
	 the maximal depth of a path of the database. An algorithm is given
	 that computes a complete answer aggregate for a given treee query
	 in time &sgr;(d?log(d)?h?). For the sublanguage of so-called rigid
	 tree queries, as well as for so-called ?nonrecursive? databases, an
	 improved bound of :&sgr;(d?log(d)?q) is obtained. The algorithm is based
	 on a specific index structure that supports practical efficiency.}}

@article{Miklau.Suciu_ContainmentEquivalence_JACM_2004,
	Address = {New York, NY, USA},
	Author = {Miklau, Gerome and Suciu, Dan},
	Doi = {http://doi.acm.org/10.1145/962446.962448},
	Issn = {0004-5411},
	Journal = {Journal of the ACM},
	Journal-Abbr = {JACM},
	Keywords = {XML XPath containment equivalence},
	Number = {1},
	Pages = {2--45},
	Pdf = {QueryEvaluation/XML/Containment/Miklau.Suciu_ContainmentEquivalence_JACM_2004.pdf},
	Publisher = {ACM Press},
	Title = {{Containment and Equivalence for a Fragment of XPath}},
	Url = {http://portal.acm.org/citation.cfm?id=962448},
	Volume = {51},
	Year = {2004},
	Abstract = {XPath is a language for
	 navigating an XML document and selecting a set of element nodes. XPath
	 expressions are used to query XML data, describe key constraints,
	 express transformations, and reference elements in remote documents.
	 This article studies the containment and equivalence problems for a
	 fragment of the XPath query language, with applications in all these
	 contexts.In particular, we study a class of XPath queries that contain
	 branching, label wildcards and can express descendant relationships
	 between nodes. Prior work has shown that languages that combine any
	 two of these three features have efficient containment algorithms.
	 However, we show that for the combination of features, containment is
	 coNP-complete. We provide a sound and complete algorithm for containment
	 that runs in exponential time, and study parameterized PTIME special
	 cases. While we identify one parameterized class of queries for which
	 containment can be decided efficiently, we also show that even with some
	 bounded parameters, containment remains coNP-complete. In response
	 to these negative results, we describe a sound algorithm that is
	 efficient for all queries, but may return false negatives in some cases.}}

@inproceedings{ONeil.ONeil.ea_ORDPATH_SIGMOD_2004,
	Author = {O'Neil, Patrick and O'Neil, Elizabeth and Pal, Shankar and Cseri, Istvan and Schaller, Gideon and Westbury, Nigel},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Doi = {http://doi.acm.org/10.1145/1007568.1007686},
	Isbn = {1-58113-859-8},
	Keywords = {XML encoding XQuery relational implementation},
	Location = {Paris, France},
	Pages = {903--908},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/ONeil.ONeil.ea_ORDPATH_SIGMOD_2004.pdf},
	Publisher = {ACM Press},
	Title = {{ORDPATHs: Insert-friendly XML Node Labels}},
	Url = {http://www.cs.umb.edu/~poneil/ordpath.pdf},
	Year = {2004},
	Abstract = {We introduce a hierarchical labeling scheme called ORDPATH that is
	 implemented in the upcoming version of Microsoft{\textregistered} SQL
	 Server?. ORDPATH labels nodes of an XML tree without requiring a
	 schema (the most general case---a schema simplifies the problem). An
	 example of an ORDPATH value display format is "1.5.3.9.1". A compressed
	 binary representation of ORDPATH provides document order by simple
	 byte-by-byte comparison and ancestry relationship equally simply.
	 In addition, the ORDPATH scheme supports insertion of new nodes at
	 arbitrary positions in the XML tree, their ORDPATH values "careted in"
	 between ORDPATHs of sibling nodes, without relabeling any old nodes.}}

@inproceedings{Olteanu.Meuss.ea_XPathLF_XMLDM_2002,
	Author = {Olteanu, Dan and Meuss, Holger and Furche, Tim and Bry, Fran{\c c}ois},
	Booktitle = {Proc. EDBT Workshop on XML-Based Data Management},
	Conference-Abbr = {XMLDM},
	Keywords = {XPath query rewriting query containment reverse axes},
	Month = {3},
	Pdf = {QueryEvaluation/XML/Containment/Olteanu.Meuss.ea_XPathLF_XMLDM_2002.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{XPath: Looking Forward}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2002-4},
	Urldate = {2004/11/11},
	Volume = {2490},
	Year = {2002},
	Abstract = {The location path language XPath is of particular importance for XML applications
	 since it is a core component of many XML processing standards such
	 as XSLT or XQuery. In this paper, based on axis symmetry of XPath,
	 equivalences of XPath 1.0 location paths involving ?reverse axes?, such as
	 ancestor and preceding, are established. These equivalences are used
	 as rewriting rules in an algorithm for transforming location paths
	 with reverse axes into equivalent reverse-axis-free ones. Location
	 paths without reverse axes as generated by the presented rewriting
	 algorithm enable efficient SAX-like streamed data processing of XPath.}}

@inproceedings{Ordonez_RecursiveSQL_SIGMOD_2005,
	Address = {New York, NY, USA},
	Author = {Ordonez, Carlos},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Doi = {http://doi.acm.org/10.1145/1066157.1066260},
	Isbn = {1-59593-060-4},
	Keywords = {SQL recursive queries},
	Location = {Baltimore, Maryland},
	Pages = {834--839},
	Pdf = {QueryEvaluation/RecursiveQueries/Ordonez_RecursiveSQL_SIGMOD_2005.pdf},
	Publisher = {ACM Press},
	Title = {{Optimizing Recursive Queries in SQL}},
	Url = {http://portal.acm.org/citation.cfm?id=1066157.1066260},
	Year = {2005},
	Abstract = {Recursion represents an important addition to the SQL language.
	 This work focuses on the optimization of linear recursive queries in
	 SQL. To provide an abstract framework for discussion, we focus on
	 computing the transitive closure of a graph. Three optimizations
	 are studied: (1) Early evaluation of row selection conditions. (2)
	 Eliminating duplicate rows in intermediate tables. (3) Defining an enhanced
	 index to accelerate join computation. Optimizations are evaluated on
	 two types of graphs: binary trees and sparse graphs. Binary trees
	 represent an ideal graph with no cycles and a linear number of edges.
	 Sparse graphs represent an average case with some cycles and a linear
	 number of edges. In general, the proposed optimizations produce a
	 significant reduction in the evaluation time of recursive queries.}}

@inproceedings{Page.Hidders.ea_NodeConstr_WebDB_2005,
	Author = {Page, Wim Le and Hidders, Jan and Michiels, Philippe and Paredaens, Jan and Vercammen, Roel},
	Booktitle = {Proc. Int. Workshop on the Web and Databases},
	Conference-Abbr = {WebDB},
	Keywords = {XML XQuery node construction expressive power},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Comlexity/Page.Hidders.ea_NodeConstr_WebDB_2005.pdf},
	Title = {{On the Expressive Power of Node Construction in XQuery}},
	Url = {http://www.adrem.ua.ac.be/~rvcamm/publications/WebDB2005.pdf},
	Year = {2005},
	Abstract = {In the relational model it has been shown that the flat relational algebra has the
	 same expressive power as the nested relational algebra, as far as
	 queries over flat relations and with flat results are concerned [6].
	 Hence, for each query that uses the nested relational model and that,
	 with a flat table as input always has a flat table as output, there
	 exists an equivalent flat query that only uses the flat relational
	 model. In analogy, we study a related flat-flat problem for XQuery:
	 for each expression containing operations that construct new nodes
	 and whose XML result contains only original nodes, there exists an
	 equivalent ?flat? expression in XQuery that does not construct new nodes.}}

@inproceedings{Paparizos.AlKhalifa.ea_GroupingXML_XMLDM_2002,
	Author = {Paparizos, Stelios and Al-Khalifa, Shurug and Jagadish, H. V. and Lakshmanan, Laks V.S. and Nierman, Andrew and Srivastava, Divesh and Wu, Yuqing},
	Booktitle = {EDBT Workshop on XML Data Management},
	Conference-Abbr = {XMLDM},
	Keywords = {XQuery, grouping, query optimization, algebra, TAX, XML},
	Number = {2490},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/XQuery/Paparizos.AlKhalifa.ea_GroupingXML_XMLDM_2002.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{Grouping in XML}},
	Url = {http://www.cs.indiana.edu/~yuqwu/papers/XMLDB02-Grouping.pdf},
	Year = {2002},
	Abstract = {XML permits repeated and missing sub-elements, and missing
	 attributes. We discuss the consequent implications on grouping, both with
	 respect to specification and with respect to implementation. The
	 techniques described here have been implemented in the TIMBER native
	 XML database system being developed at the University of Michigan.}}

@techreport{Paparizos.Al-Khalifa.ea_TIMBERPhysAlg_TR_2002,
	Author = {Paparizos, Stelios and Al-Khalifa, Shurug and Jagadish, H.V. and Nierman, Andrew and Wu, Yuqing},
	Institution = {EECS Department, Univ. of Michigan},
	Keywords = {XML TIMBER physical algebra TAX},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Paparizos.Al-Khalifa.ea_TIMBERPhysAlg_TR_2002.pdf},
	Title = {{A Physical Algebra for XML}},
	Url = {http://www.eecs.umich.edu/db/timber/files/physical.pdf},
	Year = {2002},
	Abstract = {We present a physical algebra for
	 the manipulation of XML in a database. We show how to map logical
	 algebra operators to this physical algebra. We also present several
	 physical algebra identities that are useful for query optimization.
	 This physical algebra is the basis for the implementation of the
	 TIMBER native XML database system at the University of Michigan.}}

@inproceedings{Paparizos.Jagadish_SetsVsSequences_VLDB_2005,
	Author = {Paparizos, Stelios and Jagadish, H.V.},
	Booktitle = {Proc. Int. Conf. on Very Large Databases},
	Conference-Abbr = {VLDB},
	Keywords = {XML ordering algebra query optimization TLC},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Paparizos.Jagadish_SetsVsSequences_VLDB_2005.pdf},
	Title = {{Pattern tree algebras: sets or sequences?}},
	Url = {http://www.eecs.umich.edu/db/timber/files/ordervldb05.pdf},
	Year = {2005},
	Abstract = {XML and XQuery semantics are very sensitive
	 to the order of the produced output. Although pattern-tree based
	 algebraic approaches are becoming more and more popular for evaluating
	 XML, there is no universally accepted technique which can guarantee
	 both a correct output order and a choice of efficient alternative
	 plans. We address the problem using hybrid collections of trees that
	 can be either sets or sequences or something in between. Each such
	 collection is coupled with an Ordering Specification that describes how
	 the trees are sorted (full, partial or no order). This provides us
	 with a formal basis for developing a query plan having parts that
	 maintain no order and parts with partial or full order. It turns
	 out that duplicate elimination introduces some of the same issues
	 as order maintenance: it is expensive and a single collection type
	 does not always provide all the flexibility required to optimize
	 this properly. To solve this problem we associate with each hybrid
	 collection a Duplicate Specification that describes the presence
	 or absence of duplicate elements in it. We show how to extend an
	 existing bulk tree algebra, TLC [12], to use Ordering and Duplicate
	 specifications and produce correctly ordered results. We also suggest
	 some optimizations enabled by the flexibility of our approach, and
	 experimentally demonstrate the performance increase due to them.}}

@inproceedings{Paparizos.Wu.ea_TreeLogical_SIGMOD_2004,
	Author = {Paparizos, Stelios and Wu, Yuqing and Lakshmanan, Laks V. S. and Jagadish, H. V.},
	Booktitle = {Proc. ACM SIGMOD Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Doi = {http://doi.acm.org/10.1145/1007568.1007579},
	Isbn = {1-58113-859-8},
	Keywords = {XML XQuery optimization tree locical classes efficiency},
	Location = {Paris, France},
	Pages = {71--82},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Paparizos.Wu.ea_TreeLogical_SIGMOD_2004.pdf},
	Publisher = {ACM Press},
	Title = {{Tree Logical Classes for Efficient Evaluation of XQuery}},
	Url = {http://www.cs.indiana.edu/~yuqwu/papers/SIGMOD04-TLC.pdf},
	Year = {2004},
	Abstract = {XML is widely praised for its flexibility in allowing
	 repeated and missing sub-elements. However, this flexibility makes it
	 challenging to develop a bulk algebra, which typically manipulates sets
	 of objects with identical structure. A set of XML elements, say of
	 type book, may have members that vary greatly in structure, e.g. in
	 the number of author sub-elements. This kind of heterogeneity may
	 permeate the entire document in a recursive fashion: e.g., different
	 authors of the same or different book may in turn greatly vary in
	 structure. Even when the document conforms to a schema, the flexible
	 nature of schemas for XML still allows such significant variations in
	 structure among elements in a collection. Bulk processing of such
	 heterogeneous sets is problematic.In this paper, we introduce the notion
	 of logical classes (LC) of pattern tree nodes, and generalize the
	 notion of pattern tree matching to handle node logical classes. This
	 abstraction pays off significantly in allowing us to reason with an
	 inherently heterogeneous collection of elements in a uniform, homogeneous
	 way. Based on this, we define a Tree Logical Class (TLC) algebra
	 that is capable of handling the heterogeneity arising in XML query
	 processing, while avoiding redundant work. We present an algorithm
	 to obtain a TLC algebra expression from an XQuery statement (for a
	 large fragment of XQuery). We show how to implement the TLC algebra
	 efficiently, introducing the nest-join as an important physical operator for
	 XML query processing. We show that evaluation plans generated using
	 the TLC algebra not only are simpler but also perform better than
	 those generated by competing approaches. TLC is the algebra used
	 in the Timber [8] system developed at the University of Michigan.}}

@inproceedings{Park.Min.ea_FunInlStrRecXQ_VLDB_2002,
	Author = {Park, Chang-Won and Min, Jun-Ki and Chung, Chin-Wan},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {Proc. Int. Conf. on Very Large Databases},
	Conference-Abbr = {VLDB},
	Ee = {http://www.vldb.org/conf/2002/S04P01.pdf},
	Keywords = {XML XQuery function inlining structurally recursive queries},
	Pages = {83-94},
	Pdf = {QueryEvaluation/XML/Compilation/Park.Min.ea_FunInlStrRecXQ_VLDB_2002.pdf},
	Title = {{Structural Function Inlining Technique for Structurally Recursive XML Queries}},
	Url = {http://www.vldb.org/conf/2002/S04P01.pdf},
	Year = {2002},
	Abstract = {Structurally recursive XML queries are an important query class that follows the
	 structure of XML data. At present, it is difficult for XQuery to type
	 and optimize structurally recursive queries because of polymorphic
	 recursive functions involved in the queries. In this paper, we propose
	 a new technique called structural function inlining which inlines
	 recursive functions used in a query by making good use of available type
	 information. Based on the technique, we develop a new approach to typing and
	 optimizing structurally recursive queries. The new approach yields
	 a more precise result type for a query. Furthermore, it produces
	 an optimal algebraic expression for the query with respect to the
	 type information. When a structurally recursive query is applied to
	 non-recursive XML data, our approach translates the query into a
	 finitely nested iterations. We conducted several experiments with
	 commonly used real-life and synthetic datasets. The experimental
	 results show that the number of node lookups by our approach is on the
	 average 3.7 times and up to 279.8 times smaller than that by the XQuery
	 core?s current approach in evaluating structurally recursive queries.}}

@inproceedings{Pirahesh.Kleewein.ea_SystemRX_SIGMOD_2005,
	Author = {Pirahesh, Mir Hamid and Kleewein, Jim and Cochrane, Roberta J. and Ozcan, Fatma and Beyer, Kevin S. and Josifovski, Vanja and Lapis, George and Lohman, Guy M. and Lyle, Bob and Seemann, Normen and Truong, Tuong and der Linden, Bert Van and Vickery, Brian and Zhang, Chun},
	Booktitle = {Proc. ACM SIGMOD Int Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Keywords = {XML relational database System RX},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Pirahesh.Kleewein.ea_SystemRX_SIGMOD_2005.pdf},
	Title = {{System RX: One Part Relational, One Part XML}},
	Url = {http://www-db.stanford.edu/~widom/cs346/ozcan-paper1.pdf},
	Year = {2005},
	Abstract = {This paper describes the overall
	 architecture and design aspects of a hybrid relational and XML database
	 system called System RX. We believe that such a system is fundamental
	 in the evolution of enterprise data management solutions: XML and
	 relational data will co-exist and complement each other in enterprise
	 solutions. Furthermore, a successful XML repository requires much of the
	 same infrastructure that already exists in a relational database
	 management system. Finally, XML query languages have con-siderable
	 conceptual and functional overlap with relational data-flow engines.
	 System RX is the first truly hybrid system that co-mingles XML and
	 relational data, giving them equal footing. The new support for XML
	 includes native support for storage and indexing as well as query
	 compilation and evaluation support for the latest industry-standard
	 query languages, SQL/XML and XQuery. By building a hybrid system, we
	 leverage more than 20 years of data management research to advance XML
	 technology to the same standards expected from mature relational systems.}}

@inproceedings{Ramanan_MinimizingTreePat_SIGMOD_2002,
	Address = {New York, NY, USA},
	Author = {Ramanan, Prakash},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Doi = {http://doi.acm.org/10.1145/564691.564726},
	Isbn = {1-58113-497-5},
	Keywords = {XML tree patterns minimizing efficient algorithm},
	Location = {Madison, Wisconsin},
	Pages = {299--309},
	Pdf = {QueryEvaluation/XML/Containment/Ramanan_MinimizingTreePat_SIGMOD_2002.pdf},
	Publisher = {ACM Press},
	Title = {{Efficient Algorithms for Minimizing Tree Pattern Queries}},
	Url = {http://www.cs.wichita.edu/~ramanan/PAPERS/querymin.PDF},
	Year = {2002},
	Abstract = {We consider the problem of minimizing tree pattern queries (TPQ) that arise in
	 XML and in LDAP-style network directories. In [Minimization of Tree
	 Pattern Queries, Proc. ACM SIGMOD Intl. Conf. Management of Data, 2001,
	 pp. 497-508], Amer-Yahia, Cho, Lakshmanan and Srivastava presented
	 an O(n4) algorithm for minimizing TPQs in the absence of integrity
	 constraints (Case 1); n is the number of nodes in the query. Then they
	 considered the problem of minimizing TPQs in the presence of three kinds
	 of integrity constraints: required-child, required-descendant and
	 subtype (Case 2). They presented an O(n6) algorithm for minimizing
	 TPQs in the presence of only required-child and required-descendant
	 constraints (i.e., no subtypes allowed; Case 3). We present O(n2),
	 O(n4) and O(n2) algorithms for minimizing TPQs in these three cases,
	 respectively, based on the concept of graph simulation. We believe
	 that our O(n2) algorithms for Cases 1 and 3 are runtime optimal.}}

@inproceedings{Rao.Moon_PRIXIndex_ICDE_2004,
	Author = {Rao, Praveen R. and Moon, Bongki},
	Booktitle = {Proc. Int. Conf. on Data Engineering},
	Conference-Abbr = {ICDE},
	Keywords = {XML PRIX indexing},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/Rao.Moon_PRIXIndex_ICDE_2004.pdf},
	Title = {{PRIX: Indexing and Querying XML Using Prufer Sequences}},
	Url = {http://www.cs.ucr.edu/~tsotras/cs267/prix.pdf},
	Year = {2004},
	Abstract = {We propose a new way of indexing XML
	 documents and processing twig patterns in an XML database. Every
	 XML document in the database can be transformed into a sequence of
	 labels by Pr{\"u}fer?s method that constructs a one-to-one correspondence
	 between trees and sequences. During query processing, a twig pattern is
	 also transformed into its Pr{\"u}fer sequence. By performing subsequence
	 matching on the set of sequences in the database, and performing
	 a series of refinement phases that we have developed, we can find
	 all the occurrences of a twig pattern in the database. Our approach
	 allows holistic processing of a twig pattern without breaking the twig
	 into root-to-leaf paths and processing these paths individually.
	 Furthermore, we show in the paper that all correct answers are found
	 without any false dismissals or false alarms. Experimental results
	 demonstrate the performance benefits of our proposed techniques.}}

@inproceedings{Sahuguet.Alexe_SubdocumentQueries_WWW_2005,
	Address = {New York, NY, USA},
	Author = {Sahuguet, Arnaud and Alexe, Bogdan},
	Booktitle = {Proc. Int. Conf. on World Wide Web},
	Conference-Abbr = {WWW},
	Doi = {http://doi.acm.org/10.1145/1060745.1060787},
	Isbn = {1-59593-046-9},
	Keywords = {XML XQuery sub-documents identity querying},
	Location = {Chiba, Japan},
	Pages = {268--277},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/XQuery/Sahuguet.Alexe_SubdocumentQueries_WWW_2005.pdf},
	Publisher = {ACM Press},
	Title = {{Sub-document Queries over XML with XSQirrel}},
	Url = {http://portal.acm.org/citation.cfm?id=1060787},
	Year = {2005},
	Abstract = {This paper describes XSQirrel, a new XML query language that
	 transforms a document into a sub-document, i.e. a tree where the
	 root-to-leaf paths are a subset of the root-to-leaf paths from the original
	 document.We show that this type of queries is extremely useful for various
	 applications (e.g. web services) and that the currently existing
	 query languages are poorly equipped to express, reason and evaluate
	 such queries. In particular, we emphasize the need to be able to
	 compose such queries. We present the XSQirrel language with its syntax,
	 semantics and two language specific operators, union and composition.For
	 the evaluation of the language, we leverage well established query
	 technologies by translating XSQirrel expressions into XPath programs, XQuery
	 queries or XSLT stylesheets.We provide some experimental results
	 that compare our various evaluation strategies. We also show the
	 runtime benefits of query composition over sequential evaluation.}}

@inproceedings{Schenkel.Theobald.ea_HOPI_EDBT_2004,
	Author = {Schenkel, R. and Theobald, A. and Weikum, G.},
	Booktitle = {Proc. Extending Database Technology},
	Conference-Abbr = {EDBT},
	Date-Added = {2005-05-01 22:42:02 +0200},
	Date-Modified = {2005-05-01 22:43:08 +0200},
	Keywords = {XML indexing graph transitive closure HOPI},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/Schenkel.Theobald.ea_HOPI_EDBT_2004.pdf},
	Title = {{HOPI: An Efficient Connection Index for Complex XML Document Collections}},
	Url = {http://wwwcs.uni-paderborn.de/cs/ag-boettcher/lehre/SS04/seminar/download/edbt04.HOPI.An.Efficient.Connection.Index.for.Complex.XML.Document.Collections.pdf},
	Year = {2004},
	Abstract = {In this paper we present HOPI, a new connection index for
	 XML documents based on the concept of the 2?hop cover of a directed
	 graph introduced by Cohen et al. In contrast to most of the prior
	 work on XML indexing we consider not only paths with child or parent
	 relationships between the nodes, but also provide space? and time?efficient
	 reachability tests along the ancestor, descendant, and link axes to
	 support path expressions with wildcards in our XXL search engine. We
	 improve the theoretical concept of a 2?hop cover by developing scalable
	 methods for index creation on very large XML data collections with long
	 paths and extensive cross?linkage. Our experiments show substantial
	 savings in the query performance of the HOPI index over previously
	 proposed index structures in combination with low space requirements.}}

@inproceedings{Schenkel.Theobald.ea_EfficientHOPI_ICDE_2005,
	Author = {Schenkel, Ralf and Theobald, Anja and Weikum, Gerhard},
	Booktitle = {Proc. Int. Conf. on Data Engineering},
	Conference-Abbr = {ICDE},
	Keywords = {XML indexing HOPI transitive closure},
	Owner = {Tim Furche},
	Pages = {360-371},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/Schenkel.Theobald.ea_EfficientHOPI_ICDE_2005.pdf},
	Title = {{Efficient Creation and Incremental Maintenance of the HOPI Index for Complex XML Document Collections}},
	Url = {http://doi.ieeecomputersociety.org/10.1109/ICDE.2005.57},
	Year = {2005},
	Abstract = {The HOPI index, a connection index for XML documents based on
	 the concept of a 2?hop cover, provides space? and time?efficient
	 reachability tests along the ancestor, descendant, and link axes to support
	 path expressions with wildcards in XML search engines. This paper
	 presents enhanced algorithms for building HOPI, shows how to augment the
	 index with distance information, and discusses incremental index
	 maintenance. Our experiments show substantial improvements over the existing
	 divide-and-conquer algorithm for index creation, low space overhead for
	 including distance information in the index, and efficient updates.}}

@inproceedings{Schott.Noga_LazyXSLT_DocEng_2003,
	Author = {Schott, Steffen and Noga, Markus L.},
	Booktitle = {Proc. ACM Symposium on Document Engineering},
	Conference-Abbr = {DocEng},
	Doi = {http://doi.acm.org/10.1145/958220.958224},
	Isbn = {1-58113-724-9},
	Keywords = {XML XSLT evaluation lazy query languages processing},
	Location = {Grenoble, France},
	Pages = {9--18},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Schott.Noga_LazyXSLT_DocEng_2003.pdf},
	Publisher = {ACM Press},
	Title = {{Lazy XSL Transformations}},
	Url = {http://portal.acm.org/citation.cfm?id=958224},
	Year = {2003},
	Abstract = {We introduce a lazy XSLT interpreter that provides random access to the
	 transformation result. This allows efficient pipelining of transformation
	 sequences. Nodes of the result tree are computed only upon initial access.
	 As these computations have limited fan-in, sparse output coverage
	 propagates backwards through the pipeline.In comparative measurements
	 with traditional eager implementations, our approach is on par for
	 complete coverage and excels as coverage becomes sparser. In contrast to
	 eager evaluation, lazy evaluation also admits infinite intermediate
	 results, thus extending the design space for transformation sequences.To
	 demonstrate that lazy evaluation preserves the semantics of XSLT, we reduce
	 XSLT to the lambda calculus via a functional language. While this is
	 possible for all languages, most imperative languages cannot profit from
	 the confluence of lambda as only one reduction applies at a time.}}

@article{Schwentick_XPathContainment_SIGR_2004,
	Address = {New York, NY, USA},
	Author = {Schwentick, Thomas},
	Date-Modified = {2006-02-01 17:30:30 +0100},
	Doi = {http://doi.acm.org/10.1145/974121.974140},
	Issn = {0163-5808},
	Journal = {SIGMOD Record},
	Journal-Abbr = {SIGR},
	Keywords = {XML XPath query containment query optimization language properties},
	Number = {1},
	Pages = {101--109},
	Pdf = {QueryEvaluation/XML/Containment/Schwentick_XPathContainment_SIGR_2004.pdf},
	Publisher = {ACM Press},
	Title = {{XPath Query Containment}},
	Url = {http://portal.acm.org/citation.cfm?id=974140},
	Volume = {33},
	Year = {2004},
	Abstract = {Consider an XML publish-subscribe scenario with hundreds of subscribers and tens
	 of thousands of XML documents to be delivered per day. Subscribers
	 specify the documents in which they are interested in by means of XPath
	 [8] expressions. If an expression matches a (part of a) document
	 it is delivered to the subscriber. Naturally, it is desired that
	 the decision to which subscriber a document must be sent should be
	 taken quickly. Although the test whether a single XPath expression
	 matches can be done in polynomial time, it is not efficient to test
	 every such expression for every document. Fortunately, there is a
	 partial order on expressions, i.e., for some expressions p; q it might
	 hold that whenever a document matches p it also matches q (denoted
	 p 0 q). If we already know that a document matches p, we do not
	 need to test q anymore, as it matches automatically. Correspond-
	 ingly, if we know that q does not match then p will not match either.
	 Hence, the inclusion structure of the XPath expressions should be
	 computed in advance to decrease online computation time. This leads to
	 the algorithmic problem of XPath Query Containment, i.e., checking
	 whether p 0 q (for a different, index- based approach see, e.g., [6]).}}

@inproceedings{Silberstein.He.ea_BOXesLabel_ICDE_2005,
	Author = {Silberstein, Adam and He, Hao and Yi, Ke and Yang, Jun},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {Proc. Int. Conf. on Data Engineering},
	Conference-Abbr = {ICDE},
	Crossref = {DBLP:conf/icde/2005},
	Ee = {http://csdl.computer.org/comp/proceedings/icde/2005/2285/00/22850285abs.htm},
	Keywords = {XML labeling indexing boxes maintenance},
	Pages = {285-296},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/Silberstein.He.ea_BOXesLabel_ICDE_2005.pdf},
	Title = {{BOXes: Efficient Maintenance of Order-Based Labeling for Dynamic XML Data}},
	Url = {http://www.cs.duke.edu/dbgroup/papers/2005-ICDE-shyy-xmlorder.pdf},
	Year = {2005},
	Abstract = {Order-based element labeling for tree-structured XML
	 data is an important technique in XML processing. It lies at the
	 core of many fundamental XML operations such as containment join
	 and twig matching. While labeling for static XML documents is well
	 understood, less is known about how to maintain accurate labeling for
	 dynamic XML documents, when elements and subtrees are inserted and
	 deleted. Most existing approaches do not work well for arbitrary
	 update patterns; they either produce unacceptably long labels or incur
	 enormous relabeling costs. We present two novel I/O-efficient data
	 structures, W-BOX and B-BOX, that efficiently maintain labeling for large,
	 dynamic XML documents. We show analytically and experimentally that
	 both, despite consuming minimal amounts of storage, gracefully handle
	 arbitrary update patterns without sacrificing lookup efficiency.
	 The two structures together provide a nice tradeoff between update
	 and lookup costs: W-BOX has logarithmic amortized update cost and
	 constant worst-case lookup cost, while B-BOX has constant amortized
	 update cost and logarithmic worst-case lookup cost. We further propose
	 techniques to eliminate the lookup cost for read-heavy workloads.}}

@inproceedings{Stefanescu.Thomo.ea_DistribGPQ_SAC_2005,
	Address = {New York, NY, USA},
	Author = {Stefanescu, Dan C. and Thomo, Alex and Thomo, Lida},
	Booktitle = {Proc. ACM Symposium on Applied Computing},
	Conference-Abbr = {SAC},
	Doi = {http://doi.acm.org/10.1145/1066677.1066819},
	Isbn = {1-58113-964-0},
	Keywords = {XML general path expressions XPath distributed evaluation},
	Location = {Santa Fe, New Mexico},
	Pages = {610--616},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Stefanescu.Thomo.ea_DistribGPQ_SAC_2005.pdf},
	Publisher = {ACM Press},
	Title = {{Distributed Evaluation of Generalized Path Queries}},
	Url = {http://portal.acm.org/citation.cfm?id=1066677.1066819},
	Year = {2005},
	Abstract = {Nowadays, we are required to
	 deal with more complex data, prime examples of which are data on
	 the Web, XML data, biological data, etc. There are already proposed
	 abstractions to handle these kinds of data, in particular in terms of
	 semistructured data models. A semistructured model conceives a database
	 essentially as a finite directed labeled graph whose nodes represent
	 objects, and whose edges represent relationships between objects. In
	 this paper, we focus on path queries, which are considered the basic
	 querying mechanism for semistructured data. In essence, such queries are
	 used to navigate, or discover paths that conform to specifications
	 captured by regular expressions. In order to make the navigation more
	 useful, we consider generalized path queries, in which the symbols
	 could optionally be weighted by numbers. Such numbers can express a
	 variety of information about the data that the query could possibly
	 match or navigate.Motivated by the plethora of today's applications
	 utilizing Web services and peer-to-peer architectures, we present
	 a distributed algorithm for evaluating generalized path queries.
	 We follow a realistic model with distributed (non-shared) memory
	 and message-passing between processors. An optimal solution to the
	 problem lies in the intersection of ideas related to distributed query
	 evaluation, distributed shortest path computation, and queueing systems.}}

@inproceedings{Trombetta.Montesi_EquivalencesXSLT_IDEAS_2004,
	Author = {Trombetta, Alberto and Montesi, Danilo},
	Booktitle = {Proc. Int. Database Engineering and Applications Symposium},
	Conference-Abbr = {IDEAS},
	Keywords = {XML XSLT query languages optimization equivalence},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Containment/Trombetta.Montesi_EquivalencesXSLT_IDEAS_2004.pdf},
	Title = {{Equivalences and Optimizations in an Expressive XSLT Fragment}},
	Url = {http://csdl.computer.org/dl/proceedings/ideas/2004/2168/00/21680171.pdf},
	Year = {2004},
	Abstract = {XML is the standard data interchange
	 format and XSLT is the W3C proposed standard for transforming and
	 restructuring XML documents. It turns out that XSLT has very powerful query
	 capabilities as well. However, due to its complex syntax and lack of formal
	 specification, it is not a trivial task to decide whether two XSLT
	 stylesheets yield the same result, even if for an XSLT fragment. We isolate
	 such fragment, powerful enough for expressing several interesting
	 queries and for manipulating XML documents and show how to translate
	 them into queries expressed in a properly extended version of TAX, a
	 powerful XML query algebra, for which we provide a collection of
	 equivalence rules. It is then possible to reason about XSLT equivalences,
	 by translating XSLT queries into XTAX queries and then statically
	 verifying their equivalence, by means of the mentioned equivalence rules.}}

@inproceedings{Vagena.Moro.ea_TwigGraphs_WebDB_2004,
	Address = {New York, NY, USA},
	Author = {Vagena, Zografoula and Moro, Mirella M. and Tsotras, Vassilis J.},
	Booktitle = {Proc. Int. Workshop on the Web and Databases},
	Conference-Abbr = {WebDB},
	Doi = {http://doi.acm.org/10.1145/1017074.1017087},
	Keywords = {XML twig joins structural joins graph-shaped},
	Location = {Paris, France},
	Pages = {43--48},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/StructuralJoins/Vagena.Moro.ea_TwigGraphs_WebDB_2004.pdf},
	Publisher = {ACM Press},
	Title = {{Twig Query Processing over Graph-Structured XML Data}},
	Url = {http://webdb2004.cs.columbia.edu/papers/4-1.pdf},
	Year = {2004},
	Abstract = {XML and semi-structured data is usually modeled using graph structures.
	 Structural summaries, which have been proposed to speedup XML query
	 processing have graph forms as well. The existent approaches for
	 evaluating queries over tree structured data (i.e. data whose underlying
	 structure is a tree) are not directly applicable when the data is
	 modeled as a random graph. Moreover, they cannot be applied when
	 structural summaries are employed and, to the best of our knowledge, no
	 analogous techniques have been reported for this case either. As a
	 result, the potential of structural summaries is not fully exploited.In
	 this paper, we investigate query evaluation techniques applicable
	 to graph-structured data. We propose efficient algorithms for the
	 case of directed acyclic graphs, which appear in many real world
	 situations. We then tailor our approaches to handle other directed
	 graphs as well. Our experimental evaluation reveals the advantages
	 of our solutions over existing methods for graph-structured data.}}

@inproceedings{Villard.Layaida_IncrementalXSLT_WWW_2002,
	Author = {Villard, Lionel and Laya{\"\i}da, Nabil},
	Booktitle = {Proc. Int. World Wide Web Conf.},
	Conference-Abbr = {WWW},
	Doi = {http://doi.acm.org/10.1145/511446.511508},
	Isbn = {1-58113-449-5},
	Keywords = {XML XSLT incremental query evaluation languages},
	Location = {Honolulu, Hawaii, USA},
	Pages = {474--485},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Villard.Layaida_IncrementalXSLT_WWW_2002.pdf},
	Publisher = {ACM Press},
	Title = {{An Incremental XSLT Transformation Processor for XML Document Manipulation}},
	Url = {http://www.research.ibm.com/people/v/villard/Papiers/incXSLT.pdf},
	Year = {2002},
	Abstract = {In this paper, we present an incremental transformation framework
	 called incXSLT. This framework has been experimented for the XSLT
	 language defined at the World Wide Web Consortium. For the currently
	 available tools, designing the XML content and the transformation
	 sheets is an inefficient, a tedious and an error prone experience.
	 Incremental transformation processors such as incXSLT represent a
	 better alternative to help in the design of both the content and the
	 transformation sheets. We believe that such frameworks are a first step
	 toward fully interactive transformation-based authoring environments.}}

@inproceedings{Wang.Park.ea_ViST_SIGMOD_2003,
	Address = {New York, NY, USA},
	Author = {Wang, Haixun and Park, Sanghyun and Fan, Wei and Yu, Philip S.},
	Booktitle = {Proc. of ACM SIGMOD Int. Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Doi = {http://doi.acm.org/10.1145/872757.872774},
	Isbn = {1-58113-634-X},
	Keywords = {XML indexing dynamic ViST query optimization labeling},
	Location = {San Diego, California},
	Pages = {110--121},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/Wang.Park.ea_ViST_SIGMOD_2003.pdf},
	Publisher = {ACM Press},
	Title = {{ViST: A Dynamic Index Method for Querying XML Data by Tree Structures}},
	Url = {http://www.cs.ucr.edu/~tsotras/cs267/vist.pdf},
	Year = {2003},
	Abstract = {With the growing importance of XML in data exchange, much research has been
	 done in providing flexible query facilities to extract data from
	 structured XML documents. In this paper, we propose ViST, a novel
	 index structure for searching XML documents. By representing both
	 XML documents and XML queries in structure-encoded sequences, we
	 show that querying XML data is equivalent to finding subsequence
	 matches. Unlike index methods that disassemble a query into multiple
	 sub-queries, and then join the results of these sub-queries to provide the
	 final answers, ViST uses tree structures as the basic unit of query
	 to avoid expensive join operations. Furthermore, ViST provides a
	 unified index on both content and structure of the XML documents, hence
	 it has a performance advantage over methods indexing either just
	 content or structure. ViST supports dynamic index update, and it relies
	 solely on B+ Trees without using any specialized data structures that
	 are not well supported by DBMSs. Our experiments show that ViST is
	 effective, scalable, and efficient in supporting structural queries.}}

@inproceedings{Weigel.Meuss.ea_ContentStructureIDX_WebDB_2004,
	Address = {New York, NY, USA},
	Author = {Weigel, Felix and Meuss, Holger and Schulz, Klaus U. and Bry, Fran\c{c}ois},
	Booktitle = {Proc. Int. Workshop on the Web and Databases},
	Conference-Abbr = {WebDB},
	Doi = {http://doi.acm.org/10.1145/1017074.1017092},
	Keywords = {XML indexing content index path index},
	Location = {Paris, France},
	Pages = {67--72},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/Weigel.Meuss.ea_ContentStructureIDX_WebDB_2004.pdf},
	Publisher = {ACM Press},
	Title = {{Content and Structure in Indexing and Ranking XML}},
	Url = {http://portal.acm.org/citation.cfm?id=1017092},
	Year = {2004},
	Abstract = {Rooted in electronic publishing,
	 XML is now widely used for modelling and storing structured text
	 documents. Especially in the WWW, retrieval of XML documents is most
	 useful in combination with a relevance-based ranking of the query
	 result. Index structures with ranking support are therefore needed
	 for fast access to relevant parts of large document collections.
	 This paper proposes a classification scheme for both XML ranking
	 models and index structures, allowing to determine which index suits
	 which ranking model. An analysis reveals that ranking parameters
	 related to both the content and structure of the data are poorly
	 supported by most known XML indices. The IR-CADG index, owing to its
	 tight integration of content and structure, supports various XML
	 ranking models in a very efficient retrieval process. Experiments show
	 that it outperforms separate content/structure indexing by more than
	 two orders of magnitude for large corpora of several hundred MB.}}

@inproceedings{Wu.Patel.ea_StructuralJoinOrder_ICDE_2003,
	Author = {Wu, Yuqing and Patel, Jignesh M. and Jagadish, H. V.},
	Booktitle = {Proc. Int. Conf. on Data Engineering},
	Conference-Abbr = {ICDE},
	Keywords = {XML operators structural join query plan query optimization},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/StructuralJoins/Wu.Patel.ea_StructuralJoinOrder_ICDE_2003.pdf},
	Title = {{Structural Join Order Selection for XML Query Optimization}},
	Url = {http://csdl.computer.org/dl/proceedings/icde/2003/2071/00/20710443.pdf},
	Year = {2003},
	Abstract = {Structural join operations are central to
	 evaluating queries against XML data, and are typically responsible
	 for consuming a lion?s share of the query processing time. Thus,
	 structural join order selection is at the heart of query optimization
	 in an XML database, just as (value-based) join order selection is
	 central to relational query optimization. In this paper, we introduce
	 five algorithms for structural join order optimization for XML tree
	 pattern matching and present an extensive experimental evaluation. Our
	 experiments demonstrate that many relational rules of thumb are no longer
	 appropriate: for instance, using dynamic programming style optimization is
	 not efficient; limiting consideration to left-deep plans usually
	 misses the best solution. Our experiments also show that a Dynamic
	 Programming optimization with Pruning (DPP) algorithm can find the
	 optimal solution, with low cost relative to the traditional Dynamic
	 Programming (DP) algorithm; and an optimization technique that only
	 considers Fully Pipelined (FP) plans can very quickly choose a plan that
	 in most cases is close to optimal. Our recommendation is that DPP
	 should be used in XML query optimizers where query execution time is
	 expected to be significant, and that FP should be used where it is
	 important to find a good (but not necessarily the best) plan quickly.}}

@inproceedings{Yang.Fontoura.ea_VirtualCursorsXML_CIKM_2004,
	Address = {New York, NY, USA},
	Author = {Yang, Beverly and Fontoura, Marcus and Shekita, Eugene and Rajagopalan, Sridhar and Beyer, Kevin},
	Booktitle = {Proc. Conf. on Information and Knowledge Management},
	Conference-Abbr = {CIKM},
	Doi = {http://doi.acm.org/10.1145/1031171.1031271},
	Isbn = {1-58113-874-1},
	Keywords = {XML structural joins twig joins cursors query processing},
	Location = {Washington, D.C., USA},
	Pages = {523--532},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/StructuralJoins/Yang.Fontoura.ea_VirtualCursorsXML_CIKM_2004.pdf},
	Publisher = {ACM Press},
	Title = {{Virtual Cursors for XML Joins}},
	Url = {http://portal.acm.org/citation.cfm?id=1031271},
	Year = {2004},
	Abstract = {Structural joins are a fundamental operation in XML
	 query processing and a large body of work has focused on index-based
	 algorithms for executing them. In this paper, we describe how two
	 well-known index features -- path indices and ancestor information -- can
	 be combined in a novel way to replace one or more of the physical
	 index cursors in a structural join with <i>virtual cursors</i>. The
	 position of a virtual cursor is derived from the path and ancestor
	 information of a physical cursor. Implementation results are provided to
	 show that, by eliminating index I/O, virtual cursors can improve the
	 performance of structural joins by an order of magnitude or more.}}

@inproceedings{Zhang.Ozsu.ea_NextOfKin_ICDE_2003,
	Author = {Zhang, Ning and Ozsu, M. Tamer and Kacholia, Varun},
	Booktitle = {Proc. Int. Conf. on Data Engineering},
	Conference-Abbr = {ICDE},
	Keywords = {XML next-of-kin indexing storage},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/Zhang.Ozsu.ea_NextOfKin_ICDE_2003.pdf},
	Title = {{A Succinct Physical Storage Scheme for Single-Pass Evaluation of Next-of-Kin Path Queries in XML}},
	Url = {http://db.uwaterloo.ca/~ddbms/publications/xml/icde04_storage_NoK.pdf},
	Year = {2003},
	Abstract = {Path expressions are ubiquitous in XML processing languages.
	 Existing approaches evaluate a path expression by selecting nodes that
	 satisfies the tag-name and value constraints and then joining them
	 according to the structural constraints. In this paper, we propose a
	 novel approach, next-of-kin (NoK) pattern matching, to speed up the
	 nodeselection step, and to reduce the join size significantly in the second
	 step. To efficiently perform NoK pattern matching, we also propose a
	 succinct XML physical storage scheme that is adaptive to updates
	 and streaming XML as well. Our performance results demonstrate that
	 the proposed storage scheme and path evaluation algorithm is highly
	 efficient and outperforms the other tested systems in most cases.}}

@inproceedings{Zhang.Dimitrova.ea_RainbowMultiQs_SIGMOD_2003,
	Author = {Zhang, Xin and Dimitrova, Katica and Wang, Ling and Sayed, Maged El and Murphy, Brian and Pielech, Bradford and Mulchandani, Mukesh and Ding, Luping and Rundensteiner, Elke A.},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Doi = {http://doi.acm.org/10.1145/872757.872861},
	Isbn = {1-58113-634-X},
	Keywords = {XML XQuery view-based query optimization evalution processing},
	Location = {San Diego, California},
	Pages = {671--671},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Zhang.Dimitrova.ea_RainbowMultiQs_SIGMOD_2003.pdf},
	Publisher = {ACM Press},
	Title = {{Rainbow: multi-XQuery Optimization using Materialized XML Views}},
	Url = {http://www.cs.wpi.edu/~lisading/docs/demo.pdf},
	Year = {2003},
	Abstract = {We present multiple XQuery optimization based on
	 materialized XML view technology in the Rainbow system. In this demo we in
	 particular show: (1) Rainbow?s support for defining and incrementally
	 maintaining materialized XQuery views, (2) XQuery optimization by
	 query rewriting to use materialized views, (3) Performing multiple
	 query optimization by merging multiple XML queries (XATs) into one
	 global access plan to decide upon materialization of intermediate
	 results as views, and (4) Query processing of updates issued on XML
	 views that wrap relational data by decomposing the updates into SQL
	 update statements and consistency checks on the relational base data.}}

@inproceedings{Zhang.Pielech.ea_HoneyIShrunkXAT_WIDM_2002,
	Author = {Zhang, Xin and Pielech, Bradford and Rundesnteiner, Elke A.},
	Booktitle = {Proc. International Workshop on Web Information and Data Management},
	Conference-Abbr = {WIDM},
	Doi = {http://doi.acm.org/10.1145/584931.584936},
	Isbn = {1-58113-593-9},
	Keywords = {XML XQuery XAT algebraic optimization XML SQL rewriting optimization},
	Location = {McLean, Virginia, USA},
	Pages = {15--22},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Zhang.Pielech.ea_HoneyIShrunkXAT_WIDM_2002.pdf},
	Publisher = {ACM Press},
	Title = {{Honey, I shrunk the XQuery!: an XML Algebra Optimization Approach}},
	Url = {http://portal.acm.org/citation.cfm?id=584936},
	Year = {2002},
	Abstract = {A lot of work is being done in the database community on mapping of XML data
	 into and out of relational database systems, specifically, the query
	 processing over such data using XQuery. We discuss our solution, the XML
	 Algebra Tree (XAT), as part of our larger XML management system called
	 Rainbow.Rainbow uses XQuery to describe the loading and extracting of XML
	 data into relational systems and also for the execution of queries
	 against pre-defined XML views of that stored data. The XML algebra tree
	 of the query against those views is merged with the queries that
	 define the views to form a larger tree. Because the XML formatting
	 operators are interleaved with the computation operators, this XAT
	 must then be optimized before being translated into one or more SQL
	 statements that can be executed on the database. SQL translation is
	 composed of computation pushdown and SQL generation.The computation
	 pushdown splits the tree into the XML-specific and SQL-doable operators,
	 which is then going to be converted into SQL statements. However, the
	 XAT after computation pushdown may contain unreferenced columns or
	 unused operators. Leaving these operators in the tree will create
	 unnecessarily large SQL statements and will slow down the overall
	 execution.Our main contributions to XML query processing, outlined in
	 this paper, are threefold. One, we describe an algebra based on XATs
	 for modeling XQuery expressions. Two, we propose rewriting rules to
	 optimize XQueries by XAT operator cancel out. Lastly, we show a cutting
	 algorithm to remove unreferenced columns and operators from the trees. We
	 have fully implemented the techniques discussed in this paper in
	 the Rainbow system. A preliminary experimental study compares the
	 performance of execution before and after operator cancel out and cutting.}}

@inproceedings{Gottlob.Koch_MonadicQsTree_LICS_2002,
	Author = {Gottlob, Georg and Koch, Christoph},
	Booktitle = {Proc. Annual IEEE Symposium on Logic in Computer Science},
	Conference-Abbr = {LICS},
	Date-Modified = {2006-02-01 17:38:32 +0100},
	Group = {Matrix Method},
	Isbn = {0-7695-1483-9},
	Keywords = {XML monadic datalog query languages complexity semantics tree queries},
	Pages = {189--202},
	Pdf = {QueryEvaluation/XML/Comlexity/Gottlob.Koch_MonadicQsTree_LICS_2002.pdf},
	Publisher = {IEEE Computer Society},
	Title = {{Monadic Queries over Tree-Structured Data}},
	Url = {http://www.dbai.tuwien.ac.at/proj/games/papers/lics2002.pdf},
	Year = {2002},
	Abstract = {Monadic query languages over trees currently receive considerable interest in the database community, as the problem of selecting nodes from a tree is the most basic and widespread database query problem in the context of XML. Partly a survey of recent work done by the authors and their group on logical query languages for this problem and their expressiveness, this paper provides a number of new results related to the complexity of such languages over so-called axis relations (such as ?child? or ?descendant?) which are motivated by their presence in the XPath standard or by their utility for data extraction (wrapping).}}

@article{Gottlob.Koch.ea_EfficientXPath_TODS_2005,
	Author = {Gottlob, Georg and Koch, Christoph and Pichler, Reinhard},
	Date-Modified = {2006-02-01 17:38:47 +0100},
	Group = {Matrix Method},
	Journal = {ACM Transactions on Database Systems},
	Journal-Abbr = {TODS},
	Keywords = {XML XPath efficient processing complexity},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Comlexity/Gottlob.Koch.ea_EfficientXPath_TODS_2005.pdf},
	Title = {{Efficient Algorithms for Processing XPath Queries}},
	Url = {http://www.infosys.uni-sb.de/~koch/download/tods1.pdf},
	Year = {2005},
	Abstract = {Our experimental analysis of several popular XPath processors reveals a striking fact: Query evaluation in each of the systems requires time exponential in the size of queries in the worst case. We show that XPath can be processed much more e ciently, and propose main-memory algorithms for this problem with polynomial-time combined query evaluation complexity. Moreover, we show how the main ideas of our algorithm can be pro tably integrated into existing XPath processors. Finally, we present two fragments of XPath for which linear-time query processing algorithms exist and another fragment with linear-space/quadratic-time query processing.}}

@inproceedings{Libkin_LogicTrees_ICALP2005,
	Author = {Libkin, Leonid},
	Booktitle = {Proc. Intl. Colloquium on Automata, Languages and Programming},
	Date-Added = {2006-02-01 17:23:06 +0100},
	Date-Modified = {2006-02-01 17:31:59 +0100},
	Group = {Matrix Method},
	Pages = {35--50},
	Title = {{Logics over Unranked Trees: An Overview}},
	Url = {http://www.cs.toronto.edu/~libkin/papers/icalp05.ps.gz},
	Year = {2005},
	Abstract = {Labeled unranked trees are used as a model of XML documents, and logical languages for them 
have been studied actively over the past several years. Such logics have different purposes: some 
are better suited for extracting data, some for expressing navigational properties, and some make 
it easy to relate complex properties of trees to the existence of tree automata for those properties. 
Furthermore, logics differ significantly in their model-checking properties, their automata models, 
and their behavior on ordered and unordered trees. In this paper we present a survey of logics for 
unranked trees.}}

@techreport{Furche_Syntax_DEL2006,
	Author = {Furche, Tim and Bry, Francois and Schaffert, Sebastian},
	Date-Added = {2006-02-01 16:35:40 +0100},
	Date-Modified = {2006-03-06 17:50:51 +0100},
	Institution = {REWERSE},
	Keywords = {XML Xcerpt syntax revision},
	Number = {I4-D6},
	Title = {{Initial Draft of a Language Syntax}},
	Type = {Deliverable},
	Url = {http://rewerse.net/publications.html#REWERSE-DEL-2006-I4-D6},
	Year = {2006}}

@article{Courcelle_InfiniteTrees_TCS1983,
	Author = {Courcelle, Bruno},
	Date-Added = {2006-01-31 18:21:38 +0100},
	Date-Modified = {2006-01-31 18:23:09 +0100},
	Journal = {Theoretical Computer Science},
	Keywords = {infinite trees data model references value identity},
	Pages = {95--169},
	Publisher = {Elsevier Science Publishers Ltd.},
	Title = {{Fundamental Properties of Infinite Trees.}},
	Volume = {25},
	Year = {1983},
	Abstract = {Infinite trees naturally arise in the formaliration and the c~udy of fhc \cm;lntic*, 01 
prog-amming languages. This paper investigates some of their i:omninatorial and :iIgcbri\ic 
propei ties that are especially relevant to semantics. 
This paper is concerned in particular with regtilar and algchraic itlfinitc trees, rlor ln.ith rzg\lI;lr 
or algebraic s4f.s of infinite trees. For this reason moss of the propertics s~atcd in rhi$ IVOIX 
become trivial when restricted either to tinite trees or to infinite words. 
It present:, a synthesis of various aspects of infinite trees, invcstigatcd bc diIlt*ic*nt ,tuthor\ III 
differenr contlbxts and hopes to he a unifying step towards a theor! of infinite trct.4 tlliit coultl 
take place near the theory of formal languages and the combina:,:r::c of tk* free monoi,., }}

@article{Codd_ExtendingRelationalModel_TODS1979,
	Address = {New York, NY, USA},
	Author = {Codd, Edgar F.},
	Date-Added = {2006-01-30 21:34:11 +0100},
	Date-Modified = {2006-01-30 21:39:49 +0100},
	Doi = {http://doi.acm.org/10.1145/320107.320109},
	Issn = {0362-5915},
	Journal = {ACM Transactions on Database Systems},
	Keywords = {RDBMS model surrogates identity},
	Number = {4},
	Pages = {397--434},
	Publisher = {ACM Press},
	Title = {{Extending the Database Relational Model to Capture more Meaning}},
	Url = {http://portal.acm.org/citation.cfm?id=320109},
	Volume = {4},
	Year = {1979},
	Abstract = {During the last three or four years several investigators have been exploring ``semantic models'' for formatted databases. The intent is to capture (in a more or less formal way) more of the meaning of the data so that database design can become more systematic and the database system itself can behave more intelligently. Two major thrusts are clear. (1) the search for meaningful units that are as small as possible---atomic semantics; (2) the search for meaningful units that are larger than the usual n-ary relation---molecular semantics. In this paper we propose extensions to the relational model to support certain atomic and molecular semantics. These extensions represent a synthesis of many ideas from the published work in semantic modeling plus the introduction of new rules for insertion, update, and deletion, as well as new algebraic operators.}}

@article{Kuper_LogicalDataModel_TODS1993,
	Address = {New York, NY, USA},
	Author = {Kuper, Gabriel M. and Vardi, Moshe Y.},
	Date-Added = {2006-01-30 10:00:50 +0100},
	Date-Modified = {2006-01-30 10:01:41 +0100},
	Doi = {http://doi.acm.org/10.1145/155271.155274},
	Issn = {0362-5915},
	Journal = {ACM Transactions on Database Systems},
	Keywords = {object identity logic graphs},
	Number = {3},
	Pages = {379--413},
	Publisher = {ACM Press},
	Title = {{The Logical Data Model}},
	Url = {http://portal.acm.org/citation.cfm?id=155274},
	Volume = {18},
	Year = {1993},
	Abstract = {We propose an object-oriented data model that generalizes the relational, hierarchical, and network models. A database scheme in this model is a directed graph, whose leaves represent data and whose internal nodes represent connections among the data. Instances are constructed from objects, which have separate names and values. We define a logic for the model, and describe a nonprocedural query language that is based on the logic. We also describe an algebraic query language and show that it is equivalent to the logical language.}}

@book{Fowler_Plato_HUP1977,
	Author = {Plato},
	Date-Added = {2006-01-29 22:53:53 +0100},
	Date-Modified = {2006-01-29 22:56:03 +0100},
	Editor = {Harold N. Fowler (transl.)},
	Publisher = {Harvard University Press},
	Title = {{Plato in Twelve Volumes}},
	Volume = {9},
	Year = {1977}}

@inproceedings{Grefen_MultiSetAlgebra_ICDE1994,
	Address = {Washington, DC, USA},
	Author = {Grefen, Paul W. P. J. and de By, Rolf A.},
	Booktitle = {Proc. Intl. Conf. on Data Engineering},
	Date-Added = {2006-01-29 15:10:50 +0100},
	Date-Modified = {2006-01-29 15:12:39 +0100},
	Isbn = {0-8186-5400-7},
	Keywords = {bags relational algebra optimization duplicates},
	Pages = {80--88},
	Publisher = {IEEE Computer Society},
	Title = {{A Multi-Set Extended Relational Algebra---A Formal Approach to a Practical Issue}},
	Year = {1994},
	Abstract = {The relational data model is based on sets of tuples, i.e. it does not allow duplicate tuples in a relation. Many database languages and systems do require multi-set semantics though, either because of functional requirements or because of the high costs of duplicate removal in database operations. Several proposals have been presented that discuss multi-set semantics. As these proposals tend to be either rather practical, lacking the formal background, or rather formal, lacking the connection...}}

@article{Ceri_Gottlob_Datalog_TKDE1989,
	Address = {Piscataway, NJ, USA},
	Author = {Ceri, Stefano and Gottlob, Georg and Tanca, Letizia},
	Date-Added = {2006-01-29 13:48:10 +0100},
	Date-Modified = {2006-01-29 13:50:20 +0100},
	Doi = {http://dx.doi.org/10.1109/69.43410},
	Issn = {1041-4347},
	Journal = {IEEE Transactions on Knowledge and Data Engineering},
	Keywords = {Datalog Prolog logic programming},
	Number = {1},
	Pages = {146--166},
	Publisher = {IEEE Educational Activities Department},
	Title = {{What You Always Wanted to Know About Datalog (And Never Dared to Ask)}},
	Url = {http://doi.ieeecomputersociety.org/10.1109/69.43410},
	Volume = {1},
	Year = {1989},
	Abstract = {Datalog, a database query language based on the logic programming paradigm, is described. The syntax and semantics of Datalog and its use for querying a relational database are presented. Optimization methods for achieving efficient evaluations of Datalog queries are classified, and the most relevant methods are presented. Various improvements of Datalog currently under study are discussed, and what is still needed in order to extend Datalog's applicability to the solution of real-life problems is indicated.}}

@article{Libkin_QLBagsAggregate_JCSS1997,
	Address = {Orlando, FL, USA},
	Author = {Libkin, Leonid and Wong, Limsoon},
	Date-Added = {2006-01-29 13:35:48 +0100},
	Date-Modified = {2006-01-29 14:48:48 +0100},
	Doi = {http://dx.doi.org/10.1006/jcss.1997.1523},
	Issn = {0022-0000},
	Journal = {Journal of Computer and System Sciences},
	Keywords = {bags aggregation algebra query languages duplicates},
	Number = {2},
	Pages = {241--272},
	Publisher = {Academic Press, Inc.},
	Title = {{Query Languages for Bags and Aggregate Functions}},
	Url = {http://citeseer.ist.psu.edu/libkin97query.html},
	Volume = {55},
	Year = {1997},
	Abstract = {Theoretical foundations for querying databases based on bags are studied in this paper. We fully determine the strength of many polynomial-time bag operators relative to an ambient query language. Then we obtain BQL, a query language for bags, by picking the strongest combination of these operators. The relationship between the nested relational algebra and various fragments of BQL is investigated. The precise amount of extra power that BQL possesses over the nested relational algebra is...}}

@inproceedings{Grumbach_AlgebraBags_PODS1993,
	Author = {Grumbach, St{\'e}phane and Milo, Tova},
	Booktitle = {Proc. ACM Symposium on Principles of Database Systems},
	Date-Added = {2006-01-29 04:58:42 +0100},
	Date-Modified = {2006-01-29 05:00:50 +0100},
	Keywords = {Bags algebra duplicate optimization},
	Organization = {ACM Press},
	Pages = {49--58},
	Title = {{Towards Tractable Algebras for Bags}},
	Url = {http://portal.acm.org/citation.cfm?id=153855},
	Year = {1993},
	Abstract = {Bags, i.e. sets with duplicates, are often used to implement relations in database systems. In this paper we study the expressive power of algebras for manipulating bags. The algebra we present is a simple extension of the nested relation algebra. Our aim is to investigate how the use of bags in the language extends its expressive power, and increases its complexity. We consider two main issues, namely (i) the relationship between the depth of bag nesting and the expressive power, and (ii) the relationship between the algebraic operations, and their complexity and expressive power. We show that the bag algebra is more expressive than the nested relation algebra (at all levels of nesting), and that the difference may be subtle. We establish a hierarchy based on the structure of algebra expressions. This hierarchy is shown to be highly related to the properties of the powerset operator.}}

@inproceedings{Khoshafian_ObjectIdentity_OOPSLA1986,
	Address = {New York, NY, USA},
	Author = {Khoshafian, Setrag N. and Copeland, George P.},
	Booktitle = {Proc. Intl. Conf. on Object-oriented Programming Systems, Languages and Applications},
	Date-Added = {2006-01-29 04:55:34 +0100},
	Date-Modified = {2006-01-29 05:02:07 +0100},
	Doi = {http://doi.acm.org/10.1145/28697.28739},
	Isbn = {0-89791-204-7},
	Keywords = {OODBMS object identity duplicates object sharing},
	Location = {Portland, Oregon, United States},
	Pages = {406--416},
	Publisher = {ACM Press},
	Title = {{Object Identity}},
	Url = {http://portal.acm.org/citation.cfm?id=28739},
	Year = {1986},
	Abstract = {Identity is that property of an object which distinguishes each object from all others. Identity has been investigated almost independently in general-purpose programming languages and database languages. Its importance is growing as these two environments evolve and merge.We describe a continuum between weak and strong support of identity, and argue for the incorporation of the strong notion of identity at the conceptual level in languages for general purpose programming, database systems and their hybrids. We define a data model that can directly describe complex objects, and show that identity can easily be incorporated in it. Finally, we compare different implementation schemes for identity and argue that a surrogate-based implementation scheme is needed to support the strong notion of identity.}}

@article{Abiteboul_ObjectIdentityQL_JACM1998,
	Address = {New York, NY, USA},
	Author = {Abiteboul, Serge and Kanellakis, Paris C.},
	Date-Added = {2006-01-29 04:53:52 +0100},
	Date-Modified = {2006-01-30 03:58:55 +0100},
	Doi = {http://doi.acm.org/10.1145/290179.290182},
	Issn = {0004-5411},
	Journal = {Journal of the ACM},
	Keywords = {identity query languages object sharing cycles},
	Number = {5},
	Pages = {798--842},
	Publisher = {ACM Press},
	Title = {{Object Identity as a Query Language Primitive}},
	Url = {http://portal.acm.org/citation.cfm?id=290182},
	Volume = {45},
	Year = {1998},
	Abstract = {We demonstrate the power of object identities (oids) as a database query language primitive. We develop an object-based data model, whose structural part generalizes most of the known complex-object data models: cyclicity is allowed in both its schemas and instances. Our main contribution is the operational part of the data model, the query language IQL, which uses oids for three critical purposes: (1) to represent data-structures with sharing and cycles, (2) to manipulate sets, and (3) to express any computable database query. IQL can be type checked, can be evaluated bottom-up, and naturally generalizes most popular rule-based languages. The model can also be extended to incorporate type inheritance, without changes to IQL. Finally, we investigate an analogous value-based data model, whose structural part is founded on regular infinte trees and whose operational part is IQL.}}

@inproceedings{Paparizos_TreeAlgebrasSetSequence_VLDB2005,
	Author = {Paparizos, Stelios and Jagadish, H. V.},
	Booktitle = {Proc. Intl. Conf. on Very Large Data Bases},
	Date-Added = {2006-01-29 04:49:55 +0100},
	Date-Modified = {2006-01-29 04:52:41 +0100},
	Isbn = {1-59593-154-6},
	Keywords = {XML algebra order identity pattern matching query optimization},
	Location = {Trondheim, Norway},
	Pages = {349--360},
	Publisher = {VLDB Endowment},
	Title = {{Pattern Tree Algebras: Sets or Sequences?}},
	Url = {http://portal.acm.org/citation.cfm?id=1083635},
	Year = {2005},
	Abstract = {XML and XQuery semantics are very sensitive to the order of the produced output. Although pattern-tree based algebraic approaches are becoming more and more popular for evaluating XML, there is no universally accepted technique which can guarantee both a correct output order and a choice of efficient alternative plans.We address the problem using hybrid collections of trees that can be either sets or sequences or something in between. Each such collection is coupled with an Ordering Specification that describes how the trees are sorted (full, partial or no order). This provides us with a formal basis for developing a query plan having parts that maintain no order and parts with partial or full order.It turns out that duplicate elimination introduces some of the same issues as order maintenance: it is expensive and a single collection type does not always provide all the flexibility required to optimize this properly. To solve this problem we associate with each hybrid collection a Duplicate Specification that describes the presence or absence of duplicate elements in it. We show how to extend an existing bulk tree algebra, TLC [12], to use Ordering and Duplicate specifications and produce correctly ordered results. We also suggest some optimizations enabled by the flexibility of our approach, and experimentally demonstrate the performance increase due to them.}}

@incollection{Atkinson_ea_OOManifesto_MK1992,
	Address = {San Francisco, CA, USA},
	Author = {Atkinson, Malcolm and DeWitt, David and Maier, David and Bancilhon, Fran{\c c}ois and Dittrich, Klaus and Zdonik, Stanley},
	Booktitle = {{Building an Object-oriented Database System: The Story of O2}},
	Chapter = {1},
	Date-Added = {2006-01-29 04:44:06 +0100},
	Date-Modified = {2006-01-29 04:49:53 +0100},
	Editor = {Fran{\c c}ois Bancilhon and Claude Delobel and Paris Kanellakis},
	Isbn = {1-55860-169-4},
	Keywords = {OODBMS object identity principles},
	Pages = {1--20},
	Publisher = {Morgan Kaufmann Publishers Inc.},
	Series = {Morgan Kaufmann Series In Data Management Systems},
	Title = {{The Object-oriented Database System Manifesto}},
	Url = {http://www.cs.cmu.edu/People/clamen/OODBMS/Manifesto/htManifesto/Manifesto.html},
	Year = {1992},
	Abstract = {This paper attempts to define an object-oriented database system. It describes the main features and characteristics that a system must have to qualify as an object-oriented database system.
We have separated these characteristics into three groups:

Mandatory, the ones the system must satisfy in order to be termed an object-oriented database system. These are complex objects, object identity, encapsulation, types or classes, inheritance, overriding combined with late binding, extensibility, computational completeness, persistence, secondary storage management, concurrency, recovery and an ad hoc query facility.

Optional, the ones that can be added to make the system better, but which are not mandatory. These are multiple inheritance, type checking and inferencing, distribution, design transactions and versions.

Open, the points where the designer can make a number of choices. These are the programming paradigm, the representation system, the type system, and uniformity.
We have taken a position, not so much expecting it to be the final word as to erect a provisional landmark to orient further debate.}}

@article{Stonebraker_ea_INGRES_TODS1976,
	Address = {New York, NY, USA},
	Author = {Stonebraker, Michael and Held, Gerald and Wong, Eugene and Kreps, Peter},
	Date-Added = {2006-01-29 00:53:42 +0100},
	Date-Modified = {2006-01-29 00:56:22 +0100},
	Doi = {http://doi.acm.org/10.1145/320473.320476},
	Issn = {0362-5915},
	Journal = {ACM Transactions on Database Systems},
	Keywords = {RDBMS QUEL query language relational INGRES duplicates},
	Number = {3},
	Pages = {189--222},
	Publisher = {ACM Press},
	Title = {{The Design and Implementation of INGRES}},
	Url = {http://portal.acm.org/citation.cfm?id=320476},
	Volume = {1},
	Year = {1976},
	Abstract = {The currently operational (March 1976) version of the INGRES database management system is described. This multiuser system gives a relational view of data, supports two high level nonprocedural data sublanguages, and runs as a collection of user processes on top of the UNIX operating system for Digital Equipment Corporation PDP 11/40, 11/45, and 11/70 computers. Emphasis is on the design decisions and tradeoffs related to (1) structuring the system into processes, (2) embedding one command language in a general purpose programming language, (3) the algorithms implemented to process interactions, (4) the access methods implemented, (5) the concurrency and recovery control currently provided, and (6) the data structures used for system catalogs and the role of the database administrator. Also discussed are (1) support for integrity constraints (which is only partly operational), (2) the not yet supported features concerning views and protection, and (3) future plans concerning the system.}}

@article{Astrahan_ea_SystemR_TODS1976,
	Address = {New York, NY, USA},
	Author = {Astrahan, M. M. and Blasgen, M. W. and Chamberlin, D. D. and Eswaran, K. P. and Gray, J. N. and Griffiths, P. P. and King, W. F. and Lorie, R. A. and McJones, P. R. and Mehl, J. W. and Putzolu, G. R. and Traiger, I. L. and Wade, B. W. and Watson, V.},
	Date-Added = {2006-01-29 00:51:24 +0100},
	Date-Modified = {2006-01-29 00:55:45 +0100},
	Doi = {http://doi.acm.org/10.1145/320455.320457},
	Issn = {0362-5915},
	Journal = {ACM Transactions on Database Systems},
	Keywords = {RDBMS SQL SystemR query language duplicates},
	Number = {2},
	Pages = {97--137},
	Publisher = {ACM Press},
	Title = {{System R: Relational Approach to Database Management}},
	Url = {http://portal.acm.org/citation.cfm?id=320457},
	Volume = {1},
	Year = {1976},
	Abstract = {System R is a database management system which provides a high level relational data interface. The systems provides a high level of data independence by isolating the end user as much as possible from underlying storage structures. The system permits definition of a variety of relational views on common underlying data. Data control features are provided, including authorization, integrity assertions, triggered transactions, a logging and recovery subsystem, and facilities for maintaining data consistency in a shared-update environment. This paper contains a description of the overall architecture and design of the system. At the present time the system is being implemented and the design evaluated. We emphasize that System R is a vehicle for research in database architecture, and is not planned as a product.}}

@inproceedings{Warren_ea_Prolog_AIPL1977,
	Author = {Warren, David H. D. and Pereira, Luis M. and Pereira, Fernando},
	Booktitle = {Proc. Symposium on Artificial Intelligence and Programming Languages},
	Date-Added = {2006-01-28 04:48:39 +0100},
	Date-Modified = {2006-01-28 04:50:26 +0100},
	Keywords = {Prolog programming language logic programming bags sets},
	Pages = {109--115},
	Title = {{Prolog - the Language and its Implementation compared with Lisp}},
	Url = {http://portal.acm.org/citation.cfm?id=806939},
	Year = {1977},
	Abstract = {Prolog is a simple but powerful programming language founded on symbolic logic. The basic computational mechanism is a pattern matching process (``unification'') operating on general record structures (``terms'' of logic). We briefly review the language and compare it especially with pure Lisp. The remainder of the paper discusses techniques for implementing Prolog efficiently; in particular we describe how to compile the patterns involved in the matching process. These techniques are as incorporated in our DECsystem-10 Prolog compiler (written in Prolog). The code it generates is comparable in speed with that produced by existing DEC10 Lisp compilers. We argue that pattern matching is a better method for expressing operations on structured data than conventional selectors and constructors - both for the user and for the implementor.}}

@article{Shipman_DAPLEX_TODS1981,
	Address = {New York, NY, USA},
	Author = {Shipman, David W.},
	Date-Added = {2006-01-28 04:42:24 +0100},
	Date-Modified = {2006-01-28 04:43:49 +0100},
	Doi = {http://doi.acm.org/10.1145/319540.319561},
	Issn = {0362-5915},
	Journal = {ACM Transactions on Database Systems},
	Keywords = {query language DAPLEX multisets identity duplicates},
	Number = {1},
	Pages = {140--173},
	Publisher = {ACM Press},
	Title = {{The Functional Data Model and the Data Languages DAPLEX}},
	Url = {http://portal.acm.org/citation.cfm?id=319561},
	Volume = {6},
	Year = {1981},
	Abstract = {DAPLEX is a database language which incorporates: a formulation of data in terms of entities; a functional representation for both actual and virtual data relationships; a rich collection of language constructs for expressing entity selection criteria; a notion of subtype/supertype relationships among entity types. This paper presents and motivates the DAPLEX language and the underlying data model on which it is based.}}

@inproceedings{Dayal_ea_RelationalAlgebraDuplicates_PODS1982,
	Address = {New York, NY, USA},
	Author = {Dayal, Umeshwar and Goodman, Nathan and Katz, Randy H.},
	Booktitle = {Proc. ACM Symposium on Principles of Database Systems},
	Date-Added = {2006-01-28 04:38:16 +0100},
	Date-Modified = {2006-01-28 04:44:38 +0100},
	Doi = {http://doi.acm.org/10.1145/588111.588132},
	Isbn = {0-89791-070-2},
	Keywords = {identity multirelations multisets duplicates},
	Location = {Los Angeles, California},
	Pages = {117--123},
	Publisher = {ACM Press},
	Title = {{An Extended Relational Algebra with Control over Duplicate Elimination}},
	Url = {http://portal.acm.org/citation.cfm?id=588132},
	Year = {1982},
	Abstract = {In the pure relational model, duplicate tuples are automatically eliminated. Some real world languages such as DAPLEX, however, give users control over duplicate elimination. This paper extends the relational model to include multiset relations, i.e., relations with duplicate tuples. It considers three formalisms for expressing queries in this model: extended relational algebra, tableaux, and DAPLEX. It shows that, as in the original algebra, the equivalence problem for conjunctive expressions in the extended algebra can be solved using tableaux, and is NP-complete. Finally, it demonstrates that the extended algebra and DAPLEX have essentially the same expressiveness relative to conjunctive expressions.}}

@inproceedings{Klausner_Godman_Multirelations_VLDB1985,
	Author = {Klausner, Aviel and Goodman, Nathan},
	Booktitle = {Proc. Intl. Conf. on Very Large Data Bases},
	Date-Added = {2006-01-28 04:16:37 +0100},
	Date-Modified = {2006-01-28 04:40:19 +0100},
	Keywords = {identity duplicates RDBMS algebra relations multirelations},
	Pages = {251--258},
	Publisher = {Morgan Kaufmann},
	Title = {{Multirelations --- Semantics and Languages}},
	Url = {http://www.vldb.org/conf/1985/P251.PDF},
	Volume = {11},
	Year = {1985},
	Abstract = {We argue that a multirelation (relation with duplicates) is not, a semantically independent data object, but rather it should be viewed as a sub- set of columns within a larger relation that has no duplicates. Consequently, at the level of the con- ceptual database, duplicates in base relations or in views are not allowed, nor are operations on mul- tirelations. Multirelations as query output can be specified by designating a subset of some relation's columns for output, while "hiding" the rest of the columns. Similarly, aggregate functions are applied to multirelations by applying them to a column within a relation. Our approach can be applied to extend any query language in a consistent way to have full multirelational expressiveness, and such an extension for the query language QUEL is detailed.}}

@incollection{przymusinski-local-stratification,
	Author = {Przymusinsik, Teodor},
	Booktitle = {Foundations of Deductive Databases and Logic Programming},
	Chapter = 5,
	Editor = {Jack Minker},
	Pages = {193--216},
	Publisher = {Morgan Kaufmann},
	Title = {{On the Declarative Semantics of Deductive Databases and Logic Programs}},
	Year = 1988}

@incollection{apt-stratification,
	Author = {Apt, Krzysztof and Blair, Howard and Walker, Adrian},
	Booktitle = {Foundations of Deductive Databases and Logic Programming},
	Chapter = 2,
	Editor = {Jack Minker},
	Pages = {89--148},
	Publisher = {Morgan Kaufmann},
	Title = {{Towards a Theory of Deductive Knowledge}},
	Year = 1988}

@techreport{Clark_StylesheetPI_REC_1999,
	Author = {Clark, James},
	Date-Added = {2005-11-13 20:29:51 +0100},
	Date-Modified = {2005-11-13 20:30:45 +0100},
	Institution = {W3C},
	Title = {{Associating Style Sheets with XML Documents, Version 1.0}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/xml-stylesheet/},
	Year = {1999},
	Abstract = {This document allows a style sheet to be associated with an XML document by including one or more processing instructions with a target of xml-stylesheet in the document's prolog.}}

@techreport{Marsh.ea_XMLID_REC_2005,
	Author = {Marsh, Jonathan and Veillard, Daniel and Walsh, Norman},
	Date-Added = {2005-11-13 20:16:58 +0100},
	Date-Modified = {2005-11-13 20:18:35 +0100},
	Institution = {W3C},
	Keywords = {XML Identifier ID References Links Uniqueness},
	Title = {{xml:id Version 1.0}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/2005/REC-xml-id-20050909/},
	Year = {2005},
	Abstract = {This document defines the meaning of the attribute xml:id as an ID attribute in XML documents and defines processing of this attribute to identify IDs in the absence of validation, without fetching external resources, and without relying on an internal subset.}}

@techreport{Clark_RelaxNC_2002,
	Author = {Clark, James},
	Date-Added = {2005-11-06 02:56:35 +0100},
	Date-Modified = {2005-11-06 02:57:06 +0100},
	Institution = {OASIS},
	Title = {{RELAX NG Compact Syntax}},
	Type = {Committee Specification},
	Url = {http://www.relaxng.org/compact-20021121.html},
	Year = {2002}}

@techreport{Clark.ea_RelaxNG_2001,
	Author = {Clark, James and Murata, Makoto},
	Date-Added = {2005-11-06 02:53:54 +0100},
	Date-Modified = {2005-11-06 02:55:37 +0100},
	Institution = {OASIS},
	Title = {{RELAX NG Specification}},
	Type = {Committee Specification},
	Url = {http://www.relaxng.org/spec-20011203.html},
	Year = {2001}}

@article{Naur.ea_ALGOL_CACM_1963,
	Author = {Backus, J. W. and Bauer, F. L. and Green, J. and Katz, C. and McCarthy, J. and Perlis, A. J. and Rutishauser, H. and Samelson, K. and Vauquois, B. and Wegstein, J. H. and van Wijngaarden, A. and Woodger, M.},
	Date-Added = {2005-11-06 02:21:18 +0100},
	Date-Modified = {2005-11-06 02:22:50 +0100},
	Journal = {Communications of the ACM},
	Number = {1},
	Pages = {1--17},
	Title = {{Revised Report on the Algorithm Language ALGOL 60}},
	Volume = {6},
	Year = {1963}}

@inproceedings{Braz_RailroadDia_SIDOC_1990,
	Author = {Braz, Liza},
	Booktitle = {Proc. Intl. Conf. on Systems Documentation},
	Date-Added = {2005-11-06 01:48:34 +0100},
	Date-Modified = {2005-11-06 01:49:52 +0100},
	Pages = {23--27},
	Publisher = {ACM Press},
	Title = {{Visual Syntax Diagrams for Programming Language Statements}},
	Year = {1990}}

@manual{ISO_EBNF_1996,
	Date-Added = {2005-11-05 21:11:01 +0100},
	Date-Modified = {2005-11-05 21:15:11 +0100},
	Number = {14977:1996},
	Organization = {ISO/IEC},
	Title = {ISO/IEC 14977:1996, Syntactic Metalanguage -- Extended BNF},
	Type = {International Standard},
	Url = {http://standards.iso.org/ittf/PubliclyAvailableStandards/s026153_ISO_IEC_14977_1996(E).zip},
	Year = {1996}}

@techreport{Crocker.ea_ABNF_1997,
	Author = {Crocker, D. and Overell, P.},
	Date-Added = {2005-11-05 21:07:00 +0100},
	Date-Modified = {2005-11-05 21:08:02 +0100},
	Institution = {IETF},
	Number = {2234},
	Title = {{Augmented BNF for Syntax Specifications: ABNF}},
	Type = {Request for Comment (RFC)},
	Url = {http://www.ietf.org/rfc/rfc2234.txt},
	Year = {1997}}

@article{Dovier.ea_RankBisimulation_ENTCS_2002,
	Author = {Dovier, Agostino and Gentilini, Raffaella and Piazza, Carla and Policriti, Alberto},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Date-Added = {2005-10-27 15:21:02 +0200},
	Date-Modified = {2005-10-27 15:22:05 +0200},
	Ee = {http://www.elsevier.com/gej-ng/31/29/23/124/25/show/Products/notes/index.htt\#013},
	Journal = {Electronic Notes on Theoretical Computer Science},
	Title = {Rank-Based Symbolic Bisimulation (and Model Checking)},
	Url = {http://wotan.liu.edu/docis/dbl/enitcs/2002_67__RSBMC.html#},
	Volume = {67},
	Year = {2002}}

@article{Gentilini_BiSimulation_JAR_2003,
	Address = {Hingham, MA, USA},
	Author = {Gentilini, R. and Piazza, C. and Policriti, A.},
	Date-Added = {2005-10-27 15:15:42 +0200},
	Date-Modified = {2005-10-27 15:16:26 +0200},
	Doi = {http://dx.doi.org/10.1023/A:1027328830731},
	Issn = {0168-7433},
	Journal = {Journal of Automated Reasoning},
	Number = {1},
	Pages = {73--103},
	Publisher = {Kluwer Academic Publishers},
	Title = {{From Bisimulation to Simulation: Coarsest Partition Problems}},
	Url = {http://www.dimi.uniud.it/~policrit/Papers/JAR_finale.pdf},
	Volume = {31},
	Year = {2003}}

@article{Dovier.ea_AlgBisimulation_TCS_2004,
	Address = {Essex, UK},
	Author = {Dovier, Agostino and Piazza, Carla and Policriti, Alberto},
	Date-Added = {2005-10-27 15:05:30 +0200},
	Date-Modified = {2005-10-27 15:10:24 +0200},
	Doi = {http://dx.doi.org/10.1016/S0304-3975(03)00361-X},
	Issn = {0304-3975},
	Journal = {Theoretical Computer Science},
	Number = {1-3},
	Pages = {221--256},
	Publisher = {Elsevier Science Publishers Ltd.},
	Title = {{An efficient Algorithm for Computing Bisimulation Equivalence}},
	Url = {http://www.dimi.uniud.it/~policrit/Papers/tcsb959.pdf},
	Volume = {311},
	Year = {2004}}

@inproceedings{Milner_SimulationPrograms_IJCAI_1971,
	Author = {Milner, Robin},
	Booktitle = {Proc. Intl. Joint Conf. on Artificial Intelligence},
	Date-Added = {2005-10-27 14:49:18 +0200},
	Date-Modified = {2005-10-27 14:50:37 +0200},
	Pages = {481-489},
	Title = {{An Algebraic Definition of Simulation Between Programs}},
	Year = {1971}}

@inproceedings{Henzinger.ea_Simulation_FOCS_1995,
	Address = {Washington, DC, USA},
	Author = {Henzinger, M. R. and Henzinger, T. A. and Kopke, P. W.},
	Booktitle = {Proc. Symp. on Foundations of Computer Science (FOCS)},
	Date-Added = {2005-10-27 14:44:36 +0200},
	Date-Modified = {2005-10-27 15:04:51 +0200},
	Isbn = {0-8186-7183-1},
	Pages = {453},
	Publisher = {IEEE Computer Society},
	Title = {{Computing Simulations on Finite and Infinite Graphs}},
	Year = {1995}}

@techreport{Schaffert.ea_DeclSemantics_D4_2005,
	Author = {Schaffert, Sebastian and Bry, Fran{\c c}ois and Furche, Tim},
	Date-Added = {2005-10-23 17:11:23 +0200},
	Date-Modified = {2006-03-06 17:49:01 +0100},
	Institution = {REWERSE},
	Keywords = {XML Xcerpt Unification Simulation Substitutions Declarative Semantics},
	Number = {I4-D4},
	Title = {{Initial Draft of a Possible Declarative Semantics for the Language}},
	Type = {Deliverable},
	Url = {http://rewerse.net/publications.html#REWERSE-DEL-2005-I4-D4},
	Year = {2005}}

@techreport{OMG_UML2_2005,
	Author = {{Object Management Group}},
	Date-Added = {2005-10-15 23:22:03 +0200},
	Date-Modified = {2005-10-15 23:23:34 +0200},
	Institution = {Object Management Group},
	Keywords = {UML modelling standard OMG},
	Title = {{UML 2.0 Superstructure Specification}},
	Type = {Specification},
	Url = {http://www.omg.org/technology/documents/formal/uml.htm},
	Year = {2005},
	Abstract = {This UML 2.0: Superstructure is the second of two complementary specifications that represent a major revision to the Object Management Group's Unified Modeling Language (UML), for which the most current version is UML v1.4. The first specification, which serves as the architectural foundation for this specification, is the UML 2.0: Infrastructure. 

This UML 2.0: Superstructure defines the user level constructs required for UML 2.0. It is complemented by UML 2.0: Infrastructure which defines the foundational language constructs required for UML 2.0. The two complementary specifications constitute a complete specification for the UML 2.0 modeling language. 
}}

@techreport{Marsh_XMLBase_2001,
	Author = {Marsh, Jonathan},
	Date-Added = {2005-10-14 19:46:22 +0200},
	Date-Modified = {2005-10-14 19:47:10 +0200},
	Institution = {W3C},
	Keywords = {XML URI base inclusion resolution},
	Title = {{XML Base}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/xmlbase/},
	Year = {2001}}

@techreport{Biron.ea_XMLSchemaDT_2004,
	Author = {Biron, Paul V. and Malhotra, Ashok},
	Date-Added = {2005-10-14 19:31:57 +0200},
	Date-Modified = {2005-10-14 19:33:06 +0200},
	Institution = {W3C},
	Keywords = {XML schema datatypes typing simple types},
	Title = {{XML Schema Part 2: Datatypes Second Edition}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/xmlschema-2/},
	Year = {2004},
	Abstract = {XML Schema: Datatypes is part 2 of the specification of the XML Schema language. It defines facilities for defining datatypes to be used in XML Schemas as well as other XML specifications. The datatype language, which is itself represented in XML 1.0, provides a superset of the capabilities found in XML 1.0 document type definitions (DTDs) for specifying datatypes on elements and attributes.}}

@techreport{Fallside.ea_XMLSchemaPr_2004,
	Author = {Fallside, David C. and Walmsley, Priscilla},
	Date-Added = {2005-10-14 19:26:24 +0200},
	Date-Modified = {2005-10-14 19:30:58 +0200},
	Institution = {W3C},
	Keywords = {XML schema typing},
	Title = {{XML Schema Part 0: Primer Second Edition}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/xmlschema-0/},
	Year = {2004},
	Abstract = {XML Schema Part 0: Primer is a non-normative document intended to provide an easily readable description of the XML Schema facilities, and is oriented towards quickly understanding how to create schemas using the XML Schema language. XML Schema Part 1: Structures and XML Schema Part 2: Datatypes provide the complete normative description of the XML Schema language. This primer describes the language features through numerous examples which are complemented by extensive references to the normative texts.}}

@techreport{Bry.ea_SimulationUnification_DEL_2005,
	Author = {Bry, Fran{\c c}ois and Furche, Tim and Schaffert, Sebastian and Schr{\"o}der, Andreas},
	Date-Added = {2005-10-12 17:02:33 +0200},
	Date-Modified = {2006-03-06 17:24:15 +0100},
	Institution = {REWERSE},
	Keywords = {XML Xcerpt Unification Simulation Unification Algebra Evaluation Operational Semantics},
	Number = {I4-D5},
	Title = {{Simulation Unification}},
	Type = {Deliverable},
	Url = {http://rewerse.net/publications.html#REWERSE-DEL-2005-I4-D5},
	Year = {2005}}

@techreport{Clark_XSLT_1999,
	Author = {Clark, James},
	Date-Added = {2005-10-12 13:31:55 +0200},
	Date-Modified = {2005-10-14 20:45:33 +0200},
	Institution = {W3C},
	Keywords = {XML XSLT standard recommendation},
	Title = {{XSL Transformations, Version 1.0}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/xslt},
	Year = {1999},
	Abstract = {This specification defines the syntax and semantics of XSLT, which is a language for transforming XML documents into other XML documents.

XSLT is designed for use as part of XSL, which is a stylesheet language for XML. In addition to XSLT, XSL includes an XML vocabulary for specifying formatting. XSL specifies the styling of an XML document by using XSLT to describe how the document is transformed into another XML document that uses the formatting vocabulary.

XSLT is also designed to be used independently of XSL. However, XSLT is not intended as a completely general-purpose XML transformation language. Rather it is designed primarily for the kinds of transformations that are needed when XSLT is used as part of XSL.}}

@article{McHugh.ea_Lore_SIGR_1997,
	Address = {New York, NY, USA},
	Author = {McHugh, Jason and Abiteboul, Serge and Goldman, Roy and Quass, Dallas and Widom, Jennifer},
	Date-Added = {2005-10-12 13:22:50 +0200},
	Date-Modified = {2005-10-12 13:30:07 +0200},
	Doi = {http://doi.acm.org/10.1145/262762.262770},
	Issn = {0163-5808},
	Journal = {SIGMOD Record},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/QueryEvaluation/XML/ProcessorsAndSystems/McHugh.ea_Lore_SIGR_1997.pdf},
	Number = {3},
	Pages = {54--66},
	Publisher = {ACM Press},
	Title = {{Lore: a database management system for semistructured data}},
	Volume = {26},
	Year = {1997},
	Abstract = {Lore (for Lightweight Object Repository) is a DBMS designed specifically for managing semistructured information. Implementing Lore has required rethinking all aspects of a DBMS, including storage management, indexing, query processing and optimization, and user interfaces. This paper provides an overview of these aspects of the Lore system, as well as other novel features such as dynamic structural summaries and seamless access to data from external sources.}}

@article{Abiteboul.Quass.ea_LorelQueryLanguage_JDL_1997,
	Author = {Abiteboul, Serge and Quass, Dallan and McHugh, Jason and Widom, Jennifer and Wienerm, Janet L.},
	Date-Added = {2005-10-12 13:19:15 +0200},
	Date-Modified = {2005-10-12 13:19:15 +0200},
	Journal = {Intl. Journal on Digital Libraries},
	Journal-Abbr = {JDL},
	Keywords = {XML query languages Lorel language constructs semi-structured query},
	Number = {1},
	Pages = {68--88},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/PathVariables/Abiteboul.Quass.ea_LorelQueryLanguage_JDL_1997.pdf},
	Title = {{The Lorel Query Language for Semistructured Data}},
	Url = {http://www-db.stanford.edu/lore/pubs/lorel96.pdf},
	Volume = {1},
	Year = {1997},
	Abstract = {We present the Lorel language, designed for querying semistructured data. Semistructured data
	 is becoming more and more prevalent, e.g., in structured documents
	 such as HTML and when performing simple integration of data from
	 multiple sources. Traditional data models and query languages are
	 inappropriate, since semistructured data often is irregular, some data is
	 missing, similar concepts are represented using different types,
	 heterogeneous sets are present, or object structure is not fully known.
	 Lorel is a user-friendly language in the SQL/OQL style for querying
	 such data effectively. For wide applicability, the simple object
	 model underlying Lorel can be viewed as an extension of the ODMG
	 data model and the Lorel language as an extension of OQL. The main
	 novelties of the Lorel language are: (i) the extensive use of coercion to
	 relieve the user from the strict typing of OQL, which is inappropriate
	 for semistructured data; and (ii) powerful path expressions, which
	 permit a flexible form of declarative navigational access and are
	 particularly suitable when the details of the structure are not known to the
	 user. Lorel also includes a declarative update language. Lorel is
	 implemented as the query language of the Lore prototype database
	 management system at Stanford. Information about Lore can be found at
	 http://www-db.stanford.edu/lore. In addition to presenting the Lorel language in full,
	 this paper briefly describes the Lore system and query processor. We
	 also briefly discuss a second implementation of Lorel on top of a
	 conventional object-oriented database management system, the O2 system.}}

@techreport{IEEE_POSIX_2004,
	Author = {Group, The Austin},
	Date-Added = {2005-09-29 01:07:30 +0200},
	Date-Modified = {2005-09-29 01:13:13 +0200},
	Institution = {IEEE, The Open Group},
	Keywords = {IEEE POSIX open operating system},
	Number = {1003.1},
	Title = {IEEE Standard 1003.1, 2004 Edition (aka POSIX.1)},
	Type = {IEEE Standard},
	Url = {http://www.opengroup.org/onlinepubs/009695399/},
	Year = {2001-2004}}

@techreport{Duerst.Suignard_IRI_2005,
	Author = {Duerst, M. and Suignard, M.},
	Date-Added = {2005-09-29 01:03:15 +0200},
	Date-Modified = {2005-09-29 01:04:47 +0200},
	Institution = {IEEE},
	Keywords = {IRI URI identifiers RFC IEEE W3C},
	Number = {3987},
	Title = {{Internationalized Resource Identifiers (IRIs)}},
	Type = {RFC (Request for Comments)},
	Url = {http://www.faqs.org/rfcs/rfc3987.html},
	Year = {2005}}

@book{Gosling.Joy.ea_JavaSpec_2005,
	Author = {Gosling, James and Joy, Bill and Steele, Guy and Bracha, Gilad},
	Date-Added = {2005-09-29 00:53:49 +0200},
	Date-Modified = {2005-09-29 00:56:15 +0200},
	Edition = {3rd},
	Keywords = {Java JLS language specification grammar},
	Publisher = {Addison-Wesley Professional},
	Title = {Java Language Specification, Third Edition},
	Url = {http://java.sun.com/docs/books/jls/},
	Year = {2005}}

@techreport{Bray.Hollander.ea_XMLNSRec_W3C_1999,
	Author = {Bray, Tim and Hollander, Dave and Layman, Andrew},
	Date-Added = {2005-09-29 00:37:15 +0200},
	Date-Modified = {2005-09-29 00:38:45 +0200},
	Institution = {W3C},
	Keywords = {XML W3C recommendation namespaces},
	Owner = {Tim Furche},
	Title = {{Namespaces in XML}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/REC-xml-names/},
	Urldate = {2005/09/31},
	Year = {1999},
	Abstract = {XML namespaces provide a simple method for qualifying element and attribute names used in Extensible Markup Language documents by associating them with namespaces identified by URI references.}}

@techreport{Bray.Paoli.ea_XMLRec_W3C_2004,
	Author = {Bray, Tim and Paoli, Jean and Sperberg-McQueen, C. M. and Maler, Eve and Yergeau, Fran{\c c}ois},
	Date-Added = {2005-09-29 00:30:06 +0200},
	Date-Modified = {2005-09-29 00:41:34 +0200},
	Institution = {W3C},
	Keywords = {XML W3C recommendation},
	Owner = {Tim Furche},
	Title = {{Extensible Markup Language (XML) 1.0 (Third Edition)}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/REC-xml/},
	Urldate = {2005/09/31},
	Year = {2004},
	Abstract = {The Extensible Markup Language (XML) is a subset of SGML that is completely described in this document. Its goal is to enable generic SGML to be served, received, and processed on the Web in the way that is now possible with HTML. XML has been designed for ease of implementation and for interoperability with both SGML and HTML.}}

@techreport{Alschuler.Dolin.ea_ClinicalDocumentArchitecture_TR_2000,
	Author = {Alschuler, Liora and Dolin, Robert H. and Boyer, Sandy and Beebe, Calvin},
	Institution = {Health Level Seven (HL7)},
	Owner = {Tim Furche},
	Title = {{Clinical Document Architecture Framework}},
	Year = {2000}}

@techreport{Amer-YahiaBotev.XQuery-1.0-and-XPath.2005,
	Author = {Amer-Yahia, Sihem and Botev, Chavdar and Buxton, Stephen and Case, Pat and Doerre, Jochen and McBeath, Darin and Rys, Michael and Shanmugasundaram, Jayavel},
	Date-Added = {2005-04-30 22:28:10 +0200},
	Date-Modified = {2005-04-30 22:31:35 +0200},
	Institution = {W3C},
	Keywords = {XML XQuery full-text information retrieval},
	Number = {Working Draft},
	Title = {{XQuery 1.0 and XPath 2.0 Full-Text}},
	Url = {http://www.w3.org/TR/xquery-full-text/},
	Year = {2005},
	Abstract = {This document defines the syntax and formal
	 semantics of XQuery 1.0 and XPath 2.0 Full-Text which is a language that
	 extends XQuery 1.0 [XQuery 1.0: An XML Query Language] and XPath 2.0
	 [XML Path Language (XPath) 2.0] with full-text search capabilities.}}

@inproceedings{Amer-Yahia.Botev.ea_TeXQuery-Full-TextSearch_WWW_2004,
	Author = {Amer-Yahia, Sihem and Botev, Chavdar and Shanmugasundaram, Jayavel},
	Booktitle = WWW,
	Conference-Abbr = {WWW},
	Keywords = {XML IR query languages full-text information retrieval},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/InformationRetrieval/Languages/Amer-Yahia.Botev.ea_TeXQuery-Full-TextSearch_WWW_2004.pdf},
	Title = {{TeXQuery: A Full-Text Search Extension to XQuery}},
	Url = {http://www.research.att.com/~sihem/TeXQuery/TeXQuery.pdf},
	Year = {2004},
	Abstract = {One of the key benefits of XML is its ability to represent a mix of
	 structured and unstructured (text) data. Although current XML query
	 languages such as XPath and XQuery can express rich queries over
	 structured data, they can only express very rudimentary queries over
	 text data. We thus propose TeXQuery, which is a powerful full-text
	 search extension to XQuery. TeXQuery provides a rich set of fully
	 composable full-text search primitives, such as Boolean connectives,
	 phrase matching, proximity distance, stemming and thesauri. TeXQuery
	 also enables users to seamlessly query over both structured and text
	 data by embedding TeXQuery primitives in XQuery, and vice versa.
	 Finally, TeXQuery supports a flexible scoring construct that can be
	 used to score query results based on full-text predicates. TeXQuery
	 is one of the proposals submitted to the W3C Full-Text Task Force,
	 whose charter is to extend XQuery with full-text search capabilities.}}

@inproceedings{Amer-Yahia.Fernandez.ea_PIX-Exactand_SIGMOD_2003,
	Author = {Amer-Yahia, Sihem and Fernandez, Mary F. and Srivastava, Divesh and Xu, Yu},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Keywords = {XML IR information retrieval query languages},
	Owner = {Tim Furche},
	Title = {{PIX: Exact and Approximate Phrase Matching in XML}},
	Url = {http://www.research.att.com/~sihem/publications/demopixSIGMOD03.pdf},
	Year = {2003}}

@inproceedings{Amer-Yahia.Lakshmanan.ea_FleXPath:FlexibleStructure_SIGMOD_2004,
	Author = {Amer-Yahia, Sihem and Lakshmanan, Laks V. S. and Pandit, Shashank},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Keywords = {XML IR query languages full-text information retrieval approximation structure},
	Owner = {Tim Furche},
	Title = {{FleXPath: Flexible Structure and Full-Text Querying for XML}},
	Year = {2004},
	Abstract = {Querying XML data is a
	 well-explored topic with powerful database-style query languages
	 such as XPath and XQuery set to become W3C standards. An equally
	 compelling paradigm for querying XML documents is full-text search on
	 textual content. In this paper, we study fundamental challenges that
	 arise when we try to integrate these two querying paradigms.While
	 keyword search is based on approximate matching, XPath has exact
	 match semantics. We address this mismatch by considering queries on
	 structure as a "template", and looking for answers that best match this
	 template and the full-text search. To achieve this, we provide an
	 elegant definition of relaxation on structure and define primitive
	 operators to span the space of relaxations. Query answering is now
	 based on ranking potential answers on structural and full-text search
	 conditions. We set out certain desirable principles for ranking schemes and
	 propose natural ranking schemes that adhere to these principles. We
	 develop efficient algorithms for answering top-K queries and discuss
	 results from a comprehensive set of experiments that demonstrate the
	 utility and scalability of the proposed framework and algorithms.}}

@article{Antoniou.Baldoni.ea_ReasoningMethodsPersonalization_AMCT_2004,
	Author = {Antoniou, Grigoris and Baldoni, Matteo and Baroglio, Cristina and Baumgartner, Robert and Bry, Fran{\c c}ois and Eiter, Thomas and Henze, Nicola and Herzog, Marcus and May, Wolfgang and Patti, Viviana and Schindlauer, Roman and Tompits, Hans and Schaffert, Sebastian},
	Journal = {Annals of Mathematics, Computing \& Teleinformatics},
	Journal-Abbr = {AMCT},
	Keywords = {Semantic Web Personalization Reasoning REWERSE},
	Number = {1},
	Pages = {1--24},
	Title = {{Reasoning Methods for Personalization on the Semantic Web}},
	Url = {http://www.dbis.informatik.uni-goettingen.de/Publics/04/AMCT04.html},
	Urldate = {2005/01/28},
	Volume = {2},
	Year = {2004},
	Abstract = {The Semantic Web vision of a next generation Web, in which
	 machines are enabled to understand the meaning of information in
	 order to better interoperate and better support humans in carrying
	 out their tasks, is very appealing and fosters the imagination of
	 smarter applications that can retrieve, process and present information
	 in enhanced ways. In this vision, a particular attention should be
	 devoted to personalization: By bringing the user's needs into the
	 center of interaction processes, personalized Web systems overcome the
	 one-size-fits-all paradigm and provide individually optimized access to
	 Web data and information. In this paper, we provide an overview of
	 recent trends for establishing personalization on the Semantic Web:
	 Based on a discussion on reasoning with rule- and query languages
	 for the Semantic Web, we outline an architecture for service-based
	 personalization, and show results in personalizing Web applications.}}

@techreport{Apparao.Byrne.ea_DocumentObjectModel_TR_1998,
	Author = {Apparao, Vidur and Byrne, Steve and Champion, Mike and Isaacs, Scott and Jacobs, Ian and Hors, Arnaud Le and Nicol, Gavin and Robie, Jonathan and Sutor, Robert and Wilson, Chris and Wood, Lauren},
	Institution = {W3C},
	Keywords = {XML DOM W3C data model document object model},
	Owner = {Tim Furche},
	Title = {{Document Object Model (DOM) Level 1 Specification}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/REC-DOM-Level-1/},
	Urldate = {2005/01/31},
	Year = {1998},
	Abstract = {This specification defines the Document Object Model Level 1, a platform- and
	 language-neutral interface that allows programs and scripts to dynamically
	 access and update the content, structure and style of documents.
	 The Document Object Model provides a standard set of objects for
	 representing HTML and XML documents, a standard model of how these
	 objects can be combined, and a standard interface for accessing and
	 manipulating them. Vendors can support the DOM as an interface to their
	 proprietary data structures and APIs, and content authors can write
	 to the standard DOM interfaces rather than product-specific APIs,
	 thus increasing interoperability on the Web. The goal of the DOM
	 specification is to define a programmatic interface for XML and HTML. The DOM
	 Level 1 specification is separated into two parts: Core and HTML. The
	 Core DOM Level 1 section provides a low-level set of fundamental
	 interfaces that can represent any structured document, as well as
	 defining extended interfaces for representing an XML document. These
	 extended XML interfaces need not be implemented by a DOM implementation
	 that only provides access to HTML documents; all of the fundamental
	 interfaces in the Core section must be implemented. A compliant DOM
	 implementation that implements the extended XML interfaces is required to
	 also implement the fundamental Core interfaces, but not the HTML
	 interfaces. The HTML Level 1 section provides additional, higher-level
	 interfaces that are used with the fundamental interfaces defined in the
	 Core Level 1 section to provide a more convenient view of an HTML
	 document. A compliant implementation of the HTML DOM implements all
	 of the fundamental Core interfaces as well as the HTML interfaces.}}

@inproceedings{Augurusa.Braga.ea_DesignandImplementation_SAC_2003,
	Author = {Augurusa, Enrico and Braga, Daniele and Campi, Alessandro and Ceri, Stefano},
	Booktitle = SAC,
	Conference-Abbr = {SAC},
	Doi = {http://doi.acm.org/10.1145/952532.952759},
	Isbn = {1-58113-624-2},
	Keywords = {XML XQuery visual query language XQBE query-by-example},
	Location = {Melbourne, Florida},
	Pages = {1163--1167},
	Pdf = {QueryEvaluation/XML/XQuery/Augurusa.Braga.ea_DesignandImplementation_SAC_2003.pdf},
	Publisher = {ACM Press},
	Title = {{Design and Implementation of a Graphical Interface to XQuery}},
	Url = {http://dbgroup.elet.polimi.it/xquery/papers/XQBE-SAC03.pdf},
	Year = {2003},
	Abstract = {As the use of XML is rapidly growing, a growing number of users without
	 programming skills will need to query XML data. Although designed
	 to be easily understood by humans, XQuery, the XML standard query
	 language, has the typical syntax of programming languages, which most
	 users dislike. In this paper we describe a graphical language (XQBE)
	 inspired by "Query By Example" (QBE), a popular relational query
	 language used by MS Access. XQBE covers a significant subset of XQuery
	 and is supported by a prototype enabling the formulation of queries
	 on a graphical interface and their translation into XQuery, thus
	 providing non-trivial querying capabilities to a wide spectrum of users.
	 Simple queries are easily represented in XQBE, but many "complex"
	 queries allow as well for an intuitive graphical representation.}}

@inproceedings{Assmann.Henriksson.ea_Comp_PPSWR_2005,
	Author = {A{\ss}mann, Uwe and Henriksson, Jakob and Maluszynski, Jan},
	Booktitle = {Proc. Workshop on Principles and Practice of Semantic Web Reasoning},
	Conference-Abbr = {PPSWR},
	Keywords = {composition Semantic Web ontologies rule languages I3},
	Owner = {Tim Furche},
	Pdf = {SemanticWeb/Ontologies/Assmann.Henriksson.ea_Comp_PPSWR_2005.pdf},
	Title = {{A Hybrid Technique for Composition of Rules and Ontologies for Semantic Web Reasoning}},
	Year = {2005},
	Abstract = {Previous approaches towards
	 combining rule languages with Description-Logic-based ontologies require
	 specialized reasoners for each specific combination. We outline a
	 general technique for combining various classes of rule languages
	 with various constraint languages including but not restricted to
	 Description-Logic-based ontologies. The combination is such that
	 existing reasoners, considered as software components, can be re-used
	 for reasoning in the combined language, if they support external
	 calls to rules or functions. We specifically formulate the approach
	 as a software component model as studied in software engineering.
	 We illustrate the technique by showing how a subset of SWRL can be
	 implemented by combination of a Datalog interpreter and OWL reasoner.}}

@inproceedings{Backofen.Badea.ea_PosterTowardssemantic_SocBIN_2004,
	Author = {Backofen, Rolf and Badea, Mike and Barahona, Pedro and Badea, Liviu and Bry, Fran{\c c}ois and Dawelbait, Gihan and Doms, Andreas and Fages, Fran{\c c}ois and Goble, Carole and Henschel, Andreas and Hotaran, Anca and Huang, Bingding and Krippahl, Ludwig and Lambrix, Patrick and Nutt, Werner and Schroeder, Michael and Soliman, Sylvain and Will, Sebastian},
	Booktitle = {Prof. Bioinformatics},
	Conference-Abbr = {SocBIN},
	Keywords = {REWERSE Bioinformatics Semantic Web},
	Organization = {SocBIN - Society for Bioinformatics in the Nordic countries},
	Title = {{Poster: Towards a semantic web for bioinformatics}},
	Url = {http://rewerse.net/publications.html#REWERSE-RP-2004-26},
	Year = {2004}}

@techreport{Badea.Bry.ea_DevelopmentofUse_TR_2005,
	Author = {Badea, Liviu and Bry, Fran{\c c}ois and Doms, Andreas and Furche, Tim and Hoffmann, Jan and Schaffert, Sebastian and Schroeder, Michael},
	Date-Modified = {2005-05-01 23:00:30 +0200},
	Institution = {REWERSE},
	Keywords = {REWERSE Query languages Use Cases Versatility Deliverable},
	Number = {I4-D3},
	Owner = {Tim Furche},
	Title = {{Development of Use Cases, Part II: Usage Scenarios for a Versatile Web Query Language}},
	Type = {Deliverable},
	Year = {2005}}

@inproceedings{Badea.Tilivea.ea_SemanticWebReasoning_PPSWR_2004,
	Author = {Badea, Liviu and Tilivea, Doina and Hotaran, Anca},
	Booktitle = PPSWR,
	Conference-Abbr = {PPSWR},
	Keywords = {Web Semantic Web REWERSE},
	Organization = {REWERSE},
	Pdf = {SemanticWeb/REWERSE/Badea.Tilivea.ea_SemanticWebReasoning_PPSWR_2004.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{Semantic Web Reasoning for Ontology-Based Integration of Resources}},
	Url = {http://www.ai.ici.ro/papers/ppswr04f.pdf},
	Urldate = {2004/11/11},
	Volume = {3208},
	Year = {2004},
	Abstract = {The Semantic Web should enhance the current World Wide Web with
	 reasoning capabilities for enabling automated processing of possibly
	 distributed information. In this paper we describe an architecture for
	 Semantic Web reasoning and query answering in a very general setting
	 involving several heterogeneous information sources, as well as domain
	 ontologies needed for offering a uniform and source-independent view on
	 the data. Since querying a Web source is very costly in terms of
	 response time, we focus mainly on the query planner of such a system,
	 as it may allow avoiding the access to queryirrelevant sources or
	 combinations of sources based on knowledge about the domain and the sources.}}

@inproceedings{Bae.Bailey_CodeXapproachdebugging_WISE_2003,
	Author = {Bae, Eric and Bailey, James},
	Booktitle = {Web Information Systems Engineering, 2003. WISE 2003. Proceedings of the Fourth International Conference on},
	Conference-Abbr = {WISE},
	Keywords = {XML XSLT debugging query languages},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XSLT/Bae.Bailey_CodeXapproachdebugging_WISE_2003.pdf},
	Title = {{CodeX: an approach for debugging XSLT transformations}},
	Url = {http://www.cs.mu.oz.au/~jbailey/papers/wise.ps},
	Year = {2003},
	Abstract = {XML is now a dominant
	 standard for storing and exchanging information. One very important
	 activity is the transformation of XML documents into other formats,
	 via the transformation language XSLT. XSLT provides a powerful way
	 to perform document conversion and exchange, avoiding reliance on
	 application specific solutions. However, XSLT is a complex language and the
	 current level of support for debugging tools is poor. Many tools
	 that do exist are mainly an extension of conventional techniques for
	 imperative programs and not well-suited to the task. In this paper,
	 we present CodeX, a debugger for XSLT and propose three debugging
	 techniques which are particularly suited to the language. We aim to offer
	 XSLT users a tool which is beneficial in finding errors, as well as
	 facilitating a better understanding of the XML transformation process.}}

@inproceedings{Bailey_TransformationandReaction_ADC_2005,
	Author = {Bailey, James},
	Booktitle = {Proc. Australasian Database Conference},
	Conference-Abbr = {ADC},
	Keywords = {XML XSLT transformation reactivity research issues},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XSLT/Bailey_TransformationandReaction_ADC_2005.pdf},
	Title = {{Transformation and Reaction Rules for Data on the Web}},
	Url = {http://crpit.com/confpapers/CRPITV39Bailey.pdf},
	Year = {2005},
	Abstract = {The transformation and manipulation of XML is an
	 increasingly important research topic. This paper examines a number of
	 issues with regard to languages for transforming and reacting to
	 changes on XML data. On the transformation side, we focus on XSLT, a
	 powerful language for converting XML data into other formats. We look
	 at analysis and optimisation issues for XSLT, as well as support
	 for debugging and automatic generation. On the reactivity side, we
	 focus on an event-condition-action rule approach, which is a natural
	 candidate for the support of reactive functionality on XML repositories.}}

@incollection{BaileyBry.Web-and-Semantic-Web.2005,
	Author = {Bailey, James and Bry, Fran{\c c}ois and Furche, Tim and Schaffert, Sebastian},
	Booktitle = {Reasoning Web Summer School 2005},
	Date-Added = {2005-04-20 13:38:00 +0200},
	Date-Modified = {2006-03-06 17:46:19 +0100},
	Editor = {Jan Maluszinsky and Norbert Eisinger},
	Number = {3564},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{Web and Semantic Web Query Languages: A Survey}},
	Url = {http://www.pms.ifi.lmu.de/publikationen#PMS-FB-2005-14},
	Year = {2005},
	Abstract = {A number of techniques have been developed to
	 facilitate powerful data retrieval on the Web and Semantic Web. Three
	 categories of Web query languages can be distinguished, according to
	 the format of the data they can retrieve: XML, RDF and Topic Maps.
	 This article introduces the spectrum of languages falling into these
	 categories and summarises their salient aspects. The languages are
	 introduced using common sample data and query types. Key aspects
	 of the query languages considered are stressed in a conclusion. }}

@inproceedings{Bartlett.Cook_XMLSecurityusing_SS_2003,
	Author = {Bartlett, Robert G. and Cook, Malcolm W.},
	Booktitle = {Proc. Intl. Conf. on System Sciences},
	Conference-Abbr = {SS},
	Keywords = {XML XSLT cryptography security query languages},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XSLT/Bartlett.Cook_XMLSecurityusing_SS_2003.pdf},
	Title = {{XML Security using XSLT}},
	Url = {http://www.cit.uws.edu.au/research/reports/paper/paper02/robert-15-02.pdf},
	Year = {2003},
	Abstract = {The eXtensible Markup Language (XML) is regarded generally as having promise of
	 becoming established as the general purpose framework for enabling
	 transfer of data amongst heterogeneous environments. It is of interest
	 therefore to analyse how suitable it may be once details of applications
	 requirements and constraints are taken into account. One important
	 requirement is for the security of documents in transit. Closely
	 associated with XML is the eXtensible Stylesheet Language (XSL), whose
	 document transformation component (XSLT) may well have sufficient
	 functionality to perform all reasonable cryptographic transformations
	 to deliver a desired level of document security. We examine this
	 question by describing a real world XML application whose security
	 requirements are more complex than for a simple document transfer
	 between just two parties; proposing a document transfer architecture
	 into which XSLT can be plugged-in; and identifying those features of
	 XSLT which must be applied to meet the application requirements. We
	 conclude that XSLT is only just adequate in the proposed scenario; and
	 then only by making use of its " extension functions " capability.}}

@inproceedings{Baumgartner.Gottlob.ea_AnnotatingLegacyWeb_ISWC_2004,
	Author = {Baumgartner, Robert and Gottlob, Georg and Herzog, Marcus and Slany, Wolfgang},
	Booktitle = ISWC,
	Conference-Abbr = {ISWC},
	Keywords = {Lixto Extraction Legacy Web XML Wrapper REWERSE},
	Owner = {Tim Furche},
	Pdf = {SemanticWeb/Extraction/Baumgartner.Gottlob.ea_AnnotatingLegacyWeb_ISWC_2004.pdf},
	Title = {{Annotating the Legacy Web with Lixto}},
	Url = {http://iswc2004.semanticweb.org/demos/21/paper.pdf},
	Urldate = {2005/01/28},
	Year = {2004},
	Abstract = {The Semantic Web is still a vision. The unstructured Web of
	 today contains millions of documents which cannot be queried and
	 where layout and structure are heavily mixed. Moreover, they are not
	 annotated at all. There is a huge gap between Web information and
	 the qualified, structured data as required in corporate information
	 systems. According to the vision of the Semantic Web, all information
	 available on the Web will be suitably structured, annotated, and
	 qualified in the future. However, until this goal is reached, and
	 also, towards a faster achievement of this goal, relevant data can be
	 (semi-)automatically extracted from HTML documents and automatically translated
	 into a structured format, e.g., XML. A program that automatically
	 extracts data and transforms it into another format (markups the content
	 with semantic information) is called a wrapper. Intelligent content
	 extraction provides the foundation for automatic generation of semantic
	 markup. Various approaches to automatic content extraction have been
	 proposed, ranging from machine learning techniques to pattern recognition
	 techniques. However, these approaches in general fail to produce
	 useful results due to the complexity of Web pages. Other approaches
	 suggest the manual editing of script files that wrap the relevant
	 data from Web pages into more structured formats. Such processes are
	 time-consuming, hard to understand for non-technical wrapper designers, and
	 script files are not easy to maintain. We propose another approach - a
	 supervised and visual definition of content extraction. Based on
	 interactively identifying and extracting relevant parts of HTML documents and
	 translating content to XML format, we designed and implemented the
	 efficient wrapper generation tool Lixto Visual Wrapper [2] which is
	 well-suited for building HTML to XML wrappers. Such a wrappeapplied to
	 continually extract relevant information from this class of Web pages.}}

@inproceedings{Bayardo.Gruhl.ea_EvaluationofBinary_WWW_2004,
	Author = {Bayardo, Roberto J. and Gruhl, Daniel and Josifovski, Vanja and Myllymaki, Jussi},
	Booktitle = WWW,
	Conference-Abbr = {WWW},
	Doi = {http://doi.acm.org/10.1145/988672.988719},
	Isbn = {1-58113-844-X},
	Keywords = {XML XQuery stream binary encoding},
	Location = {New York, NY, USA},
	Pages = {345--354},
	Pdf = {QueryEvaluation/XML/XQuery/Bayardo.Gruhl.ea_EvaluationofBinary_WWW_2004.pdf},
	Publisher = {ACM Press},
	Title = {{An Evaluation of Binary XML Encoding Optimizations for fast Stream based XML Processing}},
	Url = {http://www.www2004.org/proceedings/docs/1p345.pdf},
	Year = {2004},
	Abstract = {This paper provides an objective evaluation of the performance
	 impacts of binary XML encodings, using a fast stream-based XQuery
	 processor as our representative application. Instead of proposing
	 one binary format and comparing it against standard XML parsers, we
	 investigate the individual effects of several binary encoding techniques
	 that are shared by many proposals. Our goal is to provide a deeper
	 understanding of the performance impacts of binary XML encodings in order to
	 clarify the ongoing and often contentious debate over their merits,
	 particularly in the domain of high performance XML stream processing.}}

@inproceedings{Berger.Bry.ea_XcerptandvisXcerpt_ISWC_2004,
	Author = {Berger, Sacha and Bry, Fran{\c c}ois and Bolzer, Oliver and Furche, Tim and Schaffert, Sebastian and Wieser, Christoph},
	Booktitle = ISWC,
	Conference-Abbr = {ISWC},
	Keywords = {Semantic Web XML RDF Visualization Xcerpt Demo REWERSE visXcerpt},
	Pdf = {SemanticWeb/Xcerpt/Visualization/Berger.Bry.ea_XcerptandvisXcerpt_ISWC_2004.pdf},
	Title = {{Xcerpt and visXcerpt: Twin Query Languages for the Semantic Web}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2004-23},
	Urldate = {2004/11/11},
	Year = {2004},
	Abstract = {Query and transformation languages
	 such as XPath, XQuery and XSLT have evolved to standard development
	 tools for Web applications. Arguably those languages are not fully
	 suited for Semantic Web applications. The query and transformation
	 languages Xcerpt and visXcerpt have been conceived with both standard Web
	 and Semantic Web applications in mind. They are twin languages both
	 based on the same paradigms and principles. Xcerpt realizes these
	 paradigms and principles textually, visXcerpt visually. A mixed standard
	 Web and Semantic Web application scenario implemented in Xcerpt and
	 visXcerpt is presented. Xcerpt and visXcerpt are ongoing research
	 projects; prototypic implementations of the languages are available.}}

@inproceedings{Berger.Bry.ea_ReasoningonWeb_EWIMT_2004,
	Author = {Berger, Sacha and Bry, Fran{\c c}ois and Lorenz, Bernhard and Ohlbach, Hans J{\"u}rgen and P?tr{\^a}njan, Paula-Lavinia and Schaffert, Sebastian and Schwertel, Uta and Spranger, Stephanie},
	Booktitle = {Proc. European Workshop on the Integration of Knowledge, Semantics and Digital Media Technology},
	Conference-Abbr = {EWIMT},
	Keywords = {REWERSE Reasoning Semantic Web Query Languages Reactivity Temporal Reasoning},
	Organization = {IEEE},
	Pages = {157--164},
	Pdf = {SemanticWeb/REWERSE/Berger.Bry.ea_ReasoningonWeb_EWIMT_2004.pdf},
	Title = {{Reasoning on the Web: Language Prototypes and Perspectives}},
	Url = {http://rewerse.net/publications.html#REWERSE-RP-2004-39},
	Year = {2004},
	Abstract = {Reasoning on the Web is
	 gaining in importance because of emerging Web applications such as
	 context-adaptive Web systems (e.g. eLearning, rec ommender, personalised
	 (multi-)media, and mobile information systems), Web service retrieval and
	 composition, and Semantic Web applications of all kinds. A central issue is
	 combining automated reasoning methods with Web languages, especially with
	 Web query, schema, and update languages. This article reports on
	 prototypes of various kinds combining different forms of reasoning with
	 Web languages. The languages presented here have been conceived for
	 both, convention al Web and Semantic Web data, assuming that future
	 Web applications will require to freely combine data of both kinds.}}

@inproceedings{Berger.Bry.ea_XcerptetvisXcerpt_JFPLC_2004,
	Author = {Berger, Sacha and Bry, Fran{\c c}ois and Schaffert, Sebastian},
	Booktitle = {Proc. Journ{\'e}es Francophones de Programmation en Logique et Programmation par Contraintes},
	Conference-Abbr = {JFPLC},
	Keywords = {REWERSE Query Languages Xcerpt visXcerpt Visualization},
	Organization = {INRIA},
	Pdf = {SemanticWeb/REWERSE/Berger.Bry.ea_XcerptetvisXcerpt_JFPLC_2004.pdf},
	Title = {{Xcerpt et visXcerpt : Langages d{\'e}ductifs d?interrogation du Web}},
	Url = {http://rewerse.net/publications.html#REWERSE-RP-2004-13},
	Year = {2004},
	Abstract = {Web Query languages like XPath, XQuery and XSLT are
	 widely accepted tools for the development of Web applications today.
	 This article presents and motivates two new and experimental query
	 languages for the Web: Xcerpt and visXcerpt (see http://xcerpt.org).
	 Both languages are based on the same principles. They are deductive
	 languages, which is one of their central aspects: they use a sort of
	 unification similar to the unification used in logic programming and
	 deduction systems, as well as an inference mechanism similar to that
	 of logic programming and to SQL views in databases. visXcerpt is a
	 visual query language which provides a visual realization of Xcerpt's
	 textual constructs. Xcerpt's and visXcerpt's main goal is to ease the
	 development of applications for the Semantic Web applications. This
	 article introduces the essential aspects of Xcerpt and visXcerpt.}}

@inproceedings{Berger.Bry.ea_XcerptundvisXcerpt_GDB_2004,
	Author = {Berger, Sacha and Bry, Fran{\c c}ois and Schaffert, Sebastian},
	Booktitle = {Proc. Workshop Grundlagen von Datenbanken},
	Conference-Abbr = {GDB},
	Keywords = {REWERSE visXcerpt Xcerpt Query Languages Semantic Web},
	Organization = {GI},
	Pdf = {SemanticWeb/REWERSE/Berger.Bry.ea_XcerptundvisXcerpt_GDB_2004.pdf},
	Title = {{Xcerpt und visXcerpt: deduktive Anfragesprachen f{\"u}r das Web}},
	Url = {http://rewerse.net/publications.html#REWERSE-RP-2004-66},
	Year = {2004},
	Abstract = {Anfragesprachen f{\"u}r
	 XML-Daten sind heutzutage wesentliche Werkzeuge in der Entwicklung von
	 Webanwendungen. Die am weitesten verbreiteten Sprachen sind XQuery
	 und XSLT, die beide auf der pfadbasierten Selektionssprache XPath
	 aufbauen. Dieser Vortrag gibt einen Einblick in eine neue Anfragesprache
	 namens Xcerpt, die statt des pfadbasierten Ansatzes Anfragepattern
	 verwendet, welche eine deklarativere Spezifikation von Anfragen erlauben.
	 Xcerpt ist ausserdem eine deduktive, regelbasierte Sprache, die auch
	 die Verkn{\"u}pfung von mehreren Regeln (Chaining) und Rekursion
	 erm{\"o}glicht. Eine Xcerpt-Regel kann damit auch als Abstraktion der
	 Ausgangsdaten verstanden werden, hnlich zu Views in relationalen
	 Datenbanken.Auf Xcerpt aufbauend wird ausserdem die visuelle Anfragesprache
	 visXcerpt vorgestellt. Aufgrund des patternbasierten Ansatzes von Xcerpt
	 k{\"o}nnen in visXcerpt Anfragen auf einfache Weise visuell dargestellt
	 und bearbeitet werden.Das Ziel beider Anfragesprachen ist es, die
	 Entwicklung von Anwendungen insbesondere f{\"u}r das "Semantic Web" zu
	 vereinfachen:Anfnger k{\"o}nnen mit Hilfe von visXcerpt Anfragen
	 schnell und intuitiv formulieren und Fortgeschrittenen hilft die
	 Deklarativitt von Xcerpt bei der Gliederung komplexer Programme.}}

@inproceedings{Berger.Bry.ea_VisualLanguageWeb_PPSWR_2003,
	Author = {Berger, Sacha and Bry, Fran{\c c}ois and Schaffert, Sebastian},
	Booktitle = PPSWR,
	Conference-Abbr = {PPSWR},
	Keywords = {Xcerpt visXcerpt Demo Visualization Query Languages},
	Pdf = {SemanticWeb/Xcerpt/Visualization/Berger.Bry.ea_VisualLanguageWeb_PPSWR_2003.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{A Visual Language for Web Querying and Reasoning}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2003-6},
	Volume = {2901},
	Year = {2003},
	Abstract = {As XML is increasingly being used to represent information on the Web, query and
	 reasoning languages for such data are needed. This article argues that in
	 contrast to the navigational approach taken in particular by XPath
	 and XQuery, a positional approach as used in the language Xcerpt
	 is better suited for a straightforward visual representation. The
	 constructs of the pattern- and rule-based query language Xcerpt are
	 introduced and it is shown how the visual representation visXcerpt
	 renders these constructs to form a visual query language for XML.}}

@inproceedings{Berger.Bry.ea_XcerptandvisXcerpt_VLDB_2003,
	Author = {Berger, Sacha and Bry, Fran{\c c}ois and Schaffert, Sebastian and Wieser, Christoph},
	Booktitle = VLDB,
	Conference-Abbr = {VLDB},
	Keywords = {Xcerpt visXcerpt Query Languages Visualization},
	Title = {{Xcerpt and visXcerpt: From Pattern-Based to Visual Querying of XML and Semistructured Data}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2003-2},
	Year = {2003}}

@inproceedings{Berger.Bry.ea_VisualQueryingSemantic_ER_2004,
	Author = {Berger, Sacha and Bry, Fran{\c c}ois and Wieser, Christoph},
	Booktitle = {Proc. Intl. Conf. on Conceptual Modeling},
	Conference-Abbr = {ER},
	Keywords = {REWERSE visXcerpt Visualization Query Languages Xcerpt},
	Pdf = {SemanticWeb/REWERSE/Berger.Bry.ea_VisualQueryingSemantic_ER_2004.pdf},
	Title = {{Visual Querying for the Semantic Web}},
	Url = {http://rewerse.net/publications.html#REWERSE-RP-2004-43},
	Year = {2004},
	Abstract = {This paper presents a demonstration of visXcerpt, a visual query
	 language for both, standard Web as well as Semantic Web applications.}}

@article{Bex.Maneth.ea_FormalModelExpressive_IS_2002,
	Author = {Bex, Geert Jan and Maneth, Sebastian and Neven, Frank},
	Doi = {http://dx.doi.org/10.1016/S0306-4379(01)00033-3},
	Issn = {0306-4379},
	Journal = {Information Systems},
	Journal-Abbr = {IS},
	Keywords = {XML XSLT formal expressiveness},
	Number = {1},
	Pages = {21--39},
	Pdf = {QueryEvaluation/XML/XSLT/Bex.Maneth.ea_FormalModelExpressive_IS_2002.pdf},
	Publisher = {Elsevier Science Ltd.},
	Title = {{A Formal Model for an Expressive Fragment of XSLT}},
	Url = {http://alpha.luc.ac.be/~lucg5503/xsltfull.ps},
	Volume = {27},
	Year = {2002},
	Abstract = {The extension of the eXtensible
	 Style sheet Language (XSL) by variables and passing of data values
	 between template rules has generated a powerful XML query language:
	 eXtensible Style sheet Language Transformations (XSLT). An informal
	 introduction to XSTL is given, on the bases of which a formal model of a
	 fragment of XSLT is defined. This formal model is in the spirit of tree
	 transducers, and its semantics is defined by rewrite relations. It is shown
	 that the expressive power of the fragment is already beyond that
	 of most other XML query languages. Finally, important properties
	 such as termination and closure under composition are considered.}}

@inproceedings{BeyerCochrane.XQuery-for-Analytics.2004,
	Author = {Beyer, Kevin S. and Cochrane, Roberta and Colby, Latha S. and Ozcan, Fatma and Pirahesh, Hamid},
	Booktitle = {Proc. of Intl. Workshop on XQuery Implementation, Experience and Perspectives $<$XIME-P/$>$},
	Conference-Abbr = {XIME-P},
	Date-Modified = {2005-05-21 17:58:53 +0200},
	Keywords = {XQuery XML grouping analytics use cases group-by},
	Owner = {Tim Furche},
	Pages = {3-8},
	Pdf = {QueryEvaluation/XML/XQuery/Grouping/Beyer.Cochrane.ea_XQueryAnalytics-Challenges_XIME-P_2004.pdf},
	Title = {{XQuery for Analytics: Challenges and Requirements}},
	Url = {http://www-rocq.inria.fr/gemo/Gemo/Projects/XIME-P/CR/PDF/BeyerCR.pdf},
	Year = {2004},
	Abstract = {XML has emerged as the industry standard for
	 representing and exchanging data and is already predominant in several
	 applications today. Business, analytic, and structured data will
	 be exchanged as XML between applications and web services. XQuery
	 is a query language that is emerging as the standard for querying
	 XML data. The current version of the XQuery standard contains many
	 features for navigating the hierarchical and ordered content of XML
	 data. However, as compared to SQL, it lacks some key constructs which
	 makes it di cult to succinctly express and e ciently execute some
	 simple classes of analytic queries. In this paper, we describe some
	 of the limitations of the current XQuery language and argue that
	 extensions to XQuery are necessary to overcome these limitations.}}

@techreport{Boag.Chamberlin.ea_XQuery1.0-XML_TR_2005,
	Author = {Boag, Scott and Chamberlin, Don and Fern{\'a}ndez, Mary F. and Florescu, Daniela and Robie, Jonathan and Sim{\'e}on, J{\'e}r{\^o}me},
	Institution = {W3C},
	Keywords = {XML XQuery W3C Query Query Languages},
	Owner = {Tim Furche},
	Title = {{XQuery 1.0: An XML Query Language}},
	Type = {Working Draft},
	Url = {http://www.w3.org/TR/xquery/},
	Urldate = {2005/01/31},
	Year = {2005},
	Abstract = {XML is a versatile markup language, capable of
	 labeling the information content of diverse data sources including
	 structured and semi-structured documents, relational databases, and
	 object repositories. A query language that uses the structure of XML
	 intelligently can express queries across all these kinds of data,
	 whether physically stored in XML or viewed as XML via middleware. This
	 specification describes a query language called XQuery, which is
	 designed to be broadly applicable across many types of XML data sources.}}

@inproceedings{Boley_RuleMarkupLanguage_INAP_2001,
	Author = {Boley, Harold},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {Intl. Conf. on Applications of Prolog},
	Conference-Abbr = {INAP},
	Ee = {http://link.springer.de/link/service/series/0558/bibs/2543/25430005.htm},
	Keywords = {XML RDF RuleML data model integration role tags type tags},
	Pages = {5-22},
	Pdf = {SemanticWeb/RDF/RDF-XML-Integration/Boley_RuleMarkupLanguage_INAP_2001.pdf},
	Title = {{The Rule Markup Language: RDF-XML Data Model, XML Schema Hierarchy, and XSL Transformations}},
	Url = {http://iit-iti.nrc-cnrc.gc.ca/publications/nrc-47086_e.html},
	Year = {2001},
	Abstract = {Shared declarative aspects of Prolog and XML are
	 examined. An XML version of pure Prolog is shown to be at the center of
	 the Rule Markup Language. The RuleML data model uses Order-Labeled
	 trees, combining the RDF and XML models. As part of RuleMl's hierarchy
	 of sublanguages, the RuleML-Prolog DTD is employed for practical
	 XML-to-XML and XML-to-(X)HTML transformation of Prolog on the Web.}}

@mastersthesis{Bolzer_TowardsData-Integrationon_2005,
	Author = {Bolzer, Oliver},
	Date-Modified = {2006-03-06 17:26:05 +0100},
	Keywords = {XML Xcerpt RDF integration mediation views},
	Owner = {Tim Furche},
	School = {University of Munich},
	Title = {{Towards Data-Integration on the Semantic Web: Querying RDF with Xcerpt}},
	Type = {{Diplomarbeit/Master thesis}},
	Url = {http://www.pms.ifi.lmu.de/publikationen#DA_Oliver.Bolzer},
	Year = {2005}}

@talk{Bolzer_SemanticWebQuerying_SLIDES_2004,
	Author = {Bolzer, Oliver},
	Institution = {Institute for Computer Science, University of Munich, Germany},
	Keywords = {RDF Semantic Web Xcerpt Views},
	Owner = {Tim Furche},
	Pdf = {SemanticWeb/Xcerpt/Bolzer_SemanticWebQuerying_SLIDES_2004.pdf},
	Title = {{Semantic Web Querying Using Xcerpt}},
	Type = {Oberseminar ?Knowledge Representation and Markup Languages?},
	Year = {2004},
	Abstract = {Xcerpt is a declarative, rule-based query and transformation
	 language for XML and other semistructured data on the Web. This talk
	 investigates the suitability of Xcerpt and it's underlying formalisms
	 for querying and reasoning with both RDF and traditional XML data.}}

@techreport{Bolzer.Bry.ea_DevelopmentofUse_TR_2005,
	Author = {Bolzer, Oliver and Bry, Fran{\c c}ois and Furche, Tim and Kraus, Sebastian and Schaffert, Sebastian},
	Date-Modified = {2006-03-06 17:30:42 +0100},
	Institution = {REWERSE},
	Keywords = {REWERSE Query languages Use Cases Versatility Deliverable XML RDF},
	Number = {I4-D3},
	Owner = {Tim Furche},
	Title = {{Development of Use Cases, Part I: Illustrating the Functionality of a Versatile Web Query Language}},
	Type = {Deliverable},
	Url = {http://rewerse.net/publications.html#REWERSE-DEL-2005-I4-D3},
	Year = {2005}}

@inproceedings{Bonifati.Braga.ea_ActiveXQuery_ICDE_2002,
	Author = {Bonifati, Angela and Braga, Daniele and Campi, Alessandro and Ceri, Stefano},
	Booktitle = ICDE,
	Conference-Abbr = {ICDE},
	Keywords = {XML XQuery update reactivity active},
	Pages = {403},
	Pdf = {QueryEvaluation/XML/XQuery/Bonifati.Braga.ea_ActiveXQuery_ICDE_2002.pdf},
	Publisher = {IEEE Computer Society},
	Title = {{Active XQuery}},
	Url = {http://www.icar.cnr.it/angela/pubs/ICDE02.pdf},
	Year = {2002},
	Abstract = {Besides being adopted as the new interchange format for the Internet, XML is
	 finding increasing acceptance as a native data repository language. In
	 order to make XML repositories fully equipped with data management
	 capabilities, suitable query and update languages are being developed.
	 However, once the user is allowed to perform updates, it is perceivably
	 necessary to guarantee the correctness of his/her updates, especially if
	 document validity or semantic constraints are violated. We address this
	 problem by exploiting the well-grounded concept of active rules.In
	 this paper, we propose Active XQuery, an active language for XML
	 repositories that is based on a previously defined XQuery update model. In
	 particular, we present the syntax and semantics of our language, aiming at
	 emulating the trigger definition and execution model of SQL3. An
	 active extension of XQuery arises nontrivial problems, related to the
	 need of interleaving updates and triggers. These problems have led
	 us to define an algorithm for update reformulation and to devise a
	 compact semantics. In conclusion, the paper presents an architecture
	 for rapid prototyping, and hints optimization and research issues.}}

@talk{Brade_TowardsAbstractMachine_SLIDES_2004,
	Author = {Brade, Michael},
	Institution = {Institute for Computer Science, University of Munich, Germany},
	Keywords = {Abstract Machine Query Evaluation Logic Programming Xcerpt Simulation Unification},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/AbstractMachines/Xcerpt/Brade_TowardsAbstractMachine_SLIDES_2004.pdf},
	Title = {{Towards an Abstract Machine for Xcerpt?s Simulation Unification}},
	Type = {Oberseminar ?Knowledge Representation and Markup Languages?},
	Year = {2004},
	Abstract = {This talk presents first steps in the direction
	 of an abstract machine for the Simulation Unification in Xcerpt.}}

@inproceedings{Braga.Campi.ea_XQuerybyExample_WWW_2003,
	Author = {Braga, Daniele and Campi, Alessandro and Ceri, Stefano and Augurusa, Enrico},
	Booktitle = WWW,
	Conference-Abbr = {WWW},
	Keywords = {XML query languages visualization XML-GL XQuery XQBE},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Visualization/Braga.Campi.ea_XQuerybyExample_WWW_2003.pdf},
	Title = {{XQuery by Example}},
	Url = {http://www2003.org/cdrom/papers/poster/p291/p291-braga.html},
	Year = {2003},
	Abstract = {XQuery, the standard query language for XML, is gaining popularity
	 among users with a SQL background; indeed, formulating XQuery and
	 SQL queries requires comparable skills. However, this nucleus of
	 programmers is not vast, and the availability of simpler XQuery ``dialects"
	 could be valuable for establishing its success. With this motivation
	 in mind, we designed XQBE, a visual dialect of XQuery inspired by
	 QBE (Query by Example). QBE was initially proposed as alternative
	 to SQL and has gained popularity as the language supported by MS
	 Access, currently presented to users with a very limited experience of
	 query languages. Coherent with the XML data model, XQBE uses one
	 or more hierarchical structures to denote the input XML documents
	 and one structure to denote the output document. Similar to QBE,
	 structures are annotated to express selection predicates; explicit
	 bindings between these structures visualize the input/output mappings.}}

@inproceedings{Bremer.Gertz_XQuery-IR-IntegratingXML_WebDB_2002,
	Author = {Bremer, Jan-Marco and Gertz, Michael},
	Booktitle = {Proc. Intl. Workshop on the Web and Databases},
	Conference-Abbr = {WebDB},
	Keywords = {XML XQuery IR information retrieval ranking query languages},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/InformationRetrieval/Languages/Bremer.Gertz_XQuery-IR-IntegratingXML_WebDB_2002.pdf},
	Title = {{XQuery/IR: Integrating XML Document and Data Retrieval}},
	Url = {http://www.db.ucsd.edu/webdb2002/papers/57.pdf},
	Year = {2002}}

@book{Brundage_XQuery-XMLQuery_2004,
	Author = {Brundage, Michael},
	Keywords = {XML XQuery query languages},
	Owner = {Tim Furche},
	Publisher = {Addison-Wesley},
	Title = {{XQuery: The XML Query Language}},
	Year = {2004}}

@inproceedings{Bruno.Maitre.ea_ExtendingXQuerywith_DocEng_2003,
	Author = {Bruno, Emmanuel and Maitre, Jacques Le and Murisasco, Elisabeth},
	Booktitle = {Proc. ACM symposium on Document Engineering},
	Conference-Abbr = {DocEng},
	Date-Modified = {2005-05-21 18:05:17 +0200},
	Doi = {http://doi.acm.org/10.1145/958220.958223},
	Isbn = {1-58113-724-9},
	Keywords = {XML XQuery transformations document engineering query languages},
	Location = {Grenoble, France},
	Pages = {1--8},
	Pdf = {QueryEvaluation/XML/XQuery/LanguageConstructs/Bruno.Maitre.ea_ExtendingXQuerywith_DocEng_2003.pdf},
	Publisher = {ACM Press},
	Title = {{Extending XQuery with Transformation Operators}},
	Url = {http://www.univ-tln.fr/~lemaitre/doceng2003.pdf},
	Year = {2003},
	Abstract = {In this paper, we propose to extend XQuery - the
	 XML query language - with a set of transformation operators which
	 will produce a copy of an XML tree in which some subtrees will be
	 inserted, replaced or deleted. These operators - very similar to the
	 ones proposed for updating an XML document - greatly simplify the
	 expression of some queries in making it possible to express only
	 the modified part of a tree instead of its whole reconstruction. We
	 compare the expressivity of XQuery extended in this way with XSLT.}}

@article{Brusilovsky_AdaptiveHypermedia_UMUAI_2001,
	Author = {Brusilovsky, Peter},
	Journal = {User Modeling and User Adapted Interaction},
	Journal-Abbr = {UMUAI},
	Keywords = {Personalization Adaptive Hypermedia Adaptation},
	Number = {1/2},
	Owner = {Tim Furche},
	Pages = {87-110},
	Pdf = {ApplicationAreas/Personalization/Brusilovsky_AdaptiveHypermedia_UMUAI_2001.pdf},
	Title = {{Adaptive Hypermedia}},
	Url = {http://www2.sis.pitt.edu/~peterb/papers/brusilovsky-umuai-2001.pdf},
	Volume = {11},
	Year = {2001},
	Abstract = {Adaptive Systems use explicit user
	 models representing user knowledge, goals, interests, etc. that enable
	 them to tailor interaction to different users. Adaptive hypermedia
	 and AdaptiveWeb have used this paradigm to allow personalization in
	 hypertext systems and the WWW, with diverse applications ranging from
	 museum guides to web-based education. The goal of this chapter is
	 to present the history of adaptive hypermedia, introduce a number
	 of classic but popular techniques, and discuss emerging research
	 directions in the context of the Adaptive and Semantic Web, that
	 challenge the adaptive hypermedia researchers in the new Millennium.}}

@book{Brusilovsky_AdaptiveHyperTextand_1998,
	Author = {Brusilovsky, Peter and Kobsa, Alfred and Vassileva, Julita},
	Keywords = {Personalization Adaptation Adaptive Hypermedia},
	Owner = {Tim Furche},
	Publisher = {Kluwer Academic Publishers},
	Title = {{Adaptive HyperText and Hypermedia}},
	Url = {http://portal.acm.org/citation.cfm?id=551201&dl=ACM&coll=GUIDE},
	Year = {1998}}

@article{Brusilovsky.Maybury_FromAdaptiveHypermedia_CACM_2002,
	Author = {Brusilovsky, Peter and Maybury, Mark T.},
	Journal = {Communications of the ACM},
	Journal-Abbr = {CACM},
	Keywords = {Personalization Adaptive Hypermedia Adaptation},
	Number = {5},
	Owner = {Tim Furche},
	Pages = {30-33},
	Title = {{From Adaptive Hypermedia to the Adaptive Web}},
	Volume = {45},
	Year = {2002}}

@incollection{Brusilovsky.Nejdl_AdaptiveHypermediaand_2003,
	Author = {Brusilovsky, Peter and Nejdl, Wolfgang},
	Booktitle = {Practical Handbook of Internet Computing},
	Editor = {Munindar P. Singh},
	Keywords = {Personalization Web Adaptive Hypermedia Adaptation},
	Owner = {Tim Furche},
	Pdf = {ApplicationAreas/Personalization/Brusilovsky.Nejdl_AdaptiveHypermediaand_2003.pdf},
	Publisher = {CRC Press},
	Title = {{Adaptive Hypermedia and Adaptive Web}},
	Url = {http://www.kbs.uni-hannover.de/Arbeiten/Publikationen/2003/brusilovsky-nejdl.pdf},
	Year = {2003},
	Abstract = {Adaptive Systems use explicit user
	 models representing user knowledge, goals, interests, etc. that enable
	 them to tailor interaction to different users. Adaptive hypermedia
	 and AdaptiveWeb have used this paradigm to allow personalization in
	 hypertext systems and the WWW, with diverse applications ranging from
	 museum guides to web-based education. The goal of this chapter is
	 to present the history of adaptive hypermedia, introduce a number
	 of classic but popular techniques, and discuss emerging research
	 directions in the context of the Adaptive and Semantic Web, that
	 challenge the adaptive hypermedia researchers in the new Millennium.}}

@inproceedings{Bry.Coskun.ea_XMLStreamQuery_ICDE_2005,
	Author = {Bry, Fran{\c c}ois and Coskun, Fatih and Durmaz, Serap and Furche, Tim and Olteanu, Dan and Spannagel, Markus},
	Booktitle = ICDE,
	Conference-Abbr = {ICDE},
	Keywords = {Demo Streams Query Evaluation XPath XML REWERSE},
	Organization = {IEEE},
	Pdf = {QueryEvaluation/Streams/XPath/Bry.Coskun.ea_XMLStreamQuery_ICDE_2005.pdf},
	Title = {{The XML Stream Query Processor SPEX}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2005-1},
	Urldate = {2004/11/11},
	Year = {2005},
	Abstract = {Data streams (e.g., [Koudas and Srivastava, VLDB,
	 2003]) are an emerging technology for data dissemination in cases
	 where the data throughput or size make it unfeasible to rely on the
	 conventional approach based on storing the data before processing it. Areas
	 where data streams are applied include monitoring of scientific data
	 (astronomy, meteorology), control data (traffic, logistics, networks),
	 and financial data (bank transactions). Data streams are a new and
	 promising setting in which many conventional database methods have to
	 be considered anew. Querying XML data streams without storing and
	 without decreasing considerably the data throughput is especially
	 challenging because XML streams convey tree structured data with (possibly)
	 unbounded size and depth. SPEX, initially described in [Olteanu et
	 al., ICDE, 2002], evaluates XPath queries against XML data streams.
	 SPEX is built upon formal frameworks for (1) rewriting XPath queries
	 into equivalent XPath queries without reverse axes [Olteanu et al.,
	 EDBT-XMLDM, 2002] and (2) correct query evaluation with polynomial
	 combined complexity using networks of pushdown transducers [Olteanu
	 et al., SAC, 2004]. Such transducers are simple, independent, and
	 can be connected in a flexible manner, thus allowing not only easy
	 extensions but also extensive query optimization, e.g., by sharing
	 transducers. A reason for the latter is that processing new query constructs
	 implemented by new transducers does not affect the processing of
	 existing ones. As a proof of concept, SPEX is extended here with novel
	 compile-time optimizations that reduce both the size of the transducer
	 network and the processing of irrelevant stream fragments. SPEX is
	 demonstrated using a practically useful application for monitoring processes
	 running on UNIX systems, and a novel, sophisticated visualization
	 of its run-time system, called SPEX Viewer. SPEX Viewer makes it
	 possible to visualize (1) the step-by-step rewriting of XPath queries
	 into equivalent queries without reverse axes, (2) the networks of
	 pushdown transducers generated from such queries, (3) the incremental
	 processing of XML streams with these networks under various novel
	 optimization settings, and (4) the progressive generation of answers.}}

@inproceedings{Bry.Drabent.ea_OnSubtypingof_PPSWR_2004,
	Author = {Bry, Fran{\c c}ois and Drabent, W?odzimierz and Maluszynski, Jan},
	Booktitle = PPSWR # {, St. Malo, France},
	Conference-Abbr = {PPSWR},
	Keywords = {REWERSE Typing Query Languages},
	Organization = {REWERSE},
	Pdf = {SemanticWeb/REWERSE/Bry.Drabent.ea_OnSubtypingof_PPSWR_2004.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{On Subtyping of Tree-structured Data A Polynomial Approach}},
	Url = {http://rewerse.net/publications.html#REWERSE-RP-2004-11},
	Volume = {3208},
	Year = {2004},
	Abstract = {This paper discusses subtyping of
	 tree-structured data encountered on the Web, e.g. XML and HTML data. Our long
	 range objective is to de ne a type system for Web and/or Semantic Web
	 query languages amenable to static type checking. We propose a type
	 formalism motivated by XML Schema and accommodating two concepts of
	 subtyping: inclusion subtyping (corresponding to XML Schema notion of type
	 restriction) and extension subtyping (motivated by XML Schema's type
	 extension). We present algorithms for checking both kinds of subtyping. The
	 algorithms are polynomial if certain conditions are imposed on the type
	 de nitions; the conditions seem natural and not too restrictive.}}

@talk{Bry.Furche_SurveyoverQuery_SLIDES_2004,
	Author = {Bry, Fran{\c c}ois and Furche, Tim},
	Entrytype = {Principles underlying Xcerpt, a (Semantic) Web Query Language},
	Institution = {Institute for Computer Science, University of Munich, Germany},
	Keywords = {Design Query Languages Presentation REWERSE Survey},
	Owner = {Tim Furche},
	Pdf = {SemanticWeb/Xcerpt/Bry.Furche_SurveyoverQuery_SLIDES_2004.pdf},
	Title = {{Survey over Query Languages for the (Semantic) Web}},
	Type = {Oberseminar ?Knowledge Representation and Markup Languages?},
	Year = {2004},
	Abstract = {Proposal for a Classification Scheme and Exemplary Classifications}}

@article{Bry.Furche.ea_QueryingWebReconsidered_JSWIS_2005,
	Author = {Bry, Fran{\c c}ois and Furche, Tim and Badea, Liviu and Koch, Christoph and Schaffert, Sebastian and Berger, Sacha},
	Editor = {Tim Furche},
	Journal = {Journal of Semantic Web and Information Systems},
	Journal-Abbr = {JSWIS},
	Keywords = {Semantic Web Xcerpt Design Query Languages Vision Versatile Query Language REWERSE},
	Number = {2},
	Pdf = {QueryEvaluation/SemanticWeb/Bry.Furche.ea_QueryingWebReconsidered_JSWIS_2004.pdf},
	Title = {{Querying the Web Reconsidered: Design Principles for Versatile Web Query Languages}},
	Volume = {1},
	Year = {2005},
	Abstract = {A decade of experience with research proposals as well as standardized
	 query languages for the conventional Web and the recent emergence of
	 query languages for the Semantic Web call for a reconsideration of
	 design principles for Web and Semantic Web query languages. This
	 article first argues that a new generation of versatile Web query
	 languages is needed for solving the challenges posed by the changing
	 Web: We call versatile those query languages able to cope with both
	 Web and Semantic Web data expressed in any (Web or Semantic Web)
	 markup language. This article further suggests that (well-known)
	 referential transparency and (novel) answer-closedness are essential
	 features of versatile query languages. Indeed, they allow queries to be
	 considered like forms and answers like form-fillings in the spirit of the
	 ?query-by-example? paradigm. This article finally suggests that the
	 decentralized and heterogeneous nature of the Web requires incomplete
	 data specifications (or ?incomplete queries?) and incomplete data
	 selections (or ?incomplete answers?): the form-like query can be
	 specified without precise knowledge of the queried data and answers
	 can be restricted to contain only an excerpt of the queried data.}}

@techreport{Bry.Furche.ea_IdentificationofDesign_TR_2004,
	Author = {Bry, Fran{\c c}ois and Furche, Tim and Badea, Liviu and Koch, Christoph and Schaffert, Sebastian and Berger, Sacha},
	Date-Modified = {2006-03-06 17:23:38 +0100},
	Editor = {Tim Furche},
	Institution = {REWERSE},
	Keywords = {Semantic Web Xcerpt Design Query Languages REWERSE},
	Number = {I4-D2},
	Pdf = {QueryEvaluation/SemanticWeb/Bry.Furche.ea_IdentificationofDesign_TR_2004.pdf},
	Title = {{Identification of Design Principles}},
	Type = {Deliverable},
	Url = {http://rewerse.net/publications.html#REWERSE-DEL-2004-I4-D2},
	Urldate = {2004/11/11},
	Year = {2004},
	Abstract = {This report identifies those design principles
	 for a (possibly new) query and transformation language for the Web
	 supporting inference that are considered essential. Based upon these
	 design principles an initial strawman is selected. Scenarios for
	 querying the Semantic Web illustrate the design principles and their
	 reflection in the initial strawman, i.e., a first draft of the query
	 language to be designed and implemented by the REWERSE working group I4.}}

@article{Bry.Furche.ea_Datenstroeme_IS_2004,
	Author = {Bry, Fran{\c c}ois and Furche, Tim and Olteanu, Dan},
	Journal = {Informatik Spektrum},
	Journal-Abbr = {IS},
	Keywords = {Query Evaluation Streams XML REWERSE},
	Number = {2},
	Pdf = {QueryEvaluation/Streams/Bry.Furche.ea_Datenstroeme_IS_2004.pdf},
	Title = {{Datenstr{\"o}me}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2004-2},
	Urldate = {2004/11/11},
	Volume = {27},
	Year = {2004},
	Abstract = {Unter einem ?Datenstrom? versteht man kontinuierlich {\"u}bersandte Datenstze, deren
	 Gr{\"o}{\ss}e, Menge sowie schnelles Aufkommen verbieten, sie vor der
	 Verarbeitung zu speichern. Die bisherige Forschung hat in erster Linie zum
	 Ziel, Verfahren zu entwickeln, die es erlauben, ohne Verz{\"o}gerung
	 des Datenflusses (1) einen Strom auf das Vorkommen von bestimmten
	 Daten zu uberwachen und (2) die Daten aus einem Strom zu analysieren.
	 Dieser Artikel dient als kurze Einf{\"u}hrung {\"u}ber Merkmale und
	 aktuelle Forschungsergebnisse der Datenstr{\"o}menanfrage und -analyse.}}

@inproceedings{Bry.Furche.ea_DataRetrievaland_PPSWR_2004,
	Author = {Bry, Fran{\c c}ois and Furche, Tim and P?tr{\^a}njan, Paula-Lavinia and Schaffert, Sebastian},
	Booktitle = PPSWR,
	Conference-Abbr = {PPSWR},
	Keywords = {Web Semantic Web Xcerpt XChange REWERSE},
	Organization = {REWERSE},
	Pdf = {SemanticWeb/Xcerpt/Bry.Furche.ea_DataRetrievaland_PPSWR_2004.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{Data Retrieval and Evolution on the (Semantic) Web: A Deductive Approach}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2004-13},
	Urldate = {2004/11/11},
	Volume = {3208},
	Year = {2004},
	Abstract = {To make use of data represented on the Semantic Web, it is
	 necessary to provide languages for Web data retrieval and evolution. This
	 article introduces into the (conventional and Semantic) Web query
	 language Xcerpt and the event and update language XChange, and shows how
	 their deductive capabilities make them well suited for querying,
	 changing and reasoning with data on both the conventional and the
	 Semantic Web. To this aim, small application scenarios are introduced.}}

@talk{Bry.Furche.ea_DesignPrinciplesI4_SLIDES_2004,
	Author = {Bry, Fran{\c c}ois and Furche, Tim and Schaffert, Sebastian},
	Entrytype = {Principles underlying Xcerpt, a (Semantic) Web Query Language},
	Institution = {REWERSE Working Groups ?Reasoning-aware Querying? and ?Evolution and Reactivity?, Munich, Germany},
	Keywords = {Design Query Languages Xcerpt Presentation REWERSE},
	Owner = {Tim Furche},
	Pdf = {SemanticWeb/Xcerpt/Bry.Furche.ea_DesignPrinciplesI4_SLIDES_2004.pdf},
	Title = {{Design Principles for I4 Query Language}},
	Type = {Joint Workshop on Language Principles and State-of-the-Art},
	Year = {2004}}

@talk{Bry.Furche.ea_PrinciplesunderlyingXcerpt_SLIDES_2004,
	Author = {Bry, Fran{\c c}ois and Furche, Tim and Schaffert, Sebastian},
	Entrytype = {Principles underlying Xcerpt, a (Semantic) Web Query Language},
	Institution = {REWERSE Working Group ?Reasoning-aware Querying?, Vienna, Austria},
	Keywords = {Design Query Languages Xcerpt Presentation REWERSE},
	Owner = {Tim Furche},
	Pdf = {SemanticWeb/Xcerpt/Bry.Furche.ea_PrinciplesunderlyingXcerpt_SLIDES_2004.pdf},
	Title = {{Principles underlying Xcerpt, a (Semantic) Web Query Language}},
	Type = {Kickoff-Workshop},
	Year = {2004}}

@article{Bry.Nagel.ea_Grid-Computing_IS_2004,
	Author = {Bry, Fran{\c c}ois and Nagel, Wolfgang E. and Schroeder, Michael},
	Institution = {Institute of Informatics, University of Munich},
	Journal = {Informatik Spektrum},
	Journal-Abbr = {IS},
	Keywords = {REWERSE Grid},
	Number = {6},
	Pdf = {SemanticWeb/REWERSE/Bry.Nagel.ea_Grid-Computing_IS_2004.pdf},
	Title = {{Grid-Computing}},
	Type = {{Forschungsbericht/research report}},
	Url = {http://rewerse.net/publications.html#PMS-FB-2004-22},
	Volume = {27},
	Year = {2004},
	Abstract = {"Grid-Computing", ein Mitte der 90er Jahre eingef{\"u}hrter Begriff, bezeichnet eine
	 Architektur f{\"u}r verteilte Systeme, die auf dem World Wide Web
	 aufbaut und die Web-Vision erweitert. Mit dem Grid-Computing werden die
	 Ressourcen einer Gemeinschaft, einer sogenannten virtuellen Organisation
	 (siehe unten), integriert. Die Hoffnung ist, dass hierdurch rechen-
	 und/oder datenintensiven Aufgaben, die eine einzelne Organisation
	 nicht l{\"o}sen kann, handhabbar werden. Ein Grid bezeichnet eine
	 nach dem Grid-Computing-Ansatz aufgebaute Rechner-, Netzwerk- und
	 Software-Infrastruktur zur Teilung von Ressourcen mit dem Ziel, die Aufgaben einer
	 virtuellen Organisation zu erledigen. Zu Beginn war die M{\"o}glichkeit,
	 ungenutzte CPU-Ressourcen an anderen Stellen f{\"u}r die eigenen Aufgaben
	 einzusetzen, die wesentlich treibende Kraft f{\"u}r erste Experimente.
	 Internet-Computing-Projekte wie SETI@Home, distributed.net u.a., bei denen die
	 unbenutzten Rechenzyklen von weltweit verteilten privaten PCs verwendet
	 werden, illustrieren das Potential des Grid-Computing. Die heutigen
	 Grid-Konzepte und die ersten -Prototypen gehen weit {\"u}ber diese
	 Anfnge hinaus. Sie versprechen die transparente Bereitstellung von
	 Diensten unabhngig von der rumlichen Nhe. Es wird erwartet, dass das
	 Grid-Computing die Nutzung von Rechnern und Rechnernetzen so grundlegend
	 verndern wird, wie das Web den Datenaustausch bereits verndert hat.}}

@inproceedings{Bry.Patranjan_ReactivityonWeb_SAC_2005,
	Author = {Bry, Fran{\c c}ois and P?tr{\^a}njan, Paula-Lavinia},
	Booktitle = SAC,
	Conference-Abbr = {SAC},
	Keywords = {REWERSE Reactivity XChange},
	Organization = {ACM},
	Title = {{Reactivity on the Web: Paradigms and Applications of the Language XChange}},
	Url = {http://rewerse.net/publications.html#REWERSE-RP-2004-41},
	Year = {2005},
	Abstract = {Reactivity on the Web is an
	 emerging issue. It is essential for upcoming Web systems such as online
	 marketplaces, adaptive, Semantic Web systems as well as Web services and
	 Grids. This article first introduces the paradigms upon which the
	 high-level language XChange for programming reactive behaviour and
	 distributed applications on the Web relies. Then, it briefly presents
	 the main syntactical constructs of XChange. Finally, it sketches
	 the implementation in XChange of a reactive Web-based application.}}

@inproceedings{Bry.Patranjan.ea_XcerptandXChange_ICLP_2004,
	Author = {Bry, Fran{\c c}ois and P{\u a}tr{\^a}njan, Paula-Lavinia and Schaffert, Sebastian},
	Booktitle = ICLP,
	Conference-Abbr = {ICLP},
	Date-Modified = {2006-03-06 17:27:04 +0100},
	Keywords = {REWERSE Query Languages Reactivity Xcerpt XChange},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{Xcerpt and XChange: Logic Programming Languages for Querying and Evolution on the Web}},
	Url = {http://www.pms.ifi.lmu.de/publikationen#PMS-FB-2004-11},
	Year = {2004}}

@inproceedings{Bry.Schaffert_EntailmentRelationReasoning_RuleML_2003,
	Author = {Bry, Fran{\c c}ois and Schaffert, Sebastian},
	Booktitle = {Proc. Workshop on Rules and Rule Markup Languages for the Semantic Web},
	Conference-Abbr = {RuleML},
	Keywords = {Xcerpt Semantics Entailment Reasoning},
	Pdf = {SemanticWeb/Xcerpt/Bry.Schaffert_EntailmentRelationReasoning_RuleML_2003.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{An Entailment Relation for Reasoning on the Web}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2003-5},
	Volume = {2876},
	Year = {2003},
	Abstract = {Reasoning on the Web is receiving an increasing attention because
	 of emerging fields such as Web adaption and Semantic Web. Indeed,
	 the advanced functionalities striven for in these fields call for
	 reasoning capabilities. Reasoning on the Web, however, is usually done
	 using existing techniques rarely fitting the Web. As a consequence,
	 additional data processing like data conversion from Web formats (e.g. XML
	 or HTML) into some other formats (e.g. classical logic terms and
	 formulas) is often needed and aspects of the Web (e.g. its inherent
	 inconsistency) are neglected. This article first gives requirements
	 for an entailment tuned to reasoning on the Web. Then, it describes
	 how classical logic's entailment can be modified so as to enforce
	 these requirements. Finally, it discusses how the proposed entailment
	 can be used in applying logic programming to reasoning on the Web.}}

@inproceedings{Bry.Schaffert_GentleIntroductioninto_RuleML-WS_2002,
	Author = {Bry, Fran{\c c}ois and Schaffert, Sebastian},
	Booktitle = {Proc. Intl. Workshop on Rule Markup Languages for Business Rules on the Semantic Web},
	Conference-Abbr = {RuleML-WS},
	Keywords = {XML Xcerpt introduction query languages},
	Pdf = {QueryEvaluation/Xcerpt/Bry.Schaffert_GentleIntroductioninto_RuleML-WS_2002.pdf},
	Title = {{A Gentle Introduction into Xcerpt, a Rule-based Query and Transformation Language for XML}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2002-11},
	Year = {2002},
	Abstract = {This articles introduces into Xcerpt, a rule-based query and transformation language
	 for XML. First, the design principles of Xcerpt are given. Then,
	 the essential construct of Xcerpt are explained and illustrated on
	 examples: "query terms", i.e. patterns using which Xcerpt queries are
	 posed, "construct terms", i.e. pattern re-assembling the data selected
	 in a query term into a new data item, and "construct-query rule"
	 linking queries with construct terms. Then, Xcerpt and XQuery are
	 compared on examples and the advantages of Xcerpt are discussed.
	 Finally, an outlook into Xcerpt's declarative and procedural semantics
	 as well as into Xcerpt's features currently developed are given.}}

@inproceedings{Bry.Schaffert_TowardsDeclarativeQuery_ICLP_2002,
	Author = {Bry, Fran{\c c}ois and Schaffert, Sebastian},
	Booktitle = ICLP,
	Conference-Abbr = {ICLP},
	Date-Modified = {2006-03-06 17:47:44 +0100},
	Keywords = {Xcerpt Query Languages XML},
	Pdf = {SemanticWeb/Xcerpt/Bry.Schaffert_TowardsDeclarativeQuery_ICLP_2002.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{Towards a Declarative Query and Transformation Language for XML and Semistructured Data: Simulation Unification}},
	Url = {http://www.pms.ifi.lmu.de/publikationen#PMS-FB-2002-19},
	Volume = {2401},
	Year = {2002},
	Abstract = {The growing importance of XML as a
	 data interchange standard demands languages for data querying and
	 transformation. Since the mid 90es, several such languages have been
	 proposed that are inspired from functional languages (such as XSLT)
	 and/or database query languages (such as XQuery). This paper addresses
	 applying logic programming concepts and techniques to designing a
	 declarative, rule-based query and transformation language for XML
	 and semistructured data.The paper first introduces issues specific
	 to XML and semistructured data such as the necessity of flexible
	 "query terms" and of "construct terms". Then, it is argued that logic
	 programming concepts are particularly appropriate for a declarative
	 query and transformation language for XML and semistructured data.
	 Finally, a new form of unification, called "simulation unification", is
	 proposed for answering "query terms", and it is illustrated on examples.}}

@inproceedings{Bry.Schaffert_XMLQueryLanguage_GI-WebDB_2002,
	Author = {Bry, Fran{\c c}ois and Schaffert, Sebastian},
	Booktitle = {Proc. Intl. Workshop on Web and Databases},
	Conference-Abbr = {GI-WebDB},
	Date-Modified = {2006-03-06 17:47:17 +0100},
	Keywords = {XML Xcerpt principles query languages},
	Pdf = {QueryEvaluation/Xcerpt/Bry.Schaffert_XMLQueryLanguage_GI-WebDB_2002.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{The XML Query Language Xcerpt: Design Principles, Examples, and Semantics}},
	Url = {http://www.pms.ifi.lmu.de/publikationen#PMS-FB-2002-7},
	Volume = {2593},
	Year = {2002},
	Abstract = {Most query and transformation languages developed since the mid 90es for XML and
	 semistructured data -- e.g. XQuery, the precursors of XQuery, and XSLT --
	 build upon a path-oriented node selection: A node in a data item is
	 specified in terms of a root-to-node path in the manner of the file
	 selection languages of operating systems. Constructs inspired from the
	 regular expression constructs *, +, ?, and "wildcards" give rise to a
	 flexible node retrieval from incompletely specified data items.This
	 paper further introduces into Xcerpt, a query and transformation
	 language further developing an alternative approach to querying XML
	 and semistructured data first introduced with the language UnQL. A
	 metaphor for this approach views queries as patterns, answers as
	 data items matching the queries. Formally, an answer to a query is
	 defined as a simulation of an instance of the query in a data item.}}

@inproceedings{Bry.Schaffert.ea_XcerptandXChange_SWSDN_2004,
	Author = {Bry, Fran{\c c}ois and Schaffert, Sebastian and P?tr{\^a}njan, Paula-Lavinia},
	Booktitle = {Proc. Workshop on Semantic Web Services and Dynamic Networks},
	Conference-Abbr = {SWSDN},
	Keywords = {REWERSE Xcerpt XChange Query Languages Reactivity},
	Organization = {GI},
	Pdf = {SemanticWeb/REWERSE/Bry.Schaffert.ea_XcerptandXChange_SWSDN_2004.pdf},
	Title = {{Xcerpt and XChange: Deductive Languages for Data Retrieval and Evolution on the Web}},
	Url = {http://rewerse.net/publications.html#REWERSE-RP-2004-21},
	Year = {2004},
	Abstract = {In this article, two deductive languages are introduced: the language Xcerpt, for querying
	 data and reasoning with data on the (Semantic) Web, and the language
	 XChange, for evolution and reactivity on the (Semantic) Web. A small
	 application scenario is given as a motivation for these languages.}}

@inproceedings{Bry.Schaffert.ea_contributiontoSemantics_WLP_2004,
	Author = {Bry, Fran{\c c}ois and Schaffert, Sebastian and Schr{\"o}der, Andreas},
	Booktitle = {Proc. Workshop on (Constraint) Logic Programming},
	Conference-Abbr = {WLP},
	Keywords = {REWERSE Query Evaluation Xcerpt Semantics},
	Organization = {GLP, GI},
	Pdf = {SemanticWeb/REWERSE/Bry.Schaffert.ea_contributiontoSemantics_WLP_2004.pdf},
	Title = {{A contribution to the Semantics of Xcerpt, a Web Query and Transformation Language}},
	Url = {http://rewerse.net/publications.html#REWERSE-RP-2004-18},
	Year = {2004},
	Abstract = {Xcerpt is a declarative and pattern-based query and transformation
	 language for the Web with deductive capabilities. In contrast to
	 Web query languages like XQuery and XSLT, Xcerpt relies on concepts
	 and techniques from logic programming and automated theorem proving
	 such as declarative ?query patterns? and ?rule chaining?. Xcerpt can
	 also be used for querying Web metadata, like OWL or RDF data, and
	 reasoning on such metadata. In contrast to specific languages for OWL and
	 RDF, however, Xcerpt is a general purpose query, transformation, and
	 reasoning language, i.e. it can be used for reasoning not only with Web
	 metadata but also with plain Web data. Salient aspects of Xcerpt
	 are its nonstandard ?query patterns? for retrieving incompletely
	 specified data and its unusual ?grouping constructs? some and all that
	 significantly depart from the standard approaches in logic programming
	 or automated theorem proving. Xcerpt relies on a new, assymmetric
	 unification, called simulation unification for evaluating query patterns
	 that incompletely specify data. Furthermore, Xcerpt does not rely on
	 meta reasoning for expressing and processing ?grouping? constructs
	 corresponding to Prolog?s metalevel predicates setof and bagof. This article
	 gives a brief overview over challenges of applying logic programming
	 techniques to Web querying. In particular it suggests two different
	 approaches for treating the meta-level grouping constructs all and some in
	 a proof calculus formalising the operational semantics of Xcerpt.}}

@inproceedings{Bry.Spranger_TowardsMulti-CalendarTemporal_PPSWR_2004,
	Author = {Bry, Fran{\c c}ois and Spranger, Stephanie},
	Booktitle = PPSWR,
	Conference-Abbr = {PPSWR},
	Keywords = {REWERSE Xcerpt CATTS Temporal Reasoning},
	Organization = {REWERSE},
	Pdf = {SemanticWeb/REWERSE/Bry.Spranger_TowardsMulti-CalendarTemporal_PPSWR_2004.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{Towards a Multi-Calendar Temporal Type System for (Semantic) Web Query Languages}},
	Url = {http://rewerse.net/publications.html#REWERSE-RP-2004-19},
	Volume = {3208},
	Year = {2004},
	Abstract = {Time is omnipresent on the (Semantic) Web. However, for- malism like XML, XML
	 Schema, RDF, OWL and (Semantic) Web query languages have, if any, only
	 very limited notions of temporal data types and temporal theories
	 built-in. Recently, the development of Web Ser- vices for temporal
	 operations has begun. In this article, we describe a connection,
	 possibly the rst one, between such Web Services and Web formalisms: A
	 proposal of a type system for temporal and calendric data, called
	 multi-calendar temporal type system seamlessly integrated into a
	 host (query) language. The type system's associated type checking
	 meth- ods are beyond the scope of this article. For proof-of-concept
	 purposes, the Web and Semantic Web query language Xcerpt has been chosen.}}

@inproceedings{Buneman.Semistructured-data.1997,
	Author = {Buneman, Peter},
	Booktitle = {Proc. ACM Symposium on Principles of Database Systems},
	Conference-Abbr = {PODS},
	Date-Modified = {2005-04-12 21:38:08 +0200},
	Doi = {http://doi.acm.org/10.1145/263661.263675},
	Isbn = {0-89791-910-6},
	Location = {Tucson, Arizona, United States},
	Pages = {117--121},
	Publisher = {ACM Press},
	Title = {{Semistructured Data}},
	Year = {1997}}

@inproceedings{Buneman.Davidson.ea_QueryLanguageand_SIGMOD_1996,
	Author = {Buneman, Peter and Davidson, Susan and Hillebrand, Gerd and Suciu, Dan},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Doi = {http://doi.acm.org/10.1145/233269.233368},
	Isbn = {0-89791-794-4},
	Keywords = {XML query languages UnQL},
	Location = {Montreal, Quebec, Canada},
	Pages = {505--516},
	Pdf = {QueryEvaluation/XML/Buneman.Davidson.ea_QueryLanguageand_SIGMOD_1996.pdf},
	Publisher = {ACM Press},
	Title = {{A Query Language and Optimization Techniques for Unstructured Data}},
	Url = {http://www.cs.washington.edu/homes/suciu/camera-ready-final.ps},
	Year = {1996},
	Abstract = {A new kind of data model has recently emerged in which the
	 database is not constrained by a conventional schema. Systems like
	 ACeDB, which has become very popular with biologists, and the recent
	 Tsimmis proposal for data integration organize data in tree-like
	 structures whose components can be used equally well to represent
	 sets and tuples. Such structures allow great flexibility y in data
	 representation.What query language is appropriate for such structures? Here we
	 propose a simple language UnQL for querying data organized as a rooted,
	 edge-labeled graph. In this model, relational data may be represented
	 as fixed-depth trees, and on such trees UnQL is equivalent to the
	 relational algebra. The novelty of UnQL consists in its programming
	 constructs for arbitrarily deep data and for cyclic structures. While
	 strictly more powerful than query languages with path expressions
	 like XSQL, UnQL can still be efficiently evaluated. We describe new
	 optimization techniques for the deep or "vertical" dimension of UnQL
	 queries. Furthermore, we show that known optimization techniques for
	 operators on flat relations apply to the "horizontal" dimension of UnQL.}}

@inproceedings{Buneman.Davidson.ea_ProgrammingConstructsUnstructured_DBLP_1996,
	Author = {Buneman, Peter and Davidson, Susan B. and Suciu, Dan},
	Booktitle = {Proc. Intl. Workshop on Database Programming Languages},
	Conference-Abbr = {DBLP},
	Isbn = {3-540-76086-5},
	Keywords = {XML query languages UnQL structural recursion},
	Pages = {12},
	Pdf = {QueryEvaluation/XML/Buneman.Davidson.ea_ProgrammingConstructsUnstructured_DBLP_1996.pdf},
	Publisher = {Springer-Verlag},
	Title = {{Programming Constructs for Unstructured Data}},
	Url = {http://www.cs.washington.edu/homes/suciu/file32_paper.ps},
	Year = {1996}}

@techreport{BuxtonRys.XQuery-and-XPath-Ful.2003,
	Author = {Buxton, Stephen and Rys, Michael},
	Date-Added = {2005-04-30 22:26:07 +0200},
	Date-Modified = {2005-04-30 22:31:13 +0200},
	Institution = {W3C},
	Keywords = {XML XQuery full-text information retrieval requirements},
	Title = {{XQuery and XPath Full-Text Requirements}},
	Type = {Working Draft},
	Url = {http://www.w3.org/TR/xquery-full-text-requirements/},
	Year = {2003},
	Abstract = {The document specifies requirements
	 for Full-Text search for use in XQuery [XQuery] and XPath [XPath].}}

@inproceedings{Calvanese.Giacomo.ea_ContainmentofConjunctive_KR_2000,
	Author = {Calvanese, Diego and Giacomo, Giuseppe De and Lenzerini, Maurizio and Vardi, Moshe Y.},
	Booktitle = {Proc. Intl. Conf. on the Principles of Knowledge Representation and Reasoning},
	Conference-Abbr = {KR},
	Keywords = {query processing containment path expressions inverse conjunctive},
	Pages = {176--185},
	Pdf = {QueryEvaluation/Languages/Calvanese.Giacomo.ea_ContainmentofConjunctive_KR_2000.pdf},
	Title = {{Containment of Conjunctive Regular Path Queries with Inverse}},
	Url = {http://www.inf.unibz.it/%7ecalvanese/papers/calv-degi-lenz-vard-KR-2000.ps.gz},
	Year = {2000},
	Abstract = {Reasoning on queries is
	 a basic problem both in knowledge representation and databases. A
	 fundamental form of reasoning on queries is checking containment, i.e.,
	 verifying whether one query yields necessarily a subset of the result of
	 another query. Query containment is crucial in several contexts,
	 such as query optimization, knowledge base verification, information
	 integration, database integrity checking, and cooperative answering.
	 In this paper we address the problem of query containment in the
	 context of semistructured knowledge bases, where the basic querying
	 mechanism, namely regular path queries, asks for all pairs of objects
	 that are connected by a path conforming to a regular expression.
	 We consider conjunctive regular path queries with inverse, which
	 extend regular path queries with the possibility of using both the
	 inverse of binary relations, and conjunctions of atoms, where each atom
	 specifies that one regular path query with inverse holds between
	 two variables. We present a novel technique to check containment of
	 queries in this class, based on the use of two-way finite automata. The
	 technique shows the power of two-way automata in dealing with the inverse
	 operator and with the variables in the queries. We also characterize the
	 computational complexity of both the proposed algorithm and the problem.}}

@inproceedings{Calvanese.Giacomo.ea_QueryProcessingusing_PODS_2000,
	Author = {Calvanese, Diego and Giacomo, Giuseppe De and Lenzerini, Maurizio and Vardi, Moshe Y.},
	Booktitle = PODS,
	Conference-Abbr = {PODS},
	Keywords = {conjunctive queries query languages regular path expressions inverse views optimization},
	Pages = {58--66},
	Pdf = {QueryEvaluation/Languages/Calvanese.Giacomo.ea_QueryProcessingusing_PODS_2000.pdf},
	Title = {{Query Processing using Views for Regular Path Queries with Inverse}},
	Url = {http://www.inf.unibz.it/%7ecalvanese/papers/calv-degi-lenz-vard-PODS-2000.ps.gz},
	Year = {2000},
	Abstract = {Query processing using views is the problem of
	 computing the answer to a query based on a set of materialized views,
	 rather than on the raw data in the database. The problem comes in
	 two different forms, called query rewriting and query answering,
	 respectively. In the first form, we are given a query and a set of view
	 definitions, and the goal is to reformulate the query into an expression
	 that refers only to the views. In the second form, besides the query
	 and the view definitions, we are also given the extensions of the
	 views and a tuple, and the goal is to check whether the knowledge on
	 the view extensions logically implies that the tuple satisfies the
	 query. In this paper we address the problem of query processing using
	 views in the context of semistructured data, in particular for the
	 case of regular path queries extended with the inverse operator.
	 Several authors point out that the inverse operator is one of the
	 fundamental extensions for making regular path queries useful in real
	 settings. We present a novel technique based on the use of two-way finite
	 automata. Our approach demonstrates the power of this kind of automata in
	 dealing with the inverse operator, allowing us to show that both query
	 rewriting and query answering with the inverse operator has the same
	 computational complexity as for the case of standard regular path queries.}}

@article{Cardelli.Ghelli_TQL-QueryLanguage_MSCS_2004,
	Author = {Cardelli, Luca and Ghelli, Giorgio},
	Doi = {http://dx.doi.org/10.1017/S0960129504004141},
	Issn = {0960-1295},
	Journal = {Mathematical Structures in Computer Science},
	Journal-Abbr = {MSCS},
	Keywords = {XML query languages TQL ambient logic pattern path TQL},
	Number = {3},
	Pages = {285--327},
	Pdf = {QueryEvaluation/XML/LogicProgrammingApproaches/Cardelli.Ghelli_TQL-QueryLanguage_MSCS_2004.pdf},
	Publisher = {Cambridge University Press},
	Title = {{TQL: a Query Language for Semistructured Data based on the Ambient Logic}},
	Url = {http://research.microsoft.com/Users/luca/Papers/A%20Query%20Language%20Based%20on%20the%20Ambient%20Logic%20MSCS.A4.pdf},
	Volume = {14},
	Year = {2004},
	Abstract = {The ambient logic is a modal
	 logic that was proposed for the description of the structural and
	 computational properties of distributed and mobile computation. The
	 structural part of the ambient logic is, essentially, a logic of
	 labelled trees, hence it turns out to be a good foundation for query
	 languages for semistructured data, much in the same way as first-order
	 logic is a fitting foundation for relational query languages. We
	 define here a query language for semistructured data that is based
	 on the ambient logic, and we outline an execution model for this
	 language. The language turns out to be quite expressive. Its strong
	 foundations and the equivalences that hold in the ambient logic are helpful
	 in the definition of the language semantics and execution model.}}

@inproceedings{Cardelli.Gordon_AnytimeAnywhere-Modal_POPL_2000,
	Author = {Cardelli, Luca and Gordon, Andrew D.},
	Booktitle = {Proc. Symposium on Principles of Programming Languages},
	Conference-Abbr = {POPL},
	Doi = {http://doi.acm.org/10.1145/325694.325742},
	Isbn = {1-58113-125-9},
	Keywords = {XML query languages ambient logic pattern TQL},
	Location = {Boston, MA, USA},
	Pages = {365--377},
	Pdf = {QueryEvaluation/XML/Cardelli.Gordon_AnytimeAnywhere-Modal_POPL_2000.pdf},
	Publisher = {ACM Press},
	Title = {{Anytime, Anywhere: Modal Logics for Mobile Ambients}},
	Url = {http://research.microsoft.com/~adg/Talks/990506-logic.pdf},
	Year = {2000},
	Abstract = {The Ambient Calculus is a process calculus where processes may
	 reside within a hierarchy of locations and modify it. The purpose of
	 the calculus is to study mobility, which is seen as the change of
	 spatial configurations over time. In order to describe properties
	 of mobile computations we devise a modal logic that can talk about
	 space as well as time, and that has the Ambient Calculus as a model.}}

@inproceedings{Ceri.Comai.ea_XML-GL-GraphicalLanguage_WWW_1999,
	Author = {Ceri, Stefano and Comai, Sara and Damiani, Ernesto and Fraternali, Piero and Paraboschi, Stefano and Tanca, Letizia},
	Booktitle = WWW,
	Conference-Abbr = {WWW},
	Keywords = {XML query languages XML-GL visual visualization},
	Owner = {Tim Furche},
	Title = {{XML-GL: a Graphical Language for Querying and Restructuring XML Documents}},
	Url = {http://www8.org/w8-papers/1c-xml/xml-gl/xml-gl.html},
	Year = {1999},
	Abstract = {The widespreading of XML as a standard for
	 semi-structured documents on the Web opens up challenging opportunities for
	 Web query languages. In this paper we introduce XML-GL, a graphical
	 query language for XML documents. The use of a visual formalism for
	 representing both the content of XML documents (and of their DTDs) and the
	 syntax and semantics of queries enables an intuitive expression of
	 queries, even when they are rather complex. XML-GL is inspired by
	 G-log, a general purpose, logic-based language for querying structured
	 and semi-structured data. The paper presents the basic capabilities
	 of XML-GL through a sequence of examples of increasing complexity.}}

@inproceedings{Ceri.Comai.ea_XML-GL-GraphicalLanguage_QL98_1998,
	Author = {Ceri, Stefano and Comai, Sara and Damiani, Ernesto and Fraternali, Piero and Paraboschi, Stefano and Tanca:, Letizia},
	Booktitle = PROC # {W3C QL'98 -- Query Languages},
	Conference-Abbr = {QL98},
	Keywords = {XML query languages visual},
	Owner = {Tim Furche},
	Title = {{XML-GL: A Graphical Language for Querying and Reshaping XML Documents}},
	Url = {http://www.w3.org/TandS/QL/QL98/pp/xml-gl.html},
	Year = {1998},
	Abstract = {We present XML-GL, a graphical query language for XML documents. XML-GL derives
	 from GLog a general purpose, logic- and graph-based language for
	 querying structured and semi-structured data. Here we list a number of
	 interesting requirements for a query language for XML documents, and
	 give a few examples of XML-GL features addressing such requirements.}}

@techreport{Chamberlin.Frankhauser.ea_XMLQueryUse_TR_2005,
	Author = {Chamberlin, Don and Frankhauser, Peter and Florescu, Daniela and Marchiori, Massimo and Robie, Jonathan},
	Institution = {W3C},
	Keywords = {XML XQuery Use Cases W3C Query Query Languages},
	Owner = {Tim Furche},
	Title = {{XML Query Use Cases}},
	Type = {Working Draft},
	Url = {http://www.w3.org/TR/xquery-use-cases/},
	Urldate = {2005/01/31},
	Year = {2005}}

@techreport{Chamberlin.Frankhauser.ea_XMLQueryUse_TR_2001,
	Author = {Chamberlin, Don and Frankhauser, Peter and Marchiori, Massimo and Robie, Jonathan},
	Institution = {W3C},
	Keywords = {XML XQuery Use Cases W3C Query Query Languages},
	Owner = {Tim Furche},
	Title = {{XML Query Use Cases}},
	Type = {Working Draft},
	Url = {http://www.w3.org/TR/2001/WD-xmlquery-use-cases-20010215},
	Urldate = {2005/01/31},
	Year = {2001}}

@techreport{Chamberlin.Robie_XQueryUpdateFacility_TR_2005,
	Author = {Chamberlin, Don and Robie, Jonathan},
	Institution = {W3C},
	Keywords = {XML XQuery update reactivity requirements},
	Owner = {Tim Furche},
	Title = {{XQuery Update Facility Requirements}},
	Type = {Working Draft},
	Url = {http://www.w3.org/TR/xquery-update-requirements/},
	Year = {2005},
	Abstract = {This document specifies goals and requirements for the XQuery Update Facility.}}

@inproceedings{Chen.Rundensteiner_ACE-XQ-CachE-awareXQuery_WebDB_2002,
	Author = {Chen, L. and Rundensteiner, E. A.},
	Booktitle = PROC # {Workshop on the Web and Databases},
	Conference-Abbr = {WebDB},
	Keywords = {XML XQuery views processing evaluation},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XQuery/Chen.Rundensteiner_ACE-XQ-CachE-awareXQuery_WebDB_2002.pdf},
	Title = {{ACE-XQ: A CachE-aware XQuery Answering System}},
	Url = {http://www.cs.wpi.edu/~lichen/papers/webdb02-acexq.ps},
	Year = {2002}}

@inproceedings{Chen.Jagadish.ea_FromTreePatterns_VLDB_2003,
	Author = {Chen, Zhimin and Jagadish, H. V. and Lakshmanan, Laks V.S. and Paparizos, Stelios},
	Booktitle = VLDB,
	Conference-Abbr = {VLDB},
	Keywords = {XML XQuery optimization generalized tree patterns nested queries},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XQuery/Chen.Jagadish.ea_FromTreePatterns_VLDB_2003.pdf},
	Title = {{From Tree Patterns to Generalized Tree Patterns: On Efficient Evaluation of XQuery}},
	Url = {http://www.vldb.org/conf/2003/papers/S08P03.pdf},
	Year = {2003},
	Abstract = {XQuery is the de facto standard XML
	 query language, and it is important to have e cient query evaluation
	 techniques available for it. A core operation in the evaluation of XQuery
	 is the nding of matches for speci ed tree patterns, and there has
	 been much work towards algorithms for nding such matches e ciently.
	 Multiple XPath expressions can be evaluated by computing one or more
	 tree pattern matches. However, relatively little has been done on
	 e - cient evaluation of XQuery queries as a whole. In this paper,
	 we argue that there is much more to XQuery evaluation than a tree
	 pattern match. We propose a structure called generalized tree pat-
	 tern (GTP) for concise representation of a whole XQuery expression.
	 Evaluating the query reduces to nding matches for its GTP. Using this
	 idea we develop e cient evaluation plans for XQuery expressions,
	 possibly involving join, quanti ers, grouping, aggregation, and nesting.
	 XML data often conforms to a schema. We show that using relevant
	 constraints from the schema, one can optimize queries signi cantly, and
	 give algorithms for automatically inferring GTP simpli cations given
	 a schema. Finally, we show, through a detailed set of experiments
	 using the TIMBER XML database system, that plans via GTPs (with or
	 without schema knowledge) signi cantly outperform plans based on
	 navigation and straightforward plans obtained directly from the query.}}

@article{Chinenyanga.Kushmerick_ExpressiveandEfficient_JIST_2002,
	Author = {Chinenyanga, Taurai Tapiwa and Kushmerick, Nicholas},
	Journal = {Journal of the American Society for Information Science and Technology},
	Journal-Abbr = {JIST},
	Keywords = {XML IR information retrieval ranking query languages},
	Number = {6},
	Owner = {Tim Furche},
	Pages = {438--453},
	Title = {{An Expressive and Efficient Language for XML Information Retrieval}},
	Volume = {53},
	Year = {2002},
	Abstract = {Several languages for querying and
	 transforming XML, including XML-QL, Quilt, and XQL, have been proposed.
	 However, these languages do not support ranked queries based on textual
	 similarity, in the spirit of traditional IR. Several extensions to
	 these XML query languages to support keyword search have been made,
	 but the resulting languages cannot express IR-style queries such as
	 "find books and CDs with similar titles." In some of these languages
	 keywords are used merely as boolean filters without support for true
	 ranked retrieval; others permit similarity calculations only between a
	 data value and a constant, and thus cannot express the above query.
	 WHIRL avoids both problems, but assumes relational data. We propose
	 ELIXIR, an expressive and efficient language for XML information
	 retrieval that extends XML-QL with a textual similarity operator
	 that can be used for similarity joins, so ELIXIR is sufficiently
	 expressive to handle the sample query above. ELIXIR thus qualifies as a
	 general-purpose XML IR query language. Our central contribution is an efficient
	 algorithm for answering ELIXIR queries that rewrites the original
	 ELIXIR query into a series of XML-QL queries to generate intermediate
	 relational data, and uses WHIRL to efficiently evaluate the similarity
	 operators on this intermediate data, yielding an XML document with
	 nodes ranked by similarity. Our experiments demonstrate that our
	 prototype scales well with the size of the query and the XML data.}}

@techreport{Clark_RDFDataAccess_TR_2004,
	Author = {Clark, Kendall Grant},
	Institution = {W3C},
	Keywords = {RDF Data Access Use Cases W3C Query Query Languages Requirements},
	Owner = {Tim Furche},
	Title = {{RDF Data Access Use Cases and Requirements}},
	Type = {Working Draft},
	Url = {http://www.w3.org/TR/rdf-dawg-uc/},
	Urldate = {2005/01/31},
	Year = {2004},
	Abstract = {This document specifies use cases, requirements, and objectives for
	 an RDF query language and data access protocol. It suggests how an
	 RDF query language and data access protocol could be used in the
	 construction of novel, useful Semantic Web applications in areas like web
	 publishing, personal information management, transportation, and tourism.}}

@inproceedings{Coelho.Florido_Type-basedXMLProcessing_PADL_2003,
	Author = {Coelho, Jorge and Florido, M.},
	Booktitle = {Proc. Intl. Symp. on Practical Aspects of Declarative Languages (PADL), New Orleans, Louisiana, USA},
	Comment = {READ},
	Conference-Abbr = {PADL},
	Keywords = {XML Query Evaluation Logic Programming Typing},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/LogicProgrammingApproaches/Coelho.Florido_Type-basedXMLProcessing_PADL_2003.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{Type-based XML Processing in Logic Programming}},
	Url = {http://www.dei.isep.ipp.pt/~jcoelho/x-prolog/padl03.pdf},
	Urldate = {2004/11/17},
	Volume = {2562},
	Year = {2003},
	Abstract = {In this paper we propose a type-based framework for using
	 logic programming for XML processing. We transform XML documents into
	 terms and DTDs into regular types. We implemented a standard type
	 inference algorithm for logic programs and use the types corresponding to
	 the DTDs as additional type declarations for logic programs for XML
	 processing. Due to the correctness of the type inference this makes it
	 possible to use logic programs as an implicitly typed processing
	 language for XML with static type (in this case DTDs) validation.
	 As far as we know this is the first work adding type validation at
	 compile time to the use of logic programming for XML processing.}}

@inproceedings{Coelho.Florido_CLPFlex-ConstraintLogic_ODBASE_2004,
	Author = {Coelho, Jorge and Florido, M{\'a}rio},
	Booktitle = ODBASE,
	Conference-Abbr = {ODBASE},
	Keywords = {XML Query languages Prolog Logic Programming Constraint Programming},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/LogicProgrammingApproaches/Coelho.Florido_CLP(Flex)-ConstraintLogic_ODBASE_2004.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{CLP(Flex): Constraint Logic Programming Applied to XML Processing}},
	Url = {http://www.ncc.up.pt/~jcoelho/clpflex.pdf},
	Volume = {3291},
	Year = {2004},
	Abstract = {In this paper we present
	 an implementation of a constraint solving module, CLP(Flex), for
	 dealing with unification in an equality theory for terms with flexible
	 arity function symbols. Then we present an application of CLP(Flex)
	 to XML-processing where XML documents are abstracted by terms with
	 flexible arity symbols. This gives a highly declarative model for XML
	 processing yielding a substantial degree of flexibility in programming.}}

@article{Cohen.Kanza.ea_EquiX-asearchand_JASIST_2002,
	Author = {Cohen, Sara and Kanza, Yaron and Kogan, Yakov and Sagiv, Yehoshua and Nutt, Werner and Serebrenik, Alexander},
	Doi = {http://dx.doi.org/10.1002/asi.10058},
	Issn = {1532-2882},
	Journal = {Journal of the American Society for Information Science and Technology},
	Journal-Abbr = {JASIST},
	Keywords = {XML query languages searching search engine metadata visual query languages},
	Number = {6},
	Pages = {454--466},
	Pdf = {QueryEvaluation/XML/Cohen.Kanza.ea_EquiX-asearchand_JASIST_2002.pdf},
	Publisher = {John Wiley \& Sons, Inc.},
	Title = {{EquiX---a search and query language for XML}},
	Url = {http://arxiv.org/abs/cs.DB/0110044},
	Volume = {53},
	Year = {2002},
	Abstract = {EquiX is a search language
	 for XML that combines the power of querying with the simplicity of
	 searching. Requirements for such languages are discussed, and it is
	 shown that EquiX meets the necessary criteria. Both a graph-based
	 abstract syntax and a formal concrete syntax are presented for EquiX
	 queries. In addition, the semantics is defined and an evaluation
	 algorithm is presented. The evaluation algorithm is polynomial under
	 combined complexity. EquiX combines pattern matching, quantification,
	 and logical expressions to query both the data and meta-data of XML
	 documents. The result of a query in EquiX is a set of XML documents. A DTD
	 describing the result documents is derived automatically from the query.}}

@inproceedings{Cohen.Mamou.ea_XSEarch-SemanticSearch_VLDB_2003,
	Author = {Cohen, Sara and Mamou, Jonathan and Kanza, Yaron and Sagiv, Yehoshua},
	Booktitle = VLDB,
	Conference-Abbr = {VLDB},
	Keywords = {XML IR information retrieval query languages},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/InformationRetrieval/Languages/Cohen.Mamou.ea_XSEarch-SemanticSearch_VLDB_2003.pdf},
	Title = {{XSEarch: A Semantic Search Engine for XML}},
	Url = {Cohen.Mamou.ea_XSEarch-SemanticSearch_VLDB_2003},
	Year = {2003},
	Abstract = {XSEarch, a semantic search
	 engine for XML, is presented. XSEarch has a simple query language,
	 suitable for a naive user. It returns semantically related document
	 fragments that satisfy the user's query. Query answers are ranked
	 using extended information-retrieval techniques and are generated in
	 an order similar to the ranking. Advanced indexing techniques were
	 developed to facilitate efficient implementation of XSEarch. The
	 performance of the different techniques as well as the recall and the
	 precision were measured experimentally. These experiments indicate that
	 XSEarch is efficient, scalable and ranks quality results highly.}}

@article{Comai.Damiani.ea_ComputingGraphicalQueries_TOIS_2001,
	Author = {Comai, Sara and Damiani, Ernesto and Fraternali, Piero},
	Doi = {http://doi.acm.org/10.1145/502795.502797},
	Issn = {1046-8188},
	Journal = {ACM Transactions on Information Systems},
	Journal-Abbr = {TOIS},
	Keywords = {XML query languages visual query languages XML-GL visualization},
	Number = {4},
	Pages = {371--430},
	Pdf = {QueryEvaluation/XML/Comai.Damiani.ea_ComputingGraphicalQueries_TOIS_2001.pdf},
	Publisher = {ACM Press},
	Title = {{Computing Graphical Queries over XML Data}},
	Url = {http://www.elet.polimi.it/upload/comai/Paper/TODS-Xmlgl.pdf},
	Volume = {19},
	Year = {2001},
	Abstract = {The rapid evolution of XML from a mere data
	 exchange format to a universal syntax for encoding domain-specific
	 information raises the need for new query languages specifically
	 conceived to address the characteristics of XML. Such languages should be
	 able not only to extract information from XML documents, but also to
	 apply powerful transformation and restructuring operators, based on a
	 well-defined semantics. Moreover, XML queries should be natural to write and
	 understand, as nontechnical persons also are expected to access the
	 large XML information bases supporting their businesses. This article
	 describes XML-GL, a graphical query language for XML data. XML-GL's
	 uniqueness is in the definition of a graph-based syntax to express
	 a wide variety of XML queries, ranging from simple selections to
	 expressive data transformations involving grouping, aggregation, and
	 arithmetic calculations. XML-GL has an operational semantics based on the
	 notion of graph matching, which serves as a guideline both for the
	 implementation of native processors, and for the adoption of XML-GL as
	 a front-end to any of the XML query languages that are presently
	 under discussion as the standard paradigm for querying XML data.}}

@inproceedings{Comai.Marrara.ea_XMLDocumentSummarization_DEXA_2004,
	Author = {Comai, Sara and Marrara, Stefania and Tanca, Letizia},
	Booktitle = {Proc. Intl. Workshop on Database and Expert Systems Applications},
	Conference-Abbr = {DEXA},
	Keywords = {XML XQuery synopsis query languages},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XQuery/Comai.Marrara.ea_XMLDocumentSummarization_DEXA_2004.pdf},
	Title = {{XML Document Summarization: Using XQuery for Synopsis Creation}},
	Year = {2004},
	Abstract = {This work presents a methodology to support approximate queries
	 over massive and heterogeneous XML data sets, based on concise data
	 statistics such as histograms or other statistical techniques. The basic
	 idea for approximate answers is to store precomputed summaries of
	 the XML data, also called synopses, and to query them instead of
	 the original database, thus saving time and computational costs. In
	 particular, We concentrate on a set of XQuery transformation rules for the
	 construction of the synopses collection and for querying the synopsis.}}

@inproceedings{Conforti.Ghelli.ea_QueryLanguageTQL_WebDB_2002,
	Author = {Conforti, Giovanni and Ghelli, Giorgio and Albano, Antonio and Colazzo, Dario and Manghi, Paolo and Sartiani, Carlo},
	Booktitle = {Proc. Intl. Workshop on the Web and Databases},
	Conference-Abbr = {WebDB},
	Keywords = {XML query languages TQL ambient logic patterns paths},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/LogicProgrammingApproaches/Conforti.Ghelli.ea_QueryLanguageTQL_WebDB_2002.pdf},
	Title = {{The Query Language TQL}},
	Url = {http://www.db.ucsd.edu/webdb2002/papers/43.pdf},
	Year = {2002},
	Abstract = {This work presents the query language TQL, a
	 query language for semistructured data, that can be used to query
	 XML files. TQL substitutes the standard path-based pattern-matching
	 mechanism with a logic-based mechanism, where the programmer specifies
	 the properties of the pieces of data she is trying to extract. As a
	 result, TQL queries are more ?declarative?, or less ?operational?, than
	 queries in comparable languages. This feature makes some queries easier
	 to express, and should allow the adoption of better optimization
	 techniques. Through a set of examples, we show that the range of
	 queries that can be declaratively expressed in TQL is quite wide. The
	 implementation of TQL binding mechanism requires the adoption of
	 non-standard techniques, and some of its aspects are still open.
	 In this paper we implicitly report about the current status of the
	 implementation by writing all queries using the version of TQL that has been
	 implemented, and that can be freely downloaded from //tql.di.unipi.it/tql.}}

@techreport{Cowan.Tobin_XMLInformationSet_TR_2004,
	Author = {Cowan, John and Tobin, Richard},
	Institution = {W3C},
	Keywords = {XML Infoset W3C data model},
	Owner = {Tim Furche},
	Title = {{XML Information Set (2nd Ed.)}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/xml-infoset/},
	Urldate = {2005/01/31},
	Year = {2004},
	Abstract = {This specification provides a set of definitions for use in other
	 specifications that need to refer to the information in an XML document.}}

@inproceedings{DeHaan.Toman.ea_ComprehensiveXQueryto_SIGMOD_2003,
	Author = {DeHaan, David and Toman, David and Consens, Mariano P. and {\"O}zsu, M. Tamer},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Doi = {http://doi.acm.org/10.1145/872757.872832},
	Isbn = {1-58113-634-X},
	Keywords = {XML XQuery relational implementation tree encoding dynamic interval encoding},
	Location = {San Diego, California},
	Pages = {623--634},
	Pdf = {QueryEvaluation/XML/XQuery/DeHaan.Toman.ea_ComprehensiveXQueryto_SIGMOD_2003.pdf},
	Publisher = {ACM Press},
	Title = {{A Comprehensive XQuery to SQL Translation using Dynamic Interval Encoding}},
	Url = {http://db.uwaterloo.ca/~david/cs848/toman-et-al-sigmod.pdf},
	Year = {2003},
	Abstract = {The W3C XQuery language
	 recommendation, based on a hierarchical and ordered document model, supports a
	 wide variety of constructs and use cases. There is a diversity of
	 approaches and strategies for evaluating XQuery expressions, in many
	 cases only dealing with limited subsets of the language. In this
	 paper we describe an implementation approach that handles XQuery with
	 arbitrarily-nested FLWR expressions, element constructors and built-in
	 functions (including structural comparisons). Our proposal maps an XQuery
	 expression to a single equivalent SQL query using a novel dynamic interval
	 encoding of a collection of XML documents as relations, augmented with
	 information tied to the query evaluation environment. The dynamic
	 interval technique enables (suitably enhanced) relational engines to
	 produce predictably good query plans that do not preclude the use of
	 sort-merge join query operators. The benefits are realized despite the
	 challenges presented by intermediate results that create arbitrary
	 documents and the need to preserve document order as prescribed by
	 semantics of XQuery. Finally, our experimental results demonstrate
	 that (native or relational) XML systems can benefit from the above
	 technique to avoid a quadratic scale up penalty that effectively
	 prevents the evaluation of nested FLWR expressions for large documents.}}

@techreport{DeRoseMaier.XML-Linking-Language.2001,
	Author = {DeRose, Steve and Maier, Eve and Orchard, David},
	Date-Added = {2005-05-01 13:59:00 +0200},
	Date-Modified = {2005-09-29 00:29:34 +0200},
	Institution = {W3C},
	Keywords = {XML XLink linking relations},
	Title = {{XML Linking Language (XLink) Version 1.0}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/xlink/},
	Year = {2001}}

@inproceedings{Deutsch.Fernandez.ea_QueryLanguageXML_WWW_1999,
	Author = {Deutsch, Alin and Fernandez, Mary and Florescu, Daniela and Levy, Alon and Suciu, Dan},
	Booktitle = WWW,
	Conference-Abbr = {WWW},
	Keywords = {XML query languages XML-QL pattern},
	Owner = {Tim Furche},
	Title = {{A Query Language for XML}},
	Url = {http://www.research.att.com/~mff/xmlql/doc/files/final.html},
	Year = {1999},
	Abstract = {An important application of XML is the interchange of electronic
	 data (EDI) between multiple data sources on the Web. As XML data
	 proliferates on the Web, applications will need to integrate and
	 aggregate data from multiple source and clean and transform data to
	 facilitate exchange. Data extraction, conversion, transformation, and
	 integration are all well-understood database problems, and their
	 solutions rely on a query language. We present a query language for XML,
	 called XML-QL, which we argue is suitable for performing the above
	 tasks. XML-QL is a declarative, ``relational complete'' query language
	 and is simple enough that it can be optimized. XML-QL can extract
	 data from existing XML documents and construct new XML documents.}}

@inproceedings{Deutsch.Fernandez.ea_XML-QL-QueryLanguage_QL98_1998,
	Author = {Deutsch, Alin and Fernandez, Mary and Florescu, Daniela and Levy, Alon and Suciu, Dan},
	Booktitle = PROC # {W3C QL'98 -- Query Languages 1998},
	Conference-Abbr = {QL98},
	Howpublished = {Note},
	Institution = {W3C},
	Keywords = {XML XML-QL query languages positional},
	Organization = {W3C},
	Title = {{XML-QL: A Query Language for XML}},
	Url = {http://www.w3.org/TR/1998/NOTE-xml-ql-19980819/},
	Year = {1998}}

@inproceedings{Deutsch.Papakonstantinou.ea_NEXTLogicalFramework_VLDB_2004,
	Author = {Deutsch, Alin and Papakonstantinou, Yannis and Xu, Yu},
	Booktitle = VLDB,
	Conference-Abbr = {VLDB},
	Keywords = {XML XQuery optimization logical query optimization rewriting},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XQuery/Deutsch.Papakonstantinou.ea_NEXTLogicalFramework_VLDB_2004.pdf},
	Title = {{The NEXT Logical Framework for XQuery}},
	Url = {http://www.vldb.org/conf/2004/RS4P5.PDF},
	Year = {2004},
	Abstract = {Classical logical optimization techniques rely on a logical
	 semantics of the query language. The adaptation of these techniques to
	 XQuery is precluded by its definition as a functional language with
	 operational semantics. We introduce Nested XML Tableaux which enable a
	 logical foundation for XQuery semantics and provide the logical plan
	 optimization framework of our XQuery processor. As a proof of concept, we
	 develop and evaluate a minimization algorithm for removing redundant
	 navigation within and across nested subqueries. The rich XQuery features
	 create key challenges that fundamentally extend the prior work on
	 the problems of minimizing conjunctive and tree pattern queries.}}

@inproceedings{Deutsch.Tannen_ContainmentandIntegrity_KRDB_2001,
	Author = {Deutsch, Alin and Tannen, Val},
	Booktitle = {Proc. Intl. Workshop on Knowledge Representation meets Databases},
	Conference-Abbr = {KRDB},
	Keywords = {XML XPath query containment fragments query languages},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/PathExpressions/XPath/Deutsch.Tannen_ContainmentandIntegrity_KRDB_2001.pdf},
	Title = {{Containment and Integrity Constraints for XPath Fragments}},
	Url = {http://ceur-ws.org/Vol-45/01-deutsch.ps},
	Year = {2001}}

@inproceedings{deVos.Rowbotham_KnowledgeRepresentationPower_PICA_2001,
	Author = {deVos, Arnold and Rowbotham, C. T.},
	Booktitle = {IEEE Conference for Power Industry Computer Applications (PICA)},
	Conference-Abbr = {PICA},
	Keywords = {Application Use Cases RDF},
	Owner = {Tim Furche},
	Pdf = {SemanticWeb/RDF/Applications/deVos.Rowbotham_KnowledgeRepresentationPower_PICA_2001.pdf},
	Title = {{Knowledge Representation for Power System Modelling}},
	Url = {http://www.langdale.com.au/PICA/KRforPSM.pdf},
	Urldate = {2004/12/20},
	Year = {2001},
	Abstract = {Modelling power systems is an area of ongoing interest in the transmission
	 management and control systems community. Continuing development is
	 driven by two forces. The traditional tasks of model maintenance
	 and management must be achieved with fewer resources. At the same
	 time, model exchange and coordination has become a priority. The
	 latter force arises from the disaggregation of utility functions and
	 the introduction of power markets. This paper begins by identifying
	 some of the power system modelling tasks that have become important,
	 but are ill served by current tools and techniques. Among these are
	 model versioning and version control, migration of models between
	 different schema, the transformation of models for different purposes
	 or applications, and the merging of models from different sources.
	 These tasks are typically handled by semi-manual methods or heavily
	 customized software. The paper then describes the application of
	 knowledge representation to power system modelling. In particular, the
	 power of this approach to provide generic solutions to the foregoing
	 problems is explored. Knowledge representation is contrasted with
	 more common data representations and put into context with current
	 industry initiatives, EPRI CIM, UMS DAF and XML/CIM. Finally, the
	 feasibility of using knowledge representation for power system models is
	 illustrated with a case study from a major Australian distribution utility.}}

@inproceedings{Dolog.Henze.ea_PersonalizationinDistributed_WWW_2004,
	Author = {Dolog, Peter and Henze, Nicola and Nejdl, Wolfgang and Sintek, Michael},
	Booktitle = WWW,
	Conference-Abbr = {WWW},
	Keywords = {Personalization E-Learning Web},
	Owner = {Tim Furche},
	Pdf = {ApplicationAreas/Personalization/Dolog.Henze.ea_PersonalizationinDistributed_WWW_2004.pdf},
	Title = {{Personalization in Distributed e-Learning Environments}},
	Url = {http://www.kbs.uni-hannover.de/Arbeiten/Publikationen/2004/dolog_henze_nejdl_sintek_www2004.pdf},
	Year = {2004}}

@inproceedings{Dolog.Henze.ea_PersonalReader:Personalizing_AH_2004,
	Author = {Dolog, Peter and Henze, Nicola and Nejdl, Wolfgang and Sintek, Michael},
	Booktitle = {Proc. Intl. Conf. on Adaptive Hypermedia and Adaptive Web-Based Systems},
	Conference-Abbr = {AH},
	Keywords = {Personalization E-Learning Personal Reader Semantic Web RDF},
	Owner = {Tim Furche},
	Pdf = {ApplicationAreas/Personalization/Dolog.Henze.ea_PersonalReader:Personalizing_AH_2004.pdf},
	Title = {{The Personal Reader: Personalizing and Enriching Learning Resources using Semantic Web Technologies}},
	Url = {http://www.kbs.uni-hannover.de/Arbeiten/Publikationen/2004/ah2004_d_h_n_s.pdf},
	Year = {2004},
	Abstract = {Traditional adaptive hypermedia systems have focused on
	 providing adaptation functionality on a closed corpus, while Web search
	 interfaces have delivered non-personalized information to users. In this
	 paper, we show how we integrate closed corpus adaptation and global
	 context provision in a Personal Reader environment. The local context
	 consists of individually optimized recommendations to learning materials
	 within the given corpus; the global context provides individually
	 optimized recommendations to resources found on the Web, e.g., FAQs,
	 student exercises, simulations, etc. The adaptive local context of a
	 learning resource is generated by applying methods from adaptive
	 educational hypermedia in a semantic web setting. The adaptive global
	 context is generated by constructing appropriate queries, enrich them
	 based on available user pro le information, and, if necessary, relax
	 them during the querying process according to available metadata.}}

@inproceedings{DomsFurche.How-to-Query-the-Gen.2005,
	Author = {Doms, Andreas and Furche, Tim and Burger, Albert and Schroeder, Michael},
	Booktitle = {Symposium on Knowledge Representation in Bioinformatics (KRBIO'05), Espoo, Finland (17th June 2005)},
	Conference-Abbr = {KRBIO},
	Date-Added = {2005-04-20 13:40:41 +0200},
	Date-Modified = {2006-03-06 17:52:05 +0100},
	Keywords = {Xcerpt XML Prolog Bioinformatics GeneOntology Use cases Prova},
	Title = {How to Query the GeneOntology},
	Url = {http://www.pms.ifi.lmu.de/publikationen#PMS-FB-2005-15},
	Year = {2005}}

@inproceedings{Dong.Bailey_OptimizationofXML_WISE_2004,
	Author = {Dong, Ce and Bailey, James},
	Booktitle = {Proc. Intl. Conf. on Web Information Systems Engineering},
	Conference-Abbr = {WISE},
	Keywords = {XML XSLT optimization query languages},
	Owner = {Tim Furche},
	Title = {{Optimization of XML Transformations Using Template Specialization}},
	Year = {2004}}

@inproceedings{Dong.Bailey_StaticAnalysisof_ADC_2004,
	Author = {Dong, Ce and Bailey, James},
	Booktitle = {Proc. Australasian Database Conf.},
	Conference-Abbr = {ADC},
	Isbn = {1-111-11111-1},
	Keywords = {XML XSLT error checking typing query languages},
	Location = {Dunedin, New Zealand},
	Pages = {151--160},
	Pdf = {QueryEvaluation/XML/XSLT/Dong.Bailey_StaticAnalysisof_ADC_2004.pdf},
	Publisher = {Australian Computer Society, Inc.},
	Title = {{Static Analysis of XSLT Programs}},
	Url = {http://www.cs.mu.oz.au/~jbailey/papers/adc.pdf},
	Year = {2004},
	Abstract = {XML is becoming the dominant
	 standard for representing and exchanging data on the World Wide Web. The
	 ability to transform and present data in XML is crucial and XSLT
	 (Extensible Stylesheet Language Transformations) is the principal
	 programming language that supports this activity. Methods for analysis of
	 XSLT programs are currently an important open issue. In this paper,
	 we discuss new methods for analysing XSLT programs, which return
	 information about reachability, invalid calling relationships and
	 termination properties. Our methods are based on the determination of the
	 associations which can exist between components of an XSLT program,
	 refined by the knowledge from a DTD. Such analysis is important for
	 debugging and verification of XSLT programs and also their optimisation.}}

@techreport{Draper.Frankhauser.ea_XQuery1.0and_TR_2005,
	Author = {Draper, Denise and Frankhauser, Peter and Fern{\'a}ndez, Mary and Malhotra, Ashok and Rose, Kristoffer and Rys, Michael and Sim{\'e}on, J{\'e}r{\^o}me and Wadler, Philip},
	Institution = {W3C},
	Keywords = {XML XQuery Use Cases W3C Query Query Languages},
	Owner = {Tim Furche},
	Title = {{XQuery 1.0 and XPath 2.0 Formal Semantics}},
	Type = {Working Draft},
	Url = {http://www.w3.org/TR/xquery-semantics/},
	Urldate = {2005/01/31},
	Year = {2005},
	Abstract = {This document defines formally the semantics of XQuery 1.0 [XQuery 1.0: A Query
	 Language for XML] and XPath 2.0 [XML Path Language (XPath) 2.0].}}

@article{Eisenberg.Melton_earlyLookat_SIGMOD_2004,
	Author = {Eisenberg, Andrew and Melton, Jim},
	Doi = {http://doi.acm.org/10.1145/1024694.1024717},
	Issn = {0163-5808},
	Journal = {SIGMOD Record},
	Journal-Abbr = {SIGMOD},
	Keywords = {XML XQuery Java XQJ API query languages},
	Number = {2},
	Pages = {105--111},
	Pdf = {QueryEvaluation/XML/XQuery/Eisenberg.Melton_earlyLookat_SIGMOD_2004.pdf},
	Publisher = {ACM Press},
	Title = {{An early Look at XQuery API for Java\texttrademark (XQJ)}},
	Url = {http://portal.acm.org/citation.cfm?id=1024694.1024717},
	Volume = {33},
	Year = {2004},
	Abstract = {In Feb. 2004, the period for
	 submitting Last Call Working Draft comments for most parts of the XQuery
	 specification came to a close. While there is still a great deal of work
	 to be done to make XQuery a W3C Recommendation, the documents have
	 become more stable with each public release. In this column we'd
	 like to provide an initial look at the XQuery API for Java? (XQJ), a
	 project that is taking place within the Java Community Process (JCP).}}

@article{Eisenberg.Melton_earlyLookat_SIGMOD_2002,
	Author = {Eisenberg, Andrew and Melton, Jim},
	Doi = {http://doi.acm.org/10.1145/637411.637433},
	Issn = {0163-5808},
	Journal = {SIGMOD Record},
	Journal-Abbr = {SIGMOD},
	Keywords = {XML XQuery query languages historical},
	Number = {4},
	Pages = {113--120},
	Pdf = {QueryEvaluation/XML/XQuery/Eisenberg.Melton_earlyLookat_SIGMOD_2002.pdf},
	Publisher = {ACM Press},
	Title = {{An early Look at XQuery}},
	Url = {http://portal.acm.org/citation.cfm?id=637433},
	Volume = {31},
	Year = {2002}}

@inproceedings{Eiter.Ianni.ea_NonmonotonicDescriptionLogic_LPAR_2005,
	Author = {Eiter, Thomas and Ianni, Giovambattista and Schindlauer, Roman and Tompits, Hans},
	Booktitle = LPAR,
	Conference-Abbr = {LPAR},
	Keywords = {Description Logics Evaluation Semantic Web REWERSE},
	Owner = {Tim Furche},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{Nonmonotonic Description Logic Programs: Implementation and Experiments}},
	Year = {2005}}

@inproceedings{Eiter.Lukasiewicz.ea_CombiningAnswerSet_KR_2004,
	Author = {Eiter, Thomas and Lukasiewicz, Thomas and Schindlauer, Roman and Tompits, Hans},
	Booktitle = {Proc. Principles of Knowledge Representation and Reasoning (KR)},
	Conference-Abbr = {KR},
	Keywords = {Semantic Web Description Logics Answer-set Programming Query Languages Reasoning REWERSE},
	Owner = {Tim Furche},
	Pages = {141--151},
	Pdf = {QueryEvaluation/SemanticWeb/Eiter.Lukasiewicz.ea_CombiningAnswerSet_KR_2004.pdf},
	Title = {{Combining Answer Set Programming with Description Logics for the Semantic Web}},
	Url = {http://www.kr.tuwien.ac.at/staff/tompits/papers/kr-04-coupling.pdf},
	Urldate = {2005/01/28},
	Year = {2004},
	Abstract = {Towards the integration of rules and
	 ontologies in the Semantic Web, we propose a combination of logic
	 programming under the answer set semantics with the description logics
	 SHIF(D) and SHOIN(D), which underly the Web ontology languages OWL
	 Lite and OWL DL, respectively. This combination allows for building
	 rules on top of ontologies but also, to a limited extent, building
	 ontologies on top of rules. We introduce description logic programs
	 (dl-programs), which consist of a description logic knowledge base L and a
	 finite set of description logic rules (dl-rules) P. Such rules are
	 similar to usual rules in logic programs with negation as failure, but
	 may also contain queries to L, possibly default negated, in their
	 bodies. We define Herbrand models for dl-programs, and show that
	 satisfiable positive dl-programs have a unique least Herbrand model.
	 More generally, consistent stratified dlprograms can be associated
	 with a unique minimal Herbrand model that is characterized through
	 iterative least Herbrand models. We then generalize the (unique) minimal
	 Herbrand model semantics for positive and strati- fied dl-programs to a
	 strong answer set semantics for all dl-programs, which is based on a
	 reduction to the least model semantics of positive dl-programs. We also
	 de- fine a weak answer set semantics based on a reduction to the
	 answer sets of ordinary logic programs. Strong answer sets are weak
	 answer sets, and both properly generalize answer sets of ordinary
	 normal logic programs. We then give fixpoint characterizations for the
	 (unique) minimal Herbrand model semantics of positive and stratified
	 dl-programs, and show how to compute these models by finite fixpoint
	 iterations. Furthermore, we give a precise picture of the complexity
	 of deciding strong and weak answer set existence for a dl-program.}}

@inproceedings{Eiter.Lukasiewicz.ea_Well-foundedSemanticsDescription_RuleML_2004,
	Author = {Eiter, Thomas and Lukasiewicz, Thomas and Schindlauer, Roman and Tompits, Hans},
	Booktitle = {Proc. RuleML Workshop, ISWC},
	Conference-Abbr = {RuleML},
	Keywords = {Semantic Web Description Logics Semantics Querying REWERSE},
	Owner = {Tim Furche},
	Pages = {81--97},
	Pdf = {QueryEvaluation/SemanticWeb/Eiter.Lukasiewicz.ea_Well-foundedSemanticsDescription_RuleML_2004.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{Well-founded Semantics for Description Logic Programs in the Semantic Web}},
	Url = {http://www.kr.tuwien.ac.at/staff/lukasiew/ruleml04.pdf},
	Urldate = {2005/01/28},
	Volume = {3323},
	Year = {2004},
	Abstract = {In previous work, towards the integration of rules and ontologies in the
	 SemanticWeb, we have proposed a combination of logic programming under
	 the answer set semantics with the description logics SHIF(D) and
	 SHOIN(D), which underly the Web ontology languages OWL Lite and OWL
	 DL, respectively. More precisely, we have introduced description
	 logic programs (or dl-programs), which consist of a description logic
	 knowledge base L and a nite set of description logic rules P, and we have
	 de ned their answer set semantics. In this paper, we continue this
	 line of research. Here, as a central contribution, we present the
	 well-founded semantics for dl-programs, and we analyze its semantic
	 properties. In particular, we show that it generalizes the well-founded
	 semantics for ordinary normal programs. Furthermore, we show that in
	 the general case, the well-founded semantics of dl-programs is a
	 partial model that approximates the answer set semantics, whereas
	 in the positive and the stratified case, it is a total model that
	 coincides with the answer set semantics. Finally, we also provide
	 complexity results for dl-programs under the well-founded semantics.}}

@article{Fankhauser_XQueryFormalSemantics_SIGMOD_2001,
	Author = {Fankhauser, Peter},
	Doi = {http://doi.acm.org/10.1145/603867.603870},
	Issn = {0163-5808},
	Journal = {SIGMOD Record},
	Journal-Abbr = {SIGMOD},
	Keywords = {XML XQuery formal semantics historical query languages},
	Number = {3},
	Pages = {14--19},
	Pdf = {QueryEvaluation/XML/XQuery/Fankhauser_XQueryFormalSemantics_SIGMOD_2001.pdf},
	Publisher = {ACM Press},
	Title = {{XQuery Formal Semantics: State and Challenges}},
	Url = {http://portal.acm.org/citation.cfm?id=603870},
	Volume = {30},
	Year = {2001},
	Abstract = {The XQuery formalization is an ongoing effort of the
	 W3C XML Query working group to define a precise formal semantics
	 for XQuery. This paper briefly introduces the current state of the
	 formalization and discusses some of the more demanding remaining
	 challenges in formally describing an expressive query language for XML.}}

@inproceedings{Fankhauser_XQuerybybook_XML_2002,
	Author = {Fankhauser, Peter and Lehti, Patrick},
	Booktitle = {XML Conference \& Exhibition},
	Conference-Abbr = {XML},
	Keywords = {XML XQuery implementation experience query languages},
	Owner = {Tim Furche},
	Title = {{XQuery by the book: The IPSI XQuery Demonstrator}},
	Url = {http://www.ipsi.fraunhofer.de/oasys/projects/ipsi-xq/XQuery%20by%20the%20book.rtf},
	Year = {2002},
	Abstract = {XQuery is being developed by the W3C XML Query working group
	 as a standard query language for XML. It is a fully compositional,
	 strongly typed functional language to flexibly select, recombine,
	 and restructure XML documents and fragments. This paper introduces
	 IPSI-XQ, a comprehensive implementation of XQuery "by the book", which
	 closely follows XQuery's formal semantics, realizing all steps of
	 the abstract XQuery processing model in an open and modular way to
	 arrive at a fully conformant, type safe implementation. It describes
	 how the formal specification can be deployed for type analysis and
	 query optimization, and discusses the pros and cons of the approach.}}

@techreport{Fernandez.Malhotra.ea_XQuery1.0and_TR_2005,
	Author = {Fern{\'a}ndez, Mary and Malhotra, Ashok and Marsh, Jonathan and Nagy, Marton and Walsh, Norman},
	Institution = {W3C},
	Keywords = {XML XQuery XPath data model query languages},
	Owner = {Tim Furche},
	Title = {{XQuery 1.0 and XPath 2.0 Data Model}},
	Type = {Working Draft},
	Url = {http://www.w3.org/TR/xpath-datamodel/},
	Urldate = {2005/01/31},
	Year = {2005},
	Abstract = {This document defines the W3C XQuery 1.0 and XPath
	 2.0 Data Model, which is the data model of [XPath 2.0], [XSLT 2.0],
	 and [XQuery], and any other specifications that reference it. This
	 data model is based on the [XPath 1.0] data model and earlier work
	 on an [XML Query Data Model]. This document is the result of joint
	 work by the [XSL Working Group] and the [XML Query Working Group].}}

@inproceedings{Fernandez.Simeon.ea_ImplementingXQuery1.0_VLDB_2003,
	Author = {Fern{\'a}ndez, Mary and Sim{\'e}on, J{\'e}r{\^o}me and Choi, Byron and Marian, Am{\'e}lie and Sur, Gargi},
	Booktitle = VLDB,
	Conference-Abbr = {VLDB},
	Keywords = {XML XQuery galax implementation query languages},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XQuery/Fernandez.Simeon.ea_ImplementingXQuery1.0_VLDB_2003.pdf},
	Title = {{Implementing XQuery 1.0 : The Galax Experience}},
	Url = {http://www.vldb.org/conf/2003/papers/S35P07.pdf},
	Year = {2003},
	Abstract = {Galax is a light-weight, portable, open-source
	 implementation of XQuery 1.0. Started in December 2000 as a small prototype
	 designed to test the XQuery static type system, Galax has now become a
	 solid implementation, aiming at full conformance with the family of
	 XQuery 1.0 specifi- cations. Because of its completeness and open
	 architecture, Galax also turns out to be a very convenient platform for
	 researchers interested in experimenting with XQuery optimization. We
	 demonstrate the Galax system as well as its most advanced features,
	 including support for XPath 2.0, XML Schema and static typechecking.
	 We also present some of our first experiments with optimization.
	 Notably, we demonstrate query rewriting capabilities in the Galax
	 compiler, and the ability to run queries on documents up to a Gigabyte
	 without the need for preindexing. Although early versions of Galax
	 have been shown in industrial conferences over the last two years,
	 this is the first time it is demonstrated in the database community.}}

@inproceedings{Florescu.Fernandez.ea_QueryLanguageand_WMSD_1997,
	Author = {Florescu, Daniela and Fernandez, Mary and Levy, Alon and Suciu, Dan},
	Booktitle = {Proc. Workshop on Management of Semi-structured Data},
	Conference-Abbr = {WMSD},
	Keywords = {XML query languages StruQL navigational path expression},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/Languages/Florescu.Fernandez.ea_QueryLanguageand_WMSD_1997.pdf},
	Title = {{A Query Language and Processor for a Web-site Management System}},
	Url = {http://www.research.att.com/~mff/strudel/doc/files/workshop97.ps.gz},
	Year = {1997}}

@article{Florescu.Hillery.ea_BEAstreamingXQuery_VLDBJ_2004,
	Author = {Florescu, Daniela and Hillery, Chris and Kossmann, Donald and Lucas, Paul and Riccardi, Fabio and Westmann, Till and Carey, Michael J. and Sundararajan, Arvind},
	Doi = {http://dx.doi.org/10.1007/s00778-004-0137-1},
	Issn = {1066-8888},
	Journal = {VLDB Journal},
	Journal-Abbr = {VLDBJ},
	Keywords = {XML XQuery query processing implementation query languages},
	Number = {3},
	Pages = {294--315},
	Pdf = {QueryEvaluation/XML/XQuery/Florescu.Hillery.ea_BEAstreamingXQuery_VLDBJ_2004.pdf},
	Publisher = {Springer-Verlag New York, Inc.},
	Title = {{The BEA Streaming XQuery Processor}},
	Url = {http://www-dbs.informatik.uni-heidelberg.de/publications/vldbj.pdf},
	Volume = {13},
	Year = {2004},
	Abstract = {This paper describes the design, implementation, and performance characteristics
	 of a commercial XQuery processing engine, the BEA streaming XQuery
	 processor. This XQuery engine was designed to provide high performance for
	 message-processing applications, i.e., for transforming XML data
	 streams. The engine is a central component of the 8.1 release of BEA?s
	 WebLogic Integration (WLI) product. The BEA XQuery engine is fully
	 compliant with the August 2002 draft of the W3C XML Query Language
	 specification and we are currently porting it to the latest version of the
	 XQuery language (July 2004). A goal of this paper is to describe how a
	 fully compliant yet efficient XQuery engine has been built from a
	 few relatively simple components and well-understood technologies.}}

@article{Florescu.Levy.ea_QueryLanguageWeb-site_SIGMOD_1997,
	Author = {Florescu, Daniela and Levy, Alon and Fernandez, Mary and Suciu, Dan},
	Booktitle = {SIGMOD},
	Conference-Abbr = {WMSD},
	Journal = {SIGMOD Record},
	Journal-Abbr = {SIGMOD},
	Keywords = {XML query languages StruQL navigational path expression},
	Number = {3},
	Owner = {Tim Furche},
	Pages = {4--11},
	Pdf = {QueryEvaluation/Languages/Florescu.Fernandez.ea_QueryLanguageand_WMSD_1997.pdf},
	Title = {{A Query Language for a Web-site Management System}},
	Url = {http://www.research.att.com/~mff/strudel/doc/files/sigmodrec97.ps.gz},
	Volume = {26},
	Year = {1997}}

@talk{Furche_BusinessRulesConference_SLIDES_2004,
	Author = {Furche, Tim},
	Institution = {Institute for Computer Science, University of Munich, Germany},
	Keywords = {Semantic Web Use Cases Business Rules},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/Streams/XPath/Furche_QueryOptimizationon_SLIDES_2003.pdf},
	Title = {{Business Rules Conference 2004: Report and Experiences}},
	Type = {Oberseminar ?Knowledge Representation and Markup Languages?},
	Year = {2004}}

@talk{Furche_XcerptandXChange_SLIDES_2004,
	Author = {Furche, Tim},
	Institution = {Institute for Computer Science, University of Munich, Germany},
	Keywords = {Semantic Web Use Cases Bioinformatics Application},
	Owner = {Tim Furche},
	Pdf = {ApplicationAreas/Bioinformatics/Furche_XcerptandXChange_SLIDES_2004.pdf},
	Title = {{Xcerpt and XChange in Bioinformatics}},
	Type = {Oberseminar ?Knowledge Representation and Markup Languages?},
	Year = {2004},
	Abstract = {Collaboration and Use Cases}}

@mastersthesis{Furche_OptimizingMultipleQueries_2003,
	Address = {6},
	Author = {Furche, Tim},
	Keywords = {Query Evaluation Streams XPath XML},
	Pdf = {QueryEvaluation/Streams/XPath/Furche_OptimizingMultipleQueries_2003.pdf},
	School = {Institute of Computer Science, University of Munich, Germany},
	Title = {{Optimizing Multiple Queries against XML Streams}},
	Type = {Diplomarbeit},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#DA_Tim.Furche},
	Urldate = {2004/11/11},
	Year = {2003},
	Abstract = {Processing and querying streams,
	 XML streams in particular, has recently become a widely recognized
	 area of interest both in research and in industry. In contrast to
	 traditional query evaluation for databases, where multiple queries
	 against the same data can be evaluated sequentially, for a streamed
	 environment only the simultaneous execution of multiple queries is
	 feasible, as the sequential evaluation requires multiple passes over the
	 stream. This work presents an overview of techniques for optimizing
	 multiple queries posed against a stream of XML data. Building upon the
	 SPEX query engine [Kiesling, Master Thesis, 2002; Olteanu et al.,
	 ICDE, 2003], the problem how to find a cost-optimal query plan that
	 allows the simultaneous evaluation of multiple queries against the
	 same stream is presented and shown to be not only hard to solve but
	 also hard to approximate, if arbitrary parts, and not only common
	 prefixes as in previous approaches, can be shared among query plans.
	 Several heuristics are investigated and compared, in particular with
	 respect to their complexity. Furthermore, it is shown how to extend the
	 SPEX query engine to support such query plans for multiple queries.
	 This extension proves to be both natural and efficient. An extensive
	 experimental evaluation shows that sharing arbitrary operators under a
	 realistic cost function results in query plans that have consistently
	 lower cost for reasonable sets of queries than query plans where
	 only common prefixes are considered. In most cases, the relative
	 improvement is higher than 50%. Although the time for generating such
	 query plans is higher than for query plans where only common prefixes
	 are shared, the increase in time is within an acceptable margin.}}

@talk{Furche_QueryOptimizationon_SLIDES_2003,
	Author = {Furche, Tim},
	Institution = {Institute for Computer Science, University of Munich, Germany},
	Keywords = {Path Expressions Query Evaluation Streams XML Presentation},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/Streams/XPath/Furche_QueryOptimizationon_SLIDES_2003.pdf},
	Title = {{Query Optimization on XML Streams}},
	Type = {Oberseminar ?Knowledge Representation and Markup Languages?},
	Year = {2003},
	Abstract = {Techniques for multi-query optimization in face of semi-structured streams}}

@talk{Furche_QueryMergingXML_SLIDES_2002,
	Author = {Furche, Tim},
	Institution = {Institute for Computer Science, University of Munich, Germany},
	Keywords = {Path Expressions Query Evaluation Streams XML Presentation},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/Streams/XPath/Furche_QueryOptimizationon_SLIDES_2003.pdf},
	Title = {{Query Merging for XML Streams}},
	Type = {Oberseminar ?Knowledge Representation and Markup Languages?},
	Year = {2002},
	Abstract = {Overview of techniques for multi-query optimization in the SPEX framework}}

@techreport{Furche.Bry.ea_SurveyoverExisting_TR_2004,
	Author = {Furche, Tim and Bry, Fran{\c c}ois and Schaffert, Sebastian and Orsini, Renzo and Horrocks, Ian and Krauss, Michael and Bolzer, Oliver},
	Date-Modified = {2006-03-06 17:45:17 +0100},
	Editor = {Tim Furche},
	Institution = {REWERSE},
	Keywords = {REWERSE Survey Query Languages RDF XML},
	Number = {I4-D1},
	Pdf = {QueryEvaluation/SemanticWeb/Furche.Bry.ea_SurveyoverExisting_TR_2004.pdf},
	Title = {{Survey over Existing Query and Transformation Languages}},
	Type = {Deliverable},
	Url = {http://rewerse.net/publications.html#REWERSE-DEL-2004-I4-D1},
	Urldate = {2004/11/11},
	Year = {2004},
	Abstract = {A widely acknowledged obstacles for realizing the vision of the Semantic Web is the
	 inability of many current Semantic Web approaches to cope with data
	 available in such diverging representation formalisms as XML, RDF,
	 or Topic Maps. A common query language is the first step to allow
	 transparent access to data in any of these formats. To further the
	 understanding of the requirements and approaches proposed for query
	 languages in the conventional as well as the Semantic Web, this report
	 surveys a large number of query languages for accessing XML, RDF, or
	 Topic Maps. This is the first systematic survey to consider query
	 languages from all these areas. From the detailed survey of these query
	 languages, a common classification scheme is derived that is useful for
	 understanding and di erentiating languages within and among all three areas.}}

@talk{Furche.Hoehler.ea_Probablybetter..._SLIDES_2002,
	Author = {Furche, Tim and H{\"o}hler, Thomas and Weigel, Felix},
	Institution = {University of Tilburg, Netherlands, the University of T{\"u}bingen, Germany, and the Centre for Information and Language Processing, Munich, Germany, at Blaubeuren, Germany},
	Keywords = {Path Expressions Query Evaluation Streams XML Presentation},
	Owner = {Tim Furche},
	Title = {{Probably better ..., Looking at Probabilistic and Non-Probabilistic Indexing}},
	Type = {Presentation at the Fourth Virtugrade meeting on ?Information Retrieval?},
	Year = {2002}}

@talk{Furche.Patranjan_XcerptandXChange_SLIDES_2004,
	Author = {Furche, Tim and P{\u a}tr{\^a}njan, Paula-Lavinia},
	Date-Modified = {2005-04-29 22:11:30 +0200},
	Institution = {REWERSE Working Group ``Adding Semantics to the Bioinformatics Web''},
	Keywords = {Design Query Languages Xcerpt Presentation REWERSE},
	Location = {Dresden, Germany},
	Owner = {Tim Furche},
	Pdf = {SemanticWeb/Xcerpt/Furche.Patranjan_XcerptandXChange_SLIDES_2004.pdf},
	Title = {{Xcerpt and XChange: Combining Querying, Reasoning and Reactivity}},
	Type = {Internal Workshop},
	Year = {2004}}

@inproceedings{Groppe.Boettcher_XPathQueryTransformation_WIDM_2003,
	Author = {Groppe, Sven and B{\"o}ttcher, Stefan},
	Booktitle = {Proc. Intl. Workshop on Web Information and Data Management},
	Conference-Abbr = {WIDM},
	Doi = {http://doi.acm.org/10.1145/956699.956723},
	Isbn = {1-58113-725-7},
	Keywords = {XML XSLT query optimization rewriting},
	Location = {New Orleans, Louisiana, USA},
	Pages = {106--110},
	Pdf = {QueryEvaluation/XML/XSLT/Groppe.Boettcher_XPathQueryTransformation_WIDM_2003.pdf},
	Publisher = {ACM Press},
	Title = {{XPath Query Transformation based on XSLT Stylesheets}},
	Url = {http://portal.acm.org/citation.cfm?id=956723},
	Year = {2003},
	Abstract = {Whenever XML data must be shared by heterogeneous applications, transformations
	 between different application-specific XML formats are necessary. The
	 state-of-the-art method transforms entire XML documents from one
	 application format into another e.g. by using an XSLT stylesheet, so that
	 each application can work locally on its preferred format. In our
	 approach, we use an XSLT stylesheet in order to transform a given
	 XPath query such that we retrieve and transform only that part of the
	 XML document which is sufficient to answer the given query. Among
	 other things, our approach avoids problems of replication, saves
	 processing time and in distributed scenarios, transportation costs.}}

@inproceedings{Grust_AcceleratingXPathLocation_SIGMOD_2002,
	Author = {Grust, Thorsten},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Keywords = {XML XPath relational implementation location steps efficiency accelerating},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XQuery/Grust_AcceleratingXPathLocation_VLDB_2003.pdf},
	Title = {{Accelerating XPath Location Steps}},
	Url = {http://www.in.tu-clausthal.de/~grust/files/xpath-accel.pdf},
	Year = {2002},
	Abstract = {This work is a proposal for a database index structure that
	 has been speci cally designed to support the evaluation of XPath
	 queries. As such, the index is capable to support all XPath axes
	 (including ancestor, following, precedingsibling, descendant-or-self,
	 etc.). This feature lets the index stand out among related work on XML
	 indexing structures which had a focus on regular path expressions (which
	 correspond to the XPath axes children and descendantor- self plus name
	 tests). Its ability to start traversals from arbitrary context nodes
	 in an XML document additionally enables the index to support the
	 evaluation of path traversals embedded in XQuery expressions. Despite
	 its exibility, the new index can be implemented and queried using
	 purely relational techniques, but it performs especially well if the
	 underlying database host provides support for R-trees. A performance
	 assessment which shows quite promising results completes this proposal.}}

@inproceedings{Grust.Sakr.ea_XQueryonSQL_VLDB_2004,
	Author = {Grust, Torsten and Sakr, Sherif and Teubner, Jens},
	Booktitle = VLDB,
	Conference-Abbr = {VLDB},
	Keywords = {XML XQuery relational implementation SQL},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XQuery/Grust.Sakr.ea_XQueryonSQL_VLDB_2004.pdf},
	Title = {{XQuery on SQL Hosts}},
	Url = {http://www.in.tu-clausthal.de/~grust/files/sql-mapping.pdf},
	Year = {2004},
	Abstract = {Relational database systems may be turned
	 into efficient XML and XPath processors if the system is provided
	 with a suitable relational tree encoding. This paper extends this
	 relational XML processing stack and shows that an RDBMS can also serve
	 as a highly efficient XQuery runtime environment. Our approach is
	 purely relational: XQuery expressions are compiled into SQL code which
	 operates on the tree encoding. The core of the compilation procedure
	 trades XQuery's notions of variable scopes and nested iteration (FLWOR
	 blocks) for equi-joins. The resulting relational XQuery processor
	 closely adheres to the language semantics, e.g., it obeys node identity
	 as well as document and sequence order, and can support XQuery's
	 full axis feature. The system exhibits quite promising performance
	 figures in experiments. Somewhat unexpectedly, we will also see that
	 the XQuery compiler can make good use of SQL's OLAP functionality.}}

@inproceedings{Guizzardi.Wagner.ea_OntologicallyWell-FoundedProfile_CAiSE_2004,
	Author = {Guizzardi, Giancarlo and Wagner, Gerd and Guarino, Nicola and van Sinderen, Marten},
	Booktitle = {Proc. Intl. Conf. on Advanced Information Systems Engineering (CAiSE)},
	Citeseercitationcount = {0},
	Conference-Abbr = {CAiSE},
	Keywords = {UML Ontology Conceptual Modelling GOL},
	Owner = {Tim Furche},
	Pages = {112--126},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{An Ontologically Well-Founded Profile for UML Conceptual Models}},
	Url = {http://is.tm.tue.nl/staff/gwagner/CAiSE2004.pdf},
	Urldate = {2005/01/02},
	Volume = {3084},
	Year = {2004},
	Abstract = {UML class diagrams can be
	 used as a language for expressing a conceptual model of a domain.
	 In a series of papers we have been using the General Ontological
	 Language (GOL) and its underlying upper level ontology to evaluate the
	 ontological correctness of a conceptual UML class model and to develop
	 guidelines for how the constructs of the UML should be used in conceptual
	 modeling. In this paper, we focus on the UML metaconcepts of classes and
	 objects from an ontological point of view. We use a philosophically and
	 psychologically well-founded theory of classifiers to propose a UML profile
	 for Ontology Representation and Conceptual Modeling. Moreover, we
	 propose a design pattern based on this profile to target a recurrent
	 problem in role modeling discussed in the literature. Finally, we
	 demonstrate the relevance of the tools proposed by applying them to
	 solve recurrent problems in the practice of conceptual modeling.}}

@inproceedings{Guo.Shao.ea_XRANKRankedKeyword_SIGMOD_2003,
	Author = {Guo, Lin and Shao, Feng and Botev, Chavdar and Shanmugasundaram, Jayavel},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Keywords = {XML query languages IR information retrieval ranking},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/InformationRetrieval/Languages/Guo.Shao.ea_XRANKRankedKeyword_SIGMOD_2003.pdf},
	Title = {{XRANK: Ranked Keyword Search over XML Documents}},
	Url = {http://www.cs.cornell.edu/People/jai/papers/XRank.pdf},
	Year = {2003},
	Abstract = {We consider the problem of efficiently producing ranked results for
	 keyword search queries over hyperlinked XML documents. Evaluating
	 keyword search queries over hierarchical XML documents, as opposed to
	 (conceptually) flat HTML documents, introduces many new challenges. First,
	 XML keyword search queries do not always return entire documents,
	 but can return deeply nested XML elements that contain the desired
	 keywords. Second, the nested structure of XML implies that the notion of
	 ranking is no longer at the granularity of a document, but at the
	 granularity of an XML element. Finally, the notion of keyword proximity
	 is more complex in the hierarchical XML data model. In this paper,
	 we present the XRANK system that is designed to handle these novel
	 features of XML keyword search. Our experimental results show that XRANK
	 offers both space and performance benefits when compared with existing
	 approaches. An interesting feature of XRANK is that it naturally
	 generalizes a hyperlink based HTML search engine such as Google.
	 XRANK can thus be used to query a mix of HTML and XML documents.}}

@inproceedings{Guo.Li.ea_ScalableXSLTEvaluation_APWEB_2004,
	Author = {Guo, Zhimao and Li, Min and Wang, Xiaoling and Zhou, Aoying},
	Booktitle = {Proc. Asia Pacific Web Conference},
	Conference-Abbr = {APWEB},
	Keywords = {XML XSLT evaluation optimization query languages},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XSLT/Guo.Li.ea_ScalableXSLTEvaluation_APWEB_2004.pdf},
	Title = {{Scalable XSLT Evaluation}},
	Url = {http://arxiv.org/abs/cs.DB/0408051},
	Year = {2004},
	Abstract = {XSLT is an increasingly popular language for
	 processing XML data. It is widely supported by application platform
	 software. However, little optimization effort has been made inside
	 the current XSLT processing engines. Evaluating a very simple XSLT
	 program on a large XML document with a simple schema may result in
	 extensive usage of memory. In this paper, we present a novel notion of
	 \emph{Streaming Processing Model} (\emph{SPM}) to evaluate a subset of
	 XSLT programs on XML documents, especially large ones. With SPM, an
	 XSLT processor can transform an XML source document to other formats
	 without extra memory buffers required. Therefore, our approach can not
	 only tackle large source documents, but also produce large results.
	 We demonstrate with a performance study the advantages of the SPM
	 approach. Experimental results clearly confirm that SPM improves
	 XSLT evaluation typically 2 to 10 times better than the existing
	 approaches. Moreover, the SPM approach also features high scalability.}}

@article{Hamilton.Selinger_ConversationwithPat_ACMQ_2005,
	Author = {Hamilton, James and Selinger, Pat},
	Journal = {ACM Queue},
	Journal-Abbr = {ACMQ},
	Keywords = {database vision metadata unstructured information},
	Number = {3},
	Owner = {Tim Furche},
	Title = {{A Conversation with Pat Selinger}},
	Url = {http://www.acmqueue.org/modules.php?name=Content&pa=showpage&pid=297&page=1},
	Volume = {3},
	Year = {2005},
	Abstract = {Take Pat Selinger of IBM and James Hamilton of Microsoft and put
	 them in a conversation together, and you may hear everything you
	 wanted to know about database technology and weren?t afraid to ask.}}

@article{Henze.Dolog.ea_ReasoningandOntologies_ETS_2004,
	Author = {Henze, Nicola and Dolog, Peter and Nejdl, Wolfgang},
	Journal = {Educational Technology Society},
	Journal-Abbr = {ETS},
	Keywords = {Personalization Personal Reader E-Learning Semantic Web},
	Owner = {Tim Furche},
	Pdf = {ApplicationAreas/Personalization/Henze.Dolog.ea_ReasoningandOntologies_ETS_2004.pdf},
	Title = {{Reasoning and Ontologies for Personalized E-Learning}},
	Url = {http://www.kbs.uni-hannover.de/Arbeiten/Publikationen/2004/ifets_final.pdf},
	Year = {2004},
	Abstract = {The challenge of the semantic web is the provision of distributed information with well
	 defined meaning, understandable for different parties. Particularly,
	 applications should be able to provide individually optimized access
	 to information by taking the individual needs and requirements of
	 the users into account. In this paper we propose a framework for
	 personalized e-Learning in the semantic web and show how the semantic web
	 resource description formats can be utilized for automatic generation of
	 hypertext structures from distributed metadata. Ontologies and metadata
	 for three types of resources (domain, user, and observation) are
	 investigated. We investigate a logic-based approach to educational
	 hypermedia using TRIPLE, a rule and query language for the semantic web.}}

@inproceedings{Henze.Herrlich_PersonalReader-Framework_ABIS_2004,
	Author = {Henze, Nicola and Herrlich, Marc},
	Booktitle = {Proc. Workshop on Adaptation and User Modeling in Interactive Systems},
	Conference-Abbr = {ABIS},
	Keywords = {Personalization Semantic Web Personal Reader RDF},
	Owner = {Tim Furche},
	Pdf = {ApplicationAreas/Personalization/Henze.Herrlich_PersonalReader-Framework_ABIS_2004.pdf},
	Title = {{The Personal Reader: A Framework for Enabling Personalization Services on the Semantic Web}},
	Url = {http://www.kbs.uni-hannover.de/Arbeiten/Publikationen/2004/Personal_Reader_abis04.pdf},
	Year = {2004},
	Abstract = {The Personal Reader provides a framework for
	 designing, implementing and maintaining web content readers, which
	 provide personalized enrichment of web content for each individual
	 user. The idea of the the Personal Reader is based on a rigorous
	 approach for applying Semantic Web technologies: A modular framework
	 of components / services - for visualizing the Personal Reader and
	 providing the user interface, for mediating between user requests and
	 available personalization services, and for providing personalized
	 recommendations and access to web content forms the basis for the Personal
	 Reader. In this paper, we describe the architectural outline of the
	 framework as well as some implementation details, and discuss the
	 approach with a reference - a ?Personal Reader for Learning Resources?.}}

@article{Henze.Nejdl_LogicalCharacterizationof_NRHM_2004,
	Author = {Henze, Nicola and Nejdl, Wolfgang},
	Journal = {New Revies on Hypertext and Hypermedia},
	Journal-Abbr = {NRHM},
	Keywords = {Personalization Personal Reader Logic Semantic Web},
	Owner = {Tim Furche},
	Pdf = {ApplicationAreas/Personalization/Henze.Nejdl_LogicalCharacterizationof_NRHM_2004.pdf},
	Title = {{A Logical Characterization of Adaptive Educational Hypermedia}},
	Url = {http://www.kbs.uni-hannover.de/Arbeiten/Publikationen/2004/logical_characterization_henze_nejdl.pdf},
	Year = {2004},
	Abstract = {Currently, adaptive educational hypermedia systems (AEHS) are described with
	 nonuniform methods, depending on the specific view on the system, the
	 application, or other parameters. There is no common language for expressing
	 functionality of AEHS, hence these systems are difficult to compare and
	 analyze. In this paper we investigate how a logical description can be
	 employed to characterize adaptive educational hypermedia. We propose a
	 definition of AEHS based on first-order logic, characterize some AEHS due
	 to this formalism, and discuss the applicability of this approach.}}

@inproceedings{Hidders_SatisfiabilityofXPath_DBPL_2003,
	Author = {Hidders, Jan},
	Booktitle = {Intl. Workshop on Databse Programming Languages},
	Conference-Abbr = {DBPL},
	Keywords = {XML XPath satisfiability query languages theory},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/PathExpressions/XPath/Hidders_SatisfiabilityofXPath_DBPL_2003.pdf},
	Title = {{Satisfiability of XPath Expressions}},
	Url = {http://plantijn.ruca.ua.ac.be/~adrem/biborb/bibs/ADReM/papers/hidders03xpathsat.pdf},
	Year = {2003},
	Abstract = {In this paper, we investigate the complexity of deciding the satisfiability
	 of XPath 2.0 expressions, i.e., whether there is an XML document
	 for which their result is nonempty. Several fragments that allow
	 certain types of expressions are classified as either in PTIME or
	 NP-hard to see which type of expression make this a hard problem.
	 Finally, we establish a link between XPath expressions and partial
	 tree descriptions which are studied in computational linguistics.}}

@inproceedings{Horst_ExtendingRDFSEntailment_ISWC_2004,
	Author = {ter Horst, Herman J.},
	Booktitle = ISWC # {, Hiroshima, Japan},
	Comment = {Two essential contributions: the notion of ?partial closure? of an RDF graph G. In contrast to the closure graph of G defined in [Hayes, RDF-MT, W3C Recommendation, 2004] that is infinite (due to the infinite number of axiomatic triples for all rdf:_i properties), the partial closure is finite by considering only the axiomatic triples for all rdf:_i actually occuring in the G. The second contribution of this paper is an interesting restriction of OWL-DL (containing, e.g., owl:FunctionalProperty, owl:InverseFunctionalProperty, owl:sameAs, owl:inverseOf) together with an interpretation and a set of entailment rules. This could be a good start for an implementation of a restricted form of OWL on top of Xcerpt.},
	Conference-Abbr = {ISWC},
	Keywords = {RDF Entailment RDFS},
	Owner = {Tim Furche},
	Pdf = {SemanticWeb/RDF/RDFS/Horst_ExtendingRDFSEntailment_ISWC_2004.pdf},
	Title = {{Extending the RDFS Entailment Lemma}},
	Url = {http://xobjects.seu.edu.cn/resource/ISWC2004/abstracts/32980077.html},
	Urldate = {2004/11/24},
	Year = {2004},
	Abstract = {We complement the RDF semantics specification of the W3C by proving
	 decidability of RDFS entailment. Furthermore, we show completeness and
	 decidability of entailment for RDFS extended with datatypes and a
	 property-related fragment of OWL. The RDF semantics specification provides a
	 complete set of entailment rules for reasoning with RDFS, but does not
	 prove decidability of RDFS entailment: the closure graphs used in the
	 completeness proof are infinite for finite RDF graphs. We define partial
	 closure graphs, which can be taken to be finite for finite RDF graphs,
	 which can be computed in polynomial time, and which are sufficient
	 to decide RDFS entailment. We consider the extension of RDFS with
	 datatypes and a property-related fragment of OWL: FunctionalProperty,
	 InverseFunctionalProperty, sameAs, SymmetricProperty, TransitiveProperty, and
	 inverseOf. In order to obtain a complete set of simple entailment rules,
	 the semantics that we use for these extensions is in line with the
	 'if-semantics' of RDFS, and weaker than the 'iff-semantics' defining
	 D-entailment and OWL (DL or Full) entailment. Classes can be used as
	 instances, the use of FunctionalProperty and TransitiveProperty is not
	 restricted to obtain decidability, and a partial closure that is
	 sufficient for deciding entailment can be computed in polynomial time.}}

@inproceedings{HungDeng.RDF-Aggregate-Querie.2005,
	Author = {Hung, E. and Deng, Y. and Subrahmanian, V. S.},
	Booktitle = {Proc. Intl. Conf. on Data Engineering},
	Conference-Abbr = {ICDE},
	Date-Added = {2005-05-01 22:35:19 +0200},
	Date-Modified = {2005-05-01 22:35:55 +0200},
	Title = {{RDF Aggregate Queries and Views}},
	Year = {2005}}

@inproceedings{Jain.Mahajan.ea_TranslatingXSLTPrograms_WWW_2002,
	Author = {Jain, Sushant and Mahajan, Ratul and Suciu, Dan},
	Booktitle = WWW,
	Conference-Abbr = {WWW},
	Doi = {http://doi.acm.org/10.1145/511446.511526},
	Isbn = {1-58113-449-5},
	Keywords = {XML XSTL query processing relational implementation SQL},
	Location = {Honolulu, Hawaii, USA},
	Pages = {616--626},
	Publisher = {ACM Press},
	Title = {{Translating XSLT Programs to Efficient SQL Queries}},
	Url = {http://www2002.org/CDROM/refereed/226/},
	Year = {2002},
	Abstract = {We present an algorithm for translating XSLT
	 programs into SQL. Our context is that of virtual XML publishing,
	 in which a single XML view is defined from a relational database,
	 and subsequently queried with XSLT programs. Each XSLT program is
	 translated into a single SQL query and run entirely in the database
	 engine. Our translation works for a large fragment of XSLT, which we
	 define, that includes descendant/ancestor axis, recursive templates,
	 modes, parameters, and aggregates. We put considerable effort in
	 generating correct and efficient SQL queries and describe several
	 optimization techniques to achieve this efficiency. We have tested our
	 system on all 22 SQL queries of the TPC-H database benchmark which we
	 represented in XSLT and then translated back to SQL using our translator.}}

@inproceedings{Johnson.Shneiderman_Tree-maps-Space-FillingApproach_Vis_1991,
	Author = {Johnson, Brian and Shneiderman, Ben},
	Booktitle = {Proc. Intl. Conf.on Visualization},
	Conference-Abbr = {Vis},
	Keywords = {visualization hiearchical structures tree map},
	Owner = {Tim Furche},
	Pages = {284--291},
	Pdf = {QueryEvaluation/XML/Visualization/Johnson.Shneiderman_Tree-maps-Space-FillingApproach_Vis_1991.pdf},
	Title = {{Tree-maps: a Space-Filling Approach to the Visualization of Hierarchical Information Structures}},
	Url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?arnumber=175815&isnumber=4467&punumber=362&k2dockey=175815@ieeecnfs&query=%28shneiderman+b.%3CIN%3Eau+%29&pos=1&arSt=284&ared=291&arAuthor=Johnson%2C+B.%3B+Shneiderman%2C+B.%3B},
	Year = {1991},
	Abstract = {A method for visualizing
	 hierarchically structured information is described. The tree-map
	 visualization technique makes 100% use of the available display space,
	 mapping the full hierarchy onto a rectangular region in a space-filling
	 manner. This efficient use of space allows very large hierarchies to
	 be displayed in their entirety and facilitates the presentation of
	 semantic information. Tree-maps can depict both the structure and
	 content of the hierarchy. However, the approach is best suited to
	 hierarchies in which the content of the leaf nodes and the structure of the
	 hierarchy are of primary importance, and the content information
	 associated with internal nodes is largely derived from their children}}

@book{Katz.Chamberlin.ea_XQueryfromExperts_2003,
	Author = {Katz, Howard and Chamberlin, Don and Draper, Denise and Fernandez, Mary and Kay, Michael and Robie, Jonathan and Rys, Michael and Simeon, Jerome and Tivy, Jim and Wadler., Philip},
	Edition = {1st},
	Owner = {Tim Furche},
	Publisher = {Addison-Wesley},
	Title = {{XQuery from the Experts: A Guide to the W3C XML Query Language}},
	Year = {2003}}

@book{Kay_XPath-2.0Programmer-sReference_2004,
	Author = {Kay, Michael},
	Keywords = {XML XPath query query languages},
	Owner = {Tim Furche},
	Publisher = {John Wiley},
	Title = {{XPath 2.0 Programmer's Reference}},
	Year = {2004},
	Abstract = {XPath 2.0 Programmer's Reference is the only
	 authoritative reference on XPath, a sub-language within XSLT that
	 determines which part of an XML document the XSLT transforms. Written for
	 professional programmers who use XML every day but find the W3C XPath
	 specifications tough to slog through, this book explains in everyday language
	 what every construct in the language does and how to use it. It also
	 offers background material on the design thinking behind the language,
	 gentle criticism of the language specification when appropriate, and a
	 diverse range of interesting examples in various application areas.}}

@book{Kay_XSLT2.0Programmers_2004,
	Author = {Kay, Michael},
	Edition = {3rd},
	Keywords = {XML XSLT Programming Query languages},
	Owner = {Tim Furche},
	Publisher = {John Wiley},
	Title = {{XSLT 2.0 Programmer's Reference}},
	Year = {2004},
	Abstract = {XSLT 2.0 Programmer's Reference, 3rd Edition, is the
	 authoritative reference guide to the language. Without using the formal and
	 inaccessible language of the W3C specifications, it tells you exactly
	 what every construct in the language does, and how it is intended
	 to be used. This book is a reference rather than a tutorial; it is
	 designed for the professional programmer who is using the language
	 every day. It is the book that people quote when they claim that a
	 particular product is giving the wrong answer, and the book that
	 implementers of the language turn to when they want clarification of
	 the specifications. At the same time, the book is readable. Reviews
	 of the previous editions of the XSLT Programmer?s Reference, which
	 this book grew from, show that readers appreciate the background
	 material on the design thinking behind the language, the essay on
	 functional programming, the occasional dry wit, the gentle criticism of
	 the language specification when appropriate, and the fact that the
	 examples stray into a diverse range of interesting application areas.}}

@inproceedings{Kay_XSLTandXPath_XMLE_2004,
	Author = {Kay, Michael},
	Booktitle = {XML Europe},
	Conference-Abbr = {XMLE},
	Keywords = {XML XSLT XPath optimization saxon practical experiences},
	Owner = {Tim Furche},
	Title = {{XSLT and XPath Optimization}},
	Url = {http://idealliance.org/papers/dx_xmle04/papers/02-03-02/02-03-02.html},
	Year = {2004}}

@techreport{Kay.Walsh.ea_XSLT2.0and_TR_2005,
	Author = {Kay, Michael and Walsh, Norman and Zongaro, Henry and Boag, Scott and Tong, Joanne},
	Institution = {W3C},
	Keywords = {XML XQuery XSLT serialization query languages},
	Owner = {Tim Furche},
	Title = {{XSLT 2.0 and XQuery 1.0 Serialization}},
	Type = {Working Draft},
	Url = {http://www.w3.org/TR/xslt-xquery-serialization/This document defines serialization of an instance of the data model as defined in [Data Model] into a sequence of octets. [Definition: Serialization is designed to be a component of a expanded a host language such as[XSLT 2.0] or [XQuery 1.0].]},
	Year = {2005},
	Abstract = {This document defines serialization of an
	 instance of the data model as defined in [Data Model] into a sequence of
	 octets. [Definition: Serialization is designed to be a component
	 of a expanded a host language such as[XSLT 2.0] or [XQuery 1.0].]}}

@techreport{KlyneCarroll.Resource-Description.2004,
	Author = {Klyne, Graham and Carroll, Jeremy J. and McBride, Brian},
	Date-Added = {2005-05-01 22:06:41 +0200},
	Date-Modified = {2005-05-01 22:08:12 +0200},
	Institution = {W3C},
	Keywords = {RDF Semantic Web Concepts Abstract Syntax Primer},
	Title = {{Resource Description Framework (RDF): Concepts and Abstract Syntax}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/rdf-concepts/},
	Year = {2004},
	Abstract = {The Resource Description Framework
	 (RDF) is a framework for representing information in the Web. RDF
	 Concepts and Abstract Syntax defines an abstract syntax on which RDF is
	 based, and which serves to link its concrete syntax to its formal
	 semantics. It also includes discussion of design goals, key concepts,
	 datatyping, character normalization and handling of URI references.}}

@inproceedings{Koch.Scherzinger.ea_FluXQuery-OptimizingXQuery_VLDB_2004,
	Author = {Koch, Christoph and Scherzinger, Stefanie and Schweikardt, Nicole and Stegmaier, Bernhard},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = VLDB,
	Conference-Abbr = {VLDB},
	Ee = {http://www.vldb.org/conf/2004/RS6P2.PDF},
	Keywords = {XML XQuery stream implementation FluXQuery},
	Pdf = {QueryEvaluation/XML/XQuery/Koch.Scherzinger.ea_FluXQuery-OptimizingXQuery_VLDB_2004.pdf},
	Title = {{FluXQuery: An Optimizing XQuery Processor for Streaming XML Data}},
	Url = {http://www.wit.at/people/scherzinger/documents/demo.pdf},
	Year = {2004}}

@inproceedings{Koffina.Serfiotis.ea_IntegratingXMLData_DOPS_2005,
	Author = {Koffina, Ioanna and Serfiotis, Giorgos and Christophides, Vassilis and Tannen, Val and Deutsch, Alin},
	Booktitle = {Dagstuhl Seminar on Semantic Interoperability and Integration},
	Conference-Abbr = {DROPS},
	Keywords = {integration , xml , rdf schema},
	Number = {04391},
	Pdf = {SemanticWeb/RDF/RDF-XML-Integration/Koffina.Serfiotis.ea_IntegratingXMLData_DOPS_2005.pdf},
	Publisher = {IBFI},
	Series = {Dagstuhl Seminar Proceedings},
	Title = {{Integrating XML Data Sources using RDF/S Schemas: The ICS-FORTH Semantic Web Integration Middleware (SWIM)}},
	Url = {http://drops.dagstuhl.de/opus/volltexte/2005/34/pdf/04391.ChristophidesVassilis.Paper.34.pdf},
	Year = {2005},
	Abstract = {Semantic Web (SW) technology aims to facilitate
	 the integration of legacy data sources spread worldwide. Despite
	 the plethora of SW languages e.g., RDF/S, OWL recently proposed for
	 supporting large scale information interoperation, the vast majority of
	 legacy sources still rely on relational databases RDB published on
	 the Web or corporate intranets as virtual XML. In this paper, we
	 advocate a Datalog framework for mediating high level queries to
	 relational and or XML sources using community ontologies expressed in
	 a SW language such as RDF/S. We describe the architecture and the
	 reasoning services of our SW integration middleware, called SWIM, and we
	 present the main design choices and techniques for supporting powerful
	 mappings between different data models, as well as reformulation and
	 optimization of queries expressed against mediation schemas and views.}}

@mastersthesis{Kraus_UseCasesfur_2004,
	Author = {Kraus, Sebastian},
	Keywords = {XML Xcerpt use cases},
	Pdf = {QueryEvaluation/Xcerpt/Kraus_UseCasesfur_2004.pdf},
	School = {University of Munich},
	Title = {{Use Cases f{\"u}r Xcerpt: Eine positionelle Anfrage- und Transformationssprache f{\"u}r das Web}},
	Type = {{Diplomarbeit/Master thesis}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#DA_Sebastian.Kraus},
	Year = {2004},
	Abstract = {In dieser Arbeit werden Anwendungsflle f{\"u}r die logische Anfragesprache Xcerpt
	 vorgestellt und implementiert. Zweck dieser Arbeit ist hierbei, die
	 Sprache Xcerpt, welche sich noch in einem Entwicklungszustand befindet,
	 bez{\"u}glich ihrer Ausdrucksfhigkeit und Mchtigkeit zu untersuchen und
	 gegebenenfalls notwendige und noch fehlende Konstrukte und Funktionalitten zu
	 identifizieren. Hierbei werden zum einem die W3C Anwendungsflle f{\"u}r
	 XQuery in Xcerpt implementiert, da diese wegen ihrer Vielzahl von
	 unterschiedlichen Szenarien und somit unterschiedlichen Anfragen als
	 Ma{\ss}stab f{\"u}r eine Anfragesprache herangezogen werden k{\"o}nnen. Zum
	 anderen werden drei kleiner Anwendungsszenarien vorgestellt, die
	 spezielle Fhigkeiten von Xcerpt hervorheben sollen. In dem ersten
	 dieser Szenarien wird der internen Referenzmechanismus von Xcerpt
	 vorgestellt. Da Xcerpt als Webanfragsprache konzipiert wurde, wird in der
	 zweiten Anwendung ein Webcrawler vorgestellt. Die dritte Anwendung
	 beinhaltet Xcerpt-Regel, wie sie ein Mediatorsystem verwenden k{\"o}nnte,
	 um die Transformationsm{\"o}glichkeiten der Sprache hervorzuheben.}}

@inproceedings{Li.Bohannon.ea_ComposingXSLTransformations_SIGMOD_2003,
	Author = {Li, Chengkai and Bohannon, Philip and Narayan, P. P. S.},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Doi = {http://doi.acm.org/10.1145/872757.872820},
	Isbn = {1-58113-634-X},
	Keywords = {XML XSLT view query rewriting evaluation optimization},
	Location = {San Diego, California},
	Pages = {515--526},
	Publisher = {ACM Press},
	Title = {{Composing XSL Transformations with XML Publishing Views}},
	Url = {http://www.ews.uiuc.edu/~cli/417-li.pdf},
	Year = {2003},
	Abstract = {While the XML Stylesheet Language
	 for Transformations (XSLT) was not designed as a query language,
	 it is well-suited for many query-like operations on XML documents
	 including selecting and restructuring data. Further, it actively
	 fulfills the role of an XML query language in modern applications and
	 is widely supported by application platform software. However, the
	 use of database techniques to optimize and execute XSLT has only
	 recently received attention in the research community. In this paper, we
	 focus on the case where XSL transformations are to be run on XML
	 documents defined as views of relational databases. For a subset
	 of XSLT, we present an algorithm to compose a transformation with
	 an XML view, eliminating the need for the XSLT execution. We then
	 describe how to extend this algorithm to handle several additional
	 features of XSLT, including a proposed approach for handling recursion.}}

@inproceedings{Liu.Vincent_Querytranslationfrom_DEAS_2003,
	Author = {Liu, Jixue and Vincent, Millist},
	Booktitle = {Proc. Intl. Database Engineering and Applications Symposium},
	Conference-Abbr = {DEAS},
	Keywords = {XML XSLT relational implementation SQL query evaluation},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XSLT/Liu.Vincent_Querytranslationfrom_DEAS_2003.pdf},
	Title = {{Query translation from XSLT to SQL}},
	Year = {2003},
	Abstract = {XML has been accepted as a universal
	 format for data interchange and publication. It can be applied in the
	 applications in which the data of a database needs to be viewed in
	 XML format so that the data being viewed takes more semantics and
	 is easily understood. In these applications, the user of the data
	 to be viewed sees only XML data, not the database. He may use XML
	 query languages such as XSLT to query data and the retrieved data is
	 presented in XML format to them. We are interested in the connection
	 between the data that the user sees and the data in the database. More
	 specifically, we are interested in translating XSLT queries to SQL queries.}}

@techreport{Malhotra.Melton.ea_XQuery1.0and_TR_2005,
	Author = {Malhotra, Ashok and Melton, Jim and Walsh, Norman},
	Institution = {W3C},
	Keywords = {XML XQuery Functuions Operators XPath W3C Query Query Languages},
	Owner = {Tim Furche},
	Title = {{XQuery 1.0 and XPath 2.0 Functions and Operators}},
	Type = {Working Draft},
	Url = {http://www.w3.org/TR/xpath-functions/},
	Urldate = {2005/01/31},
	Year = {2005},
	Abstract = {This document defines basic operators and functions on the datatypes defined in [XML
	 Schema Part 2: Datatypes Second Edition] and the datatypes defined in
	 [XQuery 1.0 and XPath 2.0 Data Model] and in this document for use
	 in [XPath 2.0], [XQuery 1.0: An XML Query Language] and [XSLT 2.0]
	 and other related XML standards. It also discusses operators and
	 functions on nodes and node sequences as defined in the [XQuery 1.0
	 and XPath 2.0 Data Model] for use in [XPath 2.0], [XQuery 1.0: An
	 XML Query Language] and [XSLT 2.0] and other related XML standards.}}

@techreport{Manola.Miller.ea_RDFPrimer_TR_2004,
	Author = {Manola, Frank and Miller, Eric and McBride, Brian},
	Date-Added = {2005-05-01 22:06:41 +0200},
	Date-Modified = {2005-05-01 22:08:12 +0200},
	Institution = {W3C},
	Keywords = {RDF Semantic Web Concepts Abstract Syntax},
	Title = {{RDF Primer}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/rdf-primer/},
	Year = {2004},
	Abstract = {The Resource Description Framework (RDF) is a
	 language for representing information about resources in the World Wide
	 Web. This Primer is designed to provide the reader with the basic
	 knowledge required to effectively use RDF. It introduces the basic
	 concepts of RDF and describes its XML syntax. It describes how to
	 define RDF vocabularies using the RDF Vocabulary Description Language,
	 and gives an overview of some deployed RDF applications. It also
	 describes the content and purpose of other RDF specification documents.}}

@inproceedings{Manola.Pirotte_CQLF---aQueryLanguage_SIGMOD_1982,
	Author = {Manola, Frank and Pirotte, Alain},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Doi = {http://doi.acm.org/10.1145/582353.582369},
	Isbn = {0-89791-073-7},
	Keywords = {CODASYL network databases query languages CQLF path expressions},
	Location = {Orlando, Florida},
	Pages = {94--103},
	Pdf = {QueryEvaluation/Languages/Manola.Pirotte_CQLF---aQueryLanguage_SIGMOD_1982.pdf},
	Publisher = {ACM Press},
	Title = {{CQLF---a Query Language for CODASYL-type Databases}},
	Url = {http://portal.acm.org/citation.cfm?id=582369},
	Year = {1982},
	Abstract = {This paper describes CQLF (CODASYL Query Language, Flat) [MAN081].
	 CQLF is a high level language for accessing and manipulating data in
	 databases described using the 1981 ANSI dpANS version of the CODASYL Data
	 Description Language [ANSI81]. CQLF has similarities to typical relational
	 languages, such as SQL [ASTR76, CHAM76] and QUEL [STON76]. CQLF provides
	 capabilities for querying and operating on databases described both
	 in a "relational style" (having no CODASYL sets, using only values
	 to represent interrecord relationships, and having records with no
	 arrays), and in a "network style" (using CODASYL sets to represent
	 interrecord relationships, and having records containing arrays).}}

@inproceedings{Martens.Neven_FrontiersofTractability_PODS_2004,
	Author = {Martens, Wim and Neven, Frank},
	Booktitle = PODS,
	Conference-Abbr = {PODS},
	Keywords = {XML transformations type checking tractability},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XSLT/Martens.Neven_FrontiersofTractability_PODS_2004.pdf},
	Title = {{Frontiers of Tractability for Typechecking Simple XML Transformations}},
	Url = {http://www.sigmod.org/sigmod/pods/proc04/pdf/P-03.pdf},
	Year = {2004}}

@inproceedings{May.Helmer.ea_QuantifiersinXQuery_WISE_2003,
	Author = {May, Norman and Helmer, Sven and Moerkotte, Guido},
	Booktitle = {Proc. Intl. Conf. on Web Information Systems Engineering},
	Conference-Abbr = {WISE},
	Keywords = {XML XQuery quantifiers nested queries optimization rewriting},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XQuery/May.Helmer.ea_QuantifiersinXQuery_WISE_2003.pdf},
	Title = {{Quantifiers in XQuery}},
	Url = {http://pi3.informatik.uni-mannheim.de/~norman/unnesting_wise03.pdf},
	Year = {2003},
	Abstract = {We present algebraic equivalences that allow to unnest nested
	 algebraic expressions containing quantifiers for order-preserving
	 algebraic operators. We illustrate how these equivalences can be
	 applied successfully to unnest nested queries formulated in XQuery.
	 Measurements illustrate the performance gains possible by unnesting.}}

@inproceedings{Meuss.Schulz.ea_TowardsAggregatedAnswers_ICDT_2001,
	Author = {Meuss, Holger and Schulz, Klaus U. and Bry, Fran{\c c}ois},
	Booktitle = {Proc. Intl. Conf. on Database Theory},
	Conference-Abbr = {ICDT},
	Isbn = {3-540-41456-8},
	Keywords = {XML query languages CAA navigation theory path visualization},
	Pages = {346--360},
	Publisher = {Springer-Verlag},
	Title = {{Towards Aggregated Answers for Semistructured Data}},
	Url = {http://www.pms.ifi.lmu.de/publikationen#PMS-FB-2000-15},
	Year = {2001},
	Abstract = {Semistructured data are usually
	 formalized as trees or more generally as graphs. Query languages for
	 semistructured data have been proposed that, like SQL, can be seen as
	 involving a number of variables, but, in contrast to SQL, arrange
	 the variables in trees or graphs reflecting the structure of the
	 semistructured data to be retrieved. Leaving aside the ``construct''
	 parts of queries, answers can be formalized as mappings represented
	 as tuples, hence called answer tuples, that assign database nodes
	 to query variables. These answer tuples underly the semistructured
	 data delivered as answers. A simple enumeration of answer tuples
	 following the old relational approach is problematic for several reasons.
	 First, the number of answer tuples for a query may grow exponentially
	 in the size of both, the query and the database. Second, even if
	 the number of answer tuples is manageable, the frequent sharing of
	 common data between distinct answer tuples is no more apparent in
	 their enumeration. In this article, it is first argued that, in the
	 context of semistructured data, enumerating answer tuples is often
	 inappropriate and that aggregated answers are preferable. Then, a
	 notion of aggregated answers called complete answer aggregate (CAA) is
	 introduced and algorithms for computing CAAs are given. It is shown
	 that CAAs enjoy nice complexity properties: (1) While the number of
	 answer tuples may be exponential in the size of the query, the size of
	 the CAA is at most linear in the size of the query and quadratic
	 in the size of the database; (2) the complexity of computing the
	 CAA of a query depends on the query's structural complexity (i.e.
	 whether it is a sequence, tree, graph, etc.) but is independent of the
	 structural complexity of the database. For tree queries, efficient
	 polynomial algorithms are given. Besides, it is argued that CAAs are
	 particularly appropriate for answer searching and answer browsing.}}

@article{Meuss.Schulz.ea_VisualExplorationand_JDL_2005,
	Author = {Meuss, Holger and Schulz, Klaus U. and Weigel, Felix and Leonardi, Simone and Bry, Fran{\c c}ois},
	Journal = {Journal on Digital Libraries},
	Journal-Abbr = {JDL},
	Keywords = {XML query languages visualization exploration X2 CAA},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Visualization/Meuss.Schulz.ea_VisualExplorationand_JDL_2005.pdf},
	Title = {{Visual Exploration and Retrieval of XML Document Collections with the Generic System X2}},
	Url = {http://www.cis.uni-muenchen.de/~weigel/Literatur/meuss04visual.pdf},
	Year = {2005},
	Abstract = {This article reports on the XML retrieval system X2 which has been developed
	 at the University of Munich over the last five years. In a typical
	 session with X2, the user first browses a structural summary of the
	 XML database in order to select interesting elements and keywords
	 occurring in documents. Using this intermediate result, queries combining
	 structure and textual references are composed semiautomatically.
	 After query evaluation, the full set of answers is presented in a
	 visual and structured way. X2 largely exploits the structure found in
	 documents, queries and answers to enable new interactive visualization and
	 exploration techniques that support mixed IR and database-oriented
	 querying, thus bridging the gap between these three views on the
	 data to be retrieved. Another salient characteristic of X2 which
	 distinguishes it from other visual query systems for XML is that
	 it supports various degrees of detailedness in the presentation of
	 answers, as well as techniques for dynamically reordering and grouping
	 retrieved elements once the complete answer set has been computed.}}

@inproceedings{Meyer.Bruder.ea_XircusSearchEngine_INEX_2002,
	Author = {Meyer, Holger and Bruder, Ilvio and Heuer, Andreas and Weber, Gunnar},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {INEX Workshop},
	Conference-Abbr = {INEX},
	Pages = {119-124},
	Title = {{The Xircus Search Engine}},
	Year = {2002},
	Abstract = {Nowadays, XML is the document model in favour for both document- and data-centric web
	 applications. Its influence in other, more traditional projects and
	 applications grows as the web and associated techniques become the de-facto
	 standard in user interfaces in such systems. We present an XML-sensitive
	 search engine (Xircus) suited for processing semi-structured queries
	 over large collections of XML documents. Xircus is based on state
	 of the art information retrieval techniques. It is a test bed for
	 research in query processing for XML and semistructured data in general.}}

@inproceedings{Miklau.Suciu_ContainmentandEquivalence_PODS_2002,
	Author = {Miklau, Gerome and Suciu, Dan},
	Booktitle = PODS,
	Conference-Abbr = {PODS},
	Doi = {http://doi.acm.org/10.1145/543613.543623},
	Isbn = {1-58113-507-6},
	Keywords = {XML XPath fragment containment query languages},
	Location = {Madison, Wisconsin},
	Pages = {65--76},
	Pdf = {QueryEvaluation/PathExpressions/XPath/Miklau.Suciu_ContainmentandEquivalence_PODS_2002.pdf},
	Publisher = {ACM Press},
	Title = {{Containment and Equivalence for an XPath Fragment}},
	Url = {http://www.cs.washington.edu/homes/suciu/pods2002MS.pdf},
	Year = {2002},
	Abstract = {XPath is a simple language for navigating an XML document and selecting a set of element
	 nodes. XPath expressions are used to query XML data, describe key
	 constraints, express transformations, and reference elements in remote
	 documents. This paper studies the containment and equivalence problems
	 for a fragment of the XPath query language, with applications in
	 all these contexts.In particular, we study a class of XPath queries
	 that contain branching, label wildcards and can express descendant
	 relationships between nodes. Prior work has shown that languages which
	 combine any two of these three features have efficient containment
	 algorithms. However, we show that for the combination of features,
	 containment is coNP-complete. We provide a sound and complete EXPTIME
	 algorithm for containment, and study parameterized PTIME special cases.
	 While we identify two parameterized classes of queries for which
	 containment can be decided efficiently, we also show that even with
	 some bounded parameters, containment is coNP-complete. In response
	 to these negative results, we describe a sound algorithm which is
	 efficient for all queries, but may return false negatives in some cases.}}

@inproceedings{Munroe.Papakonstantinou_BBQ-VisualInterface_VDB_2000,
	Author = {Munroe, Kevin D. and Papakonstantinou, Yannis},
	Booktitle = {Proc. Conf. on Visual Database Systems},
	Conference-Abbr = {VDB},
	Isbn = {0-7923-7835-0},
	Keywords = {XML query visualization XMAS BBQ interface},
	Pages = {277--296},
	Pdf = {QueryEvaluation/XML/Visualization/Munroe.Papakonstantinou_BBQ-VisualInterface_VDB_2000.pdf},
	Publisher = {Kluwer, B.V.},
	Title = {{BBQ: A Visual Interface for Integrated Browsing and Querying of XML}},
	Url = {http://www.db.ucsd.edu/publications/bbq.pdf},
	Year = {2000},
	Abstract = {In this paper we present BBQ (Blended Browsing and Querying),
	 a graphic user interface for seamlessly browsing and querying XML
	 data sources. BBQ displays the structure of multiple data sources
	 using a paradigm that resembles drilling-down in Windows? directory
	 structures. BBQ allows queries incorporating one or more of the sources.
	 Queries are constructed in a query-by-example (QBE) manner, where
	 DTDs play the role of schema. The queries are arbitrary conjunctive
	 queries with GROUPBY, and their results can be subsequently used and
	 refined. To support query refinement, BBQ introduces virtual result
	 views: standalone virtual data sources that (i) are constructed by
	 user queries, from elements in other data sources, and (ii) can be
	 used in subsequent queries as first-class data sources themselves.
	 Furthermore, BBQ allows users to query data sources with loose or incomplete
	 schema, and can augment such schema with a DTD inference mechanism.}}

@inproceedings{Murata.Tozawa.ea_XMLAccessControl_CCS_2003,
	Author = {Murata, Makoto and Tozawa, Akihiko and Kudo, Michiharu and Hada, Satoshi},
	Booktitle = {Proc. ACM Conf. on Computer and Communications Security},
	Conference-Abbr = {CCS},
	Doi = {http://doi.acm.org/10.1145/948109.948122},
	Isbn = {1-58113-738-9},
	Keywords = {XML XQuery access control policy},
	Location = {Washington D.C., USA},
	Pages = {73--84},
	Pdf = {QueryEvaluation/XML/XQuery/Murata.Tozawa.ea_XMLAccessControl_CCS_2003.pdf},
	Publisher = {ACM Press},
	Title = {{XML Access Control using Static Analysis}},
	Url = {http://portal.acm.org/citation.cfm?id=948122},
	Year = {2003},
	Abstract = {Access control policies
	 for XML typically use regular path expressions such as XPath for
	 specifying the objects for access control policies. However such
	 access control policies are burdens to the engines for XML query
	 languages. To relieve this burden, we introduce static analysis for XML
	 access control. Given an access control policy, query expression,
	 and an optional schema, static analysis determines if this query
	 expression is guaranteed not to access elements or attributes that are
	 permitted by the schema but hidden by the access control policy. Static
	 analysis can be performed without evaluating any query expression
	 against an actual database. Run-time checking is required only when
	 static analysis is unable to determine whether to grant or deny access
	 requests. A nice side-effect of static analysis is query optimization:
	 access-denied expressions in queries can be evaluated to empty lists at
	 compile time. We have built a prototype of static analysis for XQuery,
	 and shown the effectiveness and scalability through experiments.}}

@inproceedings{ONeil.ONeil.ea_ORDPATHs-Insert-friendlyXML_SIGMOD_2004,
	Author = {O'Neil, Patrick and O'Neil, Elizabeth and Pal, Shankar and Cseri, Istvan and Schaller, Gideon and Westbury, Nigel},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Doi = {http://doi.acm.org/10.1145/1007568.1007686},
	Isbn = {1-58113-859-8},
	Keywords = {XML encoding XQuery relational implementation},
	Location = {Paris, France},
	Pages = {903--908},
	Pdf = {QueryEvaluation/XML/XQuery/O'Neil.O'Neil.ea_ORDPATHs-Insert-friendlyXML_SIGMOD_2004.pdf},
	Publisher = {ACM Press},
	Title = {{ORDPATHs: Insert-friendly XML Node Labels}},
	Url = {http://www.cs.umb.edu/~poneil/ordpath.pdf},
	Year = {2004},
	Abstract = {We introduce a hierarchical labeling scheme called ORDPATH that is
	 implemented in the upcoming version of Microsoft{\textregistered} SQL
	 Server?. ORDPATH labels nodes of an XML tree without requiring a
	 schema (the most general case---a schema simplifies the problem). An
	 example of an ORDPATH value display format is "1.5.3.9.1". A compressed
	 binary representation of ORDPATH provides document order by simple
	 byte-by-byte comparison and ancestry relationship equally simply.
	 In addition, the ORDPATH scheme supports insertion of new nodes at
	 arbitrary positions in the XML tree, their ORDPATH values "careted in"
	 between ORDPATHs of sibling nodes, without relabeling any old nodes.}}

@article{Oliboni.Tanca_VisualLanguageshould_IS_2002,
	Author = {Oliboni, Barbara and Tanca, Letizia},
	Doi = {http://dx.doi.org/10.1016/S0306-4379(02)00007-8},
	Issn = {0306-4379},
	Journal = {Information Systems},
	Journal-Abbr = {IS},
	Keywords = {XML query languages XML-GL recursion},
	Number = {7},
	Pages = {459--486},
	Publisher = {Elsevier Science Ltd.},
	Title = {{A Visual Language should be easy to use: a Step Forward for XML-GL}},
	Volume = {27},
	Year = {2002},
	Abstract = {XML is spreading out as a standard for
	 semistructured documents on the Web, so the possibility of querying
	 XML documents which are linked by XML links is becoming a goal to
	 achieve. In this paper we present XML-GLrec, an extended version
	 of the graphical query language for XML documents XML-GL. XML-GL
	 allows to extract and restructure information from XML specified
	 WWW documents. We extend XML-GL in the following directions: (i)
	 XML-GLrec allows to represent XML simple finks, so that it is possible to
	 query whole XML specified WWW sites in a simple and intuitive way;
	 (ii) XML-GLrec improves the expressive power of XML-GL, where only
	 transitive closure can be expressed, by allowing generic recursion; (iii)
	 finally, we permit the user to specify queries in an easier fashion,
	 by allowing sequences of nested query, in the same way as in SQL.}}

@phdthesis{Olteanu_EvaluationofXPath_2005,
	Author = {Olteanu, Dan},
	Keywords = {XML query streams rewriting forward XPath LGQ complexity query languages XPath SPEX},
	Owner = {Tim Furche},
	School = {University of Munich},
	Title = {{Evaluation of XPath Queries against XML Streams}},
	Type = {{Dissertation/Ph.D. thesis}},
	Year = {2005},
	Abstract = {XML is nowadays the de facto standard for
	 electronic data interchange on the Web. Available XML data ranges from
	 small Web pages to ever-growing repositories of, e.g., biological and
	 astronomical data, and even to rapidly changing and possibly unbounded
	 streams, as used in Web data integration and publish-subscribe systems.
	 Animated by the ubiquity of XML data, the basic task of XML querying is
	 becoming of great theoretical and practical importance. The last years
	 witnessed efforts as well from practitioners, as also from theoreticians
	 towards defining an appropriate XML query language. At the core of
	 this common effort has been identified a navigational approach for
	 information localization in XML data, comprised in a practical and simple
	 query language called XPath [1]. This work brings together the two
	 aforementioned ?worlds?, i.e., the XPath query evaluation and the XML data
	 streams, and shows as well theoretical as also practical relevance
	 of this fusion. Its relevance can not be subsumed by traditional
	 database management systems, because the latter are not designed for
	 rapid and continuous loading of individual data items, and do not
	 directly support the continuous queries that are typical for stream
	 applications. The first central contribution of this work consists in the
	 definition and the theoretical investigation of three term rewriting
	 systems to rewrite queries with reverse predicates, like parent or
	 ancestor, into equivalent forward queries, i.e., queries without
	 reverse predicates. Our rewriting approach is vital to the evaluation
	 of queries with reverse predicates against unbounded XML streams,
	 because neither the storage of past fragments of the stream, nor
	 several stream traversals, as required by the evaluation of reverse
	 predicates, are affordable. Beyond their declared main purpose of providing
	 equivalences between queries with reverse predicates and forward
	 queries, the applications of our rewriting systems shed light on
	 other query language properties, like the expressivity of some of its
	 fragments, the query minimization, or even the complexity of query
	 evaluation. For example, using these systems, one can rewrite any
	 graph query into an equivalent forward forest query. The second main
	 contribution consists in a streamed and progressive evaluation strategy of
	 forward queries against XML streams. The evaluation is specified
	 using compositions of so-called stream processing functions, and is
	 implemented using networks of deterministic pushdown transducers. The
	 complexity of this evaluation strategy is polynomial in both the
	 query and the data sizes for forward forest queries and even for
	 a large fragment of graph queries. The third central contribution
	 consists in two real monitoring applications that use directly the
	 results of this work: the monitoring of processes running on UNIX
	 computers, and a system for providing graphically real-time traffic and
	 travel information, as broadcasted within ubiquitous radio signals.}}

@inproceedings{Olteanu.Furche.ea_EfficientSingle-PassQuery_SAC_2004,
	Author = {Olteanu, Dan and Furche, Tim and Bry, Fran{\c c}ois},
	Booktitle = {Data Streams Track,} # SAC,
	Conference-Abbr = {SAC},
	Keywords = {REWERSE Query Languages Query Evaluation Streams SPEX XPath},
	Organization = {ACM},
	Pdf = {QueryEvaluation/Streams/XPath/Olteanu.Furche.ea_EfficientSingle-PassQuery_SAC_2004.pdf},
	Title = {{An Efficient Single-Pass Query Evaluator for XML Data Streams}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2004-1},
	Urldate = {2004/11/11},
	Year = {2004},
	Abstract = {Data streams might be preferable to data stored in memory in contexts where
	 the data is too large or volatile, or a standard approach to data
	 processing based on data parsing and/or storing is too time or space
	 consuming. Emerging applications such as publish-subscribe systems, data
	 monitoring in sensor networks, financial and traffic monitoring,
	 and routing of MPEG-7 call for querying data streams. In many such
	 applications, XML streams are arguably more appropriate than flat
	 data streams, for XML data is record-like, though not precluding
	 multiple occurrences of fields with the same name. Evaluating selection
	 queries against XML streams is especially challenging because XML
	 data is structured (like records) and might have unbounded size.This
	 paper proposes an efficient single-pass evaluator of XPath queries
	 against XML data streams unbounded (possibly infinite) in size. The
	 evaluator is based on networks of independent deterministic pushdown
	 transducers and it is especially suitable for implementation on devices
	 with low-memory and simple logic as used, e.g., in mobile computing.}}

@inproceedings{Olteanu.Furche.ea_EvaluatingComplexQueries_BNCOD_2003,
	Author = {Olteanu, Dan and Furche, Tim and Bry, Fran{\c c}ois},
	Booktitle = BNCOD,
	Conference-Abbr = {BNCOD},
	Keywords = {Streams Path Expressions XML XPath Query Evaluation},
	Pdf = {QueryEvaluation/Streams/XPath/Olteanu.Furche.ea_EvaluatingComplexQueries_BNCOD_2003.pdf},
	Title = {{Evaluating Complex Queries against XML streams with Polynomial Combined Complexity}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2003-15},
	Urldate = {2004/11/11},
	Year = {2003},
	Abstract = {Querying of XML streams is
	 receiving much attention due to its growing range of applications from
	 traffic monitoring to routing of media streams. Existing approaches to
	 querying XML streams consider restricted query language fragments,
	 in most cases with exponential worst-case complexity in the size
	 of the query. This paper investigates the complexity of the SPEX
	 evaluation method. The combined complexity of this method is shown to be
	 polynomial in the size of the data and the query. Extensive experimental
	 evaluation with a prototype confirm the theoretical complexity results.}}

@talk{Olteanu.Meuss.ea_SymmetryinXPath_SLIDES_2001,
	Author = {Olteanu, Dan and Meuss, Holger and Furche, Tim},
	Institution = {Institute for Computer Science, University of Munich, Germany},
	Keywords = {Path Expressions Query Evaluation Streams XML Presentation},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/PathExpressions/XPath/Olteanu.Meuss.ea_SymmetryinXPath_SLIDES_2001.pdf},
	Title = {{Symmetry in XPath}},
	Type = {Oberseminar ?Knowledge Representation and Markup Languages?},
	Year = {2001}}

@inproceedings{Olteanu.Meuss.ea_XPath-LookingForward_XMLDM_2002,
	Author = {Olteanu, Dan and Meuss, Holger and Furche, Tim and Bry, Fran{\c c}ois},
	Booktitle = {Proc. EDBT Workshop on XML-Based Data Management},
	Conference-Abbr = {XMLDM},
	Pdf = {QueryEvaluation/PathExpressions/XPath/Olteanu.Meuss.ea_XPath-LookingForward_XMLDM_2002.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{XPath: Looking Forward}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2002-4},
	Urldate = {2004/11/11},
	Volume = {2490},
	Year = {2002},
	Abstract = {The location path language XPath is of particular importance for XML applications
	 since it is a core component of many XML processing standards such
	 as XSLT or XQuery. In this paper, based on axis symmetry of XPath,
	 equivalences of XPath 1.0 location paths involving ?reverse axes?, such as
	 ancestor and preceding, are established. These equivalences are used
	 as rewriting rules in an algorithm for transforming location paths
	 with reverse axes into equivalent reverse-axis-free ones. Location
	 paths without reverse axes as generated by the presented rewriting
	 algorithm enable efficient SAX-like streamed data processing of XPath.}}

@inproceedings{Olteanu.Meuss.ea_SymmetryinXPath_RMT_2001,
	Author = {Olteanu, Dan and Meuss, Holger and Furche, Tim and Bry, Fran{\c c}ois},
	Booktitle = {Proc. Seminar on Rule Markup Techniques, Schloss Dagstuhl},
	Conference-Abbr = {RMT},
	Pdf = {QueryEvaluation/Streams/XPath/Olteanu.Meuss.ea_SymmetryinXPath_RMT_2001.pdf},
	Title = {{Symmetry in XPath}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2001-16},
	Urldate = {2004/11/11},
	Year = {2001},
	Abstract = {The location path language XPath is of particular importance for XML applications
	 since it is a core component of many XML processing standards such
	 as XSLT or XQuery. In this paper, based on axis symmetry of XPath,
	 equivalences of XPath 1.0 location paths involving ?reverse axes?, such as
	 ancestor and preceding, are established. These equivalences are used
	 as rewriting rules in an algorithm for transforming location paths
	 with reverse axes into equivalent reverse-axis-free ones. Location
	 paths without reverse axes as generated by the presented rewriting
	 algorithm enable efficient SAX-like streamed data processing of XPath.}}

@inproceedings{Ono.Koyanagi.ea_XSLTStylesheetGeneration_SAINT_2002,
	Author = {Ono, Kouichi and Koyanagi, Teruo and Abe, Mari and Hori, Masahiro},
	Booktitle = {Proc. Symposium on Applications and the Internet},
	Conference-Abbr = {SAINT},
	Keywords = {XML XSLT HTML visual stylesheet generation},
	Owner = {Tim Furche},
	Title = {{XSLT Stylesheet Generation by Example with WYSIWYG Editing}},
	Url = {http://doi.ieeecomputersociety.org/10.1109/SAINT.2002.994471},
	Year = {2002},
	Abstract = {XSLT plays an important role in data conversions between different XML
	 representations. However, besides the transformations between XML data
	 representations, conversion to an HTML document is one of the most practical
	 tasks for XSLT, because it allows XML documents to be rendered in a
	 human-readable form using Web browsers. We have developed XSLbyDemo,
	 which is an XSLT stylesheet generation module to be plugged into a
	 commercially available full-fledged HTML authoring tool. The remarkable
	 feature of XSLbyDemo is that users can create an XSLT stylesheet
	 automatically solely on the basis of their knowledge of HTML editing. We
	 briefly explain situations where stylesheets for XML rendering are
	 needed. We then introduce the rule generation method based on the
	 users' operation history recorded behind the WYSIWYG editor, and in
	 particular explain the ways of generalizing the created rules so that the
	 obtained rules can be applied to other documents slightly different from
	 the original one. Finally, we give a practical example of the rules
	 generation by XSLbyDemo, and demonstrate that our method can be used for
	 not only the conversion but also the partitioning of a real-life
	 HTML document into smaller pages represented with Compact HTML to
	 be rendered on Web-enabled cellular phones such as i-mode phones}}

@inproceedings{Onose.Simeon_XQueryatyour_WWW_2004,
	Author = {Onose, Nicola and Simeon, Jerome},
	Booktitle = WWW,
	Conference-Abbr = {WWW},
	Doi = {http://doi.acm.org/10.1145/988672.988754},
	Isbn = {1-58113-844-X},
	Keywords = {XML XQuery web services implementation},
	Location = {New York, NY, USA},
	Pages = {603--611},
	Pdf = {QueryEvaluation/XML/XQuery/Onose.Simeon_XQueryatyour_WWW_2004.pdf},
	Publisher = {ACM Press},
	Title = {{XQuery at your Web Service}},
	Url = {http://www.www2004.org/proceedings/docs/1p603.pdf},
	Year = {2004},
	Abstract = {XML messaging is at the
	 heart of Web services, providing the flexibility required for their
	 deployment, composition, and maintenance. Yet, current approaches to Web
	 services development hide the messaging layer behind Java or C# APIs,
	 preventing the application to get direct access to the underlying XML
	 information. To address this problem, we advocate the use of a native XML
	 language, namely XQuery, as an integral part of the Web services
	 development infrastructure. The main contribution of the paper is a
	 binding between WSDL, the Web Services Description Language, and
	 XQuery. The approach enables the use of XQuery for both Web services
	 deployment and composition. We present a simple command-line tool that can
	 be used to automatically deploy a Web service from a given XQuery
	 module, and extend the XQuery language itself with a statement for
	 accessing one or more Web services. The binding provides tight-coupling
	 between WSDL and XQuery, yielding additional benefits, notably: the
	 ability to use WSDL as an interface language for XQuery, and the
	 ability to perform static typing on XQuery programs that include
	 Web service calls. Last but not least, the proposal requires only
	 minimal changes to the existing infrastructure. We report on our
	 experience implementing this approach in the Galax XQuery processor.}}

@inproceedings{Paparizos.Al-Khalifa.ea_GroupinginXML_XMLDM_2002,
	Author = {Paparizos, Stelios and Al-Khalifa, Shurug and Jagadish, H. V. and Lakshmanan, Laks V.S. and Nierman, Andrew and Srivastava, Divesh and Wu, Yuqing},
	Booktitle = {EDBT Workshop on XML Data Management},
	Conference-Abbr = {XMLDM},
	Keywords = {XQuery, grouping, query optimization, algebra, TAX, XML},
	Number = {2490},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XQuery/Grouping/Paparizos.Al-Khalifa.ea_GroupinginXML_XMLDM_2002.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{Grouping in XML}},
	Url = {http://www.cs.indiana.edu/~yuqwu/papers/XMLDB02-Grouping.pdf},
	Year = {2002},
	Abstract = {XML permits repeated and missing sub-elements, and missing
	 attributes. We discuss the consequent implications on grouping, both with
	 respect to specification and with respect to implementation. The
	 techniques described here have been implemented in the TIMBER native
	 XML database system being developed at the University of Michigan.}}

@inproceedings{Paparizos.Wu.ea_TreeLogicalClasses_SIGMOD_2004,
	Author = {Paparizos, Stelios and Wu, Yuqing and Lakshmanan, Laks V. S. and Jagadish, H. V.},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Doi = {http://doi.acm.org/10.1145/1007568.1007579},
	Isbn = {1-58113-859-8},
	Keywords = {XML XQuery optimization tree locical classes efficiency},
	Location = {Paris, France},
	Pages = {71--82},
	Pdf = {QueryEvaluation/XML/XQuery/Paparizos.Wu.ea_TreeLogicalClasses_SIGMOD_2004.pdf},
	Publisher = {ACM Press},
	Title = {{Tree Logical Classes for Efficient Evaluation of XQuery}},
	Url = {http://www.cs.indiana.edu/~yuqwu/papers/SIGMOD04-TLC.pdf},
	Year = {2004},
	Abstract = {XML is widely praised for its flexibility in allowing
	 repeated and missing sub-elements. However, this flexibility makes it
	 challenging to develop a bulk algebra, which typically manipulates sets
	 of objects with identical structure. A set of XML elements, say of
	 type book, may have members that vary greatly in structure, e.g. in
	 the number of author sub-elements. This kind of heterogeneity may
	 permeate the entire document in a recursive fashion: e.g., different
	 authors of the same or different book may in turn greatly vary in
	 structure. Even when the document conforms to a schema, the flexible
	 nature of schemas for XML still allows such significant variations in
	 structure among elements in a collection. Bulk processing of such
	 heterogeneous sets is problematic.In this paper, we introduce the notion
	 of logical classes (LC) of pattern tree nodes, and generalize the
	 notion of pattern tree matching to handle node logical classes. This
	 abstraction pays off significantly in allowing us to reason with an
	 inherently heterogeneous collection of elements in a uniform, homogeneous
	 way. Based on this, we define a Tree Logical Class (TLC) algebra
	 that is capable of handling the heterogeneity arising in XML query
	 processing, while avoiding redundant work. We present an algorithm
	 to obtain a TLC algebra expression from an XQuery statement (for a
	 large fragment of XQuery). We show how to implement the TLC algebra
	 efficiently, introducing the nest-join as an important physical operator for
	 XML query processing. We show that evaluation plans generated using
	 the TLC algebra not only are simpler but also perform better than
	 those generated by competing approaches. TLC is the algebra used
	 in the Timber [8] system developed at the University of Michigan.}}

@inproceedings{Pietriga.Vion-Dury.ea_VXT-VisualApproach_DocEng_2001,
	Author = {Pietriga, Emmanuel and Vion-Dury, Jean-Yves and Quint, Vincent},
	Booktitle = {Proc. ACM Symposium on Document Engineering},
	Conference-Abbr = {DocEng},
	Doi = {http://doi.acm.org/10.1145/502187.502189},
	Isbn = {1-58113-432-0},
	Keywords = {XML query languages visual VXT transformer path based},
	Location = {Atlanta, Georgia, USA},
	Pages = {1--10},
	Pdf = {QueryEvaluation/XML/Visualization/Pietriga.Vion-Dury.ea_VXT-VisualApproach_DocEng_2001.pdf},
	Publisher = {ACM Press},
	Title = {{VXT: a Visual Approach to XML Transformations}},
	Url = {http://www.cs.uwm.edu/classes/cs790/digdoc-s2003/papers/p1-pietriga.pdf},
	Year = {2001},
	Abstract = {The domain of XML transformations is becoming more and more important as a result of the
	 increasing number of applications adopting XML as their format for
	 data exchange or representation. Most of the existing solutions for
	 expressing XML transformations are textual languages, such as XSLT or DOM
	 combined with a general-purpose programming language. Several tools
	 build on top of these languages, providing a graphical environment.
	 Transformations are however still specified in a textual way using the
	 underlying language (often XSLT), thus requiring the user to learn
	 the associated textual language.We believe that visual programming
	 techniques are well-suited to representing XML structures and make the
	 specification of transformations simpler. We present a visual programming
	 language for the specification of XML transformations in an interactive
	 environment, based on a zoomable user interface toolkit. Transformations can
	 be run from the application or exported to two target languages:
	 XSLT and Circus, a general-purpose structure transformation language
	 designed by the second author and briefly introduced in this paper.}}

@techreport{Prudhommeaux.Seaborne_SPARQLQueryLanguage_TR_2004,
	Author = {Prud'hommeaux, Eric and Seaborne, Andy},
	Date-Modified = {2006-03-02 17:47:09 +0100},
	Institution = {W3C},
	Keywords = {RDF Query Evaluation Query Languages},
	Owner = {Tim Furche},
	Title = {{SPARQL Query Language for RDF}},
	Type = {Working Draft},
	Url = {http://www.w3.org/TR/rdf-sparql-query/},
	Urldate = {2004/12/20},
	Year = {2006},
	Abstract = {RDF is a flexible, extensible way to
	 represent information about World Wide Web resources. It is used to
	 represent, among other things, personal information, social networks,
	 metadata about digital artifacts like music and images, as well as
	 provide a means of integration over disparate sources of information. A
	 standardized query language for RDF data with multiple implementations
	 offers developers and end users a way to write and to consume the
	 results of queries across this wide range of information. This document
	 describes a query language for RDF, called SPARQL, for querying RDF
	 data. This document describes the query language part of SPARQL for
	 easy access to RDF stores. It is designed to meet the requirements
	 and design objectives described in the W3C RDF Data Access Working
	 Group (DAWG) document "RDF Data Access Use Cases and Requirements".}}

@article{Riecken_PersonalizedViewsof_CACM_2000,
	Author = {Riecken, Doug},
	Journal = {Communications of the ACM},
	Journal-Abbr = {CACM},
	Keywords = {Personalization Web Vision},
	Number = {8},
	Owner = {Tim Furche},
	Pages = {26-28},
	Title = {{Personalized Views of Personalization}},
	Volume = {43},
	Year = {2000},
	Abstract = {Our vocabulary of Internet-related words has become socially popular and, of course, an essential
	 tool of trade in the hands of marketing initiatives. I recall in
	 the early 1990s when words like "agent" and "multimedia" were so
	 overused they became little more than meaningless marketing spin.}}

@inproceedings{Robie.The-Syntactic-Web.2001,
	Author = {Robie, Jonathan},
	Booktitle = {Proc. XML Conference and Exhibition},
	Conference-Abbr = {XML},
	Date-Added = {2005-05-01 22:33:35 +0200},
	Date-Modified = {2005-05-01 22:34:19 +0200},
	Title = {{The Syntactic Web}},
	Url = {http://www.idealliance.org/pa pers/xml2001/papers/html/03-01-04.html},
	Year = {2001}}

@inproceedings{Robie_UpdatesinXQuery_XML_2001,
	Author = {Robie, Jonathan},
	Booktitle = {XML Conference \& Exhibiton},
	Conference-Abbr = {XML},
	Keywords = {XML XQuery update query languages reactivity},
	Owner = {Tim Furche},
	Title = {{Updates in XQuery}},
	Year = {2001}}

@phdthesis{Schaffert_Xcerpt-Rule-BasedQuery_2004,
	Author = {Schaffert, Sebastian},
	Date-Modified = {2006-03-06 17:49:33 +0100},
	Keywords = {XML Xcerpt query language semantics syntax simulation unification},
	Pdf = {QueryEvaluation/Xcerpt/Schaffert_Xcerpt-Rule-BasedQuery_2004.pdf},
	School = {University of Munich},
	Title = {{Xcerpt: A Rule-Based Query and Transformation Language for the Web}},
	Type = {{Dissertation/Ph.D. thesis}},
	Url = {http://www.pms.ifi.lmu.de/publikationen#PMS-DISS-2004-1},
	Year = {2004},
	Abstract = {This thesis investigates querying the Web
	 and the Semantic Web. It proposes a new rulebased query language
	 called Xcerpt. Xcerpt differs from other query languages in that it
	 uses patterns instead of paths for the selection of data, and in
	 that it supports both rule chaining and recursion. Rule chaining
	 serves for structuring large queries, as well as for designing complex
	 query programs (e.g. involving queries to the Semantic Web), and
	 for modelling inference rules. Query patterns may contain special
	 constructs like partial subqueries, optional subqueries, or negated
	 subqueries that account for the particularly flexible structure of data
	 on the Web. Furthermore, this thesis introduces the syntax of the
	 language Xcerpt, which is illustrated on a large collection of use cases
	 both from the conventional Web and the Semantic Web. In addition,
	 a declarative semantics in form of a Tarski-style model theory is
	 described, and an algorithm is proposed that performs a backward chaining
	 evaluation of Xcerpt programs. This algorithm has also been implemented
	 (partly) in a prototypical runtime system. A salient aspect of this
	 algorithm is the specification of a non-standard unification algorithm
	 called simulation unification that supports the new query constructs
	 described above. This unification is symmetric in the sense that
	 variables in both terms can be bound. On the other hand it is in
	 contrast to standard unification assymmetric in the sense that the
	 unification determines that the one term is a subterm of the other term.}}

@inproceedings{Schaffert.Bry_QueryingWebReconsidered_EML_2004,
	Author = {Schaffert, Sebastian and Bry, Fran{\c c}ois},
	Booktitle = {Proc. Extreme Markup Languages},
	Conference-Abbr = {EML},
	Date-Modified = {2006-03-06 17:48:15 +0100},
	Keywords = {REWERSE Xcerpt Query Languages},
	Pdf = {SemanticWeb/REWERSE/Schaffert.Bry_QueryingWebReconsidered_EML_2004.pdf.download/Schaffert.Bry_QueryingWebReconsidered_EML_2004.pdf},
	Title = {{Querying the Web Reconsidered: A Practical Introduction to Xcerpt}},
	Url = {http://www.pms.ifi.lmu.de/publikationen#PMS-FB-2004-7},
	Year = {2004},
	Abstract = {Anfragesprachen f{\"u}r
	 XML-Daten sind heutzutage wesentliche Werkzeuge in der Entwicklung von
	 Webanwendungen. Die am weitesten verbreiteten Sprachen sind XQuery
	 und XSLT, die beide auf der pfadbasierten Selektionssprache XPath
	 aufbauen. Dieser Vortrag gibt einen Einblick in eine neue Anfragesprache
	 namens Xcerpt, die statt des pfadbasierten Ansatzes Anfragepattern
	 verwendet, welche eine deklarativere Spezifikation von Anfragen erlauben.
	 Xcerpt ist ausserdem eine deduktive, regelbasierte Sprache, die auch
	 die Verkn{\"u}pfung von mehreren Regeln (Chaining) und Rekursion
	 erm{\"o}glicht. Eine Xcerpt-Regel kann damit auch als Abstraktion der
	 Ausgangsdaten verstanden werden, hnlich zu Views in relationalen
	 Datenbanken.Auf Xcerpt aufbauend wird ausserdem die visuelle Anfragesprache
	 visXcerpt vorgestellt. Aufgrund des patternbasierten Ansatzes von Xcerpt
	 k{\"o}nnen in visXcerpt Anfragen auf einfache Weise visuell dargestellt
	 und bearbeitet werden.Das Ziel beider Anfragesprachen ist es, die
	 Entwicklung von Anwendungen insbesondere f{\"u}r das "Semantic Web" zu
	 vereinfachen:Anfnger k{\"o}nnen mit Hilfe von visXcerpt Anfragen
	 schnell und intuitiv formulieren und Fortgeschrittenen hilft die
	 Deklarativitt von Xcerpt bei der Gliederung komplexer Programme.}}

@inproceedings{SchenkelTheobald.HOPI-An-Efficient-C.2004,
	Author = {Schenkel, R. and Theobald, A. and Weikum, G.},
	Booktitle = {Proc. Extending Database Technology},
	Conference-Abbr = {EDBT},
	Date-Added = {2005-05-01 22:42:02 +0200},
	Date-Modified = {2005-05-01 22:43:08 +0200},
	Title = {{HOPI: An Efficient Connection Index for Complex XML Document Collections}},
	Year = {2004}}

@inproceedings{Schott.Noga_LazyXSLTransformations_DocEng_2003,
	Author = {Schott, Steffen and Noga, Markus L.},
	Booktitle = {Proc. ACM Symposium on Document Engineering},
	Conference-Abbr = {DocEng},
	Doi = {http://doi.acm.org/10.1145/958220.958224},
	Isbn = {1-58113-724-9},
	Keywords = {XML XSLT evaluation lazy query languages processing},
	Location = {Grenoble, France},
	Pages = {9--18},
	Pdf = {QueryEvaluation/XML/XSLT/Schott.Noga_LazyXSLTransformations_DocEng_2003.pdf},
	Publisher = {ACM Press},
	Title = {{Lazy XSL Transformations}},
	Url = {http://portal.acm.org/citation.cfm?id=958224},
	Year = {2003},
	Abstract = {We introduce a lazy XSLT interpreter that provides random access to the
	 transformation result. This allows efficient pipelining of transformation
	 sequences. Nodes of the result tree are computed only upon initial access.
	 As these computations have limited fan-in, sparse output coverage
	 propagates backwards through the pipeline.In comparative measurements
	 with traditional eager implementations, our approach is on par for
	 complete coverage and excels as coverage becomes sparser. In contrast to
	 eager evaluation, lazy evaluation also admits infinite intermediate
	 results, thus extending the design space for transformation sequences.To
	 demonstrate that lazy evaluation preserves the semantics of XSLT, we reduce
	 XSLT to the lambda calculus via a functional language. While this is
	 possible for all languages, most imperative languages cannot profit from
	 the confluence of lambda as only one reduction applies at a time.}}

@inproceedings{Seipel_ProcessingXML-Documentsin_WLP_2002,
	Author = {Seipel, Dietmar},
	Booktitle = {Workshop on Logic Programming},
	Conference-Abbr = {WLP},
	Keywords = {XML query languages prolog logic programming FnQuery},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/LogicProgrammingApproaches/Seipel_ProcessingXML-Documentsin_WLP_2002.pdf},
	Title = {{Processing XML-Documents in Prolog}},
	Url = {http://www-info1.informatik.uni-wuerzburg.de/database/papers/wlp_2002.ps.gz},
	Year = {2002}}

@article{Seipel.Baumeister_DeclarativeMethodsEvaluation_KI_2004,
	Author = {Seipel, Dietmar and Baumeister, Joachim},
	Journal = {KI--K{\"u}nstliche Intelligenz},
	Journal-Abbr = {KI},
	Keywords = {XML OWL FnQuery ontologies prolog logic programming},
	Owner = {Tim Furche},
	Pages = {51--57},
	Title = {{Declarative Methods for the Evaluation of Ontologies}},
	Url = {http://ki.informatik.uni-wuerzburg.de/papers/baumeister/2004/EvalOntologies_KI4_2004.pdf},
	Volume = {4},
	Year = {2004},
	Abstract = {The ontology web language Owl has been established as a standardized representation
	 for knowledge, especially in the context of the semantic web. An
	 important facet of the management of such knowledge bases consists in its
	 evaluation. Besides standard evaluation methods described in the literature
	 particular applications can require to consider further measures. In this
	 paper, we use a declarative, logic-based Xml query and transformation
	 language called FnQuery, which is suitable for fexibly defning queries
	 for evaluating Owl-based knowledge. The queries are evaluated using
	 logic programming and nonmonotonic reasoning systems. The presented
	 approach could be extended to handle complex refactorings as well.}}

@inproceedings{Seipel.Baumeister.ea_DeclarativelyQueryingand_INAP_2004,
	Author = {Seipel, Dietmar and Baumeister, Joachim and Hopfner, Marbod},
	Booktitle = {Proc. Intl. Conf. on Applications of Declarative Programming and Knowledge Management},
	Conference-Abbr = {INAP},
	Keywords = {XML query languages FnQuery visualization logic programming prolog},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/LogicProgrammingApproaches/Seipel.Baumeister.ea_DeclarativelyQueryingand_INAP_2004.pdf},
	Title = {{Declaratively Querying and Visualizing Knowledge Bases in XML}},
	Url = {http://www-info1.informatik.uni-wuerzburg.de/database/papers/inap_seipel_2004.ps.gz},
	Year = {2004},
	Abstract = {The maintenance of large knowledge systems usually is a
	 rather complex task. In this paper we will show that extensions or
	 modifications of a knowledge base can be supported by appropriate
	 visualizations techniques, e.g. by illustrating dependencies of the considered
	 knowledge. In particular, we introduce a declarative approach for
	 querying and visualizing rule-based knowledge represented as XML
	 documents; a knowledge engineer can extract and visually inspect parts
	 of the knowledge base by ad-hoc declarations in a flexible manner.}}

@inproceedings{Selinger_TopFiveData_ICDE_2005,
	Author = {Selinger, Pat},
	Booktitle = ICDE,
	Conference-Abbr = {ICDE},
	Keywords = {data processing metadata unstructured autonomic speech},
	Owner = {Tim Furche},
	Title = {{Top Five Data Challenges for the Next Decade}},
	Year = {2005}}

@book{Simpson_XPathandXPointer_2002,
	Author = {Simpson, John E.},
	Edition = {1st},
	Keywords = {XML XPath XPointer querying locating linking query languages},
	Owner = {Tim Furche},
	Publisher = {O'Reilly},
	Title = {{XPath and XPointer}},
	Year = {2002},
	Abstract = {Referring to specific information inside
	 an XML document is a little like finding a needle in a haystack.
	 XPath and XPointer are two closely related languages that play a key
	 role in XML processing by allowing developers to find these needles
	 and manipulate embedded information. By the time you've finished
	 XPath and XPointer, you'll know how to construct a full XPointer (one
	 that uses an XPath location path to address document content) and
	 completely understand both the XPath and XPointer features it uses.}}

@inproceedings{Tane.Schmitz.ea_SemanticresourceManagement_WWW_2004,
	Author = {Tane, Julien and Schmitz, Christoph and Stumme, Gerd},
	Booktitle = WWW,
	Citeseerurl = {2005/02/15},
	Conference-Abbr = {WWW},
	Keywords = {Personalization Web E-Learning KAON L3L},
	Owner = {Tim Furche},
	Pdf = {ApplicationAreas/Personalization/Tane.Schmitz.ea_SemanticresourceManagement_WWW_2004.pdf},
	Title = {{Semantic Resource Management for the Web: An E-Learning Application}},
	Url = {http://www.l3s.de/php/detail.php?dc_title=+Semantic+resource+Management+for+the+web%3A+An+e-learning+application.&dc_creator=Julien+Tane%2C+Christoph+Schmitz%3B+Gerd+Stumme.},
	Year = {2004},
	Abstract = {Topics in education are changing with an ever faster pace.
	 ELearning resources tend to be more and more decentralized. Users
	 increasingly need to be able to use the resources of the web. For this,
	 they should have tools for finding and organizing information in a
	 decentralized way. In this paper, we show how an ontologybased tool
	 suite allows to make the most of the resources available on the web.}}

@inproceedings{Tatarinov.Halevy_EfficientQueryReformulation_SIGMOD_2004,
	Author = {Tatarinov, Igor and Halevy, Alon},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Doi = {http://doi.acm.org/10.1145/1007568.1007629},
	Isbn = {1-58113-859-8},
	Keywords = {XML XQuery rewriting optimization query evaluation},
	Location = {Paris, France},
	Pages = {539--550},
	Pdf = {QueryEvaluation/XML/XQuery/Tatarinov.Halevy_EfficientQueryReformulation_SIGMOD_2004.pdf},
	Publisher = {ACM Press},
	Title = {{Efficient Query Reformulation in peer Data Management Systems}},
	Url = {http://data.cs.washington.edu/papers/piazza-sigmod2004.pdf},
	Year = {2004},
	Abstract = {Peer data management systems (PDMS) offer a flexible architecture for decentralized
	 data sharing. In a PDMS, every peer is associated with a schema that
	 represents the peer's domain of interest, and semantic relationships
	 between peers are provided locally between pairs (or small sets) of
	 peers. By traversing semantic paths of mappings, a query over one peer
	 can obtain relevant data from any reachable peer in the network.
	 Semantic paths are traversed by reformulating queries at a peer into
	 queries on its neighbors.Naively following semantic paths is highly
	 inefficient in practice. We describe several techniques for optimizing the
	 reformulation process in a PDMS and validate their effectiveness
	 using real-life data sets. In particular, we develop techniques for
	 pruning paths in the reformulation process and for minimizing the
	 reformulated queries as they are created. In addition, we consider
	 the effect of the strategy we use to search through the space of
	 reformulations. Finally, we show that pre-computing semantic paths
	 in a PDMS can greatly improve the efficiency of the reformulation
	 process. Together, all of these techniques form a basis for scalable
	 query reformulation in PDMS.To enable our optimizations, we developed
	 practical algorithms, of independent interest, for checking containment
	 and minimization of XML queries, and for composing XML mappings.}}

@book{Tennison_XSLTandXPath_2001,
	Author = {Tennison, Jeni},
	Keywords = {XML XSLT XPath query languages},
	Owner = {Tim Furche},
	Publisher = {John Wiley},
	Title = {{XSLT and XPath On The Edge}},
	Year = {2001},
	Abstract = {Extensible Stylesheet Language Transformations, along with the XML Path
	 Language, give you the power to transform XML documents into HTML
	 documents, or to other XML documents that you can use in Web-based
	 applications. But how do you implement XSLT in the real world? This book
	 provides the answers. Covering everything from reformatting numbers
	 to creating dynamic XSLT applications, XSLT expert Jeni Tennison
	 delivers a wealth of ready-to-use utility templates and practical XSLT
	 solutions -- everything you need to jump-start XSLT development.}}

@inproceedings{Theobald.Weikum_XXLSearchEngine_SIGMOD_2002,
	Author = {Theobald, Anja and Weikum, Gerhard},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Doi = {http://doi.acm.org/10.1145/564691.564768},
	Isbn = {1-58113-497-5},
	Keywords = {XML ranking IR information retrieval query languages},
	Location = {Madison, Wisconsin},
	Pages = {615--615},
	Publisher = {ACM Press},
	Title = {{The XXL Search Engine: Ranked Retrieval of XML Data using Indexes and Ontologies}},
	Year = {2002}}

@inproceedings{Tozawa_TowardsStaticType_DocEng_2001,
	Author = {Tozawa, Akihiko},
	Booktitle = {Proc. ACM Symposium on Document Engineering},
	Conference-Abbr = {DocEng},
	Doi = {http://doi.acm.org/10.1145/502187.502191},
	Isbn = {1-58113-432-0},
	Keywords = {XML XSLT type checking query languages},
	Location = {Atlanta, Georgia, USA},
	Pages = {18--27},
	Publisher = {ACM Press},
	Title = {{Towards Static Type Checking for XSLT}},
	Url = {http://wam.inrialpes.fr/people/roisin/mw2004/Tozawa2001.pdf},
	Year = {2001}}

@inproceedings{Trombetta.Montesi_EquivalencesandOptimizations_IDEAS_2004,
	Author = {Trombetta, Alberto and Montesi, Danilo},
	Booktitle = {Proc. Intl. Database Engineering and Applications Symposium},
	Conference-Abbr = {IDEAS},
	Keywords = {XML XSLT query languages optimization equivalence},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XSLT/Trombetta.Montesi_EquivalencesandOptimizations_IDEAS_2004.pdf},
	Title = {{Equivalences and Optimizations in an Expressive XSLT Fragment}},
	Url = {http://csdl.computer.org/dl/proceedings/ideas/2004/2168/00/21680171.pdf},
	Year = {2004},
	Abstract = {XML is the standard data interchange
	 format and XSLT is the W3C proposed standard for transforming and
	 restructuring XML documents. It turns out that XSLT has very powerful query
	 capabilities as well. However, due to its complex syntax and lack of formal
	 specification, it is not a trivial task to decide whether two XSLT
	 stylesheets yield the same result, even if for an XSLT fragment. We isolate
	 such fragment, powerful enough for expressing several interesting
	 queries and for manipulating XML documents and show how to translate
	 them into queries expressed in a properly extended version of TAX, a
	 powerful XML query algebra, for which we provide a collection of
	 equivalence rules. It is then possible to reason about XSLT equivalences,
	 by translating XSLT queries into XTAX queries and then statically
	 verifying their equivalence, by means of the mentioned equivalence rules.}}

@inproceedings{Villard.Layaida_IncrementalXSLTTransformation_WWW_2002,
	Author = {Villard, Lionel and Laya{\"\i}da, Nabil},
	Booktitle = WWW,
	Conference-Abbr = {WWW},
	Doi = {http://doi.acm.org/10.1145/511446.511508},
	Isbn = {1-58113-449-5},
	Keywords = {XML XSLT incremental query evaluation languages},
	Location = {Honolulu, Hawaii, USA},
	Pages = {474--485},
	Pdf = {QueryEvaluation/XML/XSLT/Villard.Layaida_IncrementalXSLTTransformation_WWW_2002.pdf},
	Publisher = {ACM Press},
	Title = {{An Incremental XSLT Transformation Processor for XML Document Manipulation}},
	Url = {http://www.research.ibm.com/people/v/villard/Papiers/incXSLT.pdf},
	Year = {2002},
	Abstract = {In this paper, we present an incremental transformation framework
	 called incXSLT. This framework has been experimented for the XSLT
	 language defined at the World Wide Web Consortium. For the currently
	 available tools, designing the XML content and the transformation
	 sheets is an inefficient, a tedious and an error prone experience.
	 Incremental transformation processors such as incXSLT represent a
	 better alternative to help in the design of both the content and the
	 transformation sheets. We believe that such frameworks are a first step
	 toward fully interactive transformation-based authoring environments.}}

@inproceedings{Walsh.RDF-Twig-accessing-.2003,
	Author = {Walsh, Norman},
	Booktitle = {Proc. Extreme Markup Languages},
	Conference-Abbr = {EML},
	Date-Added = {2005-05-01 22:37:01 +0200},
	Date-Modified = {2005-05-01 22:38:48 +0200},
	Title = {{RDF Twig: accessing RDF graphs in XSLT}},
	Url = {http://www.mulberrytech.com/Extreme/Proceedings/xslfo-pdf/2003/Walsh01/EML2003Walsh01.pdf},
	Year = {2003}}

@book{Walsh.Muellner_DocBook-DefinitiveGuide_1999,
	Author = {Walsh, Norman and Muellner, Leonard},
	Owner = {Tim Furche},
	Publisher = {O?Reilly},
	Title = {{DocBook: The Definitive Guide}},
	Url = {http://www.oreilly.com/catalog/docbook/},
	Year = {1999},
	Abstract = {DocBook is a Document Type Definition (DTD) for use with XML (the Extensible
	 Markup Language) and SGML (the Standard Generalized Markup Language).
	 DocBook lets authors in technical groups exchange and reuse technical
	 information. This book contains an introduction to SGML, XML, and the
	 DocBook DTD, plus the complete reference information for DocBook.}}

@inproceedings{Wan.Dobbie_MiningAssociationRules_CRPIT_2004,
	Author = {Wan, Jacky W. W. and Dobbie, Gillian},
	Booktitle = {Proc. Workshop on Australasian Information Security, Data Mining Web Intelligence, and Software Internationalisation},
	Conference-Abbr = {CRPIT},
	Keywords = {XML XQuery mining assocation rules},
	Location = {Dunedin, New Zealand},
	Pages = {169--174},
	Publisher = {Australian Computer Society, Inc.},
	Title = {{Mining Association Rules from XML data using XQuery}},
	Url = {http://crpit.com/confpapers/CRPITV32Wan.pdf},
	Year = {2004},
	Abstract = {In recent years XML has became very popular for
	 representing semistructured data and a standard for data exchange
	 over the web. Mining XML data from the web is becoming increasingly
	 important. Several encouraging attempts at developing methods for mining
	 XML data have been proposed. However, efficiency and simplicity are
	 still a barrier for further development. Normally, pre-processing or
	 post-processing are required for mining XML data, such as transforming the data
	 from XML format to relational format. In this paper, we show that
	 extracting association rules from XML documents without any pre-processing
	 or post-processing using XQuery is possible and analyze the XQuery
	 implementation of the well-known Apriori algorithm. In addition,
	 we suggest features that need to be added into XQuery in order to
	 make the implementation of the Apriori algorithm more efficient.}}

@inproceedings{Waworuntu.Bailey_XSLTGen-SystemAutomatically_ER_2004,
	Author = {Waworuntu, Stella and Bailey, James},
	Booktitle = {Proc. Intl. Conf. on Conceptual Modeling},
	Conference-Abbr = {ER},
	Keywords = {XML XSLT generation semantic query languages},
	Owner = {Tim Furche},
	Title = {{XSLTGen: A System for Automatically Generating XML Transformations via Semantic Mappings}},
	Url = {http://www.cs.mu.oz.au/~jbailey/papers/xsltgen.ps},
	Year = {2004},
	Abstract = {XML is rapidly emerging as a
	 dominant standard for representing and exchanging information. The
	 ability to transform and present data in XML is crucial and XSLT
	 (Extensible stylesheet transformations) is a relatively recent programming
	 language, specially designed to support this activity. Despite its
	 utility, however, XSLT is widely considered a difficult language to
	 learn. In this paper, we present a novel system called XSLTGen, an
	 automatic XSLT Generator. This system automatically generates an XSLT
	 program, given a source XML document and a desired output HTML or XML
	 document. It allows users to become familiar with and learn XSLT
	 programs, based solely on their knowledge of XML or HTML. Our method for
	 automatically generating XSLT transformations is based on the use of semantic
	 mappings between the input and output documents. We show how such
	 mappings can be first discovered and then employed to create XSLT
	 programs. The results of our experiments show that XSLTGen works
	 well with a number of different varieties of XML and HTML documents.}}

@article{Wiegand_InvestigatingXQueryQuerying_SIGMOD_2002,
	Author = {Wiegand, Nancy},
	Doi = {http://doi.acm.org/10.1145/565117.565122},
	Issn = {0163-5808},
	Journal = {SIGMOD Record},
	Journal-Abbr = {SIGMOD},
	Keywords = {XML XQuery relational databases heterogenity},
	Number = {2},
	Pages = {28--33},
	Pdf = {QueryEvaluation/XML/XQuery/Wiegand_InvestigatingXQueryQuerying_SIGMOD_2002.pdf},
	Publisher = {ACM Press},
	Title = {{Investigating XQuery for Querying across Database Object Types}},
	Url = {http://portal.acm.org/citation.cfm?id=565122},
	Volume = {31},
	Year = {2002},
	Abstract = {In addition to facilitating querying over the Web, XML query
	 languages may provide high level constructs for useful facilities
	 in traditional DBMSs that do not currently exist. In particular,
	 current DBMS query languages do not allow querying across database
	 object types to yield heterogeneous results. This paper motivates the
	 usefulness of heterogeneous querying in traditional DBMSs and investigates
	 XQuery, an emerging standard for XML query languages, to express
	 such queries. The usefulness of querying and storing heterogeneous
	 types is also applied to XML data within a Web information system.}}

@inproceedings{Wood_OnEquivalenceof_CL_2000,
	Author = {Wood, Peter T.},
	Booktitle = {Proc. Intl. Conf. on Computational Logic},
	Conference-Abbr = {CL},
	Isbn = {3-540-67797-6},
	Keywords = {XML XPath query containment fragment equivalence},
	Pages = {1152--1166},
	Publisher = {Springer-Verlag},
	Title = {{On the Equivalence of XML Patterns}},
	Year = {2000}}

@inproceedings{Zaniolo_DatabaseLanguageGEM_SIGMOD_1983,
	Author = {Zaniolo, Carlo},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Keywords = {Query languages GEM path expressions QUEL},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/Languages/Zaniolo_DatabaseLanguageGEM_SIGMOD_1983.pdf},
	Title = {{The Database Language GEM}},
	Url = {http://www.cs.ucla.edu/%7Ezaniolo/papers/sigmod83.pdf},
	Year = {1983},
	Abstract = {GEM (bn acronym for General Entity Manipulator) is a
	 general-purpose query and update language for the DSIS data model,
	 which is a semantic data model of the Entity-Relationship type. GEM
	 is designed as an easy-to-use extension of the relational language
	 QUEL. providing supporr for. the notions of entities with surrogates,
	 aggregation, generalization, null values, and set-valued attributes.}}

@inproceedings{Zhang.Dimitrova.ea_Rainbow-multi-XQueryOptimization_SIGMOD_2003,
	Author = {Zhang, Xin and Dimitrova, Katica and Wang, Ling and Sayed, Maged El and Murphy, Brian and Pielech, Bradford and Mulchandani, Mukesh and Ding, Luping and Rundensteiner, Elke A.},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Doi = {http://doi.acm.org/10.1145/872757.872861},
	Isbn = {1-58113-634-X},
	Keywords = {XML XQuery view-based query optimization evalution processing},
	Location = {San Diego, California},
	Pages = {671--671},
	Pdf = {QueryEvaluation/XML/XQuery/Zhang.Dimitrova.ea_Rainbow-multi-XQueryOptimization_SIGMOD_2003.pdf},
	Publisher = {ACM Press},
	Title = {{Rainbow: multi-XQuery Optimization using Materialized XML Views}},
	Url = {http://www.cs.wpi.edu/~lisading/docs/demo.pdf},
	Year = {2003}}

@inproceedings{Zhang.Pielech.ea_HoneyIshrunk_WIDM_2002,
	Author = {Zhang, Xin and Pielech, Bradford and Rundesnteiner, Elke A.},
	Booktitle = {Proc. International Workshop on Web Information and Data Management},
	Conference-Abbr = {WIDM},
	Doi = {http://doi.acm.org/10.1145/584931.584936},
	Isbn = {1-58113-593-9},
	Location = {McLean, Virginia, USA},
	Pages = {15--22},
	Publisher = {ACM Press},
	Title = {{Honey, I shrunk the XQuery!: an XML Algebra Optimization Approach}},
	Url = {http://davis.wpi.edu/~dsrg/rainbow/RainbowCore/document/xinz-widm-2002-XAT-cleanup.ppt},
	Year = {2002},
	Abstract = {Mapping of XML data into and out of relational database
	 systems, including query processing over such virtual XML views that
	 wrap relational sources, has become a topic of critical importance
	 recently. The Rainbow XML data management system, being developed at
	 WPI, focuses on the processing and optimization of XQuery queries
	 against XML views over relational data. For this, Rainbow?s query
	 model, the XML Algebra Tree (XAT), has been designed. Because the XML
	 formatting operators are interleaved with the computation operators, this
	 XAT must first be optimized before being translated into SQL. Our
	 computation pushdown technology handles this optimization by splitting
	 the XAT into the XML-specific and SQL-doable operators, with the
	 later then being converted into SQL statements. However, the XAT
	 after computation pushdown may contain unreferenced columns or unused
	 operators. We show that these unneeded operators cannot be discovered by
	 the relational engine after SQL generation. Leaving these operators
	 in the tree would create unnecessarily large SQL statements that
	 will slow down the overall execution. Our main contributions to XML
	 query processing, described in this paper, are threefold. One, we
	 describe the XAT algebra for modeling XQuery expressions. Two, we
	 propose rewriting rules to optimize XQueries by canceling operators.
	 Three, we describe a cutting algorithm that removes unreferenced
	 columns and operators from the XATs. The techniques discussed in
	 this paper have been successfully implemented in the Rainbow system.}}

@inproceedings{Zloof_QueryByExample_AFIPS_1975,
	Author = {Zloof, Mosh{\'e} M.},
	Booktitle = {AFIPS National Computer Conference},
	Conference-Abbr = {AFIPS},
	Keywords = {QBE relational query languages},
	Owner = {Tim Furche},
	Title = {{Query By Example}},
	Year = {1975}}

@book{ODMG_ObjectDataStandard_2000,
	Editor = {R. G. G. Cattell and Douglas K. Barry and Mark Berler and Jeff Eastman and David Jordan and Craig Russell and Olaf Schadow and Torsten Stanienda and Fernando Velez},
	Keywords = {OQL ODMG standard object-oriented database query languages},
	Owner = {Tim Furche},
	Publisher = {Morgan Kaufmann},
	Title = {{Object Data Standard: ODMG 3.0}},
	Year = {2000}}

@book{ParkHunting.XML-Topic-Maps-Creating.2002,
	Address = {Boston, MA, USA},
	Date-Modified = {2005-04-12 22:24:09 +0200},
	Editor = {Jack Park and Sam Hunting},
	Isbn = {0201749602},
	Publisher = {Addison-Wesley Longman Publishing Co., Inc.},
	Title = {{XML Topic Maps: Creating and Using Topic Maps for the Web}},
	Year = {2002}}

@comment{BibDesk Smart Groups{
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple Computer//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<array>
	<dict>
		<key>conditions</key>
		<array>
			<dict>
				<key>comparison</key>
				<integer>2</integer>
				<key>key</key>
				<string>Keywords</string>
				<key>value</key>
				<string>identity</string>
			</dict>
			<dict>
				<key>comparison</key>
				<integer>2</integer>
				<key>key</key>
				<string>Keywords</string>
				<key>value</key>
				<string>duplicate</string>
			</dict>
		</array>
		<key>conjunction</key>
		<integer>1</integer>
		<key>group name</key>
		<string>Identity, Multirelations, etc.</string>
	</dict>
</array>
</plist>
}}
