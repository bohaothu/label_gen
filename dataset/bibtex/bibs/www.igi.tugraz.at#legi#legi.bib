@STRING{colt93	= "Proceedings of the Sixth Annual ACM Conference on
		  Computational Learning Theory" }
@STRING{jacm	= "Journal of the Association for Computing Machinery" }
@STRING{jma	= "Journal of Multivariate Analysis" }
@STRING{lncs	= "Lecture Notes of Computer Science, Springer" }
@STRING{lncs	= "Lecture Notes in Computer Science" }
@STRING{nips	= "Advances in Neural Information Processing Systems" }
@STRING{pecs	= "Colloquia Mathematica Societatis Janos Bolai, 57.\ Limit
		  Theorem in Probability and Statistics, Pecs (Hungary)" }
@STRING{spl	= "Statistics \& Probability Letters" }

@InProceedings{JahrerETAL:10,
  author	= {M. Jahrer and A. T\"oscher and R. Legenstein},
  title		= {Combining Predictions for Accurate Recommender Systems},
  booktitle	= {KDD '10: Proceedings of the 16th ACM SIGKDD international
		  conference on Knowledge discovery and data mining},
  year		= {2010},
  isbn		= {978-1-4503-0055-1},
  pages		= {693--702},
  location	= {Washington, DC, USA},
  doi		= {http://doi.acm.org/10.1145/1835804.1835893},
  publisher	= {ACM},
  address	= {New York, NY, USA},
  abstract	= {We analyze the application of ensemble learning to
		  recommender systems on the Netflix Prize dataset. For our
		  analysis we use a set of diverse state-of-the-art
		  collaborative filtering (CF) algorithms, which include:
		  SVD, Neighborhood Based Approaches, Restricted Boltzmann
		  Machine, Asymmetric Factor Model and Global Effects. We
		  show that linearly combining (blending) a set of CF
		  algorithms increases the accuracy and outperforms any
		  single CF algorithm. Furthermore, we show how to use
		  ensemble methods for blending predictors in order to
		  outperform a single blending algorithm. The dataset and the
		  source code for the ensemble blending are available
		  online.}
}

@Article{LegensteinETAL:09b,
  author	= {R. Legenstein and S. M. Chase and A. B. Schwartz and W.
		  Maass},
  title		= {A reward-modulated {H}ebbian learning rule can explain
		  experimentally observed network reorganization in a brain
		  control task},
  journal	= {The Journal of Neuroscience},
  year		= {2010},
  volume	= {30},
  number	= {25},
  pages		= {8400--8410},
  abstract	= {It has recently been shown in a brain-computer interface
		  experiment that motor cortical neurons change their tuning
		  properties selectively to compensate for errors induced by
		  displaced decoding parameters. In particular, it was shown
		  that the three-dimensional tuning curves of neurons whose
		  decoding parameters were reassigned changed more than those
		  of neurons whose decoding parameters had not been
		  reassigned. In this article, we propose a simple learning
		  rule that can reproduce this effect. Our learning rule uses
		  Hebbian weight updates driven by a global reward signal and
		  neuronal noise. In contrast to most previously proposed
		  learning rules, this approach does not require extrinsic
		  information to separate noise from signal. The learning
		  rule is able to optimize the performance of a model system
		  within biologically realistic periods of time under high
		  noise levels. Furthermore, when the model parameters are
		  matched to data recorded during the brain-computer
		  interface learning experiments described above, the model
		  produces learning effects strikingly similar to those found
		  in the experiments.}
}

@Article{LegensteinETAL:10,
  author	= {R. Legenstein and N. Wilbert and L. Wiskott},
  title		= {Reinforcement Learning on Slow Features of
		  High-Dimensional Input Streams},
  journal	= {PLoS Computational Biology},
  year		= {2010},
  volume	= {6},
  number	= {8},
  pages		= {e1000894},
  abstract	= {Humans and animals are able to learn complex behaviors
		  based on a massive stream of sensory information from
		  different modalities. Early animal studies have identified
		  learning mechanisms that are based on reward and punishment
		  such that animals tend to avoid actions that lead to
		  punishment whereas rewarded actions are reinforced.
		  However, most algorithms for reward-based learning are only
		  applicable if the dimensionality of the state-space is
		  sufficiently small or its structure is sufficiently simple.
		  Therefore, the question arises how the problem of learning
		  on high-dimensional data is solved in the brain. In this
		  article we propose a biologically plausible generic
		  two-stage learning system that can directly be applied to
		  raw high-dimensional input streams. The system is composed
		  of a hierarchical slow feature analysis (SFA) network for
		  preprocessing and a simple neural network on top that is
		  trained based on rewards. We demonstrate by computer
		  simulations that this generic architecture is able to learn
		  quite demanding reinforcement learning tasks on
		  high-dimensional visual input streams in a time that is
		  comparable to the time needed when an explicit highly
		  informative low-dimensional state-space representation is
		  given instead of the high-dimensional visual input. The
		  learning speed of the proposed architecture in a task
		  similar to the Morris water maze task is comparable to that
		  found in experimental studies with rats. This study thus
		  supports the hypothesis that slowness learning is one
		  important unsupervised learning principle utilized in the
		  brain to form efficient state representations for
		  behavioral learning. }
}

@Article{BuesingETAL:09,
  author	= {L. Buesing and B. Schrauwen and R. Legenstein},
  title		= {Connectivity, Dynamics, and Memory in Reservoir Computing
		  with Binary and Analog Neurons},
  journal	= {Neural Computation},
  year		= {2010},
  volume	= {22},
  number	= {5},
  pages		= {1272-1311},
  abstract	= {Reservoir Computing (RC) systems are powerful models for
		  online computations on input sequences. They consist of a
		  memoryless readout neuron which is trained on top of a
		  randomly connected recurrent neural network. RC systems are
		  commonly used in two flavors: with analog or binary
		  (spiking) neurons in the recurrent circuits. Previous work
		  indicated a fundamental difference in the behavior of these
		  two implementations of the RC idea. The performance of a RC
		  system built from binary neurons seems to depend strongly
		  on the network connectivity structure. In networks of
		  analog neurons such clear dependency has not been observed.
		  In this article we address this apparent dichotomy by
		  investigating the influence of the network connectivity
		  (parametrized by the neuron in-degree) on a family of
		  network models that interpolates between analog and binary
		  networks. Our analyses are based on a novel estimation of
		  the Lyapunov exponent of the network dynamics with the help
		  of branching process theory, rank measures which estimate
		  the kernel-quality and generalization capabilities of
		  recurrent networks, and a novel mean-field predictor for
		  computational performance. These analyses reveal that the
		  phase transition between ordered and chaotic network
		  behavior of binary circuits qualitatively differs from the
		  one in analog circuits, leading to differences in the
		  integration of information over short and long time scales.
		  This explains the decreased computational performance
		  observed in binary circuits that are densely connected. The
		  mean-field predictor is also used to bound the memory
		  function of recurrent circuits of binary neurons.}
}

@Article{KlampflETAL:07,
  author	= {S. Klampfl and R. Legenstein and W. Maass},
  title		= {Spiking neurons can learn to solve information bottleneck
		  problems and extract independent components},
  journal	= {Neural Computation},
  year		= {2009},
  volume	= {21},
  number	= {4},
  pages		= {911--959},
  abstract	= {Independent Component Analysis (or blind source
		  separation) is assumed to be an essential component of
		  sensory processing in the brain and could provide a less
		  redundant representation about the external world. Another
		  powerful processing strategy is the optimization of
		  internal representations according to the information
		  bottleneck method. This method would allow to extract
		  preferentially those components from high-dimensional
		  sensory input streams that are related to other information
		  sources, such as internal predictions or proprioceptive
		  feedback. However there exists a lack of models that could
		  explain how spiking neurons could learn to execute either
		  of these two processing strategies. We show in this article
		  how stochastically spiking neurons with refractoriness
		  could in principle learn in an unsupervised manner to carry
		  out both information bottleneck optimization and the
		  extraction of independent components. We derive suitable
		  learning rules, which extend the well known BCM-rule, from
		  abstract information optimization principles. These rules
		  will simultaneously keep the firing rate of the neuron
		  within a biologically realistic range.}
}

@InProceedings{KlampflETAL:07b,
  author	= {S. Klampfl and R. Legenstein and W. Maass},
  title		= {Information Bottleneck Optimization and Independent
		  Component Extraction with Spiking Neurons},
  booktitle	= {Proc. of NIPS 2006, Advances in Neural Information
		  Processing Systems},
  editor	= {},
  publisher	= {MIT Press},
  year		= {2007},
  volume	= {19},
  pages		= {713--720},
  abstract	= {The extraction of statistically independent components
		  from high-dimensional multi-sensory input streams is
		  assumed to b e an essential component of sensory processing
		  in the brain. Such independent component analysis (or blind
		  source separat ion) could provide a less redundant
		  representation of inform ation about the external world.
		  Another powerful processing strategy is to extract
		  preferentially those components from high-dimensional input
		  streams that are related to other inf ormation sources,
		  such as internal predictions or propriocep tive feedback.
		  This strategy allows the optimization of inte rnal
		  representation according to the information bottleneck
		  method. However, concrete learning rules that implement
		  thes e general unsupervised learning principles for spiking
		  neuro ns are still missing. We show how both information
		  bottlenec k optimization and the extraction of independent
		  components can in principle be implemented with
		  stochastically spiking neurons with refractoriness. The new
		  learning rule that achi eves this is derived from abstract
		  information optimization principles.}
}

@PhDThesis{Legenstein:02a,
  author	= {R. A. Legenstein},
  title		= {The Wire-Length Complexity of Neural Networks},
  school	= {Graz University of Technology},
  year		= 2002,
  abstract	= {The ability of our nervous system to rapidly process and
		  react on the huge amount of sensory input data is grounded
		  on its massively parallel architecture. Arguably, physical
		  cost for communication, that is to say the space needed for
		  wires, is the most severe bottleneck in biological as well
		  as in artificial architectures of this type. In this thesis
		  the complexity of wiring in biological and artificial
		  neural networks, the implications of wiring constraints to
		  models for brain circuits, and the implementation of
		  wire-efficient circuit designs in hardware are studied. We
		  present a simple mathematical framework that allows us to
		  study the wiring complexity of neural circuits in a formal
		  and general manner. In this model, the complexity of a
		  circuit is measured by the total length of wires needed to
		  implement the circuit, a complexity measure that is one of
		  the most salient ones if real-world constraints of
		  implementations in hardware or ``wetware'' are
		  considered.Furthermore, we study the layout of general
		  computational structures like tree computations. We give
		  tight upper and lower bounds on the wire length of
		  constrained tree layouts and show efficient layout
		  strategies for prefix computations.}
}

@Article{Legenstein:02b,
  author	= {R. A. Legenstein},
  title		= {On the Complexity of Knock-Knee Channel Routing with
		  3-Terminal Nets},
  journal	= {Technical Report},
  year		= {2002},
  abstract	= {In this article we consider a basic problem in the layout
		  of VLSI-circuits, the channel-routing problem in the
		  knock-knee mode. We show that knock-knee channel routing
		  with 3-terminal nets is NP-complete and thereby settling a
		  problem that was open for more than a decade. In 1987,
		  Sarrafzadeh showed that knock-knee channel routing with
		  5-terminal nets is NP-complete. Furthermore, it is known
		  that this problem is solvable in polynomial time if only
		  2-terminal nets are involved (This problem was addressed
		  for example by Frank in 1982 and by Formann, D. Wagner, and
		  F. Wagner in 1993).}
}

@MastersThesis{Legenstein:99,
  author	= {R. A. Legenstein},
  title		= {Effizientes {L}ayout von {N}euronalen {N}etzen},
  school	= {Technische Universitaet Graz},
  year		= 1999,
  month		= {September}
}

@Article{LegensteinETAL:03,
  author	= {R. Legenstein and H. Markram and W. Maass},
  title		= {Input Prediction and Autonomous Movement Analysis in
		  Recurrent Circuits of Spiking Neurons},
  year		= {2003},
  journal	= {Reviews in the Neurosciences (Special Issue on
		  Neuroinformatics of Neural and Artificial Computation)},
  volume	= {14},
  number	= {1--2},
  pages		= {5--19},
  abstract	= {Temporal integration of information and prediction of
		  future sensory inputs are assumed to be important
		  computational tasks of generic cortical microcircuits.
		  However it has remained open how cortical microcircuits
		  could possibly achieve this, especially since they consist
		  in contrast to most neural network models of neurons and
		  synapses with heterogeneous dynamic responses. However it
		  turns out that the diversity of computational units
		  increases the capability of microcircuit models for
		  temporal integration. Furthermore the prediction of future
		  input may be rather easy for such circuits since it
		  suffices to train the readouts from such microcircuits. In
		  this article we show that very simple readouts from a
		  generic recurrently connected circuit of integrate-and-fire
		  neurons with diverse dynamic synapses can be trained in an
		  unsupervised manner to predict movements of different
		  objects, that move within an unlimited number of
		  combinations of speed, angle, and offset over a simulated
		  sensor field. The autonomously trained microcircuit model
		  is also able to compute the direction of motion, which is a
		  computationally difficult problem ("aperture problem")
		  since it requires disambiguation of local sensor readings
		  through the context of other sensor readings at the current
		  and preceding moments. Furthermore the same circuit can be
		  trained simultaneously in a supervised manner to also
		  report the shape and velocity of the moving object. Finally
		  it is shown that the trained neural circuit supports
		  novelty detection and the generation of "imagined
		  movements". Altogether the results of this article suggest
		  that it is not necessary to construct specific and
		  biologically unrealistic neural circuit models for specific
		  sensory processing tasks, since "found" generic cortical
		  microcircuit models in combination with very simple
		  perceptron-like readouts can easily be trained to solve
		  such computational tasks.}
}

@Article{LegensteinETAL:04,
  author	= {R. Legenstein and C. Naeger and W. Maass},
  title		= {What can a Neuron Learn with Spike-Timing-Dependent
		  Plasticity?},
  journal	= {Neural Computation},
  year		= {2005},
  volume	= {17},
  number	= {11},
  pages		= {2337--2382},
  abstract	= {Spiking neurons are very flexible computational modules,
		  which can implement with different values of their
		  adjustable synaptic parameters an enormous variety of
		  different transformations F from input spike trains to
		  output spike trains. We examine in this letter the question
		  to what extent a spiking neuron with biologically realistic
		  models for dynamic synapses can be taught via
		  spike-timing-dependent plasticity (STDP) to implement a
		  given transformation F. We consider a supervised learning
		  paradigm where during training, the output of the neuron is
		  clamped to the target signal (teacher forcing). The
		  well-known perceptron convergence theorem asserts the
		  convergence of a simple supervised learning algorithm for
		  drastically simplified neuron models (McCulloch-Pitts
		  neurons). We show that in contrast to the perceptron
		  convergence theorem, no theoretical guarantee can be given
		  for the convergence of STDP with teacher forcing that holds
		  for arbitrary input spike patterns. On the other hand, we
		  prove that average case versions of the perceptron
		  convergence theorem hold for STDP in the case of
		  uncorrelated and correlated Poisson input spike trains and
		  simple models for spiking neurons. For a wide class of
		  cross-correlation functions of the input spike trains, the
		  resulting necessary and sufficient condition can be
		  formulated in terms of linear separability, analogously as
		  the well-known condition of learnability by perceptrons.
		  However, the linear separability criterion has to be
		  applied here to the columns of the correlation matrix of
		  the Poisson input. We demonstrate through extensive
		  computer simulations that the theoretically predicted
		  convergence of STDP with teacher forcing also holds for
		  more realistic models for neurons, dynamic synapses, and
		  more general input distributions. In addition, we show
		  through computer simulations that these positive learning
		  results hold not only for the common interpretation of
		  STDP, where STDP changes the weights of synapses, but also
		  for a more realistic interpretation suggested by
		  experimental data where STDP modulates the initial release
		  probability of dynamic synapses.}
}

@InProceedings{LegensteinETAL:04a,
  author	= {R. Legenstein and W. Maass},
  title		= {A criterion for the convergence of learning with spike
		  timing dependent plasticity},
  booktitle	= {Advances in Neural Information Processing Systems},
  editor	= {Y. Weiss and B. Schoelkopf and J. Platt},
  volume	= {18},
  pages		= {763--770},
  year		= 2006,
  publisher	= {MIT Press},
  abstract	= {We investigate under what conditions a neuron can learn by
		  experimentally supported rules for spike timing dependent
		  plasticity (STDP) to predict the arrival times of strong
		  ``teacher inputs'' to the same neuron. It turns out that in
		  contrast to the famous Perceptron Convergence Theorem,
		  which predicts convergence of the perceptron learning rule
		  for a strongly simplified neuron model whenever a stable
		  solution exists, no equally strong convergence guarantee
		  can be given for spiking neurons with STDP. But we derive a
		  criterion on the statistical dependency structure of input
		  spike trains which characterizes exactly when learning with
		  STDP will converge on average for a simple model of a
		  spiking neuron. This criterion is reminiscent of the linear
		  separability criterion of the Perceptron Convergence
		  Theorem, but it applies here to the rows of a correlation
		  matrix related to the spike inputs. In addition we show
		  through computer simulations for more realistic neuron
		  models that the resulting analytically predicted positive
		  learning results not only hold for the common
		  interpretation of STDP where STDP changes the weights of
		  synapses, but also for a more realistic interpretation
		  suggested by experimental data where STDP modulates the
		  initial release probability of dynamic synapses.}
}

@InProceedings{LegensteinETAL:08,
  author	= {R. Legenstein and D. Pecevski and W. Maass},
  title		= {Theoretical Analysis of Learning with Reward-Modulated
		  Spike-Timing-Dependent Plasticity},
  booktitle	= {Proc. of NIPS 2007, Advances in Neural Information
		  Processing Systems},
  editor	= {},
  publisher	= {MIT Press},
  year		= {2008},
  volume	= {20},
  pages		= {881--888},
  abstract	= {Reward-modulated spike-timing-dependent plasticity
		  ({STDP}) has recently emerged as a candidate for a learning
		  rule that could explain how local learning rules at single
		  synapses support behaviorally relevant adaptive changes in
		  complex networks of spiking neurons. However the potential
		  and limitations of this learning rule could so far only be
		  tested through computer simulations. This article provides
		  tools for an analytic treatment of reward-modulated {STDP},
		  which allow us to predict under which conditions
		  reward-modulated {STDP} will be able to achieve a desired
		  learning effect. In particular, we can produce in this way
		  a theoretical explanation and a computer model for a
		  fundamental experimental finding on biofeedback in monkeys
		  (reported in [1])}
}

@Article{LegensteinETAL:08a,
  author	= {R. Legenstein and D. Pecevski and W. Maass},
  title		= {A Learning Theory for Reward-Modulated
		  Spike-Timing-Dependent Plasticity with Application to
		  Biofeedback},
  journal	= {PLoS Computational Biology},
  year		= {2008},
  volume	= {4},
  number	= {10},
  pages		= {1--27},
  abstract	= {Reward-modulated spike-timing-dependent plasticity
		  ({STDP}) has recently emerged as a candidate for a learning
		  rule that could explain how behaviorally relevant adaptive
		  changes in complex networks of spiking neurons could be
		  achieved in a self-organizing manner through local synaptic
		  plasticity. However the capabilities and limitations of
		  this learning rule could so far only be tested through
		  computer simulations. This article provides tools for an
		  analytic treatment of reward-modulated {STDP}, which allows
		  us to predict under which conditions reward-modulated
		  {STDP} will achieve a desired learning effect. These
		  analytical results imply that neurons can learn through
		  reward-modulated {STDP} to classify not only spatial, but
		  also temporal firing patterns of presynaptic neurons. They
		  also can learn to respond to specific presynaptic firing
		  patterns with particular spike patterns. Finally, the
		  resulting learning theory predicts that even difficult
		  credit-assignment problems, where it is very hard to tell
		  which synaptic weights should be modified in order to
		  increase the global reward for the system, can be solved in
		  a self-organizing manner through reward-modulated {STDP}.
		  This yields an explanation for a fundamental experimental
		  result on biofeedback in monkeys by Fetz and Baker. In this
		  experiment monkeys were rewarded for increasing the firing
		  rate of a particular neuron in the cortex, and were able to
		  solve this extremely difficult credit assignment problem.
		  Our model for this experiment relies on a combination of
		  reward-modulated {STDP} with variable spontaneous firing
		  activity. Hence it also provides a possible functional
		  explanation for trial-to-trial variability, which is
		  characteristic for cortical networks of neurons, but has no
		  analogue in currently existing artificial computing
		  systems. In addition our model demonstrates that
		  reward-modulated {STDP} can be applied to all synapses in a
		  large recurrent neural network without endangering the
		  stability of the network dynamics.}
}

@Article{LegensteinETAL:08b,
  author	= {R. Legenstein and D. Pecevski and W. Maass},
  title		= {Supplementary Information to: "{A} Learning Theory for
		  Reward-Modulated Spike-Timing-Dependent Plasticity with
		  Application to Biofeedback"},
  journal	= {PLoS Computational Biology},
  year		= {2008},
  volume	= {4},
  number	= {10},
  pages		= {}
}

@Article{LegensteinETAL:08c,
  author	= {R. Legenstein and S. A. Chase and A. B. Schwartz and W.
		  Maass},
  title		= {A model for learning effects in motor cortex that may
		  facilitate the brain control of neuroprosthetic devices},
  journal	= {38th Annual Conference of the Society for Neuroscience,
		  Program 517.6},
  year		= {2008},
  volume	= {},
  number	= {},
  pages		= {},
  abstract	= {Recent experimental results have shown that the direction
		  preference of neurons in monkey motor cortex changes in
		  order to compensate for purposeful misreading of preferred
		  directions for brain control of a robot arm. We show that a
		  simple neural network model in combination with a new rule
		  for reward-modulated Hebbian plasticity can explain this
		  effect. This rule requires substantial trial-to-trial
		  variability of the neuronal output for exploration. In
		  contrast to previously proposed rules for reward-modulated
		  Hebbian plasticity, the new rule does not require that the
		  plasticity mechanism `knows' the noise explicitly. It is
		  able to optimize the performance of the model system within
		  biologically realistic periods of time and under high noise
		  levels. When the neuronal noise is fitted to experimental
		  data, the model produces learning effects similar to those
		  found in monkey experiments. We quantified these effects
		  and found a surprisingly good match to those observed in
		  experiments. This study shows that reward-modulated
		  learning can explain detailed experimental results about
		  neuronal tuning changes in a motor control task and
		  suggests that reward-modulated learning is an essential
		  plasticity mechanism in the cortex for the acquisition of
		  goal-directed behavior. Self-tuning effects of the type
		  considered in this model are obviously important for
		  successful use of neuroprosthetic devices.}
}

@InProceedings{LegensteinETAL:09,
  author	= {B. Schrauwen and L. Buesing and R. Legenstein},
  title		= {On Computational Power and the Order-Chaos Phase
		  Transition in Reservoir Computing},
  booktitle	= {Proc. of NIPS 2008, Advances in Neural Information
		  Processing Systems},
  editor	= {},
  publisher	= {MIT Press},
  year		= {2009},
  volume	= {21},
  pages		= {1425--1432},
  abstract	= {Randomly connected recurrent neural circuits have proven
		  to be very powerful models for online computations when a
		  trained memoryless readout function is appended. Such {\em
		  Reservoir Computing (RC)} systems are commonly used in two
		  flavors: with analog or binary (spiking) neurons in the
		  recurrent circuits. Previous work showed a fundamental
		  difference between these two incarnations of the RC idea.
		  The performance of a RC system build from binary neurons
		  seems to depend strongly on the network connectivity
		  structure. In networks of analog neurons such dependency
		  has not been observed. In this article we investigate this
		  apparent dichotomy in terms of the in-degree of the circuit
		  nodes. Our analyses based amongst others on the Lyapunov
		  exponent reveal that the phase transition between ordered
		  and chaotic network behavior of binary circuits
		  qualitatively differs from the one in analog circuits. This
		  explains the observed decreased computational performance
		  of binary circuits of high node in-degree. Furthermore, a
		  novel mean-field predictor for computational performance is
		  introduced and shown to accurately predict the numerically
		  obtained results.}
}

@InProceedings{LegensteinETAL:09a,
  author	= {R. Legenstein and S. A. Chase and A. B. Schwartz and W.
		  Maass},
  title		= {Functional network reorganization in motor cortex can be
		  explained by reward-modulated {H}ebbian learning},
  booktitle	= {Proc. of NIPS 2009: Advances in Neural Information
		  Processing Systems},
  editor	= {D. Koller and D. Schuurmans and Y. Bengio and L. Bottou},
  publisher	= {MIT Press},
  year		= {2010},
  volume	= {22},
  pages		= {1105--1113},
  abstract	= {The control of neuroprosthetic devices from the activity
		  of motor cortex neurons benefits from learning effects
		  where the function of these neurons is adapted to the
		  control task. It was recently shown that tuning properties
		  of neurons in monkey motor cortex are adapted selectively
		  in order to compensate for an erroneous interpretation of
		  their activity. In particular, it was shown that the tuning
		  curves of those neurons whose preferred directions had been
		  misinterpreted changed more than those of other neurons. In
		  this article, we show that the experimentally observed
		  self-tuning properties of the system can be explained on
		  the basis of a simple learning rule. This learning rule
		  utilizes neuronal noise for exploration and performs
		  Hebbian weight updates that are modulated by a global
		  reward signal. In contrast to most previously proposed
		  reward-modulated Hebbian learning rules, this rule does not
		  require extraneous knowledge about what is noise and what
		  is signal. The learning rule is able to optimize the
		  performance of the model system within biologically
		  realistic periods of time and under high noise levels. When
		  the neuronal noise is fitted to experimental data, the
		  model produces learning effects similar to those found in
		  monkey experiments.}
}

@InProceedings{LegensteinETAL:09sup,
  author	= {B. Schrauwen and L. Buesing and R. Legenstein},
  title		= {Supplementary Material to: On Computational Power and the
		  Order-Chaos Phase Transition in Reservoir Computing},
  booktitle	= {Proc. of NIPS 2008, Advances in Neural Information
		  Processing Systems},
  editor	= {},
  publisher	= {MIT Press},
  year		= {2009},
  volume	= {21},
  note		= {in press},
  pages		= {}
}

@TechReport{LegensteinMaass:04,
  author	= {R. Legenstein and W. Maass},
  title		= {Additional material to the paper: What can a Neuron Learn
		  with Spike-Timing-Dependent Plasticity?},
  institution	= {Institute for Theoretical Computer Science, Graz
		  University of Technology},
  htmlnote	= {(<a href="./psfiles/154suplement.pdf">PDF</a>)},
  year		= {2004}
}

@InCollection{LegensteinMaass:05,
  author	= {R. Legenstein and W. Maass},
  title		= {What makes a dynamical system computationally powerful?},
  booktitle	= {New Directions in Statistical Signal Processing: From
		  Systems to Brains},
  publisher	= {MIT Press},
  editor	= {S. Haykin and J. C. Principe and T.J. Sejnowski and J.G.
		  McWhirter},
  pages		= {127--154},
  year		= {2007},
  abstract	= {We review methods for estimating the computational
		  capability of a complex dynamical system. The main examples
		  that we discuss are models for cortical neural
		  microcircuits with varying degrees of biological accuracy,
		  in the context of online computations on complex input
		  streams. We address in particular the question to what
		  extent earlier results ab out the relationship between the
		  edge of chaos and the compu tational power of dynamical
		  systems in discrete time for off -line computing also apply
		  to this case.}
}

@Article{LegensteinMaass:05a,
  author	= {R. Legenstein and W. Maass},
  title		= {Edge of Chaos and Prediction of Computational Performance
		  for Neural Circuit Models},
  journal	= {Neural Networks},
  year		= {2007},
  volume	= {20},
  number	= {3},
  pages		= {323--334},
  note		= {},
  abstract	= {We analyze in this article the significance of the edge of
		  chaos for real-time computations in neural microcircuit
		  models consisting of spiking neurons and dynamic synapses.
		  We find that the edge of chaos predicts quite well those
		  values of circuit parameters that yield maximal
		  computational performance. But obviously it makes no
		  prediction of their computational performance for other
		  parameter values. Therefore, we propose a new method for
		  predicting the computational performance of neural
		  microcircuit models. The new measure estimates directly the
		  kernel property and the generalization capability of a
		  neural microcircuit.We validate the proposed measure by
		  comparing its prediction with direct evaluations of the
		  computational performance of various neural microcircuit
		  models. The proposed method also allows us to quantify
		  differences in the computational performance and
		  generalization capability of neural circuits in different
		  dynamic regimes (UP- and DOWN-states) that have been
		  demonstrated through intracellular recordings in vivo.}
}

@Article{LegensteinMaass:07,
  author	= {R. Legenstein and W. Maass},
  title		= {On the classification capability of sign-constrained
		  perceptrons},
  journal	= {Neural Computation},
  volume	= {20},
  number	= {1},
  pages		= {288--309},
  year		= {2008},
  abstract	= {The perceptron (also referred to as McCulloch-Pitts
		  neuron, or linear threshold gate) is commonly used as a
		  simplified model for the discrimination and learning
		  capability of a biological neuron. Criteria that tell us
		  when a perceptron can implement (or learn to implement) all
		  possible dichotomies over a given set of input patterns are
		  well-known, but only for the idealized case where one
		  assumes that the sign of a synaptic weight can be switched
		  during learning. We present in this article an analysis of
		  the classification capability of the biologically more
		  realistic model of a sign-constrained perceptron, where the
		  signs of synaptic weights remain fixed during learning
		  (which is the case for most types of biological synapses).
		  In particular, the VC-dimension of sign-constrained
		  perceptrons is determined, and a necessary and sufficient
		  criterion is provided that tells us when all $2^m$
		  dichotomies over a given set of m patterns can be learned
		  by sign-constrained perceptron. We also show that
		  uniformity of {L1} norms of input patterns is a sufficient
		  condition for full representation power in the case where
		  all weights are required to be nonnegative. Finally, we
		  also exhibit cases where the sign-constraint of a
		  perceptron drastically reduces its classification
		  capability. Our theoretical analysis is complemented by
		  computer simulations, which demonstrate in particular that
		  sparse input patterns improve the classification capability
		  of sign-constrained perceptrons.}
}

@Article{LegensteinMaass:09,
  author	= {R. Legenstein and W. Maass},
  title		= {An integrated learning rule for branch strength
		  potentiation and {STDP}},
  journal	= {39th Annual Conference of the Society for Neuroscience,
		  Program 895.20, Poster HH36},
  year		= {2009},
  volume	= {},
  number	= {},
  pages		= {},
  abstract	= {Recent experimental data (Losonczy, Makara, and Magee,
		  Nature 2008) show that not only the strength of synaptic
		  efficacy is plastic, but also the coupling between
		  dendritic branches and the soma (via dendritic spikes).
		  More precisely, the strength of this coupling can be
		  increased both through a coincidence of dendritic branch
		  activations with action potential generation, and through a
		  coincidence of branch activation with ACh. This effect has
		  been called Branch Strength Potentiation (BSP). We show
		  through theoretical analysis and computer simulations that
		  the learning capability of single neurons is substantially
		  increased if STDP is combined with BSP. More precisely, we
		  show that a simple learning rule, based on a
		  error-minimization principle, contains both BSP and STDP as
		  special cases. The learning rule includes a homeostatic
		  mechanism which acts locally at the site of the dendritic
		  branch. The depression that was observed for
		  post-before-pre pairings in standard STDP experiments is
		  also observed in simulations of this learning rule. It can
		  be explained by the combined effect of this local
		  homeostatic mechanism and the backpropagating action
		  potential. This powerful new learning rule endows single
		  neurons with learning capabilities which were previously
		  unattainable. For example, a single neuron acquires through
		  this new learning rule the capability to solve a "binding
		  problem". I.e., a single neuron can learn to respond to
		  fire upon activation of presynaptic pools A and B, and also
		  upon activation of presynaptic pools C and D, but NOT in
		  response to concurrent activation of presynaptic pools A
		  and C, or B and D. We also consider a variation of this
		  learning rule where changes at synapses and branches are
		  not only based on local activity, but also on a global
		  reward signal that is indicated to the neuron by the
		  concentration of a neuromodulatory signal such as ACh. We
		  show that this biologically plausible learning rule for
		  reward-based learning is much more efficient than
		  previously proposed rules based on simple neuron models
		  without nonlinear branches.}
}

@InProceedings{MaassETAL:02a,
  author	= {W. Maass and R. Legenstein and H. Markram},
  title		= {A New Approach towards Vision suggested by Biologically
		  Realistic Neural Microcircuit Models},
  booktitle	= {Biologically Motivated Computer Vision. Proc. of the
		  Second International Workshop, BMCV 2002, Tuebingen,
		  Germany, November 22--24, 2002},
  editor	= {H. H. Buelthoff and S. W. Lee and T. A. Poggio and C.
		  Wallraven},
  series	= {Lecture Notes in Computer Science},
  volume	= {2525},
  pages		= {282--293},
  year		= {2002},
  publisher	= {Springer (Berlin)},
  abstract	= {We propose an alternative paradigm for processing
		  time-varying visual inputs, in particular for tasks
		  involving temporal and spatial integration, which is
		  inspired by hypotheses about the computational role of
		  cortical microcircuits. Since detailed knowledge about the
		  precise structure of the microcircuit is not needed for
		  that, it can in principle also be implemented with
		  partially unknown or faulty analog hardware. In addition,
		  this approach supports parallel realtime processing of
		  time-varying visual inputs for diverse tasks, since
		  different readouts can be trained to extract concurrently
		  from the same microcircuit completely different information
		  components.}
}

@InProceedings{MaassETAL:04,
  author	= {W. Maass and R. Legenstein and N. Bertschinger},
  booktitle	= {Advances in Neural Information Processing Systems},
  title		= {Methods for Estimating the Computational Power and
		  Generalization Capability of Neural Microcircuits},
  year		= {2005},
  volume	= {17},
  pages		= {865--872},
  editor	= {L. K. Saul and Y. Weiss and L. Bottou},
  publisher	= {MIT Press},
  abstract	= {What makes a neural microcircuit computationally powerful?
		  Or more precisely, which measurable quantities could
		  explain why one microcircuit $C$ is better suited for a
		  particular family of computational tasks than another
		  microcircuit $C'$? We propose in this article quantitative
		  measures for evaluating the computational power and
		  generalization capability of a neural microcircuit, and
		  apply them to generic neural microcircuit models drawn from
		  different distributions. We validate the proposed measures
		  by comparing their prediction with direct evaluations of
		  the computational performance of these microcircuit models.
		  This procedure is applied first to microcircuit models that
		  differ with regard to the spatial range of synaptic
		  connections and with regard to the scale of synaptic
		  efficacies in the circuit, and then to microcircuit models
		  that differ with regard to the level of background input
		  currents and the level of noise on the membrane potential
		  of neurons. In this case the proposed method allows us to
		  quantify differences in the computational power and
		  generalization capability of circuits in different dynamic
		  regimes (UP- and DOWN-states) that have been demonstrated
		  through intracellular recordings in vivo.}
}

@InProceedings{MaassLegenstein:01,
  author	= {R. A. Legenstein and W. Maass},
  title		= {Foundations for a circuit complexity theory of sensory
		  processing},
  booktitle	= {Proc. of NIPS 2000, Advances in Neural Information
		  Processing Systems},
  editor	= {T. K. Leen and T. G. Dietterich and V. Tresp},
  year		= {2001},
  volume	= {13},
  pages		= {259--265},
  publisher	= {MIT Press},
  address	= {Cambridge},
  htmlnote	= {The poster presented at NIPS is available as <a
		  href="./psfiles/122_poster.ps.gz">gzipped Postscript</a>.},
  abstract	= {We introduce {\em total wire length} as salient complexity
		  measure for an analysis of the circuit complexity of
		  sensory processing in biological neural systems and
		  neuromorphic engineering. Furthermore we introduce a set of
		  basic computational problems that apparently need to be
		  solved by circuits for translation- and scale-invariant
		  sensory processing. Finally we exhibit a number of circuit
		  design strategies for these new benchmark functions that
		  can be implemented within realistic complexity bounds, in
		  particular with linear or almost linear total wire length.}
}

@Article{MaassLegenstein:01a,
  author	= {R. A. Legenstein and W. Maass},
  title		= {Wire Length as a Circuit Complexity Measure},
  journal	= {Journal of Computer and System Sciences},
  year		= {2005},
  volume	= {70},
  pages		= {53--72},
  abstract	= { We introduce {\em wire length} as a salient complexity
		  measure for analyzing the circuit complexity of sensory
		  processing in biological neural systems. This new
		  complexity measure is applied in this paper to two basic
		  computational problems that arise in translation- and
		  scale-invariant pattern recognition, and hence appear to be
		  useful as benchmark problems for sensory processing. We
		  present new circuit design strategies for these benchmark
		  problems that can be implemented within realistic
		  complexity bounds, in particular with linear or almost
		  linear wire length. Finally we derive some general bounds
		  which provide information about the relationship between
		  new complexity measure wire length and traditional circuit
		  complexity measures.}
}

@Article{MaassLegenstein:01c,
  author	= {R. A. Legenstein and W. Maass},
  title		= {Neural circuits for pattern recognition with small total
		  wire length},
  journal	= {Theoretical Computer Science},
  volume	= {287},
  pages		= {239--249},
  year		= {2002},
  abstract	= {One of the most basic pattern recognition problems is
		  whether a certain local feature occurs in some linear array
		  to the left of some other local feature. We construct in
		  this article circuits that solve this problem with an
		  asymptotically optimal number of threshold gates.
		  Furthermore it is shown that much fewer threshold gates are
		  needed if one employs in addition a small number of
		  winner-take-all gates. In either case the circuits that are
		  constructed have linear or almost linear total wire length,
		  and are therefore not unrealistic from the point of view of
		  physical implementations.}
}

@Article{MaassLegenstein:01d,
  author	= {R. A. Legenstein and W. Maass},
  title		= {Optimizing the Layout of a Balanced Tree},
  journal	= {Technical Report},
  year		= {2001},
  abstract	= { It is shown that the total wire length of layouts of a
		  balanced binary tree on a 2-dimensional grid can be reduced
		  by 33% if one does not choose the obvious ``symmetric''
		  layout strategy. Furthermore it is shown that the more
		  efficient layout strategy that is presented in this article
		  is optimal, not only for binary trees but for m-ary trees
		  with any m >= 2.}
}

@InCollection{NatschlaegerETAL:04,
  author	= {T. Natschlaeger and N. Bertschinger and R. Legenstein},
  title		= {At the Edge of Chaos: Real-time Computations and
		  Self-Organized Criticality in Recurrent Neural Networks},
  booktitle	= {Advances in Neural Information Processing Systems 17},
  editor	= {Lawrence K. Saul and Yair Weiss and {L\'{e}on} Bottou},
  publisher	= {MIT Press},
  address	= {Cambridge, MA},
  pages		= {145-152},
  year		= 2005,
  abstract	= {In this paper we analyze the relationship between the
		  computational capabilities of randomly connected networks
		  of threshold gates in the timeseries domain and their
		  dynamical properties. In particular we propose a complexity
		  measure which we find to assume its highest values near the
		  edge of chaos, i.e. the transition from ordered to chaotic
		  dynamics. Furthermore we show that the proposed complexity
		  measure predicts the computational capabilities very well:
		  only near the edge of chaos are such networks able to
		  perform complex computations on time series. Additionally a
		  simple synaptic scaling rule for self-organized criticality
		  is presented and analyzed.}
}

@InProceedings{ToescherETAL:08,
  author	= {Andreas Toescher and Michael Jahrer and Robert
		  Legenstein},
  title		= {Improved Neighborhood-Based Algorithms for Large-Scale
		  Recommender Systems},
  note		= {in press},
  pages		= {},
  booktitle	= {KDD-Cup and Workshop},
  publisher	= {ACM},
  year		= 2008,
  abstract	= {Neighborhood-based algorithms are frequently used modules
		  of recommender systems. Usually, the choice of the
		  similarity measure used for evaluation of neighborhood
		  relationships is crucial for the success of such
		  approaches. In this article we propose a way to calculate
		  similarities by formulating a regression problem which
		  enables us to extract the similarities from the data in a
		  problem-specific way. Another popular approach for
		  recommender systems is regularized matrix factorization
		  (RMF). We present an algorithm -- neighborhood-aware matrix
		  factorization -- which efficiently includes neighborhood
		  information in a RMF model. This leads to increased
		  prediction accuracy. The proposed methods are tested on the
		  Netflix dataset.}
}
