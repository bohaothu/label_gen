@preamble{"\providecommand{\DTLpar}{\par}"}
@string{ESANN = "Proceedings of the European Symposium on Artifical Neural Networks"}
@string{ICANN = "Proceedings of the International Conference on Artificial Neural Networks"}
@string{ICIP = "Proceedings of the IEEE International Conference on Image Processing"}
@string{ICPR = "International Conference on Pattern Recognition"}
@string{IJCNN = "Proceedings of the IEEE/INNS International Joint Conference on Neural Networks"}
@string{IOA = "Proceedings of the Institute of Acoustics"}
@string{NIPS = "Advances in Neural Information Processing Systems"}
@string{JMLR = "Journal of Machine Learning Research"}

@article{Talbot2007,
   author  = "Nicola L. C. Talbot",
   title   = " Teaching {\LaTeX} for a staff development course",
   journal = "The Prac\TeX\ Journal",
   year    = "2007",
   number  = "4",
   url     = "http://tug.org/pracjourn/2007-4/talbot"
}

@article{Saadi2007,
   author  = "Kamel Saadi and Nicola L. C. Talbot and Gavin C. Cawley",
   title   = "Optimally regularised kernel {F}isher discriminant classification",
   journal = "Neural Networks",
   doi     = "10.1016/j.neunet.2007.05.005",
   volume  = 20,
   number  = 7,
   pages   = "832--841",
   month   = SEP,
   year    = 2007
}

@inproceedings{Cawley2007d,
   author    = "Gavin C. Cawley and Nicola L. C. Talbot",
   title     = "Agnostic learning versus prior knowledge in the  
                design of kernel machines",
   booktitle = IJCNN # " (IJCNN-2007)",
   pages     = "1720--1725",
   address   = "Orlando, Florida, USA",
   month     = AUG # "~12--17",
   year      = 2007
}

@inproceedings{Cawley2007c,
   author    = "Gavin C. Cawley and Gareth J. Janacek 
                and Nicola L. C. Talbot",
   title     = "Generalised kernel machines",
   booktitle = IJCNN # " (IJCNN-2007)",
   pages     = "1732--1737",
   address   = "Orlando, Florida, USA",
   month     = AUG # "~12--17",
   year      = 2007
}

@article{Cawley2007b,
author = "Gavin C. Cawley and Nicola L. C. Talbot",
title  = "Preventing over-fitting in model selection via {B}ayesian 
          regularisation of the hyper-parameters",
journal = JMLR,
volume  = 8,
pages   = "841--861",
month   = APR,
year    = 2007
}

@inproceedings{Cawley2007a,
author    = "Gavin C. Cawley and Nicola L. C. Talbot and Mark Girolami",
title     = "Sparse Multinomial Logistic Regression via {B}ayesian 
             {L1} Regularisation",
booktitle = NIPS # " 19",
editor    = {B. Scho\"{o}lkopf and J. C. Platt and T. Hofmann},
publisher = "MIT Press",
address   = "Cambridge, MA",
year      = 2007,
pdf       = "http://theoval.cmp.uea.ac.uk/~gcc/publications/pdf/nips2006a.pdf"
}

@article{Cawley2006a,
author    = "Gavin C. Cawley and Nicola L. C. Talbot",
title     = "Gene selection in cancer classification using sparse 
             logistic regression with {B}ayesian regularisation",
journal   = "Bioinformatics",
doi       = "10.1093/bioinformatics/btl386",
note      = "See \url{http://theoval.cmp.uea.ac.uk/~gcc/cbl/blogreg/}",
year      = 2006
}

@article{Cawley2006b,
author    = "Gavin C. Cawley and Nicola L. C. Talbot and
             Gareth J. Janacek and Mike W. Peck",
title     = "Sparse {B}ayesian kernel survival analysis for 
             modelling the growth domain of microbial pathogens",
journal   = "IEEE Transactions on Neural Networks",
volume    = 17,
number    = 2,
pages     = "471--481",
month     = MAR,
doi       = "10.1109/TNN.2005.863452",
year      = 2006
}

@article{Flom2005,
author  = "Peter Flom and Hans Hagen and Joe Hogg and 
           Nicola Talbot and Philip Taylor and Christina Thiele 
           and David Walden",
title   = "What is {\TeX}?",
journal = "The Prac{\TeX}\ Journal",
year    = "2005",
number  = "3",
url     = "http://tug.org/pracjourn/2005-3/walden-whatis"
}

@inproceedings{Cawley2005d,
   author    = "Cawley, Gavin C. and Talbot, Nicola L. C.",
   title     = "A simple trick for constructing {B}ayesian 
                formulations of sparse kernel learning methods",
   booktitle = IJCNN # " (IJCNN-2005)",
   pages     = "1425--1430",
   address   = "Montreal, Canada",
   month     = JUL # "~31~--~" # AUG # "~4",
   year      = 2005,
   pdf       = "http://theoval.sys.uea.ac.uk/~gcc/publications/pdf/ijcnn2005b.pdf"
}

@inproceedings{Cawley2005c,
   author    = "Cawley, Gavin C. and Talbot, Nicola L. C.",
   title     = "Sparse {B}ayesian learning and the relevance multi-layer
                perceptron network",
   booktitle = IJCNN # " (IJCNN-2005)",
   pages     = "1320--1324",
   address   = "Montreal, Canada",
   month     = JUL # "~31~--~" # AUG # "~4",
   year      = 2005,
   pdf       = "http://theoval.sys.uea.ac.uk/~gcc/publications/pdf/ijcnn2005a.pdf"
}

@inproceedings{Cawley2005b,
   author    = "Cawley, Gavin C. and Talbot, Nicola L. C. and Janacek, G. J. and
                Peck, Mike W.",
   title     = "{B}ayesian kernel learning methods for parametric accelerated
                life survival analysis",
   booktitle = "Proceedings of the Machine Learning Workshop",
   editor    = "Winkler, J. and Lawrence, N. and Niranjan, M.",
   series    = "Lecture Notes on Artificial Intelligence",
   volume    = "3635",
   pages     = "37--55",
   publisher = "Springer Verlag",
   address   = "Berlin",
   year      = 2005
}

@article{Cawley2005e,
   author    = "Cawley, Gavin C. and Talbot, Nicola L. C.",
   title     = "Constructing {B}ayesian formulations of sparse kernel learning
                methods",
   journal   = "Neural Networks",
   volume    = "18, issues 5--6",
   pages     = "674--683",
   month     = JUL # "--" # AUG,
   doi       = "10.1016/j.neunet.2005.06.002",
   year      = 2005
}

@article{Cawley2005f,
   author    = "Gavin C. Cawley and Nicola L. C. Talbot",
   title     = "The evidence framework applied to sparse kernel 
                logistic regression",
   journal   = "Neurocomputing",
   volume    = 64,
   pages     = "119--135",
   doi       = "10.1016/j.neucom.2004.11.021",
   year      = 2005
}

@article{Cawley2004z,
   author    = "Cawley, Gavin C. and Talbot, Nicola L. C. and 
                Janacek, G. J. and Peck, Mike W.",
   title     = "Parametric Accelerated Life Survival Analysis 
                using Sparse {B}ayesian Kernel Learning Methods",
   journal   = "IEEE Transactions on Neural Networks \emph{(accepted)}",
   year      = 2004
}

@inproceedings{Saadi2004a,
   author    = "K. Saadi and Nicola L. C. Talbot and Gavin C. Cawley",
   title     = "Optimally regularised kernel {F}isher discriminant analysis",
   booktitle = "Proceedings of the 17th " # ICPR # 
               " (ICPR-2004)",
   volume    = 2,
   pages     = "427--430",
   address   = "Cambridge, United Kingdom", 
   month     = Aug # "~23-26",
   year      = 2004,
   doi       = "10.1109/ICPR.2004.1334245",
   pdf       = "http://theoval.sys.uea.ac.uk/~gcc/publications/pdf/icpr2004b.pdf"
}
 
@inproceedings{Cawley2004a,
   author    = "Gavin C. Cawley and Nicola L. C. Talbot", 
   title     = "Efficient model selection for kernel logistic 
                regression",
   booktitle = "Proceedings of the 17th " # ICPR #
               " (ICPR-2004)",
   address   = "Cambridge, United Kingdom", 
   volume    = 2,
   pages     = "439--442",
   month     = Aug # "~23--26",
   year      = 2004,
   doi       = "10.1109/ICPR.2004.1334249",
   pdf       = "http://theoval.cmp.uea.ac.uk/~gcc/publications/pdf/icpr2004a.pdf",
   abstract  = "Kernel logistic regression models, like their
                linear counterparts, can be trained using the
                efficient iteratively re-weighted least-squares
                (IRWLS) algorithm. This approach suggests an
                \emph{approximate} leave-one-out cross-validation
                estimator based on an existing method for exact
                leave-one-out cross-validation of least-squares
                models.  Results compiled over seven benchmark
                datasets are presented for kernel logistic
                regression with model selection procedures based
                on both conventional k-fold and approximate
                leave-one-out cross-validation criteria, 
                demonstrating the proposed approach to be viable."
} 
 
@inproceedings{Cawley2004b,
   author    = "Gavin C. Cawley and Nicola L. C. Talbot",
   title     = "Sparse {B}ayesian kernel logistic regression", 
   booktitle = ESANN # " (ESANN-2004)",
   pages     = "133--138",
   address   = "Bruges, Belgium",
   month     = Apr # "~28--30",
   year      = 2004,
   pdf       = "http://theoval.cmp.uea.ac.uk/~gcc/publications/pdf/esann2004a.pdf"
}

@article{Cawley2004c,
   author    = "Cawley, Gavin C. and Talbot, Nicola L. C.",
   title     = "Fast leave-one-out cross-validation of sparse least-squares
                support vector machines",
   journal   = "Neural Networks",
   volume    = 17,
   number    = 10,
   pages     = "1467--1475",
   month     = DEC,
   year      = 2004,
   doi       = "10.1016/j.neunet.2004.07.002",
   pdf       = "http://theoval.cmp.uea.ac.uk/~gcc/publications/pdf/nn2004a.pdf",
   pubmed    = "15541948"
}

@article{Cawley2004d,
   author    = "Cawley, Gavin C. and Talbot, Nicola L. C.",
   title     = "The Evidence Framework applied to Sparse Kernel 
                Logistic Regression",
   journal   = "Neurocomputing",
   volume    = "64 (Trends in Neurocomputing : 
                12\textsuperscript{th} European Symposium on
                Artificial Neural Networks 2004)",
   pages     = "119--135",
   year      = 2004,
   doi       = "10.1016/j.neucom.2004.11.021"
}

@article{Cawley2004e,
   author    = "Cawley, Gavin C. and Talbot, Nicola L. C. and 
                Foxall, Robert J. and Dorling, Stephen R. and 
                Mandic, Danilo P.",
   title     = "Heteroscedastic kernel ridge regression",
   journal   = "Neurocomputing",
   pages     = "105--124",
   volume    = 57,
   month     = MAR,
   year      = 2004,
   pdf       = "http://theoval.sys.uea.ac.uk/~gcc/publications/pdf/neurocomp2004a.pdf",
   doi       = "10.1016/j.neucom.2004.01.005",
   abstract  = "In this paper we extend a form of kernel ridge
                regression (KRR) for data characterised by a
                heteroscedastic (i.e.\ input dependent
                variance) Gaussian noise process, introduced in
                Foxall et al.\ \cite{Foxall2002a}. It is shown
                that the proposed heteroscedastic kernel ridge
                regression model can give a more accurate
                estimate of the conditional mean of the target
                distribution than conventional KRR and also
                provides an indication of the spread of the
                target distribution (i.e.\ predictive error bars).
                The leave-one-out cross-validation estimate of the
                conditional mean is used in fitting the model of
                the conditional variance in order to overcome the
                inherent bias in maximum likelihood estimates of
                the variance. The benefits of the proposed model
                are demonstrated on synthetic and real-world
                benchmark data sets and for the task of predicting
                episodes of poor air quality in an urban 
                environment."
}
 
@inproceedings{Cawley2003b,
   author    = "Cawley, Gavin C. and Talbot, Nicola L. C. and 
                Foxall, Robert J. and Dorling, Stephen R. and 
                Mandic, Danilo P.",
   title     = "Unbiased Estimation of Conditional Variance in 
                Heteroscedastic Kernel Ridge Regression",
   booktitle = ESANN # " (ESANN-2003)",
   pages     = "209--214",
   address   = "Bruges, Belgium",
   month     = APR # "~23--25",
   year      = 2003,
   pdf       = "http://theoval.sys.uea.ac.uk/~gcc/publications/pdf/esann2003b.pdf"
}

 
@inproceedings{Cawley2003a,
   author    = "Gavin C. Cawley and Nicola L. C. Talbot",
   title     = "Efficient cross-validation of kernel Fisher 
                discriminant classifiers",
   booktitle = ESANN # " (ESANN-2003)",
   pages     = "241--246",
   address   = "Bruges, Belgium",
   month     = Apr # "~23-25",
   year      = 2003,
   pdf       = "http://theoval.sys.uea.ac.uk/~gcc/publications/pdf/esann2003a.pdf"
} 
 
@article{Cawley2003d,
   author  = "Gavin C. Cawley and Nicola L. C. Talbot",
   title   = "Efficient leave-one-out cross-validation of 
             kernel {F}isher discriminant classifiers",
   journal = "Pattern Recognition",
   volume  = 36,
   number  = 11,
   pages   = "2585--2592", 
   month   = Nov,
   year    = 2003,
   doi     = "10.1016/S0031-3203(03)00136-5",
   pdf       = "http://theoval.sys.uea.ac.uk/~gcc/publications/pdf/pr2003a.pdf"
} 
 
@article{Cawley2002f,
   author    = "Cawley, Gavin C. and Talbot, Nicola L. C.",
   title     = "Reduced rank kernel ridge regression",
   journal   = "Neural Processing Letters",
   volume    = 16,
   number    = 3,
   pages     = "293--302",
   month     = DEC,
   year      = 2002,
   pdf       = "http://theoval.sys.uea.ac.uk/~gcc/publications/pdf/npl2002a.pdf",
   doi       = "10.1023/A:1021798002258",
   Abstract  = "Ridge regression is a classical statistical 
                technique that attempts to address the 
                bias-variance trade-off in the design of linear 
                regression models. A reformulation of ridge 
                regression in dual variables permits a non-linear 
                form of ridge regression via the well-known 
                ``kernel trick''. Unfortunately, unlike support 
                vector regression models, the resulting kernel 
                expansion is typically fully dense.  In this 
                paper, we introduce a reduced rank kernel ridge 
                regression (RRKRR) algorithm, capable of 
                generating an optimally sparse kernel expansion 
                that is functionally identical to that resulting 
                from conventional kernel ridge regression (KRR). 
                The proposed method is demonstrated to 
                out-perform an alternative sparse kernel ridge 
                regression algorithm on the Motorcycle and 
                Boston Housing benchmarks"
}
 
@inproceedings{Cawley2002c,
   author    = "Cawley, Gavin C. and Talbot, Nicola L. C.",
   title     = "A Greedy Training Algorithm for Sparse 
                Least-Squares Support Vector Machines",
   booktitle = ICANN # " (ICANN-2002)",
   publisher = "Springer",
   series    = "Lecture Notes in Computer Science (LNCS)",
   volume    = "2415",
   pages     = "681--686",
   address   = "Madrid, Spain",
   month     = AUG # "~27--30",
   year      = 2002,
   pdf       = "http://theoval.sys.uea.ac.uk/~gcc/publications/pdf/icann2002a.pdf",
   Abstract  = "Suykens \emph{et al.}\ describes a form of kernel
                ridge regression known as the least-squares 
                support vector machine (LS-SVM). In this paper, 
                we present a simple, but efficient, greedy 
                algorithm for constructing near optimal sparse 
                approximations of least-squares support vector 
                machines, in which at each iteration the training 
                pattern minimising the regularised empirical risk 
                is introduced into the kernel expansion. The 
                proposed method demonstrates superior performance 
                when compared with the pruning technique described
                by Suykens \emph{et al.}, over the motorcycle and 
                Boston housing datasets"
}
 
@inproceedings{Cawley2002a,
   author    = "Cawley, G. C. and Talbot, N. L. C.",
   title     = "Efficient formation of a basis in a kernel 
                induced feature space",
   booktitle = ESANN # " (ESANN-2002)",
   pages     = "1--6",
   address   = "Bruges, Belgium",
   month     = APR # "~24--26",
   year      = 2002,
   pdf       = "http://theoval.sys.uea.ac.uk/~gcc/publications/pdf/esann2002a.pdf",
   Abstract  = "Baudat and Anouar (2001) propose a simple greedy 
                algorithm for estimation of an approximate basis 
                of the subspace spanned by a set of fixed vectors 
                embedded in a kernel induced feature space. The 
                resulting set of basis vectors can then be used 
                to construct sparse kernel expansions for 
                classification and regression tasks.  In this 
                paper we describe five algorithmic improvements 
                to the method of Baudat and Anouar, allowing the 
                construction of an approximate basis with a 
                computational complexity that is independent of 
                the number of training patterns, depending only 
                on the number of basis vectors extracted" 
}
 
@article{Cawley2002b,
   author    = "Cawley, Gavin C. and Talbot, Nicola L. C.",
   title     = "Improved Sparse Least-Squares Support Vector 
                Machines",
   journal   = "Neurocomputing",
   volume    = 48,
   pages     = "1025--1031",
   month     = OCT,
   year      = 2002,
   pdf       = "http://theoval.sys.uea.ac.uk/~gcc/publications/pdf/neurocomp2002a.pdf",
   doi       = "10.1016/S0925-2312(02)00606-9",
   Abstract  = "Suykens \emph{et al.}\  describe a weighted 
                least-squares formulation of the support vector 
                machine for regression problems and presents a 
                simple algorithm for sparse approximation of the 
                typically fully dense kernel expansions obtained 
                using this method. In this paper, we present an 
                improved method for achieving sparsity in 
                least-squares support vector machines, which 
                takes into account the residuals for all training 
                patterns, rather than only those incorporated 
                in the sparse kernel expansion. The superiority 
                of this algorithm is demonstrated on the 
                motorcycle and Boston housing datasets"
}
 
@inproceedings{Foxall2002a,
   author    = "Foxall, Robert J. and Cawley, Gavin C. and 
                Talbot, Nicola L. C. and
                Dorling, Stephen R. and Mandic, Danilo P.",
   title     = "Heteroscedastic regularised kernel regression for 
                prediction of episodes of poor air quality",
   booktitle = ESANN # " (ESANN-2002)",
   pages     = "19--24",
   address   = "Bruges, Belgium",
   month     = APR # "~24--26",
   year      = 2002,
   pdf       = "http://theoval.sys.uea.ac.uk/~gcc/publications/pdf/esann2002b.pdf",
   Abstract  = "A regularised kernel regression model is 
                introduced for data characterised by a 
                heteroscedastic (input dependent variance) 
                Gaussian noise process. The proposed model 
                provides more robust estimates of the conditional 
                mean than standard models and also confidence 
                intervals (error bars) on predictions. The 
                benefits of the proposed model are demonstrated 
                for the task of non-linear prediction of episodes 
                of poor air quality in urban environments"
}
 
@inproceedings{Saadi2002,
   author    = "Saadi, K. and Cawley, Gavin C. and 
                Talbot, Nicola L. C.",
   title     = "Fast exact leave-one-out cross-validation of 
                least-squares support vector machines",
   booktitle = ESANN # " (ESANN-2002)",
   pages     = "149--154",
   address   = "Bruges, Belgium",
   month     = APR # "~24--26",
   year      = 2002,
   pdf       = "http://theoval.sys.uea.ac.uk/~gcc/publications/pdf/esann2002c.pdf",
   Abstract  = "Model selection methods for kernel machines often 
                seek to minimise an upper bound on the 
                leave-one-out cross-validation error. This paper 
                describes an efficient algorithm for \emph{exact}
                leave-one-out cross-validation of least-squares 
                support vector machines, in both classification 
                and regression settings. The proposed method 
                exploits the considerable redundancy in the family
                of systems of linear equations to be solved in 
                explicit computation of the leave-one-out error. 
                The efficiency of the proposed approach is 
                demonstrated using real-world and synthetic 
                benchmark datasets"
}
 
@article{Barker2002,
   author   = "Gary C. Barker and Nicola L. C. Talbot and Michael W. Peck",
   title    = "Risk assessment for \emph{Clostridium botulinum}: 
             a network approach",
   journal  = "International Journal of Biodeterioration and Biodegredation", 
   volume   = 50,
   pages    = "167--175",
   year     = 2002,
   doi      = "10.1016/S0964-8305(02)00083-5", 
   abstract = "The construction and implementation of a 
               mathematical framework for the representation of 
               the hazards that arise from \emph{Clostridium 
               botulinum} growth, and toxin production, in food 
               are described. Botulism has been recognised as a 
               serious foodborne illness for over a century and, 
               more recently, has become the subject of increased 
               concern due to changing processing and consumption 
               patterns associated with foods. In this respect 
               quantitative risk assessment has an increasingly 
               important role to play in assisting risk 
               management and ensuring the safety of minimally 
               processed foods and foods with extended shelf 
               life.\DTLpar Bayesian Belief Networks are a type of 
               expert system that integrates a graphical flow 
               diagram like, representation of a hazard domain 
               with a powerful technique for combining 
               probabilities. This technique facilitates the 
               accumulation of understanding and experience, for 
               particular hazard domains, into computer tools 
               that can be used to inspect risks and account for 
               decisions.\DTLpar Analysis of the hazards associated 
               with foodborne botulism involves Belief Network 
               components that represent contamination processes, 
               thermal death kinetics for spores, germination and 
               growth of cells, toxin production and patterns of 
               consumer behaviour, etc. These developments are 
               discussed and three important aspects of the food 
               safety information supply, complexity, dependency 
               and uncertainty highlighted. The benefits 
               associated with a Bayesian view of food safety 
               assessment are illustrated by a Belief Network 
               representation which supports, and prioritises, 
               decisions and actions that (a) minimise the 
               chances and extent of the detrimental events and 
               (b) maximise opportunities for awareness and 
               control.",
}
 
@inproceedings{Cawley2001d,
   author    = "Cawley, Gavin C. and Talbot, Nicola L. C.",
   title     = "Manipulation of prior probabilities in support vector
                classification",
   booktitle = "Proceedings of the IEEE/INNS International Joint Conference on
                Neural Networks (IJCNN-2001)",
   pages     = "2433--2438",
   address   = "Washington, D.C., U.S.A.",
   month     = JUL # "~15--19",
   year      = 2001,
   pdf       = "http://theoval.sys.uea.ac.uk/~gcc/publications/pdf/ijcnn2001.pdf",
   Abstract  = "Asymmetric margin error costs for positive and 
                negative examples are often cited as an efficient 
                heuristic compensating for unrepresentative priors
                in training support vector classifiers. In this 
                paper we show that this heuristic is well 
                justified via simple resampling ideas applied to 
                the dual Lagrangian defining the 1-norm 
                soft-margin support vector machine. This 
                observation also provides a simple expression for 
                the asymptotically optimal ratio of margin error 
                penalties, eliminating the need for the 
                trial-and-error experimentation normally 
                encountered. This method allows the use of a 
                smaller, balanced training data set in problems 
                characterised by widely disparate prior 
                probabilities, reducing training time. We 
                demonstrate the usefulness of this method on a 
                real world benchmark problem, that of predicting 
                forest cover type given only cartographic data"
}
 
@inproceedings{Peck1999,
   author    = "Mike W. Peck and Nicola L. C. Talbot and 
                Gary C. Barker",
   title     = "Risk assessment for spore-forming bacteria in 
                food: {B}ayesian belief representations",
   booktitle = "Food Microbiology and Food Safety into the next 
                millennium", 
   pages     = "442--443",
   address   = "The Netherlands",
   year      =  1999, 
   publisher = "Foundation Food Micro '99: A.J.Zeist",
   editor    = "A. C. J. Tuitelaars and R. A. Samson and F. M. Rombouts
               and S. Notermans"
} 
 
@article{Barker1999a,
   author  = "Gary C. Barker and Nicola L. C. Talbot
              and Mike W. Peck",
   title   = "Microbial risk assessment for sous-vide foods",
   journal = "Third European Symposium on Sous-Vide",
   address = "Leuvan",
   month   = Mar,
   year    = 1999
} 
 
@misc{Peck1998,
   author  = "Mike W. Peck and Nicola L. C. Talbot and 
              Gary C. Barker",
   title   = "Quantitative risk assessment for \emph{Clostridium 
              botulinum} in minimally processed foods",
   note    = "Oral presentation and abstract at IBRCC 
              (Interagency botulism research co-ordinating 
              committee) meeting", 
   address = "Fort Washington, Pennsylvannia, USA",
   month   = Nov,
   year    = 1998
} 
 
@inproceedings{Talbot1997,
   author    = "Talbot, Nicola L. C. and Cawley, Gavin C.",
   title     = "A Fast Index Assignment Method for Robust Vector Quantisation
                of Image Data",
   booktitle = ICIP # " (ICIP-97)",
   volume    = "3",
   pages     = "674--677",
   address   = "Santa Barbara, California, U.S.A.",
   isbn      = "0-8186-8183-7",
   month     = OCT # "~26--29",
   year      = 1997,
   pdf       = "http://theoval.sys.uea.ac.uk/~gcc/publications/pdf/icip97.pdf"
}
 
@misc{Barker1997a,
   author = "Gary C. Barker and Nicola L. C. Talbot and 
             Mike W. Peck",
   title  = "Mathematical aspects of quantitative risk 
             assessment",
   note   = "Invited oral presentation at BBSRC Food Directorate 
             Microbiology Workshop", 
   address = "Birmingham, UK",
   month  = Mar,
   year   = 1997
} 
 
@misc{Barker1997b,
   author  = "Gary C. Barker and Nicola L. C. Talbot and 
             Mike W. Peck",
   title   = "Microbial risk assessment: a network approach",
   note    = "Poster presentation and abstract at Department of 
              Health/ACDP Seminar on Microbial Risk Assessment",
   address = "London, UK",
   month   = Jan,
   year    = 1997
} 
 
@article{Talbot1997b,
   author  = "Nicola L. C. Talbot and Rob E. Massara",
   title   = "A quadratic assignment algorithm that takes module 
             size into account",
   journal ="IEE Electronic Letters",
   year    = 1997
} 
 
@misc{Barker1996,
   author = "Gary C. Barker and Nicola L. C. Talbot and 
             Mike W. Peck",
   title  = "Risk assessment for microbial contamination hazards: 
             a network approach",
   note   = "Poster presentation and abstract at MAFF Hygienic
             Food Processing Workshop for Engineers and
             Microbiologists",
   address = "London, UK",
   month  = Nov,
   year   = 1996
} 
 
@inproceedings{Talbot1996,
   author    = "Talbot, Nicola L. C. and Cawley, Gavin C.",
   title     = "A Quadratic Index Assignment Algorithm for Vector
                Quantisation over Noisy Transmission Channels",
   booktitle = IOA # " Autumn Conference (Speech and Hearing 96)",
   volume    = 18,
   part      = 9,
   pages     = "195--199",
   month     = NOV,
   year      = 1996,
   pdf       = "http://theoval.sys.uea.ac.uk/~gcc/publications/pdf/ioa96.pdf"
}
 
@article{Cawley1996b,
   author    = "Cawley, Gavin C. and Talbot, Nicola L. C.",
   title     = "A Fast Index Assignment Algorithm for Vector Quantization over
              Noisy Transmission Channels",
   journal   = "Electronics Letters",
   volume    = 32,
   number    = 15,
   pages     = "1343--1344",
   issn      = "0013-5914",
   month     = JUL,
   year      = 1996,
   pdf       = "http://theoval.sys.uea.ac.uk/~gcc/publications/pdf/el96.pdf"
}
 
@phdthesis{Talbot1996b, 
   author = "Nicola L. C. Talbot",
   title  = "An application-oriented comparison of optimisation 
             and neural-based design techniques",
   school =  "Department of Electronic Systems Engineering, 
              University of Essex",
   month  = Mar,
   year   = 1996
} 
 
@inproceedings{Talbot1993,
   author    = "Nicola L. C. Talbot and Rob E. Massara",
   title     = "An application-oriented comparison of 
                optimisation and neural-based design techniques",
   booktitle = "36th Mid-West Symposium on Circuits and Systems", 
   year      = 1993
}
