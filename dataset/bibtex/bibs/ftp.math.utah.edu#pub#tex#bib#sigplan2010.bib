%%% -*-BibTeX-*-
%%% ====================================================================
%%%  BibTeX-file{
%%%     author          = "Nelson H. F. Beebe",
%%%     version         = "1.16",
%%%     date            = "16 September 2011",
%%%     time            = "11:32:24 MDT",
%%%     filename        = "sigplan2010.bib",
%%%     address         = "University of Utah
%%%                        Department of Mathematics, 110 LCB
%%%                        155 S 1400 E RM 233
%%%                        Salt Lake City, UT 84112-0090
%%%                        USA",
%%%     telephone       = "+1 801 581 5254",
%%%     FAX             = "+1 801 581 4148",
%%%     URL             = "http://www.math.utah.edu/~beebe",
%%%     checksum        = "59627 17445 86884 808452",
%%%     email           = "beebe at math.utah.edu, beebe at acm.org,
%%%                        beebe at computer.org (Internet)",
%%%     codetable       = "ISO/ASCII",
%%%     keywords        = "bibliography, BibTeX, programming languages,
%%%                        SIGPLAN",
%%%     license         = "public domain",
%%%     supported       = "yes",
%%%     docstring       = "This is a bibliography of ACM SIGPLAN
%%%                        Notices, covering 2010--2019.
%%%
%%%                        There are World Wide Web sites for the
%%%                        journal at
%%%
%%%                            http://www.acm.org/sigplan/
%%%                            http://portal.acm.org/browse_dl.cfm?idx=J706
%%%
%%%                        and
%%%
%%%                            http://www.rowan.edu/sigplan/
%%%
%%%                        and coverage of about a dozen volumes can be found at
%%%
%%%                            http://ftp.informatik.rwth-aachen.de/dblp/db/journals/sigplan/index.html
%%%
%%%                        Several conference proceedings are published
%%%                        as volumes of SIGPLAN Notices.  Many of them
%%%                        can also be found via the ACM proceedings Web
%%%                        sites:
%%%
%%%                            http://www.acm.org/pubs/contents/proceedings/
%%%                            http://www.acm.org/pubs/contents/proceedings/asplos/
%%%                            http://www.acm.org/pubs/contents/proceedings/plan/
%%%                            http://www.acm.org/pubs/contents/proceedings/pldi/
%%%
%%%                        At version 1.16, the year coverage looks like
%%%                        this:
%%%
%%%                             2010 ( 341)    2011 ( 202)
%%%
%%%                             Article:        543
%%%
%%%                             Total entries:  543
%%%
%%%                        Some of the bibliography entries in this
%%%                        file contain abstracts.  These are governed
%%%                        by the ACM Copyright Notice for ACM SIGPLAN
%%%                        Notices, which says:
%%%
%%%                             ``Permission to copy without fee all
%%%                             or part of this material is granted
%%%                             provided that the copies are not made
%%%                             or distributed for commercial
%%%                             advantage, the ACM copyright notice
%%%                             and the title of the publication and
%%%                             its date appear, and notice is given
%%%                             that copying is by permission of the
%%%                             Association for Computing Machinery.
%%%                             To copy otherwise, or to republish,
%%%                             requires a fee and/or specific
%%%                             permission.''
%%%
%%%                        Inasmuch as this bibliography, and its
%%%                        companion files in the master collection,
%%%                        is freely distributed without charge,
%%%                        inclusion of article abstracts clearly
%%%                        falls within the copyright permissions, and
%%%                        this author considers that ACM has given
%%%                        the required permission under the terms of
%%%                        the above Copyright Notice.
%%%
%%%                        BibTeX citation tags are uniformly chosen
%%%                        as name:year:abbrev, where name is the
%%%                        family name of the first author or editor,
%%%                        year is a 4-digit number, and abbrev is a
%%%                        3-letter condensation of important title
%%%                        words. Citation tags were automatically
%%%                        generated by software developed for the
%%%                        BibNet Project.
%%%
%%%                        In this bibliography, entries are sorted in
%%%                        publication order, using bibsort -byvolume.
%%%
%%%                        The checksum field above contains a CRC-16
%%%                        checksum as the first value, followed by the
%%%                        equivalent of the standard UNIX wc (word
%%%                        count) utility output of lines, words, and
%%%                        characters.  This is produced by Robert
%%%                        Solovay's checksum utility.",
%%%  }
%%% ====================================================================

@Preamble{
  "\input bibnames.sty " #
  "\input path.sty " #
  "\def \TM {${}^{\sc TM}$} " #
  "\hyphenation{ }"
}

%%% ====================================================================
%%% Acknowledgement abbreviations:

@String{ack-nhfb = "Nelson H. F. Beebe,
                    University of Utah,
                    Department of Mathematics, 110 LCB,
                    155 S 1400 E RM 233,
                    Salt Lake City, UT 84112-0090, USA,
                    Tel: +1 801 581 5254,
                    FAX: +1 801 581 4148,
                    e-mail: \path|beebe@math.utah.edu|,
                            \path|beebe@acm.org|,
                            \path|beebe@computer.org| (Internet),
                    URL: \path|http://www.math.utah.edu/~beebe/|"}

%%% ====================================================================
%%% Journal abbreviations:

@String{j-SIGPLAN               = "ACM SIG{\-}PLAN Notices"}

%%% ====================================================================
%%% Publisher abbreviations:

@String{pub-ACM                 = "ACM Press"}

@String{pub-ACM:adr             = "New York, NY, USA"}

@String{pub-AW                  = "Ad{\-d}i{\-s}on-Wes{\-l}ey"}

@String{pub-AW:adr              = "Reading, MA, USA"}

%%% ====================================================================
%%% Series abbreviations:

@String{ser-SIGPLAN               = "ACM SIG{\-}PLAN Notices"}

%%% ====================================================================
%%% Bibliography entries, in publication order:

@Article{Gershenfeld:2010:RAL,
  author =       "Neil Gershenfeld and David Dalrymple and Kailiang Chen
                 and Ara Knaian and Forrest Green and Erik D. Demaine
                 and Scott Greenwald and Peter Schmidt-Nielsen",
  title =        "Reconfigurable asynchronous logic automata: {(RALA)}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "1--6",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Atig:2010:VPW,
  author =       "Mohamed Faouzi Atig and Ahmed Bouajjani and Sebastian
                 Burckhardt and Madanlal Musuvathi",
  title =        "On the verification problem for weak memory models",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "7--18",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Koskinen:2010:CGT,
  author =       "Eric Koskinen and Matthew Parkinson and Maurice
                 Herlihy",
  title =        "Coarse-grained transactions",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "19--30",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Attiya:2010:SVS,
  author =       "H. Attiya and G. Ramalingam and N. Rinetzky",
  title =        "Sequential verification of serializability",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "31--42",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Godefroid:2010:CMM,
  author =       "Patrice Godefroid and Aditya V. Nori and Sriram K.
                 Rajamani and Sai Deep Tetali",
  title =        "Compositional may-must program analysis: unleashing
                 the power of alternation",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "43--56",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Chaudhuri:2010:CAP,
  author =       "Swarat Chaudhuri and Sumit Gulwani and Roberto
                 Lublinerman",
  title =        "Continuity analysis of programs",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "57--70",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Harris:2010:PAS,
  author =       "William R. Harris and Sriram Sankaranarayanan and
                 Franjo Ivan{\v{c}}i{\'c} and Aarti Gupta",
  title =        "Program analysis via satisfiability modulo path
                 programs",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "71--82",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Tristan:2010:SVV,
  author =       "Jean-Baptiste Tristan and Xavier Leroy",
  title =        "A simple, verified validator for software pipelining",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "83--92",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Chlipala:2010:VCI,
  author =       "Adam Chlipala",
  title =        "A verified compiler for an impure functional
                 language",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "93--106",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Myreen:2010:VJT,
  author =       "Magnus O. Myreen",
  title =        "Verified just-in-time compiler on {x86}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "107--118",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Terauchi:2010:DTC,
  author =       "Tachio Terauchi",
  title =        "Dependent types from counterexamples",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "119--130",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Rondon:2010:LLL,
  author =       "Patrick Maxim Rondon and Ming Kawaguchi and Ranjit
                 Jhala",
  title =        "Low-level liquid types",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "131--144",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Schafer:2010:TID,
  author =       "Max Sch{\"a}fer and Oege de Moor",
  title =        "Type inference for datalog with complex type
                 hierarchies",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "145--156",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Henzinger:2010:BQN,
  author =       "Thomas A. Henzinger",
  title =        "From {Boolean} to quantitative notions of
                 correctness",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "157--158",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Pitts:2010:NS,
  author =       "Andrew M. Pitts",
  title =        "Nominal system {T}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "159--170",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Hobor:2010:TIA,
  author =       "Aquinas Hobor and Robert Dockins and Andrew W. Appel",
  title =        "A theory of indirection via approximation",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "171--184",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Dreyer:2010:RML,
  author =       "Derek Dreyer and Georg Neis and Andreas Rossberg and
                 Lars Birkedal",
  title =        "A relational modal logic for higher-order stateful
                 {ADTs}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "185--198",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Suter:2010:DPA,
  author =       "Philippe Suter and Mirco Dotta and Viktor Kuncak",
  title =        "Decision procedures for algebraic data types with
                 abstractions",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "199--210",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Magill:2010:ANA,
  author =       "Stephen Magill and Ming-Hsien Tsai and Peter Lee and
                 Yih-Kuen Tsay",
  title =        "Automatic numeric abstractions for heap-manipulating
                 programs",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "211--222",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Jost:2010:SDQ,
  author =       "Steffen Jost and Kevin Hammond and Hans-Wolfgang Loidl
                 and Martin Hofmann",
  title =        "Static determination of quantitative resource usage
                 for higher-order programs",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "223--236",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Malecha:2010:TVR,
  author =       "Gregory Malecha and Greg Morrisett and Avraham Shinnar
                 and Ryan Wisnesky",
  title =        "Toward a verified relational database management
                 system",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "237--248",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Podelski:2010:CGF,
  author =       "Andreas Podelski and Thomas Wies",
  title =        "Counterexample-guided focus",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "249--260",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Nanevski:2010:SVH,
  author =       "Aleksandar Nanevski and Viktor Vafeiadis and Josh
                 Berdine",
  title =        "Structuring the verification of heap-manipulating
                 programs",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "261--274",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Jia:2010:DTP,
  author =       "Limin Jia and Jianzhou Zhao and Vilhelm Sj{\"o}berg
                 and Stephanie Weirich",
  title =        "Dependent types and program equivalence",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "275--286",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Hutchins:2010:PSS,
  author =       "DeLesley S. Hutchins",
  title =        "Pure subtype systems",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "287--298",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Gay:2010:MST,
  author =       "Simon J. Gay and Vasco T. Vasconcelos and Ant{\'o}nio
                 Ravara and Nils Gesbert and Alexandre Z. Caldeira",
  title =        "Modular session types for distributed object-oriented
                 programming",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "299--312",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Srivastava:2010:PVP,
  author =       "Saurabh Srivastava and Sumit Gulwani and Jeffrey S.
                 Foster",
  title =        "From program verification to program synthesis",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "313--326",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Vechev:2010:AGS,
  author =       "Martin Vechev and Eran Yahav and Greta Yorsh",
  title =        "Abstraction-guided synthesis of synchronization",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "327--338",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Bodik:2010:PAN,
  author =       "Rastislav Bodik and Satish Chandra and Joel Galenson
                 and Doug Kimelman and Nicholas Tung and Shaon Barman
                 and Casey Rodarmor",
  title =        "Programming with angelic nondeterminism",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "339--352",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Greenberg:2010:CMM,
  author =       "Michael Greenberg and Benjamin C. Pierce and Stephanie
                 Weirich",
  title =        "Contracts made manifest",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "353--364",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Siek:2010:TB,
  author =       "Jeremy G. Siek and Philip Wadler",
  title =        "Threesomes, with and without blame",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "365--376",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Wrigstad:2010:ITU,
  author =       "Tobias Wrigstad and Francesco Zappa Nardelli and
                 Sylvain Lebresne and Johan {\"O}stlund and Jan Vitek",
  title =        "Integrating typed and untyped code in a scripting
                 language",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "377--388",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Tate:2010:GCO,
  author =       "Ross Tate and Michael Stepp and Sorin Lerner",
  title =        "Generating compiler optimizations from proofs",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "389--402",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Dias:2010:AGI,
  author =       "Jo{\~a}o Dias and Norman Ramsey",
  title =        "Automatically generating instruction selectors using
                 declarative machine descriptions",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "403--416",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Jim:2010:SAD,
  author =       "Trevor Jim and Yitzhak Mandelbaum and David Walker",
  title =        "Semantics and algorithms for data-dependent grammars",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "417--430",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Broberg:2010:PRB,
  author =       "Niklas Broberg and David Sands",
  title =        "{Paralocks}: role-based information flow control and
                 beyond",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "431--444",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Bhargavan:2010:MVS,
  author =       "Karthikeyan Bhargavan and C{\'e}dric Fournet and
                 Andrew D. Gordon",
  title =        "Modular verification of security protocol code by
                 typing",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "445--456",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Martin:2010:DCO,
  author =       "Jean-Phillipe Martin and Michael Hicks and Manuel
                 Costa and Periklis Akritidis and Miguel Castro",
  title =        "Dynamically checking ownership policies in concurrent
                 {C}\slash {C++} programs",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "457--470",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Heizmann:2010:NI,
  author =       "Matthias Heizmann and Jochen Hoenicke and Andreas
                 Podelski",
  title =        "Nested interpolants",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "471--482",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Filinski:2010:MA,
  author =       "Andrzej Filinski",
  title =        "Monads in action",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "483--494",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Kobayashi:2010:HOM,
  author =       "Naoki Kobayashi and Naoshi Tabuchi and Hiroshi Unno",
  title =        "Higher-order multi-parameter tree transducers and
                 recursion schemes for program verification",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "1",
  pages =        "495--508",
  month =        jan,
  year =         "2010",
  CODEN =        "SINODQ",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Mar 15 19:13:16 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Nikhil:2010:UGP,
  author =       "Rishiyur S. Nikhil",
  title =        "Using {GPCE} principles for hardware systems and
                 accelerators: (bridging the gap to {HW} design)",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "2",
  pages =        "1--2",
  month =        feb,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1621607.1621608",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:37:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Moore's Law has precipitated a crisis in the creation
                 of hardware systems (ASICs and FPGAs)-how to design
                 such enormously complex concurrent systems quickly,
                 reliably and affordably? At the same time, portable
                 devices, the energy crisis, and high performance
                 computing present a related challenge-how to move
                 complex and high-performance algorithms from software
                 into hardware (for more speed and/or energy
                 efficiency)?\par

                 In this talk I will start with a brief technical
                 introduction to BSV, a language that directly addresses
                 these concerns. It uses ideas from Guarded Atomic
                 Actions (cf. Term Rewriting Systems, TLA+, Unity, and
                 EventB) to address complex concurrency with
                 scalability. It borrows from Haskell (types, type
                 classes, higher-order functions) for robustness and
                 powerful program generation (a.k.a. 'static
                 elaboration' to HW designers). And it is fully
                 synthesizable (compilable) into high-quality RTL
                 (Verilog/VHDL). I will then describe some of the
                 remarkable projects that BSV has enabled in industry
                 and academia today.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "Bluespec Systemverilog; BSV; energy efficient
                 computing; FPGA; hardware accelerators;
                 hardware/software codesign; Haskell; high level
                 synthesis; high performance computing; hybrid
                 computing; term rewriting systems",
}

@Article{Cordy:2010:EOO,
  author =       "James R. Cordy",
  title =        "Eating our own dog food: {DSLs} for generative and
                 transformational engineering",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "2",
  pages =        "3--4",
  month =        feb,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837852.1621609",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:37:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Languages and systems to support generative and
                 transformational solutions have been around a long
                 time. Systems such as XVCL, DMS, ASF+SDF, Stratego and
                 TXL have proven mature, efficient and effective in a
                 wide range of applications. Even so, adoption remains a
                 serious issue - almost all successful production
                 applications of these systems in practice either
                 involve help from the original authors or years of
                 experience to get rolling. While work on accessibility
                 is active, with efforts such as ETXL, Stratego XT,
                 Rascal and Colm, the fundamental big step remains -
                 it's not obvious how to apply a general purpose
                 transformational system to any given generation or
                 transformation problem, and the real power is in the
                 paradigms of use, not the languages themselves.\par

                 In this talk I will propose an agenda for addressing
                 this problem by taking our own advice - designing and
                 implementing domain specific languages (DSLs) for
                 specific generative, transformational and analysis
                 problem domains. We widely advise end users of the need
                 for DSLs for their kinds of problems - why not for our
                 kinds? And we use our tools for implementing their DSLs
                 - why not our own? I will outline a general method for
                 using transformational techniques to implement
                 transformational and generative DSLs, and review
                 applications of the method to implementing example
                 text-based DSLs for model-based code generation and
                 static code analysis. Finally, I will outline some
                 first steps in implementing model transformation DSLs
                 using the same idea - retaining the maturity and
                 efficiency of our existing tools while bringing them to
                 the masses by 'eating our own dogfood'.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "domain-specific languages; generative programming;
                 model driven engineering; source transformation
                 systems",
}

@Article{Willcock:2010:RGP,
  author =       "Jeremiah James Willcock and Andrew Lumsdaine and
                 Daniel J. Quinlan",
  title =        "Reusable, generic program analyses and
                 transformations",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "2",
  pages =        "5--14",
  month =        feb,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1621607.1621611",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:37:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "The optimizations in modern compilers are constructed
                 for a predetermined set of primitive types. As a
                 result, programmers are unable to exploit optimizations
                 for user-defined types where these optimizations would
                 be correct and beneficial. Moreover, because the set of
                 optimizations is also fixed, programmers are unable to
                 incorporate new optimizations into the compiler. To
                 address these limitations, we apply the reuse
                 methodologies from generic programming to compiler
                 analyses and optimizations. To enable compilers to
                 apply optimizations to classes of types rather than
                 particular types, we define optimizations in terms of
                 generic interface descriptions (similar to C++ concepts
                 or Haskell type classes). By extending these interface
                 descriptions to include associated program analysis and
                 transformation fragments, we enable compilers to
                 incorporate user-defined transformations and analyses.
                 Since these transformations are explicitly associated
                 with interface descriptions, they can be applied in
                 generic fashion by the compiler. We demonstrate that
                 classical compiler optimizations, when generalized
                 using this framework, can apply to a broad range of
                 types, both built-in and user-defined. Finally, we
                 present an initial implementation, the principles of
                 which are generalizable to other compilers.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "compiler optimization; generic programming",
}

@Article{Bagge:2010:ASB,
  author =       "Anya Helene Bagge and Valentin David and Magne
                 Haveraaen",
  title =        "The axioms strike back: testing with concepts and
                 axioms in {C++}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "2",
  pages =        "15--24",
  month =        feb,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1621607.1621612",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:37:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Modern development practises encourage extensive
                 testing of code while it is still under development,
                 using unit tests to check individual code units in
                 isolation. Such tests are typically case-based,
                 checking a likely error scenario or an error that has
                 previously been identified and fixed. Coming up with
                 good test cases is challenging, and focusing on
                 individual tests can distract from creating tests that
                 cover the full functionality.\par

                 Axioms, known from program specification, allow for an
                 alternative way of generating test cases, where the
                 intended functionality is described as rules or
                 equations that can be checked automatically. Axioms are
                 proposed as part of the {\em concept\/} feature of the
                 upcoming C++0x standard.\par

                 In this paper, we describe how tests may be generated
                 automatically from axioms in C++ concepts, and supplied
                 with appropriate test data to form effective automated
                 unit tests.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "algebraic specification; axiom-based testing; axioms;
                 C++; C++0x; concepts; generative programming; mouldable
                 programming; program transformation; test generation;
                 unit testing",
}

@Article{Garcia:2010:TFT,
  author =       "Ronald Garcia and Andrew Lumsdaine",
  title =        "Toward foundations for type-reflective
                 metaprogramming",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "2",
  pages =        "25--34",
  month =        feb,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1621607.1621613",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:37:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "C++ template metaprogramming has been used with great
                 success to build software applications and libraries.
                 In practice, however, template metaprogramming suffers
                 usability, reliability, and capability shortcomings,
                 and it is not well understood in theory. Template
                 metaprogramming has these problems because it relies on
                 emergent properties of disparate language features that
                 were tailored to other purposes. As a step toward solid
                 and sound language support for metaprogramming, this
                 paper establishes firm semantic foundations for select
                 capabilities of template metaprogramming.\par

                 We analyze C++ and the idioms of template
                 metaprogramming and isolate, in a language-neutral
                 fashion, fundamental capabilities of C++ that enable
                 metaprogramming. Guided by this analysis, we present a
                 design for a core calculus that directly expresses
                 fundamental metaprogramming capabilities, including
                 static computation, code generation, and type
                 reflection. We prove a typesafety property for
                 compile-time evaluation of metaprograms. To formally
                 connect the core calculus to programming practice, we
                 present a more convenient surface language for
                 metaprogramming. Its semantics are captured by
                 type-directed translation to the core calculus. We
                 prove that this translation preserves
                 well-typing.\par

                 This idealized presentation averts some of the
                 shortcomings of C++ template metaprogramming and
                 provides a framework for further study.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "c++; metaprogramming; reflection; semantics",
}

@Article{Sadat-Mohtasham:2010:TPD,
  author =       "Hossein Sadat-Mohtasham and H. James Hoover",
  title =        "Transactional pointcuts: designation reification and
                 advice of interrelated join points",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "2",
  pages =        "35--44",
  month =        feb,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837852.1621615",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:37:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Aspect-oriented mechanisms are characterized by their
                 join point models. A join point model has three
                 components: join points, which are elements of language
                 semantics; 'a means of identifying join points'; and 'a
                 means of affecting the behaviour at those join points.'
                 A pointcut-advice model is a dynamic join point model
                 in which join points are points in program execution.
                 Pointcuts select a set of join points, and advice
                 affects the behaviour of the selected join points. In
                 this model, join points are typically selected and
                 advised independently of each other. That is, the
                 relationships between join points are not taken into
                 account in join point selection and advice. In
                 practice, join points are often not independent.
                 Instead, they form part of a higher-level operation
                 that implements the intent of the developer ({\em
                 e.g.\/} managing a resource). There are natural
                 situations in which join points should be selected only
                 if they play a specific role in that operation.\par

                 We propose a new join point model that takes join point
                 interrelationships into account and allows the
                 designation of more complex computations as join
                 points. Based on the new model, we have designed an
                 aspect-oriented construct called a {\em transactional
                 pointcut (transcut)}. Transcuts select sets of
                 interrelated join points and reify them into
                 higher-level join points that can be advised. They
                 share much of the machinery and intuition of pointcuts,
                 and can be viewed as their natural extension. We have
                 implemented a transcuts prototype as an extension to
                 the AspectJ language and integrated it into the abc
                 compiler. We present an example where a transcut is
                 applied to implement recommended resource handling
                 practices in the presence of exceptions within method
                 boundaries.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "aspect-oriented programming; join point model;
                 transactional pointcut",
}

@Article{Akai:2010:EAS,
  author =       "Shumpei Akai and Shigeru Chiba",
  title =        "Extending {AspectJ} for separating regions",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "2",
  pages =        "45--54",
  month =        feb,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837852.1621616",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:37:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Synchronization is a good candidate for an aspect in
                 aspect-oriented programming (AOP) since programmers
                 have to choose the best granularity of synchronization
                 for the underlying hardware to obtain the best
                 execution performance. If synchronization is an aspect,
                 programmers can change the synchronization code
                 independently of the rest of the program when the
                 program runs on different hardware. However, existing
                 AOP languages such as AspectJ have problems. They
                 cannot select an arbitrary code region as a join point.
                 Moreover, they cannot enforce weaving of a
                 synchronization aspect. Since it is an alternative
                 feature in feature modeling, at least one of available
                 synchronization aspects must be woven. Otherwise, the
                 program would be thread-unsafe. Since an aspect in
                 AspectJ is inherently optional, programmers must be
                 responsible for weaving it. To solve these problems,
                 this paper proposes two new constructs for AspectJ,
                 {\em regioncut\/} and {\em assertions for advice}.
                 Regioncut selects arbitrary code region as a join point
                 and assertion for advice enforces weaving a mandatory
                 advice. We implemented these constructs by extending
                 the AspectBench compiler. We evaluated the design of
                 our constructs by applying them to two open-source
                 software products, Javassist and Hadoop.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "aspect-oriented programming; feature-oriented
                 programming; region; synchronization",
}

@Article{Liu:2010:LFI,
  author =       "Yanhong A. Liu and Michael Gorbovitski and Scott D.
                 Stoller",
  title =        "A language and framework for invariant-driven
                 transformations",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "2",
  pages =        "55--64",
  month =        feb,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837852.1621617",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:37:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "This paper describes a language and framework that
                 allow coordinated transformations driven by invariants
                 to be specified declaratively, as invariant rules, and
                 applied automatically. The framework supports
                 incremental maintenance of invariants for program
                 design and optimization, as well as general
                 transformations for instrumentation, refactoring, and
                 other purposes. This paper also describes our
                 implementations for transforming Python and C programs
                 and experiments with successful applications of the
                 systems in generating efficient implementations from
                 clear and modular specifications, in instrumenting
                 programs for runtime verification, profiling, and
                 debugging, and in code refactoring.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "incremental maintenance; invariants; program
                 optimization; program transformation; runtime invariant
                 checking",
}

@Article{Wehr:2010:JBP,
  author =       "Stefan Wehr and Peter Thiemann",
  title =        "{JavaGI} in the battlefield: practical experience with
                 generalized interfaces",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "2",
  pages =        "65--74",
  month =        feb,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1621607.1621619",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:37:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Generalized interfaces are an extension of the
                 interface concept found in object-oriented languages
                 such as Java or C\#. The extension is inspired by
                 Haskell's type classes. It supports retroactive and
                 type-conditional interface implementations, binary
                 methods, symmetric multimethods, interfaces over
                 families of types, and static interface
                 methods.\par

                 This article reports practical experience with
                 generalized interfaces as implemented in the JavaGI
                 language. Several real-world case studies demonstrate
                 how generalized interfaces provide solutions to
                 extension and integration problems with components in
                 binary form, how they make certain design patterns
                 redundant, and how they eliminate various run-time
                 errors. In each case study, the use of JavaGI results
                 in elegant and highly readable code.\par

                 Furthermore, the article discusses the implementation
                 of a compiler and a run-time system for JavaGI.
                 Benchmarks show that our implementation offers
                 acceptable performance.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "case studies; external methods; JavaGI; multimethods;
                 retroactive interface implementation",
}

@Article{McGachey:2010:CJC,
  author =       "Phil McGachey and Antony L. Hosking and J. Eliot B.
                 Moss",
  title =        "Classifying {Java} class transformations for pervasive
                 virtualized access",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "2",
  pages =        "75--84",
  month =        feb,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1621607.1621620",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:37:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "The indirection of object accesses is a common theme
                 for target domains as diverse as transparent
                 distribution, persistence, and program instrumentation.
                 Virtualizing accesses to fields and methods (by
                 redirecting calls through accessor and indirection
                 methods) allows interposition of arbitrary code,
                 extending the functionality of an application beyond
                 that intended by the original developer.\par

                 We present class modifications performed by our RuggedJ
                 transparent distribution platform for standard Java
                 virtual machines. RuggedJ abstracts over the location
                 of objects by implementing a single object model for
                 local and remote objects. However the implementation of
                 this model is complicated by the presence of native and
                 system code; classes loaded by Java's bootstrap class
                 loader can be rewritten only in a limited manner, and
                 so cannot be modified to conform to RuggedJ's complex
                 object model. We observe that system code comprises the
                 majority of a given Java application: an average of
                 76\% in the applications we study. We consider the
                 constraints imposed upon pervasive class transformation
                 within Java, and present a framework for systematically
                 rewriting arbitrary applications. Our system
                 accommodates all system classes, allowing both user and
                 system classes alike to be referenced using a single
                 object model.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "Java; object model; program transformation",
}

@Article{Villazon:2010:ARA,
  author =       "Alex Villaz{\'o}n and Walter Binder and Danilo
                 Ansaloni and Philippe Moret",
  title =        "Advanced runtime adaptation for {Java}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "2",
  pages =        "85--94",
  month =        feb,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1621607.1621621",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:37:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Dynamic aspect-oriented programming (AOP) enables
                 runtime adaptation of aspects, which is important for
                 building sophisticated, aspect-based software
                 engineering tools, such as adaptive profilers or
                 debuggers that dynamically modify instrumentation code
                 in response to user interactions. Today, many AOP
                 frameworks for Java, notably AspectJ, focus on aspect
                 weaving at compile-time or at load-time, and offer only
                 limited support for aspect adaptation and reweaving at
                 runtime. In this paper, we introduce HotWave, an AOP
                 framework based on AspectJ for standard Java Virtual
                 Machines (JVMs). HotWave supports dynamic (re)weaving
                 of previously loaded classes, and it ensures that all
                 classes loaded in a JVM can be (re)woven, including the
                 classes of the standard Java class library. HotWave
                 features a novel mechanism for inter-advice
                 communication, enabling efficient data passing between
                 advices that are woven into the same method. We explain
                 HotWave's programming model and discuss our
                 implementation techniques. As case study, we present an
                 adaptive, aspect-based profiler that leverages
                 HotWave's distinguishing features.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "AspectJ; bytecode instrumentation; code hotswapping;
                 dynamic aspect-oriented programming; Java Virtual
                 Machine; runtime aspect adaptation and (re)weaving",
}

@Article{Villazon:2010:HCA,
  author =       "Alex Villaz{\'o}n and Walter Binder and Danilo
                 Ansaloni and Philippe Moret",
  title =        "{HotWave}: creating adaptive tools with dynamic
                 aspect-oriented programming in {Java}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "2",
  pages =        "95--98",
  month =        feb,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1621607.1621622",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:37:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Developing tools for profiling, debugging, testing,
                 and reverse engineering is error-prone, time-consuming,
                 and therefore costly when using low-level techniques,
                 such as bytecode instrumentation. As a solution to
                 these problems, we promote tool development in Java
                 using high-level aspect-oriented programming (AOP). We
                 demonstrate that the use of aspects yields compact
                 tools that are easy to develop and extend. As enabling
                 technology, we rely on HotWave, a new tool for dynamic
                 and comprehensive aspect weaving. HotWave reconciles
                 compatibility with existing virtual machine and AOP
                 technologies. It provides support for runtime
                 adaptation of aspects and reweaving of previously
                 loaded code, as well as the ability to weave aspects
                 into all methods executing in a Java Virtual Machine,
                 including methods in the standard Java class library.
                 HotWave also features a new mechanism for efficiently
                 passing data between advices that are woven into the
                 same method. We demonstrate the benefits of HotWave's
                 distinguishing features with two case studies in the
                 area of profiling.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "AspectJ; bytecode instrumentation; code hotswapping;
                 dynamic aspect-oriented programming; Java Virtual
                 Machine; profiling; runtime weaving",
}

@Article{Heidenreich:2010:GST,
  author =       "Florian Heidenreich and Jendrik Johannes and Mirko
                 Seifert and Christian Wende and Marcel B{\"o}hme",
  title =        "Generating safe template languages",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "2",
  pages =        "99--108",
  month =        feb,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1621607.1621624",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:37:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Template languages are widely used within generative
                 programming, because they provide intuitive means to
                 generate software artefacts expressed in a specific
                 object language. However, most template languages
                 perform template instantiation on the level of string
                 literals, which allows neither syntax checks nor
                 semantics analysis. To make sure that generated
                 artefacts always conform to the object language, we
                 propose to perform static analysis at template design
                 time. In addition, the increasing popularity of
                 domainspecific languages (DSLs) demands an approach
                 that allows to reuse both the concepts of template
                 languages and the corresponding tools.\par

                 In this paper we address the issues mentioned above by
                 presenting how existing languages can be automatically
                 extended with generic template concepts (e.g.,
                 placeholders, loops, conditions) to obtain safe
                 template languages. These languages provide means for
                 syntax checking and static semantic analysis w.r.t. the
                 object language at template design time. We discuss the
                 prerequisites for this extension, analyse the types of
                 correctness properties that can be assured at template
                 design time, and exemplify the key benefits of this
                 approach on a textual DSL and Java.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "generative programming; language extension; safe
                 authoring; template language",
}

@Article{Kong:2010:APT,
  author =       "Soonho Kong and Wontae Choi and Kwangkeun Yi",
  title =        "Abstract parsing for two-staged languages with
                 concatenation",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "2",
  pages =        "109--116",
  month =        feb,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1621607.1621625",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:37:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "This article, based on Doh, Kim, and Schmidt's
                 'abstract parsing' technique, presents an abstract
                 interpretation for statically checking the syntax of
                 generated code in two-staged programs. Abstract parsing
                 is a static analysis technique for checking the syntax
                 of generated strings. We adopt this technique for
                 two-staged programming languages and formulate it in
                 the abstract interpretation framework. We parameterize
                 our analysis with the abstract domain so that one can
                 choose the abstract domain as long as it satisfies the
                 condition we provide. We also present an instance of
                 the abstract domain, namely an abstract parse stack and
                 its widening with k-cutting.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "abstract interpretation; multi-staged languages;
                 parsing; program analysis",
}

@Article{Nedunuri:2010:SFP,
  author =       "Srinivas Nedunuri and William R. Cook",
  title =        "Synthesis of fast programs for maximum segment sum
                 problems",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "2",
  pages =        "117--126",
  month =        feb,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837852.1621626",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:37:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "It is well-known that a naive algorithm can often be
                 turned into an efficient program by applying
                 appropriate semantics-preserving transformations. This
                 technique has been used to derive programs to solve a
                 variety of maximum-sum programs. One problem with this
                 approach is that each problem variation requires a new
                 set of transformations to be derived. An alternative
                 approach to generation combines problem specifications
                 with flexible algorithm theories to derive efficient
                 algorithms. We show how this approach can be
                 implemented in Haskell and applied to solve constraint
                 satisfaction problems. We illustrate this technique by
                 deriving programs for three varieties of
                 maximum-weightsum problem. The derivations of the
                 different programs are similar, and the resulting
                 programs are asymptotically faster in practice than the
                 programs created by transformation.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "algorithms; branch-and-bound; formal methods; program
                 synthesis; segment-sum problems",
}

@Article{Radermacher:2010:GEI,
  author =       "Ansgar Radermacher and Arnaud Cuccuru and Sebastien
                 Gerard and Fran{\c{c}}ois Terrier",
  title =        "Generating execution infrastructures for
                 component-oriented specifications with a model driven
                 toolchain: a case study for {MARTE}'s {GCM} and
                 real-time annotations",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "2",
  pages =        "127--136",
  month =        feb,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1621607.1621628",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:37:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "The development of embedded Systems becomes more and
                 more complex. Model driven engineering can help to
                 manage this complexity by specifying real-time
                 properties in a declarative way and automating the
                 deployment. The UML profile MARTE is a OMG standard
                 that allows to model real-time properties. However,
                 there is no execution infrastructure that supports
                 MARTE's generic component model (GCM) and the
                 application modeling (HLAM).\par

                 The contribution of the paper is twofold: it presents a
                 proposition of a component model with flexible
                 interaction support that allows to tailor code
                 generation to domain and target requirements. Second,
                 it will show how MARTE's GCM concepts can be
                 implemented by means of the proposed component model.
                 The proposed component model has been largely developed
                 in the context of the French national project
                 Flex-eWare with the intention to unify major components
                 model, notably the CORBA component model (CCM) and
                 Fractal. The paper explains the major elements of this
                 model in detail and shows how specific connector and
                 containers can implement MARTE specifications. We
                 present the tool support that is integrated into a UML
                 modeler and based on model-to-model and model to text
                 transformations.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "component models; connectors; MARTE; middleware;
                 model-driven engineering",
}

@Article{Cassou:2010:GPA,
  author =       "Damien Cassou and Benjamin Bertran and Nicolas Loriant
                 and Charles Consel",
  title =        "A generative programming approach to developing
                 pervasive computing systems",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "2",
  pages =        "137--146",
  month =        feb,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1621607.1621629",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:37:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Developing pervasive computing applications is a
                 difficult task because it requires to deal with a wide
                 range of issues: heterogeneous devices, entity
                 distribution, entity coordination, low-level hardware
                 knowledge. . . Besides requiring various areas of
                 expertise, programming such applications involves
                 writing a lot of administrative code to glue
                 technologies together and to interface with both
                 hardware and software components.\par

                 This paper proposes a generative programming approach
                 to providing programming, execution and simulation
                 support dedicated to the pervasive computing domain.
                 This approach relies on a domain-specific language,
                 named DiaSpec, dedicated to the description of
                 pervasive computing systems. Our generative approach
                 factors out features of distributed systems
                 technologies, making DiaSpec-specified software systems
                 portable.\par

                 The DiaSpec compiler is implemented and has been used
                 to generate dedicated programming frameworks for a
                 variety of pervasive computing applications, including
                 detailed ones to manage the building of an engineering
                 school.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "DSL; generative programming; pervasive computing",
}

@Article{Jarvi:2010:AUI,
  author =       "Jaakko J{\"a}rvi and Mat Marcus and Sean Parent and
                 John Freeman and Jacob Smith",
  title =        "Algorithms for user interfaces",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "2",
  pages =        "147--156",
  month =        feb,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1621607.1621630",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:37:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "User interfaces for modern applications must support a
                 rich set of interactive features. It is commonplace to
                 find applications with dependencies between values
                 manipulated by user interface elements, conditionally
                 enabled controls, and script record-ability and
                 playback against different documents. A significant
                 fraction of the application programming effort is
                 devoted to implementing such functionality, and the
                 resulting code is typically not reusable.\par

                 This paper extends our 'property models' approach to
                 programming user interfaces. Property models allow a
                 large part of the functionality of a user interface to
                 be implemented in reusable libraries, reducing
                 application specific code to a set of declarative
                 rules. We describe how, as a by-product of computations
                 that maintain the values of user interface elements,
                 property models obtain accurate information of the
                 currently active dependencies among those elements.
                 This information enables further expanding the class of
                 user interface functionality that we can encode as
                 generic algorithms. In particular, we describe
                 automating the decisions for the enablement of user
                 interface widgets and activation of command widgets.
                 Failing to disable or deactivate widgets correctly is a
                 common source of user-interface defects, which our
                 approach largely removes.\par

                 We report on the increased reuse, reduced defect rates,
                 and improved user interface design turnarounds in a
                 commercial software development effort as a result of
                 adopting our approach.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "component software; constraint systems; declarative
                 specifications; software reuse; user interfaces",
}

@Article{Kastner:2010:MRP,
  author =       "Christian K{\"a}stner and Sven Apel and Martin
                 Kuhlemann",
  title =        "A model of refactoring physically and virtually
                 separated features",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "2",
  pages =        "157--166",
  month =        feb,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837852.1621632",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:37:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Physical separation with class refinements and method
                 refinements {\`a} la AHEAD and virtual separation using
                 annotations {\`a} la {\em \#ifdef\/} or CIDE are two
                 competing implementation approaches for software
                 product lines with complementary advantages. Although
                 both approaches have been mainly discussed in
                 isolation, we strive for an integration to leverage the
                 respective advantages. In this paper, we lay the
                 foundation for such an integration by providing a model
                 that supports both physical and virtual separation and
                 by describing refactorings in both directions. We prove
                 the refactorings complete, so every virtually separated
                 product line can be automatically transformed into a
                 physically separated one (replacing annotations by
                 refinements) and vice versa. To demonstrate the
                 feasibility of our approach, we have implemented the
                 refactorings in our tool CIDE and conducted four case
                 studies.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "AHEAD; CIDE; FeatureHouse; preprocessor; refinements;
                 separation of concerns; software product lines",
}

@Article{Sanen:2010:MPS,
  author =       "Frans Sanen and Eddy Truyen and Wouter Joosen",
  title =        "Mapping problem-space to solution-space features: a
                 feature interaction approach",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "2",
  pages =        "167--176",
  month =        feb,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837852.1621633",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:37:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Mapping problem-space features into solution-space
                 features is a fundamental configuration problem in
                 software product line engineering. A configuration
                 problem is defined as generating the most optimal
                 combination of software features given a requirements
                 specification and given a set of configuration rules.
                 Current approaches however provide little support for
                 expressing complex configuration rules between problem
                 and solution space that support incomplete requirements
                 specifications. In this paper, we propose an approach
                 to model complex configuration rules based on a
                 generalization of the concept of problem-solution
                 feature interactions. These are interactions between
                 solution-space features that only arise in specific
                 problem contexts. The use of an existing tool to
                 support our approach is also discussed: we use the DLV
                 answer set solver to express a particular configuration
                 problem as a logic program whose answer set corresponds
                 to the optimal combinations of solution-space features.
                 We motivate and illustrate our approach with a case
                 study in the field of managing dynamic adaptations in
                 distributed software, where the goal is to generate an
                 optimal protocol for accommodating a given
                 adaptation.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "configuration knowledge; default logic; distributed
                 runtime adaptation; DLV; problem-solution feature
                 interactions; software product line engineering",
}

@Article{Kuhlemann:2010:SCN,
  author =       "Martin Kuhlemann and Don Batory and Christian
                 K{\"a}stner",
  title =        "Safe composition of non-monotonic features",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "2",
  pages =        "177--186",
  month =        feb,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1621607.1621634",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:37:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Programs can be composed from features. We want to
                 verify automatically that all legal combinations of
                 features can be composed safely without errors. Prior
                 work on this problem assumed that features add code
                 monotonically. We generalize prior work to enable
                 features to add {\em and remove\/} code, describe our
                 analyses and implementation, and review case studies.
                 We observe that more expressive features increase the
                 complexity of developed programs rapidly -- up to the
                 point where tools and automated concepts as presented
                 in this paper are indispensable for verification.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "AHEAD; feature-oriented programming; refactoring; safe
                 composition",
}

@Article{Brewer:2010:TDR,
  author =       "Eric A. Brewer",
  title =        "Technology for developing regions: {Moore}'s law is
                 not enough",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "1--2",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1736020.1736021",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "The historic focus of development has rightfully been
                 on macroeconomics and good governance, but technology
                 has an increasingly large role to play. In this talk, I
                 review several novel technologies that we have deployed
                 in India and Africa, and discuss the challenges and
                 opportunities of this new subfield of EECS research.
                 Working with the Aravind Eye Hospital, we are currently
                 supporting doctor / patient videoconferencing in 30+
                 rural villages; more than 25,000 people have had their
                 blindness cured due to these exams.\par

                 Although Moore's Law has led to great cost reductions
                 and thus enabled new technologies, we have reached
                 essentially the low point for cost: the computing is
                 essentially free compared to the rest of the system.
                 The premium is thus on a combination of (1) deeper
                 integration (fewer compo-nents), (2) shared usage
                 models (even phones are shared), and (3) lower
                 operating costs in terms of power and connectivity.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "developing regions; ictd; it for development.",
}

@Article{Ipek:2010:DRM,
  author =       "Engin Ipek and Jeremy Condit and Edmund B. Nightingale
                 and Doug Burger and Thomas Moscibroda",
  title =        "Dynamically replicated memory: building reliable
                 systems from nanoscale resistive memories",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "3--14",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1735970.1736023",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "DRAM is facing severe scalability challenges in
                 sub-45nm technology nodes due to precise charge
                 placement and sensing hurdles in deep-submicron
                 geometries. Resistive memories, such as phase-change
                 memory (PCM), already scale well beyond DRAM and are a
                 promising DRAM replacement. Unfortunately, PCM is
                 write-limited, and current approaches to managing
                 writes must decommission pages of PCM when the first
                 bit fails.\par

                 This paper presents {\em dynamically replicated
                 memory\/} (DRM), the first hardware and operating
                 system interface designed for PCM that allows {\em
                 continued operation through graceful degradation\/}
                 when hard faults occur. DRM reuses memory pages that
                 contain hard faults by dynamically forming pairs of
                 complementary pages that act as a single page of
                 storage. No changes are required to the processor
                 cores, the cache hierarchy, or the operating system's
                 page tables. By changing the memory controller, the
                 TLBs, and the operating system to be DRM-aware, we can
                 improve the lifetime of PCM by up to 40x over
                 conventional error-detection techniques.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "phase-change memory; write endurance",
}

@Article{Kirman:2010:PEA,
  author =       "Nevin Kirman and Jos{\'e} F. Mart{\'\i}nez",
  title =        "A power-efficient all-optical on-chip interconnect
                 using wavelength-based oblivious routing",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "15--28",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1736020.1736024",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "We present an all-optical approach to constructing
                 data networks on chip that combines the following key
                 features: (1) Wavelength-based routing, where the route
                 followed by a packet depends solely on the wavelength
                 of its carrier signal, and not on information either
                 contained in the packet or traveling along with it. (2)
                 Oblivious routing, by which the wavelength (and thus
                 the route) employed to connect a source-destination
                 pair is invariant for that pair, and does not depend on
                 ongoing transmissions by other nodes, thereby
                 simplifying design and operation. And (3) passive
                 optical wavelength routers, whose routing pattern is
                 set at design time, which allows for area and power
                 optimizations not generally available to solutions that
                 use dynamic routing. Compared to prior proposals, our
                 evaluation shows that our solution is significantly
                 more power efficient at a similar level of
                 performance.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "nanophotonics; on-chip network; optical network;
                 wavelength-based oblivious routing",
}

@Article{Neelakantam:2010:RSE,
  author =       "Naveen Neelakantam and David R. Ditzel and Craig
                 Zilles",
  title =        "A real system evaluation of hardware atomicity for
                 software speculation",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "29--38",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1735970.1736026",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "In this paper we evaluate the atomic region compiler
                 abstraction by incorporating it into a commercial
                 system. We find that atomic regions are simple and
                 intuitive to integrate into an x86 binary-translation
                 system. Furthermore, doing so trivially enables
                 additional optimization opportunities beyond that
                 achievable by a high-performance dynamic optimizer,
                 which already implements superblocks.\par

                 We show that atomic regions can suffer from severe
                 performance penalties if misspeculations are left
                 uncontrolled, but that a simple software control
                 mechanism is sufficient to reign in all detrimental
                 side-effects. We evaluate using full reference runs of
                 the SPEC CPU2000 integer benchmarks and find that
                 atomic regions enable up to a 9\% (3\% on average)
                 improvement beyond the performance of a tuned
                 product.\par

                 These performance improvements are achieved without any
                 negative side effects. Performance side effects such as
                 code bloat are absent with atomic regions; in fact,
                 static code size is reduced. The hardware necessary is
                 synergistic with other needs and was already available
                 on the commercial product used in our evaluation.
                 Finally, the software complexity is minimal as a single
                 developer was able to incorporate atomic regions into a
                 sophisticated 300,000 line code base in three months,
                 despite never having seen the translator source code
                 beforehand.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "atomicity; checkpoint; dynamic translation;
                 optimization; speculation",
}

@Article{Harris:2010:DFM,
  author =       "Tim Harris and Sa{\v{s}}a Tomic and Adri{\'a}n Cristal
                 and Osman Unsal",
  title =        "Dynamic filtering: multi-purpose architecture support
                 for language runtime systems",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "39--52",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1735970.1736027",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "This paper introduces a new abstraction to accelerate
                 the read-barriers and write-barriers used by language
                 runtime systems. We exploit the fact that, dynamically,
                 many barrier executions perform checks but no real work
                 -- e.g., in generational garbage collection (GC),
                 frequent checks are needed to detect the creation of
                 inter-generational references, even though such
                 references occur rarely in many workloads. We introduce
                 a form of dynamic filtering that identifies redundant
                 checks by (i) recording checks that have recently been
                 executed, and (ii) detecting when a barrier is
                 repeating one of these checks. We show how this
                 technique can be applied to a variety of algorithms for
                 GC, transactional memory, and language-based security.
                 By supporting dynamic filtering in the instruction set,
                 we show that the fast-paths of these barriers can be
                 streamlined, reducing the impact on the quality of
                 surrounding code. We show how we accelerate the
                 barriers used for generational GC and transactional
                 memory in the Bartok research compiler. With a
                 2048-entry filter, dynamic filtering eliminates almost
                 all the overhead of the GC write-barriers. Dynamic
                 filtering eliminates around half the overhead of STM
                 over a non-synchronized baseline -- even when used with
                 an STM that is already designed for low overhead, and
                 which employs static analyses to avoid redundant
                 operations.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "garbage collection; runtime systems; transactional
                 memory",
}

@Article{Bergan:2010:CCR,
  author =       "Tom Bergan and Owen Anderson and Joseph Devietti and
                 Luis Ceze and Dan Grossman",
  title =        "{CoreDet}: a compiler and runtime system for
                 deterministic multithreaded execution",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "53--64",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1736020.1736029",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "The behavior of a multithreaded program does not
                 depend only on its inputs. Scheduling, memory
                 reordering, timing, and low-level hardware effects all
                 introduce nondeterminism in the execution of
                 multithreaded programs. This severely complicates many
                 tasks, including debugging, testing, and automatic
                 replication. In this work, we avoid these complications
                 by eliminating their root cause: we develop a compiler
                 and runtime system that runs arbitrary multithreaded
                 C/C++ POSIX Threads programs deterministically.\par

                 A trivial nonperformant approach to providing
                 determinism is simply deterministically serializing
                 execution. Instead, we present a compiler and runtime
                 infrastructure that ensures determinism but resorts to
                 serialization rarely, for handling interthread
                 communication and synchronization. We develop two basic
                 approaches, both of which are largely dynamic with
                 performance improved by some static compiler
                 optimizations. First, an ownership-based approach
                 detects interthread communication via an evolving table
                 that tracks ownership of memory regions by threads.
                 Second, a buffering approach uses versioned memory and
                 employs a deterministic commit protocol to make changes
                 visible to other threads. While buffering has larger
                 single-threaded overhead than ownership, it tends to
                 scale better (serializing less often). A hybrid system
                 sometimes performs and scales better than either
                 approach individually.\par

                 Our implementation is based on the LLVM compiler
                 infrastructure. It needs neither programmer annotations
                 nor special hardware. Our empirical evaluation uses the
                 PARSEC and SPLASH2 benchmarks and shows that our
                 approach scales comparably to nondeterministic
                 execution.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "compilers; determinism; multicore; multithreading",
}

@Article{Raman:2010:SPU,
  author =       "Arun Raman and Hanjun Kim and Thomas R. Mason and
                 Thomas B. Jablin and David I. August",
  title =        "Speculative parallelization using software
                 multi-threaded transactions",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "65--76",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1736020.1736030",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "With the right techniques, multicore architectures may
                 be able to continue the exponential performance trend
                 that elevated the performance of applications of all
                 types for decades. While many scientific programs can
                 be parallelized without speculative techniques,
                 speculative parallelism appears to be the key to
                 continuing this trend for general-purpose applications.
                 Recently-proposed code parallelization techniques, such
                 as those by Bridges et al. and by Thies et al.,
                 demonstrate scalable performance on multiple cores by
                 using speculation to divide code into atomic units
                 (transactions) that span multiple threads in order to
                 expose data parallelism. Unfortunately, most software
                 and hardware Thread-Level Speculation (TLS) memory
                 systems and transactional memories are not sufficient
                 because they only support single-threaded atomic units.
                 Multi-threaded Transactions (MTXs) address this
                 problem, but they require expensive hardware support as
                 currently proposed in the literature. This paper
                 proposes a Software MTX (SMTX) system that captures the
                 {\em applicability\/} and {\em performance\/} of
                 hardware MTX, but on {\em existing multicore machines}.
                 The SMTX system yields a harmonic mean speedup of
                 13.36x on native hardware with four 6-core processors
                 (24 cores in total) running speculatively parallelized
                 applications.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "automatic parallelization; loop-level parallelism;
                 multi-threaded transactions; pipelined parallelism;
                 software transactional memory; thread-level
                 speculation",
}

@Article{Lee:2010:REO,
  author =       "Dongyoon Lee and Benjamin Wester and Kaushik
                 Veeraraghavan and Satish Narayanasamy and Peter M. Chen
                 and Jason Flinn",
  title =        "{Respec}: efficient online multiprocessor replay via
                 speculation and external determinism",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "77--90",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1736020.1736031",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Deterministic replay systems record and reproduce the
                 execution of a hardware or software system. While it is
                 well known how to replay uniprocessor systems,
                 replaying shared memory multiprocessor systems at low
                 overhead on commodity hardware is still an open
                 problem. This paper presents Respec, a new way to
                 support deterministic replay of shared memory
                 multithreaded programs on commodity multiprocessor
                 hardware. Respec targets online replay in which the
                 recorded and replayed processes execute
                 concurrently.\par

                 Respec uses two strategies to reduce overhead while
                 still ensuring correctness: speculative logging and
                 externally deterministic replay. Speculative logging
                 optimistically logs less information about shared
                 memory dependencies than is needed to guarantee
                 deterministic replay, then recovers and retries if the
                 replayed process diverges from the recorded process.
                 Externally deterministic replay relaxes the degree to
                 which the two executions must match by requiring only
                 their system output and final program states match. We
                 show that the combination of these two techniques
                 results in low recording and replay overhead for the
                 common case of data-race-free execution intervals and
                 still ensures correct replay for execution intervals
                 that have data races.\par

                 We modified the Linux kernel to implement our
                 techniques. Our software system adds on average about
                 18\% overhead to the execution time for recording and
                 replaying programs with two threads and 55\% overhead
                 for programs with four threads.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "external determinism; replay; speculative execution",
}

@Article{Eyerman:2010:PJS,
  author =       "Stijn Eyerman and Lieven Eeckhout",
  title =        "Probabilistic job symbiosis modeling for {SMT}
                 processor scheduling",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "91--102",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1736020.1736033",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Symbiotic job scheduling boosts simultaneous
                 multithreading (SMT) processor performance by
                 co-scheduling jobs that have `compatible' demands on
                 the processor's shared resources. Existing approaches
                 however require a sampling phase, evaluate a limited
                 number of possible co-schedules, use heuristics to
                 gauge symbiosis, are rigid in their optimization
                 target, and do not preserve system-level
                 priorities/shares.\par

                 This paper proposes probabilistic job symbiosis
                 modeling, which predicts whether jobs will create
                 positive or negative symbiosis when co-scheduled
                 without requiring the co-schedule to be evaluated. The
                 model, which uses per-thread cycle stacks computed
                 through a previously proposed cycle accounting
                 architecture, is simple enough to be used in system
                 software. Probabilistic job symbiosis modeling provides
                 six key innovations over prior work in symbiotic job
                 scheduling: (i) it does not require a sampling phase,
                 (ii) it readjusts the job co-schedule continuously,
                 (iii) it evaluates a large number of possible
                 co-schedules at very low overhead, (iv) it is not
                 driven by heuristics, (v) it can optimize a performance
                 target of interest (e.g., system throughput or job
                 turnaround time), and (vi) it preserves system-level
                 priorities/shares. These innovations make symbiotic job
                 scheduling both practical and effective.\par

                 Our experimental evaluation, which assumes a realistic
                 scenario in which jobs come and go, reports an average
                 16\% (and up to 35\%) reduction in job turnaround time
                 compared to the previously proposed SOS (sample,
                 optimize, symbios) approach for a two-thread SMT
                 processor, and an average 19\% (and up to 45\%)
                 reduction in job turnaround time for a four-thread SMT
                 processor.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "performance modeling; simultaneous multi-threading
                 (SMT); symbiotic job scheduling",
}

@Article{Shen:2010:RBV,
  author =       "Kai Shen",
  title =        "Request behavior variations",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "103--116",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1736020.1736034",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "A large number of user requests execute (often
                 concurrently) within a server system. A single request
                 may exhibit fluctuating hardware characteristics (such
                 as instruction completion rate and on-chip resource
                 usage) over the course of its execution, due to
                 inherent variations in application execution semantics
                 as well as dynamic resource competition on
                 resource-sharing processors like multicores.
                 Understanding such behavior variations can assist
                 fine-grained request modeling and adaptive resource
                 management.\par

                 This paper presents operating system management to
                 track request behavior variations online. In addition
                 to metric sample collection during periodic interrupts,
                 we exploit the frequent system calls in server
                 applications to perform low-cost in-kernel sampling. We
                 utilize identified behavior variations to support or
                 enhance request modeling in request classification,
                 anomaly analysis, and online request signature
                 construction. A foundation of our request modeling is
                 the ability to quantify the difference between two
                 requests' time series behaviors. We evaluate several
                 differencing measures and enhance the classic dynamic
                 time warping technique with additional penalties for
                 asynchronous warp steps. Finally, motivated by
                 fluctuating request resource usage and the resulting
                 contention, we implement contention-easing CPU
                 scheduling on multicore platforms and demonstrate its
                 effectiveness in improving the worst-case request
                 performance.\par

                 Experiments in this paper are based on five server
                 applications -- Apache web server, TPCC, TPCH, RUBiS
                 online auction benchmark, and a user-content-driven
                 online teaching application called WeBWorK.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "hardware counter; multicore; operating system
                 adaptation; request modeling; server system",
}

@Article{Johnson:2010:DCM,
  author =       "F. Ryan Johnson and Radu Stoica and Anastasia Ailamaki
                 and Todd C. Mowry",
  title =        "Decoupling contention management from scheduling",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "117--128",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1736020.1736035",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Many parallel applications exhibit unpredictable
                 communication between threads, leading to contention
                 for shared objects. The choice of contention management
                 strategy impacts strongly the performance and
                 scalability of these applications: spinning provides
                 maximum performance but wastes significant processor
                 resources, while blocking-based approaches conserve
                 processor resources but introduce high overheads on the
                 critical path of computation. Under situations of high
                 or changing load, the operating system complicates
                 matters further with arbitrary scheduling decisions
                 which often preempt lock holders, leading to long
                 serialization delays until the preempted thread resumes
                 execution.\par

                 We observe that contention management is orthogonal to
                 the problems of scheduling and load management and
                 propose to decouple them so each may be solved
                 independently and effectively. To this end, we propose
                 a load control mechanism which manages the number of
                 active threads in the system separately from any
                 contention which may exist. By isolating contention
                 management from damaging interactions with the OS
                 scheduler, we combine the efficiency of spinning with
                 the robustness of blocking. The proposed load control
                 mechanism results in stable, high performance for both
                 lightly and heavily loaded systems, requires no special
                 privileges or modifications at the OS level, and can be
                 implemented as a library which benefits existing
                 code.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "blocking; concurrency control; contention; load
                 management; multicore; scheduling; spinning; threads",
}

@Article{Zhuravlev:2010:ASR,
  author =       "Sergey Zhuravlev and Sergey Blagodurov and Alexandra
                 Fedorova",
  title =        "Addressing shared resource contention in multicore
                 processors via scheduling",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "129--142",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1736020.1736036",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Contention for shared resources on multicore
                 processors remains an unsolved problem in existing
                 systems despite significant research efforts dedicated
                 to this problem in the past. Previous solutions focused
                 primarily on hardware techniques and software page
                 coloring to mitigate this problem. Our goal is to
                 investigate how and to what extent contention for
                 shared resource can be mitigated via thread scheduling.
                 Scheduling is an attractive tool, because it does not
                 require extra hardware and is relatively easy to
                 integrate into the system. Our study is the first to
                 provide a comprehensive analysis of
                 contention-mitigating techniques that use only
                 scheduling. The most difficult part of the problem is
                 to find a classification scheme for threads, which
                 would determine how they affect each other when
                 competing for shared resources. We provide a
                 comprehensive analysis of such classification schemes
                 using a newly proposed methodology that enables to
                 evaluate these schemes separately from the scheduling
                 algorithm itself and to compare them to the optimal. As
                 a result of this analysis we discovered a
                 classification scheme that addresses not only
                 contention for cache space, but contention for other
                 shared resources, such as the memory controller, memory
                 bus and prefetching hardware. To show the applicability
                 of our analysis we design a new scheduling algorithm,
                 which we prototype at user level, and demonstrate that
                 it performs within 2\\% of the optimal. We also
                 conclude that the highest impact of contention-aware
                 scheduling techniques is not in improving performance
                 of a workload as a whole but in improving quality of
                 service or performance isolation for individual
                 applications.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "multicore processors; scheduling; shared resource
                 contention",
}

@Article{Yuan:2010:SED,
  author =       "Ding Yuan and Haohui Mai and Weiwei Xiong and Lin Tan
                 and Yuanyuan Zhou and Shankar Pasupathy",
  title =        "{SherLog}: error diagnosis by connecting clues from
                 run-time logs",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "143--154",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1735970.1736038",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Computer systems often fail due to many factors such
                 as software bugs or administrator errors. Diagnosing
                 such production run failures is an important but
                 challenging task since it is difficult to reproduce
                 them in house due to various reasons: (1)
                 unavailability of users' inputs and file content due to
                 privacy concerns; (2) difficulty in building the exact
                 same execution environment; and (3) non-determinism of
                 concurrent executions on
                 multi-processors.\par

                 Therefore, programmers often have to diagnose a
                 production run failure based on logs collected back
                 from customers and the corresponding source code. Such
                 diagnosis requires expert knowledge and is also too
                 time-consuming, tedious to narrow down root causes. To
                 address this problem, we propose a tool, called
                 SherLog, that analyzes source code by leveraging
                 information provided by run-time logs to infer what
                 must or may have happened during the failed production
                 run. It requires neither re-execution of the program
                 nor knowledge on the log's semantics. It infers both
                 control and data value information regarding to the
                 failed execution.\par

                 We evaluate SherLog with 8 representative {\em real
                 world\/} software failures (6 software bugs and 2
                 configuration errors) from 7 applications including 3
                 servers. Information inferred by SherLog are very
                 useful for programmers to diagnose these evaluated
                 failures. Our results also show that SherLog can
                 analyze large server applications such as Apache with
                 thousands of logging messages within only 40 minutes.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "failure diagnostics; log; static analysis",
}

@Article{Weeratunge:2010:AMD,
  author =       "Dasarath Weeratunge and Xiangyu Zhang and Suresh
                 Jagannathan",
  title =        "Analyzing multicore dumps to facilitate concurrency
                 bug reproduction",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "155--166",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1735970.1736039",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Debugging concurrent programs is difficult. This is
                 primarily because the inherent non-determinism that
                 arises because of scheduler interleavings makes it hard
                 to easily reproduce bugs that may manifest only under
                 certain interleavings. The problem is exacerbated in
                 multi-core environments where there are multiple
                 schedulers, one for each core. In this paper, we
                 propose a reproduction technique for concurrent
                 programs that execute on multi-core platforms. Our
                 technique performs a lightweight analysis of a failing
                 execution that occurs in a multi-core environment, and
                 uses the result of the analysis to enable reproduction
                 of the bug in a single-core system, under the control
                 of a deterministic scheduler.\par

                 More specifically, our approach automatically
                 identifies the execution point in the re-execution that
                 corresponds to the failure point. It does so by
                 analyzing the failure core dump and leveraging a
                 technique called {\em execution indexing\/} that
                 identifies a related point in the re-execution. By
                 generating a core dump at this point, and comparing the
                 differences between the two dumps, we are able to guide
                 a search algorithm to efficiently generate a failure
                 inducing schedule. Our experiments show that our
                 technique is highly effective and has reasonable
                 overhead.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "concurrency bugs; execution indexing; multi-core;
                 reproduction",
}

@Article{Burckhardt:2010:RSP,
  author =       "Sebastian Burckhardt and Pravesh Kothari and Madanlal
                 Musuvathi and Santosh Nagarakatte",
  title =        "A randomized scheduler with probabilistic guarantees
                 of finding bugs",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "167--178",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1736020.1736040",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "This paper presents a randomized scheduler for finding
                 concurrency bugs. Like current stress-testing methods,
                 it repeatedly runs a given test program with supplied
                 inputs. However, it improves on stress-testing by
                 finding buggy schedules more effectively and by
                 quantifying the probability of missing concurrency
                 bugs. Key to its design is the characterization of the
                 depth of a concurrency bug as the minimum number of
                 scheduling constraints required to find it. In a single
                 run of a program with {\em n\/} threads and {\em k\/}
                 steps, our scheduler detects a concurrency bug of depth
                 {\em d\/} with probability at least 1/ {\em
                 nk\/}$^{d-1}$. We hypothesize that in practice, many
                 concurrency bugs (including well-known types such as
                 ordering errors, atomicity violations, and deadlocks)
                 have small bug-depths, and we confirm the efficiency of
                 our schedule randomization by detecting previously
                 unknown and known concurrency bugs in several
                 production-scale concurrent programs.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "concurrency; race conditions; randomized algorithms;
                 testing",
}

@Article{Zhang:2010:CDS,
  author =       "Wei Zhang and Chong Sun and Shan Lu",
  title =        "{ConMem}: detecting severe concurrency bugs through an
                 effect-oriented approach",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "179--192",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1735970.1736041",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Multicore technology is making concurrent programs
                 increasingly pervasive. Unfortunately, it is difficult
                 to deliver reliable concurrent programs, because of the
                 huge and non-deterministic interleaving space. In
                 reality, without the resources to thoroughly check the
                 interleaving space, critical concurrency bugs can slip
                 into production runs and cause failures in the field.
                 Approaches to making the best use of the limited
                 resources and exposing severe concurrency bugs before
                 software release would be desirable.\par

                 Unlike previous work that focuses on bugs caused by
                 specific interleavings (e.g., races and
                 atomicity-violations), this paper targets concurrency
                 bugs that result in one type of severe effects: program
                 crashes. Our study of the error-propagation process of
                 realworld concurrency bugs reveals a common pattern
                 (50\% in our non-deadlock concurrency bug set) that is
                 highly correlated with program crashes. We call this
                 pattern concurrency-memory bugs: buggy interleavings
                 directly cause memory bugs (NULL-pointer-dereference,
                 dangling-pointer, buffer-overflow, uninitialized-read)
                 on shared memory objects.\par

                 Guided by this study, we built ConMem to monitor
                 program execution, analyze memory accesses and
                 synchronizations, and predicatively detect these common
                 and severe concurrency-memory bugs. We also built a
                 validator ConMem-v to automatically prune false
                 positives by enforcing potential bug-triggering
                 interleavings.\par

                 We evaluated ConMem using 7 open-source programs with 9
                 real-world severe concurrency bugs. ConMem detects more
                 tested bugs (8 out of 9 bugs) than a lock-set-based
                 race detector and an unserializable-interleaving
                 detector that detect 4 and 5 bugs respectively, with a
                 false positive rate about one tenth of the compared
                 tools. ConMem-v further prunes out all the false
                 positives. ConMem has reasonable overhead suitable for
                 development usage.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "concurrency bugs; software testing",
}

@Article{Mesa-Martinez:2010:CPT,
  author =       "Francisco Javier Mesa-Martinez and Ehsan K. Ardestani
                 and Jose Renau",
  title =        "Characterizing processor thermal behavior",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "193--204",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1736020.1736043",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Temperature is a dominant factor in the performance,
                 reliability, and leakage power consumption of modern
                 processors. As a result, increasing numbers of
                 researchers evaluate thermal characteristics in their
                 proposals. In this paper, we measure a real processor
                 focusing on its thermal characterization executing
                 diverse workloads.\par

                 Our results show that in real designs, thermal
                 transients operate at larger scales than their
                 performance and power counterparts. Conventional
                 thermal simulation methodologies based on profile-based
                 simulation or statistical sampling, such as Simpoint,
                 tend to explore very limited execution spans. Short
                 simulation times can lead to reduced matchings between
                 performance and thermal phases. To illustrate these
                 issues we characterize and classify from a thermal
                 standpoint SPEC00 and SPEC06 applications, which are
                 traditionally used in the evaluation of architectural
                 proposals. This paper concludes with a list of
                 recommendations regarding thermal modeling
                 considerations based on our experimental insights.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "microarchitecture; temperature; thermal simulation",
}

@Article{Venkatesh:2010:CCR,
  author =       "Ganesh Venkatesh and Jack Sampson and Nathan Goulding
                 and Saturnino Garcia and Vladyslav Bryksin and Jose
                 Lugo-Martinez and Steven Swanson and Michael Bedford
                 Taylor",
  title =        "Conservation cores: reducing the energy of mature
                 computations",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "205--218",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1735970.1736044",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Growing transistor counts, limited power budgets, and
                 the breakdown of voltage scaling are currently
                 conspiring to create a {\em utilization wall\/} that
                 limits the fraction of a chip that can run at full
                 speed at one time. In this regime, specialized,
                 energy-efficient processors can increase parallelism by
                 reducing the per-computation power requirements and
                 allowing more computations to execute under the same
                 power budget. To pursue this goal, this paper
                 introduces {\em conservation cores}. Conservation
                 cores, or {\em c-cores}, are specialized processors
                 that focus on reducing energy and energy-delay instead
                 of increasing performance. This focus on energy makes
                 c-cores an excellent match for many applications that
                 would be poor candidates for hardware acceleration
                 (e.g., irregular integer codes). We present a toolchain
                 for automatically synthesizing c-cores from application
                 source code and demonstrate that they can significantly
                 reduce energy and energy-delay for a wide range of
                 applications. The c-cores support patching, a form of
                 targeted reconfigurability, that allows them to adapt
                 to new versions of the software they target. Our
                 results show that conservation cores can reduce energy
                 consumption by up to 16.0x for functions and by up to
                 2.1x for whole applications, while patching can extend
                 the useful lifetime of individual c-cores to match that
                 of conventional processors.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "conservation core; heterogeneous many-core; patching;
                 utilization wall",
}

@Article{Sudan:2010:MPI,
  author =       "Kshitij Sudan and Niladrish Chatterjee and David
                 Nellans and Manu Awasthi and Rajeev Balasubramonian and
                 Al Davis",
  title =        "Micro-pages: increasing {DRAM} efficiency with
                 locality-aware data placement",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "219--230",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1736020.1736045",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Power consumption and DRAM latencies are serious
                 concerns in modern chip-multiprocessor (CMP or
                 multi-core) based compute systems. The management of
                 the DRAM row buffer can significantly impact both power
                 consumption and latency. Modern DRAM systems read data
                 from cell arrays and populate a row buffer as large as
                 8 KB on a memory request. But only a small fraction of
                 these bits are ever returned back to the CPU. This ends
                 up wasting energy and time to read (and subsequently
                 write back) bits which are used rarely. Traditionally,
                 an open-page policy has been used for uni-processor
                 systems and it has worked well because of spatial and
                 temporal locality in the access stream. In future
                 multi-core processors, the possibly independent access
                 streams of each core are interleaved, thus destroying
                 the available locality and significantly
                 under-utilizing the contents of the row buffer. In this
                 work, we attempt to improve row-buffer utilization for
                 future multi-core systems.\par

                 The schemes presented here are motivated by our
                 observations that a large number of accesses within
                 heavily accessed OS pages are to small, contiguous
                 'chunks' of cache blocks. Thus, the co-location of
                 chunks (from different OS pages) in a row-buffer will
                 improve the overall utilization of the row buffer
                 contents, and consequently reduce memory energy
                 consumption and access time. Such co-location can be
                 achieved in many ways, notably involving a reduction in
                 OS page size and software or hardware assisted
                 migration of data within DRAM. We explore these
                 mechanisms and discuss the trade-offs involved along
                 with energy and performance improvements from each
                 scheme. On average, for applications with room for
                 improvement, our best performing scheme increases
                 performance by 9\% (max. 18\%) and reduces memory
                 energy consumption by 15\% (max. 70\%).",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "data placement; dram row-buffer management",
}

@Article{Pelley:2010:PRD,
  author =       "Steven Pelley and David Meisner and Pooya Zandevakili
                 and Thomas F. Wenisch and Jack Underwood",
  title =        "Power routing: dynamic power provisioning in the data
                 center",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "231--242",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1735971.1736047",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Data center power infrastructure incurs massive
                 capital costs, which typically exceed energy costs over
                 the life of the facility. To squeeze maximum value from
                 the infrastructure, researchers have proposed
                 over-subscribing power circuits, relying on the
                 observation that peak loads are rare. To ensure
                 availability, these proposals employ power capping,
                 which throttles server performance during utilization
                 spikes to enforce safe power budgets. However, because
                 budgets must be enforced locally -- at each power
                 distribution unit (PDU) -- local utilization spikes may
                 force throttling even when power delivery capacity is
                 available elsewhere. Moreover, the need to maintain
                 reserve capacity for fault tolerance on power delivery
                 paths magnifies the impact of utilization
                 spikes.\par

                 In this paper, we develop mechanisms to better utilize
                 installed power infrastructure, reducing reserve
                 capacity margins and avoiding performance throttling.
                 Unlike conventional high-availability data centers,
                 where collocated servers share identical primary and
                 secondary power feeds, we reorganize power feeds to
                 create shuffled power distribution topologies. Shuffled
                 topologies spread secondary power feeds over numerous
                 PDUs, reducing reserve capacity requirements to
                 tolerate a single PDU failure. Second, we propose Power
                 Routing, which schedules IT load dynamically across
                 redundant power feeds to: (1) shift slack to servers
                 with growing power demands, and (2) balance power draw
                 across AC phases to reduce heating and improve
                 electrical stability. We describe efficient heuristics
                 for scheduling servers to PDUs (an NP-complete
                 problem). Using data collected from nearly 1000 servers
                 in three production facilities, we demonstrate that
                 these mechanisms can reduce the required power
                 infrastructure capacity relative to conventional
                 high-availability data centers by 32\% without
                 performance degradation.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "data centers; power infrastructure",
}

@Article{Ahmad:2010:JOI,
  author =       "Faraz Ahmad and T. N. Vijaykumar",
  title =        "Joint optimization of idle and cooling power in data
                 centers while maintaining response time",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "243--256",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1735971.1736048",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Server power and cooling power amount to a significant
                 fraction of modern data centers' recurring costs. While
                 data centers provision enough servers to guarantee
                 response times under the maximum loading, data centers
                 operate under much less loading most of the times
                 (e.g., 30-70\% of the maximum loading). Previous
                 server-power proposals exploit this under-utilization
                 to reduce the server idle power by keeping active only
                 as many servers as necessary and putting the rest into
                 low-power standby modes. However, these proposals incur
                 higher cooling power due to hot spots created by
                 concentrating the data center loading on fewer active
                 servers, or degrade response times due to
                 standby-to-active transition delays, or both. Other
                 proposals optimize the cooling power but incur
                 considerable idle power. To address the first issue of
                 power, we propose {\em PowerTrade}, which trades-off
                 idle power and cooling power for each other, thereby
                 reducing the total power. To address the second issue
                 of response time, we propose {\em SurgeGuard\/} to
                 overprovision the number of active servers beyond that
                 needed by the current loading so as to absorb future
                 increases in the loading. SurgeGuard is a two-tier
                 scheme which uses well-known over-provisioning at
                 coarse time granularities (e.g., one hour) to absorb
                 the common, smooth increases in the loading, and a
                 novel fine-grain replenishment of the over-provisioned
                 reserves at fine time granularities (e.g., five
                 minutes) to handle the uncommon, abrupt loading surges.
                 Using real-world traces, we show that combining
                 PowerTrade and SurgeGuard reduces total power by 30\%
                 compared to previous low-power schemes while
                 maintaining response times within 1.7\%.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "cooling power; data center; idle power; power
                 management; response time",
}

@Article{Goodstein:2010:BAA,
  author =       "Michelle L. Goodstein and Evangelos Vlachos and Shimin
                 Chen and Phillip B. Gibbons and Michael A. Kozuch and
                 Todd C. Mowry",
  title =        "Butterfly analysis: adapting dataflow analysis to
                 dynamic parallel monitoring",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "257--270",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1735971.1736050",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Online program monitoring is an effective technique
                 for detecting bugs and security attacks in running
                 applications. Extending these tools to monitor parallel
                 programs is challenging because the tools must account
                 for inter-thread dependences and relaxed memory
                 consistency models. Existing tools assume sequential
                 consistency and often slow down the monitored program
                 by orders of magnitude. In this paper, we present a
                 novel approach that avoids these pitfalls by not
                 relying on strong consistency models or detailed
                 inter-thread dependence tracking. Instead, we only
                 assume that events in the distant past on all threads
                 have become visible; we make no assumptions on (and
                 avoid the overheads of tracking) the relative ordering
                 of more recent events on other threads. To overcome the
                 potential state explosion of considering all the
                 possible orderings among recent events, we adapt two
                 techniques from static dataflow analysis, reaching
                 definitions and reaching expressions, to this new
                 domain of dynamic parallel monitoring. Significant
                 modifications to these techniques are proposed to
                 ensure the correctness and efficiency of our approach.
                 We show how our adapted analysis can be used in two
                 popular memory and security tools. We prove that our
                 approach does not miss errors, and sacrifices precision
                 only due to the lack of a relative ordering among
                 recent events. Moreover, our simulation study on a
                 collection of Splash-2 and Parsec 2.0 benchmarks
                 running a memory-checking tool on a hardware-assisted
                 logging platform demonstrates the potential benefits in
                 trading off a very low false positive rate for (i)
                 reduced overhead and (ii) the ability to run on relaxed
                 consistency models.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "data flow analysis; dynamic program monitoring;
                 parallel programming; static analysis",
}

@Article{Vlachos:2010:PEA,
  author =       "Evangelos Vlachos and Michelle L. Goodstein and
                 Michael A. Kozuch and Shimin Chen and Babak Falsafi and
                 Phillip B. Gibbons and Todd C. Mowry",
  title =        "{ParaLog}: enabling and accelerating online parallel
                 monitoring of multithreaded applications",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "271--284",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1736020.1736051",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "{\em Instruction-grain lifeguards\/} monitor the
                 events of a running application at the level of
                 individual instructions in order to identify and help
                 mitigate application bugs and security exploits.
                 Because such lifeguards impose a 10-100X slowdown on
                 existing platforms, previous studies have proposed
                 hardware designs to accelerate lifeguard processing.
                 However, these accelerators are either tailored to a
                 specific class of lifeguards or suitable only for
                 monitoring single-threaded programs.\par

                 We present ParaLog, the first design of a system
                 enabling fast online parallel monitoring of
                 multithreaded parallel applications. ParaLog supports a
                 broad class of software-defined lifeguards. We show how
                 three existing accelerators can be enhanced to support
                 online multithreaded monitoring, dramatically reducing
                 lifeguard overheads. We identify and solve several
                 challenges in monitoring parallel applications and/or
                 parallelizing these accelerators, including (i)
                 enforcing inter-thread data dependences, (ii) dealing
                 with inter-thread effects that are not reflected in
                 coherence traffic, (iii) dealing with unmonitored
                 operating system activity, and (iv) ensuring lifeguards
                 can access shared metadata with negligible
                 synchronization overheads. We present our system design
                 for both Sequentially Consistent and Total Store
                 Ordering processors. We implement and evaluate our
                 design on a 16 core simulated CMP, using benchmarks
                 from SPLASH-2 and PARSEC and two lifeguards: a
                 data-flow tracking lifeguard and a memory-access
                 checker lifeguard. Our results show that (i) our
                 parallel accelerators improve performance by 2-9X and
                 1.13-3.4X for our two lifeguards, respectively, (ii) we
                 are 5-126X faster than the time-slicing approach
                 required by existing techniques, and (iii) our average
                 overheads for applications with eight threads are 51\%
                 and 28\% for the two lifeguards, respectively.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "hardware support for debugging; instruction-grain
                 lifeguards; online parallel monitoring",
}

@Article{Hormati:2010:MMS,
  author =       "Amir H. Hormati and Yoonseo Choi and Mark Woh and
                 Manjunath Kudlur and Rodric Rabbah and Trevor Mudge and
                 Scott Mahlke",
  title =        "{MacroSS}: macro-{SIMD}ization of streaming
                 applications",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "285--296",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1736020.1736053",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "SIMD (Single Instruction, Multiple Data) engines are
                 an essential part of the processors in various
                 computing markets, from servers to the embedded domain.
                 Although SIMD-enabled architectures have the capability
                 of boosting the performance of many application domains
                 by exploiting data-level parallelism, it is very
                 challenging for compilers and also programmers to
                 identify and transform parts of a program that will
                 benefit from a particular SIMD engine. The focus of
                 this paper is on the problem of SIMDization for the
                 growing application domain of streaming. Streaming
                 applications are an ideal solution for targeting
                 multi-core architectures, such as shared/distributed
                 memory systems, tiled architectures, and single-core
                 systems. Since these architectures, in most cases,
                 provide SIMD acceleration units as well, it is highly
                 beneficial to generate SIMD code from streaming
                 programs. Specifically, we introduce MacroSS, which is
                 capable of performing macro-SIMDization on high-level
                 streaming graphs. Macro-SIMDization uses high-level
                 information such as execution rates of actors and
                 communication patterns between them to transform the
                 graph structure, vectorize actors of a streaming
                 program, and generate intermediate code. We also
                 propose low-overhead architectural modifications that
                 accelerate shuffling of data elements between the
                 scalar and vectorized parts of a streaming program. Our
                 experiments show that MacroSS is capable of generating
                 code that, on average, outperforms scalar code compiled
                 with the current state-of-art auto-vectorizing
                 compilers by 54\%. Using the low-overhead data
                 shuffling hardware, performance is improved by an
                 additional 8\% with less than 1\% area overhead.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "compiler; optimization; SIMD architecture; streaming",
}

@Article{Woo:2010:CPD,
  author =       "Dong Hyuk Woo and Hsien-Hsin S. Lee",
  title =        "{COMPASS}: a programmable data prefetcher using idle
                 {GPU} shaders",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "297--310",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1735971.1736054",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "A traditional fixed-function graphics accelerator has
                 evolved into a programmable general-purpose graphics
                 processing unit over the last few years. These powerful
                 computing cores are mainly used for accelerating
                 graphics applications or enabling low-cost scientific
                 computing. To further reduce the cost and form factor,
                 an emerging trend is to integrate GPU along with the
                 memory controllers onto the same die with the processor
                 cores. However, given such a system-on-chip, the GPU,
                 while occupying a substantial part of the silicon, will
                 sit idle and contribute nothing to the overall system
                 performance when running non-graphics workloads or
                 applications lack of data-level parallelism. In this
                 paper, we propose COMPASS, a compute shader-assisted
                 data prefetching scheme, to leverage the GPU resource
                 for improving single-threaded performance on an
                 integrated system. By harnessing the GPU shader cores
                 with very lightweight architectural support, COMPASS
                 can emulate the functionality of a hardware-based
                 prefetcher using the idle GPU and successfully improve
                 the memory performance of single-thread applications.
                 Moreover, thanks to its flexibility and
                 programmability, one can implement the best performing
                 prefetch scheme to improve each specific application as
                 demonstrated in this paper. With COMPASS, we envision
                 that a future application vendor can provide a
                 custom-designed COMPASS shader bundled with its
                 software to be loaded at runtime to optimize the
                 performance. Our simulation results show that COMPASS
                 can improve the single-thread performance of
                 memory-intensive applications by 68\% on average.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "compute shader; GPU; prefetch",
}

@Article{Sanchez:2010:FAS,
  author =       "Daniel Sanchez and Richard M. Yoo and Christos
                 Kozyrakis",
  title =        "Flexible architectural support for fine-grain
                 scheduling",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "311--322",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1736020.1736055",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "To make efficient use of CMPs with tens to hundreds of
                 cores, it is often necessary to exploit fine-grain
                 parallelism. However, managing tasks of a few thousand
                 instructions is particularly challenging, as the
                 runtime must ensure load balance without compromising
                 locality and introducing small overheads. Software-only
                 schedulers can implement various scheduling algorithms
                 that match the characteristics of different
                 applications and programming models, but suffer
                 significant overheads as they synchronize and
                 communicate task information over the deep cache
                 hierarchy of a large-scale CMP. To reduce these costs,
                 hardware-only schedulers like Carbon, which implement
                 task queuing and scheduling in hardware, have been
                 proposed. However, a hardware-only solution fixes the
                 scheduling algorithm and leaves no room for other uses
                 of the custom hardware.\par

                 This paper presents a combined hardware-software
                 approach to build fine-grain schedulers that retain the
                 flexibility of software schedulers while being as fast
                 and scalable as hardware ones. We propose asynchronous
                 direct messages (ADM), a simple architectural extension
                 that provides direct exchange of asynchronous, short
                 messages between threads in the CMP without going
                 through the memory hierarchy. ADM is sufficient to
                 implement a family of novel, software-mostly schedulers
                 that rely on low-overhead messaging to efficiently
                 coordinate scheduling and transfer task information.
                 These schedulers match and often exceed the performance
                 and scalability of Carbon when using the same
                 scheduling algorithm. When the ADM runtime tailors its
                 scheduling algorithm to application characteristics, it
                 outperforms Carbon by up to 70\%.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "chip-multiprocessors; fine-grain scheduling;
                 many-core; messaging; scheduling; work-stealing",
}

@Article{Romanescu:2010:SDV,
  author =       "Bogdan F. Romanescu and Alvin R. Lebeck and Daniel J.
                 Sorin",
  title =        "Specifying and dynamically verifying address
                 translation-aware memory consistency",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "323--334",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1735970.1736057",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Computer systems with virtual memory are susceptible
                 to design bugs and runtime faults in their address
                 translation (AT) systems. Detecting bugs and faults
                 requires a clear specification of correct behavior. To
                 address this need, we develop a framework for AT-aware
                 memory consistency models. We expand and divide memory
                 consistency into the physical address memory
                 consistency (PAMC) model that defines the behavior of
                 operations on physical addresses and the virtual
                 address memory consistency (VAMC) model that defines
                 the behavior of operations on virtual addresses. As
                 part of this expansion, we show what AT features are
                 required to bridge the gap between PAMC and VAMC. Based
                 on our AT-aware memory consistency specifications, we
                 design efficient dynamic verification hardware that can
                 detect violations of VAMC and thus detect the effects
                 of design bugs and runtime faults, including most AT
                 related bugs in published errata.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "address translation; dynamic verification; memory
                 consistency; virtual memory",
}

@Article{Ebrahimi:2010:FST,
  author =       "Eiman Ebrahimi and Chang Joo Lee and Onur Mutlu and
                 Yale N. Patt",
  title =        "Fairness via source throttling: a configurable and
                 high-performance fairness substrate for multi-core
                 memory systems",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "335--346",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1736020.1736058",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Cores in a chip-multiprocessor (CMP) system share
                 multiple hardware resources in the memory subsystem. If
                 resource sharing is unfair, some applications can be
                 delayed significantly while others are unfairly
                 prioritized. Previous research proposed separate
                 fairness mechanisms in each individual resource. Such
                 resource-based fairness mechanisms implemented
                 independently in each resource can make contradictory
                 decisions, leading to low fairness and loss of
                 performance. Therefore, a coordinated mechanism that
                 provides fairness in the entire shared memory system is
                 desirable.\par

                 This paper proposes a new approach that provides
                 fairness in the {\em entire shared memory system},
                 thereby eliminating the need for and complexity of
                 developing fairness mechanisms for each individual
                 resource. Our technique, Fairness via Source Throttling
                 (FST), estimates the unfairness in the entire shared
                 memory system. If the estimated unfairness is above a
                 threshold set by system software, FST throttles down
                 cores causing unfairness by limiting the number of
                 requests they can inject into the system and the
                 frequency at which they do. As such, our {\em
                 source-based\/} fairness control ensures fairness
                 decisions are made in tandem in the entire memory
                 system. FST also enforces thread priorities/weights,
                 and enables system software to enforce different
                 fairness objectives and fairness-performance tradeoffs
                 in the memory system.\par

                 Our evaluations show that FST provides the best system
                 fairness and performance compared to four systems with
                 no fairness control and with state-of-the-art fairness
                 mechanisms implemented in both shared caches and memory
                 controllers.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "fairness; multi-core systems; shared memory systems;
                 system performance",
}

@Article{Gelado:2010:ADS,
  author =       "Isaac Gelado and Javier Cabezas and Nacho Navarro and
                 John E. Stone and Sanjay Patel and Wen-mei W. Hwu",
  title =        "An asymmetric distributed shared memory model for
                 heterogeneous parallel systems",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "347--358",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1735970.1736059",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Heterogeneous computing combines general purpose CPUs
                 with accelerators to efficiently execute both
                 sequential control-intensive and data-parallel phases
                 of applications. Existing programming models for
                 heterogeneous computing rely on programmers to
                 explicitly manage data transfers between the CPU system
                 memory and accelerator memory.\par

                 This paper presents a new programming model for
                 heterogeneous computing, called Asymmetric Distributed
                 Shared Memory (ADSM), that maintains a shared logical
                 memory space for CPUs to access objects in the
                 accelerator physical memory but not vice versa. The
                 asymmetry allows light-weight implementations that
                 avoid common pitfalls of symmetrical distributed shared
                 memory systems. ADSM allows programmers to assign data
                 objects to performance critical methods. When a method
                 is selected for accelerator execution, its associated
                 data objects are allocated within the shared logical
                 memory space, which is hosted in the accelerator
                 physical memory and transparently accessible by the
                 methods executed on CPUs.\par

                 We argue that ADSM reduces programming efforts for
                 heterogeneous computing systems and enhances
                 application portability. We present a software
                 implementation of ADSM, called GMAC, on top of CUDA in
                 a GNU/Linux environment. We show that applications
                 written in ADSM and running on top of GMAC achieve
                 performance comparable to their counterparts using
                 programmer-managed data transfers. This paper presents
                 the GMAC system and evaluates different design choices.
                 We further suggest additional architectural support
                 that will likely allow GMAC to achieve higher
                 application performance than the current CUDA model.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "asymmetric distributed shared memory; data-centric
                 programming models; heterogeneous systems",
}

@Article{Bhattacharjee:2010:ICC,
  author =       "Abhishek Bhattacharjee and Margaret Martonosi",
  title =        "Inter-core cooperative {TLB} for chip
                 multiprocessors",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "359--370",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1735970.1736060",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Translation Lookaside Buffers (TLBs) are commonly
                 employed in modern processor designs and have
                 considerable impact on overall system performance. A
                 number of past works have studied TLB designs to lower
                 access times and miss rates, specifically for
                 uniprocessors. With the growing dominance of chip
                 multiprocessors (CMPs), it is necessary to examine TLB
                 performance in the context of parallel
                 workloads.\par

                 This work is the first to present TLB prefetchers that
                 exploit commonality in TLB miss patterns across cores
                 in CMPs. We propose and evaluate two Inter-Core
                 Cooperative (ICC) TLB prefetching mechanisms, assessing
                 their effectiveness at eliminating TLB misses both
                 individually and together. Our results show these
                 approaches require at most modest hardware and can
                 collectively eliminate 19\% to 90\% of data TLB (D-TLB)
                 misses across the surveyed parallel workloads.\par

                 We also compare performance improvements across a range
                 of hardware and software implementation possibilities.
                 We find that while a fully-hardware implementation
                 results in average performance improvements of 8-46\%
                 for a range of TLB sizes, a hardware/software approach
                 yields improvements of 4-32\%. Overall, our work shows
                 that TLB prefetchers exploiting inter-core correlations
                 can effectively eliminate TLB misses.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "parallelism; prefetching; translation lookaside
                 buffer",
}

@Article{Huang:2010:OES,
  author =       "Ruirui Huang and Daniel Y. Deng and G. Edward Suh",
  title =        "{Orthrus}: efficient software integrity protection on
                 multi-cores",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "371--384",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1736020.1736062",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "This paper proposes an efficient hardware/software
                 system that significantly enhances software security
                 through diversified replication on multi-cores. Recent
                 studies show that a large class of software attacks can
                 be detected by running multiple versions of a program
                 simultaneously and checking the consistency of their
                 behaviors. However, execution of multiple replicas
                 incurs significant overheads on today's computing
                 platforms, especially with fine-grained comparisons
                 necessary for high security. Orthrus exploits
                 similarities in automatically generated replicas to
                 enable simultaneous execution of those replicas with
                 minimal overheads; the architecture reduces memory and
                 bandwidth overheads by compressing multiple memory
                 spaces together, and additional power consumption and
                 silicon area by eliminating redundant computations.
                 Utilizing the hardware architecture, Orthrus implements
                 a fine-grained memory layout diversification with the
                 LLVM compiler and can detect corruptions in both
                 pointers and critical data. Experiments indicate that
                 the Orthrus architecture incurs minimal overheads and
                 provides a protection against a broad range of
                 attacks.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "memory protection; multi-core architecture;
                 replication-aware architecture; software diversity and
                 redundancy; software security",
}

@Article{Feng:2010:SPS,
  author =       "Shuguang Feng and Shantanu Gupta and Amin Ansari and
                 Scott Mahlke",
  title =        "Shoestring: probabilistic soft error reliability on
                 the cheap",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "385--396",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1736020.1736063",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Aggressive technology scaling provides designers with
                 an ever increasing budget of cheaper and faster
                 transistors. Unfortunately, this trend is accompanied
                 by a decline in individual device reliability as
                 transistors become increasingly susceptible to soft
                 errors. We are quickly approaching a new era where
                 resilience to soft errors is no longer a luxury that
                 can be reserved for just processors in
                 high-reliability, mission-critical domains. Even
                 processors used in mainstream computing will soon
                 require protection. However, due to tighter profit
                 margins, reliable operation for these devices must come
                 at little or no cost. This paper presents Shoestring, a
                 minimally invasive software solution that provides high
                 soft error coverage with very little overhead, enabling
                 its deployment even in commodity processors with
                 'shoestring' reliability budgets. Leveraging
                 intelligent analysis at compile time, and exploiting
                 low-cost, symptom-based error detection, Shoestring is
                 able to focus its efforts on protecting
                 statistically-vulnerable portions of program code.
                 Shoestring effectively applies instruction duplication
                 to protect only those segments of code that, when
                 subjected to a soft error, are likely to result in
                 user-visible faults without first exhibiting
                 symptomatic behavior. Shoestring is able to recover
                 from an additional 33.9\% of soft errors that are
                 undetected by a symptom-only approach, achieving an
                 overall user-visible failure rate of 1.6\%. This
                 reliability improvement comes at a modest performance
                 overhead of 15.8\%.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "compiler analysis; error detection; fault injection",
}

@Article{Yoon:2010:VFE,
  author =       "Doe Hyun Yoon and Mattan Erez",
  title =        "Virtualized and flexible {ECC} for main memory",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "3",
  pages =        "397--408",
  month =        mar,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1736020.1736064",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Mar 17 13:46:56 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "We present a general scheme for virtualizing main
                 memory error-correction mechanisms, which map redundant
                 information needed to correct errors into the memory
                 namespace itself. We rely on this basic idea, which
                 increases flexibility to increase error protection
                 capabilities, improve power efficiency, and reduce
                 system cost; with only small performance overheads. We
                 augment the virtual memory system architecture to
                 detach the physical mapping of data from the physical
                 mapping of its associated ECC information. We then use
                 this mechanism to develop two-tiered error protection
                 techniques that separate the process of detecting
                 errors from the rare need to also correct errors, and
                 thus save energy. We describe how to provide strong
                 chipkill and double-chip kill protection using existing
                 DRAM and packaging technology. We show how to maintain
                 access granularity and redundancy overheads, even when
                 using $\times 8$ DRAM chips. We also evaluate error
                 correction for systems that do not use ECC DIMMs.
                 Overall, analysis of demanding SPEC CPU 2006 and PARSEC
                 benchmarks indicates that performance overhead is only
                 1\% with ECC DIMMs and less than 10\% using standard
                 Non-ECC DIMM configurations, that DRAM power savings
                 can be as high as 27\%, and that the system
                 energy-delay product is improved by 12\% on average.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "error correction; fault tolerance; memory systems;
                 reliability",
}

@Article{Li:2010:AAB,
  author =       "Minming Li and Chun Jason Xue and Tiantian Liu and
                 Yingchao Zhao",
  title =        "Analysis and approximation for bank selection
                 instruction minimization on partitioned memory
                 architecture",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "4",
  pages =        "1--8",
  month =        apr,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1755888.1755890",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Apr 15 12:45:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "A large number of embedded systems include 8-bit
                 microcontrollers for their energy efficiency and low
                 cost. Multi-bank memory architecture is commonly
                 applied in 8-bit microcontrollers to increase the size
                 of memory without extending address buses. To switch
                 among different memory banks, a special instruction,
                 Bank Selection, is used. How to minimize the number of
                 bank selection instructions inserted is important to
                 reduce code size for embedded systems.\par

                 In this paper, we consider how to insert the minimum
                 number of bank selection instructions in a program to
                 achieve feasibility. A program can be represented by a
                 control flow graph (CFG). We prove that it is NP-Hard
                 to insert the minimum number of bank selection
                 instructions if all the variables are pre-assigned to
                 memory banks. Therefore, we introduce a 2-approximation
                 algorithm using a rounding method. When the CFG is a
                 tree or the out-degree of each node in the CFG is at
                 most two, we show that we can insert the bank selection
                 instructions optimally in polynomial time. We then
                 consider the case when there are some nodes that do not
                 access any memory bank and design a dynamic programming
                 method to compute the optimal insertion strategy when
                 the CFG is a tree. Experimental result shows the
                 proposed techniques can reduce bank selection
                 instructions significantly on partitioned memory
                 architecture.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "bank selection instruction minimization; partitioned
                 memory architecture",
}

@Article{Pyka:2010:VSL,
  author =       "Robert Pyka and Felipe Klein and Peter Marwedel and
                 Stylianos Mamagkakis",
  title =        "Versatile system-level memory-aware platform
                 description approach for embedded {MPSoCs}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "4",
  pages =        "9--16",
  month =        apr,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1755888.1755891",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Apr 15 12:45:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "In this paper, we present a novel system modeling
                 language which targets primarily the development of
                 source-level multiprocessor memory aware
                 optimizations.\par

                 In contrast to previous system modeling approaches this
                 approach tries to model the whole system and especially
                 the memory hierarchy in a structural and semantically
                 accessible way. Previous approaches primarily support
                 generation of simulators or retargetable code selectors
                 and thus concentrate on pure behavioral models or
                 describe only the processor instruction set in a
                 semantically accessible way, A simple, database-like,
                 interface is offered to the optimization developer,
                 which in conjunction with the MACCv2 framework enables
                 rapid development of source-level architecture
                 independent optimizations.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "architecture description; channel; component;
                 configuration; definition; energy models; framework",
}

@Article{Kim:2010:ODM,
  author =       "Yongjoo Kim and Jongeun Lee and Aviral Shrivastava and
                 Yunheung Paek",
  title =        "Operation and data mapping for {CGRAs} with multi-bank
                 memory",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "4",
  pages =        "17--26",
  month =        apr,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1755951.1755892",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Apr 15 12:45:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Coarse Grain Reconfigurable Architectures (CGRAs)
                 promise high performance at high power efficiency. They
                 fulfill this promise by keeping the hardware extremely
                 simple, and moving the complexity to application
                 mapping. One major challenge comes in the form of data
                 mapping. For reasons of power-efficiency and
                 complexity, CGRAs use multi-bank local memory, and a
                 row of PEs share memory access. In order for each row
                 of the PEs to access any memory bank, there is a
                 hardware arbiter between the memory requests generated
                 by the PEs and the banks of the local memory. However,
                 a fundamental restriction remains that a bank cannot be
                 accessed by two different PEs at the same time. We
                 propose to meet this challenge by mapping application
                 operations onto PEs and data into memory banks in a way
                 that avoids such conflicts. Our experimental results on
                 kernels from multimedia benchmarks demonstrate that our
                 local memory-aware compilation approach can generate
                 mappings that are up to 40\% better in performance
                 (17.3\% on average) compared to a memory-unaware
                 scheduler.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "arbiter; bank conflict; coarse-grained reconfigurable
                 architecture; compilation; multi-bank memory",
}

@Article{Foroozannejad:2010:LDB,
  author =       "Mohammad H. Foroozannejad and Matin Hashemi and Trevor
                 L. Hodges and Soheil Ghiasi",
  title =        "Look into details: the benefits of fine-grain
                 streaming buffer analysis",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "4",
  pages =        "27--36",
  month =        apr,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1755951.1755894",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Apr 15 12:45:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Many embedded applications demand processing of a
                 seemingly endless stream of input data in real-time.
                 Productive development of such applications is
                 typically carried out by synthesizing software from
                 high-level specifications, such as data-flow graphs. In
                 this context, we study the problem of inter-actor
                 buffer allocation, which is a critical step during
                 compilation of streaming applications. We argue that
                 fine-grain analysis of buffers' spatio-temporal
                 characteristics, as opposed to conventional live range
                 analysis, enables dramatic improvements in buffer
                 sharing. Improved sharing translates to reduction of
                 the compiled binary memory footprint, which is of prime
                 concern in many embedded systems. We transform the
                 buffer allocation problem to two-dimensional packing
                 using complex polygons. We develop an evolutionary
                 packing algorithm, which readily yields buffer
                 allocations. Experimental results show an average of
                 over 7X and 2X improvement in total buffer size,
                 compared to baseline and conventional live range
                 analysis schemes, respectively.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "buffer management; optimization; software synthesis;
                 streaming applications; synchronous data flow",
}

@Article{Perathoner:2010:MSE,
  author =       "Simon Perathoner and Tobias Rein and Lothar Thiele and
                 Kai Lampka and Jonas Rox",
  title =        "Modeling structured event streams in system level
                 performance analysis",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "4",
  pages =        "37--46",
  month =        apr,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1755951.1755895",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Apr 15 12:45:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "This paper extends the methodology of analytic
                 real-time analysis of distributed embedded systems
                 towards merging and extracting sub-streams based on
                 event type information. For example, one may first
                 merge a set of given event streams, then process them
                 jointly and finally decompose them into separate
                 streams again. In other words, data streams can be
                 hierarchically composed into higher level event streams
                 and decomposed later on again. The proposed technique
                 is strictly compositional, hence highly suited for
                 being embedded into well known performance evaluation
                 frameworks such as Symta/S and MPA (Modular Performance
                 Analysis). It is based on a novel characterization of
                 structured event streams which we denote as Event Count
                 Curves. They characterize the structure of event
                 streams in which the individual events belong to a
                 finite number of classes. This new concept avoids the
                 explicit maintenance of stream-individual information
                 when routing a composed stream through a network of
                 system components. Nevertheless it allows an arbitrary
                 composition and decomposition of sub-streams at any
                 stage of the distributed event processing. For
                 evaluating our approach we analyze a realistic
                 case-study and compare the obtained results with other
                 existing techniques.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "event count curves; performance analysis; real-time
                 calculus",
}

@Article{Brandt:2010:TCA,
  author =       "Jens Brandt and Klaus Schneider and Sandeep K.
                 Shukla",
  title =        "Translating concurrent action oriented specifications
                 to synchronous guarded actions",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "4",
  pages =        "47--56",
  month =        apr,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1755888.1755896",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Apr 15 12:45:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Concurrent Action-Oriented Specifications (CAOS) model
                 the behavior of a synchronous hardware circuit as
                 asynchronous guarded actions at an abstraction level
                 higher than the Register Transfer Level (RTL). Previous
                 approaches always considered the compilation of CAOS,
                 which includes a transformation of the under-lying
                 model of computation and the scheduling of guarded
                 actions per clock cycle, as a tightly integrated step.
                 In this paper, we present a new compilation procedure,
                 which separates these two tasks and translates CAOS
                 models to synchronous guarded actions with an explicit
                 interface to a scheduler. This separation of concerns
                 has many advantages, including better analyses and
                 integration of custom schedulers. Our method also
                 generates assertions that each scheduler must obey that
                 can be fulfilled by algorithms for scheduler synthesis
                 like those developed in supervisory control. We present
                 our translation procedure in detail and illustrate it
                 by various examples. We also show that our method
                 simplifies formal verification of hardware synthesized
                 from CAOS specifications over previously known formal
                 verification approaches.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "code generation; concurrent action-oriented
                 specifications; guarded commands; synchronous
                 languages",
}

@Article{Delaval:2010:CMD,
  author =       "Gwena{\"e}l Delaval and Herv{\'e} Marchand and Eric
                 Rutten",
  title =        "Contracts for modular discrete controller synthesis",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "4",
  pages =        "57--66",
  month =        apr,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1755951.1755898",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Apr 15 12:45:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "We describe the extension of a reactive programming
                 language with a behavioral contract construct. It is
                 dedicated to the programming of reactive control of
                 applications in embedded systems, and involves
                 principles of the supervisory control of discrete event
                 systems. Our contribution is in a language approach
                 where modular discrete controller synthesis (DCS) is
                 integrated, and it is concretized in the encapsulation
                 of DCS into a compilation process. From transition
                 system specifications of possible behaviors, DCS
                 automatically produces controllers that make the
                 controlled system satisfy the property given as
                 objective. Our language features and compiling
                 technique provide correctness-by-construction in that
                 sense, and enhance reliability and verifiability. Our
                 application domain is adaptive and reconfigurable
                 systems: closed-loop adaptation mechanisms enable
                 flexible execution of functionalities w.r.t. changing
                 resource and environment conditions. Our language can
                 serve programming such adaption controllers. This paper
                 particularly describes the compilation of the language.
                 We present a method for the modular application of
                 discrete controller synthesis on synchronous programs,
                 and its integration in the BZR language. We consider
                 structured programs, as a composition of nodes, and
                 first apply DCS on particular nodes of the program, in
                 order to reduce the complexity of the controller
                 computation; then, we allow the abstraction of parts of
                 the program for this computation; and finally, we show
                 how to recompose the different controllers computed
                 from different abstractions for their correct
                 co-execution with the initial program. Our work is
                 illustrated with examples, and we present quantitative
                 results about its implementation.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "adaptive and reconfigurable systems; components;
                 contracts; discrete controller synthesis; modularity;
                 reactive systems; synchronous programming",
}

@Article{Schlickling:2010:SAD,
  author =       "Marc Schlickling and Markus Pister",
  title =        "Semi-automatic derivation of timing models for {WCET}
                 analysis",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "4",
  pages =        "67--76",
  month =        apr,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1755888.1755899",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Apr 15 12:45:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Embedded systems are widely used for supporting our
                 every day life. In the area of safety-critical systems
                 human life often depends on the system's correct
                 behavior. Many of such systems are hard real-time
                 systems, so that the notion of correctness not only
                 means functional correctness. They additionally have to
                 obey stringent timing constraints, i.e. timely task
                 completion under all circumstances is essential. An
                 example for such a safety-critical system is the flight
                 control computer in an airplane, which is responsible
                 for stability, attitude and path control.\par

                 In order to derive guarantees on the timing behavior of
                 hard real-time systems, the worst-case execution time
                 (WCET) of each task in the system has to be determined.
                 Saarland University and AbsInt GmbH have successfully
                 developed the aiT WCET analyzer for computing safe
                 upper bounds on the WCET of a task. The computation is
                 mainly based on abstract interpretation of timing
                 models of the processor and its periphery. Such timing
                 models are currently hand-crafted by human experts.
                 Therefore their implementation is a time-consuming and
                 error-prone process.\par

                 Modern processors or system controllers are
                 automatically synthesized out of formal hardware
                 specifications like VHDL or Verilog. Besides the
                 system' functional behavior, such specifications
                 provide all information needed for the creation of a
                 timing model. But due to their size and complexity,
                 manually examining the sources is even more complex
                 than only looking at the processor manuals. Moreover,
                 this would not reduce the effort nor the probability of
                 implementation errors.\par

                 To face this problem, this paper proposes a method for
                 semi-automatically deriving suitable timing models out
                 of formal hardware specifications in VHDL that fit to
                 the tool chain of the aiT WCET analyzer. By this, we
                 reduce the creation time of timing models from months
                 to weeks.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "hard real-time; vhdl; worst-case execution time",
}

@Article{Viskic:2010:DEA,
  author =       "Ines Viskic and Lochi Yu and Daniel Gajski",
  title =        "Design exploration and automatic generation of {MPSoC}
                 platform {TLMs} from {Kahn Process Network}
                 applications",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "4",
  pages =        "77--84",
  month =        apr,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1755888.1755900",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Apr 15 12:45:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "With increasingly more complex Multi-Processor Systems
                 on Chip (MPSoC) and shortening time-to-market
                 projections, Transaction Level Modeling and Platform
                 Aware Design are seen as promising >approaches to
                 efficient MPSoC design.\par

                 In this paper, we present an automatized 3-phase
                 process of Platform Aware Design and apply it to Kahn
                 Process Networks (KPN) applications, a widely used
                 model of computation for data-flow applications. We
                 start with the KPN application and an abstract platform
                 template and automatically generate an executable TLM
                 with estimated timing that accurately reflects the
                 system platform. We support homogeneous and
                 heterogeneous multi-master platform models with shared
                 memory or direct communication paradigm. The
                 communication in heterogeneous platform modules is
                 enabled with the transducer unit (TX) for protocol
                 translation. TX units also act as message routers to
                 support Network on Chip (NoC) communication.\par

                 We evaluate our approach with the case study of the
                 H.264 Encoder design process, in which the
                 specification compliant design was reached from the KPN
                 application in less than 2 hours. The example
                 demonstrates that automatic generation of platform
                 aware TLMs enables a fast, efficient and error
                 resilient design process.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "automatic generation; Kahn Process Network; process
                 mapping; transaction level model",
}

@Article{Ozturk:2010:CDN,
  author =       "Ozcan Ozturk and Mahmut Kandemir and Mary J. Irwin and
                 Sri H. K. Narayanan",
  title =        "Compiler directed network-on-chip reliability
                 enhancement for chip multiprocessors",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "4",
  pages =        "85--94",
  month =        apr,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1755951.1755902",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Apr 15 12:45:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Chip multiprocessors (CMPs) are expected to be the
                 building blocks for future computer systems. While
                 architecting these emerging CMPs is a challenging
                 problem on its own, programming them is even more
                 challenging. As the number of cores accommodated in
                 chip multiprocessors increases, network-on-chip (NoC)
                 type communication fabrics are expected to replace
                 traditional point-to-point buses. Most of the prior
                 software related work so far targeting CMPs focus on
                 performance and power aspects. However, as technology
                 scales, components of a CMP are being increasingly
                 exposed to both transient and permanent hardware
                 failures. This paper presents and evaluates a
                 compiler-directed power-performance aware reliability
                 enhancement scheme for network-on-chip (NoC) based chip
                 multiprocessors (CMPs). The proposed scheme improves
                 on-chip communication reliability by duplicating
                 messages traveling across CMP nodes such that, for each
                 original message, its duplicate uses a different set of
                 communication links as much as possible (to satisfy
                 performance constraint). In addition, our approach
                 tries to reuse communication links across the different
                 phases of the program to maximize link shutdown
                 opportunities for the NoC (to satisfy power
                 constraint). Our results show that the proposed
                 approach is very effective in improving on-chip network
                 reliability, without causing excessive power or
                 performance degradation. In our experiments, we also
                 evaluate the performance oriented and energy oriented
                 versions of our compiler-directed reliability
                 enhancement scheme, and compare it to two pure hardware
                 based fault tolerant routing schemes.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "chip multiprocessors; compiler; noc; reliability",
}

@Article{Kulkarni:2010:IBP,
  author =       "Prasad A. Kulkarni and Michael R. Jantz and David B.
                 Whalley",
  title =        "Improving both the performance benefits and speed of
                 optimization phase sequence searches",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "4",
  pages =        "95--104",
  month =        apr,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1755888.1755903",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Apr 15 12:45:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "The issues of compiler optimization phase ordering and
                 selection present important challenges to compiler
                 developers in several domains, and in particular to the
                 speed, code size, power, and cost-constrained domain of
                 embedded systems. Different sequences of optimization
                 phases have been observed to provide the best
                 performance for different applications. Compiler
                 writers and embedded systems developers have recently
                 addressed this problem by conducting iterative
                 empirical searches using machine-learning based
                 heuristic algorithms in an attempt to find the phase
                 sequences that are most effective for each application.
                 Such searches are generally performed at the program
                 level, although a few studies have been performed at
                 the function level. The finer granularity of
                 function-level searches has the potential to provide
                 greater overall performance benefits, but only at the
                 cost of slower searches caused by a greater number of
                 performance evaluations that often require expensive
                 program simulations. In this paper, we evaluate the
                 performance benefits and search time increases of
                 function-level approaches as compared to their
                 program-level counterparts. We, then, present a novel
                 search algorithm that conducts distinct function-level
                 searches simultaneously, but requires only a single
                 program simulation for evaluating the performance of
                 potentially unique sequences for each function. Thus,
                 our new hybrid search strategy provides the enhanced
                 performance benefits of function-level searches with a
                 search-time cost that is comparable to or less than
                 program-level searches.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "genetic algorithms; phase ordering",
}

@Article{Li:2010:ECU,
  author =       "Weijia Li and Youtao Zhang",
  title =        "An efficient code update scheme for {DSP} applications
                 in mobile embedded systems",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "4",
  pages =        "105--114",
  month =        apr,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1755951.1755904",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Apr 15 12:45:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "DSP processors usually provide dedicated address
                 generation units (AGUs) to assist address computation.
                 By carefully allocating variables in the memory, DSP
                 compilers take advantage of AGUs and generate efficient
                 code with compact size and improved performance.
                 However, DSP applications running on mobile embedded
                 systems often need to be updated after their initial
                 releases. Studies showed that small changes at the
                 source code level may significantly change the variable
                 layout in the memory and thus the binary code, which
                 causes large energy overheads to mobile embedded
                 systems that patch through wireless or satellite
                 communication, and often pecuniary burden to the
                 users.\par

                 In this paper, we propose an update-conscious code
                 update scheme to effectively reduce patch size. It
                 first performs incremental offset assignment based on a
                 recent variable coalescing heuristic, and then
                 summarizes the code difference using two types of
                 update primitives. Our experimental results showed that
                 using update-conscious code update can greatly improve
                 code similarity and thus reduce the update script
                 sizes.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "context-aware script; context-unaware script;
                 incremental coalescing general offset assignment
                 (icgoa); incremental coalescing simple offset
                 assignment (icsoa)",
}

@Article{Wernsing:2010:ECF,
  author =       "John Robert Wernsing and Greg Stitt",
  title =        "Elastic computing: a framework for transparent,
                 portable, and adaptive multi-core heterogeneous
                 computing",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "4",
  pages =        "115--124",
  month =        apr,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1755951.1755906",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Apr 15 12:45:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Over the past decade, system architectures have
                 started on a clear trend towards increased parallelism
                 and heterogeneity, often resulting in speedups of 10x
                 to 100x. Despite numerous compiler and high-level
                 synthesis studies, usage of such systems has largely
                 been limited to device experts, due to significantly
                 increased application design complexity. To reduce
                 application design complexity, we introduce elastic
                 computing - a framework that separates functionality
                 from implementation details by enabling designers to
                 use specialized functions, called elastic functions,
                 which enable an optimization framework to explore
                 thousands of possible implementations, even ones using
                 different algorithms. Elastic functions allow designers
                 to execute the same application code efficiently on
                 potentially any architecture and for different runtime
                 parameters such as input size, battery life, etc. In
                 this paper, we present an initial elastic computing
                 framework that transparently optimizes application code
                 onto diverse systems, achieving significant speedups
                 ranging from 1.3x to 46x on a hyper-threaded Xeon
                 system with an FPGA accelerator, a 16-CPU Opteron
                 system, and a quad-core Xeon system.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "elastic computing; fpga; heterogeneous architectures;
                 multi-core; speedup",
}

@Article{Biehl:2010:ISA,
  author =       "Matthias Biehl and Chen DeJiu and Martin
                 T{\"o}rngren",
  title =        "Integrating safety analysis into the model-based
                 development toolchain of automotive embedded systems",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "4",
  pages =        "125--132",
  month =        apr,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1755951.1755907",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Apr 15 12:45:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "The automotive industry has a growing demand for the
                 seamless integration of safety analysis tools into the
                 model-based development toolchain for embedded systems.
                 This requires translating concepts of the automotive
                 domain to the safety domain. We automate such a
                 translation between the automotive architecture
                 description language EAST-ADL2 and the safety analysis
                 tool HiP-HOPS by using model transformations and by
                 leveraging the advantages of different model
                 transformation techniques. Through this integration,
                 the analysis can be conducted early in the development
                 process, when the system can be redesigned to fulfill
                 safety goals with relatively low effort and cost.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "architecture description language; model-based
                 development; safety analysis; tool integration",
}

@Article{Fischmeister:2010:SBP,
  author =       "Sebastian Fischmeister and Yanmeng Ba",
  title =        "Sampling-based program execution monitoring",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "4",
  pages =        "133--142",
  month =        apr,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1755951.1755908",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Apr 15 12:45:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "For its high overall cost during product development,
                 program debugging is an important aspect of system
                 development. Debugging is a hard and complex activity,
                 especially in time-sensitive systems which have limited
                 resources and demanding timing constraints. System
                 tracing is a frequently used technique for debugging
                 embedded systems. A specific use of system tracing is
                 to monitor and debug control-flow problems in programs.
                 However, it is difficult to implement because of the
                 potentially high overhead it might introduce to the
                 system and the changes which can occur to the system
                 behavior due to tracing. To solve the above problems,
                 in this work, we present a sampling-based approach to
                 execution monitoring which specifically helps
                 developers debug time-sensitive systems such as
                 real-time applications. We build the system model and
                 propose three theorems to determine the sampling period
                 in different scenarios. We also design seven heuristics
                 and an instrumentation framework to extend the sampling
                 period which can reduce the monitoring overhead and
                 achieve an optimal tradeoff between accuracy and
                 overhead introduced by instrumentation. Using this
                 monitoring framework, we can use the information
                 extracted through sampling to reconstruct the system
                 state and execution paths to locate the deviation.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "debugging; embedded system; monitoring; sampling;
                 tracing",
}

@Article{Shrivastava:2010:CVE,
  author =       "Aviral Shrivastava and Jongeun Lee and Reiley
                 Jeyapaul",
  title =        "Cache vulnerability equations for protecting data in
                 embedded processor caches from soft errors",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "4",
  pages =        "143--152",
  month =        apr,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1755888.1755910",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Apr 15 12:45:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Continuous technology scaling has brought us to a
                 point, where transistors have become extremely
                 susceptible to cosmic radiation strikes, or soft
                 errors. Inside the processor, caches are most
                 vulnerable to soft errors, and techniques at various
                 levels of design abstraction, e.g., fabrication, gate
                 design, circuit design, and microarchitecture-level,
                 have been developed to protect data in caches. However,
                 no work has been done to investigate the effect of code
                 transformations on the vulnerability of data in caches.
                 Data is vulnerable to soft errors in the cache only if
                 it will be read by the processor, and not if it will be
                 overwritten. Since code transformations can change the
                 read-write pattern of program variables, they
                 significantly effect the soft error vulnerability of
                 program variables in the cache. We observe that often
                 opportunity exists to significantly reduce the soft
                 error vulnerability of cache data by trading-off a
                 little performance. However, even if one wanted to
                 exploit this trade-off, it is difficult, since there
                 are no efficient techniques to estimate vulnerability
                 of data in caches. To this end, this paper develops
                 efficient static analysis method to estimate program
                 vulnerability in caches, which enables the compiler to
                 exploit the performance-vulnerability trade-offs in
                 applications. Finally, as compared to simulation based
                 estimation, static analysis techniques provide the
                 insights into vulnerability calculations that provide
                 some simple schemes to reduce program vulnerability.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "cache vulnerability; code transformation; compiler
                 technique; embedded processors; soft errors; static
                 analysis",
}

@Article{Altmeyer:2010:RAT,
  author =       "Sebastian Altmeyer and Claire Maiza and Jan Reineke",
  title =        "Resilience analysis: tightening the {CRPD} bound for
                 set-associative caches",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "4",
  pages =        "153--162",
  month =        apr,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1755888.1755911",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Apr 15 12:45:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "In preemptive real-time systems, scheduling analyses
                 need - in addition to the worst-case execution time -
                 the context-switch cost. In case of preemption, the
                 preempted and the preempting task may interfere on the
                 cache memory.\par

                 This interference leads to additional cache misses in
                 the preempted task. The delay due to these cache misses
                 is referred to as the cache-related preemption
                 delay~(CRPD), which constitutes the major part of the
                 context-switch cost.\par

                 In this paper, we present a new approach to compute
                 tight bounds on the CRPD for LRU set-associative
                 caches, based on analyses of both the preempted and the
                 preempting task. Previous approaches analyzing both the
                 preempted and the preempting task were either imprecise
                 or unsound.\par

                 As the basis of our approach we introduce the notion of
                 resilience: The resilience of a memory block of the
                 preempted task is the maximal number of memory accesses
                 a preempting task could perform without causing an
                 additional miss to this block. By computing lower
                 bounds on the resilience of blocks and an upper bound
                 on the number of accesses by a preempting task, one can
                 guarantee that some blocks may not contribute to the
                 CRPD. The CRPD analysis based on resilience
                 considerably outperforms previous approaches.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "cache-related preemption delay; lru caches; timing
                 analysis",
}

@Article{Wang:2010:RRA,
  author =       "Yi Wang and Duo Liu and Meng Wang and Zhiwei Qin and
                 Zili Shao and Yong Guan",
  title =        "{RNFTL}: a reuse-aware {NAND} flash translation layer
                 for flash memory",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "4",
  pages =        "163--172",
  month =        apr,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1755951.1755912",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Apr 15 12:45:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "In this paper, we propose a hybrid-level flash
                 translation layer (FTL) called RNFTL (Reuse-Aware NFTL)
                 to improve the endurance and space utilization of NAND
                 flash memory. Our basic idea is to prevent a primary
                 block with many free pages from being erased in a merge
                 operation. The preserved primary blocks are further
                 reused as replacement blocks. In such a way, the space
                 utilization and the number of erase counts for each
                 block in NAND flash can be enhanced. To the best of our
                 knowledge, this is the first work to employ a
                 reuse-aware strategy in FTL for improving the space
                 utilization and endurance of NAND flash. We conduct
                 experiments on a set of traces that collected from real
                 workload in daily life. The experimental results show
                 that our technique has significant improvement on space
                 utilization, block lifetime and wear-leveling compared
                 with the previous work.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "endurance; flash memory; reuse; space utilization;
                 wear-leveling",
}

@Article{Agerwala:2010:ECC,
  author =       "Tilak Agerwala",
  title =        "Exascale computing: the challenges and opportunities
                 in the next decade",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "1--2",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693454",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Supercomputing systems have made great strides in
                 recent years as the extensive computing needs of
                 cutting-edge engineering work and scientific discovery
                 have driven the development of more powerful systems.
                 In 2008, the first petaflop machine was released, and
                 historic trends indicate that in ten years, we should
                 be at the exascale level. Indeed, various agencies are
                 targeting a computer system capable of 1 Exaop (10**18
                 ops) of computation within the next decade. We believe
                 that applications in many industries will be materially
                 transformed by exascale computers.\par

                 Meeting the exascale challenge will require significant
                 innovation in technology, architecture and
                 programmability. Power is a fundamental problem at all
                 levels; traditional memory cost and performance are not
                 keeping pace with compute potential; the storage
                 hierarchy will have to be re-architected; networks will
                 be a much bigger part of the system cost; reliability
                 at exascale levels will require a holistic approach to
                 architecture design, and programmability and
                 ease-of-use will be an essential component to extract
                 the promised performance at the exascale level.\par

                 In this talk, I will discuss the importance of exascale
                 computing and address the major challenges, touching on
                 the areas of technology, architecture, reliability and
                 usability.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "architecture; challenges; exascale",
}

@Article{Mendez-Lojo:2010:SDO,
  author =       "Mario M{\'e}ndez-Lojo and Donald Nguyen and Dimitrios
                 Prountzos and Xin Sui and M. Amber Hassaan and Milind
                 Kulkarni and Martin Burtscher and Keshav Pingali",
  title =        "Structure-driven optimizations for amorphous
                 data-parallel programs",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "3--14",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693457",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Irregular algorithms are organized around
                 pointer-based data structures such as graphs and trees,
                 and they are ubiquitous in applications. Recent work by
                 the Galois project has provided a systematic approach
                 for parallelizing irregular applications based on the
                 idea of optimistic or speculative execution of
                 programs. However, the overhead of optimistic parallel
                 execution can be substantial. In this paper, we show
                 that many irregular algorithms have structure that can
                 be exploited and present three key optimizations that
                 take advantage of algorithmic structure to reduce
                 speculative overheads. We describe the implementation
                 of these optimizations in the Galois system and present
                 experimental results to demonstrate their benefits. To
                 the best of our knowledge, this is the first system to
                 exploit algorithmic structure to optimize the execution
                 of irregular programs.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "amorphous data-parallelism; cautious operator
                 implementations; irregular programs; iteration
                 coalescing; one-shot optimization; optimistic
                 parallelization; synchronization overheads",
}

@Article{Coons:2010:GEU,
  author =       "Katherine E. Coons and Sebastian Burckhardt and
                 Madanlal Musuvathi",
  title =        "{GAMBIT}: effective unit testing for concurrency
                 libraries",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "15--24",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837853.1693458",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "As concurrent programming becomes prevalent, software
                 providers are investing in concurrency libraries to
                 improve programmer productivity. Concurrency libraries
                 improve productivity by hiding error-prone, low-level
                 synchronization from programmers and providing
                 higher-level concurrent abstractions. Testing such
                 libraries is difficult, however, because concurrency
                 failures often manifest only under particular
                 scheduling circumstances. Current best testing
                 practices are often inadequate: heuristic-guided
                 fuzzing is not systematic, systematic schedule
                 enumeration does not find bugs quickly, and stress
                 testing is neither systematic nor fast.\par

                 To address these shortcomings, we propose a prioritized
                 search technique called GAMBIT that combines the speed
                 benefits of heuristic-guided fuzzing with the
                 soundness, progress, and reproducibility guarantees of
                 stateless model checking. GAMBIT combines known
                 techniques such as partial-order reduction and
                 preemption-bounding with a generalized best-first
                 search frame- work that prioritizes schedules likely to
                 expose bugs. We evaluate GAMBIT's effectiveness on
                 newly released concurrency libraries for Microsoft's
                 .NET framework. Our experiments show that GAMBIT finds
                 bugs more quickly than prior stateless model checking
                 techniques without compromising coverage guarantees or
                 reproducibility.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "concurrency; model checking; multithreading;
                 partial-order reduction; preemption bound; software
                 testing",
}

@Article{Lee:2010:FXC,
  author =       "Jonathan K. Lee and Jens Palsberg",
  title =        "Featherweight {X10}: a core calculus for async-finish
                 parallelism",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "25--36",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693459",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "We present a core calculus with two of X10's key
                 constructs for parallelism, namely async and finish.
                 Our calculus forms a convenient basis for type systems
                 and static analyses for languages with async-finish
                 parallelism, and for tractable proofs of correctness.
                 For example, we give a short proof of the
                 deadlock-freedom theorem of Saraswat and Jagadeesan.
                 Our main contribution is a type system that solves the
                 open problem of context-sensitive
                 may-happen-in-parallel analysis for languages with
                 async-finish parallelism. We prove the correctness of
                 our type system and we report experimental results of
                 performing type inference on 13,000 lines of X10 code.
                 Our analysis runs in polynomial time, takes a total of
                 28 seconds on our benchmarks, and produces a low number
                 of false positives, which suggests that our analysis is
                 a good basis for other analyses such as race
                 detectors.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "operational semantics; parallelism; static analysis",
}

@Article{Mannarswamy:2010:CAS,
  author =       "Sandya Mannarswamy and Dhruva R. Chakrabarti and
                 Kaushik Rajan and Sujoy Saraswati",
  title =        "Compiler aided selective lock assignment for improving
                 the performance of software transactional memory",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "37--46",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693460",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Atomic sections have been recently introduced as a
                 language construct to improve the programmability of
                 concurrent software. They simplify programming by not
                 requiring the explicit specification of locks for
                 shared data. Typically atomic sections are supported in
                 software either through the use of optimistic
                 concurrency by using transactional memory or through
                 the use of pessimistic concurrency using
                 compiler-assigned locks. As a software transactional
                 memory (STM) system does not take advantage of the
                 specific memory access patterns of an application it
                 often suffers from false conflicts and high validation
                 overheads. On the other hand, the compiler usually ends
                 up assigning coarse grain locks as it relies on whole
                 program points-to analysis which is conservative by
                 nature. This adversely affects performance by limiting
                 concurrency. In order to mitigate the disadvantages
                 associated with STM's lock assignment scheme, we
                 propose a hybrid approach which combines STM's lock
                 assignment with a compiler aided selective lock
                 assignment scheme (referred to as SCLA-STM). SCLA-STM
                 overcomes the inefficiencies associated with a purely
                 compile-time lock assignment approach by (i) using the
                 underlying STM for shared variables where only a
                 conservative analysis is possible by the compiler
                 (e.g., in the presence of may-alias points to
                 information) and (ii) being selective about the shared
                 data chosen for the compiler-aided lock assignment. We
                 describe our prototype SCLA-STM scheme implemented in
                 the HP-UX IA-64 C/C++ compiler, using TL2 as our STM
                 implementation. We show that SCLA-STM improves
                 application performance for certain STAMP benchmarks
                 from 1.68\% to 37.13\%.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "compilers; multithreading; parallelization;
                 performance",
}

@Article{Rossbach:2010:TPA,
  author =       "Christopher J. Rossbach and Owen S. Hofmann and Emmett
                 Witchel",
  title =        "Is transactional programming actually easier?",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "47--56",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693462",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Chip multi-processors (CMPs) have become ubiquitous,
                 while tools that ease concurrent programming have not.
                 The promise of increased performance for all
                 applications through ever more parallel hardware
                 requires good tools for concurrent programming,
                 especially for average programmers. Transactional
                 memory (TM) has enjoyed recent interest as a tool that
                 can help programmers program concurrently.\par

                 The transactional memory (TM) research community is
                 heavily invested in the claim that programming with
                 transactional memory is easier than alternatives (like
                 locks), but evidence for or against the veracity of
                 this claim is scant. In this paper, we describe a
                 user-study in which 237 undergraduate students in an
                 operating systems course implement the same programs
                 using coarse and fine-grain locks, monitors, and
                 transactions. We surveyed the students after the
                 assignment, and examined their code to determine the
                 types and frequency of programming errors for each
                 synchronization technique. Inexperienced programmers
                 found baroque syntax a barrier to entry for
                 transactional programming. On average, subjective
                 evaluation showed that students found transactions
                 harder to use than coarse-grain locks, but slightly
                 easier to use than fine-grained locks. Detailed
                 examination of synchronization errors in the students'
                 code tells a rather different story. Overwhelmingly,
                 the number and types of programming errors the students
                 made was much lower for transactions than for locks. On
                 a similar programming problem, over 70\% of students
                 made errors with fine-grained locking, while less than
                 10\% made errors with transactions.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "optimistic concurrency; synchronization; transactional
                 memory",
}

@Article{Zyulkyarov:2010:DPU,
  author =       "Ferad Zyulkyarov and Tim Harris and Osman S. Unsal and
                 Adr{\'\i}an Cristal and Mateo Valero",
  title =        "Debugging programs that use atomic blocks and
                 transactional memory",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "57--66",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837853.1693463",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "With the emergence of research prototypes, programming
                 using atomic blocks and transactional memory (TM) is
                 becoming more attractive. This paper describes our
                 experience building and using a debugger for programs
                 written with these abstractions. We introduce three
                 approaches: ({\em i\/}) debugging at the level of
                 atomic blocks, where the programmer is shielded from
                 implementation details (such as exactly what kind of TM
                 is used, or indeed whether lock inference is used
                 instead), ({\em ii\/}) debugging at the level of
                 transactions, where conflict rates, read sets, write
                 sets, and other TM internals are visible, and ({\em
                 iii\/}) debug-time transactions, which let the
                 programmer manipulate synchronization from within the
                 debugger - e.g., enlarging the scope of an atomic block
                 to try to identify a bug.\par

                 In this paper we explain the rationale behind the new
                 debugging approaches that we propose. We describe the
                 design and implementation of an extension to the WinDbg
                 debugger, enabling support for C\# programs using
                 atomic blocks and TM. We also demonstrate the design of
                 a 'conflict point discovery' technique for identifying
                 program statements that introduce contention between
                 transactions. We illustrate how these techniques can be
                 used by optimizing a C\# version of the Genome
                 application from STAMP TM benchmark suite.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "debugging; transactional memory",
}

@Article{Dalessandro:2010:NSS,
  author =       "Luke Dalessandro and Michael F. Spear and Michael L.
                 Scott",
  title =        "{NOrec}: streamlining {STM} by abolishing ownership
                 records",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "67--78",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837853.1693464",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Drawing inspiration from several previous projects, we
                 present an ownership-record-free software transactional
                 memory (STM) system that combines extremely low
                 overhead with unusually clean semantics. While unlikely
                 to scale to hundreds of active threads, this 'NOrec'
                 system offers many appealing features: very low
                 fast-path latency--as low as any system we know of that
                 admits concurrent updates; publication and
                 privatization safety; livelock freedom; a small,
                 constant amount of global metadata, and full
                 compatibility with existing data structure layouts; no
                 false conflicts due to hash collisions; compatibility
                 with both managed and unmanaged languages, and both
                 static and dynamic compilation; and easy accommodation
                 of closed nesting, inevitable (irrevocable)
                 transactions, and starvation avoidance mechanisms. To
                 the best of our knowledge, no extant STM system
                 combines this set of features.\par

                 While transactional memory for processors with hundreds
                 of cores is likely to require hardware support,
                 software implementations will be required for backward
                 compatibility with current and near-future processors
                 with 2--64 cores, as well as for fall-back in future
                 machines when hardware resources are exhausted. Our
                 experience suggests that NOrec may be an ideal
                 candidate for such a software system. We also observe
                 that it has considerable appeal for use within the
                 operating system, and in systems that require both
                 closed nesting and publication safety.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "ownership records; software transactional memory;
                 transactional memory; transactional memory models",
}

@Article{Maldonado:2010:SST,
  author =       "Walther Maldonado and Patrick Marlier and Pascal
                 Felber and Adi Suissa and Danny Hendler and Alexandra
                 Fedorova and Julia L. Lawall and Gilles Muller",
  title =        "Scheduling support for transactional memory contention
                 management",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "79--90",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693465",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Transactional Memory (TM) is considered as one of the
                 most promising paradigms for developing concurrent
                 applications. TM has been shown to scale well on
                 >multiple cores when the data access pattern behaves
                 'well,' i.e., when few conflicts are induced. In
                 contrast, data patterns with frequent write sharing,
                 with long transactions, or when many threads contend
                 for a smaller number of cores, result in numerous
                 conflicts. Until recently, TM implementations had
                 little control of transactional threads, which remained
                 under the supervision of the kernel's
                 transaction-ignorant scheduler. Conflicts are thus
                 traditionally resolved by consulting an STM-level {\em
                 contention manager}. Consequently, the contention
                 managers of these 'conventional' TM implementations
                 suffer from a lack of precision and often fail to
                 ensure reasonable performance in high-contention
                 workloads.\par

                 Recently, scheduling-based TM contention-management has
                 been proposed for increasing TM efficiency under
                 high-contention [2, 5, 19]. However, only user-level
                 schedulers have been considered. In this work, we
                 propose, implement and evaluate several novel
                 kernel-level scheduling support mechanisms for TM
                 contention management. We also investigate different
                 strategies for efficient communication between the
                 kernel and the user-level TM library. To the best of
                 our knowledge, our work is the first to investigate
                 kernel-level support for TM contention
                 management.\par

                 We have introduced kernel-level TM scheduling support
                 into both the Linux and Solaris kernels. Our
                 experimental evaluation demonstrates that lightweight
                 kernel-level scheduling support significantly reduces
                 the number of aborts while improving transaction
                 throughput on various workloads.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "contention management; scheduling; transactional
                 memory",
}

@Article{Barreto:2010:LPN,
  author =       "Jo{\~a}o Barreto and Aleksandar Dragojevi{\'c} and
                 Paulo Ferreira and Rachid Guerraoui and Michal
                 Kapalka",
  title =        "Leveraging parallel nesting in transactional memory",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "91--100",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693466",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Exploiting the emerging reality of affordable
                 multi-core architectures goes through providing
                 programmers with simple abstractions that would enable
                 them to easily turn their sequential programs into
                 concurrent ones that expose as much parallelism as
                 possible. While transactional memory promises to make
                 concurrent programming easy to a wide programmer
                 community, current implementations either disallow
                 nested transactions to run in parallel or do not scale
                 to arbitrary parallel nesting depths. This is an
                 important obstacle to the central goal of transactional
                 memory, as programmers can only start parallel threads
                 in restricted parts of their code.\par

                 This paper addresses the intrinsic difficulty behind
                 the support for parallel nesting in transactional
                 memory, and proposes a novel solution that, to the best
                 of our knowledge, is the first practical solution to
                 meet the lowest theoretical upper bound known for the
                 problem.\par

                 Using a synthetic workload configured to test parallel
                 transactions on a multi-core machine, a practical
                 implementation of our algorithm yields substantial
                 speed-ups (up to 22x with 33 threads) relatively to
                 serial nesting, and shows that the time to start and
                 commit transactions, as well as to detect conflicts, is
                 independent of nesting depth.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "fork-join; nested parallel programs; transactional
                 memory; work-stealing",
}

@Article{Torrellas:2010:ESC,
  author =       "Josep Torrellas and Bill Gropp and Jaime Moreno and
                 Kunle Olukotun and Vivek Sarkar",
  title =        "Extreme scale computing: challenges and
                 opportunities",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "101--102",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693468",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "architecture; challenges; exascale",
}

@Article{Arvind:2010:HI,
  author =       "Professor Arvind",
  title =        "Is hardware innovation over?",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "103--104",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837853.1693455",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "My colleagues, promotion committees, research funding
                 agencies and business people often wonder if there is
                 need for any architecture research. There seems to be
                 no room to dislodge Intel IA-32. Even the number of new
                 Application-Specific Integrated Circuits (ASICs) seems
                 to be declining each year, because of the
                 ever-increasing development cost.\par

                 This viewpoint ignores another reality which is that
                 the future will be dominated by mobile devices such as
                 smart phones and the infrastructure needed to support
                 consumer services on these devices. This is already
                 restructuring the IT industry. To the first-order, in
                 the mobile world functionality is determined by what
                 can be supported within a 3W power budget. The only way
                 to reduce power by one to two orders of magnitude is
                 via functionally specialized hardware blocks. A
                 fundamental shift is needed in the current design flow
                 of systems-on-a-chip (SoCs) to produce them in a
                 less-risky and cost-effective manner.\par

                 In this talk we will present, via examples, a method of
                 designing systems that facilitates the synthesis of
                 complex SoCs from reusable 'IP' modules. The technical
                 challenge is to provide a method for connecting modules
                 in a parallel setting so that the functionality and the
                 performance of the composite are predictable.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "hardware innovation; system-on-chip",
}

@Article{Baghsorkhi:2010:APM,
  author =       "Sara S. Baghsorkhi and Matthieu Delahaye and Sanjay J.
                 Patel and William D. Gropp and Wen-mei W. Hwu",
  title =        "An adaptive performance modeling tool for {GPU}
                 architectures",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "105--114",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693470",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "This paper presents an analytical model to predict the
                 performance of\par

                 general-purpose applications on a GPU architecture. The
                 model is designed to provide performance information to
                 an auto-tuning compiler and assist it in narrowing down
                 the search to the more promising implementations. It
                 can also be incorporated into a tool to help
                 programmers better assess the performance bottlenecks
                 in their code. We analyze each GPU kernel and identify
                 how the kernel exercises major GPU microarchitecture
                 features. To identify the performance bottlenecks
                 accurately, we introduce an abstract interpretation of
                 a GPU kernel, {\em work flow graph}, based on which we
                 estimate the execution time of a GPU kernel. We
                 validated our performance model on the NVIDIA GPUs
                 using CUDA (Compute Unified Device Architecture). For
                 this purpose, we used data parallel benchmarks that
                 stress different GPU microarchitecture events such as
                 uncoalesced memory accesses, scratch-pad memory bank
                 conflicts, and control flow divergence, which must be
                 accurately modeled but represent challenges to the
                 analytical performance models. The proposed model
                 captures full system complexity and shows high accuracy
                 in predicting the performance trends of different
                 optimized kernel implementations. We also describe our
                 approach to extracting the performance model
                 automatically from a kernel code.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "analytical model; GPU; parallel programming;
                 performance estimation",
}

@Article{Choi:2010:MDA,
  author =       "Jee W. Choi and Amik Singh and Richard W. Vuduc",
  title =        "Model-driven autotuning of sparse matrix-vector
                 multiply on {GPUs}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "115--126",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693471",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "We present a performance model-driven framework for
                 automated performance tuning (autotuning) of sparse
                 matrix-vector multiply (SpMV) on systems accelerated by
                 graphics processing units (GPU). Our study consists of
                 two parts.\par

                 First, we describe several carefully hand-tuned SpMV
                 implementations for GPUs, identifying key GPU-specific
                 performance limitations, enhancements, and tuning
                 opportunities. These implementations, which include
                 variants on classical blocked compressed sparse row
                 (BCSR) and blocked ELLPACK (BELLPACK) storage formats,
                 match or exceed state-of-the-art implementations. For
                 instance, our best BELLPACK implementation achieves up
                 to 29.0 Gflop/s in single-precision and 15.7 Gflop/s in
                 double-precision on the NVIDIA T10P multiprocessor
                 (C1060), enhancing prior state-of-the-art unblocked
                 implementations (Bell and Garland, 2009) by up to
                 1.8\times and 1.5\times for single-and double-precision
                 respectively.\par

                 However, achieving this level of performance requires
                 input matrix-dependent parameter tuning. Thus, in the
                 second part of this study, we develop a performance
                 model that can guide tuning. Like prior autotuning
                 models for CPUs (e.g., Im, Yelick, and Vuduc, 2004),
                 this model requires offline measurements and run-time
                 estimation, but more directly models the structure of
                 multithreaded vector processors like GPUs. We show that
                 our model can identify the implementations that achieve
                 within 15\% of those found through exhaustive search.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "GPU; performance modeling; sparse matrix-vector
                 multiplication",
}

@Article{Zhang:2010:FTS,
  author =       "Yao Zhang and Jonathan Cohen and John D. Owens",
  title =        "Fast tridiagonal solvers on the {GPU}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "127--136",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693472",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "We study the performance of three parallel algorithms
                 and their hybrid variants for solving tridiagonal
                 linear systems on a GPU: cyclic reduction (CR),
                 parallel cyclic reduction (PCR) and recursive doubling
                 (RD). We develop an approach to measure, analyze, and
                 optimize the performance of GPU programs in terms of
                 memory access, computation, and control overhead. We
                 find that CR enjoys linear algorithm complexity but
                 suffers from more algorithmic steps and bank conflicts,
                 while PCR and RD have fewer algorithmic steps but do
                 more work each step. To combine the benefits of the
                 basic algorithms, we propose hybrid CR+PCR and CR+RD
                 algorithms, which improve the performance of PCR, RD
                 and CR by 21\%, 31\% and 61\% respectively. Our GPU
                 solvers achieve up to a 28x speedup over a sequential
                 LAPACK solver, and a 12x speedup over a multi-threaded
                 CPU solver.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "GPGPU; performance optimization; tridiagonal linear
                 system",
}

@Article{Sandes:2010:CUG,
  author =       "Edans Flavius O. Sandes and Alba Cristina M. A. de
                 Melo",
  title =        "{CUDAlign}: using {GPU} to accelerate the comparison
                 of megabase genomic sequences",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "137--146",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693473",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Biological sequence comparison is a very important
                 operation in Bioinformatics. Even though there do exist
                 exact methods to compare biological sequences, these
                 methods are often neglected due to their quadratic time
                 and space complexity. In order to accelerate these
                 methods, many GPU algorithms were proposed in the
                 literature. Nevertheless, all of them restrict the size
                 of the smallest sequence in such a way that Megabase
                 genome comparison is prevented. In this paper, we
                 propose and evaluate CUDAlign, a GPU algorithm that is
                 able to compare Megabase biological sequences with an
                 exact Smith--Waterman affine gap variant. CUDAlign was
                 implemented in CUDA and tested in two GPU boards,
                 separately. For real sequences whose size range from
                 1MBP (Megabase Pairs) to 47MBP, a close to uniform
                 GCUPS (Giga Cells Updates per Second) was obtained,
                 showing the potential scalability of our approach.
                 Also, CUDAlign was able to compare the human chromosome
                 21 and the chimpanzee chromosome 22. This operation
                 took 21 hours on GeForce GTX 280, resulting in a peak
                 performance of 20.375 GCUPS. As far as we know, this is
                 the first time such huge chromosomes are compared with
                 an exact method.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "biological sequence comparison; GPU; Smith--Waterman",
}

@Article{Hofmeyr:2010:LBS,
  author =       "Steven Hofmeyr and Costin Iancu and Filip
                 Blagojevi{\'c}",
  title =        "Load balancing on speed",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "147--158",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693475",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "To fully exploit multicore processors, applications
                 are expected to provide a large degree of thread-level
                 parallelism. While adequate for low core counts and
                 their typical workloads, the current load balancing
                 support in operating systems may not be able to achieve
                 efficient hardware utilization for parallel workloads.
                 Balancing run queue length globally ignores the needs
                 of parallel applications where threads are required to
                 make equal progress. In this paper we present a load
                 balancing technique designed specifically for parallel
                 applications running on multicore systems. Instead of
                 balancing run queue length, our algorithm balances the
                 time a thread has executed on ``faster'' and ``slower''
                 cores. We provide a user level implementation of speed
                 balancing on UMA and NUMA multi-socket architectures
                 running Linux and discuss behavior across a variety of
                 workloads, usage scenarios and programming models. Our
                 results indicate that speed balancing when compared to
                 the native Linux load balancing improves performance
                 and provides good performance isolation in all cases
                 considered. Speed balancing is also able to provide
                 comparable or better performance than DWRR, a fair
                 multi-processor scheduling implementation inside the
                 Linux kernel. Furthermore, parallel application
                 performance is often determined by the implementation
                 of synchronization operations and speed balancing
                 alleviates the need for tuning the implementations of
                 such primitives.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "load balancing; operating systems; parallel
                 applications",
}

@Article{Hoefler:2010:SCP,
  author =       "Torsten Hoefler and Christian Siebert and Andrew
                 Lumsdaine",
  title =        "Scalable communication protocols for dynamic sparse
                 data exchange",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "159--168",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693476",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Many large-scale parallel programs follow a bulk
                 synchronous parallel (BSP) structure with distinct
                 computation and communication phases. Although the
                 communication phase in such programs may involve all
                 (or large numbers) of the participating processes, the
                 actual communication operations are usually sparse in
                 nature. As a result, communication phases are typically
                 expressed explicitly using point-to-point communication
                 operations or collective operations. We define the
                 dynamic sparse data-exchange (DSDE) problem and derive
                 bounds in the well known LogGP model. While current
                 approaches work well with static applications, they run
                 into limitations as modern applications grow in scale,
                 and as the problems that are being solved become
                 increasingly irregular and dynamic.\par

                 To enable the compact and efficient expression of the
                 communication phase, we develop suitable sparse
                 communication protocols for irregular applications at
                 large scale. We discuss different irregular
                 applications and show the sparsity in the communication
                 for real-world input data. We discuss the time and
                 memory complexity of commonly used protocols for the
                 DSDE problem and develop {\em NBX\/} --a novel fast
                 algorithm with constant memory overhead for solving it.
                 Algorithm {\em NBX\/} improves the runtime of a sparse
                 data-exchange among 8,192 processors on BlueGene/P by a
                 factor of 5.6. In an application study, we show
                 improvements of up to a factor of 28.9 for a parallel
                 breadth first search on 8,192 BlueGene/P processors.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "alltoall; distributed termination; irregular
                 algorithms; nonblocking collective operations; sparse
                 data exchange",
}

@Article{Romein:2010:LCI,
  author =       "John W. Romein and P. Chris Broekema and Jan David Mol
                 and Rob V. van Nieuwpoort",
  title =        "The {LOFAR} correlator: implementation and performance
                 analysis",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "169--178",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693477",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "LOFAR is the first of a new generation of radio
                 telescopes. Rather than using expensive dishes, it
                 forms a distributed sensor network that combines the
                 signals from many thousands of simple antennas. Its
                 revolutionary design allows observations in a frequency
                 range that has hardly been studied before.\par

                 Another novel feature of LOFAR is the elaborate use of
                 {\em software\/} to process data, where traditional
                 telescopes use customized hardware. This dramatically
                 increases flexibility and substantially reduces costs,
                 but the high processing and bandwidth requirements
                 compel the use of a supercomputer. The antenna signals
                 are centrally combined, filtered, optionally
                 beam-formed, and correlated by an IBM Blue
                 Gene/P.\par

                 This paper describes the implementation of the
                 so-called correlator. To meet the real-time
                 requirements, the application is highly optimized, and
                 reaches exceptionally high computational and I/O
                 efficiencies. Additionally, we study the scalability of
                 the system, and show that it scales well beyond the
                 requirements. The optimizations allows us to use only
                 half the planned amount of resources, {\em and\/}
                 process 50\% more telescope data, significantly
                 improving the effectiveness of the entire telescope.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "correlator; IBM Blue Gene/P; LOFAR",
}

@Article{Tzannes:2010:LBS,
  author =       "Alexandros Tzannes and George C. Caragea and Rajeev
                 Barua and Uzi Vishkin",
  title =        "Lazy binary-splitting: a run-time adaptive
                 work-stealing scheduler",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "179--190",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693479",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "We present Lazy Binary Splitting (LBS), a user-level
                 scheduler of nested parallelism for shared-memory
                 multiprocessors that builds on existing Eager Binary
                 Splitting work-stealing (EBS) implemented in Intel's
                 Threading Building Blocks (TBB), but improves
                 performance and ease-of-programming. In its simplest
                 form (SP), EBS requires manual tuning by repeatedly
                 running the application under carefully controlled
                 conditions to determine a {\em stop-splitting-threshold
                 (sst)\/} for every do-all loop in the code. This
                 threshold limits the parallelism and prevents excessive
                 overheads for fine-grain parallelism. Besides being
                 tedious, this tuning also over-fits the code to some
                 particular dataset, platform and calling context of the
                 do-all loop, resulting in poor performance portability
                 for the code. LBS overcomes both the performance
                 portability and ease-of-programming pitfalls of a
                 manually fixed threshold by adapting dynamically to
                 run-time conditions without requiring tuning.\par

                 We compare LBS to Auto-Partitioner (AP), the latest
                 default scheduler of TBB, which does not require manual
                 tuning either but lacks context portability, and
                 outperform it by 38.9\% using TBB's default AP
                 configuration, and by 16.2\% after we tuned AP to our
                 experimental platform. We also compare LBS to SP by
                 manually finding SP's sst using a training dataset and
                 then running both on a different execution dataset. LBS
                 outperforms SP by 19.5\% on average. while allowing for
                 improved performance portability without requiring
                 tedious manual tuning. LBS also outperforms SP with
                 {\em sst=1}, its default value when undefined, by
                 56.7\%, and serializing work-stealing (SWS), another
                 work-stealer by 54.7\%. Finally, compared to
                 serializing inner parallelism (SI) which has been used
                 by OpenMP, LBS is 54.2\% faster.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "dynamic scheduling; load balancing; nested
                 parallelism; thread scheduling; work stealing",
}

@Article{Radojkovic:2010:TSB,
  author =       "Petar Radojkovi{\'c} and Vladimir {\v{C}}akarevi{\'c}
                 and Javier Verd{\'u} and Alex Pajuelo and Francisco J.
                 Cazorla and Mario Nemirovsky and Mateo Valero",
  title =        "Thread to strand binding of parallel network
                 applications in massive multi-threaded systems",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "191--202",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837853.1693480",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "In processors with several levels of hardware resource
                 sharing,like CMPs in which each core is an SMT, the
                 scheduling process becomes more complex than in
                 processors with a single level of resource sharing,
                 such as pure-SMT or pure-CMP processors. Once the
                 operating system selects the set of applications to
                 simultaneously schedule on the processor (workload),
                 each application/thread must be assigned to one of the
                 hardware contexts(strands). We call this last
                 scheduling step the Thread to Strand Binding or TSB. In
                 this paper, we show that the TSB impact on the
                 performance of processors with several levels of shared
                 resources is high. We measure a variation of up to 59\%
                 between different TSBs of real multithreaded network
                 applications running on the UltraSPARC T2 processor
                 which has three levels of resource sharing. In our
                 view, this problem is going to be more acute in future
                 multithreaded architectures comprising more cores, more
                 contexts per core, and more levels of resource
                 sharing.\par

                 We propose a resource-sharing aware TSB algorithm
                 (TSBSched) that significantly facilitates the problem
                 of thread to strand binding for software-pipelined
                 applications, representative of multithreaded network
                 applications. Our systematic approach encapsulates
                 both, the characteristics of multithreaded processors
                 under the study and the structure of the software
                 pipelined applications. Once calibrated for a given
                 processor architecture, our proposal does not require
                 hardware knowledge on the side of the programmer, nor
                 extensive profiling of the application. We validate our
                 algorithm on the UltraSPARC T2 processor running a set
                 of real multithreaded network applications on which we
                 report improvements of up to 46\% compared to the
                 current state-of-the-art dynamic schedulers.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "CMT; process scheduling; simultaneous multithreading;
                 UltraSPARC T2",
}

@Article{Zhang:2010:DCS,
  author =       "Eddy Z. Zhang and Yunlian Jiang and Xipeng Shen",
  title =        "Does cache sharing on modern {CMP} matter to the
                 performance of contemporary multithreaded programs?",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "203--212",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693482",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Most modern Chip Multiprocessors (CMP) feature shared
                 cache on chip. For multithreaded applications, the
                 sharing reduces communication latency among co-running
                 threads, but also results in cache contention.\par

                 A number of studies have examined the influence of
                 cache sharing on multithreaded applications, but most
                 of them have concentrated on the design or management
                 of shared cache, rather than a systematic measurement
                 of the influence. Consequently, prior measurements have
                 been constrained by the reliance on simulators, the use
                 of out-of-date benchmarks, and the limited coverage of
                 deciding factors. The influence of CMP cache sharing on
                 contemporary multithreaded applications remains
                 preliminarily understood.\par

                 In this work, we conduct a systematic measurement of
                 the influence on two kinds of commodity CMP machines,
                 using a recently released CMP benchmark suite, PARSEC,
                 with a number of potentially important factors on
                 program, OS, and architecture levels considered. The
                 measurement shows some surprising results. Contrary to
                 commonly perceived importance of cache sharing, neither
                 positive nor negative effects from the cache sharing
                 are significant for most of the program executions,
                 regardless of the types of parallelism, input datasets,
                 architectures, numbers of threads, and assignments of
                 threads to cores. After a detailed analysis, we find
                 that the main reason is the mismatch of current
                 development and compilation of multithreaded
                 applications and CMP architectures. By transforming the
                 programs in a cache-sharing-aware manner, we observe up
                 to 36\% performance increase when the threads are
                 placed on cores appropriately.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "chip multiprocessors; parallel program optimizations;
                 shared cache; thread scheduling",
}

@Article{Liu:2010:IPL,
  author =       "Lixia Liu and Zhiyuan Li",
  title =        "Improving parallelism and locality with asynchronous
                 algorithms",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "213--222",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837853.1693483",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "As multicore chips become the main building blocks for
                 high performance computers, many numerical applications
                 face a performance impediment due to the limited
                 hardware capacity to move data between the CPU and the
                 off-chip memory. This is especially true for large
                 computing problems solved by iterative algorithms
                 because of the large data set typically used. Loop
                 tiling, also known as loop blocking, was shown
                 previously to be an effective way to enhance data
                 locality, and hence to reduce the memory bandwidth
                 pressure, for a class of iterative algorithms executed
                 on a single processor. Unfortunately, the tiled
                 programs suffer from reduced parallelism because only
                 the loop iterations within a single tile can be easily
                 parallelized. In this work, we propose to use the
                 asynchronous model to enable effective loop tiling such
                 that both parallelism and locality can be attained
                 simultaneously. Asynchronous algorithms were previously
                 proposed to reduce the communication cost and
                 synchronization overhead between processors. Our new
                 discovery is that carefully controlled asynchrony and
                 loop tiling can significantly improve the performance
                 of parallel iterative algorithms on multicore
                 processors due to simultaneously attained data locality
                 and loop-level parallelism. We present supporting
                 evidence from experiments with three well-known
                 numerical kernels.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "asynchronous algorithms; data locality; loop tiling;
                 memory performance; parallel numerical programs",
}

@Article{Castaldo:2010:SLP,
  author =       "Anthony M. Castaldo and R. Clint Whaley",
  title =        "Scaling {LAPACK} panel operations using parallel cache
                 assignment",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "223--232",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693484",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "In LAPACK many matrix operations are cast as block
                 algorithms which iteratively process a panel using an
                 unblocked algorithm and then update a remainder matrix
                 using the high performance Level 3 BLAS. The Level~3
                 BLAS have excellent weak scaling, but panel processing
                 tends to be bus bound, and thus scales with bus speed
                 rather than the number of processors ({\em p\/}).
                 Amdahl's law therefore ensures that as {\em p\/} grows,
                 the panel computation will become the dominant cost of
                 these LAPACK routines. Our contribution is a novel
                 parallel cache assignment approach which we show scales
                 well with {\em p}. We apply this general approach to
                 the QR and LU panel factorizations on two commodity
                 8-core platforms with very different cache structures,
                 and demonstrate superlinear panel factorization
                 speedups on both machines. Other approaches to this
                 problem demand complicated reformulations of the
                 computational approach, new kernels to be tuned, new
                 mathematics, an inflation of the high-order flop count,
                 and do not perform as well. By demonstrating a
                 straight-forward alternative that avoids all of these
                 contortions and scales with {\em p}, we address a
                 critical stumbling block for dense linear algebra in
                 the age of massive parallelism.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "Atlas; factorization; GPU; LAPACK; LU; multicore;
                 multi-core; parallel; QR",
}

@Article{Sutherland:2010:CTC,
  author =       "Dean F. Sutherland and William L. Scherlis",
  title =        "Composable thread coloring",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "233--244",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693485",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "This paper introduces the language-independent concept
                 of ``thread usage policy.'' Many multi-threaded
                 software systems contain policies that regulate
                 associations among threads, executable code, and
                 potentially shared state. A system, for example, may
                 constrain which threads are permitted to execute
                 particular code segments, usually as a means to
                 constrain those threads from accessing or writing
                 particular elements of state. These policies ensure
                 properties such as state confinement or reader/writer
                 constraints, often without recourse to locking or
                 transaction discipline.\par

                 Our approach allows developers to concisely document
                 their thread usage policies in a manner that enables
                 the use of sound scalable analysis to assess
                 consistency of policy and as-written code. This paper
                 identifies the key semantic concepts of our thread
                 coloring language and illustrates how to use its
                 succinct source-level annotations to express models of
                 thread usage policies, following established annotation
                 conventions for Java.\par

                 We have built a prototype static analysis tool,
                 implemented as an integrated development environment
                 plug-in (for the Eclipse IDE), that notifies developers
                 of discrepancies between policy annotations and
                 as-written code. Our analysis technique uses several
                 underlying algorithms based on abstract interpretation,
                 call-graphs, and type inference. The resulting overall
                 analysis is both sound and composable. We have used
                 this prototype analysis tool in case studies to model
                 and analyze more than a million lines of code.\par

                 Our validation process included field trials on a wide
                 variety of complex large-scale production code selected
                 by the host organizations. Our in-field experience led
                 us to focus on potential adoptability by real-world
                 developers. We have developed techniques that can
                 reduce annotation density to less than one line per
                 thousand lines of code (KLOC). In addition, the
                 prototype analysis tool supports an incremental and
                 iterative approach to modeling and analysis. This
                 approach enabled field trial partners to directly
                 target areas of greatest concern and to achieve useful
                 results within a few hours.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "annotation; Java; keywords: state consistency;
                 multicore; race conditions; state confinement; thread
                 policy",
}

@Article{Agrawal:2010:HLF,
  author =       "Kunal Agrawal and Charles E. Leiserson and Jim Sukha",
  title =        "Helper locks for fork-join parallel programming",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "245--256",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693487",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Helper locks allow programs with large parallel
                 critical sections, called parallel regions, to execute
                 more efficiently by enlisting processors that might
                 otherwise be waiting on the helper lock to aid in the
                 execution of the parallel region. Suppose that a
                 processor {\em p\/} is executing a parallel region {\em
                 A\/} after having acquired the lock {\em L\/}
                 protecting {\em A}. If another processor {\em p\/}
                 $\prime$ tries to acquire {\em L}, then instead of
                 blocking and waiting for {\em p\/} to complete {\em A},
                 processor {\em p\/} $\prime$ joins {\em p\/} to help it
                 complete {\em A}. Additional processors not blocked on
                 {\em L\/} may also help to execute {\em A}.\par

                 The HELPER runtime system can execute fork-join
                 computations augmented with helper locks and parallel
                 regions. HELPER supports the unbounded nesting of
                 parallel regions. We provide theoretical
                 completion-time and space-usage bounds for a design of
                 HELPER based on work stealing. Specifically, let {\em
                 V\/} be the number of parallel regions in a
                 computation, let {\em T\/}$_1$ be its work, and let
                 {\em T\/} $\infty$ be its `aggregate span' --- the sum
                 of the spans (critical-path lengths) of all its
                 parallel regions. We prove that HELPER completes the
                 computation in expected time {\em O\/} ({\em T\/}$_1$ /
                 {\em P\/} P + {\em T\/} $\infty$+ {\em PV\/}) on {\em
                 P\/} processors. This bound indicates that programs
                 with a small number of highly parallel critical
                 sections can attain linear speedup. For the space
                 bound, we prove that HELPER completes a program using
                 only $O(P S_1)$ stack space, where $S_1$ is the sum,
                 over all regions, of the stack space used by each
                 region in a serial execution. Finally, we describe a
                 prototype of HELPER implemented by modifying the Cilk
                 multithreaded runtime system. We used this prototype to
                 implement a concurrent hash table with a resize
                 operation protected by a helper lock.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "Cilk; dynamic multithreading; helper lock; nested
                 parallelism; parallel region; scheduling; work
                 stealing",
}

@Article{Bronson:2010:PCB,
  author =       "Nathan G. Bronson and Jared Casper and Hassan Chafi
                 and Kunle Olukotun",
  title =        "A practical concurrent binary search tree",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "257--268",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693488",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "We propose a concurrent relaxed balance AVL tree
                 algorithm that is fast, scales well, and tolerates
                 contention. It is based on optimistic techniques
                 adapted from software transactional memory, but takes
                 advantage of specific knowledge of the algorithm to
                 reduce overheads and avoid unnecessary retries. We
                 extend our algorithm with a fast linearizable clone
                 operation, which can be used for consistent iteration
                 of the tree. Experimental evidence shows that our
                 algorithm outperforms a highly tuned concurrent skip
                 list for many access patterns, with an average of 39\%
                 higher single-threaded throughput and 32\% higher
                 multi-threaded throughput over a range of contention
                 levels and operation mixes.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "optimistic concurrency; snapshot isolation",
}

@Article{Tallent:2010:ALC,
  author =       "Nathan R. Tallent and John M. Mellor-Crummey and Allan
                 Porterfield",
  title =        "Analyzing lock contention in multithreaded
                 applications",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "269--280",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693489",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Many programs exploit shared-memory parallelism using
                 multithreading. Threaded codes typically use locks to
                 coordinate access to shared data. In many cases,
                 contention for locks reduces parallel efficiency and
                 hurts scalability. Being able to quantify and attribute
                 lock contention is important for understanding where a
                 multithreaded program needs improvement.\par

                 This paper proposes and evaluates three strategies for
                 gaining insight into performance losses due to lock
                 contention. First, we consider using a straightforward
                 strategy based on call stack profiling to attribute
                 idle time and show that it fails to yield insight into
                 lock contention. Second, we consider an approach that
                 builds on a strategy previously used for analyzing
                 idleness in work-stealing computations; we show that
                 this strategy does not yield insight into lock
                 contention. Finally, we propose a new technique for
                 measurement and analysis of lock contention that uses
                 data associated with locks to blame lock holders for
                 the idleness of spinning threads. Our approach incurs
                 $\leq$ 5\% overhead on a quantum chemistry application
                 that makes extensive use of locking (65M distinct
                 locks, a maximum of 340K live locks, and an average of
                 30K lock acquisitions per second per thread) and
                 attributes lock contention to its full static and
                 dynamic calling contexts. Our strategy, implemented in
                 HPCToolkit, is fully distributed and should scale well
                 to systems with large core counts.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "HPCToolkit; lock contention; multithreading;
                 performance analysis",
}

@Article{Upadhyaya:2010:UDS,
  author =       "Gautam Upadhyaya and Samuel P. Midkiff and Vijay S.
                 Pai",
  title =        "Using data structure knowledge for efficient lock
                 generation and strong atomicity",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "281--292",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693490",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "To achieve high-performance on multicore systems,
                 sharedmemory parallel languages must efficiently
                 implement atomic operations. The commonly used and
                 studied paradigms for atomicity are fine-grained
                 locking, which is both difficult to program and
                 error-prone; optimistic software transactions, which
                 require substantial overhead to detect and recover from
                 atomicity violations; and compiler-generation of locks
                 from programmer-specified atomic sections, which leads
                 to serialization whenever imprecise pointer analysis
                 suggests the mere possibility of a conflicting
                 operation. This paper presents a new strategy for
                 compiler-generated locking that uses data structure
                 knowledge to facilitate more precise alias and lock
                 generation analyses and reduce unnecessary
                 serialization. Implementing and evaluating these ideas
                 in the Java language shows that the new strategy
                 achieves eight-thread speedups of 0.83 to 5.9 for the
                 five STAMP benchmarks studied, outperforming software
                 transactions on all but one benchmark, and nearly
                 matching programmer-specified fine-grained locks on all
                 but one benchmark. The results also indicate that
                 compiler knowledge of data structures improves the
                 effectiveness of compiler analysis, boosting
                 eight-thread performance by up to 300\%. Further, the
                 new analysis allows for software support of strong
                 atomicity with less than 1\% overhead for two
                 benchmarks and less than 20\% for three others. The
                 strategy also nearly matches the performance of
                 programmer-specified fine-grained locks for the
                 SPECjbb2000 benchmark, which has traditionally not been
                 amenable to static analyses.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "automatic lock generation; parallel programming;
                 transactional memory",
}

@Article{Ali:2010:MAC,
  author =       "Qasim Ali and Samuel Pratt Midkiff and Vijay S. Pai",
  title =        "Modeling advanced collective communication algorithms
                 on {Cell}-based systems",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "293--304",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693492",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "This paper presents and validates performance models
                 for a variety of high-performance collective
                 communication algorithms for systems with Cell
                 processors. The systems modeled include a single Cell
                 processor, two Cell chips on a Cell Blade, and a
                 cluster of Cell Blades. The models extend PLogP, the
                 well-known point-to-point performance model, by
                 accounting for the unique hardware characteristics of
                 the Cell (e.g., heterogeneous interconnects and DMA
                 engines) and by applying the model to collective
                 communication. This paper also presents a
                 micro-benchmark suite to accurately measure the
                 extended PLogP parameters on the Cell Blade and then
                 uses these parameters to model different algorithms for
                 the {\em barrier, broadcast, reduce, all-reduce}, and
                 {\em all-gather\/} collective operations. Out of 425
                 total performance predictions, 398 of them see less
                 than 10\% error compared to the actual execution time
                 and all of them see less than 15\%.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "algorithms; collective communication; modeling",
}

@Article{Zhai:2010:PPP,
  author =       "Jidong Zhai and Wenguang Chen and Weimin Zheng",
  title =        "{PHANTOM}: predicting performance of parallel
                 applications on large-scale parallel machines using a
                 single node",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "305--314",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693493",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "For designers of large-scale parallel computers, it is
                 greatly desired that performance of parallel
                 applications can be predicted at the design phase.
                 However, this is difficult because the execution time
                 of parallel applications is determined by several
                 factors, including sequential computation time in each
                 process, communication time and their convolution.
                 Despite previous efforts, it remains an open problem to
                 estimate sequential computation time in each process
                 accurately and efficiently for large-scale parallel
                 applications on non-existing target machines.\par

                 This paper proposes a novel approach to predict the
                 sequential computation time accurately and efficiently.
                 We assume that there is at least one node of the target
                 platform but the whole target system need not be
                 available. We make two main technical contributions.
                 First, we employ deterministic replay techniques to
                 execute any process of a parallel application on a
                 single node at real speed. As a result, we can simply
                 measure the real sequential computation time on a
                 target node for each process one by one. Second, we
                 observe that computation behavior of processes in
                 parallel applications can be clustered into a few
                 groups while processes in each group have similar
                 computation behavior. This observation helps us reduce
                 measurement time significantly because we only need to
                 execute representative parallel processes instead of
                 all of them.\par

                 We have implemented a performance prediction framework,
                 called PHANTOM, which integrates the above
                 computation-time acquisition approach with a
                 trace-driven network simulator. We validate our
                 approach on several platforms. For ASCI Sweep3D, the
                 error of our approach is less than 5\% on 1024
                 processor cores. Compared to a recent regression-based
                 prediction approach, PHANTOM presents better prediction
                 accuracy across different platforms.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "deterministic replay; parallel application;
                 performance prediction; trace-driven simulation",
}

@Article{Aleen:2010:IDD,
  author =       "Farhana Aleen and Monirul Sharif and Santosh Pande",
  title =        "Input-driven dynamic execution prediction of streaming
                 applications",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "315--324",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837853.1693494",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Streaming applications are promising targets for
                 effectively utilizing multicores because of their
                 inherent amenability to pipelined parallelism. While
                 existing methods of orchestrating streaming programs on
                 multicores have mostly been static, real-world
                 applications show ample variations in execution time
                 that may cause the achieved speedup and throughput to
                 be sub-optimal. One of the principle challenges for
                 moving towards dynamic orchestration has been the lack
                 of approaches that can predict or accurately estimate
                 upcoming dynamic variations in execution efficiently,
                 well before they occur.\par

                 In this paper, we propose an automated dynamic
                 execution behavior prediction approach that can be used
                 to efficiently estimate the time that will be spent in
                 different pipeline stages for upcoming inputs without
                 requiring program execution. This enables dynamic
                 balancing or scheduling of execution to achieve better
                 speedup. Our approach first uses dynamic taint analysis
                 to automatically generates an input-based execution
                 characterization of the streaming program, which
                 identifies the key control points where variation in
                 execution might occur with the associated input
                 elements that cause these variations. We then
                 automatically generate a light-weight emulator from the
                 program using this characterization that can simulate
                 the execution paths taken for new streaming inputs and
                 provide an estimate of execution time that will be
                 spent in processing these inputs, enabling prediction
                 of possible dynamic variations. We present experimental
                 evidence that our technique can accurately and
                 efficiently estimate execution behaviors for several
                 benchmarks. Our experiments show that dynamic
                 orchestration using our predicted execution behavior
                 can achieve considerably higher speedup than static
                 orchestration.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "dynamic execution; parallelization; software
                 pipeline",
}

@Article{Lupei:2010:TST,
  author =       "Daniel Lupei and Bogdan Simion and Don Pinto and
                 Matthew Misler and Mihai Burcea and William Krick and
                 Cristiana Amza",
  title =        "Towards scalable and transparent parallelization of
                 multiplayer games using transactional memory support",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "325--326",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837853.1693496",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "This work addresses the problem of parallelizing
                 multiplayer games using {\em software\/} Transactional
                 Memory (STM) support. Using a realistic high impact
                 application, we show that STM provides not only ease of
                 programming, but also {\em better\/} performance than
                 that achievable with state-of-the-art lock-based
                 programming.\par

                 Towards this goal, we use SynQuake, a game benchmark
                 which extracts the main data structures and the
                 essential features of the popular multiplayer game
                 Quake, but can be driven with a synthetic workload
                 generator that flexibly emulates client game actions
                 and various hot-spot scenarios in the game
                 world.\par

                 We implement, evaluate and compare the STM version of
                 SynQuake with a state-of-the-art lock-based
                 parallelization of Quake, which we ported to SynQuake.
                 While in STM-SynQuake support for maintaining the
                 consistency of each potentially complex game action is
                 automatic, conservative locking of surrounding objects
                 within a bounding box for the duration of the game
                 action is inherently needed in lock-based SynQuake.
                 This leads to a higher scalability factor of
                 STM-SynQuake versus lock-based SynQuake, due to a
                 higher degree of false sharing in the latter.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "massively multiplayer games; scalability; software
                 transactional memory; synchronization",
}

@Article{Perarnau:2010:KRC,
  author =       "Swann Perarnau and Guillaume Huard",
  title =        "{KRASH}: reproducible {CPU} load generation on many
                 cores machines",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "327--328",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837853.1693497",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "In this article we present KRASH, a tool for
                 reproducible generation of system-level CPU load. This
                 tool is intended for use in shared memory machines
                 equipped with multiple CPU cores which are usually
                 exploited concurrently by several users. The objective
                 of KRASH is to enable parallel application developers
                 to validate their resources use strategies on a
                 partially loaded machine by {\em replaying\/} an
                 observed load in concurrence with their application. To
                 reach this objective, we present a method for CPU load
                 generation which behaves as realistically as possible:
                 the resulting load is similar to the load that would be
                 produced by concurrent processes run by other users.
                 Nevertheless, contrary to a simple run of a
                 CPU-intensive application, KRASH is not sensitive to
                 system scheduling decisions. The main benefit brought
                 by KRASH is this reproducibility: no matter how many
                 processes are present in the system the load generated
                 by our tool strictly respects a given load profile. To
                 our knowledge, KRASH is the only tool that implements
                 the generation of a dynamic load profile (a load
                 varying with time). When used to generate a constant
                 load, KRASH result is among the most realistic ones.
                 Furthermore, KRASH provides more flexibility than other
                 tools.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "CPU load generation; experimentation testbed; many
                 cores",
}

@Article{Muralidhara:2010:IAS,
  author =       "Sai Prashanth Muralidhara and Mahmut Kandemir and
                 Padma Raghavan",
  title =        "Intra-application shared cache partitioning for
                 multithreaded applications",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "329--330",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837853.1693498",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "In this paper, we address the problem of partitioning
                 a shared cache when the executing threads belong to the
                 same application.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "cache; multicore; parallel applications",
}

@Article{Dash:2010:SPT,
  author =       "Alokika Dash and Brian Demsky",
  title =        "Symbolic prefetching in transactional distributed
                 shared memory",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "331--332",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837853.1693499",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "We present a static analysis for the automatic
                 generation of symbolic prefetches in a transactional
                 distributed shared memory. A symbolic prefetch
                 specifies the first object to be prefetched followed by
                 a list of field offsets or array indices that define a
                 path through the heap. We also provide an object
                 caching framework and language extensions to support
                 our approach. To our knowledge, this is the first
                 prefetching approach that can prefetch objects whose
                 addresses have not been computed or predicted.\par

                 Our approach makes aggressive use of both prefetching
                 and caching of remote objects to hide network latency.
                 It relies on the transaction commit mechanism to
                 preserve the simple transactional consistency model
                 that we present to the developer. We have evaluated
                 this approach on several shared memory parallel
                 benchmarks and a distributed gaming benchmark to
                 observe speedups due to prefetching and caching.
                 Categories and Subject Descriptors",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "distributed shared memory; symbolic prefetching;
                 transactional memory",
}

@Article{Chakrabarti:2010:NAE,
  author =       "Dhruva R. Chakrabarti",
  title =        "New abstractions for effective performance analysis of
                 {STM} programs",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "333--334",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837853.1693500",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "We present the design and implementation of a dynamic
                 conflict graph annotated with fine grain transaction
                 characteristics and show that this is important
                 information for effective performance analysis of a
                 software transactional memory (STM) program. We show
                 how to implement the necessary support in a compiler
                 and an STM with minimal perturbation of the original
                 behavior of the application.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "concurrency; software transactional memory",
}

@Article{Zhang:2010:CSP,
  author =       "Chao Zhang and Chen Ding and Xiaoming Gu and Kirk
                 Kelsey and Tongxin Bai and Xiaobing Feng",
  title =        "Continuous speculative program parallelization in
                 software",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "335--336",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693501",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "This paper addresses the problem of extracting
                 coarse-grained parallelism from large sequential code.
                 It builds on BOP, a system for software speculative
                 parallelization. BOP lets a user to mark possibly
                 parallel regions (PPR) in a program and at run-time
                 speculatively executes PPR instances using Unix
                 processes. This short paper presents a new run-time
                 support called continuous speculation, which fully
                 utilizes available parallelism to tolerate differences
                 in PPR task size and processor speed.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "software speculative parallelization",
}

@Article{Marjanovic:2010:ECC,
  author =       "Vladimir Marjanovic and Jes{\'u}s Labarta and Eduard
                 Ayguad{\'e} and Mateo Valero",
  title =        "Effective communication and computation overlap with
                 hybrid {MPI\slash SMPSs}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "337--338",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837853.1693502",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Communication overhead is one of the dominant factors
                 affecting performance in high-performance computing
                 systems. To reduce the negative impact of
                 communication, programmers overlap communication and
                 computation by using asynchronous communication
                 primitives. This increases code complexity, requiring
                 more development effort and making less readable
                 programs. This paper presents the hybrid use of MPI and
                 SMPSs (SMP superscalar, a task-based shared-memory
                 programming model) that allows the programmer to easily
                 introduce the asynchrony necessary to overlap
                 communication and computation. We demonstrate the
                 hybrid use of MPI/SMPSs with the high-performance
                 LINPACK benchmark (HPL), and compare it to the pure MPI
                 implementation, which uses the look-ahead technique to
                 overlap communication and computation. The hybrid
                 MPI/SMPSs version significantly improves the
                 performance of the pure MPI version, getting close to
                 the asymptotic performance at medium problem sizes and
                 still getting significant benefits at small/large
                 problem sizes.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "hybrid MPI/SMPSs; LINPACK; MPI; parallel programming
                 model",
}

@Article{Cederman:2010:SLF,
  author =       "Daniel Cederman and Philippas Tsigas",
  title =        "Supporting lock-free composition of concurrent data
                 objects",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "339--340",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1693453.1693503",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Lock-free data objects offer several advantages over
                 their blocking counterparts, such as being immune to
                 deadlocks and convoying and, more importantly, being
                 highly concurrent. But they share a common disadvantage
                 in that the operations they provide are difficult to
                 compose into larger atomic operations while still
                 guaranteeing lock-freedom. We present a lock-free
                 methodology for composing highly concurrent
                 linearizable objects together by unifying their
                 linearization points. This makes it possible to
                 relatively easily introduce atomic lock-free move
                 operations to a wide range of concurrent objects.
                 Experimental evaluation has shown that the operations
                 originally supported by the data objects keep their
                 performance behavior under our methodology.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "composition; data structures; lock-free",
}

@Article{Guo:2010:SSL,
  author =       "Yi Guo and Jisheng Zhao and Vincent Cave and Vivek
                 Sarkar",
  title =        "{SLAW}: a scalable locality-aware adaptive
                 work-stealing scheduler for multi-core systems",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "341--342",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837853.1693504",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "This poster introduces SLAW, a Scalable Locality-aware
                 Adaptive Work-stealing scheduler. The SLAW features an
                 adaptive task scheduling algorithm combined with a
                 locality-aware scheduling framework.\par

                 Past work has demonstrated the pros and cons of using
                 fixed scheduling policies, such as {\em work-first\/}
                 and {\em help-first}, in different cases without a
                 clear winner. Prior work also assumes the availability
                 and successful execution of a serial version of the
                 parallel program. This assumption can limit the
                 expressiveness of dynamic task parallel
                 languages.\par

                 The SLAW scheduler supports both work-first and
                 help-first policies simultaneously. It does so by using
                 an {\em adaptive\/} approach that selects a scheduling
                 policy on a per-task basis at runtime. The SLAW
                 scheduler also establishes bounds on the stack usage
                 and the heap space needed to store tasks. The
                 experimental results for the benchmarks studied show
                 that SLAW's adaptive scheduler achieves 0.98x - 9.2x
                 speedup over the help-first scheduler and 0.97x - 4.5x
                 speedup over the work-first scheduler for 64-thread
                 executions, thereby establishing the robustness of
                 using an adaptive approach instead of a fixed policy.
                 In contrast, the help-first policy is 9.2x slower than
                 work-first in the worst case for a fixed help-first
                 policy, and the work-first policy is 3.7x slower than
                 help-first in the worst case for a fixed work-first
                 policy. Further, for large irregular recursive parallel
                 computations, the adaptive scheduler runs with bounded
                 stack usage and achieves performance (and supports data
                 sizes) that cannot be delivered by the use of any
                 single fixed policy.\par

                 The SLAW scheduler is designed for programming models
                 where locality hints are provided to the runtime by the
                 programmer or compiler, and achieves {\em
                 locality-awareness\/} by grouping workers into {\em
                 places}. Locality awareness can lead to improved
                 performance by increasing temporal data reuse within a
                 worker and among workers in the same place. Our
                 experimental results show that locality-aware
                 scheduling can achieve up to 2.6x speedup over
                 locality-oblivious scheduling, for the benchmarks
                 studied.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "help-first; work-first; work-stealing",
}

@Article{Yang:2010:OCG,
  author =       "Yi Yang and Ping Xiang and Jingfei Kong and Huiyang
                 Zhou",
  title =        "An optimizing compiler for {GPGPU} programs with
                 input-data sharing",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "343--344",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837853.1693505",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Developing high performance GPGPU programs is
                 challenging for application developers since the
                 performance is dependent upon how well the code
                 leverages the hardware features of specific graphics
                 processors. To solve this problem and relieve
                 application developers of low-level hardware-specific
                 optimizations, we introduce a novel compiler to
                 optimize GPGPU programs. Our compiler takes a naive GPU
                 kernel function, which is functionally correct but
                 without any consideration for performance optimization.
                 The compiler then analyzes the code, identifies memory
                 access patterns, and generates optimized code. The
                 proposed compiler optimizations target at one category
                 of scientific and media processing algorithms, which
                 has the characteristics of input-data sharing when
                 computing neighboring output pixels/elements. Many
                 commonly used algorithms, such as matrix
                 multiplication, convolution, etc., share such
                 characteristics. For these algorithms, novel approaches
                 are proposed to enforce memory coalescing and achieve
                 effective data reuse. Data prefetching and
                 hardware-specific tuning are also performed
                 automatically with our compiler framework. The
                 experimental results based on a set of applications
                 show that our compiler achieves very high performance,
                 either superior or very close to the highly fine-tuned
                 library, NVIDIA CUBLAS 2.1.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "compiler; GPGPU",
}

@Article{Chandramowlishwaran:2010:ACC,
  author =       "Aparna Chandramowlishwaran and Kathleen Knobe and
                 Richard Vuduc",
  title =        "Applying the concurrent collections programming model
                 to asynchronous parallel dense linear algebra",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "345--346",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837853.1693506",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "This poster is a case study on the application of a
                 novel programming model, called Concurrent Collections
                 (CnC), to the implementation of an
                 asynchronous-parallel algorithm for computing the
                 Cholesky factorization of dense matrices. In CnC, the
                 programmer expresses her computation in terms of
                 application-specific operations, partially-ordered by
                 semantic scheduling constraints. We demonstrate the
                 performance potential of CnC in this poster, by showing
                 that our Cholesky implementation nearly matches or
                 exceeds competing vendor-tuned codes and alternative
                 programming models. We conclude that the CnC model is
                 well-suited for expressing asynchronous-parallel
                 algorithms on emerging multicore systems.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "asynchronous algorithms; concurrent collections; dense
                 linear algebra",
}

@Article{Hoffmann:2010:AHS,
  author =       "Henry Hoffmann and Jonathan Eastep and Marco D.
                 Santambrogio and Jason E. Miller and Anant Agarwal",
  title =        "Application heartbeats for software performance and
                 health",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "347--348",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837853.1693507",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Adaptive, or self-aware, computing has been proposed
                 to help application programmers confront the growing
                 complexity of multicore software development. However,
                 existing approaches to adaptive systems are largely ad
                 hoc and often do not manage to incorporate the true
                 performance goals of the applications they are designed
                 to support. This paper presents an enabling technology
                 for adaptive computing systems: Application Heartbeats.
                 The Application Heartbeats framework provides a simple,
                 standard programming interface that applications can
                 use to indicate their performance and system software
                 (and hardware) can use to query an application's
                 performance. The PARSEC benchmark suite is instrumented
                 with Application Heartbeats to show the broad
                 applicability of the interface and an external resource
                 scheduler demonstrates the use of the interface by
                 assigning cores to an application to maintain a
                 designated performance goal.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "adaptive algorithms",
}

@Article{Porter:2010:MTM,
  author =       "Donald E. Porter and Emmett Witchel",
  title =        "Modeling transactional memory workload performance",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "349--350",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837853.1693508",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Transactional memory promises to make parallel
                 programming easier than with fine-grained locking,
                 while performing just as well. This performance claim
                 is not always borne out because an application may
                 violate a common-case assumption of the TM designer or
                 because of external system effects. In order to help
                 programmers assess the suitability of their code for
                 transactional memory, this work introduces a formal
                 model of transactional memory as well as a tool, called
                 Syncchar. Syncchar can predict the speedup of a
                 conversion from locks to transactions within 25\% for
                 the STAMP benchmarks. Because getting good performance
                 from transactions is more difficult than commonly
                 appreciated, developers need tools to tune
                 transactional performance.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "performance; syncchar; transactional memory",
}

@Article{Carter:2010:PLN,
  author =       "John D. Carter and William B. Gardner and Gary
                 Grewal",
  title =        "The {Pilot} library for novice {MPI} programmers",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "351--352",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837853.1693509",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "The Pilot library is a new method for programming
                 MPI-enabled clusters in C, targeted at novice parallel
                 programmers. Formal elements from Communicating
                 Sequential Processes (CSP) are used to realize a
                 process/channel model of parallel computation that
                 reduces opportunities for deadlock and other
                 communication errors. This simple model, plus an
                 application programming inter-face (API) styled after
                 C's formatted I/O, are designed to make the library
                 easy to learn. The Pilot library exists as a thin layer
                 on top of any standard Message Passing Interface (MPI)
                 implementation, preserving MPI's portability and
                 efficiency, with little performance overhead arising as
                 result of Pilot's additional features.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "C; cluster programming; collective operations;
                 deadlock detection; high-performance computing; MPI",
}

@Article{Jang:2010:DTE,
  author =       "Byunghyun Jang and Perhaad Mistry and Dana Schaa and
                 Rodrigo Dominguez and David Kaeli",
  title =        "Data transformations enabling loop vectorization on
                 multithreaded data parallel architectures",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "353--354",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837853.1693510",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Loop vectorization, a key feature exploited to obtain
                 high performance on Single Instruction Multiple Data
                 (SIMD) vector architectures, is significantly hindered
                 by irregular memory access patterns in the data stream.
                 This paper describes data transformations that allow us
                 to vectorize loops targeting massively multithreaded
                 data parallel architectures. We present a mathematical
                 model that captures loop-based memory access patterns
                 and computes the most appropriate data transformations
                 in order to enable vectorization. Our experimental
                 results show that the proposed data transformations can
                 significantly increase the number of loops that can be
                 vectorized and enhance the data-level parallelism of
                 applications. Our results also show that the overhead
                 associated with our data transformations can be easily
                 amortized as the size of the input data set increases.
                 For the set of high performance benchmark kernels
                 studied, we achieve consistent and significant
                 performance improvements (up to 11.4X) by applying
                 vectorization using our data transformation approach.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "data transformation; GPGPU; loop vectorization",
}

@Article{Buehrer:2010:DPS,
  author =       "Gregory Buehrer and Srinivasan Parthasarathy and
                 Shirish Tatikonda",
  title =        "A distributed placement service for graph-structured
                 and tree-structured data",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "355--356",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837853.1693511",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Effective data placement strategies can enhance the
                 performance of data-intensive applications implemented
                 on high end computing clusters. Such strategies can
                 have a significant impact in localizing the
                 computation, in minimizing synchronization
                 (communication) costs, in enhancing reliability (via
                 strategic replication policies), and in ensuring a
                 balanced workload or enhancing the available bandwidth
                 from massive storage devices (e.g. disk
                 arrays).\par

                 Existing work has largely targeted the placement of
                 relatively simple data types or entities (e.g.
                 elements, vectors, sets, and arrays). Here we
                 investigate several hash-based distributed data
                 placement methods targeting tree- and graph- structured
                 data, and develop a locality enhancing placement
                 service for large cluster systems. Target applications
                 include the placement of a single large graph (e.g. Web
                 graph), a single large tree (e.g. large XML file), a
                 forest of graphs or trees (e.g. XML database) and other
                 specialized graph data types - bi-partite (query-click
                 graphs), directed acyclic graphs etc. We empirically
                 evaluate our service by demonstrating its use in
                 improving mining executions for pattern discovery,
                 nearest neighbor searching, graph computations, and
                 applications that combine link and content analysis.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "data placement; distributed computing; structured
                 data",
}

@Article{Li:2010:SVC,
  author =       "Guodong Li and Ganesh Gopalakrishnan and Robert M.
                 Kirby and Dan Quinlan",
  title =        "A symbolic verifier for {CUDA} programs",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "5",
  pages =        "357--358",
  month =        may,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837853.1693512",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue Aug 31 22:39:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "We present a preliminary automated verifier based on
                 mechanical decision procedures which is able to prove
                 functional correctness of CUDA programs and guarantee
                 to detect bugs such as race conditions. We also employ
                 a symbolic partial order reduction (POR) technique to
                 mitigate the interleaving explosion problem.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "cuda; formal verification; spmd; symbolic analysis",
}

@Article{Richards:2010:ADB,
  author =       "Gregor Richards and Sylvain Lebresne and Brian Burg
                 and Jan Vitek",
  title =        "An analysis of the dynamic behavior of {JavaScript}
                 programs",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "1--12",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806596.1806598",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "The JavaScript programming language is widely used for
                 web programming and, increasingly, for general purpose
                 computing. As such, improving the correctness, security
                 and performance of JavaScript applications has been the
                 driving force for research in type systems, static
                 analysis and compiler techniques for this language.
                 Many of these techniques aim to reign in some of the
                 most dynamic features of the language, yet little seems
                 to be known about how programmers actually utilize the
                 language or these features. In this paper we perform an
                 empirical study of the dynamic behavior of a corpus of
                 widely-used JavaScript programs, and analyze how and
                 why the dynamic features are used. We report on the
                 degree of dynamism that is exhibited by these
                 JavaScript programs and compare that with assumptions
                 commonly made in the literature and accepted industry
                 benchmark suites.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "dynamic behavior; dynamic metrics; execution tracing;
                 javascript; program analysis",
}

@Article{Bond:2010:BEC,
  author =       "Michael D. Bond and Graham Z. Baker and Samuel Z.
                 Guyer",
  title =        "{Breadcrumbs}: efficient context sensitivity for
                 dynamic bug detection analyses",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "13--24",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1809028.1806599",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Calling context--the set of active methods on the
                 stack--is critical for understanding the dynamic
                 behavior of large programs. Dynamic program analysis
                 tools, however, are almost exclusively context
                 insensitive because of the prohibitive cost of
                 representing calling contexts at run time. Deployable
                 dynamic analyses, in particular, have been limited to
                 reporting only static program locations.\par

                 This paper presents Breadcrumbs, an efficient technique
                 for recording and reporting dynamic calling contexts.
                 It builds on an existing technique for computing a
                 compact (one word) encoding of each calling context
                 that client analyses can use in place of a program
                 location. The key feature of our system is a search
                 algorithm that can reconstruct a calling context from
                 its encoding using only a static call graph and a small
                 amount of dynamic information collected at cold
                 (infrequently executed) callsites. Breadcrumbs requires
                 no offline training or program modifications, and
                 handles all language features, including dynamic class
                 loading.\par

                 We use Breadcrumbs to add context sensitivity to two
                 dynamic analyses: a data-race detector and an analysis
                 for diagnosing null pointer exceptions. On average, it
                 adds 10\% to 20\% runtime overhead, depending on a
                 tunable parameter that controls how much dynamic
                 information is collected. Collecting less information
                 lowers the overhead, but can result in a search space
                 explosion. In some cases this causes reconstruction to
                 fail, but in most cases Breadcrumbs >produces
                 non-trivial calling contexts that have the potential to
                 significantly improve both the precision of the
                 analyses and the quality of the bug reports.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "bug detection; context sensitivity; dynamic analysis",
}

@Article{Ruwase:2010:DLE,
  author =       "Olatunji Ruwase and Shimin Chen and Phillip B. Gibbons
                 and Todd C. Mowry",
  title =        "Decoupled lifeguards: enabling path optimizations for
                 dynamic correctness checking tools",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "25--35",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806596.1806600",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Dynamic correctness checking tools (a.k.a. lifeguards)
                 can detect a wide array of correctness issues, such as
                 memory, security, and concurrency misbehavior, in
                 unmodified executables at run time. However, lifeguards
                 that are implemented using dynamic binary
                 instrumentation (DBI) often slow down the monitored
                 application by 10-50X, while proposals that replace DBI
                 with hardware still see 3-8X slowdowns. The remaining
                 overhead is the cost of performing the lifeguard
                 analysis itself. In this paper, we explore compiler
                 optimization techniques to reduce this
                 overhead.\par

                 The lifeguard software is typically structured as a set
                 of event-driven handlers, where the events are
                 individual instructions in the monitored application's
                 dynamic instruction stream. We propose to {\em
                 decouple\/} the lifeguard checking code from the
                 application that it is monitoring so that the lifeguard
                 analysis can be invoked at the granularity of {\em hot
                 paths\/} in the monitored application. In this way, we
                 are able to find many more opportunities for
                 eliminating redundant work in the lifeguard analysis,
                 even starting with well-optimized applications and
                 hand-tuned lifeguard handlers. Experimental results
                 with two lifeguard frameworks - one DBI-based and one
                 hardware-assisted - show significant reduction in
                 monitoring overhead.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "dynamic code optimization; dynamic correctness
                 checking; dynamic program analysis",
}

@Article{Lee:2010:JSD,
  author =       "Byeongcheol Lee and Ben Wiedermann and Martin Hirzel
                 and Robert Grimm and Kathryn S. McKinley",
  title =        "{Jinn}: synthesizing dynamic bug detectors for foreign
                 language interfaces",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "36--49",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1809028.1806601",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Programming language specifications mandate static and
                 dynamic analyses to preclude syntactic and semantic
                 errors. Although individual languages are usually
                 well-specified, composing languages is not, and this
                 poor specification is a source of many errors in {\em
                 multilingual\/} programs. For example, virtually all
                 Java programs compose Java and C using the Java Native
                 Interface (JNI). Since JNI is informally specified,
                 developers have difficulty using it correctly, and
                 current Java compilers and virtual machines (VMs)
                 inconsistently check only a subset of JNI
                 constraints.\par

                 This paper's most significant contribution is to show
                 how to synthesize dynamic analyses from state machines
                 to detect foreign function interface (FFI) violations.
                 We identify three classes of FFI constraints encoded by
                 eleven state machines that capture thousands of JNI and
                 Python/C FFI rules. We use a mapping function to
                 specify which state machines, transitions, and program
                 entities (threads, objects, references) to check at
                 each FFI call and return. From this function, we
                 synthesize a context-specific dynamic analysis to find
                 FFI bugs. We build bug detection tools for JNI and
                 Python/C using this approach. For JNI, we dynamically
                 and transparently interpose the analysis on Java and C
                 language transitions through the JVM tools interface.
                 The resulting tool, called Jinn, is compiler and
                 virtual machine {\em independent}. It detects and
                 diagnoses a wide variety of FFI bugs that other tools
                 miss. This approach greatly reduces the annotation
                 burden by exploiting common FFI constraints: whereas
                 the generated Jinn code is 22,000+ lines, we wrote only
                 1,400 lines of state machine and mapping code. Overall,
                 this paper lays the foundation for a more principled
                 approach to developing correct multilingual software
                 and a more concise and automated approach to FFI
                 specification.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "dynamic analysis; ffi bugs; foreign function
                 interfaces (FFI); java native interface (jni);
                 multilingual programs; python/C; specification;
                 specification generation",
}

@Article{Prabhu:2010:SPS,
  author =       "Prakash Prabhu and Ganesan Ramalingam and Kapil
                 Vaswani",
  title =        "Safe programmable speculative parallelism",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "50--61",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806596.1806603",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Execution order constraints imposed by dependences can
                 serialize computation, preventing parallelization of
                 code and algorithms. Speculating on the value(s)
                 carried by dependences is one way to break such
                 critical dependences. Value speculation has been used
                 effectively at a low level, by compilers and hardware.
                 In this paper, we focus on the use of speculation {\em
                 by programmers\/} as an algorithmic paradigm to
                 parallelize seemingly sequential code.\par

                 We propose two new language constructs, {\em
                 speculative composition\/} and {\em speculative
                 iteration}. These constructs enable programmers to
                 declaratively express speculative parallelism in
                 programs: to indicate when and how to speculate,
                 increasing the parallelism in the program, without
                 concerning themselves with mundane implementation
                 details.\par

                 We present a core language with speculation constructs
                 and mutable state and present a formal operational
                 semantics for the language. We use the semantics to
                 define the notion of a correct speculative execution as
                 one that is equivalent to a non-speculative execution.
                 In general, speculation requires a runtime mechanism to
                 undo the effects of speculative computation in the case
                 of mis predictions. We describe a set of conditions
                 under which such rollback can be avoided. We present a
                 static analysis that checks if a given program
                 satisfies these conditions. This allows us to implement
                 speculation efficiently, without the overhead required
                 for rollbacks.\par

                 We have implemented the speculation constructs as a C\#
                 library, along with the static checker for safety. We
                 present an empirical evaluation of the efficacy of this
                 approach to parallelization.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "purity; rollback freedom; safety; speculative
                 parallelism; value speculation",
}

@Article{Tian:2010:SSP,
  author =       "Chen Tian and Min Feng and Rajiv Gupta",
  title =        "Supporting speculative parallelization in the presence
                 of dynamic data structures",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "62--73",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1809028.1806604",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "The availability of multicore processors has led to
                 significant interest in compiler techniques for
                 speculative parallelization of sequential programs.
                 Isolation of speculative state from non-speculative
                 state forms the basis of such speculative techniques as
                 this separation enables recovery from misspeculations.
                 In our prior work on CorD [35,36] we showed that for
                 array and scalar variable based programs copying of
                 data between speculative and non-speculative memory can
                 be highly optimized to support state separation that
                 yields significant speedups on multicore machines
                 available today. However, we observe that in context of
                 heap-intensive programs that operate on linked dynamic
                 data structures, state separation based speculative
                 parallelization poses many challenges. The copying of
                 data structures from non-speculative to speculative
                 state (copy-in operation) can be very expensive due to
                 the large sizes of dynamic data structures. The copying
                 of updated data structures from speculative state to
                 non-speculative state (copy-out operation) is made
                 complex due to the changes in the shape and size of the
                 dynamic data structure made by the speculative
                 computation. In addition, we must contend with the need
                 to translate pointers internal to dynamic data
                 structures between their non-speculative and
                 speculative memory addresses. In this paper we develop
                 an augmented design for the representation of dynamic
                 data structures such that all of the above operations
                 can be performed efficiently. Our experiments
                 demonstrate significant speedups on a real machine for
                 a set of programs that make extensive use of heap based
                 dynamic data structures.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "multicore processors; speculative parallelization",
}

@Article{Kandemir:2010:CTA,
  author =       "Mahmut Kandemir and Taylan Yemliha and SaiPrashanth
                 Muralidhara and Shekhar Srikantaiah and Mary Jane Irwin
                 and Yuanrui Zhnag",
  title =        "Cache topology aware computation mapping for
                 multicores",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "74--85",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806596.1806605",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "The main contribution of this paper is a compiler
                 based, cache topology aware code optimization scheme
                 for emerging multicore systems. This scheme distributes
                 the iterations of a loop to be executed in parallel
                 across the cores of a target multicore machine and
                 schedules the iterations assigned to each core. Our
                 goal is to improve the utilization of the on-chip
                 multi-layer cache hierarchy and to maximize overall
                 application performance. We evaluate our cache topology
                 aware approach using a set of twelve applications and
                 three different commercial multicore machines. In
                 addition, to study some of our experimental parameters
                 in detail and to explore future multicore machines
                 (with higher core counts and deeper on-chip cache
                 hierarchies), we also conduct a simulation based study.
                 The results collected from our experiments with three
                 Intel multicore machines show that the proposed
                 compiler-based approach is very effective in enhancing
                 performance. In addition, our simulation results
                 indicate that optimizing for the on-chip cache
                 hierarchy will be even more important in future
                 multicores with increasing numbers of cores and cache
                 levels.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "cache; compiler; multicore; multi-level;
                 topology-aware",
}

@Article{Yang:2010:GCM,
  author =       "Yi Yang and Ping Xiang and Jingfei Kong and Huiyang
                 Zhou",
  title =        "A {GPGPU} compiler for memory optimization and
                 parallelism management",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "86--97",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1809028.1806606",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "This paper presents a novel optimizing compiler for
                 general purpose computation on graphics processing
                 units (GPGPU). It addresses two major challenges of
                 developing high performance GPGPU programs: effective
                 utilization of GPU memory hierarchy and judicious
                 management of parallelism.\par

                 The input to our compiler is a na&\#239;ve GPU kernel
                 function, which is functionally correct but without any
                 consideration for performance optimization. The
                 compiler analyzes the code, identifies its memory
                 access patterns, and generates both the optimized
                 kernel and the kernel invocation parameters. Our
                 optimization process includes vectorization and memory
                 coalescing for memory bandwidth enhancement, tiling and
                 unrolling for data reuse and parallelism management,
                 and thread block remapping or address-offset insertion
                 for partition-camping elimination. The experiments on a
                 set of scientific and media processing algorithms show
                 that our optimized code achieves very high performance,
                 either superior or very close to the highly fine-tuned
                 library, NVIDIA CUBLAS 2.2, and up to 128 times
                 speedups over the naive versions. Another
                 distinguishing feature of our compiler is the
                 understandability of the optimized code, which is
                 useful for performance analysis and algorithm
                 refinement.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "compiler; gpgpu",
}

@Article{Eggers:2010:AL,
  author =       "Susan Eggers",
  title =        "{2010 Athena} lecture",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "98--98",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1809028.1806608",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Susan Eggers, a Professor of Computer Science and
                 Engineering at the University of Washington, joined her
                 department in 1989. She received a B.A. in 1965 from
                 Connecticut College and a Ph. D. in 1989 from the
                 University of California, Berkeley. Her research
                 interests are in computer architecture and back-end
                 compiler optimization, with an emphasis on experimental
                 performance analysis. With her colleague Hank Levy and
                 their students, she developed the first commercially
                 viable multithreaded architecture, Simultaneous
                 Multithreading, adopted by Intel (as Hyperthreading),
                 IBM, Sun and others. Her current research is in the
                 areas of distributed dataflow machines, FPGAs and chip
                 multiprocessors. In 1989 Professor Eggers was awarded
                 an IBM Faculty Development Award, in 1990 an NSF
                 Presidential Young Investigator Award, in 1994 the
                 Microsoft Professorship in Computer Science and
                 Engineering, and in 2009 the ACM-W Athena Lecturer. She
                 is a Fellow of the ACM and IEEE, a Fellow of the AAAS,
                 and a member of the National Academy of Engineering.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "invited talk",
}

@Article{Yang:2010:SLI,
  author =       "Jean Yang and Chris Hawblitzel",
  title =        "Safe to the last instruction: automated verification
                 of a type-safe operating system",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "99--110",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1809028.1806610",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Typed assembly language (TAL) and Hoare logic can
                 verify the absence of many kinds of errors in low-level
                 code. We use TAL and Hoare logic to achieve highly
                 automated, static verification of the safety of a new
                 operating system called Verve. Our techniques and tools
                 mechanically verify the safety of every assembly
                 language instruction in the operating system, run-time
                 system, drivers, and applications (in fact, every part
                 of the system software except the boot loader). Verve
                 consists of a 'Nucleus' that provides primitive access
                 to hardware and memory, a kernel that builds services
                 on top of the Nucleus, and applications that run on top
                 of the kernel. The Nucleus, written in verified
                 assembly language, implements allocation, garbage
                 collection, multiple stacks, interrupt handling, and
                 device access. The kernel, written in C\# and compiled
                 to TAL, builds higher-level services, such as
                 preemptive threads, on top of the Nucleus. A TAL
                 checker verifies the safety of the kernel and
                 applications. A Hoare-style verifier with an automated
                 theorem prover verifies both the safety and correctness
                 of the Nucleus. Verve is, to the best of our knowledge,
                 the first operating system mechanically verified to
                 guarantee both type and memory safety. More generally,
                 Verve's approach demonstrates a practical way to mix
                 high-level typed code with low-level untyped code in a
                 verifiably safe manner.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "operating system; run-time system; type safety;
                 verification",
}

@Article{Tatlock:2010:BEV,
  author =       "Zachary Tatlock and Sorin Lerner",
  title =        "Bringing extensibility to verified compilers",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "111--121",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806596.1806611",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Verified compilers, such as Leroy's CompCert, are
                 accompanied by a fully checked correctness proof. Both
                 the compiler and proof are often constructed with an
                 interactive proof assistant. This technique provides a
                 strong, end-to-end correctness guarantee on top of a
                 small trusted computing base. Unfortunately, these
                 compilers are also challenging to extend since each
                 additional transformation must be proven correct in
                 full formal detail.\par

                 At the other end of the spectrum, techniques for
                 compiler correctness based on a domain-specific
                 language for writing optimizations, such as Lerner's
                 Rhodium and Cobalt, make the compiler easy to extend:
                 the correctness of additional transformations can be
                 checked completely automatically. Unfortunately, these
                 systems provide a weaker guarantee since their
                 end-to-end correctness has not been proven fully
                 formally.\par

                 We present an approach for compiler correctness that
                 provides the best of both worlds by bridging the gap
                 between compiler verification and compiler
                 extensibility. In particular, we have extended Leroy's
                 CompCert compiler with an execution engine for
                 optimizations written in a domain specific and proved
                 that this execution engine preserves program semantics,
                 using the Coq proof assistant. We present our CompCert
                 extension, XCert, including the details of its
                 execution engine and proof of correctness in Coq.
                 Furthermore, we report on the important lessons learned
                 for making the proof development manageable.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "compiler optimization; correctness; extensibility",
}

@Article{Chlipala:2010:UST,
  author =       "Adam Chlipala",
  title =        "{Ur}: statically-typed metaprogramming with type-level
                 record computation",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "122--133",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1809028.1806612",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "{\em Dependent types\/} provide a strong foundation
                 for specifying and verifying rich properties of
                 programs through type-checking. The earliest
                 implementations combined dependency, which allows types
                 to mention program variables; with type-level
                 computation, which facilitates expressive
                 specifications that compute with recursive functions
                 over types. While many recent applications of dependent
                 types omit the latter facility, we argue in this paper
                 that it deserves more attention, even when implemented
                 without dependency.\par

                 In particular, the ability to use functional programs
                 as specifications enables {\em statically-typed
                 metaprogramming\/}: programs write programs, and static
                 type-checking guarantees that the generating process
                 never produces invalid code. Since our focus is on
                 generic validity properties rather than full
                 correctness verification, it is possible to engineer
                 type inference systems that are very effective in
                 narrow domains. As a demonstration, we present Ur, a
                 programming language designed to facilitate
                 metaprogramming with first-class records and names. On
                 top of Ur, we implement Ur/Web, a special standard
                 library that enables the development of modern Web
                 applications. Ad-hoc code generation is already in wide
                 use in the popular Web application frameworks, and we
                 show how that generation may be tamed using types,
                 without forcing metaprogram authors to write proofs or
                 forcing metaprogram users to write any fancy types.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "dependent types; metaprogramming",
}

@Article{Emmi:2010:PVT,
  author =       "Michael Emmi and Rupak Majumdar and Roman Manevich",
  title =        "Parameterized verification of transactional memories",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "134--145",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806596.1806613",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "We describe an automatic verification method to check
                 whether transactional memories ensure strict
                 serializability a key property assumed of the
                 transactional interface. Our main contribution is a
                 technique for effectively verifying parameterized
                 systems. The technique merges ideas from parameterized
                 hardware and protocol verification--verification by
                 invisible invariants and symmetry reduction--with ideas
                 from software verification--template-based invariant
                 generation and satisfiability checking for quantified
                 formul&\#230; (modulo theories). The combination
                 enables us to precisely model and analyze unbounded
                 systems while taming state explosion.\par

                 Our technique enables automated proofs that two-phase
                 locking (TPL), dynamic software transactional memory
                 (DSTM), and transactional locking II (TL2) systems
                 ensure strict serializability. The verification is
                 challenging since the systems are unbounded in several
                 dimensions: the number and length of concurrently
                 executing transactions, and the size of the shared
                 memory they access, have no finite limit. In contrast,
                 state-of-the-art software model checking tools such as
                 BLAST and TVLA are unable to validate either system,
                 due to inherent expressiveness limitations or state
                 explosion.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "parameterized verification; transactional memory",
}

@Article{Pizlo:2010:SFT,
  author =       "Filip Pizlo and Lukasz Ziarek and Petr Maj and Antony
                 L. Hosking and Ethan Blanton and Jan Vitek",
  title =        "{SCHISM}: fragmentation-tolerant real-time garbage
                 collection",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "146--159",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806596.1806615",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Managed languages such as Java and C\# are being
                 considered for use in hard real-time systems. A hurdle
                 to their widespread adoption is the lack of garbage
                 collection algorithms that offer predictable
                 space-and-time performance in the face of
                 fragmentation. We introduce SCHISM/CMR, a new
                 concurrent and real-time garbage collector that is
                 fragmentation tolerant and guarantees time-and-space
                 worst-case bounds while providing good throughput.
                 SCHISM/CMR combines mark-region collection of
                 fragmented objects and arrays (arraylets) with separate
                 replication-copying collection of immutable arraylet
                 spines, so as to cope with external fragmentation when
                 running in small heaps. We present an implementation of
                 SCHISM/CMR in the Fiji VM, a high-performance Java
                 virtual machine for mission-critical systems, along
                 with a thorough experimental evaluation on a wide
                 variety of architectures, including server-class and
                 embedded systems. The results show that SCHISM/CMR
                 tolerates fragmentation better than previous schemes,
                 with a much more acceptable throughput penalty.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "fragmentation; mark-region; mark-sweep; real-time;
                 replication-copying",
}

@Article{Xu:2010:DIU,
  author =       "Guoqing Xu and Atanas Rountev",
  title =        "Detecting inefficiently-used containers to avoid
                 bloat",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "160--173",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806596.1806616",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Runtime bloat degrades significantly the performance
                 and scalability of software systems. An important
                 source of bloat is the inefficient use of containers.
                 It is expensive to create inefficiently-used containers
                 and to invoke their associated methods, as this may
                 ultimately execute large volumes of code, with call
                 stacks dozens deep, and allocate many temporary
                 objects.\par

                 This paper presents practical static and dynamic tools
                 that can find inappropriate use of containers in Java
                 programs. At the core of these tools is a base static
                 analysis that identifies, for each container, the
                 objects that are added to this container and the key
                 statements (i.e., heap loads and stores) that achieve
                 the semantics of common container operations such as
                 {\em ADD\/} and {\em GET}. The static tool finds
                 problematic uses of containers by considering the
                 nesting relationships among the loops where these {\em
                 semantics-achieving statements\/} are located, while
                 the dynamic tool can instrument these statements and
                 find inefficiencies by profiling their execution
                 frequencies.\par

                 The high precision of the base analysis is achieved by
                 taking advantage of a context-free language
                 (CFL)-reachability formulation of points-to analysis
                 and by accounting for container-specific properties. It
                 is demand-driven and client-driven, facilitating
                 refinement specific to each queried container object
                 and increasing scalability. The tools built with the
                 help of this analysis can be used both to avoid the
                 creation of container-related performance problems
                 early during development, and to help with diagnosis
                 when problems are observed during tuning. Our
                 experimental results show that the static tool has a
                 low false positive rate and produces more relevant
                 information than its dynamic counterpart. Further case
                 studies suggest that significant optimization
                 opportunities can be found by focusing on
                 statically-identified containers for which high
                 allocation frequency is observed at run time.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "cfl reachability; container bloat; points-to
                 analysis",
}

@Article{Xu:2010:FLU,
  author =       "Guoqing Xu and Nick Mitchell and Matthew Arnold and
                 Atanas Rountev and Edith Schonberg and Gary Sevitsky",
  title =        "Finding low-utility data structures",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "174--186",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806596.1806617",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Many opportunities for easy, big-win, program
                 optimizations are missed by compilers. This is
                 especially true in highly layered Java applications.
                 Often at the heart of these missed optimization
                 opportunities lie computations that, with great
                 expense, produce data values that have little impact on
                 the program's final output. Constructing a new date
                 formatter to format every date, or populating a large
                 set full of expensively constructed structures only to
                 check its size: these involve costs that are out of
                 line with the benefits gained. This disparity between
                 the formation costs and accrued benefits of data
                 structures is at the heart of much runtime
                 bloat.\par

                 We introduce a run-time analysis to discover these {\em
                 low-utility\/} data structures. The analysis employs
                 dynamic thin slicing, which naturally associates costs
                 with value flows rather than raw data flows. It
                 constructs a model of the incremental, hop-to-hop,
                 costs and benefits of each data structure. The analysis
                 then identifies suspicious structures based on
                 imbalances of its incremental costs and benefits. To
                 decrease the memory requirements of slicing, we
                 introduce {\em abstract dynamic thin slicing}, which
                 performs thin slicing over bounded abstract domains. We
                 have modified the IBM J9 commercial JVM to implement
                 this approach.\par

                 We demonstrate two client analyses: one that finds
                 objects that are expensive to construct but are not
                 necessary for the forward execution, and second that
                 pinpoints ultimately-dead values. We have successfully
                 applied them to large-scale and long-running Java
                 applications. We show that these analyses are effective
                 at detecting operations that have unbalanced costs and
                 benefits.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "abstract dynamic thin slicing; cost benefit analysis;
                 memory bloat",
}

@Article{Mytkowicz:2010:EAJ,
  author =       "Todd Mytkowicz and Amer Diwan and Matthias Hauswirth
                 and Peter F. Sweeney",
  title =        "Evaluating the accuracy of {Java} profilers",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "187--197",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806596.1806618",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Performance analysts profile their programs to find
                 methods that are worth optimizing: the 'hot' methods.
                 This paper shows that four commonly-used Java profilers
                 ({\em xprof , hprof , jprofile, and yourkit\/}) often
                 disagree on the identity of the hot methods. If two
                 profilers disagree, at least one must be incorrect.
                 Thus, there is a good chance that a profiler will
                 mislead a performance analyst into wasting time
                 optimizing a cold method with little or no performance
                 improvement.\par

                 This paper uses causality analysis to evaluate
                 profilers and to gain insight into the source of their
                 incorrectness. It shows that these profilers all
                 violate a fundamental requirement for sampling based
                 profilers: to be correct, a sampling-based profiler
                 must collect samples randomly.\par

                 We show that a proof-of-concept profiler, which
                 collects samples randomly, does not suffer from the
                 above problems. Specifically, we show, using a number
                 of case studies, that our profiler correctly identifies
                 methods that are important to optimize; in some cases
                 other profilers report that these methods are cold and
                 thus not worth optimizing.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "bias; observer effect; profiling",
}

@Article{Baek:2010:GFS,
  author =       "Woongki Baek and Trishul M. Chilimbi",
  title =        "{Green}: a framework for supporting energy-conscious
                 programming using controlled approximation",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "198--209",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1809028.1806620",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Energy-efficient computing is important in several
                 systems ranging from embedded devices to large scale
                 data centers. Several application domains offer the
                 opportunity to tradeoff quality of service/solution
                 (QoS) for improvements in performance and reduction in
                 energy consumption. Programmers sometimes take
                 advantage of such opportunities, albeit in an ad-hoc
                 manner and often without providing any QoS
                 guarantees.\par

                 We propose a system called Green that provides a simple
                 and flexible framework that allows programmers to take
                 advantage of such approximation opportunities in a
                 systematic manner while providing statistical QoS
                 guarantees. Green enables programmers to approximate
                 expensive functions and loops and operates in two
                 phases. In the calibration phase, it builds a model of
                 the QoS loss produced by the approximation. This model
                 is used in the operational phase to make approximation
                 decisions based on the QoS constraints specified by the
                 programmer. The operational phase also includes an
                 adaptation function that occasionally monitors the
                 runtime behavior and changes the approximation
                 decisions and QoS model to provide strong statistical
                 QoS guarantees.\par

                 To evaluate the effectiveness of Green, we implemented
                 our system and language extensions using the Phoenix
                 compiler framework. Our experiments using benchmarks
                 from domains such as graphics, machine learning, signal
                 processing, and finance, and an in-production,
                 real-world web search engine, indicate that Green can
                 produce significant improvements in performance and
                 energy consumption with small and controlled QoS
                 degradation.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "controlled approximation; energy-conscious
                 programming",
}

@Article{Rajan:2010:GPM,
  author =       "Kaushik Rajan and Sriram Rajamani and Shashank
                 Yaduvanshi",
  title =        "{GUESSTIMATE}: a programming model for collaborative
                 distributed systems",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "210--220",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1809028.1806621",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "We present a new programming model GUESSTIMATE for
                 developing collaborative distributed systems. The model
                 allows atomic, isolated operations that transform a
                 system from consistent state to consistent state, and
                 provides a shared transactional store for a collection
                 of such operations executed by various machines in a
                 distributed system. In addition to 'committed state'
                 which is identical in all machines in the distributed
                 system, GUESSTIMATE allows each machine to have a
                 replicated local copy of the state (called
                 'guesstimated state') so that operations on shared
                 state can be executed locally without any blocking,
                 while also guaranteeing that eventually all machines
                 agree on the sequences of operations executed. Thus,
                 each operation is executed multiple times, once at the
                 time of issue when it updates the guesstimated state of
                 the issuing machine, once when the operation is
                 committed (atomically) to the committed state of all
                 machines, and several times in between as the
                 guesstimated state converges toward the committed
                 state. While we expect the results of these executions
                 of the operation to be identical most of the time in
                 the class of applications we study, it is possible for
                 an operation to succeed the first time when it is
                 executed on the guesstimated state, and fail when it is
                 committed. GUESSTIMATE provides facilities that allow
                 the programmer to deal with this potential discrepancy.
                 This paper presents our programming model, its
                 operational semantics, its realization as an API in
                 C\#, and our experience building collaborative
                 distributed applications with this model.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "collaborative applications; concurrency; distributed
                 systems; language extensions",
}

@Article{Xi:2010:CFM,
  author =       "Qian Xi and David Walker",
  title =        "A context-free markup language for semi-structured
                 text",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "221--232",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1809028.1806622",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "An {\em ad hoc data format\/} is any nonstandard,
                 semi-structured data format for which robust data
                 processing tools are not easily available. In this
                 paper, we present ANNE, a new kind of markup language
                 designed to help users generate documentation and data
                 processing tools for ad hoc text data. More
                 specifically, given a new ad hoc data source, an ANNE
                 programmer edits the document to add a number of simple
                 annotations, which serve to specify its syntactic
                 structure. Annotations include elements that specify
                 constants, optional data, alternatives, enumerations,
                 sequences, tabular data, and recursive patterns. The
                 ANNE system uses a combination of user annotations and
                 the raw data itself to extract a context-free grammar
                 from the document. This context-free grammar can then
                 be used to parse the data and transform it into an XML
                 parse tree, which may be viewed through a browser for
                 analysis or debugging purposes. In addition, the ANNE
                 system generates a PADS/ML description, which may be
                 saved as lasting documentation of the data format or
                 compiled into a host of useful data processing
                 tools.\par

                 In addition to designing and implementing ANNE, we have
                 devised a semantic theory for the core elements of the
                 language. This semantic theory describes the editing
                 process, which translates a raw, unannotated text
                 document into an annotated document, and the grammar
                 extraction process, which generates a context-free
                 grammar from an annotated document. We also present an
                 alternative characterization of system behavior by
                 drawing upon ideas from the field of relevance logic.
                 This secondary characterization, which we call {\em
                 relevance analysis}, specifies a direct relationship
                 between unannotated documents and the context-free
                 grammars that our system can generate from them.
                 Relevance analysis allows us to prove important
                 theorems concerning the expressiveness and utility of
                 our system.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "ad hoc data; ANNE; domain-specific languages; PADS;
                 tool generation",
}

@Article{Loitsch:2010:PFP,
  author =       "Florian Loitsch",
  title =        "Printing floating-point numbers quickly and accurately
                 with integers",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "233--243",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1809028.1806623",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "We present algorithms for accurately converting
                 floating-point numbers to decimal representation. They
                 are fast (up to 4 times faster than commonly used
                 algorithms that use high-precision integers) and
                 correct: any printed number will evaluate to the same
                 number, when read again.\par

                 Our algorithms are fast, because they require only
                 fixed-size integer arithmetic. The sole requirement for
                 the integer type is that it has at least two more bits
                 than the significand of the floating-point number.
                 Hence, for IEEE 754 double-precision numbers (having a
                 53-bit significand) an integer type with 55 bits is
                 sufficient. Moreover we show how to exploit additional
                 bits to improve the generated output.\par

                 We present three algorithms with different properties:
                 the first algorithm is the most basic one, and does not
                 take advantage of any extra bits. It simply shows how
                 to perform the binary-to-decimal transformation with
                 the minimal number of bits. Our second algorithm
                 improves on the first one by using the additional bits
                 to produce a shorter (often the shortest)
                 result.\par

                 Finally we propose a third version that can be used
                 when the shortest output is a requirement. The last
                 algorithm either produces optimal decimal
                 representations (with respect to shortness and
                 rounding) or rejects its input. For IEEE 754
                 double-precision numbers and 64-bit integers roughly
                 99.4\% of all numbers can be processed efficiently. The
                 remaining 0.6\% are rejected and need to be printed by
                 a slower complete algorithm.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "dtoa; floating-point printing",
}

@Article{Flanagan:2010:AMD,
  author =       "Cormac Flanagan and Stephen N. Freund",
  title =        "Adversarial memory for detecting destructive races",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "244--254",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806596.1806625",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Multithreaded programs are notoriously prone to race
                 conditions, a problem exacerbated by the widespread
                 adoption of multi-core processors with complex memory
                 models and cache coherence protocols. Much prior work
                 has focused on static and dynamic analyses for race
                 detection, but these algorithms typically are unable to
                 distinguish destructive races that cause erroneous
                 behavior from benign races that do not. Performing this
                 classification manually is difficult, time consuming,
                 and error prone.\par

                 This paper presents a new dynamic analysis technique
                 that uses {\em adversarial memory\/} to classify race
                 conditions as destructive or benign on systems with
                 relaxed memory models. Unlike a typical language
                 implementation, which may only infrequently exhibit
                 non-sequentially consistent behavior, our adversarial
                 memory implementation exploits the full freedom of the
                 memory model to return older, unexpected, or stale
                 values for memory reads whenever possible, in an
                 attempt to crash the target program (that is, to force
                 the program to behave erroneously). A crashing
                 execution provides concrete evidence of a destructive
                 bug, and this bug can be strongly correlated with a
                 specific race condition in the target
                 program.\par

                 Experimental results with our Jumble prototype for Java
                 demonstrate that adversarial memory is highly effective
                 at identifying destructive race conditions, and in
                 distinguishing them from race conditions that are real
                 but benign. Adversarial memory can also reveal
                 destructive races that would not be detected by
                 traditional testing (even after thousands of runs) or
                 by model checkers that assume sequential consistency.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "concurrency; dynamic analysis; race conditions;
                 relaxed memory models",
}

@Article{Bond:2010:PPD,
  author =       "Michael D. Bond and Katherine E. Coons and Kathryn S.
                 McKinley",
  title =        "{PACER}: proportional detection of data races",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "255--268",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806596.1806626",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Data races indicate serious concurrency bugs such as
                 order, atomicity, and sequential consistency
                 violations. Races are difficult to find and fix, often
                 manifesting only after deployment. The frequency and
                 unpredictability of these bugs will only increase as
                 software adds parallelism to exploit multicore
                 hardware. Unfortunately, sound and precise race
                 detectors slow programs by factors of eight or more and
                 do not scale to large numbers of threads.\par

                 This paper presents a precise, low-overhead {\em
                 sampling-based\/} data race detector called Pacer.
                 PACER makes a {\em proportionality\/} guarantee: it
                 detects any race at a rate equal to the sampling rate,
                 by finding races whose first access occurs during a
                 global sampling period. During sampling, PACER tracks
                 all accesses using the dynamically sound and precise
                 FastTrack algorithm. In nonsampling periods, Pacer
                 discards sampled access information that cannot be part
                 of a reported race, {\em and\/} Pacer simplifies
                 tracking of the happens-before relationship, yielding
                 near-constant, instead of linear, overheads.
                 Experimental results confirm our theoretical
                 guarantees. PACER reports races in proportion to the
                 sampling rate. Its time and space overheads scale with
                 the sampling rate, and sampling rates of 1-3\% yield
                 overheads low enough to consider in production
                 software. The resulting system provides a 'get what you
                 pay for' approach that is suitable for identifying
                 real, hard-to-reproduce races in deployed systems.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "bugs; concurrency; data races; sampling",
}

@Article{Nakaike:2010:LER,
  author =       "Takuya Nakaike and Maged M. Michael",
  title =        "Lock elision for read-only critical sections in
                 {Java}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "269--278",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806596.1806627",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "It is not uncommon in parallel workloads to encounter
                 shared data structures with read-mostly access
                 patterns, where operations that update data are
                 infrequent and most operations are read-only.
                 Typically, data consistency is guaranteed using mutual
                 exclusion or read-write locks. The cost of atomic
                 update of lock variables result in high overheads and
                 high cache coherence traffic under active sharing, thus
                 slowing down single thread performance and limiting
                 scalability.\par

                 In this paper, we present {\em SOLERO (Software
                 Optimistic Lock Elision for Read-Only critical
                 sections)}, a new lock implementation called for
                 optimizing read-only critical sections in Java based on
                 sequential locks. SOLERO is compatible with the
                 conventional lock implementation of Java. However,
                 unlike the conventional implementation, only critical
                 sections that may write data or have side effects need
                 to update lock variables, while read-only critical
                 sections need only read lock variables without writing
                 them. Each writing critical section changes the lock
                 value to a new value. Hence, a read-only critical
                 section is guaranteed to be consistent if the lock is
                 free and its value does not change from the beginning
                 to the end of the read-only critical section.\par

                 Using Java workloads including SPECjbb2005 and the
                 HashMap and TreeMap Java classes, we evaluate the
                 performance impact of applying SOLERO to read-mostly
                 locks. Our experimental results show performance
                 improvements across the board, often substantial, in
                 both single thread speed and scalability over the
                 conventional lock implementation (mutual exclusion) and
                 read-write locks. SOLERO improves the performance of
                 SPECjbb2005 by 3-5\% on single and multiple threads.
                 The results using the HashMap and TreeMap benchmarks
                 show that SOLERO outperforms the conventional lock
                 implementation and read-write locks by substantial
                 multiples on multi-threads.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "java; just-in-time compiler; lock; lock elision;
                 monitor; optimization; synchronization",
}

@Article{Chaudhuri:2010:SI,
  author =       "Swarat Chaudhuri and Armando Solar-Lezama",
  title =        "Smooth interpretation",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "279--291",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1809028.1806629",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "We present {\em smooth interpretation}, a method to
                 systematically approximate numerical imperative
                 programs by smooth mathematical functions. This
                 approximation facilitates the use of numerical search
                 techniques like gradient descent for program analysis
                 and synthesis. The method extends to programs the
                 notion of {\em Gaussian smoothing}, a popular
                 signal-processing technique that filters out noise and
                 discontinuities from a signal by taking its convolution
                 with a Gaussian function.\par

                 In our setting, Gaussian smoothing executes a program
                 according to a probabilistic semantics; the execution
                 of program {\em P\/} on an input {\em x\/} after
                 Gaussian smoothing can be summarized as follows: (1)
                 Apply a Gaussian perturbation to {\em x\/} -- the
                 perturbed input is a random variable following a normal
                 distribution with mean {\em x}. (2) Compute and return
                 the {\em expected output\/} of {\em P\/} on this
                 perturbed input. Computing the expectation explicitly
                 would require the execution of {\em P\/} on all
                 possible inputs, but smooth interpretation bypasses
                 this requirement by using a form of symbolic execution
                 to approximate the effect of Gaussian smoothing on {\em
                 P}. The result is an efficient but approximate
                 implementation of Gaussian smoothing of
                 programs.\par

                 Smooth interpretation has the effect of attenuating
                 features of a program that impede numerical searches of
                 its input space -- for example, discontinuities
                 resulting from conditional branches are replaced by
                 continuous transitions. We apply smooth interpretation
                 to the problem of synthesizing values of numerical
                 control parameters in embedded control applications.
                 This problem is naturally formulated as one of
                 numerical optimization: the goal is to find parameter
                 values that minimize the error between the resulting
                 program and a programmer-provided behavioral
                 specification. Solving this problem by directly
                 applying numerical optimization techniques is often
                 impractical due to the discontinuities in the error
                 function. By eliminating these discontinuities, smooth
                 interpretation makes it possible to search the
                 parameter space efficiently by means of simple gradient
                 descent. Our experiments demonstrate the value of this
                 strategy in synthesizing parameters for several
                 challenging programs, including models of an automated
                 gear shift and a PID controller.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "continuity; parameter synthesis; program smoothing",
}

@Article{Gulwani:2010:RBP,
  author =       "Sumit Gulwani and Florian Zuleger",
  title =        "The reachability-bound problem",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "292--304",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806596.1806630",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "We define the {\em reachability-bound problem\/} to be
                 the problem of finding a symbolic worst-case bound on
                 the number of times a given control location inside a
                 procedure is visited in terms of the inputs to that
                 procedure. This has applications in bounding resources
                 consumed by a program such as time, memory,
                 network-traffic, power, as well as estimating
                 quantitative properties (as opposed to boolean
                 properties) of data in programs, such as information
                 leakage or uncertainty propagation. Our approach to
                 solving the reachability-bound problem brings together
                 two different techniques for reasoning about loops in
                 an effective manner. One of these techniques is an
                 abstract-interpretation based iterative technique for
                 computing precise disjunctive invariants (to summarize
                 nested loops). The other technique is a non-iterative
                 proof-rules based technique (for loop bound
                 computation) that takes over the role of doing
                 inductive reasoning, while deriving its power from the
                 use of SMT solvers to reason about abstract loop-free
                 fragments.\par

                 Our solution to the reachability-bound problem allows
                 us to compute precise symbolic complexity bounds for
                 several loops in .Net base-class libraries for which
                 earlier techniques fail. We also illustrate the
                 precision of our algorithm for disjunctive invariant
                 computation (which has a more general applicability
                 beyond the reachability-bound problem) on a set of
                 benchmark examples.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "disjunctive invariants; pattern matching; ranking
                 functions; resource bound analysis; transitive
                 closure",
}

@Article{Might:2010:REK,
  author =       "Matthew Might and Yannis Smaragdakis and David Van
                 Horn",
  title =        "Resolving and exploiting the $k$-{CFA} paradox:
                 illuminating functional vs. object-oriented program
                 analysis",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "305--315",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1809028.1806631",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Low-level program analysis is a fundamental problem,
                 taking the shape of 'flow analysis' in functional
                 languages and 'points-to' analysis in imperative and
                 object-oriented languages. Despite the similarities,
                 the vocabulary and results in the two communities
                 remain largely distinct, with limited
                 cross-understanding. One of the few links is Shivers's
                 $k$-CFA work, which has advanced the concept of
                 'context-sensitive analysis' and is widely known in
                 both communities.\par

                 Recent results indicate that the relationship between
                 the functional and object-oriented incarnations of
                 $k$-CFA is not as well understood as thought. Van Horn
                 and Mairson proved $k$-CFA for $k \geq 1$ to be
                 EXPTIME-complete; hence, no polynomial-time algorithm
                 can exist. Yet, there are several polynomial-time
                 formulations of context-sensitive points-to analyses in
                 object-oriented languages. Thus, it seems that
                 functional $k$-CFA may actually be a profoundly
                 different analysis from object-oriented $k$-CFA. We
                 resolve this paradox by showing that the exact same
                 specification of $k$-CFA is polynomial-time for
                 object-oriented languages yet exponential-time for
                 functional ones: objects and closures are subtly
                 different, in a way that interacts crucially with
                 context-sensitivity and complexity. This illumination
                 leads to an immediate payoff: by projecting the
                 object-oriented treatment of objects onto closures, we
                 derive a polynomial-time hierarchy of context-sensitive
                 CFAs for functional programs.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "control-flow analysis; functional; k-cfa; m-cfa;
                 object-oriented; pointer analysis; static analysis",
}

@Article{Kuncak:2010:CFS,
  author =       "Viktor Kuncak and Mika{\"e}l Mayer and Ruzica Piskac
                 and Philippe Suter",
  title =        "Complete functional synthesis",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "316--329",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806596.1806632",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Synthesis of program fragments from specifications can
                 make programs easier to write and easier to reason
                 about. To integrate synthesis into programming
                 languages, synthesis algorithms should behave in a
                 predictable way - they should succeed for a
                 well-defined class of specifications. They should also
                 support unbounded data types such as numbers and data
                 structures. We propose to generalize decision
                 procedures into predictable and complete synthesis
                 procedures. Such procedures are guaranteed to find code
                 that satisfies the specification if such code exists.
                 Moreover, we identify conditions under which synthesis
                 will statically decide whether the solution is
                 guaranteed to exist, and whether it is unique. We
                 demonstrate our approach by starting from decision
                 procedures for linear arithmetic and data structures
                 and transforming them into synthesis procedures. We
                 establish results on the size and the efficiency of the
                 synthesized code. We show that such procedures are
                 useful as a language extension with implicit value
                 definitions, and we show how to extend a compiler to
                 support such definitions. Our constructs provide the
                 benefits of synthesis to programmers, without requiring
                 them to learn new concepts or give up a deterministic
                 execution model.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "bapa; decision procedure; presburger arithmetic;
                 synthesis procedure",
}

@Article{Burckhardt:2010:LCA,
  author =       "Sebastian Burckhardt and Chris Dern and Madanlal
                 Musuvathi and Roy Tan",
  title =        "{Line-Up}: a complete and automatic linearizability
                 checker",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "330--340",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806596.1806634",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Modular development of concurrent applications
                 requires thread-safe components that behave correctly
                 when called concurrently by multiple client threads.
                 This paper focuses on linearizability, a specific
                 formalization of thread safety, where all operations of
                 a concurrent component appear to take effect
                 instantaneously at some point between their call and
                 return. The key insight of this paper is that if a
                 component is intended to be deterministic, then it is
                 possible to build an automatic linearizability checker
                 by systematically enumerating the sequential behaviors
                 of the component and then checking if each its
                 concurrent behavior is equivalent to some sequential
                 behavior.\par

                 We develop this insight into a tool called Line-Up, the
                 first complete and automatic checker for {\em
                 deterministic linearizability}. It is complete, because
                 any reported violation proves that the implementation
                 is not linearizable with respect to {\em any\/}
                 sequential deterministic specification. It is
                 automatic, requiring no manual abstraction, no manual
                 specification of semantics or commit points, no
                 manually written test suites, no access to source
                 code.\par

                 We evaluate Line-Up by analyzing 13 classes with a
                 total of 90 methods in two versions of the .NET
                 Framework 4.0. The violations of deterministic
                 linearizability reported by Line-Up exposed seven
                 errors in the implementation that were fixed by the
                 development team.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "atomicity; linearizability; thread safety",
}

@Article{Torlak:2010:MCA,
  author =       "Emina Torlak and Mandana Vaziri and Julian Dolby",
  title =        "{MemSAT}: checking axiomatic specifications of memory
                 models",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "341--350",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806596.1806635",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Memory models are hard to reason about due to their
                 complexity, which stems from the need to strike a
                 balance between ease-of-programming and allowing
                 compiler and hardware optimizations. In this paper, we
                 present an automated tool, MemSAT, that helps in
                 debugging and reasoning about memory models. Given an
                 axiomatic specification of a memory model and a
                 multi-threaded test program containing assertions,
                 MemSAT outputs a trace of the program in which both the
                 assertions and the memory model axioms are satisfied,
                 if one can be found. The tool is fully automatic and is
                 based on a SAT solver. If it cannot find a trace, it
                 outputs a minimal subset of the memory model and
                 program constraints that are unsatisfiable. We used
                 MemSAT to check several existing memory models against
                 their published test cases, including the current Java
                 Memory Model by Manson et al. and a revised version of
                 it by Sevcik and Aspinall. We found subtle
                 discrepancies between what was expected and the actual
                 results of test programs.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "axiomatic specifications; bounded model checking;
                 memory models; sat",
}

@Article{Marino:2010:DSE,
  author =       "Daniel Marino and Abhayendra Singh and Todd Millstein
                 and Madanlal Musuvathi and Satish Narayanasamy",
  title =        "{DRFX}: a simple and efficient memory model for
                 concurrent programming languages",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "351--362",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806596.1806636",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "The most intuitive memory model for shared-memory
                 multithreaded programming is {\em sequential
                 consistency\/} (SC), but it disallows the use of many
                 compiler and hardware optimizations thereby impacting
                 performance. Data-race-free (DRF) models, such as the
                 proposed C++0x memory model, guarantee SC execution for
                 datarace-free programs. But these models provide no
                 guarantee at all for racy programs, compromising the
                 safety and debuggability of such programs. To address
                 the safety issue, the Java memory model, which is also
                 based on the DRF model, provides a weak semantics for
                 racy executions. However, this semantics is subtle and
                 complex, making it difficult for programmers to reason
                 about their programs and for compiler writers to ensure
                 the correctness of compiler optimizations.\par

                 We present the DRFx memory model, which is simple for
                 programmers to understand and use while still
                 supporting many common optimizations. We introduce a
                 {\em memory model (MM) exception\/} which can be
                 signaled to halt execution. If a program executes
                 without throwing this exception, then DRFx guarantees
                 that the execution is SC. If a program throws an MM
                 exception during an execution, then DRFx guarantees
                 that the program has a data race. We observe that SC
                 violations can be detected in hardware through a
                 lightweight form of conflict detection. Furthermore,
                 our model safely allows aggressive compiler and
                 hardware optimizations within compiler-designated
                 program regions. We formalize our memory model, prove
                 several properties about this model, describe a
                 compiler and hardware design suitable for DRFx, and
                 evaluate the performance overhead due to our compiler
                 and hardware requirements.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "data races; memory model exception; memory models;
                 sequential consistency; soft fences",
}

@Article{Chambers:2010:FEE,
  author =       "Craig Chambers and Ashish Raniwala and Frances Perry
                 and Stephen Adams and Robert R. Henry and Robert
                 Bradshaw and Nathan Weizenbaum",
  title =        "{FlumeJava}: easy, efficient data-parallel pipelines",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "363--375",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1809028.1806638",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "MapReduce and similar systems significantly ease the
                 task of writing data-parallel code. However, many
                 real-world computations require a pipeline of
                 MapReduces, and programming and managing such pipelines
                 can be difficult. We present FlumeJava, a Java library
                 that makes it easy to develop, test, and run efficient
                 data-parallel pipelines. At the core of the FlumeJava
                 library are a couple of classes that represent
                 immutable parallel collections, each supporting a
                 modest number of operations for processing them in
                 parallel. Parallel collections and their operations
                 present a simple, high-level, uniform abstraction over
                 different data representations and execution
                 strategies. To enable parallel operations to run
                 efficiently, FlumeJava defers their evaluation, instead
                 internally constructing an execution plan dataflow
                 graph. When the final results of the parallel
                 operations are eventually needed, FlumeJava first
                 optimizes the execution plan, and then executes the
                 optimized operations on appropriate underlying
                 primitives (e.g., MapReduces). The combination of
                 high-level abstractions for parallel data and
                 computation, deferred evaluation and optimization, and
                 efficient parallel primitives yields an easy-to-use
                 system that approaches the efficiency of hand-optimized
                 pipelines. FlumeJava is in active use by hundreds of
                 pipeline developers within Google.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "data-parallel programming; java; mapreduce",
}

@Article{Pan:2010:CPS,
  author =       "Heidi Pan and Benjamin Hindman and Krste
                 Asanovi{\'c}",
  title =        "Composing parallel software efficiently with {Lithe}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "376--387",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1809028.1806639",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Applications composed of multiple parallel libraries
                 perform poorly when those libraries interfere with one
                 another by obliviously using the same physical cores,
                 leading to destructive resource oversubscription. This
                 paper presents the design and implementation of {\em
                 Lithe}, a low-level substrate that provides the basic
                 primitives and a standard interface for composing
                 parallel codes efficiently. Lithe can be inserted
                 underneath the runtimes of legacy parallel libraries to
                 provide {\em bolt-on\/} composability without needing
                 to change existing application code. Lithe can also
                 serve as the foundation for building new parallel
                 abstractions and libraries that automatically
                 interoperate with one another.\par

                 In this paper, we show versions of Threading Building
                 Blocks (TBB) and OpenMP perform competitively with
                 their original implementations when ported to Lithe.
                 Furthermore, for two applications composed of multiple
                 parallel libraries, we show that leveraging our
                 substrate outperforms their original, even expertly
                 tuned, implementations.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "composability; cooperative scheduling; hierarchical
                 scheduling; oversubscription; parallelism; resource
                 management; user-level scheduling",
}

@Article{Zhou:2010:BDC,
  author =       "Jin Zhou and Brian Demsky",
  title =        "{Bamboo}: a data-centric, object-oriented approach to
                 many-core software",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "388--399",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806596.1806640",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Traditional data-oriented programming languages such
                 as dataflow languages and stream languages provide a
                 natural abstraction for parallel programming. In these
                 languages, a developer focuses on the flow of data
                 through the computation and these systems free the
                 developer from the complexities of low-level,
                 thread-oriented concurrency primitives. This
                 simplification comes at a cost --- traditional
                 data-oriented approaches restrict the mutation of state
                 and, in practice, the types of data structures a
                 program can effectively use. Bamboo borrows from work
                 in typestate and software transactions to relax the
                 traditional restrictions of data-oriented programming
                 models to support mutation of arbitrary data
                 structures.\par

                 We have implemented a compiler for Bamboo which
                 generates code for the TILEPro64 many-core processor.
                 We have evaluated this implementation on six
                 benchmarks: Tracking, a feature tracking algorithm from
                 computer vision; KMeans, a K-means clustering
                 algorithm; MonteCarlo, a Monte Carlo simulation;
                 FilterBank, a multi-channel filter bank; Fractal, a
                 Mandelbrot set computation; and Series, a Fourier
                 series computation. We found that our compiler
                 generated implementations that obtained speedups
                 ranging from 26.2x to 61.6x when executed on 62
                 cores.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "data-centric languages; many-core programming",
}

@Article{Westbrook:2010:MJM,
  author =       "Edwin Westbrook and Mathias Ricken and Jun Inoue and
                 Yilong Yao and Tamer Abdelatif and Walid Taha",
  title =        "{Mint}: {Java} multi-stage programming using weak
                 separability",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "400--411",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1809028.1806642",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Multi-stage programming (MSP) provides a disciplined
                 approach to run-time code generation. In the purely
                 functional setting, it has been shown how MSP can be
                 used to reduce the overhead of abstractions, allowing
                 clean, maintainable code without paying performance
                 penalties. Unfortunately, MSP is difficult to combine
                 with imperative features, which are prevalent in
                 mainstream languages. The central difficulty is scope
                 extrusion, wherein free variables can inadvertently be
                 moved outside the scopes of their binders. This paper
                 proposes a new approach to combining MSP with
                 imperative features that occupies a 'sweet spot' in the
                 design space in terms of how well useful MSP
                 applications can be expressed and how easy it is for
                 programmers to understand. The key insight is that
                 escapes (or 'anti-quotes') must be weakly separable
                 from the rest of the code, i.e. the computational
                 effects occurring inside an escape that are visible
                 outside the escape are guaranteed to not contain code.
                 To demonstrate the feasibility of this approach, we
                 formalize a type system based on Lightweight Java which
                 we prove sound, and we also provide an implementation,
                 called Mint, to validate both the expressivity of the
                 type system and the effect of staging on the
                 performance of Java programs.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "java; multi-staged languages; multi-stage programming;
                 type systems",
}

@Article{Chen:2010:TPC,
  author =       "Juan Chen and Ravi Chugh and Nikhil Swamy",
  title =        "Type-preserving compilation of end-to-end verification
                 of security enforcement",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "412--423",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806596.1806643",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "A number of programming languages use rich type
                 systems to verify security properties of code. Some of
                 these languages are meant for source programming, but
                 programs written in these languages are compiled
                 without explicit security proofs, limiting their
                 utility in settings where proofs are necessary, e.g.,
                 proof-carrying authorization. Others languages do
                 include explicit proofs, but these are generally lambda
                 calculi not intended for source programming, that must
                 be further compiled to an executable form. A language
                 suitable for source programming backed by a compiler
                 that enables end-to-end verification is missing.\par

                 In this paper, we present a type-preserving compiler
                 that translates programs written in FINE, a
                 source-level functional language with dependent
                 refinements and affine types, to DCIL, a new extension
                 of the .NET Common Intermediate Language. FINE is type
                 checked using an external SMT solver to reduce the
                 proof burden on source programmers. We extract explicit
                 LCF-style proof terms from the solver and carry these
                 proof terms in the compilation to DCIL, thereby
                 removing the solver from the trusted computing base.
                 Explicit proofs enable DCIL to be used in a number of
                 important scenarios, including the verification of
                 mobile code, proof-carrying authorization, and
                 evidence-based auditing. We report on our experience
                 using FINE to build reference monitors for several
                 applications, ranging from a plugin-based email client
                 to a conference management server.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "authorization; bytecode languages; compilers;
                 dependent types; functional programming; information
                 flow; mobile code security; security type systems",
}

@Article{Tate:2010:IOO,
  author =       "Ross Tate and Juan Chen and Chris Hawblitzel",
  title =        "Inferable object-oriented typed assembly language",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "424--435",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806596.1806644",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "A certifying compiler preserves type information
                 through compilation to assembly language programs,
                 producing typed assembly language (TAL) programs that
                 can be verified for safety independently so that the
                 compiler does not need to be trusted. There are two
                 challenges for adopting certifying compilation in
                 practice. First, requiring every compiler
                 transformation and optimization to preserve types is a
                 large burden on compilers, especially when adopting
                 certifying compilation into existing optimizing
                 non-certifying compilers. Second, type annotations
                 significantly increase the size of assembly language
                 programs.\par

                 This paper proposes an alternative to traditional
                 certifying compilers. It presents iTalX, the first
                 inferable TAL type system that supports existential
                 types, arrays, interfaces, and stacks. We have proved
                 our inference algorithm is complete, meaning if an
                 assembly language program is typeable with iTalX then
                 our algorithm will infer an iTalX typing for that
                 program. Furthermore, our algorithm is guaranteed to
                 terminate even if the assembly language program is
                 untypeable. We demonstrate that it is practical to
                 infer such an expressive TAL by showing a prototype
                 implementation of type inference for code compiled by
                 Bartok, an optimizing C\# compiler. Our prototype
                 implementation infers complete type annotations for
                 98\% of functions in a suite of realistic C\#
                 benchmarks. The type-inference time is about 8\% of the
                 compilation time. We needed to change only 2.5\% of the
                 compiler code, mostly adding new code for defining
                 types and for writing types to object files. Most
                 transformations are untouched. Type-annotation size is
                 only 17\% of the size of pure code and data, reducing
                 type annotations in our previous certifying compiler
                 [4] by 60\%. The compiler needs to preserve only
                 essential type information such as method signatures,
                 object-layout information, and types for static data
                 and external labels. Even non-certifying compilers have
                 most of this information available.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "certifying compiler; existential quantification;
                 object-oriented compiler; typed assembly language
                 (tal); type inference",
}

@Article{Khoo:2010:MTC,
  author =       "Yit Phang Khoo and Bor-Yuh Evan Chang and Jeffrey S.
                 Foster",
  title =        "Mixing type checking and symbolic execution",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "436--447",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1809028.1806645",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Static analysis designers must carefully balance
                 precision and efficiency. In our experience, many
                 static analysis tools are built around an elegant, core
                 algorithm, but that algorithm is then extensively
                 tweaked to add just enough precision for the coding
                 idioms seen in practice, without sacrificing too much
                 efficiency. There are several downsides to adding
                 precision in this way: the tool's implementation
                 becomes much more complicated; it can be hard for an
                 end-user to interpret the tool's results; and as
                 software systems vary tremendously in their coding
                 styles, it may require significant algorithmic
                 engineering to enhance a tool to perform well in a
                 particular software domain.\par

                 In this paper, we present Mix, a novel system that
                 mixes type checking and symbolic execution. The key
                 aspect of our approach is that these analyses are
                 applied independently on disjoint parts of the program,
                 in an off-the-shelf manner. At the boundaries between
                 nested type checked and symbolically executed code
                 regions, we use special mix rules to communicate
                 information between the off-the-shelf systems. The
                 resulting mixture is a provably sound analysis that is
                 more precise than type checking alone and more
                 efficient than exclusive symbolic execution. In
                 addition, we also describe a prototype implementation,
                 Mixy, for C. Mixy checks for potential null
                 dereferences by mixing a null/non-null type qualifier
                 inference system with a symbolic executor.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "false alarms; mix; mixed off-the-shelf analysis; mix
                 rules; precision; symbolic execution; type checking",
}

@Article{Chen:2010:EIO,
  author =       "Yang Chen and Yuanjie Huang and Lieven Eeckhout and
                 Grigori Fursin and Liang Peng and Olivier Temam and
                 Chengyong Wu",
  title =        "Evaluating iterative optimization across 1000
                 datasets",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "448--459",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806596.1806647",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "While iterative optimization has become a popular
                 compiler optimization approach, it is based on a
                 premise which has never been truly evaluated: that it
                 is possible to learn the best compiler optimizations
                 across data sets. Up to now, most iterative
                 optimization studies find the best optimizations
                 through repeated runs on the same data set. Only a
                 handful of studies have attempted to exercise iterative
                 optimization on a few tens of data sets.\par

                 In this paper, we truly put iterative compilation to
                 the test for the first time by evaluating its
                 effectiveness across a large number of data sets. We
                 therefore compose KDataSets, a data set suite with 1000
                 data sets for 32 programs, which we release to the
                 public. We characterize the diversity of KDataSets, and
                 subsequently use it to evaluate iterative optimization.
                 We demonstrate that it is possible to derive a robust
                 iterative optimization strategy across data sets: for
                 all 32 programs, we find that there exists at least one
                 combination of compiler optimizations that achieves
                 86\% or more of the best possible speedup across {\em
                 all\/} data sets using Intel's ICC (83\% for GNU's
                 GCC). This optimal combination is program-specific and
                 yields speedups up to 1.71 on ICC and 2.23 on GCC over
                 the highest optimization level (-fast and -O3,
                 respectively). This finding makes the task of
                 optimizing programs across data sets much easier than
                 previously anticipated, and it paves the way for the
                 practical and reliable usage of iterative optimization.
                 Finally, we derive pre-shipping and post-shipping
                 optimization strategies for software vendors.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "benchmarking; compiler optimization; iterative
                 optimization",
}

@Article{Kamruzzaman:2010:SDS,
  author =       "Md Kamruzzaman and Steven Swanson and Dean M.
                 Tullsen",
  title =        "Software data spreading: leveraging distributed caches
                 to improve single thread performance",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "460--470",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806596.1806648",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Single thread performance remains an important
                 consideration even for multicore, multiprocessor
                 systems. As a result, techniques for improving single
                 thread performance using multiple cores have received
                 considerable attention. This work describes a
                 technique, {\em software data spreading}, that
                 leverages the cache capacity of extra cores and extra
                 sockets rather than their computational resources.
                 Software data spreading is a software-only technique
                 that uses compiler-directed thread migration to
                 aggregate cache capacity across cores and chips and
                 improve performance. This paper describes an automated
                 scheme that applies data spreading to various types of
                 loops. Experiments with a set of SPEC2000, SPEC2006,
                 NAS, and microbenchmark workloads show that data
                 spreading can provide speedup of over 2, averaging 17\%
                 for the SPEC and NAS applications on two systems. In
                 addition, despite using more cores for the same
                 computation, data spreading actually saves power since
                 it reduces access to DRAM.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "chip multiprocessors; compilers; single-thread
                 performance",
}

@Article{Sartor:2010:ZRD,
  author =       "Jennifer B. Sartor and Stephen M. Blackburn and Daniel
                 Frampton and Martin Hirzel and Kathryn S. McKinley",
  title =        "{Z}-rays: divide arrays and conquer speed and
                 flexibility",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "471--482",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806596.1806649",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Arrays are the ubiquitous organization for indexed
                 data. Throughout programming language evolution,
                 implementations have laid out arrays contiguously in
                 memory. This layout is problematic in space and time.
                 It causes heap fragmentation, garbage collection pauses
                 in proportion to array size, and wasted memory for
                 sparse and over-provisioned arrays. Because of array
                 virtualization in managed languages, an array layout
                 that consists of indirection pointers to fixed-size
                 discontiguous memory blocks can mitigate these problems
                 transparently. This design however incurs significant
                 overhead, but is justified when real-time deadlines and
                 space constraints trump performance.\par

                 This paper proposes {\em z-rays}, a discontiguous array
                 design with flexibility and efficiency. A z-ray has a
                 spine with indirection pointers to fixed-size memory
                 blocks called {\em arraylets}, and uses five
                 optimizations: (1) inlining the first N array bytes
                 into the spine, (2) lazy allocation, (3) zero
                 compression, (4) fast array copy, and (5) arraylet
                 copy-on-write. Whereas discontiguous arrays in prior
                 work improve responsiveness and space efficiency,
                 z-rays combine time efficiency and flexibility. On
                 average, the best z-ray configuration performs within
                 12.7\% of an unmodified Java Virtual Machine on 19
                 benchmarks, whereas previous designs have {\em two to
                 three times\/} higher overheads. Furthermore, language
                 implementers can configure z-ray optimizations for
                 various design goals. This combination of performance
                 and flexibility creates a better building block for
                 past and future array optimization.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "arraylets; arrays; compression; heap; z-rays",
}

@Article{Acar:2010:TDT,
  author =       "Umut A. Acar and Guy Blelloch and Ruy Ley-Wild and
                 Kanat Tangwongsan and Duru Turkoglu",
  title =        "Traceable data types for self-adjusting computation",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "6",
  pages =        "483--496",
  month =        jun,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806596.1806650",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:53:18 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Self-adjusting computation provides an evaluation
                 model where computations can respond automatically to
                 modifications to their data by using a mechanism for
                 propagating modifications through the computation.
                 Current approaches to self-adjusting computation
                 guarantee correctness by recording dependencies in a
                 trace at the granularity of individual memory
                 operations. Tracing at the granularity of memory
                 operations, however, has some limitations: it can be
                 asymptotically inefficient (\eg, compared to optimal
                 solutions) because it cannot take advantage of
                 problem-specific structure, it requires keeping a large
                 computation trace (often proportional to the runtime of
                 the program on the current input), and it introduces
                 moderately large constant factors in practice.\par

                 In this paper, we extend dependence-tracing to work at
                 the granularity of the query and update operations of
                 arbitrary (abstract) data types, instead of just reads
                 and writes on memory cells. This can significantly
                 reduce the number of dependencies that need to be kept
                 in the trace and followed during an update. We define
                 an interface for supporting a traceable version of a
                 data type, which reports the earliest query that
                 depends on (is changed by) revising operations back in
                 time, and implement several such structures, including
                 priority queues, queues, dictionaries, and counters. We
                 develop a semantics for tracing, extend an existing
                 self-adjusting language, $\Delta$ML, and its
                 implementation to support traceable data types, and
                 present an experimental evaluation by considering a
                 number of benchmarks. Our experiments show dramatic
                 improvements on space and time, sometimes by as much as
                 two orders of magnitude.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "self-adjusting computation; traceable data types",
}

@Article{Chen:2010:TTT,
  author =       "Peter M. Chen",
  title =        "Transistors to toys: teaching systems to freshmen",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "7",
  pages =        "1--2",
  month =        jul,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1735997.1735998",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "How should we introduce students to the art of system
                 building, and when are students ready to start
                 designing and building interesting systems? In this
                 talk, I describe an experimental course at the
                 University of Michigan that teaches systems to freshmen
                 by having them conceive of, design, and build the
                 hardware and software of a microprocessor-based
                 educational toy. Students in this course build their
                 own microprocessor on an FPGA using a hardware
                 description language. They then write the complete
                 software stack for their toy in assembly language,
                 including device drivers for numerous I/O devices, a
                 simple file system, a graphical user interface, digital
                 audio processing, and application software. By building
                 a substantial system involving hardware, system
                 software, and application software, students gain an
                 appreciation for the complexity and beauty of building
                 computing systems.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "education",
}

@Article{Pohle:2010:CWM,
  author =       "Aaron Pohle and Bj{\"o}rn D{\"o}bel and Michael
                 Roitzsch and Hermann H{\"a}rtig",
  title =        "Capability wrangling made easy: debugging on a
                 microkernel with {{\tt valgrind}}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "7",
  pages =        "3--12",
  month =        jul,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837854.1736001",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Not all operating systems are created equal.
                 Contrasting traditional monolithic kernels, there is a
                 class of systems called microkernels more prevalent in
                 embedded systems like cellphones, chip cards or
                 real-time controllers. These kernels offer an
                 abstraction very different from the classical POSIX
                 interface. The resulting unfamiliarity for programmers
                 complicates development and debugging. Valgrind is a
                 well-known debugging tool that virtualizes execution to
                 perform dynamic binary analysis. However, it assumes to
                 run on a POSIX-like kernel and closely interacts with
                 the system to control execution. In this paper we
                 analyze how to adapt Valgrind to a non-POSIX
                 environment and describe our port to the Fiasco. OC
                 microkernel. Additionally, we analyze bug classes that
                 are indigenous to capability systems and show how
                 Valgrind's flexibility can be leveraged to create
                 custom debugging tools detecting these errors.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "capability; l4; microkernel; valgrind",
}

@Article{Chow:2010:MSR,
  author =       "Jim Chow and Dominic Lucchetti and Tal Garfinkel and
                 Geoffrey Lefebvre and Ryan Gardner and Joshua Mason and
                 Sam Small and Peter M. Chen",
  title =        "Multi-stage replay with {Crosscut}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "7",
  pages =        "13--24",
  month =        jul,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837854.1736002",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Deterministic record-replay has many useful
                 applications, ranging from fault tolerance and
                 forensics to reproducing and diagnosing bugs. When
                 choosing a record-replay solution, the system
                 administrator must choose a priori how comprehensively
                 to record the execution and at what abstraction level
                 to record it. Unfortunately, these choices may not
                 match well with how the recording is eventually used. A
                 recording may contain too little information to support
                 the end use of replay, or it may contain more sensitive
                 information than is allowed to be shown to the end user
                 of replay. Similarly, fixing the abstraction level at
                 the time of recording often leads to a semantic
                 mismatch with the end use of replay.\par

                 This paper describes how to remedy these problems by
                 adding customizable replay stages to create
                 special-purpose logs for the end users of replay. Our
                 system, called Crosscut, allows replay logs to be
                 'sliced' along time and abstraction boundaries. Using
                 this approach, users can create slices that include
                 only the processes, applications, or components of
                 interest, excluding parts that handle sensitive data.
                 Users can also retarget the abstraction level of the
                 replay log to higher-level platforms, such as Perl or
                 Valgrind. Execution can then be augmented with
                 additional analysis code at replay time, without
                 disturbing the replayed components in the slice.
                 Crosscut thus uses replay itself to transform logs into
                 a more efficient, secure, and usable form for
                 replay-based applications.\par

                 Our current Crosscut prototype builds on VMware
                 Workstation's record-replay capabilities, and supports
                 a variety of different replay environments. We show how
                 Crosscut can create slices of only the parts of the
                 computation of interest and thereby avoid leaking
                 sensitive information, and we show how to retarget the
                 abstraction level of the log to enable more convenient
                 use during replay debugging.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "design; experimentation; performance; replay;
                 security; virtual machines",
}

@Article{Huang:2010:OCD,
  author =       "Yijian Huang and Haibo Chen and Binyu Zang",
  title =        "Optimizing crash dump in virtualized environments",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "7",
  pages =        "25--36",
  month =        jul,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837854.1736003",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Crash dump, or core dump is the typical way to save
                 memory image on system crash for future offline
                 debugging and analysis. However, for typical server
                 machines with likely abundant memory, the time of core
                 dump can significantly increase the mean time to repair
                 (MTTR) by delaying the reboot-based recovery, while not
                 dumping the failure context for analysis would risk
                 recurring crashes on the same problems.\par

                 In this paper, we propose several optimization
                 techniques for core dump in virtualized environments,
                 in order to shorten the MTTR of consolidated virtual
                 machines during crashes. First, we parallelize the
                 process of crash dump and the process of rebooting the
                 crashed VM, by dynamically reclaiming and allocating
                 memory between the crashed VM and the newly spawned VM.
                 Second, we use the virtual machine management layer to
                 introspect the critical data structures of the crashed
                 VM to filter out the dump of unused memory. Finally, we
                 implement disk I/O rate control between core dump and
                 the newly spawned VM according to user-tuned rate
                 control policy to balance the time of crash dump and
                 quality of services in the recovery VM.\par

                 We have implemented a working prototype, Vicover, that
                 optimizes core dump on system crash of a virtual
                 machine in Xen, to minimize the MTTR of core dump and
                 recovery as a whole. In our experiment on a virtualized
                 TPC-W server, Vicover shortens the downtime caused by
                 crash dump by around 5X.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "core dump; parallel core dump; virtual machines",
}

@Article{Hunt:2010:LBS,
  author =       "Galen C. Hunt",
  title =        "Looking beyond a singularity",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "7",
  pages =        "37--38",
  month =        jul,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837854.1735999",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "How does one build a truly dependable software system?
                 Seven years ago, Microsoft Research started the
                 Singularity project to answer this question. The
                 premise was to start with the best known software
                 development tools and to build a new kind of operating
                 system from the ground up. The operating system was to
                 be both an output artifact and a laboratory for the
                 research. Portions of the code and ideas have been
                 incorporated into three separate Microsoft operating
                 systems so far. I will give a brief overview of
                 Singularity planned and built, then describe what we
                 learned, both positive and negative. I will speculate
                 on OS futures including current research to build an
                 operating system in which every last assembly
                 instruction has been verified for type safety, a system
                 for truly mobile computation, and new tools for
                 automatically restructuring large software systems.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "sing#; singularity; software-isolated processes
                 (sips)",
}

@Article{Titzer:2010:ICR,
  author =       "Ben L. Titzer and Thomas W{\"u}rthinger and Doug Simon
                 and Marcelo Cintra",
  title =        "Improving compiler-runtime separation with {XIR}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "7",
  pages =        "39--50",
  month =        jul,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837854.1736005",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Intense research on virtual machines has highlighted
                 the need for flexible software architectures that allow
                 quick evaluation of new design and implementation
                 techniques. The interface between the compiler and
                 runtime system is a principal factor in the flexibility
                 of both components and is critical to enabling rapid
                 pursuit of new optimizations and features. Although
                 many virtual machines have demonstrated modularity for
                 many components, significant dependencies often remain
                 between the compiler and the runtime system components
                 such as the object model and memory management system.
                 This paper addresses this challenge with a carefully
                 designed strict compiler-runtime interface and the XIR
                 language. Instead of the compiler backend lowering
                 object operations to machine operations using
                 hard-wired runtime-specific logic, XIR allows the
                 runtime system to implement this logic, simultaneously
                 simplifying and separating the backend from
                 runtime-system details. In this paper we describe the
                 design and implementation of this compiler-runtime
                 interface and the XIR language in the C1X dynamic
                 compiler, a port of the HotSpotTM Client compiler. Our
                 results show a significant reduction in backend
                 complexity with XIR and an overall reduction in the
                 compiler-runtime interface complexity while still
                 generating comparable quality code with only minor
                 impact on compilation time.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "compilers; intermediate representations; java; JIT;
                 lowering; object model; register allocation; runtime
                 interface; software architecture; virtual machines",
}

@Article{Geoffray:2010:VSM,
  author =       "Nicolas Geoffray and Ga{\"e}l Thomas and Julia Lawall
                 and Gilles Muller and Bertil Folliot",
  title =        "{VMKit}: a substrate for managed runtime
                 environments",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "7",
  pages =        "51--62",
  month =        jul,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1735997.1736006",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Managed Runtime Environments (MREs), such as the JVM
                 and the CLI, form an attractive environment for program
                 execution, by providing portability and safety, via the
                 use of a bytecode language and automatic memory
                 management, as well as good performance, via
                 just-in-time (JIT) compilation. Nevertheless,
                 developing a fully featured MRE, including e.g. a
                 garbage collector and JIT compiler, is a herculean
                 task. As a result, new languages cannot easily take
                 advantage of the benefits of MREs, and it is difficult
                 to experiment with extensions of existing MRE based
                 languages.\par

                 This paper describes and evaluates VMKit, a first
                 attempt to build a common substrate that eases the
                 development of high-level MREs. We have successfully
                 used VMKit to build two MREs: a Java Virtual Machine
                 and a Common Language Runtime. We provide an extensive
                 study of the lessons learned in developing this
                 infrastructure, and assess the ease of implementing new
                 MREs or MRE extensions and the resulting performance.
                 In particular, it took one of the authors only one
                 month to develop a Common Language Runtime using VMKit.
                 VMKit furthermore has performance comparable to the
                 well-established open-source MREs Cacao, Apache Harmony
                 and Mono, and is 1.2 to 3 times slower than JikesRVM on
                 most of the Dacapo benchmarks.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "just in time compiler; virtual machine; vmkit",
}

@Article{Zhang:2010:NSS,
  author =       "Qing Zhang and John McCullough and Justin Ma and Nabil
                 Schear and Michael Vrable and Amin Vahdat and Alex C.
                 Snoeren and Geoffrey M. Voelker and Stefan Savage",
  title =        "{Neon}: system support for derived data management",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "7",
  pages =        "63--74",
  month =        jul,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1735997.1736008",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Modern organizations face increasingly complex
                 information management requirements. A combination of
                 commercial needs, legal liability and regulatory
                 imperatives has created a patchwork of mandated
                 policies. Among these, personally identifying customer
                 records must be carefully access-controlled, sensitive
                 files must be encrypted on mobile computers to guard
                 against physical theft, and intellectual property must
                 be protected from both exposure and 'poisoning.'
                 However, enforcing such policies can be quite difficult
                 in practice since users routinely share data over
                 networks and derive new files from these
                 inputs--incidentally laundering any policy
                 restrictions. In this paper, we describe a virtual
                 machine monitor system called Neon that transparently
                 labels derived data using byte-level 'tints' and tracks
                 these labels end to end across commodity applications,
                 operating systems and networks. Our goal with Neon is
                 to explore the viability and utility of transparent
                 information flow tracking within conventional networked
                 systems when used in the manner in which they were
                 intended. We demonstrate that this mechanism allows the
                 enforcement of a variety of data management policies,
                 including data-dependent confinement, mandatory I/O
                 encryption, and intellectual property management.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "difc; memory tainting; qemu; virtualization; xen",
}

@Article{Ye:2010:EES,
  author =       "Lei Ye and Gen Lu and Sushanth Kumar and Chris Gniady
                 and John H. Hartman",
  title =        "Energy-efficient storage in virtual machine
                 environments",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "7",
  pages =        "75--84",
  month =        jul,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1735997.1736009",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Current trends in increasing storage capacity and
                 virtualization of resources combined with the need for
                 energy efficiency put a challenging task in front of
                 system designers. Previous studies have suggested many
                 approaches to reduce hard disk energy dissipation in
                 native OS environments; however, those mechanisms do
                 not perform well in virtual machine environments
                 because a virtual machine (VM) and the virtual machine
                 monitor (VMM) that runs it have different semantic
                 contexts. This paper explores the disk I/O activities
                 between VMM and VMs using trace driven simulation to
                 understand the I/O behavior of the VM system.
                 Subsequently, this paper proposes three mechanisms to
                 address the isolation between VMM and VMs, and increase
                 the burstiness of hard disk accesses to increase energy
                 efficiency of a hard disk. Compared to standard
                 shutdown mechanisms, with eight VMs the proposed
                 mechanisms reduce disk spin-ups, increase the disk
                 sleep time, and reduce energy consumption by 14.8\%
                 with only 0.5\% increase in execution time. We
                 implemented the proposed mechanisms in Xen and
                 validated our simulation results.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "energy management; storage system; virtual machine",
}

@Article{Kazempour:2010:AAA,
  author =       "Vahid Kazempour and Ali Kamali and Alexandra
                 Fedorova",
  title =        "{AASH}: an asymmetry-aware scheduler for hypervisors",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "7",
  pages =        "85--96",
  month =        jul,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837854.1736011",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Asymmetric multicore processors (AMP) consist of cores
                 exposing the same instruction-set architecture (ISA)
                 but varying in size, frequency, power consumption and
                 performance. AMPs were shown to be more power efficient
                 than conventional symmetric multicore processors, and
                 it is therefore likely that future multicore systems
                 will include cores of different types. AMPs derive
                 their efficiency from core specialization: instruction
                 streams can be assigned to run on the cores best suited
                 to their demands for architectural resources. System
                 efficiency is improved as a result. To perform
                 effective matching of threads to cores, the thread
                 scheduler must be asymmetry-aware; and while
                 asymmetry-aware schedulers for operating systems are a
                 well studied topic, asymmetry-awareness in hypervisors
                 has not been addressed. A hypervisor must be
                 asymmetry-aware to enable proper functioning of
                 asymmetry-aware guest operating systems; otherwise they
                 will be ineffective in virtual environments.
                 Furthermore, a hypervisor must ensure that asymmetric
                 cores are shared among multiple guests in a fair
                 fashion or in accordance with their
                 priorities.\par

                 This work for the first time implements simple changes
                 to the hypervisor scheduler, required to make it
                 asymmetry-aware, and evaluates the benefits and
                 overheads of these asymmetry-aware mechanisms. Our
                 evaluation was performed using an open source
                 hypervisor Xen on a real multicore system where
                 asymmetry was emulated via CPU frequency scaling. We
                 compared the asymmetry-aware hypervisor to default Xen.
                 Our results indicate that asymmetry support can be
                 implemented with low overheads, and resulting
                 performance improvements can be significant, reaching
                 up to 36\% in our experiments. Most performance
                 improvements are derived from the fact that an
                 asymmetry-aware hypervisor ensures that the fast cores
                 do not go idle before slow cores and from the fact that
                 it maps virtual cores to physical cores for
                 asymmetry-aware guests according to the guest's
                 expectations. Other benefits from asymmetry awareness
                 are fairer sharing of computing resources among VMs and
                 more stable execution times.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "asymmetric; heterogeneous; hypervisor; multicore
                 processors; scheduling algorithms; virtual machine
                 monitor",
}

@Article{Lee:2010:SSR,
  author =       "Min Lee and A. S. Krishnakumar and P. Krishnan and
                 Navjot Singh and Shalini Yajnik",
  title =        "Supporting soft real-time tasks in the {Xen}
                 hypervisor",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "7",
  pages =        "97--108",
  month =        jul,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1735997.1736012",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Virtualization technology enables server consolidation
                 and has given an impetus to low-cost green data
                 centers. However, current hypervisors do not provide
                 adequate support for real-time applications, and this
                 has limited the adoption of virtualization in some
                 domains. Soft real-time applications, such as
                 media-based ones, are impeded by components of
                 virtualization including low-performance virtualization
                 I/O, increased scheduling latency, and shared-cache
                 contention. The virtual machine scheduler is central to
                 all these issues. The goal in this paper is to adapt
                 the virtual machine scheduler to be more soft-real-time
                 friendly.\par

                 We improve two aspects of the VMM scheduler -- managing
                 scheduling latency as a first-class resource and
                 managing shared caches. We use enterprise IP telephony
                 as an illustrative soft real-time workload and design a
                 scheduler S that incorporates the knowledge of soft
                 real-time applications in {\em all\/} aspects of the
                 scheduler to support responsiveness. For this we first
                 define a {\em laxity\/} value that can be interpreted
                 as the target scheduling latency that the workload
                 desires. The load balancer is also designed to minimize
                 the latency for real-time tasks. For cache management,
                 we take cache-affinity into account for real time tasks
                 and load-balance accordingly to prevent cache
                 thrashing. We measured cache misses and demonstrated
                 that cache management is essential for soft real time
                 tasks. Although our scheduler S employs a different
                 design philosophy, interestingly enough it can be
                 implemented with simple modifications to the Xen
                 hypervisor's credit scheduler. Our experiments
                 demonstrate that the Xen scheduler with our
                 modifications can support soft real-time guests well,
                 without penalizing non-real-time domains.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "enterprise telephony workloads; laxity; server
                 consolidation; virtualization; xen",
}

@Article{Odaira:2010:ERT,
  author =       "Rei Odaira and Kazunori Ogata and Kiyokuni Kawachiya
                 and Tamiya Onodera and Toshio Nakatani",
  title =        "Efficient runtime tracking of allocation sites in
                 {Java}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "7",
  pages =        "109--120",
  month =        jul,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837854.1736014",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Tracking the allocation site of every object at
                 runtime is useful for reliable, optimized Java. To be
                 used in production environments, the tracking must be
                 accurate with minimal speed loss. Previous approaches
                 suffer from performance degradation due to the
                 additional field added to each object or track the
                 allocation sites only probabilistically. We propose two
                 novel approaches to track the allocation sites of every
                 object in Java with only a 1.0\% slow-down on average.
                 Our first approach, the {\em
                 Allocation-Site-as-a-Hash-code (ASH) Tracker}, encodes
                 the allocation site ID of an object into the hash code
                 field of its header by regarding the ID as part of the
                 hash code. ASH Tracker avoids an excessive increase in
                 hash code collisions by dynamically shrinking the
                 bit-length of the ID as more and more objects are
                 allocated at that site. For those Java VMs without the
                 hash code field, our second approach, the {\em
                 Allocation-Site-via-a-Class-pointer (ASC) Tracker},
                 makes the class pointer field in an object header refer
                 to the allocation site structure of the object, which
                 in turn points to the actual class structure. ASC
                 Tracker mitigates the indirection overhead by
                 constant-class-field duplication and allocation-site
                 equality checks. While a previous approach of adding a
                 4-byte field caused up to 14.4\% and an average 5\%
                 slowdown, both ASH and ASC Trackers incur at most a
                 2.0\% and an average 1.0\% loss. We demonstrate the
                 usefulness of our low-overhead trackers by an
                 allocation-site-aware memory leak detector and
                 allocation-site-based pretenuring in generational GC.
                 Our pretenuring achieved on average 1.8\% and up to
                 11.8\% speedups in SPECjvm2008.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "allocation site; hash code; memory allocation",
}

@Article{Tatsubori:2010:EJT,
  author =       "Michiaki Tatsubori and Akihiko Tozawa and Toyotaro
                 Suzumura and Scott Trent and Tamiya Onodera",
  title =        "Evaluation of a just-in-time compiler retrofitted for
                 {PHP}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "7",
  pages =        "121--132",
  month =        jul,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1735997.1736015",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Programmers who develop Web applications often use
                 dynamic scripting languages such as Perl, PHP, Python,
                 and Ruby. For general purpose scripting language usage,
                 interpreter-based implementations are efficient and
                 popular but the server-side usage for Web application
                 development implies an opportunity to significantly
                 enhance Web server throughput. This paper summarizes a
                 study of the optimization of PHP script processing. We
                 developed a PHP processor, P9, by adapting an existing
                 production-quality just-in-time (JIT) compiler for a
                 Java virtual machine, for which optimization
                 technologies have been well-established, especially for
                 server-side application. This paper describes and
                 contrasts microbenchmarks and SPECweb2005 benchmark
                 results for a well-tuned configuration of a traditional
                 PHP interpreter and our JIT compiler-based
                 implementation, P9. Experimental results with the
                 microbenchmarks show 2.5-9.5x advantage with P9, and
                 the SPECweb2005 measurements show about 20-30\%
                 improvements. These results show that the acceleration
                 of dynamic scripting language processing does matter in
                 a realistic Web application server environment. CPU
                 usage profiling shows our simple JIT compiler
                 introduction reduces the PHP core runtime overhead from
                 45\% to 13\% for a SPECweb2005 scenario, implying that
                 further improvements of dynamic compilers would provide
                 little additional return unless other major overheads
                 such as heavy memory copy between the language runtime
                 and Web server frontend are reduced.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "dynamic scripting languages; just-in-time compiler;
                 php",
}

@Article{Namjoshi:2010:NOP,
  author =       "Manjiri A. Namjoshi and Prasad A. Kulkarni",
  title =        "Novel online profiling for virtual machines",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "7",
  pages =        "133--144",
  month =        jul,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1735997.1736016",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Application {\em profiling\/} is a popular technique
                 to improve program performance based on its behavior.
                 {\em Offline\/} profiling, although beneficial for
                 several applications, fails in cases where prior
                 program runs may not be feasible, or if changes in
                 input cause the profile to not match the behavior of
                 the actual program run. Managed languages, like Java
                 and C\\#, provide a unique opportunity to overcome the
                 drawbacks of offline profiling by generating the
                 profile information online during the current program
                 run. Indeed, online profiling is extensively used in
                 current VMs, especially during selective compilation to
                 improve program {\em startup\/} performance, as well as
                 during other feedback-directed optimizations.\par

                 In this paper we illustrate the drawbacks of the
                 current {\em reactive\/} mechanism of online profiling
                 during selective compilation. Current VM profiling
                 mechanisms are slow -- thereby delaying associated
                 transformations, and estimate future behavior based on
                 the program's immediate past -- leading to potential
                 misspeculation that limit the benefits of compilation.
                 We show that these drawbacks produce an average
                 performance loss of over 14.5\% on our set of benchmark
                 programs, over an {\em ideal offline\/} approach that
                 accurately compiles the hot methods early. We then
                 propose and evaluate the potential of a novel strategy
                 to achieve similar performance benefits with an online
                 profiling approach. Our new online profiling strategy
                 uses early determination of loop iteration bounds to
                 predict future method hotness. We explore and present
                 promising results on the potential, feasibility, and
                 other issues involved for the successful implementation
                 of this approach.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "java; online profiling; virtual machines",
}

@Article{Guha:2010:DPS,
  author =       "Apala Guha and Kim hazelwood and Mary Lou Soffa",
  title =        "{DBT} path selection for holistic memory efficiency
                 and performance",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "7",
  pages =        "145--156",
  month =        jul,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837854.1736018",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Dynamic binary translators(DBTs) provide powerful
                 platforms for building dynamic program monitoring and
                 adaptation tools. DBTs, however, have high memory
                 demands because they cache translated code and
                 auxiliary code to a software code cache and must also
                 maintain data structures to support the code cache. The
                 high memory demands make it difficult for
                 memory-constrained embedded systems to take advantage
                 of DBT-based tools. Previous research on DBT memory
                 management focused on the translated code and auxiliary
                 code only. However, we found that data structures are
                 comparable to the code cache in size. We show that the
                 translated code size, auxiliary code size and the data
                 structure size interact in a complex manner, depending
                 on the path selection (trace selection and link
                 formation) strategy. Therefore, holistic memory
                 efficiency (comprising translated code, auxiliary code
                 and data structures) cannot be improved by focusing on
                 the code cache only. In this paper, we use path
                 selection for improving holistic memory efficiency
                 which in turn impacts performance in memory-constrained
                 environments. Although there has been previous research
                 on path selection, such research only considered
                 performance in memory-unconstrained
                 environments.\par

                 The challenge for holistic memory efficiency is that
                 the path selection strategy results in complex
                 interactions between the memory demand components.
                 Also, individual aspects of path selection and the
                 holistic memory efficiency may impact performance in
                 complex ways. We explore these interactions to motivate
                 path selection targeting holistic memory demand. We
                 enumerate all the aspects involved in a path selection
                 design and evaluate a comprehensive set of approaches
                 for each aspect. Finally, we propose a path selection
                 strategy that reduces memory demands by 20\% and at the
                 same time improves performance by 5-20\% compared to an
                 industrial-strength DBT.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "dynamic binary translation; embedded systems; memory
                 management; path selection; virtual machines",
}

@Article{Kondoh:2010:DBT,
  author =       "Goh Kondoh and Hideaki Komatsu",
  title =        "Dynamic binary translation specialized for embedded
                 systems",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "7",
  pages =        "157--166",
  month =        jul,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1735997.1736019",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:01 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "This paper describes the design and implementation of
                 a novel dynamic binary translation technique
                 specialized for embedded systems. Virtual platforms
                 have been widely used to develop embedded software and
                 dynamic binary translation is essential to boost their
                 speed in simulations. However, unlike application
                 simulation, the code generated for systems simulation
                 is still slow because the simulator must replicate all
                 of the functions of the target hardware. Embedded
                 systems, which focus on providing one or a few
                 functions, utilize only a small portion of the
                 processor's features most of the time. For example,
                 they may use a Memory Management Unit (MMU) in a
                 processor to map physical memory to effective
                 addresses, but they may not need paged memory support
                 as in an OS. We can exploit this to specialize the
                 dynamically translated code for more
                 performance.\par

                 We built a specialization framework on top of a
                 functional simulator with a dynamic binary translator.
                 Using the framework, we implemented three specializers
                 for an MMU, bi-endianness, and register banks.
                 Experiments with the EEMBC1.1 benchmark showed that the
                 speed of the specialized code was up to 39\% faster
                 than the unspecialized code.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "dynamic binary translation; embedded systems; partial
                 evaluation; specialization",
}

@Article{Barabash:2010:TGC,
  author =       "Katherine Barabash and Erez Petrank",
  title =        "Tracing garbage collection on highly parallel
                 platforms",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "8",
  pages =        "1--10",
  month =        aug,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837855.1806653",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:48 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "The pervasiveness of multiprocessor and multicore
                 hardware and the rising level of available parallelism
                 are radically changing the computing landscape. Can
                 software deal with tomorrow's potential higher
                 parallelism? In this paper we study this issue from the
                 garbage collection perspective. In particular, we
                 investigate the scalability of parallel heap tracing,
                 which stands at the core of the garbage collection
                 activity. Heap shapes can be sequential in nature, and
                 prevent the collector from scaling the trace. We start
                 by proposing the idealized trace utilization as a
                 scalability measure for evaluating the scalability of a
                 given heap shape. We then examine standard Java
                 benchmarks and evaluate the existence of non-scalable
                 object-graph shapes in their execution. Next, we
                 propose and implement a prototype of garbage collection
                 techniques that attempt to ameliorate the object-graph
                 shape problem. Finally, we measure and report their
                 efficacy.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "garbage collection; memory management; parallel
                 garbage collection; runtime systems",
}

@Article{Siebert:2010:CPR,
  author =       "Fridtjof Siebert",
  title =        "Concurrent, parallel, real-time garbage-collection",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "8",
  pages =        "11--20",
  month =        aug,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837855.1806654",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:48 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "With the current developments in CPU implementations,
                 it becomes obvious that ever more parallel multicore
                 systems will be used even in embedded controllers that
                 require real-time guarantees. When garbage collection
                 is used in these systems, parallel and concurrent
                 garbage collection brings important performance
                 advantages in the average case. In a real-time system,
                 however, guarantees on the GC's performance in the
                 worst case are required.\par

                 This paper explains how the single-CPU real-time GC of
                 the Java implementation JamaicaVM was changed to make
                 it a hard real-time garbage collector that is parallel
                 and concurrent. Parallel means that an arbitrary number
                 of CPUs may perform GC work in parallel, while
                 concurrent means that the GC work can be performed
                 concurrently to the application code without
                 pre-empting the application. In addition, the single
                 units of work that this garbage collector has to
                 perform are very small and uniform and the total amount
                 of GC work is bounded by a function of the heap size,
                 such that it becomes possible for any application that
                 has a bounded amount of reachable memory to run the GC
                 work such that sufficient GC progress can be ensured
                 for the application never to run out of heap space.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "concurrent; garbage collection; java; multicore;
                 parallel; real-time",
}

@Article{Anderson:2010:OPN,
  author =       "Todd A. Anderson",
  title =        "Optimizations in a private nursery-based garbage
                 collector",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "8",
  pages =        "21--30",
  month =        aug,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837855.1806655",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:48 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "This paper describes a garbage collector designed
                 around the use of permanent, private, thread-local
                 nurseries and is principally oriented towards
                 functional languages. We try to maximize the cache hit
                 rate by having threads continually reuse their
                 individual private nurseries. These private nurseries
                 operate in such a way that they can be garbage
                 collected independently of other threads, which creates
                 low collection pause times. Objects which survive
                 thread-local collections are moved to a mature
                 generation that can be collected either concurrently or
                 in a stop-the-world fashion. We describe several
                 optimizations (including two dynamic control parameter
                 adaptation schemes) related to garbage collecting the
                 private nurseries and to our concurrent collector, some
                 of which are made possible when the language provides
                 mutability information. We tested our collector against
                 six benchmarks and saw single-threaded performance
                 improvements in the range of 5-74\%. We also saw a 10x
                 increase (for 24 processors) in scalability for one
                 parallel benchmark that had previously been
                 memory-bound.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "functional languages; garbage collection",
}

@Article{Nagarakatte:2010:CCE,
  author =       "Santosh Nagarakatte and Jianzhou Zhao and Milo M. K.
                 Martin and Steve Zdancewic",
  title =        "{CETS}: compiler enforced temporal safety for {C}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "8",
  pages =        "31--40",
  month =        aug,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837855.1806657",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:48 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Temporal memory safety errors, such as dangling
                 pointer dereferences and double frees, are a prevalent
                 source of software bugs in unmanaged languages such as
                 C. Existing schemes that attempt to retrofit temporal
                 safety for such languages have high runtime overheads
                 and/or are incomplete, thereby limiting their
                 effectiveness as debugging aids. This paper presents
                 CETS, a compile-time transformation for detecting all
                 violations of temporal safety in C programs. Inspired
                 by existing approaches, CETS maintains a unique
                 identifier with each object, associates this metadata
                 with the pointers in a disjoint metadata space to
                 retain memory layout compatibility, and checks that the
                 object is still allocated on pointer dereferences. A
                 formal proof shows that this is sufficient to provide
                 temporal safety even in the presence of arbitrary casts
                 if the program contains no spatial safety violations.
                 Our CETS prototype employs both temporal check removal
                 optimizations and traditional compiler optimizations to
                 achieve a runtime overhead of just 48\% on average.
                 When combined with a spatial-checking system, the
                 average overall overhead is 116\% for complete memory
                 safety",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "c; dangling pointers; memory safety; temporal errors",
}

@Article{Vechev:2010:PPC,
  author =       "Martin Vechev and Eran Yahav and Greta Yorsh",
  title =        "{PHALANX}: parallel checking of expressive heap
                 assertions",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "8",
  pages =        "41--50",
  month =        aug,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837855.1806658",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:48 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Unrestricted use of heap pointers makes software
                 systems difficult to understand and to debug. To
                 address this challenge, we developed PHALANX -- a
                 practical framework for dynamically checking expressive
                 heap properties such as ownership, sharing and
                 reachability. PHALANX uses novel parallel algorithms to
                 efficiently check a wide range of heap properties
                 utilizing the available cores.\par

                 PHALANX runtime is implemented on top of IBM's Java
                 production virtual machine. This has enabled us to
                 apply our new techniques to real world software. We
                 checked expressive heap properties in various scenarios
                 and found the runtime support to be valuable for
                 debugging and program understanding. Further, our
                 experimental results on DaCapo and other benchmarks
                 indicate that evaluating heap queries using parallel
                 algorithms can lead to significant performance
                 improvements, often resulting in linear speedups as the
                 number of cores increases.\par

                 To encourage adoption by programmers, we extended an
                 existing JML compiler to translate expressive JML
                 assertions about the heap into their efficient
                 implementation provided by PHALANX. To debug her
                 program, a programmer can annotate it with expressive
                 heap assertions in JML, that are efficiently checked by
                 PHALANX.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "ownership; parallel garbage collector; virtual
                 machine",
}

@Article{Sewell:2010:MEA,
  author =       "Peter Sewell",
  title =        "Memory, an elusive abstraction",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "8",
  pages =        "51--52",
  month =        aug,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806651.1806660",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:48 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Multiprocessors are now ubiquitous. They provide an
                 abstraction of shared memory, accessible by
                 concurrently executing threads, which supports a wide
                 range of software. However, exactly what this key
                 abstraction is -- what the hardware designers
                 implement, and what programmers can depend on -- is
                 surprisingly elusive. In 1979, when articulating the
                 notion of sequential consistency (SC), Lamport wrote
                 'For some applications, achieving sequential
                 consistency may not be worth the price of slowing down
                 the processors.' [7], and indeed most major
                 multiprocessor families, including Alpha, ARM, Itanium,
                 Power, Sparc, and x86, do not provide the abstraction
                 of SC memory. Internally, they incorporate a range of
                 sophisticated optimisations which have various
                 programmer-visible effects. For some (such as Sparc)
                 these effects are captured in a well-defined relaxed
                 memory model, making it possible (if challenging) to
                 reason with confidence about the behaviour of
                 concurrent programs. For others, however, it has been
                 very unclear what a reasonable model is, despite
                 extensive research over the last three decades. In this
                 talk, I will reflect on the experience of my colleagues
                 and I in trying to establish usable models for x86
                 multiprocessors, where it appears that our x86-TSO
                 model suffices for common-case code [1-4], and for
                 Power and ARM multiprocessors, where we have models
                 that capture some but not all aspects of their
                 behaviour [5,6]. The underlying causes of these
                 difficulties are complex, including:\par

                 The programmer-observable relaxed-memory behaviour of a
                 multiprocessor is a whole-system property that arises
                 from the interaction between many complex aspects of
                 the processor implementation: speculative execution,
                 store buffering, cache protocol, and so forth.

                 Programs are executed (and tested) on specific
                 multiprocessor implementations, but processor vendors
                 attempt to document loose specifications to cover a
                 range of possible (past and future)
                 implementations

                 Multiprocessor implementation details are typically
                 confidential and may change radically from one
                 implementation to another

                 Vendor specifications suffer from the tension between
                 the need for loose specification, to preserve freedom
                 for such changes, and the need for tight specification,
                 to give strong properties to properties

                 All too often, loose specification has been achieved by
                 vague specification, using informal prose. When it
                 comes to subtle concurrent properties this is almost
                 inevitably ambiguous; it also makes it impossible (even
                 in principle) to test conformance between a processor
                 implementation and such a specification, let alone to
                 verify such a correspondence or to reason about
                 concurrent programs.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "relaxed memory models; semantics",
}

@Article{Petricek:2010:CHG,
  author =       "Tomas Petricek and Don Syme",
  title =        "Collecting {Hollywood}'s garbage: avoiding space-leaks
                 in composite events",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "8",
  pages =        "53--62",
  month =        aug,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1837855.1806662",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:48 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "The reactive programming model is largely different to
                 what we're used to as we don't have full control over
                 the application's control flow. If we mix the
                 declarative and imperative programming style, which is
                 usual in the ML family of languages, the situation is
                 even more complex. It becomes easy to introduce
                 patterns where the usual garbage collector for objects
                 cannot automatically dispose all components that we
                 intuitively consider garbage.\par

                 In this paper we discuss a duality between the
                 definitions of garbage for {\em objects\/} and {\em
                 events}. We combine them into a single one, to specify
                 the notion of garbage for reactive programming model in
                 a mixed functional/imperative language and we present a
                 formal algorithm for collecting garbage in this
                 environment.\par

                 Building on top of the theoretical model, we implement
                 a library for reactive programming that does not cause
                 leaks when used in the mixed declarative/imperative
                 model. The library allows us to safely combine both of
                 the reactive programming patterns. As a result, we can
                 take advantage of the clarity and simplicity of the
                 declarative approach as well as the expressivity of the
                 imperative model.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "combinator libraries; duality; event-driven; garbage
                 collection; inversion of control; reactive
                 programming",
}

@Article{Tian:2010:SPU,
  author =       "Chen Tian and Min Feng and Rajiv Gupta",
  title =        "Speculative parallelization using state separation and
                 multiple value prediction",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "8",
  pages =        "63--72",
  month =        aug,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806651.1806663",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:48 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "With the availability of chip multiprocessor (CMP) and
                 simultaneous multithreading (SMT) machines, extracting
                 thread level parallelism from a sequential program has
                 become crucial for improving performance. However, many
                 sequential programs cannot be easily parallelized due
                 to the presence of dependences. To solve this problem,
                 different solutions have been proposed. Some of them
                 make the optimistic assumption that such dependences
                 rarely manifest themselves at runtime. However, when
                 this assumption is violated, the recovery causes very
                 large overhead. Other approaches incur large
                 synchronization or computation overhead when resolving
                 the dependences. Consequently, for a loop with
                 frequently arising cross-iteration dependences,
                 previous techniques are not able to speed up the
                 execution. In this paper we propose a compiler
                 technique which uses state separation and multiple
                 value prediction to speculatively parallelize loops in
                 sequential programs that contain frequently arising
                 cross-iteration dependences. The key idea is to
                 generate multiple versions of a loop iteration based on
                 multiple predictions of values of variables involved in
                 cross-iteration dependences (i.e., live-in variables).
                 These speculative versions and the preceding loop
                 iteration are executed in separate memory states
                 simultaneously. After the execution, if one of these
                 versions is correct (i.e., its predicted values are
                 found to be correct), then we merge its state and the
                 state of the preceding iteration because the dependence
                 between the two iterations is correctly resolved. The
                 memory states of other incorrect versions are
                 completely discarded. Based on this idea, we further
                 propose a runtime adaptive scheme that not only gives a
                 good performance but also achieves better CPU
                 utilization. We conducted experiments on 10 benchmark
                 programs on a real machine. The results show that our
                 technique can achieve 1.7x speedup on average across
                 all used benchmarks.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "multicore processors; speculative parallelization",
}

@Article{Ugawa:2010:IRB,
  author =       "Tomoharu Ugawa and Hideya Iwasaki and Taiichi Yuasa",
  title =        "Improved replication-based incremental garbage
                 collection for embedded systems",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "8",
  pages =        "73--82",
  month =        aug,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806651.1806664",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:48 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "We have developed an incremental compacting garbage
                 collector for embedded Java systems. The collector
                 divides the heap into equal sized pages and uses the
                 segregated free lists for fast allocation. Collectors
                 that have such a heap layout have a problem of
                 fragmentation in allocating objects larger than the
                 page size. We solve this problem by using the
                 replication-based incremental compaction. The compactor
                 evacuates all objects in one area, the evacuation area,
                 of the heap, thereby creating a large chunk of free
                 space. We developed an algorithm for choosing the
                 evacuation area that effectively cures fragmentation.
                 The compactor does not use any read-barriers. Instead,
                 it uses a technique similar to the replication-based
                 incremental copying collection. This needs forwarding
                 pointers for all evacuated objects. Rather than
                 introducing an extra field for each object, we use a
                 hash table to store forwarding pointers.\par

                 Evaluation of this garbage collector implemented in
                 Sun's J2ME Java Virtual Machine showed that all the
                 benchmarks used were able to run without memory
                 starvation using the heap sizes of only 151\%-286\% of
                 the maximum amount of live data plus 8 KB of the hash
                 table. Experiments on a desktop computer, though it is
                 not a platform for embedded systems, showed that the
                 maximum pause time was shorter than 200 &\#956;s, which
                 was comparable to that of our implementation of the
                 snapshot-at-the-beginning collector without compaction.
                 On an ARM processor, the runtime overhead was 1\%-16\%
                 with 8.0\% on average compared to the mark-sweep
                 collector.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "compaction; embedded systems; fragmentation; garbage
                 collection; real-time garbage collection",
}

@Article{Hellyer:2010:LCW,
  author =       "Laurence Hellyer and Richard Jones and Antony L.
                 Hosking",
  title =        "The locality of concurrent write barriers",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "8",
  pages =        "83--92",
  month =        aug,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806651.1806666",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:48 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Concurrent and incremental collectors require barriers
                 to ensure correct synchronisation between mutator and
                 collector. The overheads imposed by particular barriers
                 on particular systems have been widely studied.
                 Somewhat fewer studies have also compared barriers in
                 terms of their termination properties or the volume of
                 floating garbage they generate. Until now, the
                 consequences for locality of different barrier choices
                 has not been studied, although locality will be of
                 increasing importance for emerging architectures. This
                 paper provides a study of the locality of concurrent
                 write barriers, independent of the processor
                 architecture, virtual machine, compiler or garbage
                 collection algorithm.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "garbage collection; java; language implementation;
                 memory management",
}

@Article{Zhao:2010:EMS,
  author =       "Qin Zhao and Derek Bruening and Saman Amarasinghe",
  title =        "Efficient memory shadowing for 64-bit architectures",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "8",
  pages =        "93--102",
  month =        aug,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806651.1806667",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:48 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Shadow memory is used by dynamic program analysis
                 tools to store metadata for tracking properties of
                 application memory. The efficiency of mapping between
                 application memory and shadow memory has substantial
                 impact on the overall performance of such analysis
                 tools. However, traditional memory mapping schemes that
                 work well on 32-bit architectures cannot easily port to
                 64-bit architectures due to the much larger 64-bit
                 address space.\par

                 This paper presents EMS64, an efficient memory
                 shadowing scheme for 64-bit architectures. By taking
                 advantage of application reference locality and unused
                 regions in the 64-bit address space, EMS64 provides a
                 fast and flexible memory mapping scheme without relying
                 on any underlying platform features or requiring any
                 specific shadow memory size. Our experiments show that
                 EMS64 is able to reduce the runtime shadow memory
                 translation overhead to 81\% on average, which almost
                 halves the overhead of the fastest 64-bit shadow memory
                 system we are aware of.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "dynamic optimization; shadow memory",
}

@Article{Singer:2010:EGC,
  author =       "Jeremy Singer and Richard E. Jones and Gavin Brown and
                 Mikel Luj{\'a}n",
  title =        "The economics of garbage collection",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "8",
  pages =        "103--112",
  month =        aug,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806651.1806669",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:48 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "This paper argues that economic theory can improve our
                 understanding of memory management. We introduce the
                 {\em allocation curve}, as an analogue of the demand
                 curve from microeconomics. An allocation curve for a
                 program characterises how the amount of garbage
                 collection activity required during its execution
                 varies in relation to the heap size associated with
                 that program. The standard treatment of microeconomic
                 demand curves (shifts and elasticity) can be applied
                 directly and intuitively to our new allocation curves.
                 As an application of this new theory, we show how {\em
                 allocation elasticity\/} can be used to control the
                 heap growth rate for variable sized heaps in Jikes
                 RVM.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "allocation curve; elasticity; garbage collection;
                 java; memory management; microeconomics",
}

@Article{Beg:2010:GTA,
  author =       "Mirza Beg and Peter van Beek",
  title =        "A graph theoretic approach to cache-conscious
                 placement of data for direct mapped caches",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "8",
  pages =        "113--120",
  month =        aug,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806651.1806670",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:48 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Caches were designed to amortize the cost of memory
                 accesses by moving copies of frequently accessed data
                 closer to the processor. Over the years the increasing
                 gap between processor speed and memory access latency
                 has made the cache a bottleneck for program
                 performance. Enhancing cache performance has been
                 instrumental in speeding up programs. For this reason
                 several hardware and software techniques have been
                 proposed by researchers to optimize the cache for
                 minimizing the number of misses. Among these are
                 compile-time data placement techniques in memory which
                 improve cache performance. For the purpose of this
                 work, we concern ourselves with the problem of laying
                 out data in memory given the sequence of accesses on a
                 finite set of data objects such that cache-misses are
                 minimized. The problem has been shown to be hard to
                 solve optimally even if the sequence of data accesses
                 is known at compile time. In this paper we show that
                 given a direct-mapped cache, its size, and the data
                 access sequence, it is possible to identify the
                 instances where there are no conflict misses. We
                 describe an algorithm that can assign the data to cache
                 for minimal number of misses if there exists a way in
                 which conflict misses can be avoided altogether. We
                 also describe the implementation of a heuristic for
                 assigning data to cache for instances where the size of
                 the cache forces conflict misses. Experiments show that
                 our technique results in a 30\% reduction in the number
                 of cache misses compared to the original assignment.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "cache consciousness; cache optimization; data
                 placement in cache; memory management; offline
                 algorithms",
}

@Article{Albert:2010:PIM,
  author =       "Elvira Albert and Samir Genaim and Miguel
                 G{\'o}mez-Zamalloa",
  title =        "Parametric inference of memory requirements for
                 garbage collected languages",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "8",
  pages =        "121--130",
  month =        aug,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://doi.acm.org/10.1145/1806651.1806671",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Oct 8 17:55:48 MDT 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "The accurate prediction of program's memory
                 requirements is a critical component in software
                 development. Existing heap space analyses either do not
                 take deallocation into account or adopt specific models
                 of garbage collectors which do not necessarily
                 correspond to the actual memory usage. We present a
                 novel approach to inferring upper bounds on memory
                 requirements of Java-like programs which is {\em
                 parametric\/} on the notion of {\em object lifetime},
                 i.e., on when objects become collectible. If objects
                 lifetimes are inferred by a reachability analysis, then
                 our analysis infers accurate upper bounds on the memory
                 consumption for a {\em reachability\/} -based garbage
                 collector. Interestingly, if objects lifetimes are
                 inferred by a {\em heap liveness\/} analysis, then we
                 approximate the program minimal memory requirement,
                 i.e., the peak memory usage when using an optimal
                 garbage collector which frees objects as soon as they
                 become dead. The key idea is to integrate information
                 on objects lifetimes into the process of generating the
                 {\em recurrence equations\/} which capture the memory
                 usage at the different program states. If the heap size
                 limit is set to the memory requirement inferred by our
                 analysis, it is ensured that execution will not exceed
                 the memory limit with the only assumption that garbage
                 collection works when the limit is reached. Experiments
                 on Java bytecode programs provide evidence of the
                 feasibility and accuracy of our analysis.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "garbage collection; java bytecode; live heap space
                 analysis; low-level languages; peak memory
                 consumption",
}

@Article{Gordon:2010:MMO,
  author =       "Michael J. C. Gordon",
  title =        "{ML}: metalanguage or object language?",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "1--2",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863545",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Chapman:2010:GAL,
  author =       "James Chapman and Pierre-{\'E}variste Dagand and Conor
                 McBride and Peter Morris",
  title =        "The gentle art of levitation",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "3--14",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863547",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Vytiniotis:2010:FPE,
  author =       "Dimitrios Vytiniotis and Andrew J. Kennedy",
  title =        "Functional pearl: every bit counts",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "15--26",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863548",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Buisson:2010:RES,
  author =       "J{\'e}r{\'e}my Buisson and Fabien Dagnat",
  title =        "{ReCaml}: execution state as the cornerstone of
                 reconfigurations",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "27--38",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863550",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Mazurak:2010:LCC,
  author =       "Karl Mazurak and Steve Zdancewic",
  title =        "{Lolliproc}: to concurrency from classical linear
                 logic via {Curry--Howard} and control",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "39--50",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863551",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Horn:2010:AAM,
  author =       "David Van Horn and Matthew Might",
  title =        "Abstracting abstract machines",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "51--62",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863553",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Holdermans:2010:PFA,
  author =       "Stefan Holdermans and Jurriaan Hage",
  title =        "Polyvariant flow analysis with higher-ranked
                 polymorphic types and higher-order effect operators",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "63--74",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863554",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Naylor:2010:RR,
  author =       "Matthew Naylor and Colin Runciman",
  title =        "The {Reduceron} reconfigured",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "75--86",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863556",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "The leading implementations of graph reduction all
                 target conventional processors designed for low-level
                 imperative execution. In this paper, we present a
                 processor specially designed to perform
                 graph-reduction. Our processor the Reduceron is
                 implemented using off-the-shelf reconfigurable
                 hardware. We highlight the lowlevel parallelism present
                 in sequential graph reduction, and show how parallel
                 memories and dynamic analyses are used in the Reduceron
                 to achieve an average reduction rate of 0.55 function
                 applications per clock-cycle.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Scott:2010:UFP,
  author =       "David Scott and Richard Sharp and Thomas Gazagnaire
                 and Anil Madhavapeddy",
  title =        "Using functional programming within an industrial
                 product group: perspectives and perceptions",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "87--92",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863557",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Bergstrom:2010:LTS,
  author =       "Lars Bergstrom and Mike Rainey and John Reppy and Adam
                 Shaw and Matthew Fluet",
  title =        "Lazy tree splitting",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "93--104",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863558",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Bierman:2010:SSS,
  author =       "Gavin M. Bierman and Andrew D. Gordon and Catalin
                 Hritcu and David Langworthy",
  title =        "Semantic subtyping with an {SMT} solver",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "105--116",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863560",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Tobin-Hochstadt:2010:LTU,
  author =       "Sam Tobin-Hochstadt and Matthias Felleisen",
  title =        "Logical types for untyped languages",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "117--128",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863561",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Felleisen:2010:TC,
  author =       "Matthias Felleisen",
  title =        "{TeachScheme!}: a checkpoint",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "129--130",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863563",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Crary:2010:HOR,
  author =       "Karl Crary",
  title =        "Higher-order representation of substructural logics",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "131--142",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863565",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Dreyer:2010:IHO,
  author =       "Derek Dreyer and Georg Neis and Lars Birkedal",
  title =        "The impact of higher-order state and control effects
                 on local relational reasoning",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "143--156",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863566",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Reed:2010:DMT,
  author =       "Jason Reed and Benjamin C. Pierce",
  title =        "Distance makes the types grow stronger: a calculus for
                 differential privacy",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "157--168",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863568",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Morgenstern:2010:STP,
  author =       "Jamie Morgenstern and Daniel R. Licata",
  title =        "Security-typed programming within dependently typed
                 programming",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "169--180",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863569",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Voigtlander:2010:CSS,
  author =       "Janis Voigtl{\"a}nder and Zhenjiang Hu and Kazutaka
                 Matsuda and Meng Wang",
  title =        "Combining syntactic and semantic
                 bidirectionalization",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "181--192",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863571",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Barbosa:2010:MLA,
  author =       "Davi M. J. Barbosa and Julien Cretin and Nate Foster
                 and Michael Greenberg and Benjamin C. Pierce",
  title =        "Matching lenses: alignment and view update",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "193--204",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863572",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Hidaka:2010:BGT,
  author =       "Soichiro Hidaka and Zhenjiang Hu and Kazuhiro Inaba
                 and Hiroyuki Kato and Kazutaka Matsuda and Keisuke
                 Nakano",
  title =        "Bidirectionalizing graph transformations",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "205--216",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863573",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Pouillard:2010:FLP,
  author =       "Nicolas Pouillard and Fran{\c{c}}ois Pottier",
  title =        "A fresh look at programming with names and binders",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "217--228",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863575",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Crestani:2010:ERG,
  author =       "Marcus Crestani and Michael Sperber",
  title =        "Experience report: growing programming languages for
                 beginning students",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "229--234",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863576",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Culpepper:2010:FM,
  author =       "Ryan Culpepper and Matthias Felleisen",
  title =        "Fortifying macros",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "235--246",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863577",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Blelloch:2010:FPA,
  author =       "Guy E. Blelloch",
  title =        "Functional parallel algorithms",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "247--248",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863579",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Arnold:2010:SVS,
  author =       "Gilad Arnold and Johannes H{\"o}lzl and Ali Sinan
                 K{\"o}ksal and Rastislav Bod{\'\i}k and Mooly Sagiv",
  title =        "Specifying and verifying sparse matrix codes",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "249--260",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863581",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Keller:2010:RSP,
  author =       "Gabriele Keller and Manuel M. T. Chakravarty and Roman
                 Leshchinskiy and Simon Peyton Jones and Ben Lippmeier",
  title =        "Regular, shape-polymorphic, parallel arrays in
                 {Haskell}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "261--272",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863582",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{McCreight:2010:CFC,
  author =       "Andrew McCreight and Tim Chevalier and Andrew
                 Tolmach",
  title =        "A certified framework for compiling and executing
                 garbage-collected languages",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "273--284",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863584",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Danielsson:2010:TPC,
  author =       "Nils Anders Danielsson",
  title =        "Total parser combinators",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "285--296",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863585",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Brady:2010:SYI,
  author =       "Edwin C. Brady and Kevin Hammond",
  title =        "Scrapping your inefficient engine: using partial
                 evaluation to improve domain-specific language
                 implementation",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "297--308",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863587",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Mitchell:2010:RS,
  author =       "Neil Mitchell",
  title =        "Rethinking supercompilation",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "309--320",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863588",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Chargueraud:2010:PVT,
  author =       "Arthur Chargu{\'e}raud",
  title =        "Program verification through characteristic formulae",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "321--332",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863590",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Stampoulis:2010:VTC,
  author =       "Antonis Stampoulis and Zhong Shao",
  title =        "{VeriML}: typed computation of logical terms inside a
                 language with effects",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "333--344",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863591",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Bernardy:2010:PDT,
  author =       "Jean-Philippe Bernardy and Patrik Jansson and Ross
                 Paterson",
  title =        "Parametricity and dependent types",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "345--356",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863592",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Fischer:2010:PRE,
  author =       "Sebastian Fischer and Frank Huch and Thomas Wilke",
  title =        "A play on regular expressions: functional pearl",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "357--368",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863594",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Pop:2010:ERH,
  author =       "Iustin Pop",
  title =        "Experience report: {Haskell} as a reagent: results and
                 observations on the use of {Haskell} in a {Python}
                 project",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "369--374",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863595",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Morris:2010:ICT,
  author =       "J. Garrett Morris and Mark P. Jones",
  title =        "Instance chains: type class programming without
                 overlapping instances",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "9",
  pages =        "375--386",
  month =        sep,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932681.1863596",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:43 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Forrest:2010:CES,
  author =       "Stephanie Forrest",
  title =        "The case for evolvable software",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "1--1",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869539",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Pierce:2010:ASF,
  author =       "Benjamin C. Pierce",
  title =        "Art, science, and fear",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "2--2",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869540",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Syme:2010:FTS,
  author =       "Don Syme",
  title =        "{F\#}: Taking Succinct, Efficient, Typed Functional
                 Programming into the Mainstream",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "3--3",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1921682",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Stanley:2010:AOH,
  author =       "Kenneth O. Stanley",
  title =        "To achieve our highest goals, we must be willing to
                 abandon them",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "3--3",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869541",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Roberson:2010:EMG,
  author =       "Michael Roberson and Chandrasekhar Boyapati",
  title =        "Efficient modular glass box software model checking",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "4--21",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869461",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Hanenberg:2010:EAS,
  author =       "Stefan Hanenberg",
  title =        "An experiment about static and dynamic type systems:
                 doubts about the positive impact of static type systems
                 on development time",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "22--35",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869462",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Itzhaky:2010:SIS,
  author =       "Shachar Itzhaky and Sumit Gulwani and Neil Immerman
                 and Mooly Sagiv",
  title =        "A simple inductive synthesis methodology and its
                 applications",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "36--46",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869463",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Mercadal:2010:DSA,
  author =       "Julien Mercadal and Quentin Enard and Charles Consel
                 and Nicolas Loriant",
  title =        "A domain-specific approach to architecturing error
                 handling in pervasive computing",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "47--61",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869465",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Li:2010:GFR,
  author =       "Wei Li and Charles Zhang and Songlin Hu",
  title =        "{G-Finder}: routing programming questions closer to
                 the experts",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "62--73",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869466",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Hoda:2010:AC,
  author =       "Rashina Hoda and Philippe Kruchten and James Noble and
                 Stuart Marshall",
  title =        "Agility in context",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "74--88",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869467",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Auerbach:2010:LJC,
  author =       "Joshua Auerbach and David F. Bacon and Perry Cheng and
                 Rodric Rabbah",
  title =        "{Lime}: a {Java}-compatible and synthesizable language
                 for heterogeneous architectures",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "89--108",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869469",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Kou:2010:OFF,
  author =       "Stephen Kou and Jens Palsberg",
  title =        "From {OO} to {FPGA}: fitting round objects into square
                 hardware?",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "109--124",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869470",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Tian:2010:ICP,
  author =       "Kai Tian and Yunlian Jiang and Eddy Z. Zhang and
                 Xipeng Shen",
  title =        "An input-centric paradigm for program dynamic
                 optimizations",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "125--139",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869471",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Wood:2010:CSS,
  author =       "Benjamin P. Wood and Adrian Sampson and Luis Ceze and
                 Dan Grossman",
  title =        "Composable specifications for structured shared-memory
                 communication",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "140--159",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869473",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Shi:2010:DUW,
  author =       "Yao Shi and Soyeon Park and Zuoning Yin and Shan Lu
                 and Yuanyuan Zhou and Wenguang Chen and Weimin Zheng",
  title =        "Do {I} use the wrong definition?: {DeFuse}:
                 definition-use invariants for detecting concurrency and
                 sequential bugs",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "160--174",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869474",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Gabel:2010:SSD,
  author =       "Mark Gabel and Junfeng Yang and Yuan Yu and Moises
                 Goldszmidt and Zhendong Su",
  title =        "Scalable and systematic detection of buggy
                 inconsistencies in source code",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "175--190",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869475",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Ogata:2010:SJN,
  author =       "Kazunori Ogata and Dai Mikurube and Kiyokuni Kawachiya
                 and Scott Trent and Tamiya Onodera",
  title =        "A study of {Java}'s non-{Java} memory",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "191--204",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869477",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{McIlroy:2010:HJR,
  author =       "Ross McIlroy and Joe Sventek",
  title =        "{Hera-JVM}: a runtime system for heterogeneous
                 multi-core architectures",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "205--222",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869478",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Wegiel:2010:CLT,
  author =       "Michal Wegiel and Chandra Krintz",
  title =        "Cross-language, type-safe, and transparent object
                 sharing for co-located managed runtimes",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "223--240",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869479",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Jin:2010:ISS,
  author =       "Guoliang Jin and Aditya Thakur and Ben Liblit and Shan
                 Lu",
  title =        "Instrumentation and sampling strategies for
                 cooperative concurrency bug isolation",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "241--255",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869481",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Reichenbach:2010:WCG,
  author =       "Christoph Reichenbach and Neil Immerman and Yannis
                 Smaragdakis and Edward E. Aftandilian and Samuel Z.
                 Guyer",
  title =        "What can the {GC} compute efficiently?: a language for
                 heap assertions at {GC} time",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "256--269",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869482",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Purandare:2010:MOS,
  author =       "Rahul Purandare and Matthew B. Dwyer and Sebastian
                 Elbaum",
  title =        "Monitor optimization via stutter-equivalent loop
                 transformation",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "270--285",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869483",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Schaefer:2010:SIR,
  author =       "Max Schaefer and Oege de Moor",
  title =        "Specifying and implementing refactorings",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "286--301",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869485",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Nguyen:2010:GBA,
  author =       "Hoan Anh Nguyen and Tung Thanh Nguyen and Jr. Gary
                 Wilson and Anh Tuan Nguyen and Miryung Kim and Tien N.
                 Nguyen",
  title =        "A graph-based approach to {API} usage adaptation",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "302--321",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869486",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Kell:2010:CAA,
  author =       "Stephen Kell",
  title =        "Component adaptation and assembly using interface
                 relations",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "322--340",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869487",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Oliveira:2010:TCO,
  author =       "Bruno C.d.S. Oliveira and Adriaan Moors and Martin
                 Odersky",
  title =        "Type classes as objects and implicits",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "341--360",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869489",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Lerner:2010:SDT,
  author =       "Benjamin S. Lerner and Herman Venter and Dan
                 Grossman",
  title =        "Supporting dynamic, third-party code customizations in
                 {JavaScript} using aspects",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "361--376",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869490",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Herzeel:2010:DPR,
  author =       "Charlotte Herzeel and Pascal Costanza",
  title =        "Dynamic parallelization of recursive code: part 1:
                 managing control flow interactions with the
                 continuator",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "377--396",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869491",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Dillig:2010:SHA,
  author =       "Isil Dillig and Thomas Dillig and Alex Aiken",
  title =        "Symbolic heap abstraction with demand-driven
                 axiomatization of memory invariants",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "397--410",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869493",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Liang:2010:DEP,
  author =       "Percy Liang and Omer Tripp and Mayur Naik and Mooly
                 Sagiv",
  title =        "A dynamic evaluation of the precision of static heap
                 abstractions",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "411--427",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869494",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Mendez-Lojo:2010:PIB,
  author =       "Mario M{\'e}ndez-Lojo and Augustine Mathew and Keshav
                 Pingali",
  title =        "Parallel inclusion-based points-to analysis",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "428--443",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869495",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Kats:2010:SLW,
  author =       "Lennart C. L. Kats and Eelco Visser",
  title =        "The {Spoofax} language workbench: rules for
                 declarative specification of languages and {IDEs}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "444--463",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869497",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Servetto:2010:MMC,
  author =       "Marco Servetto and Elena Zucca",
  title =        "{MetaFJig}: a meta-circular composition language for
                 {Java}-like classes",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "464--483",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869498",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Klose:2010:MLM,
  author =       "Karl Klose and Klaus Ostermann",
  title =        "Modular logic metaprogramming",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "484--503",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869499",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{vanStaden:2010:RAM,
  author =       "Stephan van Staden and Cristiano Calcagno",
  title =        "Reasoning about multiple related abstractions with
                 {MultiStar}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "504--519",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869501",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Qi:2010:HFS,
  author =       "Xin Qi and Andrew C. Myers",
  title =        "Homogeneous family sharing",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "520--538",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869502",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Chiba:2010:MMC,
  author =       "Shigeru Chiba and Atsushi Igarashi and Salikh
                 Zakirov",
  title =        "Mostly modular compilation of crosscutting concerns by
                 contextual predicate dispatch",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "539--554",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869503",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Klein:2010:RTH,
  author =       "Casey Klein and Matthew Flatt and Robert Bruce
                 Findler",
  title =        "Random testing for higher-order, stateful programs",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "555--566",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869505",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{McCarthy:2010:TSS,
  author =       "Jay A. McCarthy",
  title =        "The two-state solution: native and serializable
                 continuations accord",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "567--582",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869506",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Swaine:2010:BFI,
  author =       "James Swaine and Kevin Tew and Peter Dinda and Robert
                 Bruce Findler and Matthew Flatt",
  title =        "Back to the futures: incremental parallelization of
                 existing sequential runtime systems",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "583--597",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869507",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Zibin:2010:OIG,
  author =       "Yoav Zibin and Alex Potanin and Paley Li and Mahmood
                 Ali and Michael D. Ernst",
  title =        "Ownership and immutability in generic {Java}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "598--617",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869509",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Cameron:2010:TO,
  author =       "Nicholas Cameron and James Noble and Tobias Wrigstad",
  title =        "Tribal ownership",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "618--633",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869510",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Matsakis:2010:TAT,
  author =       "Nicholas D. Matsakis and Thomas R. Gross",
  title =        "A time-aware type system for data-race protection and
                 guaranteed initialization",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "634--651",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869511",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Upadhyaya:2010:AAR,
  author =       "Gautam Upadhyaya and Samuel P. Midkiff and Vijay S.
                 Pai",
  title =        "Automatic atomic region identification in shared
                 memory {SPMD} programs",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "652--670",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869513",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Kulkarni:2010:TTP,
  author =       "Aditya Kulkarni and Yu David Liu and Scott F. Smith",
  title =        "Task types for pervasive atomicity",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "671--690",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869514",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Burckhardt:2010:CPR,
  author =       "Sebastian Burckhardt and Alexandro Baldassin and Daan
                 Leijen",
  title =        "Concurrent programming with revisions and isolation
                 types",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "691--707",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869515",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Bebenita:2010:STB,
  author =       "Michael Bebenita and Florian Brandner and Manuel
                 Fahndrich and Francesco Logozzo and Wolfram Schulte and
                 Nikolai Tillmann and Herman Venter",
  title =        "{SPUR}: a trace-based {JIT} compiler for {CIL}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "708--725",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869517",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Kapur:2010:RRL,
  author =       "Puneet Kapur and Brad Cossette and Robert J. Walker",
  title =        "Refactoring references for library migration",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "726--738",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869518",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Altman:2010:PAI,
  author =       "Erik Altman and Matthew Arnold and Stephen Fink and
                 Nick Mitchell",
  title =        "Performance analysis of idle programs",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "739--753",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869519",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Davis:2010:RBL,
  author =       "Samuel Davis and Gregor Kiczales",
  title =        "Registration-based language abstractions",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "754--773",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869521",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Verwaest:2010:PBR,
  author =       "Toon Verwaest and Camillo Bruni and David Gurtner and
                 Adrian Lienhard and Oscar Niestrasz",
  title =        "{Pinocchio}: bringing reflection to life with
                 first-class interpreters",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "774--789",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869522",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Rajan:2010:CMD,
  author =       "Hridesh Rajan and Steven M. Kautz and Wayne
                 Rowcliffe",
  title =        "Concurrency by modularity: design patterns, a case in
                 point",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "790--805",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869523",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Rinard:2010:PSA,
  author =       "Martin Rinard and Henry Hoffmann and Sasa Misailovic
                 and Stelios Sidiroglou",
  title =        "Patterns and statistical analysis for understanding
                 reduced resource computing",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "806--821",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869525",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Sorensen:2010:PTC,
  author =       "Andrew Sorensen and Henry Gardner",
  title =        "Programming with time: cyber-physical programming with
                 {impromptu}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "822--834",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869526",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Chafi:2010:LVH,
  author =       "Hassan Chafi and Zach DeVito and Adriaan Moors and
                 Tiark Rompf and Arvind K. Sujeeth and Pat Hanrahan and
                 Martin Odersky and Kunle Olukotun",
  title =        "Language virtualization for heterogeneous parallel
                 computing",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "835--847",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869527",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Ossher:2010:FMT,
  author =       "Harold Ossher and Rachel Bellamy and Ian Simmonds and
                 David Amid and Ateret Anaby-Tavor and Matthew Callery
                 and Michael Desmond and Jacqueline de Vries and Amit
                 Fisher and Sophia Krasikov",
  title =        "Flexible modeling tools for pre-requirements analysis:
                 conceptual architecture and research challenges",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "848--864",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869529",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Dumitras:2010:UUI,
  author =       "Tudor Dumitras and Priya Narasimhan and Eli Tilevich",
  title =        "To upgrade or not to upgrade: impact of online
                 upgrades across multiple administrative domains",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "865--876",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869530",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Arnold:2010:MAP,
  author =       "Kenneth C. Arnold and Henry Lieberman",
  title =        "Managing ambiguity in programming by finding
                 unambiguous examples",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "877--884",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869531",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Gabriel:2010:BST,
  author =       "Richard P. Gabriel and Kevin J. Sullivan",
  title =        "Better science through art",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "885--900",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869533",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Quillien:2010:RDN,
  author =       "Jenny Quillien and Dave West",
  title =        "Rubber ducks, nightmares, and unsaturated predicates:
                 proto-scientific schemata are good for agile",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "901--917",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869534",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Kats:2010:PDS,
  author =       "Lennart C. L. Kats and Eelco Visser and Guido
                 Wachsmuth",
  title =        "Pure and declarative syntax definition: paradise lost
                 and regained",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "918--932",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869535",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Hanenberg:2010:FHL,
  author =       "Stefan Hanenberg",
  title =        "Faith, hope, and love: an essay on software science's
                 neglect of human factors",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "933--946",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869536",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Adamczyk:2010:TBD,
  author =       "Paul Adamczyk and Munawar Hafiz",
  title =        "The {Tower of Babel} did not fail",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "10",
  pages =        "947--957",
  month =        oct,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1932682.1869537",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:13:46 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

%% TO DO: find missing volume 45 issue 11 2010

@Article{Brunthaler:2010:EIU,
  author =       "Stefan Brunthaler",
  title =        "Efficient interpretation using quickening",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "12",
  pages =        "1--14",
  month =        dec,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1899661.1869633",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Dec 15 10:25:15 MST 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Just-in-time compilers offer the biggest achievable
                 payoff performance-wise, but their implementation is a
                 non-trivial, time-consuming task affecting the
                 interpreter's maintenance for years to come, too.
                 Recent research addresses this issue by providing ways
                 of leveraging existing just-in-time compilation
                 infrastructures. Though there has been considerable
                 research on improving the efficiency of just-in-time
                 compilers, the area of optimizing interpreters has
                 gotten less attention as if the implementation of a
                 dynamic translation system was the ``ultima ratio'' for
                 efficiently interpreting programming languages.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Zakirov:2010:ODD,
  author =       "Salikh S. Zakirov and Shigeru Chiba and Etsuya
                 Shibayama",
  title =        "Optimizing dynamic dispatch with fine-grained state
                 tracking",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "12",
  pages =        "15--26",
  month =        dec,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1899661.1869634",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Dec 15 10:25:15 MST 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Dynamic mixin is a construct available in Ruby and
                 other dynamic languages. It can be used as a base to
                 implement a range of programming paradigms, such as
                 dynamic aspect-oriented programming and
                 context-oriented programming. However, the performance
                 characteristics of current implementation of dynamic
                 mixin in Ruby leaves much to be desired under condition
                 of frequent dynamic mixin operations, global method
                 cache and inline cache misses incur significant
                 overhead. In this work we implemented fine-grained
                 state tracking for CRuby 1. and were able to improve
                 performance by more than six times on the
                 microbenchmark exercising extreme case flowing 4 times
                 to global method cache clearing, 28\% to fine-grained
                 state tracking and further 12\% to inline cache miss
                 elimination by caching alternating states.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Gorbovitski:2010:AAO,
  author =       "Michael Gorbovitski and Yanhong A. Liu and Scott D.
                 Stoller and Tom Rothamel and Tuncay K. Tekle",
  title =        "Alias analysis for optimization of dynamic languages",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "12",
  pages =        "27--42",
  month =        dec,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1899661.1869635",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Dec 15 10:25:15 MST 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Dynamic languages such as Python allow programs to be
                 written more easily using high-level constructs such as
                 comprehensions for queries and using generic code.
                 Efficient execution of programs then requires powerful
                 optimizations - incrementalization of expensive queries
                 and specialization of generic code. Effective
                 incrementalization and specialization of dynamic
                 languages require precise and scalable alias analysis.
                 This paper describes the development and experimental
                 evaluation of a may-alias analysis for a full dynamic
                 object-oriented language, for program optimization by
                 incrementalization and specialization. The analysis is
                 flow-sensitive; we show that this is necessary for
                 effective optimization of dynamic languages. It uses
                 precise type analysis and a powerful form of context
                 sensitivity, called trace sensitivity, to further
                 improve analysis precision.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Pestov:2010:FDS,
  author =       "Sviatoslav Pestov and Daniel Ehrenberg and Joe Groff",
  title =        "{Factor}: a dynamic stack-based programming language",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "12",
  pages =        "43--58",
  month =        dec,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1899661.1869637",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Dec 15 10:25:15 MST 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Factor is a new dynamic object-oriented programming
                 language. It began as an embedded scripting language
                 and evolved to a mature application development
                 language. The language has a simple execution model and
                 is based on the manipulation of data on a stack. An
                 advanced metaprogramming system provides means for
                 easily extending the language. Thus, Factor allows
                 programmers to use the right features for their problem
                 domain. The Factor implementation is self-hosting,
                 featuring an interactive development environment and an
                 optimizing compiler. In this paper, the language and
                 its implementation are presented.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Cutsem:2010:PDP,
  author =       "Tom Van Cutsem and Mark S. Miller",
  title =        "Proxies: design principles for robust object-oriented
                 intercession {APIs}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "12",
  pages =        "59--72",
  month =        dec,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1899661.1869638",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Dec 15 10:25:15 MST 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Proxies are a powerful approach to implement
                 meta-objects in object-oriented languages without
                 having to resort to metacircular interpretation. We
                 introduce such a meta-level API based on proxies for
                 Javascript. We simultaneously introduce a set of design
                 principles that characterize such APIs in general, and
                 compare similar APIs of other languages in terms of
                 these principles. We highlight how principled
                 proxy-based APIs improve code robustness by avoiding
                 interference between base and meta-level code that
                 occur in more common reflective intercession
                 mechanisms.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Tratt:2010:EIL,
  author =       "Laurence Tratt",
  title =        "Experiences with an {Icon3}-like expression evaluation
                 system",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "12",
  pages =        "73--80",
  month =        dec,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1899661.1869640",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Dec 15 10:25:15 MST 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "The design of the Icon programming language's
                 expression evaluation system, which can perform limited
                 backtracking, was unique amongst imperative programming
                 languages when created. In this paper I explain and
                 critique the original Icon design and show how a
                 similar system can be integrated into a modern
                 dynamically typed language. Finally I detail my
                 experiences of this system and offer suggestions for
                 the lessons to be learned from it.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Axelsen:2010:CDM,
  author =       "Eyvind W. Axelsen and Stein Krogdahl and Birger
                 M{\o}ller-Pedersen",
  title =        "Controlling dynamic module composition through an
                 extensible meta-level {API}",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "12",
  pages =        "81--96",
  month =        dec,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1899661.1869641",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Dec 15 10:25:15 MST 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "In addition to traditional object-oriented (OO)
                 concepts such as inheritance and polymorphism, several
                 modularization and composition mechanisms like e.g.
                 traits, mixins and virtual classes have emerged. The
                 Package Template mechanism is another attempt at
                 providing a flexible mechanism for modularization,
                 composition and adaption. Dynamic languages have
                 traditionally employed strong support for
                 meta-programming, with hooks to control OO concepts
                 such as method invocation and object construction, by
                 utilizing meta-classes and meta-object protocols. In
                 this work, we attempt to bring a corresponding degree
                 of meta-level control to composition primitives, with a
                 concrete starting point in the package template
                 mechanism as developed for the dynamic language
                 Groovy.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Strickland:2010:CFC,
  author =       "T. Stephen Strickland and Matthias Felleisen",
  title =        "Contracts for first-class classes",
  journal =      j-SIGPLAN,
  volume =       "45",
  number =       "12",
  pages =        "97--112",
  month =        dec,
  year =         "2010",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1899661.1869642",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Dec 15 10:25:15 MST 2010",
  bibsource =    "http://portal.acm.org/",
  abstract =     "First-class classes add expressive power to
                 class-based object-oriented languages. Most
                 importantly, programmers can abstract over common
                 scenarios with first-class classes. When it comes to
                 behavioral software contracts, however, first-class
                 classes pose significant challenges. In this paper, we
                 present the first contract system for a programming
                 language with first-class classes. The design has been
                 implemented for Racket, which supports first-class
                 classes and which implements mixins and traits as
                 syntactic sugar. We expect that our experience also
                 applies to languages with native mixins and/or
                 traits.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Leroy:2011:VSD,
  author =       "Xavier Leroy",
  title =        "Verified squared: does critical software deserve
                 verified tools?",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "1--2",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926387",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Lhotak:2011:PAE,
  author =       "Ondrej Lhot{\'a}k and Kwok-Chiang Andrew Chung",
  title =        "Points-to analysis with efficient strong updates",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "3--16",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926389",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Smaragdakis:2011:PYC,
  author =       "Yannis Smaragdakis and Martin Bravenboer and Ondrej
                 Lhot{\'a}k",
  title =        "Pick your contexts well: understanding
                 object-sensitivity",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "17--30",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926390",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Liang:2011:LMA,
  author =       "Percy Liang and Omer Tripp and Mayur Naik",
  title =        "Learning minimal abstractions",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "31--42",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926391",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Sevcik:2011:RMC,
  author =       "Jaroslav {\v{S}}ev{\c{c}}ik and Viktor Vafeiadis and
                 Francesco Zappa Nardelli and Suresh Jagannathan and
                 Peter Sewell",
  title =        "Relaxed-memory concurrency and verified compilation",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "43--54",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926393",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Batty:2011:MCC,
  author =       "Mark Batty and Scott Owens and Susmit Sarkar and Peter
                 Sewell and Tjark Weber",
  title =        "Mathematizing {C++} concurrency",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "55--66",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926394",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Ramananandro:2011:FVO,
  author =       "Tahina Ramananandro and Gabriel Dos Reis and Xavier
                 Leroy",
  title =        "Formal verification of object layout for {C++}
                 multiple inheritance",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "67--80",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926395",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Choi:2011:SAM,
  author =       "Wontae Choi and Baris Aktemur and Kwangkeun Yi and
                 Makoto Tatsuta",
  title =        "Static analysis of multi-staged programs via unstaging
                 translation",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "81--92",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926397",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Schwarz:2011:SAI,
  author =       "Martin D. Schwarz and Helmut Seidl and Vesal Vojdani
                 and Peter Lammich and Markus M{\"u}ller-Olm",
  title =        "Static analysis of interrupt-driven programs
                 synchronized via the priority ceiling protocol",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "93--104",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926398",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Cousot:2011:PSF,
  author =       "Patrick Cousot and Radhia Cousot and Francesco
                 Logozzo",
  title =        "A parametric segmentation functor for fully automatic
                 and scalable array content analysis",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "105--118",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926399",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Birkedal:2011:SIK,
  author =       "Lars Birkedal and Bernhard Reus and Jan Schwinghammer
                 and Kristian St{\o}vring and Jacob Thamsborg and
                 Hongseok Yang",
  title =        "Step-indexed {Kripke} models over recursive worlds",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "119--132",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926401",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Hur:2011:KLR,
  author =       "Chung-Kil Hur and Derek Dreyer",
  title =        "A {Kripke} logical relation between {ML} and
                 assembly",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "133--146",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926402",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Pottier:2011:TSP,
  author =       "Fran{\c{c}}ois Pottier",
  title =        "A typed store-passing translation for general
                 references",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "147--158",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926403",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Prountzos:2011:SAO,
  author =       "Dimitrios Prountzos and Roman Manevich and Keshav
                 Pingali and Kathryn S. McKinley",
  title =        "A shape analysis for optimizing parallel graph
                 programs",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "159--172",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926405",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Rival:2011:CCA,
  author =       "Xavier Rival and Bor-Yuh Evan Chang",
  title =        "Calling context abstraction with shapes",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "173--186",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926406",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Dillig:2011:PRP,
  author =       "Isil Dillig and Thomas Dillig and Alex Aiken",
  title =        "Precise reasoning for programs using containers",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "187--200",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926407",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Ahmed:2011:BA,
  author =       "Amal Ahmed and Robert Bruce Findler and Jeremy G. Siek
                 and Philip Wadler",
  title =        "Blame for all",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "201--214",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926409",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Dimoulas:2011:CBC,
  author =       "Christos Dimoulas and Robert Bruce Findler and Cormac
                 Flanagan and Matthias Felleisen",
  title =        "Correct blame for contracts: no more scapegoating",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "215--226",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926410",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Weirich:2011:GTA,
  author =       "Stephanie Weirich and Dimitrios Vytiniotis and Simon
                 Peyton Jones and Steve Zdancewic",
  title =        "Generative type abstraction and type-level
                 computation",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "227--240",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926411",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{MacLaurin:2011:DKT,
  author =       "Matthew B. MacLaurin",
  title =        "The design of {Kodu}: a tiny visual programming
                 language for children on the {Xbox 360}",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "241--246",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926413",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Turon:2011:SLR,
  author =       "Aaron Joseph Turon and Mitchell Wand",
  title =        "A separation logic for refining concurrent objects",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "247--258",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926415",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Dodds:2011:MRD,
  author =       "Mike Dodds and Suresh Jagannathan and Matthew J.
                 Parkinson",
  title =        "Modular reasoning for deterministic parallelism",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "259--270",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926416",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Jacobs:2011:EMF,
  author =       "Bart Jacobs and Frank Piessens",
  title =        "Expressive modular fine-grained concurrency
                 specification",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "271--282",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926417",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Madhusudan:2011:TWA,
  author =       "P. Madhusudan and Gennaro Parlato",
  title =        "The tree width of auxiliary storage",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "283--294",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926419",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Tzevelekos:2011:FRA,
  author =       "Nikos Tzevelekos",
  title =        "Fresh-register automata",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "295--306",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926420",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Leroux:2011:VAS,
  author =       "J{\'e}r{\^o}me Leroux",
  title =        "Vector addition system reachability problem: a short
                 self-contained proof",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "307--316",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926421",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Gulwani:2011:ASP,
  author =       "Sumit Gulwani",
  title =        "Automating string processing in spreadsheets using
                 input-output examples",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "317--330",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926423",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Gupta:2011:PAR,
  author =       "Ashutosh Gupta and Corneliu Popeea and Andrey
                 Rybalchenko",
  title =        "Predicate abstraction and refinement for verifying
                 multi-threaded programs",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "331--344",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926424",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Ghica:2011:GSI,
  author =       "Dan R. Ghica and Alex Smith",
  title =        "Geometry of synthesis {III}: resource management
                 through type inference",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "345--356",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926425",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Hoffmann:2011:MAR,
  author =       "Jan Hoffmann and Klaus Aehlig and Martin Hofmann",
  title =        "Multivariate amortized resource analysis",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "357--370",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926427",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Hofmann:2011:SL,
  author =       "Martin Hofmann and Benjamin Pierce and Daniel Wagner",
  title =        "Symmetric lenses",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "371--384",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926428",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Henglein:2011:REC,
  author =       "Fritz Henglein and Lasse Nielsen",
  title =        "Regular expression containment: coinductive
                 axiomatization and computational interpretation",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "385--398",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926429",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Cook:2011:MPD,
  author =       "Byron Cook and Eric Koskinen",
  title =        "Making prophecies with decision predicates",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "399--410",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926431",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Emmi:2011:DBS,
  author =       "Michael Emmi and Shaz Qadeer and Zvonimir
                 Rakamari\'c",
  title =        "Delay-bounded scheduling",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "411--422",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926432",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Sinha:2011:IA,
  author =       "Nishant Sinha and Chao Wang",
  title =        "On interference abstractions",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "423--434",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926433",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Denielou:2011:DMS,
  author =       "Pierre-Malo Deni{\'e}lou and Nobuko Yoshida",
  title =        "Dynamic multirole session types",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "435--446",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926435",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Tov:2011:PAT,
  author =       "Jesse A. Tov and Riccardo Pucella",
  title =        "Practical affine types",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "447--458",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926436",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{An:2011:DIS,
  author =       "Jong-hoon (David) An and Avik Chaudhuri and Jeffrey S.
                 Foster and Michael Hicks",
  title =        "Dynamic inference of static types for ruby",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "459--472",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926437",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Gordon:2011:RMV,
  author =       "Andrew D. Gordon and Robert Harper and John Harrison
                 and Alan Jeffrey and Peter Sewell",
  title =        "{Robin Milner 1934--2010}: verification, languages,
                 and concurrency",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "473--474",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926439",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Bendersky:2011:SOB,
  author =       "Anna Bendersky and Erez Petrank",
  title =        "Space overhead bounds for dynamic memory management
                 with partial compaction",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "475--486",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926441",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Attiya:2011:LOE,
  author =       "Hagit Attiya and Rachid Guerraoui and Danny Hendler
                 and Petr Kuznetsov and Maged M. Michael and Martin
                 Vechev",
  title =        "Laws of order: expensive synchronization in concurrent
                 algorithms cannot be eliminated",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "487--498",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926442",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Esparza:2011:CPB,
  author =       "Javier Esparza and Pierre Ganty",
  title =        "Complexity of pattern-based verification for
                 multithreaded programs",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "499--510",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926443",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Prabhu:2011:EAF,
  author =       "Tarun Prabhu and Shreyas Ramalingam and Matthew Might
                 and Mary Hall",
  title =        "{EigenCFA}: accelerating flow analysis with {GPUs}",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "511--522",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926445",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Feng:2011:BQP,
  author =       "Yuan Feng and Runyao Duan and Mingsheng Ying",
  title =        "Bisimulation for quantum processes",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "523--534",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926446",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Bocchino:2011:SND,
  author =       "Robert L. {Bocchino, Jr.} and Stephen Heumann and Nima
                 Honarmand and Sarita V. Adve and Vikram S. Adve and
                 Adam Welc and Tatiana Shpeisman",
  title =        "Safe nondeterminism in a deterministic-by-default
                 parallel language",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "535--548",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926447",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Pouchet:2011:LTC,
  author =       "Louis-No{\"e}l Pouchet and Uday Bondhugula and
                 C{\'e}dric Bastoul and Albert Cohen and J. Ramanujam
                 and P. Sadayappan and Nicolas Vasilache",
  title =        "Loop transformations: convexity, pruning and
                 optimization",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "549--562",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926449",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Guo:2011:ECT,
  author =       "Shu-yu Guo and Jens Palsberg",
  title =        "The essence of compiling with traces",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "563--574",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926450",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Ramsey:2011:RRM,
  author =       "Norman Ramsey and Jo{\~a}o Dias",
  title =        "Resourceable, retargetable, modular instruction
                 selection using a machine-independent, type-based
                 tiling of low-level intermediate code",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "575--586",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926451",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Ong:2011:VHO,
  author =       "C.-H. Luke Ong and Steven James Ramsay",
  title =        "Verifying higher-order functional programs with
                 pattern-matching algebraic data types",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "587--598",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926453",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Alur:2011:STA,
  author =       "Rajeev Alur and Pavol Cern{\'y}",
  title =        "Streaming transducers for algorithmic verification of
                 single-pass list-processing programs",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "599--610",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926454",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Madhusudan:2011:DLC,
  author =       "P. Madhusudan and Gennaro Parlato and Xiaokang Qiu",
  title =        "Decidable logics combining heap structures and data",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "611--622",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926455",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Joisha:2011:TEA,
  author =       "Pramod G. Joisha and Robert S. Schreiber and
                 Prithviraj Banerjee and Hans J. Boehm and Dhruva R.
                 Chakrabarti",
  title =        "A technique for the effective and automatic reuse of
                 classical compiler optimizations on multithreaded
                 code",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "1",
  pages =        "623--636",
  month =        jan,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1925844.1926457",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Wed Jan 26 15:06:39 MST 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Lammel:2011:HGS,
  author =       "Ralf L{\"a}mmel",
  title =        "The hitchhiker's guide to software languages",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "2",
  pages =        "1--2",
  month =        feb,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1942788.1868295",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Feb 14 16:37:34 MST 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "There is only that much space in the CS curriculum,
                 and there are always new subjects that should be
                 accommodated by the curriculum. For instance, in our
                 community, we would want all graduates to leave
                 university with a modest background in technical
                 spaces, software languages, and meta-programming; also,
                 with conceptually informed and reasonably timeless
                 skills to efficiently master related programming
                 techniques and technologies. In reality, the curricula
                 of few CS departments meet this expectation. In this
                 talk, I will discuss such curricula-related
                 expectations of our community and the suboptimal
                 situation at CS departments---as perceive them.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Erwig:2011:LSV,
  author =       "Martin Erwig",
  title =        "A language for software variation research",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "2",
  pages =        "3--12",
  month =        feb,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1942788.1868296",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Feb 14 16:37:34 MST 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Managing variation is an important problem in software
                 engineering that takes different forms, ranging from
                 version control and configuration management to
                 software product lines. In this paper, I present our
                 recent work on the choice calculus, a fundamental
                 representation for software variation that can serve as
                 a common language of discourse for variation research,
                 filling a role similar to lambda calculus in
                 programming language research. After motivating the
                 design of the choice calculus and sketching its
                 semantics, I will discuss several potential application
                 areas.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Clarke:2011:ADM,
  author =       "Dave Clarke and Michiel Helvensteijn and Ina
                 Schaefer",
  title =        "Abstract delta modeling",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "2",
  pages =        "13--22",
  month =        feb,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1942788.1868298",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Feb 14 16:37:34 MST 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Delta modeling is an approach to facilitate automated
                 product derivation for software product lines. It is
                 based on a set of deltas specifying modifications that
                 are incrementally applied to a core product. The
                 applicability of deltas depends on feature-dependent
                 conditions. This paper presents abstract delta
                 modeling, which explores delta modeling from an
                 abstract, algebraic perspective. Compared to previous
                 work, we take a more flexible approach with respect to
                 conflicts between modifications and introduce the
                 notion of conflict-resolving deltas. We present
                 conditions on the structure of deltas to ensure
                 unambiguous product generation.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Ryssel:2011:AVP,
  author =       "Uwe Ryssel and Joern Ploennigs and Klaus Kabitzsch",
  title =        "Automatic variation-point identification in
                 function-block-based models",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "2",
  pages =        "23--32",
  month =        feb,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1942788.1868299",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Feb 14 16:37:34 MST 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Function-block-based modeling is often used to develop
                 embedded systems, particularly as system variants can
                 be developed rapidly from existing modules. Generative
                 approaches can simplify the handling and development of
                 the resulting high variety of function-block-based
                 models. But they often require the development of new
                 generic models that do not utilize existing ones.
                 Reusing existing models will significantly decrease the
                 effort to apply generative programming. This work
                 introduces an automatic approach to recognize variants
                 in a set of models and identify the variation points
                 and their dependencies within variants.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Sincero:2011:EEA,
  author =       "Julio Sincero and Reinhard Tartler and Daniel Lohmann
                 and Wolfgang Schr{\"o}der-Preikschat",
  title =        "Efficient extraction and analysis of
                 preprocessor-based variability",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "2",
  pages =        "33--42",
  month =        feb,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1942788.1868300",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Feb 14 16:37:34 MST 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "The C Preprocessor (CPP) is the tool of choice for the
                 implementation of variability in many large-scale
                 configurable software projects. Linux, probably the
                 most-configurable piece of software ever, employs more
                 than 10,000 preprocessor variables for this purpose.
                 However, this de-facto variability tends to be ``hidden
                 in the code''; which on the long term leads to
                 variability defects, such as dead code or
                 inconsistencies with respect to the intended (modeled)
                 variability of the software. This calls for tool
                 support for the efficient extraction of (and reasoning
                 over) CPP-based variability. We suggest a novel
                 approach to extract CPP-based variability. Our tool
                 transforms CPP-based variability in O(n) complexity
                 into a propositional formula that ``mimics'' all valid
                 effects of conditional compilation and can be analyzed
                 with standard SAT or BDD packages.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Middelkoop:2011:ITI,
  author =       "Arie Middelkoop and Atze Dijkstra and S. Doaitse
                 Swierstra",
  title =        "Iterative type inference with attribute grammars",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "2",
  pages =        "43--52",
  month =        feb,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1942788.1868302",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Feb 14 16:37:34 MST 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Type inference is the process of constructing a typing
                 derivation while gradually discovering type
                 information. During this process, inference algorithms
                 typically make subtle decisions based on the derivation
                 constructed so far. Because a typing derivation is a
                 decorated tree we aim to use attribute grammars as the
                 main implementation tool. Unfortunately, we can neither
                 express iteration, nor express decisions based on
                 intermediate derivations in such grammars. We present
                 the language ruler-front, a conservative extension to
                 ordered attribute grammars, that deals with the
                 aforementioned problems. We show why this extension is
                 suitable for the description of constraint-based
                 inference algorithms.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Krieger:2011:AES,
  author =       "Matthias P. Krieger and Alexander Knapp and Burkhart
                 Wolff",
  title =        "Automatic and efficient simulation of operation
                 contracts",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "2",
  pages =        "53--62",
  month =        feb,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1942788.1868303",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Feb 14 16:37:34 MST 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Operation contracts consisting of pre- and
                 postconditions are a well-known means of specifying
                 operations. In this paper we deal with the problem of
                 operation contract simulation, i.e., determining
                 operation results satisfying the postconditions based
                 on input data supplied by the user; simulating
                 operation contracts is an important technique for
                 requirements validation and prototyping. Current
                 approaches to operation contract simulation exhibit
                 poor performance for large sets of input data or
                 require additional guidance from the user. We show how
                 these problems can be alleviated and describe an
                 efficient as well as fully automatic approach. It is
                 implemented in our tool OCLexec that generates from
                 UML/OCL operation contracts corresponding Java
                 implementations which call a constraint solver at
                 runtime.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Long:2011:IIM,
  author =       "Yuheng Long and Sean L. Mooney and Tyler Sondag and
                 Hridesh Rajan",
  title =        "Implicit invocation meets safe, implicit concurrency",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "2",
  pages =        "63--72",
  month =        feb,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1942788.1868304",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Feb 14 16:37:34 MST 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Writing correct and efficient concurrent programs
                 still remains a challenge. Explicit concurrency is
                 difficult, error prone, and creates code which is hard
                 to maintain and debug. This type of concurrency also
                 treats modular program design and concurrency as
                 separate goals, where modularity often suffers. To
                 solve these problems, we are designing a new language
                 that we call Panini. In this paper, we focus on
                 Panini's asynchronous, typed events which reconcile the
                 modularity goal promoted by the implicit invocation
                 design style with the concurrency goal of exposing
                 potential concurrency between the execution of subjects
                 and observers. Since modularity is improved and
                 concurrency is implicit in Panini, programs are easier
                 to reason about and maintain.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Navas:2011:CBR,
  author =       "Juan F. Navas and Jean-Philippe Babau and Jacques
                 Pulou",
  title =        "A component-based run-time evolution infrastructure
                 for resource-constrained embedded systems",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "2",
  pages =        "73--82",
  month =        feb,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1942788.1868306",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Feb 14 16:37:34 MST 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "This paper deals with embedded systems software and
                 the modification of its architecture and behavior at
                 execution-time. Incautious implementation of these
                 features demands both heavy memory and performance
                 overrun. To accomplish such software evolution
                 activities in resource-constrained embedded systems, we
                 propose a component-based run-time evolution
                 infrastructure that reconciles richness of evolution
                 alternatives and performance requirements. Our proposal
                 is based on off-site components reifications, which are
                 representations of components that allow us to treat
                 evolution concerns remotely. Hence, the workload to be
                 processed by the embedded device is alleviated.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Hofer:2011:MDS,
  author =       "Christian Hofer and Klaus Ostermann",
  title =        "Modular domain-specific language components in
                 {Scala}",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "2",
  pages =        "83--92",
  month =        feb,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1942788.1868307",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Feb 14 16:37:34 MST 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Programs in domain-specific embedded languages (DSELs)
                 can be represented in the host language in different
                 ways, for instance implicitly as libraries, or
                 explicitly in the form of abstract syntax trees. Each
                 of these representations has its own strengths and
                 weaknesses. The implicit approach has good
                 composability properties, whereas the explicit approach
                 allows more freedom in making syntactic program
                 transformations. Traditional designs for DSELs fix the
                 form of representation, which means that it is not
                 possible to choose the best representation for a
                 particular interpretation or transformation. We propose
                 a new design for implementing DSELs in Scala which
                 makes it easy to use different program representations
                 at the same time.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Wolfinger:2011:AGP,
  author =       "Reinhard Wolfinger and Markus L{\"o}berbauer and
                 Markus Jahn and Hanspeter M{\"o}ssenb{\"o}ck",
  title =        "Adding genericity to a plug-in framework",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "2",
  pages =        "93--102",
  month =        feb,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1942788.1868308",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Feb 14 16:37:34 MST 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Plug-in components are a means for making feature-rich
                 applications customizable. Combined with plug-and-play
                 composition, end users can assemble customized
                 applications without programming. If plug-and-play
                 composition is also dynamic, applications can be
                 reconfigured on the fly to load only components the
                 user needs for his current work. We have created
                 Plux.NET, a plug-in framework that supports dynamic
                 plug-and-play composition. The basis for plug-and-play
                 in Plux is the composer which replaces programmatic
                 composition by automatic composition. Components just
                 specify their requirements and provisions using
                 metadata. The composer then assembles the components
                 based on that metadata by matching requirements and
                 provisions. When the composer needs to reuse
                 general-purpose components in different parts of an
                 application, the component model requires genericity.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Schulze:2011:CCF,
  author =       "Sandro Schulze and Sven Apel and Christian
                 K{\"a}stner",
  title =        "Code clones in feature-oriented software product
                 lines",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "2",
  pages =        "103--112",
  month =        feb,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1942788.1868310",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Feb 14 16:37:34 MST 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Some limitations of object-oriented mechanisms are
                 known to cause code clones (e.g., extension using
                 inheritance). Novel programming paradigms such as
                 feature-oriented programming (FOP) aim at alleviating
                 these limitations. However, it is an open issue whether
                 FOP is really able to avoid code clones or whether it
                 even facilitates (FOP-related) clones. To address this
                 issue, we conduct an empirical analysis on ten
                 feature-oriented software product lines with respect to
                 code cloning. We found that there is a considerable
                 number of clones in feature-oriented software product
                 lines and that a large fraction of these clones is
                 FOP-related (i.e., caused by limitations of
                 feature-oriented mechanisms).",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Tanter:2011:CDA,
  author =       "{\'E}ric Tanter and Philippe Moret and Walter Binder
                 and Danilo Ansaloni",
  title =        "Composition of dynamic analysis aspects",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "2",
  pages =        "113--122",
  month =        feb,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1942788.1868311",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Feb 14 16:37:34 MST 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Aspect-oriented programming provides a convenient
                 high-level model to define several kinds of dynamic
                 analyses, in particular thanks to recent advances in
                 exhaustive weaving in core libraries. Casting dynamic
                 analyses as aspects allows the use of a single weaving
                 infrastructure to apply different analyses to the same
                 base program, simultaneously. However, even if dynamic
                 analysis aspects are mutually independent, their mere
                 presence perturbates the observations of others: this
                 is due to the fact that aspectual computation is
                 potentially visible to all aspects. Because current
                 aspect composition approaches do not address this kind
                 of computational interference, combining different
                 analysis aspects yields at best unpredictable
                 results.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Wurthinger:2011:AED,
  author =       "Thomas W{\"u}rthinger and Walter Binder and Danilo
                 Ansaloni and Philippe Moret and Hanspeter
                 M{\"o}ssenb{\"o}ck",
  title =        "Applications of enhanced dynamic code evolution for
                 {Java} in {GUI} development and dynamic aspect-oriented
                 programming",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "2",
  pages =        "123--126",
  month =        feb,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1942788.1868312",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Feb 14 16:37:34 MST 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "While dynamic code evolution in object-oriented
                 systems is an important feature supported by dynamic
                 languages, there is currently only limited support for
                 dynamic code evolution in high-performance,
                 state-of-the-art runtime systems for statically typed
                 languages, such as the Java Virtual Machine. In this
                 tool demonstration, we present the Dynamic Code
                 Evolution VM, which is based on a recent version of
                 Oracle's state-of-the-art Java HotSpot(TM) VM and
                 allows unlimited changes to loaded classes at runtime.
                 Based on the Dynamic Code Evolution VM, we developed an
                 enhanced version of the Mantisse GUI builder (which is
                 part of the NetBeans IDE) that allows adding GUI
                 components without restarting the application under
                 development.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Rompf:2011:LMS,
  author =       "Tiark Rompf and Martin Odersky",
  title =        "Lightweight modular staging: a pragmatic approach to
                 runtime code generation and compiled {DSLs}",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "2",
  pages =        "127--136",
  month =        feb,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1942788.1868314",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Feb 14 16:37:34 MST 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Software engineering demands generality and
                 abstraction, performance demands specialization and
                 concretization. Generative programming can provide
                 both, but the effort required to develop high-quality
                 program generators likely offsets their benefits, even
                 if a multi-stage programming language is used. We
                 present lightweight modular staging, a library-based
                 multi-stage programming approach that breaks with the
                 tradition of syntactic quasi-quotation and instead uses
                 only types to distinguish between binding times.
                 Through extensive use of component technology,
                 lightweight modular staging makes an optimizing
                 compiler framework available at the library level,
                 allowing programmers to tightly integrate
                 domain-specific abstractions and optimizations into the
                 generation process. We argue that lightweight modular
                 staging enables a form of language virtualization,
                 i.e.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Porkolab:2011:DSL,
  author =       "Zolt{\'a}n Porkolab and {\'A}bel Sinkovics",
  title =        "Domain-specific language integration with compile-time
                 parser generator library",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "2",
  pages =        "137--146",
  month =        feb,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1942788.1868315",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Feb 14 16:37:34 MST 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Smooth integration of domain-specific languages into a
                 general purpose host language requires absorbing of
                 domain code written in arbitrary syntax. The
                 integration should cause minimal syntactical and
                 semantic overhead and introduce minimal dependency on
                 external tools. In this paper we discuss a DSL
                 integration technique for the C++ programming language.
                 The solution is based on compile-time parsing of the
                 DSL code. The parser generator is a C++ template
                 metaprogram reimplementation of a runtime Haskell
                 parser generator library. The full parsing phase is
                 executed when the host program is compiled. The library
                 uses only standard C++ language features, thus our
                 solution is highly portable.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Atkinson:2011:ACT,
  author =       "Kevin Atkinson and Matthew Flatt and Gary Lindstrom",
  title =        "{ABI} compatibility through a customizable language",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "2",
  pages =        "147--156",
  month =        feb,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1942788.1868316",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Feb 14 16:37:34 MST 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "ZL is a C++-compatible language in which high-level
                 constructs, such as classes, are defined using macros
                 over a C-like core language. This approach makes many
                 parts of the language easily customizable. For example,
                 since the class construct can be defined using macros,
                 a programmer can have complete control over the memory
                 layout of objects. Using this capability, a programmer
                 can mitigate certain problems in software evolution
                 such as fragile ABIs (Application Binary Interfaces)
                 due to software changes and incompatible ABIs due to
                 compiler changes.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Bordignon:2011:MBK,
  author =       "Mirko Bordignon and Ulrik Pagh Schultz and Kasper
                 Stoy",
  title =        "Model-based kinematics generation for modular
                 mechatronic toolkits",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "2",
  pages =        "157--166",
  month =        feb,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1942788.1868318",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Feb 14 16:37:34 MST 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Modular robots are mechatronic devices that enable the
                 construction of highly versatile and flexible robotic
                 systems whose mechanical structure can be dynamically
                 modified. The key feature that enables this dynamic
                 modification is the capability of the individual
                 modules to connect to each other in multiple ways and
                 thus generate a number of different mechanical systems,
                 in contrast with the monolithics fixed structure of
                 conventional robots. The mechatronic flexibility,
                 however, complicates the development of models and
                 programming abstractions for modular robots, since
                 manually describing and enumerating the full set of
                 possible interconnections is tedious and error-prone
                 for real-world robots. In order to allow for a general
                 formulation of spatial abstractions for modular robots
                 and to ensure correct and streamlined generation of
                 code dependent on mechanical properties, we have
                 developed the Modular Mechatronics Modelling Language
                 (M3L).",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Miao:2011:ITC,
  author =       "Weiyu Miao and Jeremy G. Siek",
  title =        "Incremental type-checking for type-reflective
                 metaprograms",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "2",
  pages =        "167--176",
  month =        feb,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1942788.1868319",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Feb 14 16:37:34 MST 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Garcia introduces a calculus for type-reflective
                 metaprogramming that provides much of the power and
                 flexibility of C++ templates and solves many of its
                 problems. However, one of the problems that remains is
                 that the residual program is not type checked until
                 after meta computation is complete. Ideally, one would
                 like the type system of the metaprogram to also
                 guarantee that the residual program will type check, as
                 is the case in MetaML. However, in a language with
                 type-reflective metaprogramming, type expressions in
                 the residual program may be the result of meta
                 computation, making the MetaML guarantee next to
                 impossible to achieve.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Grech:2011:JGE,
  author =       "Neville Grech and Julian Rathke and Bernd Fischer",
  title =        "{JEqualityGen}: generating equality and hashing
                 methods",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "2",
  pages =        "177--186",
  month =        feb,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1942788.1868320",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Mon Feb 14 16:37:34 MST 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Manually implementing equals (for object comparisons)
                 and hashCode (for object hashing) methods in large
                 software projects is tedious and error-prone. This is
                 due to many special cases, such as field shadowing,
                 comparison between different types, or cyclic object
                 graphs. Here, we present JEqualityGen, a source code
                 generator that automatically derives implementations of
                 these methods. JEqualityGen proceeds in two states: it
                 first uses source code reflection in MetaAspectJ to
                 generate aspects that contain the method
                 implementations, before it uses weaving on the bytecode
                 level to insert these into the target application.
                 JEqualityGen generates not only correct, but efficient
                 source code that on a typical large-scale Java
                 application exhibits a performance improvement of more
                 than two orders of magnitude in the equality operations
                 generated, compared to an existing system based on
                 runtime reflection.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Larus:2011:CWC,
  author =       "James R. Larus",
  title =        "The cloud will change everything",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "1--2",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950367",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Yuan:2011:ISD,
  author =       "Ding Yuan and Jing Zheng and Soyeon Park and Yuanyuan
                 Zhou and Stefan Savage",
  title =        "Improving software diagnosability via log
                 enhancement",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "3--14",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950369",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Veeraraghavan:2011:DPS,
  author =       "Kaushik Veeraraghavan and Dongyoon Lee and Benjamin
                 Wester and Jessica Ouyang and Peter M. Chen and Jason
                 Flinn and Satish Narayanasamy",
  title =        "{DoublePlay}: parallelizing sequential logging and
                 replay",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "15--26",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950370",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Casper:2011:HAT,
  author =       "Jared Casper and Tayo Oguntebi and Sungpack Hong and
                 Nathan G. Bronson and Christos Kozyrakis and Kunle
                 Olukotun",
  title =        "Hardware acceleration of transactional memory on
                 commodity systems",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "27--38",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950372",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Dalessandro:2011:HNC,
  author =       "Luke Dalessandro and Fran{\c{c}}ois Carouge and Sean
                 White and Yossi Lev and Mark Moir and Michael L. Scott
                 and Michael F. Spear",
  title =        "{Hybrid NOrec}: a case study in the effectiveness of
                 best effort hardware transactional memory",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "39--52",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950373",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Singh:2011:EPS,
  author =       "Abhayendra Singh and Daniel Marino and Satish
                 Narayanasamy and Todd Millstein and Madan Musuvathi",
  title =        "Efficient processor support for {DRFx}, a memory model
                 with exceptions",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "53--66",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950375",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Devietti:2011:RRC,
  author =       "Joseph Devietti and Jacob Nelson and Tom Bergan and
                 Luis Ceze and Dan Grossman",
  title =        "{RCDC}: a relaxed consistency deterministic computer",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "67--78",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950376",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Burnim:2011:SCS,
  author =       "Jacob Burnim and George Necula and Koushik Sen",
  title =        "Specifying and checking semantic atomicity for
                 multithreaded programs",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "79--90",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950377",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Volos:2011:MLP,
  author =       "Haris Volos and Andres Jaan Tack and Michael M.
                 Swift",
  title =        "{Mnemosyne}: lightweight persistent memory",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "91--104",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950379",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Coburn:2011:NHM,
  author =       "Joel Coburn and Adrian M. Caulfield and Ameen Akel and
                 Laura M. Grupp and Rajesh K. Gupta and Ranjit Jhala and
                 Steven Swanson",
  title =        "{NV-Heaps}: making persistent objects fast and safe
                 with next-generation, non-volatile memories",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "105--118",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950380",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Schupbach:2011:DLA,
  author =       "Adrian Sch{\"u}pbach and Andrew Baumann and Timothy
                 Roscoe and Simon Peter",
  title =        "A declarative language approach to device
                 configuration",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "119--132",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950382",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Ryzhyk:2011:IDD,
  author =       "Leonid Ryzhyk and John Keys and Balachandra Mirla and
                 Arun Raghunath and Mona Vij and Gernot Heiser",
  title =        "Improved device driver reliability through hardware
                 verification reuse",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "133--144",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950383",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Hashmi:2011:CNI,
  author =       "Atif Hashmi and Andrew Nere and James Jamal Thomas and
                 Mikko Lipasti",
  title =        "A case for neuromorphic {ISAs}",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "145--158",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950385",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Ransford:2011:MSS,
  author =       "Benjamin Ransford and Jacob Sorber and Kevin Fu",
  title =        "{Mementos}: system support for long-running
                 computation on {RFID}-scale devices",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "159--170",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950386",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Koukoumidis:2011:PC,
  author =       "Emmanouil Koukoumidis and Dimitrios Lymberopoulos and
                 Karin Strauss and Jie Liu and Doug Burger",
  title =        "Pocket cloudlets",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "171--184",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950387",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Sharma:2011:BMS,
  author =       "Navin Sharma and Sean Barker and David Irwin and
                 Prashant Shenoy",
  title =        "{Blink}: managing server clusters on intermittent
                 power",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "185--198",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950389",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Hoffmann:2011:DKR,
  author =       "Henry Hoffmann and Stelios Sidiroglou and Michael
                 Carbin and Sasa Misailovic and Anant Agarwal and Martin
                 Rinard",
  title =        "Dynamic knobs for responsive power-aware computing",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "199--212",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950390",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Liu:2011:FSD,
  author =       "Song Liu and Karthik Pattabiraman and Thomas
                 Moscibroda and Benjamin G. Zorn",
  title =        "{Flikker}: saving {DRAM} refresh-power through
                 critical data partitioning",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "213--224",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950391",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Deng:2011:MAL,
  author =       "Qingyuan Deng and David Meisner and Luiz Ramos and
                 Thomas F. Wenisch and Ricardo Bianchini",
  title =        "{MemScale}: active low-power modes for main memory",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "225--238",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950392",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Gao:2011:TMH,
  author =       "Qi Gao and Wenbin Zhang and Zhezhe Chen and Mai Zheng
                 and Feng Qin",
  title =        "{2ndStrike}: toward manifesting hidden concurrency
                 typestate bugs",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "239--250",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950394",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Zhang:2011:CDC,
  author =       "Wei Zhang and Junghee Lim and Ramya Olichandran and
                 Joel Scherpelz and Guoliang Jin and Shan Lu and Thomas
                 Reps",
  title =        "{ConSeq}: detecting concurrency bugs through
                 sequential errors",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "251--264",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950395",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Chipounov:2011:SPV,
  author =       "Vitaly Chipounov and Volodymyr Kuznetsov and George
                 Candea",
  title =        "{S2E}: a platform for in-vivo multi-path analysis of
                 software systems",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "265--278",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950396",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Hofmann:2011:EOS,
  author =       "Owen S. Hofmann and Alan M. Dunn and Sangman Kim and
                 Indrajit Roy and Emmett Witchel",
  title =        "Ensuring operating system kernel integrity with
                 {OSck}",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "279--290",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950398",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Porter:2011:RLT,
  author =       "Donald E. Porter and Silas Boyd-Wickizer and Jon
                 Howell and Reuben Olinsky and Galen C. Hunt",
  title =        "Rethinking the library {OS} from the top down",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "291--304",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950399",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Palix:2011:FLT,
  author =       "Nicolas Palix and Ga{\"e}l Thomas and Suman Saha and
                 Christophe Calv{\`e}s and Julia Lawall and Gilles
                 Muller",
  title =        "Faults in {Linux}: ten years later",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "305--318",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950401",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Esmaeilzadeh:2011:LBL,
  author =       "Hadi Esmaeilzadeh and Ting Cao and Yang Xi and Stephen
                 M. Blackburn and Kathryn S. McKinley",
  title =        "Looking back on the language and hardware revolutions:
                 measured power, performance, and scaling",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "319--332",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950402",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Nguyen:2011:SCS,
  author =       "Donald Nguyen and Keshav Pingali",
  title =        "Synthesizing concurrent schedulers for irregular
                 algorithms",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "333--344",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950404",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Hoang:2011:ECT,
  author =       "Giang Hoang and Robby Bruce Findler and Russ Joseph",
  title =        "Exploring circuit timing-aware language and
                 compilation",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "345--356",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950405",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Farhad:2011:OAM,
  author =       "Sardar M. Farhad and Yousun Ko and Bernd Burgstaller
                 and Bernhard Scholz",
  title =        "Orchestration by approximation: mapping stream
                 programs onto multicore architectures",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "357--368",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950406",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Zhang:2011:FED,
  author =       "Eddy Z. Zhang and Yunlian Jiang and Ziyu Guo and Kai
                 Tian and Xipeng Shen",
  title =        "On-the-fly elimination of dynamic irregularities for
                 {GPU} computing",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "369--380",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950408",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Hormati:2011:SPS,
  author =       "Amir H. Hormati and Mehrzad Samadi and Mark Woh and
                 Trevor Mudge and Scott Mahlke",
  title =        "{Sponge}: portable stream programming on graphics
                 engines",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "381--392",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950409",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Kamruzzaman:2011:ICP,
  author =       "Md Kamruzzaman and Steven Swanson and Dean M.
                 Tullsen",
  title =        "Inter-core prefetching for multicore processors using
                 migrating helper threads",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "393--404",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950411",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Hayashizaki:2011:IPT,
  author =       "Hiroshige Hayashizaki and Peng Wu and Hiroshi Inoue
                 and Mauricio J. Serrano and Toshio Nakatani",
  title =        "Improving the performance of trace-based systems by
                 false loop filtering",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "3",
  pages =        "405--418",
  month =        mar,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1961296.1950412",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:08 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "ASPLOS '11 conference proceedings",
}

@Article{Bala:2011:DTD,
  author =       "Vasanth Bala and Evelyn Duesterwald and Sanjeev
                 Banerjia",
  title =        "{Dynamo}: a transparent dynamic optimization system",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "4",
  pages =        "41--52",
  month =        apr,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1988042.1988044",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:07 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "We describe the design and implementation of Dynamo, a
                 software dynamic optimization system that is capable of
                 transparently improving the performance of a native
                 instruction stream as it executes on the processor. The
                 input native instruction stream to Dynamo can be
                 dynamically generated (by a JIT for example), or it can
                 come from the execution of a statically compiled native
                 binary. This paper evaluates the Dynamo system in the
                 latter, more challenging situation, in order to
                 emphasize the limits, rather than the potential, of the
                 system. Our experiments demonstrate that even
                 statically optimized native binaries can be accelerated
                 Dynamo, and often by a significant degree.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Claessen:2011:QLT,
  author =       "Koen Claessen and John Hughes",
  title =        "{QuickCheck}: a lightweight tool for random testing of
                 {Haskell} programs",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "4",
  pages =        "53--64",
  month =        apr,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1988042.1988046",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:07 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "QuickCheck is a tool which aids the Haskell programmer
                 in formulating and testing properties of programs.
                 Properties are discribed as Haskell functions, and can
                 be automatically tested on random input, but it is also
                 possible to define custom test data generators. We
                 present a number of case studies, in which the tool was
                 successfully used, and also point out some pitfalls to
                 avoid. Random testing is especially suitable for
                 functional programs because properties can be stated at
                 a fine grain.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Arnold:2011:AOJ,
  author =       "Matthew Arnold and Stephen Fink and David Grove and
                 Michael Hind and Peter F. Sweeney",
  title =        "Adaptive optimization in the {Jalapeno JVM}",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "4",
  pages =        "65--83",
  month =        apr,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1988042.1988048",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:07 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Future high-performance virtual machines will improve
                 performance through sophisticated online
                 feedback-directed optimizations. This paper presents
                 the architecture of the Jalapeno Adaptive Optimization
                 System, a system to support leading-edge virtual
                 machine technology and enable ongoing research on
                 online feedback-directed optimizations. We describe the
                 extensible system architecture, based on a federation
                 of threads with asynchronous communication. We present
                 an implementation of the general architecture that
                 supports adaptive multi-level optimization based purely
                 on statistical sampling. We empirically demonstrate
                 that this profiling technique has low overhead and can
                 improve startup and steady-state performance, even
                 without the presence of online feedback-directed
                 optimizations. The paper also describes and evaluates
                 an online feedback-directed inlining optimization based
                 on statistical edge sampling.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Ishtiaq:2011:BAL,
  author =       "Samin Ishtiaq and Peter W. O'Hearn",
  title =        "{BI} as an assertion language for mutable data
                 structures",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "4",
  pages =        "84--96",
  month =        apr,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1988042.1988050",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Tue May 24 10:55:07 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Reynolds has developed a logic for reasoning about
                 mutable data structures in which the pre- and
                 postconditions are written in an intuitionistic logic
                 enriched with a spatial form of conjunction. We
                 investigate the approach from the point of view of the
                 logic BI of bunched implications of O'Hearn and Pym. We
                 begin by giving a model in which the law of the
                 excluded middle holds, thus showing that the approach
                 is compatible with classical logic. The relationship
                 between the intuitionistic and classical versions of
                 the system is established by a translation, analogous
                 to a translation from intuitionistic logic into the
                 modal logic S4.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Virlet:2011:SSB,
  author =       "Bruno Virlet and Xing Zhou and Jean Pierre Giacalone
                 and Bob Kuhn and Maria J. Garzaran and David Padua",
  title =        "Scheduling of stream-based real-time applications for
                 heterogeneous systems",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "5",
  pages =        "1--10",
  month =        may,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2016603.1967679",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Aug 18 13:30:54 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "LCTES '10 conference proceedings",
}

@Article{Chattopadhyay:2011:SBS,
  author =       "Sudipta Chattopadhyay and Abhik Roychoudhury",
  title =        "Static bus schedule aware scratchpad allocation in
                 multiprocessors",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "5",
  pages =        "11--20",
  month =        may,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2016603.1967680",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Aug 18 13:30:54 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "LCTES '10 conference proceedings",
}

@Article{Albert:2011:TLA,
  author =       "Elvira Albert and Puri Arenas and Samir Genaim and
                 Damiano Zanardini",
  title =        "Task-level analysis for a language with async\slash
                 finish parallelism",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "5",
  pages =        "21--30",
  month =        may,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2016603.1967681",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Aug 18 13:30:54 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "LCTES '10 conference proceedings",
}

@Article{Chang:2011:LCW,
  author =       "Li-Pin Chang and Li-Chun Huang",
  title =        "A low-cost wear-leveling algorithm for block-mapping
                 solid-state disks",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "5",
  pages =        "31--40",
  month =        may,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2016603.1967683",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Aug 18 13:30:54 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Multilevel flash memory cells double or even triple
                 storage density, producing affordable solid-state disks
                 for end users. However, flash lifetime is becoming a
                 critical issue in the popularity of solid-state disks.
                 Wear-leveling methods can prevent flash-storage devices
                 from prematurely retiring any portions of flash memory.
                 The two practical challenges of wear-leveling design
                 are implementation cost and tuning complexity. This
                 study proposes a new wear-leveling design that features
                 both simplicity and adaptiveness. This design requires
                 no new data structures, but utilizes the intelligence
                 available in sector-translating algorithms. Using an
                 on-line tuning method, this design adaptively tunes
                 itself to reach good balance between wear evenness and
                 overhead. A series of trace-driven simulations show
                 that the proposed design outperforms a competitive
                 existing design in terms of wear evenness and overhead
                 reduction. This study also presents a prototype that
                 proves the feasibility of this wear-leveling design in
                 real solid-state disks.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "LCTES '10 conference proceedings",
}

@Article{Saha:2011:AIS,
  author =       "Suman Saha and Julia Lawall and Gilles Muller",
  title =        "An approach to improving the structure of
                 error-handling code in the {Linux} kernel",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "5",
  pages =        "41--50",
  month =        may,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2016603.1967684",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Aug 18 13:30:54 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "LCTES '10 conference proceedings",
}

@Article{Gray:2011:TCE,
  author =       "Ian Gray and Neil C. Audsley",
  title =        "Targeting complex embedded architectures by combining
                 the multicore communications {API} ({{\tt mcapi}}) with
                 compile-time virtualisation",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "5",
  pages =        "51--60",
  month =        may,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2016603.1967685",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Aug 18 13:30:54 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "LCTES '10 conference proceedings",
}

@Article{Benveniste:2011:DRT,
  author =       "Albert Benveniste and Timothy Bourke and Beno{\^\i}t
                 Caillaud and Marc Pouzet",
  title =        "Divide and recycle: types and compilation for a hybrid
                 synchronous language",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "5",
  pages =        "61--70",
  month =        may,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2016603.1967687",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Aug 18 13:30:54 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "LCTES '10 conference proceedings",
}

@Article{Gamatie:2011:SAS,
  author =       "Abdoulaye Gamatie and Laure Gonnord",
  title =        "Static analysis of synchronous programs in signal for
                 efficient design of multi-clocked embedded systems",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "5",
  pages =        "71--80",
  month =        may,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2016603.1967688",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Aug 18 13:30:54 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "LCTES '10 conference proceedings",
}

@Article{Berthier:2011:SPD,
  author =       "Nicolas Berthier and Florence Maraninchi and Laurent
                 Mounier",
  title =        "Synchronous programming of device drivers for global
                 resource control in embedded operating systems",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "5",
  pages =        "81--90",
  month =        may,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2016603.1967689",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Aug 18 13:30:54 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "LCTES '10 conference proceedings",
}

@Article{Wang:2011:DBM,
  author =       "Man Wang and Zhiyuan Li and Feng Li and Xiaobing Feng
                 and Saurabh Bagchi and Yung-Hsiang Lu",
  title =        "Dependence-based multi-level tracing and replay for
                 wireless sensor networks debugging",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "5",
  pages =        "91--100",
  month =        may,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2016603.1967691",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Aug 18 13:30:54 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "LCTES '10 conference proceedings",
}

@Article{Thomas:2011:LOS,
  author =       "Johnson J. Thomas and Sebastian Fischmeister and
                 Deepak Kumar",
  title =        "Lowering overhead in sampling-based execution
                 monitoring and tracing",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "5",
  pages =        "101--110",
  month =        may,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2016603.1967692",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Aug 18 13:30:54 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "LCTES '10 conference proceedings",
}

@Article{Navabpour:2011:SDT,
  author =       "Samaneh Navabpour and Borzoo Bonakdarpour and
                 Sebastian Fischmeister",
  title =        "Software debugging and testing using the abstract
                 diagnosis theory",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "5",
  pages =        "111--120",
  month =        may,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2016603.1967693",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Aug 18 13:30:54 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "LCTES '10 conference proceedings",
}

@Article{Cullmann:2011:CPA,
  author =       "Christoph Cullmann",
  title =        "Cache persistence analysis: a novel approachtheory and
                 practice",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "5",
  pages =        "121--130",
  month =        may,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2016603.1967695",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Aug 18 13:30:54 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "LCTES '10 conference proceedings",
}

@Article{Sarkar:2011:PTM,
  author =       "Abhik Sarkar and Frank Mueller and Harini Ramaprasad",
  title =        "Predictable task migration for locked caches in
                 multi-core systems",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "5",
  pages =        "131--140",
  month =        may,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2016603.1967696",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Aug 18 13:30:54 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "LCTES '10 conference proceedings",
}

@Article{Althaus:2011:PEP,
  author =       "Ernst Althaus and Sebastian Altmeyer and Rouven
                 Naujoks",
  title =        "Precise and efficient parametric path analysis",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "5",
  pages =        "141--150",
  month =        may,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2016603.1967697",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Aug 18 13:30:54 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "LCTES '10 conference proceedings",
}

@Article{Jang:2011:ISA,
  author =       "Choonki Jang and Jungwon Kim and Jaejin Lee and
                 Hee-Seok Kim and Dong-Hoon Yoo and Sukjin Kim and
                 Hong-Seok Kim and Soojung Ryu",
  title =        "An instruction-scheduling-aware data partitioning
                 technique for coarse-grained reconfigurable
                 architectures",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "5",
  pages =        "151--160",
  month =        may,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2016603.1967699",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Aug 18 13:30:54 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "LCTES '10 conference proceedings",
}

@Article{Bhagat:2011:GPP,
  author =       "Indu Bhagat and Enric Gibert and Jes{\'u}s S{\'a}nchez
                 and Antonio Gonz{\'a}lez",
  title =        "Global productiveness propagation: a code optimization
                 technique to speculatively prune useless narrow
                 computations",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "5",
  pages =        "161--170",
  month =        may,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2016603.1967700",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Aug 18 13:30:54 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  remark =       "LCTES '10 conference proceedings",
}

@Article{Prabhu:2011:CSL,
  author =       "Prakash Prabhu and Soumyadeep Ghosh and Yun Zhang and
                 Nick P. Johnson and David I. August",
  title =        "Commutative set: a language extension for implicit
                 parallel programming",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "1--11",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993500",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Pingali:2011:TPA,
  author =       "Keshav Pingali and Donald Nguyen and Milind Kulkarni
                 and Martin Burtscher and M. Amber Hassaan and Rashid
                 Kaleem and Tsung-Hsien Lee and Andrew Lenharth and
                 Roman Manevich and Mario M{\'e}ndez-Lojo and Dimitrios
                 Prountzos and Xin Sui",
  title =        "The tao of parallelism in algorithms",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "12--25",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993501",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Raman:2011:POU,
  author =       "Arun Raman and Hanjun Kim and Taewook Oh and Jae W.
                 Lee and David I. August",
  title =        "Parallelism orchestration using {DoPE}: the degree of
                 parallelism executive",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "26--37",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993502",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Hawkins:2011:DRS,
  author =       "Peter Hawkins and Alex Aiken and Kathleen Fisher and
                 Martin Rinard and Mooly Sagiv",
  title =        "Data representation synthesis",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "38--49",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993504",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Gulwani:2011:SGC,
  author =       "Sumit Gulwani and Vijay Anand Korthikanti and Ashish
                 Tiwari",
  title =        "Synthesizing geometry constructions",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "50--61",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993505",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Gulwani:2011:SLF,
  author =       "Sumit Gulwani and Susmit Jha and Ashish Tiwari and
                 Ramarathnam Venkatesan",
  title =        "Synthesis of loop-free programs",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "62--73",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993506",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Bohm:2011:GJT,
  author =       "Igor B{\"o}hm and Tobias J. K. Edler von Koch and
                 Stephen C. Kyle and Bj{\"o}rn Franke and Nigel Topham",
  title =        "Generalized just-in-time trace compilation using a
                 parallel task farm in a dynamic binary translator",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "74--85",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993508",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Jung:2011:BES,
  author =       "Changhee Jung and Silvius Rus and Brian P. Railing and
                 Nathan Clark and Santosh Pande",
  title =        "{Brainy:} effective selection of data structures",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "86--97",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993509",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Zhou:2011:SBA,
  author =       "Hucheng Zhou and Wenguang Chen and Fred Chow",
  title =        "An {SSA}-based algorithm for optimal speculative code
                 motion under an execution profile",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "98--108",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993510",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Li:2011:CHD,
  author =       "Xun Li and Mohit Tiwari and Jason K. Oberg and Vineeth
                 Kashyap and Frederic T. Chong and Timothy Sherwood and
                 Ben Hardekopf",
  title =        "{Caisson}: a hardware description language for secure
                 information flow",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "109--120",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993512",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Murray:2011:SAO,
  author =       "Derek Gordon Murray and Michael Isard and Yuan Yu",
  title =        "{Steno}: automatic optimization of declarative
                 queries",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "121--131",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993513",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Tobin-Hochstadt:2011:LL,
  author =       "Sam Tobin-Hochstadt and Vincent St-Amour and Ryan
                 Culpepper and Matthew Flatt and Matthias Felleisen",
  title =        "Languages as libraries",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "132--141",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993514",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Jablin:2011:ACG,
  author =       "Thomas B. Jablin and Prakash Prabhu and James A.
                 Jablin and Nick P. Johnson and Stephen R. Beard and
                 David I. August",
  title =        "Automatic {CPU--GPU} communication management and
                 optimization",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "142--151",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993516",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Prasad:2011:ACM,
  author =       "Ashwin Prasad and Jayvant Anantpur and R.
                 Govindarajan",
  title =        "Automatic compilation of {MATLAB} programs for
                 synergistic execution on heterogeneous processors",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "152--163",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993517",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Sampson:2011:EAD,
  author =       "Adrian Sampson and Werner Dietl and Emily Fortuna and
                 Danushen Gnanapragasam and Luis Ceze and Dan Grossman",
  title =        "{EnerJ}: approximate data types for safe and general
                 low-power computation",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "164--174",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993518",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Sarkar:2011:UPM,
  author =       "Susmit Sarkar and Peter Sewell and Jade Alglave and
                 Luc Maranget and Derek Williams",
  title =        "Understanding {POWER} multiprocessors",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "175--186",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993520",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Kuperstein:2011:PCA,
  author =       "Michael Kuperstein and Martin Vechev and Eran Yahav",
  title =        "Partial-coherence abstractions for relaxed memory
                 models",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "187--198",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993521",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Marino:2011:CSP,
  author =       "Daniel Marino and Abhayendra Singh and Todd Millstein
                 and Madanlal Musuvathi and Satish Narayanasamy",
  title =        "A case for an {SC}-preserving compiler",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "199--210",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993522",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "The most intuitive memory consistency model for
                 shared-memory multi-threaded programming is sequential
                 consistency (SC). However, current concurrent
                 programming languages support a relaxed model, as such
                 relaxations are deemed necessary for enabling important
                 optimizations. This paper demonstrates that an
                 SC-preserving compiler, one that ensures that every SC
                 behavior of a compiler-generated binary is an SC
                 behavior of the source program, retains most of the
                 performance benefits of an optimizing compiler. The key
                 observation is that a large class of optimizations
                 crucial for performance are either already
                 SC-preserving or can be modified to preserve SC while
                 retaining much of their effectiveness. An SC-preserving
                 compiler, obtained by restricting the optimization
                 phases in LLVM, a state-of-the-art C/C++ compiler,
                 incurs an average slowdown of 3.8% and a maximum
                 slowdown of 34% on a set of 30 programs from the
                 SPLASH-2, PARSEC, and SPEC CINT2006 benchmark
                 suites.\par

                 While the performance overhead of preserving SC in the
                 compiler is much less than previously assumed, it might
                 still be unacceptable for certain applications. We
                 believe there are several avenues for improving
                 performance without giving up SC-preservation. In this
                 vein, we observe that the overhead of our SC-preserving
                 compiler arises mainly from its inability to
                 aggressively perform a class of optimizations we
                 identify as eager-load optimizations. This class
                 includes common-subexpression elimination, constant
                 propagation, global value numbering, and common cases
                 of loop-invariant code motion. We propose a notion of
                 interference checks in order to enable eager-load
                 optimizations while preserving SC. Interference checks
                 expose to the compiler a commonly used hardware
                 speculation mechanism that can efficiently detect
                 whether a particular variable has changed its value
                 since last read.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
  keywords =     "LLVM compiler suite; sequential consistency (SC)",
}

@Article{Beckman:2011:PMS,
  author =       "Nels E. Beckman and Aditya V. Nori",
  title =        "Probabilistic, modular and scalable inference of
                 typestate specifications",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "211--221",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993524",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Kobayashi:2011:PAC,
  author =       "Naoki Kobayashi and Ryosuke Sato and Hiroshi Unno",
  title =        "Predicate abstraction and {CEGAR} for higher-order
                 model checking",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "222--233",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993525",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Chlipala:2011:MAV,
  author =       "Adam Chlipala",
  title =        "Mostly-automated verification of low-level programs in
                 computational separation logic",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "234--245",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993526",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Lee:2011:TGR,
  author =       "Kyu Hyung Lee and Yunhui Zheng and Nick Sumner and
                 Xiangyu Zhang",
  title =        "Toward generating reducible replay logs",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "246--257",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993528",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Godefroid:2011:HOT,
  author =       "Patrice Godefroid",
  title =        "Higher-order test generation",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "258--269",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993529",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Xu:2011:LHP,
  author =       "Guoqing Xu and Michael D. Bond and Feng Qin and Atanas
                 Rountev",
  title =        "{LeakChaser}: helping programmers narrow down causes
                 of memory leaks",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "270--282",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993530",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Yang:2011:FUB,
  author =       "Xuejun Yang and Yang Chen and Eric Eide and John
                 Regehr",
  title =        "Finding and understanding bugs in {C} compilers",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "283--294",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993532",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Compilers should be correct. To improve the quality of
                 C compilers, we created Csmith, a randomized test-case
                 generation tool, and spent three years using it to find
                 compiler bugs. During this period we reported more than
                 325 previously unknown bugs to compiler developers.
                 Every compiler we tested was found to crash and also to
                 silently generate wrong code when presented with valid
                 input. In this paper we present our compiler-testing
                 tool and the results of our bug-hunting study. Our
                 first contribution is to advance the state of the art
                 in compiler testing. Unlike previous tools, Csmith
                 generates programs that cover a large subset of C while
                 avoiding the undefined and unspecified behaviors that
                 would destroy its ability to automatically find
                 wrong-code bugs. Our second contribution is a
                 collection of qualitative and quantitative results
                 about the bugs we have found in open-source C
                 compilers.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Tristan:2011:EVG,
  author =       "Jean-Baptiste Tristan and Paul Govereau and Greg
                 Morrisett",
  title =        "Evaluating value-graph translation validation for
                 {LLVM}",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "295--305",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993533",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Sevcik:2011:SOS,
  author =       "Jaroslav Sevc{\'\i}k",
  title =        "Safe optimisations for shared-memory concurrent
                 programs",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "306--316",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993534",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Harris:2011:STT,
  author =       "William R. Harris and Sumit Gulwani",
  title =        "Spreadsheet table transformations from examples",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "317--328",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993536",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Meng:2011:SEG,
  author =       "Na Meng and Miryung Kim and Kathryn S. McKinley",
  title =        "Systematic editing: generating program transformations
                 from an example",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "329--342",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993537",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Srivastava:2011:SPO,
  author =       "Varun Srivastava and Michael D. Bond and Kathryn S.
                 McKinley and Vitaly Shmatikov",
  title =        "A security policy oracle: detecting security holes
                 using multiple {API} implementations",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "343--354",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993539",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Ansel:2011:LIS,
  author =       "Jason Ansel and Petr Marchenko and Ulfar Erlingsson
                 and Elijah Taylor and Brad Chen and Derek L. Schuff and
                 David Sehr and Cliff L. Biffle and Bennet Yee",
  title =        "Language-independent sandboxing of just-in-time
                 compilation and self-modifying code",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "355--366",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993540",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Zeng:2011:CCH,
  author =       "Qiang Zeng and Dinghao Wu and Peng Liu",
  title =        "{Cruiser}: concurrent heap buffer overflow monitoring
                 using lock-free data structures",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "367--377",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993541",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Lucia:2011:IUC,
  author =       "Brandon Lucia and Benjamin P. Wood and Luis Ceze",
  title =        "Isolating and understanding concurrency errors using
                 reconstructed execution fragments",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "378--388",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993543",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Jin:2011:AAV,
  author =       "Guoliang Jin and Linhai Song and Wei Zhang and Shan Lu
                 and Ben Liblit",
  title =        "Automated atomicity-violation fixing",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "389--400",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993544",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Burnim:2011:NRC,
  author =       "Jacob Burnim and Tayfun Elmas and George Necula and
                 Koushik Sen",
  title =        "{NDSeq}: runtime checking for nondeterministic
                 sequential specifications of parallel correctness",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "401--414",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993545",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Jin:2011:GCM,
  author =       "Dongyun Jin and Patrick O'Neil Meredith and Dennis
                 Griffith and Grigore Rosu",
  title =        "Garbage collection for monitoring parametric
                 properties",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "415--424",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993547",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Parr:2011:LFA,
  author =       "Terence Parr and Kathleen Fisher",
  title =        "{LL(*)}: the foundation of the {ANTLR} parser
                 generator",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "425--436",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993548",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Despite the power of Parser Expression Grammars (PEGs)
                 and GLR, parsing is not a solved problem. Adding
                 nondeterminism (parser speculation) to traditional LL
                 and LR parsers can lead to unexpected parse-time
                 behavior and introduces practical issues with error
                 handling, single-step debugging, and side-effecting
                 embedded grammar actions. This paper introduces the
                 LL(*) parsing strategy and an associated grammar
                 analysis algorithm that constructs LL(*) parsing
                 decisions from ANTLR grammars. At parse-time, decisions
                 gracefully throttle up from conventional fixed $k >= 1$
                 lookahead to arbitrary lookahead and, finally, fail
                 over to backtracking depending on the complexity of the
                 parsing decision and the input symbols. LL(*) parsing
                 strength reaches into the context-sensitive languages,
                 in some cases beyond what GLR and PEGs can express. By
                 statically removing as much speculation as possible,
                 LL(*) provides the expressivity of PEGs while retaining
                 LL's good error handling and unrestricted grammar
                 actions. Widespread use of ANTLR (over 70,000
                 downloads/year) shows that it is effective for a wide
                 variety of applications.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Jose:2011:CCC,
  author =       "Manu Jose and Rupak Majumdar",
  title =        "Cause clue clauses: error localization using maximum
                 satisfiability",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "437--446",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993550",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Budi:2011:AMA,
  author =       "Aditya Budi and David Lo and Lingxiao Jiang and
                 Lucia",
  title =        "$kb$-anonymity: a model for anonymized
                 behaviour-preserving test and debugging data",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "447--457",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993551",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Garcia:2011:KRR,
  author =       "Saturnino Garcia and Donghwan Jeon and Christopher M.
                 Louie and Michael Bedford Taylor",
  title =        "{Kremlin}: rethinking and rebooting {{\tt gprof}} for
                 the multicore age",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "458--469",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993553",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  abstract =     "Many recent parallelization tools lower the barrier
                 for parallelizing a program, but overlook one of the
                 first questions that a programmer needs to answer:
                 which parts of the program should I spend time
                 parallelizing?\par

                 This paper examines Kremlin, an automatic tool that,
                 given a serial version of a program, will make
                 recommendations to the user as to what regions (e.g.
                 loops or functions) of the program to attack first.
                 Kremlin introduces a novel hierarchical critical path
                 analysis and develops a new metric for estimating the
                 potential of parallelizing a region: self-parallelism.
                 We further introduce the concept of a parallelism
                 planner, which provides a ranked order of specific
                 regions to the programmer that are likely to have the
                 largest performance impact when parallelized. Kremlin
                 supports multiple planner personalities, which allow
                 the planner to more effectively target a particular
                 programming environment or class of machine.\par

                 We demonstrate the effectiveness of one such
                 personality, an OpenMP planner, by comparing versions
                 of programs that are parallelized according to
                 Kremlin's plan against third-party manually
                 parallelized versions. The results show that Kremlin's
                 OpenMP planner is highly effective, producing plans
                 whose performance is typically comparable to, and
                 sometimes much better than, manual parallelization. At
                 the same time, these plans would require that the user
                 parallelize significantly fewer regions of the
                 program.",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Sato:2011:APM,
  author =       "Shigeyuki Sato and Hideya Iwasaki",
  title =        "Automatic parallelization via matrix multiplication",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "470--479",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993554",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Udupa:2011:AEB,
  author =       "Abhishek Udupa and Kaushik Rajan and William Thies",
  title =        "{ALTER}: exploiting breakable dependences for
                 parallelization",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "480--491",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993555",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Srivastava:2011:PBI,
  author =       "Saurabh Srivastava and Sumit Gulwani and Swarat
                 Chaudhuri and Jeffrey S. Foster",
  title =        "Path-based inductive synthesis for program inversion",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "492--503",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993557",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Person:2011:DIS,
  author =       "Suzette Person and Guowei Yang and Neha Rungta and
                 Sarfraz Khurshid",
  title =        "Directed incremental symbolic execution",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "504--515",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993558",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{DElia:2011:MHC,
  author =       "Daniele Cono D'Elia and Camil Demetrescu and Irene
                 Finocchi",
  title =        "Mining hot calling contexts in small space",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "516--527",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993559",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Kim:2011:VSC,
  author =       "Deokhwan Kim and Martin C. Rinard",
  title =        "Verification of semantic commutativity conditions and
                 inverse operations on linked data structures",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "528--541",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993561",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Kulkarni:2011:ECL,
  author =       "Milind Kulkarni and Donald Nguyen and Dimitrios
                 Prountzos and Xin Sui and Keshav Pingali",
  title =        "Exploiting the commutativity lattice",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "542--555",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993562",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Perez:2011:SLS,
  author =       "Juan Antonio Navarro P{\'e}rez and Andrey
                 Rybalchenko",
  title =        "Separation logic $+$ superposition calculus $=$ heap
                 theorem prover",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "556--566",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993563",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Dillig:2011:PCM,
  author =       "Isil Dillig and Thomas Dillig and Alex Aiken and Mooly
                 Sagiv",
  title =        "Precise and compact modular procedure summaries for
                 heap manipulating programs",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "567--577",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993565",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Bouajjani:2011:IPA,
  author =       "Ahmed Bouajjani and Cezara Dragoi and Constantin Enea
                 and Mihaela Sighireanu",
  title =        "On inter-procedural analysis of programs with lists
                 and data",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "578--589",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993566",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Liang:2011:SAR,
  author =       "Percy Liang and Mayur Naik",
  title =        "Scaling abstraction refinement via pruning",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "590--601",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993567",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Altidor:2011:TWC,
  author =       "John Altidor and Shan Shan Huang and Yannis
                 Smaragdakis",
  title =        "Taming the wildcards: combining definition- and
                 use-site variance",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "602--613",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993569",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Tate:2011:TWJ,
  author =       "Ross Tate and Alan Leung and Sorin Lerner",
  title =        "Taming wildcards in {Java}'s type system",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "614--627",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993570",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Ziarek:2011:CAE,
  author =       "Lukasz Ziarek and KC Sivaramakrishnan and Suresh
                 Jagannathan",
  title =        "Composable asynchronous events",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "628--639",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993572",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Best:2011:SST,
  author =       "Micah J. Best and Shane Mottishaw and Craig Mustard
                 and Mark Roth and Alexandra Fedorova and Andrew
                 Brownsword",
  title =        "Synchronization via scheduling: techniques for
                 efficiently managing shared state",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "6",
  pages =        "640--652",
  month =        jun,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/1993316.1993573",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Thu Jun 9 10:23:33 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Bacon:2011:VAH,
  author =       "David F. Bacon",
  title =        "Virtualization in the age of heterogeneous machines",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "7",
  pages =        "1--2",
  month =        jul,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2007477.1952684",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Sep 16 10:02:34 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Du:2011:PPV,
  author =       "Jiaqing Du and Nipun Sehrawat and Willy Zwaenepoel",
  title =        "Performance profiling of virtual machines",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "7",
  pages =        "3--14",
  month =        jul,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2007477.1952686",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Sep 16 10:02:34 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Nikolaev:2011:PXF,
  author =       "Ruslan Nikolaev and Godmar Back",
  title =        "{Perfctr-Xen}: a framework for performance counter
                 virtualization",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "7",
  pages =        "15--26",
  month =        jul,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2007477.1952687",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Sep 16 10:02:34 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Zhao:2011:DCC,
  author =       "Qin Zhao and David Koh and Syed Raza and Derek
                 Bruening and Weng-Fai Wong and Saman Amarasinghe",
  title =        "Dynamic cache contention detection in multi-threaded
                 applications",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "7",
  pages =        "27--38",
  month =        jul,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2007477.1952688",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Sep 16 10:02:34 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Wang:2011:RVM,
  author =       "Kun Wang and Jia Rao and Cheng-Zhong Xu",
  title =        "Rethink the virtual machine template",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "7",
  pages =        "39--50",
  month =        jul,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2007477.1952690",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Sep 16 10:02:34 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Cecchet:2011:DVD,
  author =       "Emmanuel Cecchet and Rahul Singh and Upendra Sharma
                 and Prashant Shenoy",
  title =        "{Dolly}: virtualization-driven database provisioning
                 for the cloud",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "7",
  pages =        "51--62",
  month =        jul,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2007477.1952691",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Sep 16 10:02:34 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Le:2011:REV,
  author =       "Michael Le and Yuval Tamir",
  title =        "{ReHype}: enabling {VM} survival across hypervisor
                 failures",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "7",
  pages =        "63--74",
  month =        jul,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2007477.1952692",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Sep 16 10:02:34 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Park:2011:FSE,
  author =       "Eunbyung Park and Bernhard Egger and Jaejin Lee",
  title =        "Fast and space-efficient virtual machine
                 checkpointing",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "7",
  pages =        "75--86",
  month =        jul,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2007477.1952694",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Sep 16 10:02:34 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Zhang:2011:FRC,
  author =       "Irene Zhang and Alex Garthwaite and Yury Baskakov and
                 Kenneth C. Barr",
  title =        "Fast restore of checkpointed memory using working set
                 estimation",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "7",
  pages =        "87--98",
  month =        jul,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2007477.1952695",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Sep 16 10:02:34 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Kourai:2011:FCP,
  author =       "Kenichi Kourai",
  title =        "Fast and correct performance recovery of operating
                 systems using a virtual machine monitor",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "7",
  pages =        "99--110",
  month =        jul,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2007477.1952696",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Sep 16 10:02:34 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Svard:2011:EDC,
  author =       "Petter Sv{\"a}rd and Benoit Hudzia and Johan Tordsson
                 and Erik Elmroth",
  title =        "Evaluation of delta compression techniques for
                 efficient live migration of large virtual machines",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "7",
  pages =        "111--120",
  month =        jul,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2007477.1952698",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Sep 16 10:02:34 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Wood:2011:CDP,
  author =       "Timothy Wood and K. K. Ramakrishnan and Prashant
                 Shenoy and Jacobus van der Merwe",
  title =        "{CloudNet}: dynamic pooling of cloud resources by live
                 {WAN} migration of virtual machines",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "7",
  pages =        "121--132",
  month =        jul,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2007477.1952699",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Sep 16 10:02:34 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Zheng:2011:WAL,
  author =       "Jie Zheng and Tze Sing Eugene Ng and Kunwadee
                 Sripanidkulchai",
  title =        "Workload-aware live storage migration for clouds",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "7",
  pages =        "133--144",
  month =        jul,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2007477.1952700",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Sep 16 10:02:34 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Litty:2011:PAI,
  author =       "Lionel Litty and David Lie",
  title =        "Patch auditing in infrastructure as a service clouds",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "7",
  pages =        "145--156",
  month =        jul,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2007477.1952702",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Sep 16 10:02:34 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Payer:2011:FGU,
  author =       "Mathias Payer and Thomas R. Gross",
  title =        "Fine-grained user-space security through
                 virtualization",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "7",
  pages =        "157--168",
  month =        jul,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2007477.1952703",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Sep 16 10:02:34 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Lange:2011:MOV,
  author =       "John R. Lange and Kevin Pedretti and Peter Dinda and
                 Patrick G. Bridges and Chang Bae and Philip Soltero and
                 Alexander Merritt",
  title =        "Minimal-overhead virtualization of a large scale
                 supercomputer",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "7",
  pages =        "169--180",
  month =        jul,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2007477.1952705",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Sep 16 10:02:34 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Xia:2011:VWB,
  author =       "Lei Xia and Sanjay Kumar and Xue Yang and Praveen
                 Gopalakrishnan and York Liu and Sebastian Schoenberg
                 and Xingang Guo",
  title =        "Virtual {WiFi}: bring virtualization from wired to
                 wireless",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "7",
  pages =        "181--192",
  month =        jul,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2007477.1952706",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Sep 16 10:02:34 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Lange:2011:SSV,
  author =       "John R. Lange and Peter Dinda",
  title =        "{SymCall}: symbiotic virtualization through
                 {VMM}-to-guest upcalls",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "7",
  pages =        "193--204",
  month =        jul,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2007477.1952707",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Sep 16 10:02:34 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Williams:2011:OHM,
  author =       "Dan Williams and Hani Jamjoom and Yew-Huey Liu and
                 Hakim Weatherspoon",
  title =        "{Overdriver}: handling memory overload in an
                 oversubscribed cloud",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "7",
  pages =        "205--216",
  month =        jul,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2007477.1952709",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Sep 16 10:02:34 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Wang:2011:SHS,
  author =       "Xiaolin Wang and Jiarui Zang and Zhenlin Wang and
                 Yingwei Luo and Xiaoming Li",
  title =        "Selective hardware\slash software memory
                 virtualization",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "7",
  pages =        "217--226",
  month =        jul,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2007477.1952710",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Sep 16 10:02:34 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}

@Article{Roy:2011:HBR,
  author =       "Amitabha Roy and Steven Hand and Tim Harris",
  title =        "Hybrid binary rewriting for memory access
                 instrumentation",
  journal =      j-SIGPLAN,
  volume =       "46",
  number =       "7",
  pages =        "227--238",
  month =        jul,
  year =         "2011",
  CODEN =        "SINODQ",
  DOI =          "http://dx.doi.org/10.1145/2007477.1952711",
  ISSN =         "0362-1340 (print), 1523-2867 (print), 1558-1160 (electronic)",
  ISSN-L =       "0362-1340",
  bibdate =      "Fri Sep 16 10:02:34 MDT 2011",
  bibsource =    "http://portal.acm.org/",
  acknowledgement = ack-nhfb,
  fjournal =     "ACM SIGPLAN Notices",
}
