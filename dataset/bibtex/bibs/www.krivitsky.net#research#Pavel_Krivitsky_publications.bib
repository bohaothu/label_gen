% Encoding: ISO8859_1

@ARTICLE{krivitsky2011erg,
  author = {Krivitsky, Pavel N.},
  title = {Exponential-Family Random Graph Models for Valued Networks},
  journal = {Under revise and resubmit},
  year = {2011},
  month = jan,
  abstract = {Exponential-family random graph models (ERGMs) provide a principled
	and flexible way to model and simulate features common in social
	networks, such as propensities for homophily, mutuality, and friend-of-a-friend
	triad closure, through choice of model terms (sufficient statistics).
	However, those ERGMs modeling the more complex features have, to
	date, been limited to binary data: presence or absence of ties. Thus,
	analysis of valued networks, such as those where counts, measurements,
	or ranks are observed, has necessitated dichotomizing them, losing
	information. In this work, we generalize ERGMs to valued networks.
	Using the concept of reference measures, we describe a rigorous yet
	intuitive framework that retains many of the inferential and interpretability
	properties of the binary case, and discuss additional issues and
	caveats that emerge. Focusing on modeling counts, we introduce terms
	that generalize and model common social network features for count
	data, while avoiding degeneracy. We apply these methods on a commonly
	analyzed dataset whose values are counts of interactions.},
  eprint = {http://arxiv.org/abs/1101.1359},
  url = {http://arxiv.org/abs/1101.1359}
}

@PHDTHESIS{krivitsky2009sms,
  author = {Krivitsky, Pavel N.},
  title = {Statistical Models for Social Network Data and Processes},
  school = {University of Washington},
  year = {2009},
  address = {Seattle, WA},
  month = aug,
  abstract = {This work deals with three areas of network modeling. First, in the
	area of latent space modeling of social networks, it develops and
	extends latent cluster social network models by adding random effects
	and providing efficient algorithms for fitting these models. Second,
	it explores properties of ERGM and ERGM-based models under changing
	network size, and proposes a way of addressing the problems that
	arise. Third, in the area of dynamic networks, it proposes and develops
	a model separating tie formation process from tie dissolution process,
	facilitating flexible and realistic simulation of dynamic networks.
	Methods for integrating of adjustments for network size changes into
	the dynamic models are also developed.}
}

@ARTICLE{krivitsky2010smd,
  author = {Krivitsky, Pavel N. and Handcock, Mark S.},
  title = {A Separable Model for Dynamic Networks},
  journal = {Under review},
  year = {2010},
  month = nov,
  abstract = {Models of dynamic networks â€” networks that evolve over time ---
	have manifold applications. We develop a discrete-time generative
	model for social network evolution that inherits the richness and
	flexibility of the class of exponential-family random graph models.
	The model facilitates separable modeling of the tie duration distributions
	and the structural dynamics of tie formation. We develop likelihood-based
	inference for the model, and provide computational algorithms for
	maximum likelihood estimation. We illustrate the interpretability
	of the model in analyzing a longitudinal network of friendship ties
	within a school.},
  eprint = {http://arxiv.org/abs/1011.1937},
  keywords = {Social networks; Longitudinal; Exponential random graph model; Markov
	chain Monte Carlo; Maximum likelihood estimation},
  url = {http://arxiv.org/abs/1011.1937}
}

@ARTICLE{krivitsky2008fpl,
  author = {Krivitsky, Pavel N. and Handcock, Mark S.},
  title = {Fitting Position Latent Cluster Models for Social Networks with \pkg{latentnet}},
  journal = {Journal of Statistical Software},
  year = {2008},
  volume = {24},
  pages = {1--23},
  number = {5},
  month = may,
  abstract = {latentnet is a package to fit and evaluate statistical latent position
	and cluster models for networks. Hoff, Raftery, and Handcock (2002)
	suggested an approach to modeling networks based on positing the
	existence of an latent space of characteristics of the actors. Relationships
	form as a function of distances between these characteristics as
	well as functions of observed dyadic level covariates. In latentnet
	social distances are represented in a Euclidean space. It also includes
	a variant of the extension of the latent position model to allow
	for clustering of the positions developed in Handcock, Raftery, and
	Tantrum (2007). The package implements Bayesian inference for the
	models based on an Markov chain Monte Carlo algorithm. It can also
	compute maximum likelihood estimates for the latent position model
	and a two-stage maximum likelihood method for the latent position
	cluster model. For latent position cluster models, the package provides
	a Bayesian way of assessing how many groups there are, and thus whether
	or not there is any clustering (since if the preferred number of
	groups is 1, there is little evidence for clustering). It also estimates
	which cluster each actor belongs to. These estimates are probabilistic,
	and provide the probability of each actor belonging to each cluster.
	It computes four types of point estimates for the coefficients and
	positions: maximum likelihood estimate, posterior mean, posterior
	mode and the estimator which minimizes Kullback-Leibler divergence
	from the posterior. You can assess the goodness-of-fit of the model
	via posterior predictive checks. It has a function to simulate networks
	from a latent position or latent position cluster model.},
  issn = {1548-7660},
  url = {http://www.jstatsoft.org/v24/i05}
}

@ARTICLE{krivitsky2010ans,
  author = {Krivitsky, Pavel N. and Handcock, Mark S. and Morris, Martina},
  title = {Adjusting for Network Size and Composition Effects in Exponential-Family
	Random Graph Models},
  journal = {Statistical Methodology},
  year = {2011},
  volume = {8},
  number = {4},
  mon = {jul},
  page = {319--339},
  abstract = {Exponential-family random graph models (ERGMs) provide a principled
	way to model and simulate features common in human social networks,
	such as propensities for homophily and friend-of-a-friend triad closure.
	We show that, without adjustment, ERGMs preserve density as network
	size increases. Density invariance is often not appropriate for social
	networks. We suggest a simple modification based on an offset which
	instead preserves the mean degree and accommodates changes in network
	composition asymptotically. We demonstrate that this approach allows
	ERGMs to be applied to the important situation of egocentrically
	sampled data. We analyze data from the National Health and Social
	Life Survey (NHSLS).},
  eprint = {http://arxiv.org/abs/1004.5328},
  keywords = {network size; ERGM; random graph; egocentrically-sampled data},
  url = {http://arxiv.org/abs/1004.5328}
}

@ARTICLE{krivitsky2009rdd,
  author = {Krivitsky, Pavel N. and Handcock, Mark S. and Raftery, Adrian E.
	and Hoff, Peter D.},
  title = {Representing Degree Distributions, Clustering, and Homophily in Social
	Networks with Latent Cluster Random Effects Models},
  journal = {Social Networks},
  year = {2009},
  volume = {31},
  pages = {204--213},
  number = {3},
  month = jul,
  abstract = {Social network data often involve transitivity, homophily on observed
	attributes, community structure, and heterogeneity of actor degrees.
	We propose a latent cluster random effects model to represent all
	of these features, and we develop Bayesian inference for it. The
	model is applicable to both binary and non-binary network data. We
	illustrate the model using two real datasets: liking between monks
	and coreaderships between Slovenian publications. We also apply it
	to two simulated network datasets with very different network structure
	but the same highly skewed degree sequence generated from a preferential
	attachment process. One has transitivity and community structure
	while the other does not. Models based solely on degree distributions,
	such as scale-free, preferential attachment and power-law models,
	cannot distinguish between these very different situations, but the
	latent cluster random effects model does.},
  doi = {10.1016/j.socnet.2009.04.001},
  issn = {0378-8733}
}

@INPROCEEDINGS{raftery2007eil,
  author = {Raftery, Adrian E. and Newton, Michael A. and Satagopan, Jaya M.
	and Krivitsky, Pavel N.},
  title = {Estimating the Integrated Likelihood via Posterior Simulation Using
	the Harmonic Mean Identity},
  booktitle = {Bayesian Statistics 8: Proceedings of the Valencia/ISBA 8th World
	Meeting on Bayesian Statistics},
  year = {2007},
  volume = {8},
  pages = {317--416},
  publisher = {Oxford University Press, USA},
  abstract = {The integrated likelihood (also called the marginal likelihood or
	the normalizing constant) is a central quantity in Bayesian model
	selection and model averaging. It is defined as the integral over
	the parameter space of the likelihood times the prior density. The
	Bayes factor for model comparison and Bayesian testing is a ratio
	of integrated likelihoods, and the model weights in Bayesian model
	averaging are proportional to the integrated likelihoods. We consider
	the estimation of the integrated likelihood from posterior simulation
	output, aiming at a generic method that uses only the likelihoods
	from the posterior simulation iterations. The key is the harmonic
	mean identity, which says that the reciprocal of the integrated likelihood
	is equal to the posterior harmonic mean of the likelihood. The simplest
	estimator based on the identity is thus the harmonic mean of the
	likelihoods. While this is an unbiased and simulation-consistent
	estimator, its reciprocal can have infinite variance and so it is
	unstable in general. We describe two methods for stabilizing the
	harmonic mean estimator. In the first one, the parameter space is
	reduced in such a way that the modified estimator involves a harmonic
	mean of heavier-tailed densities, thus resulting in a finite variance
	estimator. The resulting estimator is stable. It is also self-monitoring,
	since it obeys the central limit theorem, and so confidence intervals
	are available. We discuss general conditions under which this reduction
	is applicable. The second method is based on the fact that the posterior
	distribution of the log-likelihood is approximately a gamma distribution.
	This leads to an estimator of the maximum achievable likelihood,
	and also an estimator of the effective number of parameters that
	is extremely simple to compute from the loglikelihoods, independent
	of the model parametrization, and always positive. This yields estimates
	of the log integrated likelihood, and posterior simulation-based
	analogues of the BIC and AIC model selection criteria, called BICM
	and AICM. We illustrate the proposed methods through several examples.},
  isbn = {0199214654}
}

