@Article{Greenberg:1976:CGS,

  author =       "Donald P. Greenberg and Richard H. Gallagher",
  title =        "Computer Graphics in Structural Engineering Research",
  journal =      "",
  month =        dec,
  year =         "1976",
}

@Article{Abel:1977:ICG,
  author =       "John F. Abel and Donald P. Greenberg and Shen-Chuan
                 Wu",
  title =        "An Interactive Computer Graphics Approach to Surface
                 Representation",
  journal =      "",
  volume =       "20",
  month =        oct,
  year =         "1977",
  pages =        "703--712",
}

@Article{Atherton:1977:ECC,
  author =       "Peter Atherton and Robert Haber and Richard Rogers",
  title =        "The Engineer's Computerized Consultant",
  journal =      "The Cornell Engineer",
  volume =       "42",
  number =       "4",
  month =        feb,
  year =         "1977",
  pages =        "22",
}

@MastersThesis{Atherton:1977:PSG,
  author =       "Peter Atherton",
  title =        "Polygon Shadow Generation with an Application to
                 Solar Rights",
  school =       "Cornell University",
  year =         "1977",
}

@Article{Greenberg:1977:CGB,
  author =       "Donald P. Greenberg",
  title =        "Computer Graphics: Back to the Electronic Drawing Board",
  journal =      "The Cornell Engineer",
  volume =       "42",
  number =       "4",
  month =        feb,
  year =         "1977",
  pages =        "4",
}

@Article{Greenberg:1977:IPG,
  author =       "Donald P. Greenberg",
  title =        "An Interdisciplinary Program for Graphics Research
                 and Applications",
  journal =      "Computer Graphics",
  volume =       "11",
  month =        "Summer",
  year =         "1977",
  pages =        "90--97",
  keywords =     "education and teaching",
}

@Article{Haber:1977:CAD,
  author =       "Robert B. Haber and Thomas A. Mutryn and John F.
                 Abel and Donald P. Greenberg",
  title =        "Computer-Aided Design of Framed Dome Structures with
                 Interactive Graphics",
  journal =      "Comp. Aided Design",
  volume =       "9",
  month =        jul,
  year =         "1977",
  pages =        "157--164",
  keywords =     "civil engineering and structural design",
}

@Article{Levoy:1977:CAS,
  author =       "Marc Levoy",
  title =        "A Color Animation System Based on the Multiplane Technique",
  journal =      "Computer Graphics",
  volume =       "11",
  month =        "Summer",
  year =         "1977",
  pages =        "65--71",
  keywords =     "color animation",
}

@Article{Levoy:1977:DD,
  author =       "Marc Levoy and Jose Gelabert",
  title =        "The Digital Draftsman",
  journal =      "The Cornell Engineer",
  volume =       "42",
  number =       "4",
  month =        feb,
  year =         "1977",
  pages =        "10",
}

@Article{Mutryn:1977:CGN,
  author =       "Thomas A. Mutryn and William McGuire and John Gross",
  title =        "Computer Graphics in Nonlinear Design Problems",
  journal =      "",
  address =      "Montreal, Canada",
  month =        oct,
  year =         "1977",
  pages =        "311",
}

@Article{Nall:1977:IGI,
  author =       "Daniel H. Nall and Richard J. Rogers and Donald P.
                 Greenberg and George D. Meixel",
  title =        "Interactive Graphics Input Methods for Residential
                 Building Load Calculation",
  journal =      "ASHRA Transactions -- Semi Annual Meeting",
  volume =       "83",
  year =         "1977",
}

@Article{Rogers:1977:CGI,
  author =       "Richard Rogers and Daniel Nall and Donald Greenberg",
  title =        "Computer Graphics Input Methods for Building Energy
                 Analysis",
  journal =      "Computer-Aided Design",
  volume =       "9",
  number =       "3",
  month =        jul,
  year =         "1977",
  pages =        "165--171",
  keywords =     "civil engineering",
}

@MastersThesis{Thornton:1977:IMT,
  author =       "Robert W. Thornton",
  title =        "Interactive Modeling in Three Dimensions through
                 Two-Dimensional Windows",
  school =       "Cornell University",
  year =         "1977",
}

@Article{Weiler:1977:HSR,
  author =       "Kevin Weiler and Peter Atherton",
  title =        "Hidden Surface Removal Using Polygon Area Sorting",
  journal =      "Computer Graphics (SIGGRAPH '77 Proceedings)",
  conference =   "held in San Jose, California; 20 -- 22 July 1977",
  editor =       "James George",
  volume =       "11",
  number =       "2",
  month =        jul,
  year =         "1977",
  pages =        "214--222",
  keywords =     "hidden surface removal, hidden line removal",
}

@MastersThesis{Weingarten:1977:CGI,
  author =       "Nicholas H. Weingarten",
  title =        "Computer Graphics Input Methods for Interactive Design",
  school =       "Cornell University",
  year =         "1977",
}

@InProceedings{Weingarten:1977:TDG,
  author =       "Nicholas Weingarten and Donald P. Greenberg",
  title =        "Three-Dimensional Graphic Input Using Recursive Instancing",
  booktitle =    "IEEE Computer Society First Int. Computer Software
                 and Applications Conference (COMSAC)",
  year =         "1977",
  pages =        "377--383",
  keywords =     "three-dimensional",
}

@Article{Wu:1977:ICG,
  author =       "S. C. Wu and John F. Abel and Donald P. Greenberg",
  title =        "An Interactive Computer Graphics Approach to Surface
                 Representation",
  journal =      "Communications of the ACM",
  volume =       "20",
  month =        oct,
  year =         "1977",
  pages =        "703--712",
  keywords =     "representation graphic and representation surface
                 geometry and representation",
}

@InProceedings{Allison:1978:TDG,
  author =       "H. C. Allison and Donald P. Greenberg",
  title =        "The Three-Dimensional Graphical Input Method for
                 Architecture",
  booktitle =    "Proceedings of the Fifteenth Annual Design Automation
                 Conference",
  organization = "IEEE",
  year =         "1978",
  pages =        "133--137",
  keywords =     "three-dimensional, methodology, architecture",
}

@Article{Atherton:1978:PSG,
  author =       "Peter Atherton and Kevin Weiler and Donald Greenberg",
  title =        "Polygon Shadow Generation",
  journal =      "Computer Graphics (SIGGRAPH '78 Proceedings)",
  conference =   "held in Atlanta, Georgia; 23 -- 25 August 1978",
  volume =       "12",
  number =       "3",
  month =        aug,
  year =         "1978",
  pages =        "275--281",
  keywords =     "shadow generation",
}

@Article{Sunguroff:1978:CGI,
  author =       "Alexander Sunguroff and Donald P. Greenberg",
  title =        "Computer Generated Images for Medical Applications",
  journal =      "Computer Graphics (SIGGRAPH '78 Proceedings)",
  conference =   "held in Atlanta, Georgia; 23 -- 25 August 1978",
  volume =       "12",
  number =       "3",
  month =        aug,
  year =         "1978",
  pages =        "",
  keywords =     "",
}

@Article{French:1978:WRP,
  author =       "Peter N. French and L. E. Johnson and Donald P. Loucks
                 and Donald P. Greenberg",
  title =        "Water Resources Planning Using Computer Graphics",
  journal =      "",
  month =        oct,
  year =         "1978",
}

@Article{Greenberg:1978:CGI,
  author =       "Donald P. Greenberg and Allex Allison",
  title =        "Computer Generated Images for Medical Applications",
  journal =      "",
  volume =       "12",
  month =        aug,
  year =         "1978",
  pages =        "196--202",
}

@InProceedings{Haber:1978:CAD,
  author =       "Robert Haber and John Abel and Donald Greenberg",
  title =        "A Computer-Aided Design System for Funicular Network
                 Structures",
  booktitle =    "Third Int. Conf. and Exhib. on Computers in Engineering
                 and Building Design",
  conference =   "held in Guildford, UK",
  publisher =    "IPC Sci. and Techn. Press",
  year =         "1978",
  pages =        "212--222",
}

@Article{Haber:1978:GGP,
  author =       "Robert Haber and Marc Shephard and John Abel and
                 Richard Gallagher and Donald Greenberg",
  title =        "A Generalized Graphic Preprocessor for Two-Dimensional
                 Finite Element Analysis",
  journal =      "Computer Graphics (SIGGRAPH '78 Proceedings)",
  conference =   "held in Atlanta, Georgia; 23 -- 25 August 1978",
  volume =       "12",
  number =       "3",
  month =        aug,
  year =         "1978",
  pages =        "323--329",
  keywords =     "finite element analysis",
}

@Article{Joblove:1978:CSC,
  author =       "George H. Joblove and Donald Greenberg",
  title =        "Color Spaces for Computer Graphics",
  journal =      "Computer Graphics (SIGGRAPH '78 Proceedings)",
  conference =   "held in Atlanta, Georgia; 23 -- 25 August 1978",
  volume =       "12",
  number =       "3",
  month =        aug,
  year =         "1978",
  pages =        "20--25",
  keywords =     "colors",
}

@MastersThesis{Levoy:1978:CAC,
  author =       "Marc S. Levoy",
  title =        "Computer-Assisted Cartoon Animation",
  school =       "Cornell University",
  year =         "1978",
}

@Article{Mutryn:1978:UCD,
  author =       "Thomas Mutryn and Donald Greenberg and John Abel",
  title =        "Use of Color Displays for the Interactive Design
                 of a Reticulated Dome Structure",
  journal =      "",
  month =        mar,
  year =         "1978",
  pages =        "589--599",
}

@Article{Rehkugler:1978:SMT,
  author =       "Gerald E. Rehkugler and Peter Atherton and J. E.
                 Kelly",
  title =        "Simulating the Motion of Two-and Four-Wheel Drive Tractors",
  journal =      "Agricultural Engineering",
  month =        mar,
  year =         "1978",
  pages =        "17--19",
}

@Article{Robertz:1978:CCP,
  author =       "Wayne Robertz and Richard Rogers and Daniel Nall
                 and Donald P. Greenberg",
  title =        "Comparison of Computer-Predicted Thermal Loads with
                 Measured Data from Three Occupied Townhouses",
  journal =      "",
  volume =       "84",
  number =       "2590",
  year =         "1978",
}

@Article{Rogers:1978:MIS,
  author =       "Richard Rogers and Peter Atherton and Daniel Nall
                 and Donald Greenberg",
  title =        "A Means for Including Shadowing in a Building's Thermal
                 Analysis",
  journal =      "",
  month =        mar,
  year =         "1978",
  pages =        "97--109",
}

@MastersThesis{Weiler:1978:HSR,
  author =       "Kevin Weiler",
  title =        "Hidden Surface Removal Using Polygon Area Sorting",
  school =       "Cornell University",
  year =         "1978",
}

@Article{Weiler:1978:PSG,
  author =       "Kevin Weiler and Peter Atherton and Donald P. Greenberg",
  title =        "Polygon Shadow Generation",
  journal =      "",
  volume =       "12",
  month =        aug,
  year =         "1978",
  pages =        "275--281",
}

@Article{Wu:1978:RDA,
  author =       "Sheng-Chuan Wu and John F. Abel",
  title =        "Representation and Discretization of Arbitrary Surfaces
                 for Finite Element Shell Analysis",
  journal =      "International Journal for Numerical Methods in Engineering",
  volume =       "14",
  month =        jul,
  year =         "1978",
  pages =        "813--836",
}

@Article{Abel:1979:IGF,
  author =       "John F. Abel and Donald P. Greenberg and William
                 McGuire and Richard S. Gallagher",
  title =        "Interactive Graphics for Finite Element Analysis",
  journal =      "ASCE",
  month =        aug,
  year =         "1979",
  pages =        "670--685",
}

@MastersThesis{Allison:1979:TDG,
  author =       "Harvey Allison",
  title =        "A Three-Dimensional Graphic Input Method
		  for Architectural Design",
  school =       "Cornell University",
  year =         "1979",
}

@MastersThesis{Barsky:1979:MDC,
  author =       "Brian A. Barsky",
  title =        "A Method for Describing Curved Surfaces by Transforming
                 Between Interpolatory and B-Spline Representations",
  school =       "Cornell University",
  year =         "1979",
}

@Article{Greenberg:1979:CGA,
  author =       "Donald P. Greenberg",
  title =        "Computer Graphics in Architecture",
  journal =      "",
  editor =       "Kellogg S. Booth",
  volume =       "EHO 147-9",
  year =         "1979",
}

@Article{Greenberg:1979:CGD,
  author =       "Donald P. Greenberg",
  title =        "Computer Graphics in Design: Today, Tomorrow or ?",
  journal =      "Computers in Architectural Design",
  month =        feb,
  year =         "1979",
}

@Article{Greenberg:1979:CSF,
  author =       "Donald P. Greenberg and Marc Schiler",
  title =        "Computer Simulation of Foliage Shading in Building
                 Energy Loads",
  journal =      "",
  year =         "1979",
}

@Article{Gross:1979:CGNa,
  author =       "John L. Gross and Thomas A. Mutryn and Donald P.
                 Greenberg",
  title =        "Computer Graphics in Nonlinear Design Problems",
  journal =      "Canadian Journal of Civil Engineering",
  volume =       "5",
  number =       "1",
  month =        mar,
  year =         "1979",
}

@Article{Gross:1979:CGNb,
  author =       "John L. Gross and Thomas A. Mutryn and William McGuire",
  title =        "Computer Graphics and Nonlinear Frame Analysis",
  journal =      "ASCE",
  month =        aug,
  year =         "1979",
  pages =        "",
}

@MastersThesis{Joblove:1979:CSC,
  author =       "George H. Joblove",
  title =        "Color Space and Computer Graphics",
  school =       "Cornell University",
  year =         "1979",
}

@Article{Kaplan:1979:PPT,
  author =       "Michael Kaplan and Donald P. Greenberg",
  title =        "Parallel Processing Techniques for Hidden Surface Removal",
  journal =      "Computer Graphics (SIGGRAPH '79 Proceedings)",
  volume =       "13",
  number =       "3",
  month =        aug,
  year =         "1979",
  pages =        "300--307",
  keywords =     "algorithmic aspects, hidden line/surface removal,
                 parallel processing, parallel processing",
}

@Article{Kay:1979:TCS,
  author =       "Douglas S. Kay and Donald P. Greenberg",
  title =        "Transparency for Computer Synthesized Images",
  journal =      "Computer Graphics (SIGGRAPH '79 Proceedings)",
  volume =       "13",
  number =       "2",
  month =        aug,
  year =         "1979",
  pages =        "158--164",
  keywords =     "ray tracing",
}

@MastersThesis{Kay:1979:TRR,
  author =       "Douglas S. Kay",
  title =        "Transparency, Refraction and Ray Tracing for Computer
                 Synthesized Images",
  school =       "Cornell University",
  year =         "1979",
}

@Article{Moffat:1979:CBA,
  author =       "Anne Simon Moffat",
  title =        "Computers Become A Major Design Tool",
  journal =      "",
  month =        dec,
  year =         "1979",
  pages =        "C1--2",
}

@MastersThesis{Mutryn:1979:NIB,
  author =       "Thomas A. Mutryn",
  title =        "Nonlinear, Inelastic Building Connections",
  school =       "Cornell University",
  year =         "1979",
}

@MastersThesis{Rogers:1979:CAM,
  author =       "Richard Rogers",
  title =        "A Computer-Aided Method for Shading Device Design
                 and Analysis",
  school =       "Cornell University",
  year =         "1979",
}

@MastersThesis{Schiler:1979:CSF,
  author =       "Marc E. Schiler",
  title =        "Computer Simulation of Foliage Effects on Building
                 Energy Load Calculations",
  school =       "Cornell University",
  year =         "1979",
}

@Article{Shephard:1979:EIC,
  author =       "Mark S. Shephard and R. H. Gallagher and John F.
                 Abel",
  title =        "Experience with Interactive Computer Graphics for
                 the Synthesis of Optimal Finite Element Meshes",
  journal =      "ASME",
  month =        jun,
  year =         "1979",
  pages =        "61--73",
}

@PhdThesis{Shephard:1979:FEG,
  author =       "Mark S. Shephard",
  title =        "Finite Element Grid Optimization with Interactive
                 Computer Graphics",
  school =       "Cornell University",
  year =         "1979",
  annote =       "(University Microfilms International, Ann Arbor,
                 MI, No. CRL79--10779).",
}

@Article{Wu:1979:ENT,
  author =       "Sheng-Chuan Wu and John F. Abel",
  title =        "Experience with a New Triangular, Doubly-Curved Element
                 for Shell Analysis",
  journal =      "ASCE",
  month =        aug,
  year =         "1979",
  pages =        "670--685",
}

@Article{Barsky:1980:DSB,
  author =       "Brian A. Barsky and Donald P. Greenberg",
  title =        "Determining a Set of {B}-Spline Control Vertices
                 to Generate an Interpolating Surface",
  journal =      "Comput. Gr. Image Process.",
  volume =       "14",
  month =        nov,
  year =         "1980",
  pages =        "203--226",
  keywords =     "Algorithmic Aspects splines and Mathematical Aspects
                 surface interpolation and Surface Graphics generation",
}

@Article{Feibush:1980:STU,
  author =       "Elliot A. Feibush and Marc Levoy and Robert L. Cook",
  title =        "Synthetic Texturing Using Digital Filters",
  journal =      "Computer Graphics (SIGGRAPH '80 Proceedings)",
  volume =       "14",
  number =       "3",
  month =        jul,
  year =         "1980",
  pages =        "294--301",
  keywords =     "Algorithmic Aspects, texture",
}

@Article{Feibush:1980:TRS,
  author =       "Elliot Feibush and Donald P. Greenberg",
  title =        "Texture Rendering System for Architectural Design",
  journal =      "Computer-Aided Design",
  volume =       "12",
  month =        mar,
  year =         "1980",
  pages =        "67--71",
  keywords =     "Algorithmic Aspects texture and Applications of Computer
                 Graphics architecture",
}

@PhdThesis{French:1980:WQM,
  author =       "Peter N. French",
  title =        "Water Quality Modeling Using Interactive Computer Graphics",
  school =       "Cornell University",
  year =         "1980",
  pages =        "252",
  keywords =     "Applications of Computer Graphics civil engineering",
  annote =       "(University Microfilms International, Ann Arbor MI,
                 No. 8020819).",
}

@Article{Greenberg:1980:ICG,
  author =       "Donald P. Greenberg and John F. Abel and William
                 McGuire",
  title =        "Interactive Computer Graphics in Structural Engineering",
  journal =      "Proceedings of the 11th Congress of the International
  Association for Bridge and Structural Engineering",
  month =        sep,
  year =         "1980",
  pages =        "631--636",
}

@Article{Greenberg:1980:ILC,
  author =       "Donald P. Greenberg",
  title =        "An Interdisciplinary Laboratory for Computer Graphics
                 and Computer-Aided Design",
  journal =      "Proceedings of CAD 80, Fourth International Conference and
  Exhibition on Computers and Design Engineering",
  volume =       "12",
  month =        mar,
  year =         "1980",
}

@Article{Greenberg:1980:LCG,
  author =       "Donald P. Greenberg",
  title =        "A Laboratory for Computer Graphics Research and Applications",
  journal =      "SID Digest",
  month =        may,
  year =         "1980",
}

@PhdThesis{Gross:1980:DPP,
  author =       "John L. Gross",
  title =        "Design for the Presentation of Progressive Collapse
                 Using Interactive Computer Graphics",
  school =       "Cornell University",
  year =         "1980",
  pages =        "195",
  annote =       "(University Microfilms International, Ann Arbor MI,
                 No. 8020822).",
}

@Article{Gross:1980:SNI,
  author =       "John L. Gross and Thomas A. Mutryn",
  title =        "Studies in Nonlinear Interactive Analysis of Framed
                 Structures",
  journal =      "",
  month =        may,
  year =         "1980",
}

@PhdThesis{Haber:1980:CAD,
  author =       "Robert B. Haber",
  title =        "Computer-Aided Design of Cable Reinforced Membrane
                 Structures",
  school =       "Cornell University",
  year =         "1980",
}

@Article{Johnson:1980:IMP,
  author =       "Lynn E. Johnson and Daniel P. Loucks",
  title =        "Interactive Multiobjective Planning Using Computer
                 Graphics",
  journal =      "Computers and Operational Research",
  year =         "1980",
  pages =        "89--97",
  keywords =     "Applications of Computer Graphics management science
                 planning and mathematics optimization",
}

@MastersThesis{Kaplan:1980:PPT,
  author =       "Michael Kaplan",
  title =        "Parallel Processing Techniques for Hidden-Surface Removal",
  school =       "Cornell University",
  year =         "1980",
}

@Article{Meyer:1980:PCS,
  author =       "Gary W. Meyer and Donald P. Greenberg",
  title =        "Perceptual Color Spaces for Computer Graphics",
  journal =      "Computer Graphics (SIGGRAPH '80 Proceedings)",
  volume =       "14",
  number =       "3",
  month =        jul,
  year =         "1980",
  pages =        "254--261",
  keywords =     "Methodologies, Techniques, Modeling colour spaces,
                 Colour Graphics color spaces/mapping, Man-Machine
                 Communications visual perception",
}

@InProceedings{Robertz:1980:GISa,
  author =       "Wayne Robertz and Donald P. Greenberg",
  title =        "A Graphical Input System for Computer-Aided Architectural
                 Design",
  booktitle =    "CAD 80, Fourth International Conference and Exhibition
                 on Computers in Design Engineering",
  publisher =    "IPC Business Press Ltd",
  address =      "Guildford, UK",
  volume =       "4",
  year =         "1980",
  pages =        "715--723",
  keywords =     "graphics systems interactive system and Methodologies,
                 Techniques, Modeling geometric design/modeling and
                 Applications of Computer Graphics architecture",
}

@MastersThesis{Robertz:1980:GISb,
  author =       "Wayne E. Robertz",
  title =        "A Graphical Input System for Computer-Aided Architectural
                 Design",
  school =       "Cornell University",
  year =         "1980",
}

@Article{Schiler:1980:CTO,
  author =       "Marc Schiler and Donald P. Greenberg",
  title =        "The Calculation of Translucent and Opaque Shadow
                 Effects on Building Thermal Loads",
  journal =      "Proceedings of CAD 80, Fourth International Conference and
  Exhibition on Computers in Design Engineering",
  volume =       "12",
  month =        mar,
  year =         "1980",
}

@Article{Shephard:1980:ADS,
  author =       "Mark Shephard",
  title =        "An Algorithm for Defining a Single Near-Optimum Mesh
                 for Multiple-Load-Case Problems",
  journal =      "International Journal for Numerical Methods in Engineering",
  volume =       "15",
  number =       "4",
  month =        apr,
  year =         "1980",
  pages =        "617--625",
}

@Article{Shephard:1980:SNO,
  author =       "Mark S. Shephard and Richard H. Gallagher and John
                 F. Abel",
  title =        "The Synthesis of Near-Optimum Finite Element Meshes
                 with Interactive Computer Graphics",
  journal =      "International Journal for Numerical Methods of Engineering",
  volume =       "15",
  number =       "7",
  month =        jul,
  year =         "1980",
  pages =        "1021--1039",
}

@Article{Weiler:1980:PCU,
  author =       "Kevin Weiler",
  title =        "Polygon Comparison Using a Graph Representation",
  journal =      "Computer Graphics (SIGGRAPH '80 Proceedings)",
  volume =       "14",
  number =       "3",
  month =        jul,
  year =         "1980",
  pages =        "10--18",
  keywords =     "Algorithmic Aspects polygon comparison, Applications
                 of Computer Graphics mathematics graphs, graph theory",
}

@Article{Abel:1981:VSE,
  author =       "John F. Abel and William McGuire and Anthony R. Ingraffea",
  title =        "In the Vanguard of Structural Engineering",
  journal =      "Engineering: Cornell Quarterly",
  volume =       "16",
  number =       "3",
  year =         "1981",
  pages =        "23--36",
}

@PhdThesis{Chang:1981:IFE,
  author =       "San-Cheng Chang",
  title =        "An Integrated Finite Element Nonlinear Shell Analysis
                 System with Interactive Computer Graphics",
  school =       "Cornell University",
  year =         "1981",
  annote =       "(University Microfilms International, Ann Arbor,
                 MI, KRA81--10971).",
}

@Article{Cook:1981:RMC,
  author =       "Robert L. Cook and Kenneth E. Torrance",
  title =        "A Reflectance Model for Computer Graphics",
  journal =      "Computer Graphics (SIGGRAPH '81 Proceedings)",
  conference =   "held in Dallas, Texas; July 1981",
  volume =       "15",
  number =       "3",
  month =        aug,
  year =         "1981",
  pages =        "307--316",
  keywords =     "I33 reflectance models",
}

@MastersThesis{Cook:1981:RMR,
  author =       "Robert L. Cook",
  title =        "A Reflection Model for Realistic Image Synthesis",
  school =       "Cornell University",
  year =         "1981",
}

@Article{Dill:1981:ACG,
  author =       "John C. Dill",
  title =        "An Application of Color Graphics to the Display of
                 Surface Curvature",
  journal =      "Computer Graphics (SIGGRAPH '81 Proceedings)",
  conference =   "held in Dallas, Texas; July 1981",
  volume =       "15",
  number =       "3",
  month =        aug,
  year =         "1981",
  pages =        "153--161",
  keywords =     "I35 colour graphics, I35 curvature display",
}

@Article{Dill:1981:CAD,
  author =       "John C. Dill",
  title =        "CAD/CAM: Industrial Takeover by Designing Computers",
  journal =      "Engineering: Cornell Quarterly",
  volume =       "16",
  number =       "3",
  year =         "1981",
  pages =        "37--45",
}

@MastersThesis{Feibush:1981:ICG,
  author =       "Eliot A. Feibush",
  title =        "An Interactive Computer Graphics Geometric Input
                 and Editing System for Architectural Design",
  school =       "Cornell University",
  year =         "1981",
}

@MastersThesis{Forbes:1981:MRC,
  author =       "Bruce K. Forbes",
  title =        "Methods for Reducing Computational Requirements in
                 the Geometric Modeling of Planar Surfaces and Volumes",
  school =       "Cornell University",
  year =         "1981",
}

@Article{Greenberg:1981:HCG,
  author =       "Donald P. Greenberg",
  title =        "How Computer Graphics Works and What It Can Do",
  journal =      "Engineering: Cornell Quarterly",
  volume =       "16",
  number =       "3",
  year =         "1981",
  pages =        "2--14",
}

@Article{Greenberg:1981:MCG,
  author =       "Donald P. Greenberg",
  title =        "The Magic of Computer Graphics",
  journal =      "APEC Journal",
  volume =       "XVI",
  number =       "1",
  year =         "1981",
  pages =        "4--10",
}

@Article{Greenberg:1981:VPR,
  author =       "Donald P. Greenberg and Stuart Sechrest",
  title =        "A Visible Polygon Reconstruction Algorithm",
  journal =      "",
  volume =       "15",
  month =        aug,
  year =         "1981",
  pages =        "17--27",
}

@Article{Haber:1981:GTD,
  author =       "Robert B. Haber and Mark S. Shephard and John F.
                 Abel and Richard H. Gallagher and Donald P. Greenberg",
  title =        "A General Two-Dimensional Graphical Finite Element
                 Preprocessor Utilizing Discrete Transfinite Mappings",
  journal =      "International Journal for Numerical Methods in Engineering",
  volume =       "17",
  number =       "7",
  month =        jul,
  year =         "1981",
  pages =        "1015--1044",
}

@Article{Haber:1981:IDS,
  author =       "Robert B. Haber and John F. Abel and Donald P. Greenberg",
  title =        "An Integrated Design System for Cable Reinforced
                 Membranes Using Interactive Computer Graphics",
  journal =      "Computers and Structures",
  volume =       "14",
  year =         "1981",
  pages =        "261--280",
  keywords =     "I34 civil engineering",
}

@MastersThesis{Han:1981:GTD,
  author =       "Tao-Yang Han",
  title =        "A General Two-Dimensional, Interactive Graphical
                 Finite/Boundary Element Preprocessor for a Virtual
                 Storage Environment",
  school =       "Cornell University",
  year =         "1981",
}

@PhdThesis{Johnson:1981:IMD,
  author =       "Lynn E. Johnson",
  title =        "An Interactive Method for Development and Evaluation
                 of Reservoir Operating Policies",
  school =       "Cornell University",
  year =         "1981",
}

@Article{Levoy:1981:TDC,
  author =       "Marc Levoy",
  title =        "Two-Dimensional Computer Animation",
  journal =      "",
  month =        aug,
  year =         "1981",
}

@Article{Loucks:1981:FCC,
  author =       "Daniel P. Loucks and Peter French and Marchall R.
                 Taylor",
  title =        "Friendly Computers with Color Pictures",
  journal =      "Engineering: Cornell Quarterly",
  volume =       "16",
  number =       "3",
  year =         "1981",
  pages =        "46--55",
}

@MastersThesis{Schulman:1981:IDP,
  author =       "Michael Schulman",
  title =        "The Interactive Display of Parameters on Two- and
                 Three-Dimensional Surfaces",
  school =       "Cornell University",
  year =         "1981",
}

@MastersThesis{Sechrest:1981:VPR,
  author =       "Stuart Sechrest",
  title =        "A Visible Polygon Reconstruction Algorithm",
  school =       "Cornell University",
  year =         "1981",
}

@Article{Wallace:1981:MTR,
  author =       "Bruce A. Wallace",
  title =        "Merging and Transformation of Raster Images for Cartoon
                 Animation",
  journal =      "Computer Graphics (SIGGRAPH '81 Proceedings)",
  conference =   "held in Dallas, Texas; July 1981",
  volume =       "15",
  number =       "3",
  month =        aug,
  year =         "1981",
  pages =        "253--262",
  keywords =     "I30 animation, I30 cartoon animation",
}

@Article{Beatty:1982:CGA,
  author =       "Donald P. Greenberg",
  title =        "Computer Graphics in Architecture",
  journal =      "",
  editor =       "John C. Beatty and Kellogg S. Booth",
  number =       "EHO 147-9",
  year =         "1982",
  pages =        "533",
}

@Article{Cook:1982:RMC,
  author =       "Robert L. Cook and Kenneth E. Torrance",
  title =        "A Reflectance Model for Computer Graphics",
  journal =      "ACM Transactions on Graphics",
  volume =       "1",
  number =       "1",
  month =        jan,
  year =         "1982",
  pages =        "7--24",
  keywords =     "I37 reflected light and color, TOG, shading",
}

@InCollection{Feibush:1982:GIE,
  author =       "Elliot A. Feibush and Donald P. Greenberg",
  title =        "A Geometric Input and Editing System for Architectural
                 Design",
  booktitle =    "CAD 82",
  editor =       "A. Pipes",
  year =         "1982",
  pages =        "164--172",
  keywords =     "I32 architectural CAD and I3m architectural CAD",
}

@PhdThesis{Gattas:1982:LDI,
  author =       "Marcelo Gattas",
  title =        "Large Displacement, Interactive-Adaptive Dynamic
                 Analysis of Frames",
  school =       "Cornell University",
  year =         "1982",
}

@Book{Greenberg:1982:CIA,
  author =       "Donald Greenberg and Aaron Marcus and Allan H. Schmidt
                 and Vernon Goter",
  title =        "The Computer Image: Applications of Computer Graphics",
  publisher =    "Addison-Wesley",
  year =         "1982",
  pages =        "128",
  keywords =     "I30 textbooks",
}

@Article{Greenberg:1982:IGE,
  author =       "Jon H. Pittman and Donald P. Greenberg",
  title =        "An Interactive Graphics Environment for Architectural
                 Energy Simulation",
  journal =      "",
  volume =       "16",
  month =        jul,
  year =         "1982",
  pages =        "233--241",
}

@Article{Haber:1982:IES,
  author =       "Robert B. Haber and John F. Abel",
  title =        "Initial Equilibrium Solution Methods for Cable Reinforced
                 Membranes. {II}. Implementation",
  journal =      "Comput. Methods Appl. Mech. and Eng.",
  volume =       "30",
  month =        jun,
  year =         "1982",
  pages =        "285--306",
  keywords =     "I34 civil engineering computing",
}

@Article{McGuire:1982:ICG,
  author =       "William McGuire and C. I. Pesquera",
  title =        "Interactive Computer Graphics in Steel Analysis/Design-A
                 Progress Report",
  journal =      "Engineering Journal",
  month =        mar,
  year =         "1982",
  pages =        "89--102",
}

@Article{Pittman:1982:IGEa,
  author =       "Jon H. Pittman and Donald P. Greenberg",
  title =        "An Interactive Graphics Environment for Architectural
                 Energy Simulation",
  journal =      "Computer Graphics (SIGGRAPH '82 Proceedings)",
  conference =   "held in Boston, Mass.; 26--30 July 1982",
  volume =       "16",
  number =       "3",
  month =        jul,
  year =         "1982",
  pages =        "233--241",
  keywords =     "I34 application packages, I3m architectural CAD",
}

@MastersThesis{Pittman:1982:IGEb,
  author =       "Jon H. Pittman",
  title =        "An Interactive Graphics Environment for Architectural
                 Energy Simulation",
  school =       "Cornell University",
  year =         "1982",
}

@Article{Sechrest:1982:VPR,
  author =       "Stuart Sechrest and Donald P. Greenberg",
  title =        "A Visible Polygon Reconstruction Algorithm",
  journal =      "ACM Trans. on Graphics (USA)",
  volume =       "1",
  month =        jan,
  year =         "1982",
  pages =        "25--42",
  keywords =     "I35 polygon reconstruction algorithm",
}

@Article{Shelley:1982:PSP,
  author =       "Kin L. Shelley and Donald P. Greenberg",
  title =        "Path Specification and Path Coherence",
  journal =      "Computer Graphics (SIGGRAPH '82 Proceedings)",
  conference =   "held in Boston, Mass.; 26--30 July 1982",
  volume =       "16",
  number =       "3",
  month =        jul,
  year =         "1982",
  pages =        "157--166",
  keywords =     "I33 display algorithms, I33 viewing algorithms, I36
                 interaction techniques, I37 visible line/surface algorithms",
}

@MastersThesis{Shelley:1982:PSU,
  author =       "Kim L. Shelley",
  title =        "Path Specification and the Use of Path Coherence
                 in the Rendering of Dynamic Sequences",
  school =       "Cornell University",
  year =         "1982",
}

@MastersThesis{Wallace:1982:APT,
  author =       "Bruce A. Wallace",
  title =        "Automated Production Techniques in Cartoon Animation",
  school =       "Cornell University",
  year =         "1982",
}

@Article{Crane:1983:EDA,
  author =       "Ted Crane and Jon H. Pittman",
  title =        "An Event Driven Approach to Graphical Menu Interaction",
  journal =      "",
  volume =       "9",
  number =       "4",
  month =        may,
  year =         "1983",
}

@Article{Dill:1983:CGC,
  author =       "John C. Dill",
  title =        "Computer Graphics and Computer-Aided Design at Cornell's
                 College of Engineering",
  journal =      "",
  month =        apr,
  year =         "1983",
}

@MastersThesis{Hall:1983:MRI,
  author =       "Roy A. Hall",
  title =        "A Methodology for Realistic Image Synthesis",
  school =       "Cornell University",
  year =         "1983",
}

@Article{Hall:1983:TRI,
  author =       "Roy A. Hall and Donald P. Greenberg",
  title =        "A Testbed for Realistic Image Synthesis",
  journal =      "IEEE Computer Graphics and Applications",
  volume =       "3",
  month =        nov,
  year =         "1983",
  pages =        "10--20",
  keywords =     "I37 Image Synthesis and I37 Surface Finish",
}

@InCollection{Hanna:1983:IPSa,
  author =       "Samir L. Hanna and John F. Abel and Donald P. Greenberg",
  title =        "Intersection of Parametric Surfaces Using Lookup
                 Tables",
  booktitle =    "Computer-Aided Geometric Design",
  month =        apr,
  year =         "1983",
  pages =        "37--49",
}

@Article{Hanna:1983:IPSb,
  author =       "Samir L. Hanna and John F. Abel and Donald P. Greenberg",
  title =        "Intersection of Parametric Surfaces by Means of Lookup
                 Tables",
  journal =      "IEEE Computer Graphics and Applications",
  volume =       "3",
  number =       "7",
  year =         "1983",
  pages =        "39--48",
}

@MastersThesis{Hedelman:1983:DFA,
  author =       "Harold Hedelman",
  title =        "A Data Flow Approach to Composition with Procedural
                 Models",
  school =       "Cornell University",
  year =         "1983",
}

@MastersThesis{Hollyday:1983:RMI,
  author =       "John D. Hollyday",
  title =        "Refined Modeling and Interactive Display of Finite
                 Element Stresses for Cable-Reinforced Membranes",
  school =       "Cornell University",
  year =         "1983",
}

@Article{Meyer:1983:CCGa,
  author =       "Gary W. Meyer",
  title =        "Colorimetry and Computer-Graphics",
  journal =      "",
  month =        apr,
  year =         "1983",
}

@MastersThesis{Meyer:1983:CCGb,
  author =       "Gary W. Meyer",
  title =        "Colorimetry and Computer Graphics",
  school =       "Cornell University",
  year =         "1983",
}

@Article{Pesquera:1983:DSF,
  author =       "C. I. Pesquera and William M. McGuire",
  title =        "Design of Steel Frames with Interactive Computer
                 Graphics",
  journal =      "",
  month =        sep,
  year =         "1983",
  pages =        "140--151",
}

@Article{Pesquera:1983:IGP,
  author =       "Carlos I. Pesquera and William McGuire and John F.
                 Abel",
  title =        "Interactive Graphical Preprocessing of Three-Dimensional
                 Framed Structures",
  journal =      "Computers and Structures",
  address =      "GB",
  volume =       "17",
  year =         "1983",
  pages =        "1--12",
  keywords =     "I3m mechanical engineering",
}

@MastersThesis{Carey:1984:TRI,
  author =       "Richard J. Carey",
  title =        "Textures for Realistic Image Synthesis",
  school =       "Cornell University",
  year =         "1984",
}

@Article{Goral:1984:MILa,
  author =       "Cindy M. Goral and Kenneth E. Torrance and Donald
                 P. Greenberg and Bennett Battaile",
  title =        "Modelling the Interaction of Light Between Diffuse
                 Surfaces",
  journal =      "Computer Graphics (SIGGRAPH '84 Proceedings)",
  conference =   "held in Minneapolis, Minnesota; July 23--27, 1984",
  volume =       "18",
  number =       "3",
  month =        jul,
  year =         "1984",
  pages =        "212--22",
  keywords =     "shading, diffuse reflection, radiosity",
  bibsource =    "sig-11-1994",
}

@Article{Greenberg:1984:CBC,
  author =       "Donald Greenberg",
  title =        "The Coming Breakthrough of Computers as a True Design
                 Tool",
  journal =      "Architectural Record",
  month =        sep,
  year =         "1984",
  pages =        "149--160",
}

@PhdThesis{Han:1984:ASI,
  author =       "Tao-Yang Han",
  title =        "Adaptive Substructuring and Interactive Graphics
                 for Three-Dimensional Elasto-Plastic Finite Element
                 Analysis",
  school =       "Cornell University",
  year =         "1984",
}

@MastersThesis{Hooper:1984:SIS,
  author =       "Gary J. Hooper",
  title =        "A System for Image Synthesis",
  school =       "Cornell University",
  year =         "1984",
}

@PhdThesis{Perucchio:1984:IBE,
  author =       "Renato Perucchio",
  title =        "An Integrated Boundary Element Analysis System with
                 Interactive Computer Graphics for Three-Dimensional
                 Linear-Elastic Fracture Mechanics",
  school =       "Cornell University",
  year =         "1984",
}

@MastersThesis{Salmon:1984:ICA,
  author =       "David C. Salmon",
  title =        "Improved Computer-Aided Design of Cable-Reinforced
                 Membranes",
  school =       "Cornell University",
  year =         "1984",
}

@Article{Verbeck:1984:CLSa,
  author =       "Channing P. Verbeck and Donald P. Greenberg",
  title =        "A Comprehensive Light Source Description for Computer
                 Graphics",
  journal =      "IEEE Computer Graphics and Applications",
  volume =       "4",
  number =       "7",
  month =        jul,
  year =         "1984",
  pages =        "66--75",
  bibsource =    "sig-11-1994",
}

@MastersThesis{Verbeck:1984:CLSb,
  author =       "Channing P. Verbeck",
  title =        "A Comprehensive Light Source Description for Computer
                 Graphics",
  school =       "Cornell University",
  year =         "1984",
}

@Article{Weghorst:1984:ICM,
  author =       "Hank Weghorst and Gary Hooper and Donald P. Greenberg",
  title =        "Improved Computational Methods for Ray Tracing",
  journal =      "ACM Transactions on Graphics",
  volume =       "3",
  number =       "1",
  month =        jan,
  year =         "1984",
  pages =        "52--69",
  keywords =     "I35 Ray Tracing, bounding volume",
}

@MastersThesis{Weghorst:1984:ISS,
  author =       "Hank Weghorst",
  title =        "An Image Synthesis System with Emphasis on Ray Tracing
                 Techniques",
  school =       "Cornell University",
  year =         "1984",
}

@MastersThesis{Ambrosi:1985:QSM,
  author =       "Dan V. Ambrosi",
  title =        "Quadric Surface Modeling for Ray Tracing",
  school =       "Cornell University",
  year =         "1985",
}

@MastersThesis{Bailey:1985:UCP,
  author =       "Bruce C. Bailey",
  title =        "Unification of Color Postprocessing Techniques for
                 Three-Dimensional Computational Mechanics",
  school =       "Cornell University",
  year =         "1985",
}

@Article{Carey:1985:TRI,
  author =       "Rikk J. Carey and Donald P. Greenberg",
  title =        "Textures for Realistic Image Synthesis",
  journal =      "Computers and Graphics",
  volume =       "9",
  number =       "2",
  year =         "1985",
  pages =        "125--138",
  keywords =     "texture",
}

@Article{Cohen:1985:HCR,
  author =       "Michael F. Cohen and Donald P. Greenberg",
  title =        "The {H}emi-{C}ube: {A} Radiosity Solution for Complex
                 Environments",
  journal =      "Computer Graphics (SIGGRAPH '85 Proceedings)",
  conference =   "held in San Francisco, CA; 22--26 July 1985",
  editor =       "Brian A. Barsky",
  volume =       "19",
  number =       "3",
  month =        jul,
  year =         "1985",
  pages =        "31--40",
}

@MastersThesis{Cohen:1985:RMR,
  author =       "Michael F. Cohen",
  title =        "A Radiosity Method for the Realistic Image Synthesis
                 of Complex Diffuse Environments",
  school =       "Cornell University",
  year =         "1985",
}

@MastersThesis{Goral:1985:MILb,
  author =       "Cindy M. Goral",
  title =        "A Model for the Interaction of Light Between Diffuse
                 Surfaces",
  school =       "Cornell University",
  year =         "1985",
}

@Article{Greenberg:1985:CGV,
  author =       "Donald P. Greenberg",
  title =        "Computer Graphics and Visualization",
  journal =      "",
  month =        dec,
  year =         "1985",
  pages =        "25--27",
}

@MastersThesis{Hajjar:1985:GPT,
  author =       "Jerome F. Hajjar",
  title =        "General-Purpose Three-Dimensional Color Postprocessing
                 for Engineering Analysis",
  school =       "Cornell University",
  year =         "1985",
}

@MastersThesis{Mazzotta:1985:MSA,
  author =       "Thomas V. Mazzotta",
  title =        "Modeling with Scripts: A Procedural Approach to the
                 Construction of Geometric Models Using Interactive
                 Computer Graphic Techniques",
  school =       "Cornell University",
  year =         "1985",
}

@InCollection{Meyer:1985:CCG,
  author =       "Gary W. Meyer and Donald P. Greenberg",
  title =        "Colorimetry and Computer Graphics",
  booktitle =    "SIGGRAPH '85 Image Rendering Tricks seminar notes",
  month =        jul,
  year =         "1985",
  keywords =     "color space",
}

@MastersThesis{White:1985:MGN,
  author =       "Donald Woodrow White",
  title =        "Material and Geometric Nonlinear Analysis of Local
                 Planar Behavior in Steel Frames Using Interactive
                 Computer Graphics",
  school =       "Cornell University",
  year =         "1985",
}

@Article{Baum:1986:BBA,
  author =       "Daniel R. Baum and John R. Wallace and Michael F.
                 Cohen and Donald P. Greenberg",
  title =        "The Back Buffer Algorithm: An Extension of the Radiosity
                 Method to Dynamic Environments",
  journal =      "The Visual Computer, Volume 2",
  year =         "1986",
  pages =        "298--306",
}

@Article{Brock:1986:UIGa,
  author =       "Philip J. Brock and Alan J. Polinsky and Rebecca
                 Slivka and Donald P. Greenberg",
  title =        "Unified Interactive Geometric Modeller for Simulating
                 Highly Complex Environments",
  journal =      "Computer-Aided Design",
  volume =       "18",
  number =       "10",
  month =        dec,
  year =         "1986",
  pages =        "539--545",
}

@MastersThesis{Brock:1986:UIGb,
  author =       "Philip J. Brock",
  title =        "A Unified Interactive Geometric Modeling System for
                 Simulating Highly Complex Environments",
  school =       "Cornell University",
  year =         "1986",
}

@Article{Cohen:1986:ERA,
  author =       "Michael Cohen and Donald P. Greenberg and Dave S.
                 Immel and Philip J. Brock",
  title =        "An Efficient Radiosity Approach for Realistic Image
                 Synthesis",
  journal =      "IEEE Computer Graphics and Applications",
  volume =       "6",
  number =       "3",
  month =        mar,
  year =         "1986",
  pages =        "26--35",
  bibsource =    "sig-11-1994",
}

@MastersThesis{Desjarlais:1986:WBR,
  author =       "Lisa Maynes Desjarlais",
  title =        "A Wave Based Reflection Model for Realistic Image
                 synthesis",
  school =       "Cornell University",
  year =         "1986",
}

@Article{Greenberg:1986:RMC,
  author =       "Donald P. Greenberg and Michael Cohen and Kenneth
                 E. Torrance",
  title =        "Radiosity: {A} Method for Computing Global Illumination",
  journal =      "The Visual Computer",
  volume =       "2",
  number =       "5",
  month =        sep,
  year =         "1986",
  pages =        "291--7",
  bibsource =    "sig-11-1994",
}

@Article{Greenberg:1986:CGS,
  author =       "Donald P. Greenberg",
  title =        "Computer Graphics Simulation in the 1990s",
  journal =      "Schweizer Ingenieur und Architekt",
  month =        feb,
  year =         "1986",
  pages =        "104--110",
}

@MastersThesis{Haines:1986:LBR,
  author =       "Eric A. Haines",
  title =        "The Light Buffer: A Ray Tracer Shadow Testing Accelerator",
  school =       "Cornell University",
  year =         "1986",
}

@Article{Haines:1986:LBS,
  author =       "Eric A. Haines and Donald P. Greenberg",
  title =        "The Light Buffer: a Shadow Testing Accelerator",
  journal =      "IEEE Computer Graphics and Applications",
  volume =       "6",
  number =       "9",
  year =         "1986",
  pages =        "6--16",
}

@Article{Hall:1986:CIM,
  author =       "Roy Hall",
  title =        "A Characterization of Illumination Models and Shading
                 Techniques",
  journal =      "The Visual Computer",
  volume =       "2",
  number =       "5",
  month =        sep,
  year =         "1986",
  pages =        "268--277",
}

@Article{Immel:1986:RMNa,
  author =       "David S. Immel and Michael F. Cohen and Donald P.
                 Greenberg",
  title =        "A Radiosity Method for Non-Diffuse Environments",
  journal =      "Computer Graphics (SIGGRAPH '86 Proceedings)",
  conference =   "held in Dallas, Texas; August 18--22, 1986",
  editor =       "David C. Evans and Russell J. Athay",
  volume =       "20",
  number =       "4",
  month =        aug,
  year =         "1986",
  pages =        "133--142",
  keywords =     "I37 radiosity, I37 reflectance, bi-directional, I37
                 hidden-surface elimination, I37 non-diffuse reflection,
                 radiosity, shading",
}

@MastersThesis{Immel:1986:RMNb,
  author =       "David S. Immel",
  title =        "A Radiosity Method for Non-Diffuse Surfaces",
  school =       "Cornell University",
  year =         "1986",
}

@MastersThesis{Koestner:1986:WBR,
  author =       "Kevin J. Koestner",
  title =        "A Wave Based Reflection Model for Realistic Image
                 Synthesis",
  school =       "Cornell University",
  year =         "1986",
}

@PhdThesis{Meyer:1986:CCP,
  author =       "Gary W. Meyer",
  title =        "Color Calculations for and Perceptual Assessment
                 of Computer Graphic Images",
  school =       "Cornell University",
  year =         "1986",
}

@InProceedings{Meyer:1986:CEC,
  author =       "Gary W. Meyer and Donald P. Greenberg",
  title =        "Color Education and Colour Synthesis in Computer Graphics",
  booktitle =    "Color Research and Application",
  conference =   "Proceedings of the 1986 AIC Interim Meeting on Color
                 in Computer Generated Displays; held in Toronto, Ont.,
                 Canada; 19--20 June 1986",
  volume =       "11 Suppl.",
  year =         "1986",
  pages =        "S39--S44",
  keywords =     "I37 color, I37 color synthesis",
}

@Article{Meyer:1986:EEC,
  author =       "Gary W. Meyer and Holly E. Rushmeier and Michael
                 F. Cohen and Donald P. Greenberg and Kenneth E. Torrance",
  title =        "An Experimental Evaluation of Computer Graphics Imagery",
  journal =      "ACM Transactions on Graphics",
  volume =       "5",
  number =       "1",
  month =        jan,
  year =         "1986",
  pages =        "30--50",
  bibsource =    "sig-11-1994",
}

@Article{Meyer:1986:WSS,
  author =       "Gary W. Meyer",
  title =        "Wavelength Selection for Synthetic Image Generation",
  journal =      "Computer Graphics and Image Processing",
  volume =       "II",
  year =         "1986",
  pages =        "39-44",
}

@MastersThesis{Polinsky:1986:UIG,
  author =       "Alan J. Polinsky",
  title =        "A Unified Interactive Geometric Modeling System for
                 Simulating Highly Complex Environments",
  school =       "Cornell University",
  year =         "1986",
}

@MastersThesis{Rushmeier:1986:ERM,
  author =       "Holly E. Rushmeier",
  title =        "Extending the Radiosity Method to Transmitting and
                 Specularly Reflecting Surfaces",
  school =       "Cornell University",
  year =         "1986",
}

@MastersThesis{Slivka:1986:MCS,
  author =       "Rebecca Slivka",
  title =        "A Motion Control System for Realistic Dynamics",
  school =       "Cornell University",
  year =         "1986",
}

@MastersThesis{Baum:1987:ERM,
  author =       "Daniel R. Baum",
  title =        "An Efficient Radiosity Method for Dynamic Environments",
  school =       "Cornell University",
  year =         "1987",
}

@Article{Cohen:1987:CDS,
  author =       "Michael F. Cohen and Paul M. Isaacs",
  title =        "Controlling Dynamic Simulation with Kinematic Constraints,
                 Behavior Functions and Inverse Dynamics",
  journal =      "",
  volume =       "21",
  month =        jul,
  year =         "1987",
  pages =        "214--224",
}

@Article{Cohen:1987:LRM,
  author =       "Michael F. Cohen",
  title =        "Light Reflection Models and Diffuse Interaction of
                 Light",
  journal =      "",
  year =         "1987",
}

@Article{Cohen:1987:NRC,
  author =       "Michael F. Cohen",
  title =        "The Need for Realism in Computer-Aided Design",
  journal =      "",
  year =         "1987",
}

@Article{Cohen:1987:RBL,
  author =       "Michael Cohen",
  title =        "Radiosity Based Lighting Design",
  journal =      "",
  year =         "1987",
}

@MastersThesis{Ferwerda:1987:PAA,
  author =       "James A. Ferwerda",
  title =        "A Psychophysical Approach to the Aliasing Problem
                 in Realistic Image Synthesis",
  school =       "Cornell University",
  year =         "1987",
}

@Article{Isaacs:1987:CDS,
  author =       "Paul M. Isaacs and Michael F. Cohen",
  title =        "Controlling Dynamic Simulation with Kinematic Constraints,
                 Behavior Functions and Inverse Dynamics",
  journal =      "Computer Graphics (SIGGRAPH '87 Proceedings)",
  conference =   "held in Anaheim, California; 27 -- 31 July 1987",
  editor =       "Maureen C. Stone",
  volume =       "21",
  number =       "4",
  month =        jul,
  year =         "1987",
  pages =        "215--224",
}

@MastersThesis{Panthaki:1987:CPF,
  author =       "Malcolm Panthaki",
  title =        "Color Postprocessing for Three-Dimensional Finite
                 Element Mesh Quality Evaluation And Evolving Graphical
                 Workstations",
  school =       "Cornell University",
  year =         "1987",
}

@Article{Rushmeier:1987:ZMC,
  author =       "Holly E. Rushmeier and Kenneth E. Torrance",
  title =        "The Zonal Method for Calculating Light Intensities
                 in the Presence of a Participating Medium",
  journal =      "Computer Graphics (SIGGRAPH '87 Proceedings)",
  conference =   "held in Anaheim, California; 27 -- 31 July 1987",
  editor =       "Maureen C. Stone",
  volume =       "21",
  number =       "4",
  month =        jul,
  year =         "1987",
  pages =        "293--302",
  keywords =     "clouds, light scattering, participating media, radiative
                 transport, radiosity, zonal method, haze",
}

@PhdThesis{Salmon:1987:LCO,
  author =       "David C. Salmon",
  title =        "Large Change-Of-Curvature Effects in Quadratic Finite
                 Elements for CAD of Membrane Structures",
  school =       "Cornell University",
  year =         "1987",
}

@Article{Wallace:1987:TPS,
  author =       "John R. Wallace and Michael F. Cohen and Donald P.
                 Greenberg",
  title =        "A Two-Pass Solution to the Rendering Equation: A
                 Synthesis of Ray Tracing and Radiosity Methods",
  journal =      "",
  volume =       "21",
  month =        jul,
  year =         "1987",
  pages =        "311--320",
}

@Article{Cohen:1988:PRA,
  author =       "Michael F. Cohen and Shenchang Eric Chen and John
                 R. Wallace and Donald P. Greenberg",
  title =        "A Progressive Refinement Approach to Fast Radiosity
                 Image Generation",
  journal =      "Computer Graphics (SIGGRAPH '88 Proceedings)",
  editor =       "John Dill",
  volume =       "22",
  number =       "4",
  month =        aug,
  year =         "1988",
  pages =        "75--84",
}

@Article{Ferwerda:1988:PAA,
  author =       "James A. Ferwerda and Donald P. Greenberg",
  title =        "A Psychophysical Approach to Assessing the Quality
                 of Antialiased Images",
  journal =      "IEEE Computer Graphics and Applications",
  volume =       "8",
  number =       "5",
  month =        sep,
  year =         "1988",
  pages =        "85--95",
}

@Article{Greenberg:1988:CAL,
  author =       "Donald P. Greenberg",
  title =        "Coons Award Lecture",
  journal =      "Communications of the ACM",
  volume =       "31",
  number =       "2",
  month =        feb,
  year =         "1988",
  pages =        "123--151",
}

@MastersThesis{Isaacs:1988:CCG,
  author =       "Paul M. Isaacs",
  title =        "Controlling Computer Generated Motion with Dynamics,
                 Kinematics, and Behavior Functions",
  school =       "Cornell University",
  year =         "1988",
}

@Article{Isaacs:1988:MMC,
  author =       "Paul M. Isaacs and Michael F. Cohen",
  title =        "Mixed Methods for Complex Kinematic Constraints in
                 Dynamic Figure Animation",
  journal =      "The Visual Computer",
  volume =       "4",
  number =       "6",
  month =        dec,
  year =         "1988",
  pages =        "296--305",
  keywords =     "simulation, dynamics",
}

@MastersThesis{Lu:1988:COM,
  author =       "Wei Lu",
  title =        "Curved Object Modeling and Rendering",
  school =       "Cornell University",
  year =         "1988",
}

@Article{Meyer:1988:CDV,
  author =       "Gary W. Meyer and Donald P. Greenberg",
  title =        "Color-Defective Vision and Computer Graphics Displays",
  journal =      "IEEE Computer Graphics and Applications",
  volume =       "8",
  number =       "5",
  month =        sep,
  year =         "1988",
  pages =        "28--40",
}

@Article{Meyer:1988:WSS,
  author =       "Gary W. Meyer",
  title =        "Wavelength Selection for Synthetic Image Generation",
  journal =      "Computer Vision, Graphics, and Image Processing",
  volume =       "41",
  year =         "1988",
  pages =        "57--79",
}

@PhdThesis{Rushmeier:1988:RIS,
  author =       "Holly Rushmeier",
  title =        "Realistic Image Synthesis for Scenes with Radiatively
                 Participating Media",
  school =       "Cornell University",
  year =         "1988",
}

@MastersThesis{Wallace:1988:TPS,
  author =       "John R. Wallace",
  title =        "A Two-Pass Solution to the Rendering Equation: A
                 Synthesis of Ray Tracing and Radiosity Methods",
  school =       "Cornell University",
  year =         "1988",
}

@Article{Baraff:1989:AMD,
  author =       "David Baraff",
  title =        "Analytical Methods for Dynamic Simulation of Non-penetrating
                 Rigid Bodies",
  journal =      "Computer Graphics (SIGGRAPH '89 Proceedings)",
  conference =   "held in Boston, Massachusetts; 31 July -- 4 August
                 1989",
  editor =       "Jeffrey Lane",
  volume =       "23",
  number =       "3",
  month =        jul,
  year =         "1989",
  pages =        "223--232",
  keywords =     "dynamics, constraints, simulation",
}

@MastersThesis{Chen:1989:PRM,
  author =       "Shenchang Eric Chen",
  title =        "A Progressive Radiosity Method and its Implementation
                 in a Distributed Processing Environment",
  school =       "Cornell University",
  year =         "1989",
}

@MastersThesis{Eaton:1989:EGC,
  author =       "Richard L. Eaton",
  title =        "Explicit Geometric Constraints",
  school =       "Cornell University",
  year =         "1989",
}

@MastersThesis{Feldman:1989:APM,
  author =       "Stuart Feldman",
  title =        "An Abstraction Paradigm for Modeling Complex Environments",
  school =       "Cornell University",
  year =         "1989",
}

@Article{Greenberg:1989:BF,
  author =       "Donald P. Greenberg",
  title =        "A Blueprint for the Future",
  journal =      "Computer Graphics World",
  volume =       "12",
  number =       "2",
  month =        feb,
  year =         "1989",
  pages =        "62--66",
}

@Article{Greenberg:1989:LRM,
  author =       "Donald P. Greenberg",
  title =        "Light Reflection Models in Computer Graphics",
  journal =      "Science",
  volume =       "244",
  month =        apr,
  year =         "1989",
  pages =        "166--173",
}

@Book{Hall:1989:ICC,
  author =       "Roy Hall",
  title =        "Illumination and Color in Computer Generated Imagery",
  publisher =    "Springer-Verlag",
  address =      "New York",
  year =         "1989",
  bibsource =    "sig-11-1994",
}

@PhdThesis{Kochevar:1989:CGM,
  author =       "Peter Kochevar",
  title =        "Computer Graphics on Massively Parallel Machines",
  school =       "Cornell University",
  year =         "1989",
}

@MastersThesis{Lytle:1989:MTR,
  author =       "Wayne Lytle",
  title =        "A Modular Testbed for Realistic Image Synthesis",
  school =       "Cornell University",
  year =         "1989",
}

@MastersThesis{Stettner:1989:CGA,
  author =       "Adam C. Stettner",
  title =        "Computer Graphics for Acoustic Simulation and Visualization",
  school =       "Cornell University",
  year =         "1989",
}

@Article{Stettner:1989:CGV,
  author =       "Adam Stettner and Donald P. Greenberg",
  title =        "Computer Graphics Visualization for Acoustic Simulation",
  journal =      "Computer Graphics (SIGGRAPH '89 Proceedings)",
  conference =   "held in Boston, Massachusetts; 31 July -- 4 August 1989",
  editor =       "Jeffrey Lane",
  volume =       "23",
  number =       "3",
  month =        jul,
  year =         "1989",
  pages =        "195--206",
  keywords =     "acoustics, simulation, scientific visualization,
                 ray tracing, Monte Carlo",
}

@MastersThesis{Tampieri:1989:GIA,
  author =       "Filippo Tampieri",
  title =        "Global Illumination Algorithms for Parallel Computer
                 Architectures",
  school =       "Cornell University",
  year =         "1989",
}

@Article{Baraff:1990:CSC,
  author =       "David Baraff",
  title =        "Curved Surfaces and Coherence for Non-penetrating
                 Rigid Body Simulation",
  journal =      "Computer Graphics (SIGGRAPH '90 Proceedings)",
  conference =   "held in Dallas, Texas; 6--10 August 1990",
  editor =       "Forest Baskett",
  volume =       "24",
  month =        aug,
  year =         "1990",
  pages =        "19--28",
  keywords =     "dynamics, constraints, simulation",
  abstract = 	"A formulation for the contact forces between curved 
		surfaces in resting (non-colliding) contact is presented. In
		contrast to previous formulations, constraints on the 
		allowable tangential movement between contacting surfaces
		are not required. Surfaces are restricted to be 
		twice-differentiable surfaces without boundary.  
		Only finitely many
		contact points between surfaces are allowed; however, the 
		surfaces need not be convex. The formulation yields the
		contact forces between curved surfaces and polyhedra as well. 
		Algorithms for performing collision detection during
		simulation on bodies composed of both polyhedra and 
		strictly convex curved surfaces are also presented. The
		collision detection algorithms exploit the geometric 
		coherence between successive time steps of the simulation to
		achieve efficient running times.",
}

@TechReport{Baraff:1990:DFI,
  author =       "David Baraff",
  title =        "Determining Frictional Inconsistency for Rigid Bodies is
		 NP-Complete",
  type =         "Technical report",
  institution =  "Department of Computer Science, Cornell University",
  number =       "TR90-1112",
  month =        apr,
  year =         "1990",
  abstract =     "The computational complexity of computing the forces between
		 bodies in contact is presented. The bodies are restricted to
		 be perfectly rigid bodies that contact at finitely many
		 points. It has been known for some time that under the
		 Coulomb model of friction, some configurations of bodies are
		 inconsistent; that is, no contact forces satisfying the
		 constraints of the Coulomb friction model exist for the
		 configuration. The main result of this paper is a proof that
		 determining if a configuration is inconsistent is an
		 NP-complete problem. An immediate corollary of this proof is
		 that computing the contact forces for a configuration of
		 bodies is NP-hard. Computing contact forces remains NP-hard
		 even if configurations are restricted to be consistent.",
}

@MastersThesis{Dorsey:1990:CGD,
  author =       "Julie O'Brien Dorsey",
  title =        "Computer Graphics for the Design and Visualization
                 of Opera Lighting Effect",
  school =       "Cornell University",
  year =         "1990",
}

@MastersThesis{George:1990:RRA,
  author =       "David W. George",
  title =        "A Radiosity Redistribution Algorithm for Dynamic
                 Environments",
  school =       "Cornell University",
  year =         "1990",
}

@Article{George:1990:RRD,
  author =       "David W. George and Francois X. Sillion and Donald
                 P. Greenberg",
  title =        "Radiosity Redistribution for Dynamic Environments",
  journal =      "IEEE Computer Graphics and Applications",
  volume =       "10",
  number =       "4",
  month =        jul,
  year =         "1990",
  pages =        "26--34",
  keywords =     "radiosity, animation, interaction, shadow, negative
                 radiosity",
  abstract = 	"The radiosity algorithm is extended to dynamic environments, 
		providing global-illumination simulations to scenes
		that are modified interactively. The illumination effects 
		introduced by a change in position, shape, or attributes of
		any object in the scene are computed very rapidly by 
		redistributing the energy already exchanged between objects.
		Corrections are made by shooting positive and negative energy, 
		accounting for increased illumination and the
		creation of shadows. Object coherence is used to minimize 
		computation, and progressive-refinement techniques
		are used to accelerate convergence. The extended algorithm 
		yields excellent approximations to the exact solutions
		at interactive speeds.",
}

@Article{Lengyel:1990:RTR,
  author =       "Jed Lengyel and Mark Reichert and Bruce R. Donald
                 and Donald P. Greenberg",
  title =        "Real-Time Robot Motion Planning Using Rasterizing
                 Computer Graphics Hardware",
  journal =      "Computer Graphics (SIGGRAPH '90 Proceedings)",
  conference =   "held in Dallas, Texas; 6--10 August 1990",
  editor =       "Forest Baskett",
  volume =       "24",
  number =       "4",
  month =        aug,
  year =         "1990",
  pages =        "327--335",
  abstract =     "We present a real-time robot motion planner that is fast and
		 complete to a resolution. The technique is guaranteed to find
		 a path if one exists at the resolution, and all paths returned
		 are safe. The planner can handle any polyhedral geometry of
		 robot and obstacles, including disjoint and highly concave
		 unions of polyhedra. The planner uses standard graphics
		 hardware to rasterize configuration space obstacles into a
		 series of bitmap slices, and then uses dynamic programming to
		 create a navigation function (a discrete vector-valued
		 function) and to calculate paths in this rasterized space.
		 The motion paths which the planner produces are minimal with
		 respect to an $L_{1}$ (Manhattan) distance metric that
		 includes rotation as well as translation. Several examples
		 are shown illustrating the competence of the planner at
		 generating planar rotational and translational plans for
		 complex two and three dimensional robots. Dynamic motion
		 sequences including complicated and non-obvious backtracking
		 solutions, can be executed in real time.",
}

@TechReport{Lengyel:1990:RTM,
  author =       "Jed Lengyel and Mark Reichert and Bruce R. Donald
                 and Donald P. Greenberg",
  title =        "Real-Time Robot Motion Planning Using Rasterizing
                 Computer Graphics Hardware",
  type =         "Technical report",
  institution =  "Department of Computer Science, Cornell University",
  number =       "TR90-1122",
  year =         "1990",
  abstract =     "We present a real-time robot motion planner that is fast and
		 complete to a resolution. The technique is guaranteed to find
		 a path if one exists at the resolution, and all paths returned
		 are safe. The planner can handle any polyhedral geometry of
		 robot and obstacles, including disjoint and highly concave
		 unions of polyhedra. The planner uses standard graphics
		 hardware to rasterize configuration space obstacles into a
		 series of bitmap slices, and then uses dynamic programming to
		 create a navigation function (a discrete vector-valued
		 function) and to calculate paths in this rasterized space.
		 The motion paths which the planner produces are minimal with
		 respect to an $L_{1}$ (Manhattan) distance metric that
		 includes rotation as well as translation. Several examples
		 are shown illustrating the competence of the planner at
		 generating planar rotational and translational plans for
		 complex two and three dimensional robots. Dynamic motion
		 sequences including complicated and non-obvious backtracking
		 solutions, can be executed in real time.",
}

@Article{Novins:1990:EMV,
  author =       "Kevin L. Novins and Fran{\,{c}}ois X. Sillion and
                 Donald P. Greenberg",
  title =        "An Efficient Method for Volume Rendering Using Perspective
                 Projection",
  journal =      "Computer Graphics",
  volume =       "24",
  number =       "5",
  month =        nov,
  year =         "1990",
  pages =        "95--102",
  abstract =     "Use of the perspective projection adds important perceptual
		 cues for image comprehension. However, it has not been widely
		 used in volume rendering because of the lack of efficient
		 computational algorithms and convern over the nonuniform
		 sampling rate imposed by perspective ray divergence. This
		 paper introduces two new techniques to help make perspective
		 projection more feasible in rendering volume data. First, a
		 method is presented for efficient slice-by-slice processing
		 of volume data, allowing high resolution data sets by
		 eliminating typical memory constraints. Second, an adaptive
		 'ray splitting' approach is described which ensures that the
		 entire volume is sampled within user-specified limits.
		 Additionally, we present results using distributed ray
		 tracing to achieve depth of field effects.",
}

@MastersThesis{Recker:1990:ITP,
  author =       "Rodney J. Recker",
  title =        "Improved Techniques for Progressive Refinement Radiosity",
  school =       "Cornell University",
  year =         "1990",
}

@Article{Rushmeier:1990:ERM,
  author =       "Holly E. Rushmeier and Kenneth E. Torrance",
  title =        "Extending the Radiosity Method to Include Specularly
                 Reflecting and Translucent Materials",
  journal =      "ACM Transactions on Graphics",
  volume =       "9",
  number =       "1",
  month =        jan,
  year =         "1990",
  pages =        "1--27",
  keywords =     "backward form factor, forward form factor, global
                 illumination, image synthesis, radiosity, ray tracing",
  abstract =     "An extension to the radiosity method is presented
                 that rigorously accounts for the presence of a small
                 number of specularly reflecting surfaces in an otherwise
                 diffuse scene, and for the presence of a small number
                 of specular or ideal diffuse transmitter. The relationship
                 between the extended method and earlier radiosity
                 and ray-tracing methods is outlined. It is shown that
                 all three methods are based on the same general equation
                 of radiative transfer. A simple superposition of the
                 earlier radiosity and ray-tracing methods in order
                 to account for specular behavior is shown to be physically
                 inconsistent, as the methods are based on different
                 assumptions. Specular behavior is correctly included
                 in the present method. The extended radiosity method
                 and example images are presented.",
}

@Article{Stettner:1990:CSA,
  author =       "Adam Stettner",
  title =        "Computer Simulation for Acoustic Visualization",
  journal =      "Audio Engineering Society 89th Convention",
  conference =   "Los Angeles, California",
  month =        sep,
  year =         "1990",
}

@Book{Arvo:1991:GGI,
  author =       "",
  title =        "Graphics Gems {II}",
  editor =       "James R. Arvo",
  publisher =    "Academic Press",
  address =      "San Diego",
  year =         "1991",
  abstract = 	"",
}

@Article{Baraff:1991:CFN,
  author =       "David Baraff",
  title =        "Coping with Friction for Non-Penetrating Rigid Body
                 Simulation",
  journal =      "Computer Graphics (SIGGRAPH '91 Proceedings)",
  conference =   "held in Las Vegas, Nevada; 28 July - 2 August 1991",
  editor =       "Thomas W. Sederberg",
  volume =       "25",
  number =       "4",
  month =        jul,
  year =         "1991",
  pages =        "31--40",
  keywords =     "dynamics, friction, simulation, np-complete",
  abstract = 	"Algorithms and computational complexity measures for 
		simulating the motion of contacting bodies with friction are
		presented. The bodies are restricted to be perfectly rigid 
		bodies that contact at finitely many points. Contact forces
		between bodies must satisfy the Coulomb model of friction. 
		A traditional principle of mechanics is that contact
		forces are impulsive if and only if non-impulsive contact 
		forces are insufficient to maintain the non-penetration
		constraints between bodies. When friction is allowed, it is 
		known that impulsive contact forces can be necessary
		even in the absence of collisions between bodies. This paper 
		shows that computing contact forces according to this
		traditional principle is likely to require exponential time. 
		An analysis of this result reveals that the principle for when
		impulses can occur is too restrictive, and a natural 
		reformulation of the principle is proposed.  Using the
		reformulated principle, an algorithm with expected 
		polynomial time behavior for computing contact forces is
		presented.",
}

@Article{Dorsey:1991:DSO,
  author =       "Julie O'B. Dorsey and Francois X. Sillion and Donald
                 P. Greenberg",
  title =        "Design and Simulation of Opera Lighting and Projection
                 Effects",
  journal =      "Computer Graphics (SIGGRAPH '91 Proceedings)",
  conference =   "held in Las Vegas, Nevada; 28 July - 2 August 1991",
  editor =       "Thomas W. Sederberg",
  volume =       "25",
  number =       "4",
  month =        jul,
  year =         "1991",
  pages =        "41--50",
  abstract = 	"A major problem challenging opera designers is the inability 
		to coordinate lighting, projection systems, and set
		designs in the preliminary planning phase. New computer 
		graphics techniques, which provide the set and lighting
		designer the opportunity to evaluate, test, and control opera 
		designs prior to the construction of full scale systems
		are presented, These techniques: light source input, simulation 
		of directional lighting, modeling of scenic projection
		systems, and full three-dimensional simulation show the 
		potential for the use of computer graphics in theater
		design. The light source input component consists of a program 
		for assigning light source attributes with a set of
		theater lighting icons.  This module allows a designer to 
		specify light source characteristics in a way familiar to the
		discipline and to make preliminary evaluations of the lighting 
		conditions. An extended progressive radiosity method
		is introduced to simulate the directional lighting 
		characteristics which are specified by the input program. A new
		projection approach is presented to simulate the optical 
		effects of scenic projectors. In addition, a solution to the
		distortion problem produced by angular projections is 
		described.  The above components are integrated to
		produce full three dimensional simulations of the global 
		illumination effects in an opera scene.",
}

@MastersThesis{Georgiades:1991:IMF,
  author =       "Priamos N. Georgiades",
  title =        "Interactive Methods for Locally Manipulating the
                 Intrinsic Geometry of Curved Surfaces",
  school =       "Cornell University",
  year =         "1991",
}

@Article{Greenberg:1991:CA,
  author =       "Donald P. Greenberg",
  title =        "Computers in Architecture",
  journal =      "Scientific American",
  month =        feb,
  year =         "1991",
  pages =        "104--109",
  abstract = 	"",
}

@Article{Greenberg:1991:MAS,
  author =       "Donald P. Greenberg",
  title =        "More Accurate Simulations at Faster Rates",
  journal =      "IEEE Computer Graphics and Applications",
  month =        jan,
  year =         "1991",
  pages =        "23--29",
  abstract = 	"The author discusses what has occurred in computer graphics 
		during the past two decades and what will occur in
		the future. He covers increases in model complexity, the 
		continuing quest for photorealism, progressive rendering
		algorithms, progressive modeling systems, physically based 
		light reflection models, elimination of display lists,
		migration from polygon algorithms to pixel algorithms based 
		on the true geometries, and separating sampling from
		discretization.",
}

@InProceedings{Hall:1991:TAM,
  author =       "Roy Hall and Mimi Bussan and Priamos Georgiades and
                 Donald P. Greenberg",
  title =        "A Testbed for Architectural Modeling",
  booktitle =    "Eurographics '91",
  conference =   "European Computer Graphics Conference and Exhibition;
                 held in Vienna, Austria; 2--6 September 1991",
  editor =       "Werner Purgathofer",
  publisher =    "North-Holland",
  month =        sep,
  year =         "1991",
  pages =        "47--58",
  abstract = 	"A boundary-representation modeling system that can be used 
		for architectural design is described.  The system is
		easy to use and has the ability to migrate from coarse, 
		preliminary design strategies to precise, geometric models
		for final design presentation.  The system also incorporates 
		fast rendering techniques for interactive use and
		employs global illumination algorithms for design evaluation 
		and high quality presentations.  The process of design is
		one of continued refinement of the design problem through the 
		exploration of possible solutions.  For computer
		tools to aid in this process, they must support conceptual 
		and schematic representations as well as geometric
		representations, allowing for the specification of multiple 
		levels of detail at a wide variety of scales.  This article
		presents the philosophy and implementation of software that 
		begins to provide such support.  The system is
		currently being used for teaching a fourth-year architectural 
		design studio in Cornell's Department of Architecture.",
}

@Article{He:1991:CPM,
  author =       "Xiao D. He and Kenneth E. Torrance and Francois X.
                 Sillion and Donald P. Greenberg",
  title =        "A Comprehensive Physical Model for Light Reflection",
  journal =      "Computer Graphics (SIGGRAPH '91 Proceedings)",
  conference =   "held in Las Vegas, Nevada; 28 July - 2 August 1991",
  editor =       "Thomas W. Sederberg",
  volume =       "25",
  number =       "4",
  month =        jul,
  year =         "1991",
  pages =        "175--186",
  abstract = 	"A new general reflectance model for computer graphics is 
		presented.  The model is based on physical optics and
		describes specular, directional diffuse, and uniform diffuse 
		reflection by a surface. The reflected light pattern
		depends on wavelength, incidence angle, two surface 
		roughness parameters. and surface refractive index. The
		formulation is self consistent in terms of polarization, 
		surface roughness, masking, shadowing, and energy. The
		model applies to a wide range of materials and surface 
		finishes and provides a smooth transition from diffuse-like
		to specular reflection as the wavelength and incidence angle 
		are increased or the surface roughness is decreased. 
		The model is analytic and suitable for Computer Graphics 
		applications.  Predicted reflectance distributions
		compare favorably with experiment. The model is applied to 
		metallic, nonmetallic, and plastic materials, with
		smooth and rough surfaces.",	
}

@MastersThesis{Himlan:1991:SDI,
  author =       "Theodore H. Himlan",
  title =        "Spectroradiometric 2D Imaging and Physical Property
                 Measurements for Validating and Improving Global Illumination
                 Simulations",
  school =       "Cornell University",
  year =         "1991",
}

@Article{Pini:1991:CTH,
  author =       "R. Pini and M. Costi and G. A. Mensah and K. L. Novins
                 and Donald P. Greenberg and B. Greppi and M. Cerofolini
                 and R. B. Devereaux",
  title =        "Computed Tomography of the Heart By Ultrasound",
  journal =      "Computers in Cardiology 1992",
  month =        sep,
  year =         "1991",
  pages =        "17--20",
  abstract =     "We developed a new echocardiographic transducer that allows
		 acquisition of 50 standard two-dimensional (2D) images at
		 3.6 degree increments of rotation around its central axis
		 from any acoustic window. To reconstruct three-dimensional
		 (3D) images of the beating heart, an entire cardiac cycle was
		 recorded form each transducer position with automatic
		 ECG-gating. For each frame of the cardiac cycle, the 50
		 images digitized in cylindrical coordinates were processed to
		 reconstruct a 3D cone of information in cartesian coordinates.
		 From the 3D matrices, 2D images in any plane can be derived
		 or full 3D perspective projections can be visualized. In
		 conclusion we have developed a new echocardiographic system
		 that allows a computed 3D reconstruction of the beating heart
		 without cumbersome external reference systems.",
}

@InCollection{Sillion:1991:DSB,
  author =       "Fran{\,{c}}ois Sillion",
  title =        "Detection of Shadow Boundaries for Adaptive Meshing
                 in Radiosity",
  booktitle =    "Graphics Gems II",
  editor =       "James Arvo",
  publisher =    "Academic Press",
  address =      "San Diego",
  year =         "1991",
  pages =        "311--315",
  bibsource =    "sig-11-1994",
  abstract = 	"",
}

@Article{Sillion:1991:GIS,
  author =       "Fran{\,{c}}ois X. Sillion and James R. Arvo and Stephen
                 H. Westin and Donald P. Greenberg",
  title =        "A Global Illumination Solution for General Reflectance
                 Distributions",
  journal =      "Computer Graphics (SIGGRAPH '91 Proceedings)",
  conference =   "held in Las Vegas, Nevada; 28 July -- 2 August 1991",
  editor =       "Thomas W. Sederberg",
  volume =       "25",
  month =        jul,
  year =         "1991",
  pages =        "187--196",
  abstract =     "A general light transfer simulation algorithm for
		  environments composed of materials with arbitrary
		  reflectance functions is presented. This algorithm removes
		  the previous practical restriction to ideal specular and/or
		  diffuse environments, and supports complex physically based
		  reflectance distributions. This is accomplished by extending
		  previous two-pass ray-casting radiosity approaches to handle
		  non-uniform intensity distributions, and resolving all
		  possible energy transfers between sample points. An
		  implimentation is described based on a spherical harmonic
		  decomposition for encoding both bidirectional reflectance
		  distribution functions for materials, and directional
		  intensity distributions for illuminated surfaces. The
		  method compares favorably with experimental measurements.",
}

@InProceedings{Tampieri:1991:CRA,
  author =       "Filippo Tampieri and Dani Lischinski",
  title =        "The Constant Radiosity Assumption Syndrome",
  booktitle =    "Eurographics Workshop on Rendering",
  conference =   "held in Barcelona, Spain; 13--15 May 1991",
  year =         "1991",
  pages =        "",
  abstract =     "In progressive refinement the radiosity of the shooting
                 patch is assumed to be constant. This is not correct.
                 It is better to take into account the variation of
                 the radiosity of the source. A progressive refinement
                 method is given that takes into account the non uniform
                 radiosity distribution of the shooting patch.",
}

@InCollection{Tampieri:1991:FVR,
  author =       "Filippo Tampieri",
  title =        "Fast Vertex Radiosity Update",
  booktitle =    "Graphics Gems II",
  editor =       "James Arvo",
  publisher =    "Academic Press",
  address =      "San Diego",
  year =         "1991",
  pages =        "303--305",
  bibsource =    "sig-11-1994",
  abstract = 	"",
}

@TechReport{Tampieri:1991:ISR,
  author =       "Filippo Tampieri and Dani Lischinski and Donald P.
                 Greenberg",
  title =        "Improving Sampling and Reconstruction Techniques
                 for Radiosity",
  type =         "Technical report",
  institution =  "Department of Computer Science, Cornell University",
  number =       "TR91-1202",
  month =        aug,
  year =         "1991",
  abstract =     "The view-independent global illumination problem is rephrased
		 as one determining a radiance function across each surface in
		 the environment. A new methodology for diffuse environments,
		 based on the sampling and reconstruction of these functions
		 is introduced. Within this context, the following problems
		 are investigated: (i) where the radiance functions should be
		 samples; (ii) how to evaluate a radiance function at each
		 sample; and (iii) how to reconstruct a radiance function for
		 the set of samples. The new methodology relaxes some of the
		 assumptions built into current radiosity algorithms. Results
		 are presented which show that the new methodology yields
		 significantly higher accuracy than existing radiosity
		 methods.",
}

@InProceedings{Trumbore:1991:TIS,
  author =       "Ben Trumbore and Wayne Lytle and Donald P. Greenberg",
  title =        "A Testbed for Image Synthesis",
  booktitle =    "Eurographics '91",
  conference =   "European Computer Graphics Conference and Exhibition;
                 held in Vienna, Austria; 2--6 September 1991",
  editor =       "Werner Purgathofer",
  publisher =    "North-Holland",
  month =        sep,
  year =         "1991",
  pages =        "467--480",
}

@MastersThesis{Wanger:1991:PSR,
  author =       "Leonard R. Wanger",
  title =        "Perceiving Spatial Relationships in Computer Generated
                 Images",
  school =       "Cornell University",
  year =         "1991",
}

@MastersThesis{Wanuga:1991:ARM,
  author =       "Paul H. Wanuga",
  title =        "Accelerated Radiosity Methods for Rendering Complex
                 Environments",
  school =       "Cornell University",
  year =         "1991",
}

@Article{Baraff:1992:DSNa,
  author =       "David Baraff and Andrew Witkin",
  title =        "Dynamic Simulation of Non-Penetrating Flexible Bodies",
  journal =      "Computer Graphics (SIGGRAPH '92 Proceedings)",
  conference =   "held in Chicago, Illinois; 26--31 July 1992",
  editor =       "Edwin E. Catmull",
  volume =       "26",
  number =       "2",
  month =        jul,
  year =         "1992",
  pages =        "303--308",
  abstract = 	"A model for the dynamic simulation of flexible bodies subject
to non-penetration constraints is presented. Flexible bodies are described
in terms of global deformations of a rest shape. The dynamical
behavior of these bodies that most closely matches the behavior
of ideal continuum bodies is derived, and subsumes the results of
earl ier Lagrangian dynamics-based models. The dynamics derived
for the flexible-body model allows the unification of previous work
on flexible body simulation and previous work on non-penetrating
rigid body simulation. The non-penetration constraints for a system
of bodies that contact at multiple points are maintained by analytically
calculated contact forces. An implementation for first- and
second-order polynomially deformable bodies is described. The
simulation of second-order or higher deformations currently involves
a polyhedral boundary approximation for collision detection
purposes.",
}

@PhdThesis{Baraff:1992:DSNb,
  author =       "David Baraff",
  title =        "Dynamic Simulation of Non-Penetrating Rigid Bodies",
  school =       "Cornell University",
  year =         "1992",
  abstract =     "This thesis examines the problems and difficulties in the
		 forward dynamic simulation of rigid bodies subject to
		 non-penetration constraints. By adopting a simple but
		 well-defined model of rigid body dynamics, we are able to
		 focus on and gain insight into some of the inherent
		 difficulties of rigid body simulation.  Additionally,
		 computationally practical solutions to some of the problems
		 encountered in this thesis are presented. Enforcing
		 non-penetration constraints is essentially a two step process.
		 The first step of the simulation involves the detection of
		 potential contacts between bodies. This thesis presents
		 collision detection algorithms for the dynamic simulation of
		 bodies that are composed of both polyhedra and convex closed
		 curved surfaces. The collision detection algorithms exploit
		 temporal coherence to achieve fast running times and are a
		 practical solution to the problem of collision detection
		 during simulation. The second step of the simulation involves
		 the computation of the contact forces between bodies that
		 maintain the non-penetration constraint. This thesis considers
		 first the problem of computing contact forces between a pair
		 of bodies that contact at a point without friction. A
		 mathematical formulation for the contact force between the
		 bodies is presented, and then modified to yield a formulation
		 that is computationally practical for use in a simulator.
		 After considering the dynamics of single point contacts,
		 systems with multiple contacts are considered both in terms
		 of computational complexity measures and practical solution
		 methods. The methods used in this thesis to compute constraint
		 forces are also theoretically and practically compared with a
		 popular method for preventing inter-penetration called the
		 ``penalty method''. After considering frictionless systems,
		 this thesis considers systems of bodies that behave according
		 to the classical Coulomb model of friction (which includes
		 both sliding and dry friction). This leads us to consider
		 systems in which there are no solutions to the classical
		 constraint force equations, as well as systems which admit
		 multiple solutions for the constraint force equations and
		 whose subsequent behavior is thus indeterminate. Both
		 computational and practical complexity results for simulating
		 such systems are discussed.",
}

@MastersThesis{Barshatzky:1992:GTM,
  author =       "Kathy Kershaw Barshatzky",
  title =        "A Generalized Texture-Mapping Pipeline",
  school =       "Cornell University",
  year =         "1992",
}

@Article{Georgiades:1992:LMG,
  author =       "Priamos N. Georgiades and Donald P. Greenberg",
  title =        "Locally Manipulating the Geometry of Curved Surfaces",
  journal =      "IEEE Computer Graphics and Applications",
  volume =       "12",
  number =       "1",
  month =        jan,
  year =         "1992",
  pages =        "54--64",
  keywords =     "local surface manipulation, gaussian curvature",
  abstract =     "Interactive tools that can be used to edit a curved surface 
		locally by altering its intrinsic geometric measures are
		described. The interface consists of two parts. The first 
		uses graphic displays that illustrate specific characteristics
		of the surface. Users can isolate different types of curves 
		on a surface. These curves yield unique information about
		the surface. The second part of the interface uses some of 
		the specialized icons to interactively manipulate the
		surface itself. The methods can be used with many 
		previously published techniques, and, because they are based
		on the intrinsic differential geometry of the surface, can 
		be applied to all types of surfaces (parametric, implicit,
		algebraic, and so forth). ",
}

@Article{He:1992:FAL,
  author =       "Xiao D. He and Patrick O. Heynen and Richard L. Phillips
                 and Kenneth E. Torrance and David H. Salesin and Donald
                 P. Greenberg",
  title =        "A Fast and Accurate Light Reflection Model",
  journal =      "Computer Graphics (SIGGRAPH '92 Proceedings)",
  conference =   "held in Chicago, Illinois; 26--31 July 1992",
  editor =       "Edwin E. Catmull",
  volume =       "26",
  number =       "2",
  month =        jul,
  year =         "1992",
  pages =        "253--254",
  keywords =     "reflectance model, multimedia",
  abstract =	"This multimedia paper elaborates on the 
		comprehensive physically based
		light reflection model introduced by He et al. [ 11.To explain
		the model more fully, the paper gives an 
		overview of the light reflection
		process at a surface, and employs an interactive graphical
		tool to demonstrate the reflection 
		model's directional behavior. To
		make the model more practical, the paper 
		describes an accurate approximation
		of the reflection model. based on a spline surface, that
		is much faster to compute. The paper concludes with two animated
		sequences, which demonstrate some features 
		of light reflection that
		are accounted for by the model. The full 
		paper demonstrates the potential
		of interactive multimedia. It is written using MediaVlew [2], a
		system for authoring documents that include 
		graphics, sound, video,
		and computer animation.",
}

@InCollection{Lischinski:1992:CBT,
  author =       "Dani Lischinski",
  title =        "Converting Bezier Triangles into Rectangular Patches",
  booktitle =    "Graphics Gems III",
  editor =       "David Kirk",
  publisher =    "Academic Press",
  address =      "San Diego",
  month =        jul,
  year =         "1992",
  abstract = 	"",
}

@TechReport{Novins:1992:AEB,
  author =       "Kevin Novins and James Arvo and David Salesin",
  title =        "Adaptive Error Bracketing for Controlled Precision
                 Volume Rendering",
  type =         "Technical report",
  institution =  "Department of Computer Science, Cornell University",
  number =       "TR92-1312",
  year =         "1992",
  abstract =     "We present a new ray tracing approach to volume rendering in
		 which the low-albedo volume rendering integral for each ray
		 is efficiently computed to any prescribed accuracy. By
		 bracketing the emission and absorption functions along each
		 ray with adaptively refined step functions, computation is
		 directed toward large sources of error and continued until a
		 desired accuracy is reached. As a result, coarse
		 approximations can be used in regions that are nearly
		 uniform, of low emission, or of low visibility due to
		 absorption by material closer to the eye. Adaptive refinement
		 for each ray is performed using a hierarchical organization
		 of the volume data; at each step, a part of the ray estimated
		 to contribute large error is refined, and the approximate
		 integral is updated incrementally. Our current implementation
		 operates on regularly-spaced data samples combined with
		 trilinear interpolation; however, the concepts described
		 apply to more general data topologies and reconstruction
		 filters.",
}

@MastersThesis{Pomeranz:1992:MMR,
  author =       "Ricardo Pomeranz",
  title =        "Mathematical Means of Representing Curves and Surfaces
                 of Varying Spatial Frequencies",
  school =       "Cornell University",
  year =         "1992",
}

@MastersThesis{Pruyn:1992:ETD,
  author =       "Peter W. Pruyn",
  title =        "An Exploration of Three Dimensional Computer Graphics
                 in Cockpit Avionics",
  school =       "Cornell University",
  year =         "1992",
}

@MastersThesis{Reichert:1992:TPR,
  author =       "Mark C. Reichert",
  title =        "A Two-Pass Radiosity Method Driven By Lights and
                 Viewers Position",
  school =       "Cornell University",
  year =         "1992",
}

@Article{Salesin:1992:RIF,
  author =       "David Salesin and Daniel Lischinski and Tony DeRose",
  title =        "Reconstructing Illumination Functions with Selected
                 Discontinuities",
  journal =      "Third Eurographics Workshop on Rendering",
  address =      "Bristol, UK",
  month =        may,
  year =         "1992",
  pages =        "99--112",
  abstract =     "Typical illumination functions contain boundaries that are
		  discontinuous in intensity or derivative. These
		  discontinuities arise from contact between surfaces, and
		  from the penumbra and umbra boundaries of shadows cast by
		  area light sources. In this paper, we present an algorithm
		  that allows for smooth (C1) reconstruction of intensity
		  everywhere across a surface except along selected edges of
		  intensity or derivative discontinuity. The reconstruction
		  algorithm is based on a piecewise-cubic scattered data
		  interpolation method originally proposed by Clough and
		  Tocher. Our results show marked improvement over piecewise
		  linear or C1 quadratic reconstructions of some simple
		  illumination functions.",
}

@InCollection{Scofield:1992:SCA,
  author =       "Cary Scofield and James Arvo",
  title =        "The Shader Cache: A Rendering Pipeline Accelerator",
  booktitle =    "Graphics Gems III",
  editor =       "David Kirk",
  publisher =    "Academic Press",
  address =      "San Diego",
  month =        jul,
  year =         "1992",
  abstract = 	"",
}

@InCollection{Shirley:1992:NRP,
  author =       "Peter Shirley",
  title =        "Nonuniform Random Point Sets via Warping",
  booktitle =    "Graphics Gems III",
  editor =       "David Kirk",
  publisher =    "Academic Press",
  address =      "San Diego",
  year =         "1992",
  pages =        "80--83",
  keywords =     "Monte Carlo",
  bibsource =    "sig-11-1994",
  abstract = 	"",
}

@Article{Smits:1992:IDR,
  author =       "Brian E. Smits and James R. Arvo and David H. Salesin",
  title =        "An Importance-Driven Radiosity Algorithm",
  journal =      "Computer Graphics (SIGGRAPH '92 Proceedings)",
  editor =       "Edwin E. Catmull",
  volume =       "26",
  month =        jul,
  year =         "1992",
  pages =        "273--282",
  abstract =     "We present a new radiosity algorithm for efficiently
		  computing global solutions with respect to a constrained
		  set of views.  Radiosities of directly visible surfaces
		  are computed to high accuracy, while those surfaces having
		  only an indirect effect are computed to an accuracy
		  commensurate with their contribution. The algorithm uses an
		  adaptive subdivision scheme that is guided by the interplay
		  between two closely related transport processes: one
		  propagating power from the light sources, and the other
		  propagating importance from the visible surfaces. By
		  simultaneously refining approximate solutions to the dual
		  transport equations, computation is significantly reduced
		  in areas that contribute little to the region of interest.
		  This approach is very effective for complex environments in
		  which only a small fraction is visible at any time. Our
		  statistics show dramatic speedups over the fastest previous
		  radiosity algorithms for diffuse environments with details
		  at a wide range of scales.",
}

@InCollection{Tampieri:1992:AFF,
  author =       "Filippo Tampieri",
  title =        "Accurate Form-Factor Computation",
  booktitle =    "Graphics Gems III",
  editor =       "David Kirk",
  publisher =    "Academic Press",
  address =      "San Diego",
  year =         "1992",
  pages =        "329--333",
  bibsource =    "sig-11-1994",
  abstract = 	"",
}

@InCollection{Tampieri:1992:GNC,
  author =       "Filippo Tampieri and David Salesin",
  title =        "Grouping Nearly Coplanar Polygons into Coplanar Sets",
  booktitle =    "Graphics Gems III",
  editor =       "David Kirk",
  publisher =    "Academic Press",
  address =      "San Diego",
  month =        jul,
  year =         "1992",
  abstract = 	"",
}

@InCollection{Tampieri:1992:NMCa,
  author =       "Filippo Tampieri",
  title =        "Newell's Method for Computing the Planar Equation
                 of a Polygon",
  booktitle =    "Graphics Gems III",
  editor =       "David Kirk",
  publisher =    "Academic Press",
  address =      "San Diego",
  month =        jul,
  year =         "1992",
  abstract = 	"",
}

@InCollection{Trumbore:1992:RBV,
  author =       "Ben Trumbore",
  title =        "Rectangular Bounding Volumes for Popular Primitives",
  booktitle =    "Graphics Gems III",
  editor =       "David Kirk",
  publisher =    "Academic Press",
  address =      "San Diego",
  month =        jul,
  year =         "1992",
  abstract = 	"",
}

@Article{Wanger:1992:PSR,
  author =       "Leonard R. Wanger and James A. Ferwerda and Donald
                 P. Greenberg",
  title =        "Perceiving Spatial Relationships in Computer-Generated
                 Images",
  journal =      "IEEE Computer Graphics and Applications",
  month =        may,
  year =         "1992",
  abstract = 	"The perception of spatial relations in computer generated 
		images was studied in three psychophysical experiments.
		In each experiment, the accuracy with which subjects were 
		able to perform interactive spatial manipulation tasks
		was measured while visual cues for spatial relations were 
		varied. Three tasks (positioning, orienting, and size
		scaling) and six cues (projection, relative motion, shadow, 
		object texture, ground texture, and elevation) were
		studied. Results indicate that in the positioning task 
		where spatial location information is needed, shadow and
		perspective projection cues greatly increase performance 
		accuracy. In the orient ing task where spatial location is
		unimportant but relative alignment information is needed, 
		orthographic projection and motion cues have substantial
		positive effects on performance accuracy. Finally, in the 
		size scaling task where both spatial location and
		object-relative size information is needed, interactions 
		between combinations of the above-mentioned cues have
		the greatest effect on performance accuracy. The experiments 
		suggest that knowledge of the task-at-hand should
		be taken into account in deciding what visual cues should 
		be included in a image. These results have implications
		for those concerned with three-dimensional interactive 
		computer graphics, from designers of geometric modeling
		and visualization software to hardware engineers implementing 
		rendering algorithms for graphics workstations. ",
}

@Article{Westin:1992:PRFa,
  author =       "Stephen H. Westin and James R. Arvo and Kenneth E.
                 Torrance",
  title =        "Predicting Reflectance Functions From Complex Surfaces",
  journal =      "Computer Graphics (SIGGRAPH '92 Proceedings)",
  conference =   "held in Chicago, Illinois; 26--31 July 1992",
  editor =       "Edwin E. Catmull",
  volume =       "26",
  month =        jul,
  year =         "1992",
  pages =        "255--264",
  keywords =     "monte carlo, shading",
  abstract =     "We describe a physically-based Monte Carlo technique
                 for approximating bi-directional reflectance distribution
                 functions (BRDFs) for a large class of geometries
                 by directly simulating optical scattering. The technique
                 is more general than previous analytical models: it
                 removes most restrictions on surface microgeometry.
                 Three main points are described: a new representation
                 of the BRDF, a Monte Carlo technique to estimate the
                 coefficients of the representation, and the means
                 of creating a milliscale BRDF from microscale scattering
                 events. These allow the prediction of scattering from
                 essentially arbitrary roughness geometries. The BRDF
                 is concisely represented by a matrix of spherical
                 harmonic coefficients; the matrix is directly estimated
                 from a geometric optics simulation, enforcing exact
                 reciprocity. The method applies to roughness scales
                 that are large with respect to the wavelength of light
                 and small with respect to the spatial density at which
                 the BRDF is sampled across the surface; examples include
                 brushed metal and textiles. The method is validated
                 by comparing with an existing scattering model and
                 sample images are generated with a physically-based
                 global illumination algorithm.",
}

@MastersThesis{Westin:1992:PRFb,
  author =       "Stephen H. Westin",
  title =        "Predicting Reflectance Functions from Complex Surfaces",
  school =       "Cornell University",
  year =         "1992",
}

@MastersThesis{Zatz:1992:GRA,
  author =       "Harold R. Zatz",
  title =        "Galerkin Radiosity: A Higher Order Solution Method
                 for Global Illumination",
  school =       "Cornell University",
  year =         "1992",
}

@Article{Lischinski:1992:DMA,
  author =       "Dani Lischinski and Filippo Tampieri and Donald P. Greenberg",
  title =        "Discontinuity meshing for accurate radiosity",
  journal =      "IEEE Computer Graphics and Applications",
  month =        "November",
  year =         "1992",
  pages = 	"25--39",
  volume = 	"12(6)",
  abstract = 	"We discuss the problem of accurately computing the 
		illumination of a diffuse polyhedral environment due to an 
		area light source. We show how umbra and penumbra boundaries 
		and other illumination details correspond to discontinuities 
		in the radiance function and its derivatives. The shape, 
		location, and order of these discontinuities is determined by 
		the geometry of the light sources and obstacles in the 
		environment. We describe an object-space algorithm that 
		accurately reproduces the radiance across a surface by 
		constructing a discontinuity mesh that explicitly represents 
		various discontinuities in the radiance function as 
		boundaries between mesh elements. A piecewise quadratic 
		interpolant is used to approximate the radiance function, 
		preserving the discontinuities associated with the edges in 
		the mesh. This algorithm can be used in the framework of a 
		progressive refinement radiosity system to solve the diffuse 
		global illumination problem. Results produced by the new 
		method are compared with ones obtained using a 
		standard radiosity system.",
}
		

@InCollection{Bussan:1993:ACC,
  author =       "Mimi Bussan and Roy Hall",
  title =        "Abstraction, Context and Constraint",
  booktitle =    "State of the Art in Computer Graphics",
  publisher =    "Springer-Verlag",
  address =      "New York",
  year =         "1993",
  abstract = 	"The design process and the assembly of thousands of 
		components can only be supported by systems that use a
		variety of presentational abstractions to reduce screen 
		complexity.  Reduction of screen complexity is required to
		allow the designer to focus on important detail, provide 
		uncluttered overviews, reveal relationships, and facilitate
		interactive manipulation.  Providing a wide selection of 
		presentational abstractions to reduce screen complexity
		introduces a specification, management, and control 
		challenge and often has the side effect of hiding features and
		context that are necessary in specifying or visualizing 
		interrelationships.  We explore strategies for managing
		abstraction, context, and constraint to minimize ambiguity 
		in interaction and presentation.",
}

@PhdThesis{Dorsey:1993:CGT,
  author =       "Julie O'Brien Dorsey",
  title =        "Computer Graphics Techniques for Opera Lighting Design
                 and Simulation",
  school =       "Cornell University",
  year =         "1993",
}

@Article{Georgiades:1993:EGB,
  author =       "Priamos N. Georgiades",
  title =        "Using Graphs of Bivariate Functions to locally
		 Represent and Modify Surfaces",
  journal =      "Computer Aided Geometric Design",
  volume =       "10",
  year =         "1993",
  pages =        "453--463",
  keywords =     "surfaces, graph functions, differential geometry,
		 intrinsic geometry",
  abstract =     "This article develops methods for locally representing and
		 manipulating curved surfaces as graphs of scalar algebraic
		 functions in two variables.  Based on two propositions, one
		 from differential geometry and one from algebraic geometry,
		 any surface can be approximated and locally represented as
		 such a function.  This representation offers many advantages
		 in terms of its display in computer graphics, the evaluation
		 of its geometric properties and the calculation of
		 intersections with lines and other surfaces.  One can locally
		 manipulate the surface, using its intrinsic geometric
		 measures as well as other external constraints.  The
		 formulation is extremely fast and allows interactive surface
		 manipulation and display to occur in real or close-to-real
		 time.",
}

@PhdThesis{He:1993:PBM,
  author =       "Xiao Dong He",
  title =        "Physically-Based Models for the Reflection, Transmission
                 and Subsurface Scattering of Light by Smooth and Rough
                 Surfaces, with Applications to Realistic Image Synthesis",
  school =       "Cornell University",
  year =         "1993",
}

@MastersThesis{Monks:1993:FDP,
  author =       "Michael C. Monks",
  title =        "Facilitating Design with Parametric Construction Methods",
  school =       "Cornell University",
  year =         "1993",
}

@PhdThesis{Novins:1993:TAE,
  author =       "Kevin L. Novins",
  title =        "Towards Accurate and Efficient Volume Rendering",
  school =       "Cornell University",
  year =         "1993",
  abstract =     "This thesis is concerned with improvements to algorithms for
		 volume rendering; a technique that provides scientists with
		 the means for visual exploration of three-dimensional data.
		 Despite its numerous successes, and its increasing use within
		 the scientific community, state-of-the-art volume rendering
		 algorithms have many shortcomings. Difficulties include:
		 ensuring the accuracy of the rendered images, producing
		 images with modest computational resources, and rendering the
		 diverse types of data that are currently being produced. 

		 The work in this thesis was motivated by the demands of an
		 ongoing visualization project in four-dimensional cardiac
		 visualization. We present solutions to some key problems in
		 ensuring accuracy and in producing algorithms that can scale
		 to handle large datasets. Although the theoretical work in
		 this thesis applies to arbitrary data topologies, our
		 implementations have assumed that the data is defined by
		 sample points on a regular rectilinear grid. 

		 In the area of accuracy, we focus on the error that is
		 introduced during volume projection. This phase of the
		 volume rendering process involves the evaluation of the
		 emission-absorption volume rendering line integral. This
		 thesis presents four techniques for controlled precision
		 volume integration. These schema depart from existing
		 approaches in that they provide error bounds along with the
		 solutions they generate. In each case, the error analysis
		 leads to an algorithm for evaluating the integral to any
		 specified tolerance. 

		 Our investigations into efficiency issues have resulted in
		 two advances.  First, an adaptive error bracketing scheme is
		 presented that builds on the controlled precision volume
		 integration methods. Using adaptive error bracketing, the
		 solution for a viewing ray is continually refined until a
		 user-specified error tolerance is met. The algorithm allows
		 processing of the data without imposing a strict front-to-back
		 or back-to-front evaluation order. Second, a suite of tools
		 are presented that can be used to efficiently compute
		 perspective projections of volume data. These include a
		 paging strategy that is useful when a dataset is too large to
		 fit into RAM memory and a ray splitting technique for adaptive
		 supersampling. The latter technique ensures that all data
		 features contribute to the final image while avoiding
		 overcomputation in regions close to the eyepoint.",
}

@MastersThesis{Pasetto:1993:BMH,
  author =       "Richard S. Pasetto",
  title =        "A Biomechanical Model of Human Skin Using Finite
                 Element Analysis",
  school =       "Cornell University",
  year =         "1993",
}

@Article{Pruyn:1993:ECG,
  author =       "Peter W. Pruyn and Donald P. Greenberg",
  title =        "Exploring 3{D} Computer Graphics in Cockpit Avionics",
  journal =      "IEEE Computer Graphics and Applications",
  volume =       "13",
  number =       "3",
  month =        may,
  year =         "1993",
  pages =        "28--35",
  keywords =     "information representation",
  abstract =     "A system that uses 3-D computer graphics to integrate 
		and visualize flight information and to encode navigational
		information of the objects of a 3-D scene is described. 
		The computer-generated views of geographic features,
		weather information, and air traffic used in the system 
		are discussed. The system's support of instrument approach
		technology is also discussed. A number of design notions 
		that have come out of this work, are reviewed. ",
}

@InProceedings{Schoeneman:1993:PL,
  author =       "Chris Schoeneman and Julie Dorsey and Brian Smits
                 and James Arvo and Donald Greenberg",
  title =        "Painting with Light",
  booktitle =    "SIGGRAPH 93 Conference Proceedings",
  conference =   "held in Anaheim, California; August 1--6, 1993",
  editor =       "James T. Kajiya",
  organization = "ACM SIGGRAPH",
  publisher =    "ACM Press",
  series =       "Computer Graphics Proceedings, Annual Conference Series",
  month =        aug,
  year =         "1993",
  pages =        "143--146",
  keywords =     "simulation, global illumination, radiosity, ray tracing,
                 light design, inverse problems",
  abstract =     "We present a new approach to lighting design for
                 image synthesis. It is based on the inverse problem
                 of determining light settings for an environment from
                 a description of the desired solution. The method
                 is useful for determining light intensities to achieve
                 a desired effect in a computer simulation and can
                 be used in conjunction with any rendering algorithm.
                 Given a set of lights with fixed positions, we determine
                 the light intensities and colors that most closely
                 match the target image painted by the designer using
                 a constrained least squares approach. We describe
                 an interactive system that allows exible input and
                 display of the solution.",
}

@InProceedings{Tampieri:1993:CHR,
  author =       "Dani Lischinski and Filippo Tampieri and Donald P. Greenberg",
  title =        "Combining Hierarchical Radiosity and Discontinuity Meshing",
  booktitle =    "SIGGRAPH 93 Conference Proceedings",
  conference =   "held in Anaheim, California; August 1--6, 1993",
  editor =       "James T. Kajiya",
  organization = "ACM SIGGRAPH",
  publisher =    "ACM Press",
  series =       "Computer Graphics Proceedings, Annual Conference Series",
  month =        aug,
  year =         "1993",
  pages =        "199--208",
  abstract = 	"We introduce a new approach for the computation of view 
		independent solutions to the diffuse global illumination
		problem in polyhedral environments. The approach combines 
		ideas from hierarchical radiosity and discontinuity
		meshing to yield solutions that are accurate both numerically 
		and visually. First, we describe a modified hierarchical
		radiosity algorithm that uses a discontinuity driven 
		subdivision strategy to achieve better numerical accuracy and
		faster convergence. Second, we present a new algorithm based 
		on discontinuity meshing that uses the hierarchical
		solution to reconstruct an object-space approximation to the 
		radiance function that is visually accurate. Our results
		show significant improvements over both hierarchical 
		radiosity and discontinuity meshing algorithms.",
}

@PhdThesis{Tampieri:1993:DMRb,
  author =       "Filippo Tampieri",
  title =        "Discontinuity Meshing for Radiosity Image Synthesis",
  school =       "Cornell University",
  year =         "1993",
  abstract =     "The simulation of global illumination is one of the most
		 fundamental problems in computer graphics, with applications
		 is a wide variety of areas. This problem studies the light
		 energy transfer between reflective surfaces in an environment.
		 Initially derived from the field of thermal engineering,
		 radiosity has emerged over the past several years as one of
		 the most promising solution methods.  Despite having produced
		 some of the most realistic-looking computer generated images
		 to date, radiosity methods have not yet met with widespread
		 acceptance. The main obstacle has been their need for very
		 careful and time consuming user intervention, without which,
		 current techniques are prone to generating a wide range of
		 annoying visual artifacts. These artifacts are generally due
		 to poor surface meshing, resulting in insufficient sampling
		 density and ineffective sample placement. This thesis
		 investigates the roots of this problem by taking a step back
		 from the traditional finite element formulation of radiosity
		 and examining the more general integral equation formulation.
		 An analysis of the radiance functions described by this
		 equation shows how umbra and penumbra boundaries as well as
		 other sharp changes in illumination actually correspond to
		 discontinuities in the radiance function and its derivatives.
		 The results of this analysis have led to the concept of
		 discontinuity meshing, whereby accurate approximations to the
		 radiance functions are computed by explicitly representing
		 their discontinuities as boundaries in the mesh. This concept
		 has been applied to the design of a discontinuity meshing
		 algorithm for polyhedral environments. The algorithm is
		 embedded in a progressive refinement radiosity system and
		 uses piecewise quadratic interpolation to reconstruct a
		 smooth radiance function while preserving discontinuities
		 where appropriate. The radiosity solutions produced by the
		 new algorithm are compared against a photograph of a physical
		 environment, an analytical solution, and a conventional, yet
		 state-of-the-art, radiosity system, and its performance on
		 architectural models of medium complexity is measured. The
		 results are remarkably accurate both numerically and visually.
		 The new discontinuity meshing algorithm drastically reduces,
		 and in many cases eliminates, many of the annoying artifacts
		 typical of conventional radiosity meshes, producing images of
		 previously unattained quality. Moreover, the meshing is
		 completely automatic and produces solutions that are highly
		 view-independent.",
}

@InProceedings{Zatz:1993:GRHb,
  author =       "Harold R. Zatz",
  title =        "Galerkin Radiosity: {A} Higher Order Solution Method
                 for Global Illumination",
  booktitle =    "SIGGRAPH 93 Conference Proceedings",
  conference =   "held in Anaheim, California; August 1--6, 1993",
  editor =       "James T. Kajiya",
  organization = "ACM SIGGRAPH",
  publisher =    "ACM Press",
  series =       "Computer Graphics Proceedings, Annual Conference Series",
  month =        aug,
  year =         "1993",
  pages =        "213--220",
  keywords =     "global illumination, radiosity, integral equations,
                 Galerkin methods, curved surfaces, progressive refinement",
  abstract =     "This paper presents an alternative radiosity formulation
                 using piecewise smooth radiance functions that incorporates
                 curved surfaces directly. Using the Galerkin integral
                 equation technique as a mathematical foundation, surface
                 radiance functions are approximated by polynomials.
                 This model eliminates the need for a posteriori rendering
                 interpolation, and allows the direct use of non-planar
                 parametric surfaces. Convergence problems due to singularities
                 in the radiosity kernel are analyzed and rectified,
                 and sources of approximation error are examined. The
                 incorporation of a shadow masking technique vastly
                 reduces the need for meshing and associated storage
                 space-accurate radiosity calculations can often be
                 made with no meshing. The technique is demonstrated
                 on traditional radiosity scenes, as well as environments
                 with untessellated curved surfaces.",
}

@TechReport{Arvo:1994:FAEa,
  author =       "James Arvo and Kenneth E. Torrance and Brian Smits",
  title =        "A Framework for the Analysis of Error in Global Illumination
                 Algorithms",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-94-1",
  month =        jan,
  year =         "1994",
}

@InProceedings{Arvo:1994:FAEb,
  author =       "James Arvo and Kenneth Torrance and Brian Smits",
  title =        "A Framework for the Analysis of Error in Global Illumination
                 Algorithms",
  booktitle =    "SIGGRAPH 94 Conference Proceedings",
  conference =   "held in Orlando, Florida; July 24--29, 1994",
  editor =       "Andrew Glassner",
  organization = "ACM SIGGRAPH",
  publisher =    "ACM Press",
  series =       "Computer Graphics Proceedings, Annual Conference
                 Series",
  month =        jul,
  year =         "1994",
  pages =        "75--84",
  notes =        "ISBN 0-89791-667-0",
  bibsource =    "sig-11-1994",
  abstract =     "In this paper we identify sources of error in global
		 illumination algorithms and derive bounds for each distinct
		 category. Errors arise from three sources: inaccuracies in
		 the boundary data, discretization, and computation. Boundary
		 data consist of surface geometry, reflectance functions, and
		 emission functions, all of which may be perturbed by errors
		 in measurement or simulation, or by simplifications made for
		 computational efficiency. Discretization error is introduced
		 by replacing the continuous radiative transfer equation with
		 a finite-dimensional linear system, usually by means of
		 boundary elements and a corresponding projection method.
		 Finally, computational errors perturb the finite-dimensional
		 linear system through imprecise form factors, inner products,
		 visibility, etc., as well as by halting iterative solvers
		 after a finite number of steps. Using the error taxonomy
		 introduced in the paper we examine existing global
		 illumination algorithms and suggest new avenues of research.",
}

@MastersThesis{Shaw:1994:HRD,
  author =       "Erin Shaw",
  title =        "Hierarchical Radiosity for Dynamic Environments",
  school =       "Cornell University",
  year =         "1994",
}

@InProceedings{Arvo:1994:ICV,
  author =       "James Arvo and Kevin Novins",
  title =        "{Iso-Contour} Volume Rendering",
  booktitle =    "1994 Symposium on Volume Visualization",
  editor =       "Arie Kaufman and Wolfgang Krueger",
  organization = "ACM SIGGRAPH",
  month =        oct,
  year =         "1994",
  pages =        "115--122",
  notes =        "ISBN 0-89791-741-3",
  abstract =     "In this paper we present a new approach to volume rendering
		 in which curves of constant intensity in image space, or
		 iso-contours, are computed directly for each view. The
		 generated iso-contours can be used to drive various
		 visualization and feature-detection algorithms. The approach
		 imposes no restriction on the organization of the data points
		 and can accommodate a large class of radially-symmetric
		 filter functions. The technique works well for both
		 perspective and orthographic viewing projections. Each
		 iso-contour is defined by an ordinary differential equation,
		 which is solved numerically using a predictor-corrector
		 method.  A key element of the algorithm is the use of image
		 intensity gradients, which we compute by means of a
		 closed-form expression that holds at every point in the
		 image plane. A caching algorithm is described that
		 dramatically accelerates the gradient computations on
		 large datasets. The algorithm is demonstrated on
		 emission-only datasets. We conclude by describing a number
		 of possible enhancements.",
}

@InProceedings{Arvo:1994:IJP,
  author =       "James Arvo",
  title =        "The Irradiance {J}acobian for Partially Occluded
                 Polyhedral Sources",
  booktitle =    "SIGGRAPH 94 Conference Proceedings",
  conference =   "held in Orlando, Florida; July 24--29, 1994",
  editor =       "Andrew Glassner",
  organization = "ACM SIGGRAPH",
  publisher =    "ACM Press",
  series =       "Computer Graphics Proceedings, Annual Conference
                 Series",
  month =        jul,
  year =         "1994",
  pages =        "343--350",
  keywords =     "irradiance gradient, irradiance Jacobian, isolux
                 contours, light field, mesh generation, vector irradiance",
  notes =        "ISBN 0-89791-667-0",
  bibsource =    "sig-11-1994",
  abstract =     "The irradiance at a point on a surface due to a polyhedral
		 source of uniform brightness has a well-known analytic
		 formula. In this paper we derive the corresponding analytic
		 expression for the irradiance Jacobian, the derivative of the
		 vector representation of irradiance. Although the result is
		 elementary for unoccluded sources, within penumbrae the
		 irradiance Jacobian must incorporate more information about
		 blockers than either the irradiance or vector irradiance. The
		 expression presented here holds for any number of polyhedral
		 blockers and requires only a minor extension of standard
		 polygon clipping to evaluate. To illustrate its use, three
		 related applications are briefly described: direct
		 computation of isolux contours, finding local irradiance
		 extrema, and iso-meshing. Isolux contours are curves of
		 constant irradiance across a surface that can be followed
		 using a predictor-corrector method based on the irradiance
		 Jacobian. Similarly, local extrema can be found using a
		 descent method. Finally, iso-meshing is a new approach to
		 surface mesh generation that incorporates families of
		 isolux contours.",
}

@InProceedings{Durkin:1994:NIR,
  author =       "James W. Durkin and John F. Hughes",
  title =        "Nonpolygonal Isosurface Rendering for Large Volume
                 Data Sets",
  booktitle =    "Proceedings of Visualization '94",
  editor =       "R. Daniel Bergeron and Arie E. Kaufman",
  organization = "IEEE",
  month =        oct,
  year =         "1994",
  pages =        "293--300",
  abstract = 	"Surface-based rendering techniques, particularly those 
		that extract a polygonal approximation of an isosurface, are
		widely used in volume visualization. As dataset size increases 
		though, the computational demands of these methods
		can overwhelm typically available computing resources. 
		Recent work on accelerating such techniques has
		focused on preprocessing the volume data or postprocessing 
		the extracted polygonization. Our new algorithm
		concentrates instead on streamlining the surface extraction
		 process itself so as to accelerate the rendering of large
		volumes. The technique shortens the conventional isosurface 
		visualization pipeline by eliminating the intermediate
		polygonization. We compute the contribution of the 
		isosurface within a volume cell to the resulting image directly
		from a simplified numerical description of the cell/surface 
		intersection. Our approach also reduces the work in the
		remaining stages of the visualization process. By 
		quantizing the volume data, we exploit precomputed and cached
		data at key processing steps to improve rendering efficiency. 
		The resulting implementation provides comparatively
		fast renderings with reasonable image quality.",
}

@PhdThesis{Lischinski:1994:ARA,
  author =       "Daniel Lischinski",
  title =        "Accurate and Reliable Algorithms for Global Illumination",
  school =       "Cornell University",
  year =         "1994",
  abstract =     "The simulation of global illumination is one of the most
		 fundamental problems in computer graphics, with applications
		 in a wide variety of areas, such as architecture and lighting
		 design, computer-aided design, and virtual reality. This
		 problem concerns the transport of light energy between
		 reflective surfaces in an environment.  During the past
		 decade, radiosity has become the method of choice for
		 simulating global illumination in diffuse environments.
		 Despite much recent progress in efficiency and applicability
		 of radiosity methods, there are several very important open
		 issues remaining: 1) Radiosity images suffer from many visual
		 artifacts, resulting from lack of reliable automatic
		 discretization algorithms; and 2) Current radiosity
		 algorithms do not provide the user with guaranteed bounds or
		 reliable estimates of the approximation errors. As a result,
		 current radiosity systems require very careful and
		 time-consuming user intervention in the discretization
		 process, and the accuracy of the resulting solutions can only
		 be assessed by visual appearance. This thesis presents new
		 radiosity algorithms for diffuse polyhedral environments that
		 address the open problems mentioned above. First, we have
		 improved and combined together two recently developed
		 radiosity approaches: hierarchical radiosity and discontinuity
		 meshing. An improved hierarchical radiosity algorithm that is
		 based on a discontinuity-driven subdivision strategy to
		 achieve better numerical accuracy and faster convergence is
		 used to compute the global distribution of light energy in an
		 environment. Then, a new algorithm based on discontinuity
		 meshing uses the hierarchical solution to reconstruct a
		 visually accurate approximation to the radiance function.
		 Thus, results of high visual quality can be obtained even
		 from coarse global illumination simulations. The solution is
		 performed entirely in object-space, which enables users to
		 walk through high-fidelity shaded virtual environments in
		 real time, using appropriate display hardware. Second, we
		 have developed algorithms that compute a posteriori error
		 bounds and estimates for local and total errors in
		 hierarchical radiosity solutions. A conservative algorithm
		 computes guaranteed upper bounds on the errors. A
		 non-conservative algorithm is capable of computing more
		 realistic error estimates more efficiently. These error
		 estimates are used in a new error-driven refinement strategy
		 for hierarchical radiosity, resulting in faster convergence.",
}

@InProceedings{Lischinski:1994:BEE,
  author =       "Dani Lischinski and Brian Smits and Donald P. Greenberg",
  title =        "Bounds and Error Estimates for Radiosity",
  booktitle =    "SIGGRAPH 94 Conference Proceedings",
  conference =   "held in Orlando, Florida; July 24--29, 1994",
  editor =       "Andrew Glassner",
  organization = "ACM SIGGRAPH",
  publisher =    "ACM Press",
  series =       "Computer Graphics Proceedings, Annual Conference Series",
  month =        jul,
  year =         "1994",
  pages =        "67--74",
  notes =        "ISBN 0-89791-667-0",
  bibsource =    "sig-11-1994",
  abstract = 	"We present a method for determining a posteriori bounds and 
		es timates for local and total errors in radiosity
		solutions. The ability to obtain bounds and estimates for the 
		total error is crucial for reliably judging the
		acceptability of a solution. Realistic estimates of the local 
		error improve the efficiency of adaptive radiosity 
		algo\xad rithms, such as hierarchical radiosity, by 
		indicating where adaptive refinement is necessary. 
		First, we describe a hierarchical radiosity algorithm that 
		com putes conservative lower and upper bounds on the
		exact radiosity function, as well as on the approximate 
		solution. These bounds account for the propagation of
		errors due to interreflections, and provide a conservative 
		upper bound on the error. We also describe a
		nonconservative version of the same algorithm that is 
		capable of computing tighter bounds, from which more
		realistic error estimates can be obtained. Finally, we 
		derive an expression for the effect of a particular interaction
		on the total error. This yields a new errordriven refinement 
		strategy for hierarchical radiosity, which is shown to be
		superior to brightnessweighted refinement. ",
}

@InProceedings{Marschner:1994:ERF,
  author =       "Stephen R. Marschner and Richard J. Lobb",
  title =        "An Evaluation of Reconstruction Filters for Volume
                 Rendering",
  booktitle =    "Proceedings of Visualization '94",
  editor =       "R. Daniel Bergeron and Arie E. Kaufman",
  organization = "IEEE",
  month =        oct,
  year =         "1994",
  pages =        "100--107",
  abstract =     "To render images from a three-dimensional array of
                 sample values, it is necessary to interpolate between
                 the samples. This paper is concerned with interpolation
                 methods that are equivalent to convolving the samples
                 with a reconstruction filter; this covers all commonly
                 used schemes, including trilinear and cubic interpolation.
                 We first outline the formal basis of interpolation
                 in three-dimensional signal processing theory. We
                 then propose numerical metrics that can be used to
                 measure filter characteristics that are relevant to
                 the appearance of images generated using that filter.
                 We apply those metrics to several previously used
                 filters and relate the results to isosurface images
                 of the interpolations. We show that the choice of
                 interpolation scheme can have a dramatic effect on
                 image quality, and we discuss the cost/benefit tradeoff
                 inherent in choosing a filter.",
}

@MastersThesis{Schoeneman:1994:SFU,
  author =       "Christopher R. Schoeneman",
  title =        "A Software Framework for User Interface Design",
  school =       "Cornell University",
  year =         "1994",
}

@InProceedings{Smits:1994:CAR,
  author =       "Brian Smits and James Arvo and Donald Greenberg",
  title =        "A Clustering Algorithm for Radiosity in Complex Environments",
  booktitle =    "SIGGRAPH 94 Conference Proceedings",
  conference =   "held in Orlando, Florida; July 24--29, 1994",
  editor =       "Andrew Glassner",
  organization = "ACM SIGGRAPH",
  publisher =    "ACM Press",
  series =       "Computer Graphics Proceedings, Annual Conference
                 Series",
  month =        jul,
  year =         "1994",
  pages =        "435--442",
  notes =        "ISBN 0-89791-667-0",
  bibsource =    "sig-11-1994",
  abstract =     "We present an approach for accelerating hierarchical
		 radiosity by clustering objects. Previous approaches
		 constructed effective hierarchies by subdividing surfaces,
		 but could not exploit a hierarchical grouping on existing
		 surfaces. This limitation resulted in an excessive number of
		 initial links in complex environments. Initial linking is
		 potentially the most expensive portion of hierarchical
		 radiosity algorithms, and constrains the complexity of
		 environments that can be simulated. The clustering algorithm
		 presented here operates by estimating energy transfers
		 between collections of objects while maintaining reliable
		 error bounds on each transfer. Two methods of bounding the
		 transfers are employed with different tradeoffs between
		 accuracy and time. In contrast with the O(s2) time and space
		 complexity of the initial linking in previous hierarchical
		 radiosity algorithms, the new methods have complexities of
		 O(s log s) and O(s) for both time and space.  Using these
		 methods we have obtained speedups of two orders of magnitude
		 for environments of moderate complexity while maintaining
		 comparable accuracy.",
}

@PhdThesis{Smits:1994:EHR,
  author =       "Brian Edward Smits",
  title =        "Efficient Hierarchical Radiosity in Complex Environments",
  school =       "Cornell University",
  year =         "1994",
  abstract =     "This thesis presents methods for speeding up the global
		 illumination computations by using bounds on error to
		 eliminate work that is not needed for a solution of a given
		 accuracy. This work makes the hieerarchical radiosity approach
		 feasible for complex environments. First, a new radiosity
		 algorithm for efficiently computing global solutions with
		 respect to a constrained set of views is presented.
		 Radiosities of directly visible surfaces are computed to high
		 acccuracy, while those of surfaces having only an indirect
		 effect are computed to an accuracy commensurate with their
		 contribution. The algorithm uses an adaptive subdivision
		 scheme that is guided by the interplay between two closely
		 related transport processes: one propagating power from the
		 light sources, and the other propagating importance from the
		 visible surfaces. By simultaneously refining approximate
		 solutions to the dual transport equations, computation is
		 significantly reduced in areas that contribute little to the
		 region of interest. This approach is very effective for
		 complex environments in which only a small fraction is
		 visible at any time. Our statistics show dramatic speedups
		 over the fastest previous radiosity algorithms for diffuse
		 environments with details at a wide range of scales. A new
		 approach for accelerating hierarchical radiosity by
		 clustering objects is also presented. Previous approaches
		 constructed effective hierarchies by subdividing surfaces,
		 but could not exploit a hierarchical grouping on existing
		 surfaces. This limitation resulted in an excessive number of
		 initial links in complex environments. Initial linking is
		 potentially the most expensive portion of hierarchical
		 radiosity algorithms, and constrains the complexity of the
		 environments that can be simulated. The clustering algorithm
		 presented here operates by estimating energy transfers
		 between collections of objects which maintaining reliable
		 error bounds on each transfer. Two methods of bounding the
		 transfers are employed with different tradeoffs between
		 accuracy and time. In contrast with the O(s^2) time and space
		 complexity of the initial linking in previous hierarchical
		 radiosity algorithms, the new methods have complexities of
		 O(s log s) and O(s) for both time and space. Using these
		 methods we have obtained speedups of two orders of magnitude
		 for environments of moderate complexity while maintaining
		 comparable accuracy. Finally, the thesis describes a method
		 for reconstructing the radiance functions across the visible
		 surfaces given a global solution to the energy balance
		 equations. This approach greatly reduces artifacts resulting
		 from the choice of constant basis functions used for the
		 global solution.",
}

@InProceedings{Tampieri:1994:CRA,
  author =       "Filippo Tampieri and Daniel Lischinski",
  title =        "The Constant Radiosity Assumption Syndrome",
  booktitle =    "Photorealistic Rendering in Computer Graphics (Proceedings
                 of the Second Eurographics Workshop on Rendering)",
  publisher =    "Springer-Verlag",
  address =      "New York",
  year =         "1994",
  pages =        "83--92",
  bibsource =    "sig-11-1994",
  abstract =     "In progressive refinement the radiosity of the shooting
                 patch is assumed to be constant. This is not correct.
                 It is better to take into account the variation of
                 the radiosity of the source. A progressive refinement
                 method is given that takes into account the non uniform
                 radiosity distribution of the shooting patch.",
}

@InProceedings{Arvo:1995:AIT,
  author =       "James Arvo",
  title =        "Applications of Irradiance Tensors to the Simulation
                 of Non-Lambertian Phenomena",
  booktitle =    "SIGGRAPH 95 Conference Proceedings",
  conference =   "held in Los Angeles, California; 6--11 August 1995",
  editor =       "Robert Cook",
  organization = "ACM SIGGRAPH",
  publisher =    "Addison Wesley",
  series =       "Annual Conference Series",
  month =        "Aug",
  year =         "1995",
  pages =        "335--342",
  abstract =     "We present new techniques for computing illumination from
		 non-diffuse luminaires and scattering from non-diffuse
		 surfaces. The methods are based on new closed-form
		 expressions derived using a generalization of irradiance
		 known as irradiance tensors. The elements of these tensors
		 are angular moments, weighted integrals of the radiation
		 field that are useful in simulating a variety of non-diffuse
		 phenomena. Applications include the computation of irradiance
		 due to directionally-varying area light sources, reflections
		 from glossy surfaces, and transmission through glossy
		 surfaces. The principles apply to any emission, reflection,
		 or transmission distribution expressed as a polynomial over
		 the unit sphere. We derive expressions for a simple but
		 versatile subclass of these functions, called axial moments,
		 and present complete algorithms their exact evaluation in
		 polyhedral environments. The algorithms are demonstrated by
		 simulating Phong-like emission and scattering effects.",
}

@InProceedings{Arvo:1995:RFA,
  author =       "James Arvo",
  title =        "The Role of Functional Analysis in Global Illumination",
  booktitle =    "Rendering Techniques '95",
  conference =   "Proceedings of the 6th Eurographics Workshop on Rendering,
                 held in Dublin, Ireland; June 12--14, 1995",
  editor =       "P. M. Hanrahan and Werner Purgathofer",
  organization = "Eurographics",
  publisher =    "Springer-Verlag",
  month =        jun,
  year =         "1995",
  abstract =     "The problem of global illumination is virtually synonymous
		 with solving the rendering equation. Although a great deal of
		 research has been directed toward Monte Carlo and finite
		 element methods for solving the rendering equation, little
		 is known about the continuous equation beyond the existence
		 and uniqueness of its solution. The continuous problem may be
		 posed in terms of linear operators acting on
		 infinite-dimensional function spaces. Such operators are
		 fundamentally different from their finite-dimensional
		 counterparts, and are properly studied using the methods of
		 functional analysis. This paper summarizes some of the basic
		 concepts of functional analysis and shows how these concepts
		 may be applied to a linear operator formulation of the
		 rendering equation. In particular, operator norms are
		 obtained from thermodynamic principles, and a number of
		 common function spaces are shown to be closed under global
		 illumination. Finally, several fundamental operators that
		 arise in global illumination are shown to be nearly
		 finite-dimensional in that they can be uniformly
		 approximated by matrices.",
}

@InProceedings{Arvo:1995:SSS,
  author =       "James Arvo",
  title =        "Stratified Sampling of Spherical Triangles",
  booktitle =    "SIGGRAPH 95 Conference Proceedings",
  conference =   "held in Los Angeles, California; 6--11 August 1995",
  editor =       "Robert Cook",
  organization = "ACM SIGGRAPH",
  publisher =    "Addison Wesley",
  series =       "Annual Conference Series",
  month =        aug,
  year =         "1995",
  pages =        "437--438",
  abstract =     "We present an algorithm for generating uniformly distributed
		 random samples from arbitrary spherical triangles. The
		 algorithm is based on a transformation of the unit square and
		 easily accommodates stratified sampling, an effective means
		 of reducing variance. With the new algorithm it is
		 straightforward to perform stratified sampling of the solid
		 angle subtended by an arbitrary polygon; this is a fundamental
		 operation in image synthesis which has not been addressed in
		 the Monte Carlo literature. We derive the required
		 transformation using elementary spherical trigonometry and
		 provide the complete sampling algorithm.",
}

@Article{Dorsey:1995:IDC,
  author =       "Julie Dorsey and James Arvo and Donald P. Greenberg",
  title =        "Interactive Design of Complex Time-Dependent Lighting",
  journal =      "IEEE Computer Graphics and Applications",
  volume =       "15",
  number =       "2",
  month =        mar,
  year =         "1995",
  pages =        "26--36",
  abstract =     "We describe new tools for the interactive design of complex,
		 time-dependent lighting in scenes with fixed geometry. The
		 work is motivated by the difficulty of visualizing
		 complicated lighting sequences during the design of
		 large-scale theatrical productions. Fast interaction is
		 achieved regardless of scene and lighting complexity, even
		 when used in conjunction with costly rendering techniques
		 such as radiosity and ray tracing. Time-variant lighting is
		 simulated using linear combinations of static images, each
		 depicting the scene under different lighting conditions.
		 Multiple levels of accuracy facilitate interactive design by
		 trading image quality for fast feedback in a controlled way.
		 Coarse approximations are used in the preliminary design
		 stage to allow for instantaneous feedback, then the sequence
		 is progressively refined by computing basis solutions in
		 order of increasing overall contribution. When changes to
		 the design are required, existing global solutions are
		 re-used to the greatest extent possible. The techniques are
		 demonstrated with complex models based on actual stage sets.",
}

@Article{Hubbard:1995:CDI,
  author =       "Philip M. Hubbard",
  title =        "Collision Detection for Interactive Graphics Applications",
  journal =      "IEEE Transactions on Visualization and Computer Graphics",
  volume =       "1",
  number =       "3",
  month =        sep,
  year =         "1995",
  pages =        "218--230",
  notes =        "ISSN 1077-2626",
  abstract = 	"Collision detection and response are important for 
		interactive graphics applications such as vehicle simulators and
		virtual reality. Unfortunately, previous collision-detection 
		algorithms are too slow for interactive use. This paper
		presents a new algorithm for rigid or articulated objects 
		that meets performance goals through a form of
		time-critical computing. The algorithm supports progressive 
		refinement, detecting collisions between successively
		tighter approximations to object surfaces as the application 
		allows it more processing time. The algorithm uses
		simple four-dimensional geometry to approximate motion, 
		and hierarchies of spheres to approximate
		three-dimensional surfaces at multiple resolutions. In a 
		sample application, the algorithm allows interactive
		performance that is not possible with a good previous 
		algorithm. In particular, the new algorithm provides
		acceptable accuracy while maintaining a steady and high frame 
		rate, which in some cases improves on the previous
		algorithm's rate by more than two orders of magnitude.",
}

@TechReport{Walter:1995:PB,
  author =       "Bruce Walter and Jed Lengyel",
  title =        "The Path-Buffer",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-95-4",
  year =         "1995",
}

@InProceedings{Lengyel:1995:TDR,
  author =       "Jed Lengyel and Donald P. Greenberg and A. Yeung
                 and E. Alderman and Richard Popp",
  title =        "Three-Dimensional Reconstruction and Volume Rendering
                 of Intravascular Ultrasound Slices Imaged on a Curved
                 Arterial Path",
  booktitle =    "Computer Vision, Virtual Reality and Robotics in Medicine",
  editor =       "Nicholas Ayache",
  publisher =    "Springer-Verlag",
  series =       "Lecture Notes in Computer Science",
  month =        apr,
  year =         "1995",
  notes =        "ISBN 3-540-59120-6",
}

@InProceedings{Lengyel:1995:TDT,
  author =       "Jed Lengyel and Donald P. Greenberg and Richard Popp",
  title =        "{Time-Dependent} {Three-Dimensional} Intravascular
                 Ultrasound",
  booktitle =    "SIGGRAPH 95 Conference Proceedings",
  conference =   "held in Los Angeles, California; 6--11 August 1995",
  editor =       "Robert Cook",
  organization = "ACM SIGGRAPH",
  publisher =    "Addison Wesley",
  series =       "Annual Conference Series",
  month =        aug,
  year =         "1995",
  pages =        "457--464",
  abstract = 	"Intravascular ultrasonography and x-ray angiography provide 
		two complimentary techniques for imaging the
		moving coronary arteries. We present a technique that 
		combines the strengths of both, by recovering the moving
		threedimensional arterial tree from a stereo pair of 
		angiograms through the use of compound-energy  snakes,
		placing the intravascular ultrasound slices at their proper 
		positions in time and space, and dynamically displaying the
		combined data.
		Past techniques have assumed that the ultrasound slices are 
		parallel and that the vessel being imaged is straight. 
		For the first time, by applying simple but effective 
		techniques from computer graphics, the moving geometry of the
		artery from the angiogram and the time-dependent images of 
		the interior of the vessel wall from the intravascular
		ultrasound can be viewed simultaneously, showing the proper 
		geometric and temporal relations of the slice data
		and the angiogram projections. By using texture-mapped 
		rectangles the combined ultrasound slice/angiogram
		display technique is well suited to run in real time 
		on current graphics workstations.",
}

@TechReport{Shirley:1995:COM,
  author =       "Peter Shirley and Bruce Walter",
  title =        "Cost Analysis of a Monte Carlo Radiosity Algorithm",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-95-3",
  year =         "1995",
}

@TechReport{Shirley:1995:DER,
  author =       "Peter Shirley and Bretton Wade and Philip M. Hubbard
                 and David Zareski and Bruce Walter and Donald P. Greenberg",
  title =        "Density Estimation Radiosity",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-95-2",
  year =         "1995",
}

@InProceedings{Shirley:1995:GID,
  author =       "Peter Shirley and Bretton Wade and Philip Hubbard
                 and David Zareski and Bruce Walter and Donald P. Greenberg",
  title =        "Global Illumination via Density Estimation",
  booktitle =    "Eurographics Rendering Workshop 1995",
  organization = "Eurographics",
  month =        jun,
  year =         "1995",
  abstract =     "This paper presents a new global-illumination algorithm
                 for highly complex static environments containing
                 both diffuse and non-diffuse surfaces. The algorithm
                 accounts for all types of surface reflection, accommodates
                 textured surfaces, and supports coarse-grained parallelism.
                 A key to this method is a novel decomposition of the
                 problem into a sequence of three loosely-coupled phases.
                 The first phase consists of Monte Carlo particle tracing
                 in which power-carrying particles are emitted from
                 each luminaire, and tracked through the environment
                 until they are absorbed. A list of particle ``hit
                 points'' is kept for each surface. In the second phase,
                 called the ``density-estimation'' phase, the stored
                 hit points are used to construct an approximate irradiance
                 function for each surface. In the final phase, called
                 the ``meshing'' phase, each surface irradiance function
                 is approximated by a piecewise-linear function. Display
                 output can be either Gouraud-shaded polygonal elements
                 for interactive walk-throughs, or ray-traced pixels
                 for higher-quality still frames. The method is modular,
                 relatively easy to implement, has low memory overhead,
                 and has produced view-independent display meshes for
                 models larger than the ones that have been processed
                 by previous methods. Such solutions could improve
                 the state-of-the-art in architectural simulations,
                 immersive environments, and other virtual reality
                 applications.",
}

@InProceedings{Spencer:1995:PBG,
  author =       "Greg Spencer and Peter Shirley and Kurt Zimmerman
                 and Donald P. Greenberg",
  title =        "Physically-Based Glare Effects for Digital Images",
  booktitle =    "SIGGRAPH 95 Conference Proceedings",
  conference =   "held in Los Angeles, California; 6--11 August 1995",
  editor =       "Robert Cook",
  organization = "ACM SIGGRAPH",
  publisher =    "Addison Wesley",
  series =       "Annual Conference Series",
  month =        aug,
  year =         "1995",
  pages =        "325--334",
  abstract = 	"The physical mechanisms and physiological causes of glare 
		in human vision are reviewed. These mechanisms are
		scattering in the cornea, lens, and retina, and diffraction 
		in the coherent cell structures on the outer radial areas of
		the lens. This scattering and diffraction are responsible 
		for the bloom and flare lines seen around very bright
		objects. The diffraction effects cause the lenticular halo. 
		The quantitative models of these glare effects are
		reviewed, and an algorithm for using these models to add 
		glare effects to digital images is presented. The resulting
		digital point-spread function is thus psychophysically based 
		and can substantially increase the perceived dynamic
		range of computer simulations containing light sources. 
		Finally, a perceptual test is presented that indicates these
		added glare effects increase the apparent brightness of 
		light sources in digital images.",
}

@TechReport{Torrance:1995:EAL,
  author =       "Sing-Choong Foo and Kenneth E. Torrance",
  title =        "Equipment Acquisition for the Light Measurement Laboratory
                 of the {C}ornell {P}rogram of {C}omputer {G}raphics",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-95-5",
  year =         "1995",
}

@InProceedings{Zareski:1995:EPG,
  author =       "David Zareski and Bretton Wade and Philip Hubbard
 		 and Peter Shirley",
  title =        "Efficient Parallel Global Illumination Using Density
                 Estimation",
  booktitle =    "Proceedings of Visualization '95 - Parallel Rendering
                 Symposium",
  conference =   "held in Atlanta, Georgia",
  month =        oct,
  year =         "1995",
  pages = 	"219--230",
  abstract =     "This paper presents a multi-computer, parallel version
                 of the recently-proposed ``Density Estimation'' (DE)
                 global illumination method, designed for computing
                 solutions of environments with high geometric complexity
                 (as many as hundreds of thousands of initial surfaces).
                 In addition to the diffuse inter-reflections commonly
                 handled by conventional radiosity methods, this new
                 method can also handle energy transport involving
                 arbitrary non-diffuse surfaces. Output can either
                 be Gouraud-shaded elements for interactive walkthroughs,
                 or ray-traced images for higher quality still frames.
                 The key difference of the DE algorithm from conventional
                 radiosity, in terms of its ability to parallelize
                 efficiently, is its microscopic view of energy transport,
                 which avoids the O(n*n) pairwise surface interactions
                 of most previous macroscopic radiosity algorithms
                 (i.e., those without clustering). Parallel DE is implemented
                 as two separate parallel programs which perform different
                 phases of the DE method. The first program performs
                 the particle-tracing phase, and the second performs
                 the density-estimation and meshing phases. Each parallel
                 program consists of a single master task and multiple
                 worker tasks executing on separate workstations connected
                 over a local area network. Communication is performed
                 using the PVM software package and a shared file system.
                 The goal of this effort is to provide a near-linear
                 speedup for solutions to existing environment models
                 using tens of processors. The parallel efficiency
                 of the first program has been measured to be above
                 90\% for as many as 16 workers, and the parallel efficiency
                 of the second program has been measured to be above
                 70\% for as many as 12 workers.",
}

@TechReport{Wangpattanasirikul:1995:UGO,
  author =       "Kenneth E Torrance and Suithipong Wangpattanasirikul and Sing-Choong Foo",
  title =        "A User's Guide to the OL750 Spectral Reflectance
                 Measurement System",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-95-1",
  month =        feb,
  year =         "1995",
}

@InProceedings{Ferwerda:1996:MVA,
  author =       "James A. Ferwerda and Sumanta N. Pattanaik and Peter
                 Shirley and Donald P. Greenberg",
  title =        "A Model of Visual Adaptation for Realistic Image Synthesis",
  booktitle =    "SIGGRAPH 96 Conference Proceedings",
  conference =   "held in New Orleans, Louisiana; 4--9 August 1996",
  editor =       "Holly Rushmeier",
  organization = "ACM SIGGRAPH",
  publisher =    "Addison Wesley",
  series =       "Annual Conference Series",
  month =        aug,
  year =         "1996",
  pages =        "249--258",
  abstract =     "In this paper we develop a computational model of
                 visual adaptation for realistic image synthesis based
                 on psychophysical experiments. The model captures
                 the changes in threshold visibility, color appearance,
                 visual acuity, and sensitivity over time that are
                 caused by the visual system's adaptation mechanisms.
                 We use the model to display the results of global
                 illumination simulations illuminated at intensities
                 ranging from daylight down to starlight. The resulting
                 images better capture the visual characteristics of
                 scenes viewed over a wide range of illumination levels.
                 Because the model is based on psychophysical data
                 it can be used to predict the visibility and appearance
                 of scene features. This allows the model to be used
                 as the basis of perceptually-based error metrics for
                 limiting the precision of global illumination computations.",
}

@MastersThesis{Foo:1996:GMB,
  author =       "Sing-Choong Foo",
  title =        "A Gonioreflectometer for Measuring the Bidirectional
                 Reflectance of Material for use in Illumination Computation",
  school =       "Cornell University",
  year =         "1996",
  abstract =     "This thesis presents the detailed design and measurement
                 procedures of an automated three-axis gonioreflectometer
                 for measuring the bidirectional reflectance distribution
                 function (BRDF) of an isotropic material for use in
                 computer graphics rendering. The working gonioreflectometer
                 is a modification of a partially completed instr ument
                 donated by Kodak to the Light Measurement Laboratory
                 of the Cornell Program of Computer Graphics. The gonioreflectometer
                 consists of a broad band light source that emits parallel
                 rays in the visible wavelength range. The light source
                 revolves around the test sample which itself has two
                 degrees of freedom of rotation. The detector is stationary
                 and views the test sample via a folding mirror. The
                 detector consists of external focusing optics, a diffraction
                 grating spectrograph, and a diode-array sensor. The
                 system has a high dynamic range and can measure the
                 reflection at high grazing angles (up to 86$^{\circ}$).
                 Both absolute calibration by measuring the direct
                 irradiance, and relative calibration by using a reference
                 sample, can be used for converting measurements to
                 BRDF values. BRDFs of three different samples, a white
                 PTFE sample (Spectralon), a latex blue paint, and
                 a matte-finished steel plate (Q-Panel R-46), were
                 measured with the gonioreflectometer. The results
                 are presented along with close comparisons to data
                 published by other facilities. Specular reflectance
                 and directional-hemispherical reflectance measured
                 with the instrument were cross-checked to measurements
                 made with an Optronic Spectroradiometer (OL-750).",
}

@MastersThesis{Greger:1996:IV,
  author =       "Gene Greger",
  title =        "The Irradiance Volume",
  school =       "Cornell University",
  year =         "1996",
  abstract =     "This thesis presents a volumetric representation for the
                 global illumination within a space based on the radiometric
                 quantity irradiance. We call this representation the
                 irradiance volume. Although irradiance is traditionally
                 computed only for surfaces, its definition can be naturally
                 extended to all points and directions in space. The
                 irradiance volume supports the reconstruction of believable
                 approximations to the illumination in situations that
                 overwhelm traditional global illumination algorithms. A
                 theoretical basis for the irradiance volume is discussed and
                 the methods and issues involved with building the volume are
                 described. The irradiance volume method is tested within
                 several situations in which the use of traditional global
                 illumination methods is impractical, and is shown to provide
                 good performance.",
}

@MastersThesis{Heynen:1996:IPO,
  author =       "Patrick Heynen",
  title =        "Issues in Perceptual Organization for Realistic Image
                 Synthesis",
  school =       "Cornell University",
  year =         "1996",
}

@Article{Hubbard:1996:APS,
  author =       "Philip M. Hubbard",
  title =        "Approximating Polyhedra with Spheres for Time-Critical
                 Collision Detection",
  journal =      "ACM Transactions on Graphics",
  volume =       "15",
  number =       "3",
  month =        jul,
  year =         "1996",
  pages =        "179--210",
  abstract =     "This paper presents a method for approximating polyhedral
                 objects to support a {\em time-critical\/} collision-detection
                 algorithm. The approximations are hierarchies of spheres,
                 and they allow the time-critical algorithm to progressively
                 refine the accuracy of its detection, stopping as
                 needed to maintain the real-time performance essential
                 for interactive applications. The key to this approach
                 is a preprocess that automatically builds tightly
                 fitting hierarchies for rigid and articulated objects.
                 The preprocess uses {\em medial-axis surfaces}, which
                 are skeletal representations of objects. These skeletons
                 guide an optimization technique that gives the hierarchies
                 accuracy properties appropriate for collision detection.
                 In a sample application, hierarchies built this way
                 allow the time-critical collision-detection algorithm
                 to have acceptable accuracy, improving significantly
                 on that possible with hierarchies built by previous
                 techniques. The performance of the time-critical algorithm
                 in this application is consistently 10 to 100 times
                 better than a previous collision-detection algorithm,
                 maintaining low latency and a nearly-constant frame
                 rate of 10 frames per second on a conventional graphics
                 workstation. The time-critical algorithm maintains
                 its real-time performance as objects become more complicated,
                 even as they exceed previously reported complexity
                 levels by a factor of more than 10.",
  notes =        "ISSN 0730-0301",
}

@Article{Hubbard:1996:IAR,
  author =       "Philip M. Hubbard",
  title =        "Improving Accuracy in a Robust Algorithm for Three-{D}imensional
                 Voronoi Diagrams",
  journal =      "Journal of Graphics Tools",
  volume =       "1",
  number =       "1",
  year =         "1996",
  pages =        "33--45",
  abstract =     "This paper descirbes extensions to a previous algorithm
                 that robustly builds three-dimensional {V}oronoi diagrams
                 in the presence of inexact numerical computations.
                 The extensions improve the algorithm's accuracy, making
                 its results more nearly represent the proximity properties
                 of an ideal {V}oronoi diagram. In empirical tests,
                 these extensions have improved accuracy by more than
                 eight orders of magnitude. Complete pseudocode for
                 the algorithm appears in an appendix of this paper.",
  notes =        "ISSN 1086-7651",
}

@MastersThesis{Joseph:1996:DVR,
  author =       "Jonathan Joseph",
  title =        "Direct Volume Rendering of Irregularly Sampled Data
                 Using Voronoi Decomposition",
  school =       "Cornell University",
  year =         "1996",
}

@InProceedings{Lafortune:1996:RPM,
  author =       "Eric P. Lafortune and Yves D. Willems",
  title =        "Rendering Participating Media with Bidirectional
                 Path Tracing",
  booktitle =    "Rendering Techniques '96",
  conference =   "Proceedings of the 7th Eurographics Workshop on Rendering,
                 held in Porto, Portugal; June 17--18, 1996",
  editor =       "Xavier Pueyo and Peter Schr{\"{o}}der",
  organization = "Eurographics",
  publisher =    "Springer-Verlag",
  month =        jun,
  year =         "1996",
  pages =        "91--100",
  abstract =     "In this paper we show how bidirectional path tracing
                 can be extended to handle global illumination effects
                 due to participating media. The resulting image-based
                 algorithm is computationally expensive but more versatile
                 than previous solutions. It correctly handles multiple
                 scattering in non-homogeneous, anisotropic media in
                 complex illumination situations. We illustrate its
                 specific advantages by means of examples.",
}

@MastersThesis{Spencer:1996:PSF,
  author =       "Greg Reeves Spencer",
  title =        "Perceptual Scaling Functions for High Dynamic Range Images",
  school =       "Cornell University",
  year =         "1996",
}

@MastersThesis{Wade:1996:KBD,
  author =       "Bretton Wade",
  title =        "Kernel Based Density Estimation for Global Illumination",
  school =       "Cornell University",
  year =         "1996",
}

@TechReport{Wei-Chieh-Li:1996:PCP,
  author =       "Steve Shiang-Feng Chen and Jerry Wei-Chieh-Li and Kenneth E. Torrance 
                 and Sumanta N. Pattanaik",
  title =        "Preliminary Calibration of the Photometrics {PXL1300L}
                 {CCD} Camera",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-96-1",
  month =        mar,
  year =         "1996",
}

@MastersThesis{Zareski:1996:PDV,
  author =       "David M. Zareski",
  title =        "Parallel Decomposition of View-Independent Global
                 Illumination Algorithms",
  school =       "Cornell University",
  year =         "1996",
}

@InProceedings{Coutts:1997:RS,
  author =       "Richard Coutts and Donald P. Greenberg",
  title =        "Rendering with Streamlines",
  booktitle =    "SIGGRAPH 97 Visual Proceedings",
  organization = "ACM SIGGRAPH",
  publisher =    "Addison Wesley",
  month =        aug,
  year =         "1997",
  pages =        "188",
  notes =        "ISBN 0-89791-921-1",
  abstract = 	"In this technique for generating pen-and-ink drawings, vector 
		field streamlines are used to approximate the hatch
		marks of traditional artists. The streamlines are calculated 
		by a new one-pass algorithm. ",
}

@InProceedings{Ferwerda:1997:MVM,
  author =       "James A. Ferwerda and Sumanta N. Pattanaik and Peter
                 Shirley and Donald P. Greenberg",
  title =        "A Model of Visual Masking for Computer Graphics",
  booktitle =    "SIGGRAPH 97 Conference Proceedings",
  editor =       "Turner Whitted",
  organization = "ACM SIGGRAPH",
  publisher =    "Addison Wesley",
  series =       "Annual Conference Series",
  month =        aug,
  year =         "1997",
  pages =        "143--152",
  keywords =     "visual perception, masking, image quality, error
                 metrics",
  abstract =     "In this paper we develop a computational model of
                 visual masking based on psychophysical data. The model
                 predicts how the presence of one visual pattern affects
                 the detectability of another. The model allows us
                 to choose texture patterns for computer graphics images
                 that hide the effects of faceting, banding, aliasing,
                 noise and other visual artifacts produced by sources
                 of error in graphics algorithms. We demonstrate the
                 utility of the model by choosing a texture pattern
                 to mask faceting artifacts caused by polygonal tesselation
                 of a at-shaded curved surface. The model predicts
                 how changes in the contrast, spatial frequency, and
                 orientation of the texture pattern, or changes in
                 the tesselation of the surface will alter the masking
                 effect. The model is general and has uses in geometric
                 modeling, realistic image synthesis, scientific visualization,
                 image compression, and image-based rendering.",
  notes =        "ISBN 0-89791-896-7",
}

@InProceedings{Greenberg:1997:FRI,
  author =       "Donald P. Greenberg and Kenneth Torrance and Peter
                 Shirley and James Arvo and James A. Ferwerda and Sumanta
                 Pattanaik and Eric Lafortune and Bruce Walter and
                 Sing-Choong Foo and Ben Trumbore",
  title =        "A Framework for Realistic Image Synthesis",
  booktitle =    "SIGGRAPH 97 Conference Proceedings",
  editor =       "Turner Whitted",
  organization = "ACM SIGGRAPH",
  publisher =    "Addison Wesley",
  series =       "Annual Conference Series",
  month =        aug,
  year =         "1997",
  pages =        "477--494",
  keywords =     "Realistic Image Synthesis, Light Reflection, Perception",
  abstract =     "Our goal is to develop physically based lighting
                 models and perceptually based rendering procedures
                 for computer graphics that will produce synthetic
                 images that are visually and measurably indistinguishable
                 from real-world images. Fidelity of the physical simulation
                 is of primary concern. Our research framework is subdivided
                 into three sub-sections: the local light reflection
                 model, the energy transport simulation, and the visual
                 display algorithms. The first two subsections are
                 physically based, and the last is perceptually based.
                 We emphasize the comparisons between simulations and
                 actual measurements, the difficulties encountered,
                 and the need to utilize the vast amount of psychophysical
                 research already conducted. Future research directions
                 are enumerated. We hope that results of this research
                 will help establish a more fundamental, scientific
                 approach for future rendering algorithms. This presentation
                 describes a chronology of past research in global
                 illumination and how parts of our new system are currently
                 being developed.",
  notes =        "ISBN 0-89791-896-7",
}

@InProceedings{Lafortune:1997:NLA,
  author =       "Eric P. F. Lafortune and Sing-Choong Foo and Kenneth
                 E. Torrance and Donald P. Greenberg",
  title =        "Non-Linear Approximation of Reflectance Functions",
  booktitle =    "SIGGRAPH 97 Conference Proceedings",
  editor =       "Turner Whitted",
  organization = "ACM SIGGRAPH",
  publisher =    "Addison Wesley",
  series =       "Annual Conference Series",
  month =        aug,
  year =         "1997",
  pages =        "117--126",
  keywords =     "Reflectance function, BRDF representation",
  abstract =     "We introduce a new class of primitive functions with
                 non-linear parameters for representing light reflectance
                 functions. The functions are reciprocal, energy-conserving
                 and expressive. They can capture important phenomena
                 such as off-specular reflection, increasing reflectance
                 and retro-reflection. We demonstrate this by fitting
                 sums of primitive functions to a physically-based
                 model and to actual measurements. The resulting representation
                 is simple, compact and uniform. It can be applied
                 efficiently in analytical and Monte Carlo computations.",
  notes =        "ISBN 0-89791-896-7",
}

@InProceedings{Marschner:1997:ILP,
  author =       "Stephen R. Marschner and Donald P. Greenberg",
  title =        "Inverse Lighting for Photography",
  booktitle =    "Proceedings of the Fifth Color Imaging Conference,
                 Society for Imaging Science and Technology",
  month =        nov,
  year =         "1997",
  abstract =     "We introduce a technique for improving photographs
                 using inverse lighting, a new process based on algorithms
                 developed in computer graphics for computing the reflection
                 of light in 3D space. From a photograph and a 3D surface
                 model for the object pictured, inverse lighting estimates
                 the directional distribution of the incident light.
                 We then use this information to process the photograph
                 digitally to alter the lighting on the object. Inverse
                 lighting is a specific example of the general idea
                 of inverse rendering. This refers to the practice
                 of using the methods of computer graphics, which normally
                 are used to render images from scene information,
                 to infer scene information from images. Our system
                 uses physically based rendering technology to construct
                 a linear least squares system that we solve to find
                 the lighting. As an application, the results are then
                 used to simulate a change in the incident light in
                 the photograph. An implementation is described that
                 uses 3D models from a laser range scanner and photographs
                 from a high-resolution color CCD camera. We demonstrate
                 the system on a simple test object and a human face.",
}

@TechReport{Marschner:1997:TMP,
  author =       "Stephen R. Marschner",
  title =        "Texture Maps from Photographs of Scanned 3D Surfaces",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-97-1",
  month =        apr,
  year =         "1997",
  abstract =     "Many techniques for measuring three-dimensional objects
                 for computer graphics record the radiance reflected
                 from the object in order to describe the variations
                 in its surface color. Examples include texture maps
                 from range scanners and photographs [Debevec96], and
                 image-based rendering techniques [McMillan95, Levoy96].
                 Because these techniques do not consider the lighting
                 conditions under which the measurements are taken,
                 the color information is not suitable for rendering
                 the object under different lighting conditions. This
                 prevents their use in realistic rendering systems
                 that simulate lighting. This paper describes a method
                 for building texture maps on 3D surface models from
                 a range scanner using photographs taken of the scanned
                 object under controlled lighting conditions. A simple
                 technique is presented to account for lighting so
                 that the texture map stores reflectance, making the
                 models suitable for realistic rendering. An implementation
                 for diffuse reflectance is demonstrated on a test
                 object and on complex natural objects.",
}

@Article{Moller:1997:FMS,
  author =       "Tomas M{\"{o}}ller and Ben Trumbore",
  title =        "Fast, Minimum Storage Ray-Triangle Intersection",
  journal =      "Journal of Graphics Tools",
  volume =       "2",
  number =       "1",
  year =         "1997",
  pages =        "21--28",
  abstract =     "We present a clean algorithm for determining whether
                 a ray intersects a triangle. The algorithm translates
                 the origin of the ray and then changes the base to
                 yield a vector (t u v)T, where t is the distance to
                 the plane in which the triangle lies and (u,v) represents
                 the coordinates inside the triangle. One advantage
                 of this method is that the plane equation need not
                 be computed on the fly nor be stored, which can amount
                 to significant memory savings for triangle meshes.
                 As we found our method to be comparable in speed to
                 previous methods, we believe it is the fastest ray-triangle
                 intersection routine for triangles that do not have
                 precomputed plane equations.",
}

@InProceedings{Pattanaik:1997:VGI,
  author =       "Sumanta N. Pattanaik and James A. Ferwerda and Kenneth
                 E. Torrance and Donald P. Greenberg",
  title =        "Validation of Global Illumination Solutions through
                 {CCD} Camera Measurements",
  booktitle =    "Proceedings of the Fifth Color Imaging Conference,
                 Society for Imaging Science and Technology",
  month =        nov,
  year =         "1997",
  pages =        "250--253",
  abstract = 	"In this paper we present a technique for calibrating a CCD 
		camera for direct colorimetric comparison between the
		captured images of the real environment and synthetic images 			of the simulated environments. We use this
		comparison to validate lighting simulation algorithms used 
		for computing synthetic images.", 
}

@InProceedings{Peng:1997:UCG,
  author =       "Liang Peng and Eric Lafortune and Donald P. Greenberg",
  title =        "Use of Computer Graphic Simulation to Explain Color
                 Histogram Structure",
  booktitle =    "Proceedings of the Fifth Color Imaging Conference,
                 Society for Imaging Science and Technology",
  month =        nov,
  year =         "1997",
  abstract = 	"In this paper, we discuss the use of computer graphics 
		tech niques to model and explain the structures commonly
		ob served in color histograms of images. This includes an 
		accurate simulation of the physical reflection and
		transport behavior of light energy within 3D environments, the 
		pre cise modeling of an image capturing system,
		and an in teractive visualization module to display color 
		histograms.  Based on the fundamental rendering equation
		that describes light reflection and transport in the 3D world, 
		we classify the color histogram structures of color
		images, and relate them to various physical components in 
		image formation, including scene illumination, material
		reflectance proper ties, and the surface geometry of 
		objects. We further show how these histogram structures can
		be effected by the arti facts caused by the limitation of 
		image capturing systems.  Our results demonstrate that the
		use of accurate simulation procedures under a precisely 
		controlled computer graphic environment can clearly
		illustrate the causes of the struc tures observed, and can 
		provide unique insights and expla nations of image
		formation.",
}

@InProceedings{Shirley:1997:PAL,
  author =       "Peter Shirley and Helen Hu and Brian Smits and Eric
                 Lafortune",
  title =        "A Practitioners' Assessment of Light Reflection Models",
  booktitle =    "Proceedings of Pacific Graphics 97",
  conference =   "held in Seoul, Korea; October 1997",
  month =        oct,
  year =         "1997",
  abstract =     "We discuss the theory and practical issues behind
                 creating reflection models to show the difficulty
                 of the problem. We survey the current approaches towards
                 reflection models for computer graphics to show that
                 even for simple surfaces, the important issues are
                 far from settled. We briefly discuss future directions
                 for research. Finally, we present a case study of
                 a particular type of light reflection that captures
                 some important aspects of appearance for a limited
                 class of materials with subsurface reflection.",
}

@InProceedings{Walter:1997:FVL,
  author =       "Bruce Walter and G{\"{u}}n Alppay and Eric Lafortune
                 and Sebastian Fernandez and Donald P. Greenberg",
  title =        "Fitting Virtual Lights for Non-Diffuse Walkthroughs",
  booktitle =    "SIGGRAPH 97 Conference Proceedings",
  editor =       "Turner Whitted",
  organization = "ACM SIGGRAPH",
  publisher =    "Addison Wesley",
  series =       "Annual Conference Series",
  month =        aug,
  year =         "1997",
  pages =        "45--48",
  keywords =     "interactive walkthroughs, non-diffuse appearance,
                 global illumination, Phong shading",
  abstract =     "This paper describes a technique for using a simple
                 shading method, such as the Phong lighting model,
                 to approximate the appearance calculated by a more
                 accurate method. The results are then suitable for
                 rapid display using existing graphics hardware and
                 portable via standard graphics API's. Interactive
                 walkthroughs of view-independent nondiffuse global
                 illumination solutions are explored as the motivating
                 application.",
  notes =        "ISBN 0-89791-896-7",
}

@Article{Walter:1997:GIU,
  author =       "Bruce Walter and Philip M. Hubbard and Peter Shirley
                 and Donald P. Greenberg",
  title =        "Global Illumination Using Local Linear Density Estimation",
  journal =      "ACM Transactions on Graphics",
  volume =       "16",
  number =       "3",
  month =        jul,
  year =         "1997",
  pages =        "217--259",
  keywords =     "decimation, density estimation, particle tracing,
                 realistic image synthesis, regression",
  abstract =     "This article presents the density estimation framework
                 for generating view-independent global illumination
                 solutions. It works by probabilistically simulating
                 the light flow in an environment with light particles
                 that trace random walks originating at luminaires
                 and then using statistical density estimation techniques
                 to reconstruct the lighting on each surface. By splitting
                 the computation into separate transport and reconstruction
                 stages, we gain many advantages including reduced
                 memory usage, the ability to simulate nondiffuse transport,
                 and natural parallelism. Solutions to several theoretical
                 and practical difficulties in implementing this framework
                 are also described. Light sources that vary spectrally
                 and directionally are integrated into a spectral particle
                 tracer using nonuniform rejection. A new local linear
                 density estimation technique eliminates boundary bias
                 and extends to arbitrary polygons. A mesh decimation
                 algorithm with perceptual calibration is introdued
                 to simplify the Gouraud-shaded representation of the
                 solution for interactive display.",
  notes =        "ISSN 0730-0301",
}

@Article{Greger:1998:IV,
  author =       "Gene Greger and Peter Shirley and Philip M. Hubbard
                 and Donald P. Greenberg",
  title =        "The Irradiance Volume",
  journal =      "IEEE Computer Graphics and Applications",
  volume =       "18",
  number =       "2",
  month =        mar,
  year =         "1998",
  pages =        "32--43",
  abstract =     "This article presents a volumetric representation for the 
		global illumination within a space based on the radiometric 
		quantity irradiance. We call
		this representation the irradiance volume. Although irradiance 
		is traditionally computed only for surfaces, we extend its 
		definition to all points
		and directions in space. The irradiance volume supports the 
		reconstruction of believable approximations to the illumination 		in situations that
		overwhelm traditional global illumination algorithms. 
		A theoretical basis for the irradiance volume is 
		discussed and the methods and issues
		involved with building the volume are described. 
		The irradiance volume method shows good performance 
		in several practical situations.",
}

@PhdThesis{Peng:1998:CHA,
  author =       "Liang Peng",
  title =        "The Color Histogram and its Applications in Digital
                 Photography",
  school =       "Cornell University",
  year =         "1998",
  abstract =     "The color histogram is a tool that has been widely
                 used in many image processing and computer vision
                 applications such as image retrieval and image segmentation.
                 In these applications, the features in the color histogram
                 are used as signatures for feature comparison, scene
                 analysis and object recognition. Various histogram
                 features were explained previously by several models
                 in computer vision which incorporate the physical
                 process of light reflection. However, most of these
                 approaches are mainly based on a dichromatic reflectance
                 model, and only consider the lighting coming directly
                 from the light source in the scene. In this dissertation,
                 we present a comprehensive study of the formation
                 of color histogram structures based on both the theory
                 and simulation of light reflection and transport in
                 the three dimensional world with the full spectrum
                 of visible light by using advanced computer graphic
                 techniques. By using a physically accurate, precisely
                 controlled computer graphic environment, we have been
                 able to successfully isolate and reproduce the features
                 in the color histogram observed by previous researchers.
                 Furthermore, we have also produced more complex new
                 features, such as off-plane thickening and ``banana''
                 shaped structures in the color histogram by incorporating
                 global illumination in our image synthesis procedure.
                 Several physically based reflectance models are used
                 to illustrate and explain the formation of these features
                 in the color histogram. We then use the color histogram
                 analysis techniques in a digital photographic application
                 to extract the spectral information about the illumination
                 in the scene and spectral information about the diffuse
                 component of the reflectance of a dichromatic surface.
                 This spectral information is then used to predict
                 the appearance of objects in the image under different
                 illumination spectra. Our method is demonstrated to
                 show improved performance over some traditional illumination
                 compensation methods, and has great potential in digital
                 photography.",
}

@MastersThesis{Coutts:1998:CMR,
  author =       "Richard M. Coutts",
  title =        "Conceptual Modeling and Rendering Techniques for
                 Architectural Design",
  school =       "Cornell University",
  year =         "1998",
  abstract =     "Today's design professions are not integrating the computer
                 into their workplace as successfully as more technical
                 professionals. It is tempting to attribute this to the fact
                 that artists and architects are not as technically savvy as
                 engineers and scientists. Closer inspection reveals, however,
                 that current software applications simply do not fit their
                 needs.

                 Three problematic areas are identified in this thesis in
                 current computer design software. (1) Human-computer
                 interfaces are too cumbersome for design. (2) The current
                 human-computer interfaces do not facilitate transitioning
                 between conceptual drawings and computer models. (3) Current
                 computer rendering styles are not abstract enough for
                 visualizing incomplete designs. These shortcomings are
                 alleviated here by introducing new human-computer interface
                 and {\em sketch rendering} \footnote{The computer graphics
                 community refers to computer images that approximate hand
                 drawings as {\em non-photorealistic} images. Because this
                 term describes what the images are {\em not}, rather than
                 what they {\em are}, the author considers this inappropriate
                 terminology. Consequently, the term {\em sketch rendering} is
                 introduced.} techniques. A solid modeler was written for this
                 thesis to address the human-computer interface issues.
                 Currently, architects and designers use traditional media --
                 e.g., clay, chip board, and sketches -- in preliminary
                 design. For a solid modeler to compete with these materials,
                 it must be as simple to use. Our modeler's interface
                 approaches this goal by incorporating a surface cursor that
                 {\em feels} its way along the model's surface, giving the
                 designer much needed visual cues as to the cursor's location
                 in three dimensions.

                 The need for more abstract rendering styles is addressed by
                 presenting a new technique for generating sketch renderings.
                 These renderings approximate the look and feel of
                 conventional hand drawings. The algorithms presented here
                 simulate an artist's hatch markings with vectored
                 streamlines. The streamlines are calculated in a
                 two-dimensional vector field generated by projecting
                 three-dimensional surface flow onto the image plane. A global
                 illumination image is used as a tone map to control the
                 hatching density. Because the algorithms operate on strictly
                 two-dimensional data extracted from the three-dimensional
                 model, they are robust and simple to implement. Several new
                 support algorithms, including a new one-pass streamline
                 algorithm that approximates both density and direction, are
                 described.",
}

@TechReport{Pattanaik:1998:LMP,
  author =       "Sumanta N. Pattanaik and Kenneth E. Torrance",
  title =        "Light Measurement using the Photometrics
 		 {PXL1300L} {CCD} Camera",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-98-1",
  month =        may,
  year =         "1998",
  abstract =     "",
}

@InProceedings{Pattanaik:1998:MMAa,
  author =       "Sumanta N. Pattanaik and James A. Ferwerda
                 and Mark D. Fairchild and Donald P. Greenberg",
  title =        "A Multiscale Model of Adaptation and Spatial Vision
		 for Realistic Image Display",
  booktitle =    "SIGGRAPH 98 Conference Proceedings",
  editor =       "Michael F. Cohen",
  organization = "ACM SIGGRAPH",
  publisher =    "Addison Wesley",
  series =       "Annual Conference Series",
  month =        jul,
  year =         "1998",
  pages =        "287--298",
  keywords =     "realistic imaging, visual perception, tone reproduction,
		 adaptation, spatial vision",
  abstract =     "In this paper we develop a computational model of adaptation
                 and spatial vision for realistic tone reproduction. The model
                 is based on a multiscale representation of pattern,
                 luminance, and color processing in the human visual system.
                 We incorporate the model into a tone reproduction operator
                 that maps the vast ranges of radiances found in real and
                 synthetic scenes into the small fixed ranges available on
                 conventional display devices such as CRT's and printers. The
                 model allows the operator to address the two major problems
                 in realistic tone reproduction: wide absolute range and high
                 dynamic range scenes can be displayed; and the displayed
                 images match our perceptions of the scenes at both threshold
                 and suprathreshold levels to the degree possible given a
                 particular display device. Although in this paper we apply
                 our visual model to the tone reproduction problem, the model
                 is general and can be usefully applied to image quality
                 metrics, image compression methods, and perceptually-based
                 image synthesis algorithms.",
}

@InProceedings{Pattanaik:1998:MMAb,
  author =       "Sumanta N. Pattanaik and Mark D. Fairchild
                 and James A. Ferwerda and Donald P. Greenberg",
  title =        "Multiscale Model of Adaptation, Spatial Vision and Color
                 Appearance",
  booktitle =    "Proceedings of the Sixth Color Imaging Conference,
                 Society for Imaging Science and Technology",
  conference =   "held in Scottsdale, Arizona",
  month =        nov,
  year =         "1998",
  abstract =     "In this paper we present a multi-scale color appearance
                 model which simulates luminance, pattern and color processing
                 of the human visual system to accurately predict the color
                 appearance attributes of spectral stimuli in complex
                 surroundings under a wide range of illumination and viewing
                 conditions.",
}

@InProceedings{Peng:1998:DBP,
  author =       "Liang Peng",
  title =        "Dichromatic Based Photographic Modification",
  booktitle =    "Proceedings of the Sixth Color Imaging Conference,
                 Society for Imaging Science and Technology",
  conference =   "held in Scottsdale, Arizona",
  month =        nov,
  year =         "1998",
  abstract =     "We propose a technique to modify colors in photographic
  		 images predicting the color appearance of objects in an image
		 under different illuminations.  Using the dichromatic surface
		 reflectance model, we estimate the illumination spectrum and
		 the spectrum of the diffuse surface reflectance via the color
		 histogram and subspace analyses.  With this estimated spectral
		 information, and the spectrum of a newly specified
		 illumination, we construct two color correction operators, one
		 for the specular reflection color component and the other for
		 the diffuse reflection color component, to modify color values
		 in the images.  We demonstrate this new method with a skin
		 tone modification example using a human face subject.",
}

@MastersThesis{Alppay:1998:FDD,
  author =       "Gun Alppay",
  title =        "Fast Display of Directional Global Illumination Solutions",
  school =       "Cornell University",
  year =         "1998",
  abstract =     "",
}

@MastersThesis{Piccolotto:1998:SAM,
  author =       "Moreno A. Piccolotto",
  title =        "Sketchpad+ Architectural Modeling through Perspective
  		 Sketching on a Pen-Based Display",
  school =       "Cornell University",
  year =         "1998",
  abstract =     "",
}

@MastersThesis{Malone:1998:SCG,
  author =       "Michael J. Malone",
  title =        "Sketchpad+ Conceptual Geometric Modeling through
  		 Perspective Sketching on a Pen-Based Display",
  school =       "Cornell University",
  year =         "1998",
  abstract =     "",
}
@PhdThesis{Marschner:1998:IRC,
  author =       "Stephen R. Marschner",
  title =        "Inverse Rendering for Computer Graphics",
  school =       "Cornell University",
  year =         "1998",
  abstract =     "Creating realistic images has been a major focus in the
                 study of computer graphics for much of its history. This
                 effort has led to mathematical models and algorithms that can
                 compute predictive, or physically realistic, images from
                 known camera positions and scene descriptions that include
                 the geometry of objects, the reflectance of surfaces, and the
                 lighting used to illuminate the scene. These images
                 accurately describe the physical quantities that would be
                 measured from a real scene. Because these algorithms can
                 predict real images, they can also be used in inverse
                 problems to work backward from photographs to attributes of
                 the scene.

                 Work on three such inverse rendering problems is described.
                 The first, inverse lighting, assumes knowledge of geometry,
                 reflectance, and the recorded photograph and solves for the
                 lighting in the scene. A technique using a linear
                 least-squares system is proposed and demonstrated. Also
                 demonstrated is an application of inverse lighting, called
                 re-lighting, which modifies lighting in photographs.

                 The second two inverse rendering problems solve for unknown
                 reflectance, given images with known geometry, lighting, and
                 camera positions. Photographic texture measurement
                 concentrates on capturing the spatial variation in an
                 object's reflectance. The resulting system begins with
                 scanned 3D models of real objects and uses photographs to
                 construct accurate, high-resolution textures suitable for
                 physically realistic rendering. The system is demonstrated on
                 two complex natural objects with detailed surface textures.

                 Image-based BRDF measurement takes the opposite approach to
                 reflectance measurement, capturing the directional
                 characteristics of a surface's reflectance by measuring the
                 bidirectional reflectance distribution function, or BRDF.
                 Using photographs of an object with spatially uniform
                 reflectance, the BRDFs of paints and papers are measured with
                 completeness and accuracy that rival that of measurements
                 obtained using specialized devices. The image-based approach
                 and novel light source positioning technique require only
                 general-purpose equipment, so the cost of the apparatus is
                 low compared to conventional approaches. In addition, very
                 densely sampled data can be measured very quickly, when the
                 wavelength spectrum of the BRDF does not need to be measured
                 in detail. ",
}

@PhdThesis{Ferwerda:1998:VMR,
  author =       "James A. Ferwerda",
  title =        "Visual Models for Realistic Image Synthesis",
  school =       "Cornell University",
  year =         "1998",
  abstract =     "This thesis explores how psychophysically-based models of
  		 vision can be used to improve the fidelity and efficiency of
		 image synthesis algorithms.  In separate chapters
		 computational models of visual adaptation, spatial vision,
		 and spatial vision incorporating adaptation are developed and
		 applied to problems in realistic image synthesis.  The
		 adaptation model addresses the problem of tone reproduction
		 in image display and allows images of scenes illuminated at
		 a wide range of absolute levels to be displayed within the
		 limited ranges available on conventional display devices such
		 as CRT's and printers.  The spatial vision model is used to
		 investigate the properties of visual masking, which can be
		 used to predict the visibility of artifacts in synthetic
		 images and used to choose surface textures for synthetic
		 objects that hide these artifacts.  Finally the model of
		 adaptation and spatial vision returns to the issue of tone
		 and color reproduction and provides a more comprehensive
		 approach for displaying wide absolute range and high dynamic
		 range color images on conventional displays.  This work
		 highlights the potential for useful symbiosis between the
		 fields of perception psychology and computer graphics.",
}

@PhdThesis{Walter:1998:DET,
  author =       "Bruce J. Walter",
  title =        "Density Estimation Techniques For Global Illumination",
  school =       "Cornell University",
  year =         "1998",
  abstract =     "In this thesis we present the density estimation framework
                 for computing view-independent global illumination
                 solutions. The framework consists of three phases: particle
                 tracing, density estimation, and decimation. Monte Carlo
                 particle tracing is used to accurately simulate the light
                 transport under a general spectral geometric-optics based
                 physical model. Next kernel density estimation is used to
                 reconstruct perceptual illumination functions. Finally
                 decimation is used to optimize the resulting mesh for
                 compactness and rapid interactive display as Gouraud-shaded
                 triangles.

                 The three principal contributions of this work are the
                 framework's separation of transport and function
                 reconstruction computations, its ability to produce accurate
                 solutions with precisely known error characteristics, and the
                 techniques that we introduce to improve its efficiency and
                 accuracy.

                 Particle tracing's generality allows us to eliminate or delay
                 many common simplifying assumptions and improves our accuracy
                 and error analysis. Delaying the density estimation until
                 particle tracing is complete allows us to make better use of
                 the expensive particle data. The separation of global
                 transport and local representation computations also reduces
                 the computational complexity of each phase, enhances the
                 framework's scalability, and exposes abundant opportunities
                 for parallelism. Another advantage is that we can solve
                 directly for the radiant exitance without needing to estimate
                 the more complicated spectral radiance function.

                 Despite its advantages, if naively implemented the framework
                 would be prohibitively expensive. Thus we also introduce
                 several techniques that significantly improve its accuracy and
                 efficiency. These include the separation of luminance and
                 chromaticity bandwidths, perceptually-motivated noise
                 visibility predictors, statistical bias detection techniques
                 to automatically enhance underresolved illumination features,
                 a local polynomial density estimation method to eliminate
                 boundary bias, and wavelength importance sampling to reduce
                 the spectral noise. Results of the framework are shown for
                 some complex environments and compared against measured data
                 for a simple scene.

                 The strength of our framework is that it can simulate a wider
                 variety of lighting effects, with fewer simplifying
                 assumptions, and more precise error analysis that current
                 view-independent methods. Furthermore, because of its
                 accuracy, our density estimation framework solutions are used
                 as reference solutions for judging the quality and
                 effectiveness of more approximate but faster rendering
                 methods.",
}

@InProceedings{Kindlmann:1998:SAG,
  author =       "Gordon Kindlmann and James Durkin",
  title =        "Semi-Automatic Generation of Transfer Functions
		 for Direct Volume Rendering",
  booktitle =    "IEEE Symposium on Volume Rendering Proceedings",
  organization = "IEEE",
  month =        oct,
  year =         "1998",
  abstract =     "Although direct volume rendering is a powerful tool for 
		visualizing complex structures within volume data, the size
		and complexity of the parameter space controlling the 
		rendering process makes generating an informative rendering
		challenging. In particular, the specification of the transfer 
		function --- the mapping from data values to renderable
		optical properties --- is frequently a time-consuming and 
		unintuitive task. Ideally, the data being visualized should
		itself suggest an appropriate transfer function that brings 
		out the features of interest without obscuring them with
		elements of little importance. We demonstrate that this is 
		possible for a large class of scalar volume data.",
}

@MastersThesis{Kindlmann:1999:SAG,
  author =       "Gordon Kindlmann",
  title =        "Semi-Automatic Generation of Transfer Functions
  		 for Direct Volume Rendering",
  school =       "Cornell University",
  year =         "1999",
  abstract =     "Finding appropriate transfer functions for direct volume
		 rendering is a difficult problem because of the large amount
		 of user experimentation typically involved.  Ideally, the
		 dataset being rendered should istelf be able to suggest a
		 transfer function which makes the important structures
		 visible.  We demonstrate that this is possible for a large
		 class of scalar volume data, namely that where the region of
		 interest is the boundary between different materials.  A
		 transfer function which makes boundaries readily visible can
		 be generated from the relationship between three quantitites:
		 the data value and its first and second directional
		 derivatives along the gradient direction. A data structure we
		 term the histogram volume captures the relationship between
		 these quantities throughout the volume in a position
		 independent, computationally efficient fashion.  We describe
		 the theoretical importance of the quantities measured by the
		 histogram volume, the implementation issues in its
		 calculation, and a method  for semi-automatic transfer
		 function generation through its analysis.  The techniques
		 presented here make direct volume rendering easier to use, not
		 only because there are much fewer variables for the user to
		 adjust to find an informative rendering, but because using
		 them is more intuitive than current interfaces for transfer
		 function specification.  Furthermore, the results are derived
		 solely from the original dataset and its inherent patterns of
		 values, without the introduction of any artificial structures
		 or limitations. Examples with volume datasets from a variety
		 of disciplines illustrate the generality and strength of the
		 techniques.",
}

@MastersThesis{Kunz:1999:FVA,
  author =       "Andrew Kunz",
  title =        "Face Vectors: An Abstraction for Data-Driven 3-D
		 Facial Animation",
  school =       "Cornell University",
  year =         "1999",
  abstract =     "",
}
@MastersThesis{Gelb:1999:IBR,
  author =       "Daniel G. Gelb",
  title =        "Image-Based Rendering for Non-diffuse Scenes",
  school =       "Cornell University",
  year =         "1999",
  abstract =     "",
}

@MastersThesis{Wong:1999:ARP,
  author =       "Eric Chih-Cheng Wong",
  title =        "Artistic Rendering of Portrait Photographs",
  school =       "Cornell University",
  year =         "1999",
  abstract =     "",
}

@InProceedings{Ramasubramanian:1999:PBP,
  author =       "Mahesh Ramasubramanian and Sumanta N. Pattanaik
                 and Donald P. Greenberg",
  title =        "A Perceptually Based Physical Error Metric
		 for Realistic Image Synthesis",
  booktitle =    "SIGGRAPH 99 Conference Proceedings",
  editor =       "Alyn Rockwood",
  organization = "ACM SIGGRAPH",
  publisher =    "Addison Wesley",
  conference =   "Los Angeles, California, August 8-13, 1999",
  series =       "Annual Conference Series",
  month =        "Aug",
  year =         "1999",
  pages =        "73--82",
  keywords =     "realistic image synthesis, global illumination,
		 adaptive sammpling, perception, visual masking,
		 error metric, visual threshold.",
  abstract =     "We introduce a new concept for accelerating realistic image
		 synthesis algorithms. At the core of this procedure is a
		 novel physical error metric that correctly predicts the
		 perceptual threshold for detecting artifacts in scene
		 features. Built into this metric is a computational model of
		 the human visual system's loss of sensitivity at high
		 background illumination levels, high spatial frequencies,
		 and high contrast levels (visual masking). An important
		 feature of our model is that it handles the
		 luminance-dependent processing and spatially-dependent
		 processing independently. This allows us to precompute the
		 expensive spatially-dependent component, making our model
		 extremely efficient.

		 We illustrate the utility of our procedure with global
		 illumination algorithms used for realistic image synthesis.
		 The expense of global illumination computations is many
		 orders of magnitude higher than the expense of direct
		 illumination  computations and can greatly benefit by
		 applying our perceptually based technique. Results show our
		 method preserves visual quality while achieving significant
		 computational gains in areas of  images with high frequency
		 texture patterns, geometric details, and lighting
		 variations.",
}

@InProceedings{Hart:1999:DIL,
  author =       "David Hart and Philip Dutre and Donald P. Greenberg",
  title =        "Direct Illumination with Lazy Visibility Evaluation",
  booktitle =    "SIGGRAPH 99 Conference Proceedings",
  editor =       "Alyn Rockwood",
  organization = "ACM SIGGRAPH",
  conference =   "Los Angeles, California, August 8-13, 1999",
  publisher =    "Addison Wesley",
  series =       "Annual Conference Series",
  month =        aug,
  year =         "1999",
  pages =        "147--154",
  keywords =     "Rendering, Illuminationn Effects, Monte Carlo Techniques,
		 Shadow Algorithms, Visibility Determination.",
  abstract =     "In this paper we present a technique for computing the
  		 direct lighting in a three-dimensional scene containing area
		 light sources. Our method correctly handles partial
		 visibility between luminaires and receivers, and is able to
		 efficiently generate accurate soft shadows in scenes modeled
		 with general bidirectional reflectance distribution
		 functions. In most current algorithms, the form factor between
  		 a light source and receiver is computed using a stochastic
		 ray casting approach which evaluates partial visibility. Such
		 an approach often leads to noisy artifacts or aliasing
		 problems. Generating significantly more rays is often the
		 only solution to improving image quality. Our approach first
		 stores visibility information in the image plane, using lazy
		 evaluation of the visibility function. In a second phase,
		 illumination values for each pixel are generated, using
		 analytic or stochastic integration. Soft shadows and other
		 shading effects are generated with high accuracy in less time
		 than with existing shading algorithms. Coherence in specific
		 blocker-light source relationships across the image plane is
		 exploited to amortize the cost of analytic form factor
		 calculations. By storing information in the image plane, our
		 method is currently designed for generating a single image,
		 and is thus view-dependent.",
}

@InProceedings{Marschner:1999:IBX,
  author =       "Stephen R. Marschner and Stephen H. Westin
                  and Eric P. F. Lafortune and Kenneth E. Torrance
                  and Donald P. Greenberg",
  title =        "Image-Based BRDF Measurement Including Human Skin",
  booktitle =    "Eurographics Workshop on Rendering",
  conference =   "held in Granada, Spain; 21-23 June 1999",
  year =         "1999",
  pages =        "",
  abstract =     "We present a new image-based process for measuring the
                  bidirectional reflectance of homogeneous surfaces
                  rapidly, completely, and accurately.  For simple
                  sample shapes (spheres and cylinders) the method
                  requires only a digital camera and a stable light
                  source. Adding a 3D scanner allows a wide class of
                  curved near-convex objects to be measured.  With
                  measurements for a variety of materials from paints
                  to human skin, we demonstrate the new method's
                  ability to achieve high resolution and accuracy over
                  a large domain of illumination and reflection
                  directions. We verify our measurements by tests of
                  internal consistency and by comparison against
                  measurements made using a gonioreflectometer.",
}

@TechReport{Marschner:1999:RMH,
  author =       "Stephen R. Marschner and Stephen H. Westin and
 		 Eric P. F. Lafortune and and Kenneth E. Torrance and
		 Donald P. Greenberg",
  title =        "Reflectance Measurements of Human Skin",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-99-2",
  month =        "Jan",
  year =         "1999",
  abstract =     "We use a novel image-based technique to measure the
                 directional reflectance of living human skin. Using only a
                 commercial-grade digital camera and electronic flash, we can
                 collect many samples in a few minutes. By exploiting the
                 body's own curvature, we obtain data comprehensively covering
                 a wide range of directions. We present results from several
                 different individuals, showing interesting effects both
                 individually and in their differences from each other.",
}

@TechReport{Marschner:1999:IBM,
  author =       "Stephen R. Marschner and Eric P. F. Lafortune and
 		 Stephen H. Westin and and Kenneth E. Torrance and
		 Donald P. Greenberg",
  title =        "Image-Based BRDF Measurement",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-99-1",
  month =        "Jan",
  year =         "1999",
  abstract =     "We present a new image-based process for measuring surface 
		  reflectance rapidly, completely, and accurately.
		  Requiring only a digital camera, a light source, and a 
		  convex curved test sample, our method can measure the
		  BRDF with high resolution and accuracy over a very large 
		  domain of illumination and reflection directions. We
		  have verified our measurements both by tests of internal 
		  consistency and by comparison against measurements
		  made using a gonioreflectometer.",
}

@Article{Greenberg:1999:FRI,
  author =       "Donald P. Greenberg",
  title =        "A Framework for Realistic Image Synthesis",
  journal =      "Communications of the ACM",
  volume =       "42",
  number =       "8",
  month =        aug,
  year =         "1999",
  pages =        "44--53",
  abstract = 	"Our goal at the Cornell Program of Computer Graphics is to 
		develop physically based lighting models and perceptually
		based rendering procedures that produce synthetic images 
		visually and measurably indistinguishable from
		real-world images. Fidelity of the physical simulation is the 
		primary concern. Here, I emphasize the formal comparisons
		between simulations and actual measurements, the difficulties 
		algorithm designers and scientists encounter building
		light-reflection and light-transport
		models, and the need to tap the vast amount of psychophysical 
		research conducted over the past
		50 years, as well as future research directions. We hope our 
		research helps establish a more fundamental, scientific
		approach toward developing rendering algorithms.",
}

@PhdThesis{Kartch:2000:ERC,
  author =       "Daniel Kartch",
  title =        "Efficient Rendering and Compression for Full-Parallax
                  Computer-Generated Holographic Stereograms",
  school =       "Cornell University",
  year =         "2000",
  abstract =     "In the past decade, we have witnessed a quantum leap in 
                 rendering technology and a simultaneous increase in usage 
                 of computer generated images. Despite the advances made 
                 thus far, we are faced with an ever increasing desire for 
                 technology which can provide a more realistic, more 
                 immersive experience. One fledgeling technology which shows 
                 great promise is the electronic holographic display. 
                 Holograms are capable of producing a fully three-dimensional 
                 image, exhibiting all the depth cues of a real scene, 
                 including motion parallax, binocular disparity, and focal 
                 effects. Furthermore, they can be viewed simultaneously by 
                 any number of users, without the aid of special headgear or 
                 position trackers. However, to date, they have been limited 
                 in use because of their computational intractability. This 
                 thesis deals with the complex task of computing a hologram 
                 for use with such a device. Specifically, we will focus on 
                 one particular type of hologram: the holographic stereogram. 
                 A holographic stereogram is created by generating a large set 
                 of two-dimensional images of a scene as seen from multiple 
                 camera points, and then converting them to a holographic 
                 interference pattern. It is closely related to the light 
                 fields or lumigraphs used in image-based rendering. Most 
                 previous algorithms have treated the problem of rendering 
                 these images as independent computations, ignoring a great 
                 deal of coherency which could be used to our advantage. We 
                 present a new computationally efficient algorithm which 
                 operates on the image set as a whole, rather than on its 
                 individual elements. Scene polygons are mapped by perspective 
                 projection into a four-dimensional space, where they are 
                 scan-converted into 4D color and depth buffers. We use a set 
                 of very simple data structures and basic operations to form 
                 an algorithm which will lend itself well to future hardware 
                 implementation, so as to drive a real-time holographic 
                 display. We also examined issues related to the compression 
                 of stereograms. Holograms contain enormous amounts of data, 
                 which make storage and transmission cumbersome. We have 
                 derived new methods for efficiently compressing this data. 
                 Results compare favorably with existing techniques. Finally, 
                 we describe an algorithm for simulating a camera viewing a 
                 computed hologram from arbitrary positions. It uses wave 
                 optics to track the propagation of light from the hologram, 
                 through a lens, and onto a film plane. This enabled us to 
                 evaluate our rendering and compression methods in the absence 
                 of an electronic holographic display and without the lengthy 
                 processing time of hardcopy holographic printing.",
}

@MastersThesis{Toler:2000:CBA,
  author =       "Corey Theresa Toler",
  title =        "A Computer-based Approach for Teaching Architectural Drawing",
  school =       "Cornell University",
  year =         "2000",
  abstract =     "",
}

@MastersThesis{Hart:2000:DIL,
  author =       "David Augustus Hart",
  title =        "Direct Illumination with Lazy Visibility Evaluation",
  school =       "Cornell University",
  year =         "2000",
  abstract =     "",
}

@MastersThesis{Ramasubramanian:2000:PBP,
  author =       "Mahesh Ramasubramanian",
  title =        "A Perceptually Based Physical Error Metric for Realistic Image Synthesis",
  school =       "Cornell University",
  year =         "2000",
  abstract =     "",
}

@TechReport{Dutre:2000:AVI,
  author =       "Philip Dutre and Parag Tole and Donald P. Greenberg",
  title =        "Approximate Visibility for Illumination Computations
  		  using Point Clouds",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-00-1",
  month =        "Jun",
  year =         "2000",
  abstract =     "",
}

@TechReport{Fernandez:2000:IDL,
  author =       "Sebastian Fernandez and Kavita Bala and
  		  Moreno A. Piccolotto and Donald P. Greenberg",
  title =        "Interactive Direct Lighting in Dynamic Scenes",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-00-2",
  month =        "Jan",
  year =         "2000",
  abstract =     "This paper presents an interactive renderer that computes
		 direct illumination in dynamic scenes with soft shadows and
		 complex BRDFs. The renderer permits the user to both
		 navigate the scene interactively and modify the scene by
		 moving objects, changing materials, and changing lighting
		 conditions.

		 To support interactive viewing, we introduce a visibility
		 caching technique in which the illumination of each patch in
		 the scene is captured by a local illumination environment.
		 This simplified environment enables interactive rendering by
		 accelerating visibility computations.  Since this is an
		 object-space technique, local illumination environments
		 can be reused from frame to frame.

		 To support interactive modification of the scene, we
		 introduce a dynamic visibility algorithm that rapidly
		 identifies which  local illumination environments to update
		 when the scene is modified.  A 5D hierarchy stores
		 illumination dependencies, and permits efficient
		 identification of affected local illumination environments. 

		 These techniques have been implemented in a parallel
		 rendering system that uses a cluster of Intel processors
		 connected on a fast network.  The renderer produces images
		 at interactive rates, achieving speedups of 10 times to 20
		 times over a standard parallelized ray tracer.",
}

@TechReport{Fernandez:2000:SCM,
  author =       "Moreno Piccolotto and Sebastian Fernandez and
		 Kavita Bala and Michael J. Malone and Donald P. Greenberg",
  title =        "A System for 3D Conceptual Modeling for Architectural Design",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-00-3",
  month =        "Jan",
  year =         "2000",
  abstract =     "This paper introduces a novel computer-based system for
		 conceptual architectural design. The system, which is
		 composed of both commercially available software and original
		 routines, has five unique components providing an environment
		 conducive to exploratory creative design.

		 These components include:

		 1. A pen-digitizing tablet with an easy to use user interface
		 with gestural commands.

		 2. Sketching input routines which allow an architect to
		 directly sketch in truly three dimensions.

		 3. Fast, interactive, rendering routines which provide
		 shadows and glossy reflections and allow rendering while
		 modeling.

		 4. The ability to sketch in a virtual world and modify
		 three-dimensional environments interactively.

		 5. A three-dimensional communication space for remote
		 collaboration.

		 Collectively, these routines enable new paradigms for the
		 early stages of the design process. Portions of the system
		 have now been successfully used in teaching an undergraduate
		 architectural design studio.",
}

@InProceedings{Pellacini:2000:TPB,
  author =       "Fabio Pellacini and James A. Ferwerda
  		  and Donald P. Greenberg",
  title =        "Toward a Psychophysically-Based Light Reflection Model
  		  for Image Synthesis",
  booktitle =    "SIGGRAPH 2000 Conference Proceedings",
  editor =       "Kurt Akeley",
  organization = "ACM SIGGRAPH",
  conference =   "New Orleans, LA, July 23-28, 2000",
  series =       "Annual Conference Series",
  month =        jul,
  year =         "2000",
  pages =        "55--64",
  publisher =    "Addison Wesley",
  keywords =     "Three-Dimensional Graphics and REalism, Human Factors,
  		  Experimentation, Light Reflection Models, Gloss,
  		  Visual Perception.",
  abstract =     "In this paper we introduce a new light reflection model for
	   image synthesis based on experimental studies of surface gloss
	   perception. To develop the model, we've conducted two
	   experiments that explore the relationships between the physical
	   parameters used to describe the reflectance properties of glossy
	   surfaces and the perceptual dimensions of glossy appearance. In
	   the first experiment we use multidimensional scaling techniques
	   to reveal the dimensionality of gloss perception for simulated
	   painted surfaces. In the second experiment we use magnitude
	   estimation methods to place metrics on these dimensions that
	   relate changes in apparent gloss to variations in surface
	   reflectance properties. We use the results of these experiments to
	   rewrite the parameters of a physically-based light reflection model
	   in perceptual terms. The result is a new psychophysically-based
	   light reflection model where the dimensions of the model are
	   perceptually meaningful, and variations along the dimensions are
	   perceptually uniform. We demonstrate that the model can
	   facilitate describing surface gloss in graphics rendering
	   applications. This work represents a new methodology for
	   developing light reflection models for image synthesis.",
}

@InProceedings{Pattanaik:2000:TDV,
  author =       "Sumanta N. Pattanaik and Jack Tumblin and Hector Yee 
  		  and Donald P. Greenberg",
  title =        "Time-Dependent Visual Adaptation
 		  for Fast Realistic Display",
  booktitle =    "SIGGRAPH 2000 Conference Proceedings",
  editor =       "Kurt Akeley",
  organization = "ACM SIGGRAPH",
  conference =   "New Orleans, LA, July 23-28, 2000",
  series =       "Annual Conference Series",
  month =        jul,
  year =         "2000",
  pages =        "47--54",
  publisher =    "Addison Wesley",
  keywords =     "Rendering, realistic image display, time course of
  		  adaptation, background intensity, adaptation model.",
  abstract =     "Human vision takes time to adapt to large changes in scene
	intensity, and these transient adjustments have a profound effect on
	visual appearance.  This paper offers a new operator to include these
	appearance changes in animations or interactive real-time simulations,
	and to match a user's visual responses to those the user would
	experience in a real-world scene.
	Large, abrupt changes in scene intensities can cause dramatic
	compression of visual responses, followed by a gradual recovery of
	normal vision. Asymmetric mechanisms govern these time-dependent
	adjustments, and offer adaptation to increased light that is much more
	rapid than adjustment to darkness. We derive a new tone reproduction
	operator that simulates these mechanisms. The operator accepts a stream
	of scene intensity frames and creates a stream of color display images.
	All operator components are derived from published quantitative
	measurements from physiology, psychophysics, color science, and
	photography.  Kept intentionally simple to allow fast computation, the
	operator is meant for use with real-time walk-through renderings, high
	dynamic range video cameras, and other interactive applications. We
	demonstrate its performance on both synthetically generated and
	acquired `real-world' scenes with large dynamic variations of
	illumination and contrast.",
}

@MastersThesis{Yee:2000:SSV,
  author =       "Yang Li Hector Yee",
  title =        "Spatiotemporal Sensitivity and Visual Attention for
		 Efficient Rendering of Dynamic Environments",
  school =       "Cornell University",
  year =         "2000",
  abstract =     "We present a method to accelerate global illumination
		computation in dynamic environments by taking advantage of
		limitations of the human visual system. A model of visual
		attention is used to locate regions of interest in a scene
		and to modulate spatiotemporal sensitivity. The method is
		applied in the form of a spatiotemporal error tolerance map.
		Perceptual acceleration combined with good sampling protocols
		provide a global illumination solution feasible for use in
		animation. Results indicate an order of magnitude improvement
		in computational speed. The method is adaptable and can also
		be used in image-based rendering, geometry level of detail
		selection, realistic image synthesis, video telephony and
		video compression.",
}

@InProceedings{Fernando:2001:ASM,
  author =       "Randima Fernando and Sebastian Fernandez and Kavita Bala and
  Donald P. Greenberg",
  title =        "Adaptive Shadow Maps",
  booktitle =    "SIGGRAPH 2001 Conference Proceedings",
  editor =       "Eugene Fiume",
  organization = "ACM SIGGRAPH",
  conference =   "Los Angeles, CA, August 12-17, 2001",
  series =       "Annual Conference Series",
  month =        aug,
  year =         "2001",
  pages =        "",
  publisher =    "Addison Wesley",
  keywords =     "Rendering, Shadow Algorithms.",
  abstract =     "Shadow maps provide a fast and convenient method of
		 identifying shadows in scenes but can introduce aliasing.
		 This paper introduces the Adaptive Shadow Map (ASM) as a
		 solution to this problem. An ASM removes aliasing by
		 resolving pixel size mismatches between the eye view and the
		 light source view. It achieves this goal by storing the light
		 source view (i.e., the shadow map for the light source) as a
		 hierarchical grid structure as opposed to the conventional
		 flat structure. As pixels are transformed from the eye view
		 to the light source view, the ASM is refined to create
		 higher-resolution pieces of the shadow map when needed. This
		 is done by evaluating the contributions of shadow map pixels
		 to the overall image quality. The improvement process is
		 view-driven, progressive, and confined to a user-specifiable
		 memory footprint. We show that ASMs enable dramatic
		 improvements in shadow quality while maintaining interactive
		 rates.",
}

@Article{Marschner:2000:IBB,
  author =       "Stephen R. Marschner and Stephen H. Westin and
  		 Eric P. F. Lafortune and Kenneth E. Torrance",
  title =        "Image-Based Bidirectional Reflectance Distribution
		 Function Measurement",
  journal =      "Applied Optics-OT",
  volume =       "39",
  number =       "16",
  month =        jun,
  year =         "2000",
  pages =        "2592--2600",
  abstract =     "We present a new image-based process for measuring a
  		 surface's bidirectional reflectance distribution rapidly,
  		 completely, and accurately.  Requiring only two cameras, a
  		 light source, and a test sample of known shape, our method
  		 generates densely spaced samples covering a very large
  		 domain of illumination and reflection directions.  We have
  		 verified our measurements both by tests of internal
  		 consistency and by comparison against measurements made
  		 using a gonioreflectometer.  The resulting data show accuracy
  		 rivaling that of custom-built dedicated instruments.",
}

@Article{Yee:2001:SSV,
  author =       "Hector Yee and Sumanta Pattanaik and Donald P. Greenberg",
  title =        "Spatiotemporal Sensistivity and Visual Attention for
		 Efficient Rendering of Dynamic Environments",
  journal =      "ACM Transactions on Graphics",
  volume =       "20",
  number =       "1",
  month =        jan,
  year =         "2001",
  pages =        "",
  abstract =     "We present a method to accelerate global illumination
		 computation in prerendered animations by taking advantage
		 of limitations of the human visual system. A spatiotemporal
		 error tolerance map, constructed from psychophysical data
		 based on velocity dependent contrast sensitivity, is used
		 to accelerate rendering. The error map is augmented by a
		 model of visual attention in order to account for the
		 tracking behavior of the eye. Perceptual acceleration
		 combined with good sampling protocols provide a global
		 illumination solution feasible for use in animation. Results
		 indicate an order of magnitude improvement in computational
		 speed.",
}

@InProceedings{Dumont:2001:PBT,
  author =       "Reynald Dumont and Fabio Pellacini and James A. Ferwerda",
  title =        "A Perceptually-Based Texture Caching Algorithm
		 for Hardware-Based Rendering",
  booktitle =    "Eurographics Workshop on Rendering",
  conference =   "held in London, England; 25-27 June 2001",
  year =         "2001",
  pages =        "",
  abstract =     "The performance of hardware-based interactive rendering
  		 systems is often constrained by polygon fill rates and
  		 texture map capacity, rather than polygon count alone. We
  		 present a new software texture caching algorithm that
  		 optimizes the use of texture memory in current graphics
  		 hardware by dynamically allocating more memory to the
  		 textures that have the greatest visual importance in the
  		 scene. The algorithm employs a resource allocation scheme
  		 that decides which resolution to use for each texture in
  		 board memory. The allocation scheme estimates the visual
  		 importance of textures using a perceptually-based metric
  		 that takes into account view point and vertex illumination
  		 as well as texture contrast and frequency content.  This
  		 approach provides high frame rates while maximizing image
  		 quality.",
}

@MastersThesis{Levy:2002:SVD,
  author =       "Richard Levy",
  title =        "A scalable Visualization Display Wall Presentation System
		  For Cluster-Based Computing",
  school =       "Cornell University",
  year =         "2002",
  abstract =     "",
}

@MastersThesis{Berman:2002:HAS,
  author =       "Steven Berman",
  title =        "Hardware-Accelerated Sort-Last Parallel Rendering For PC
                  Clusters",
  school =       "Cornell University",
  year =         "2002",
  abstract =     "",
}

@MastersThesis{Fernando:2002:ATH,
  author =       "Randima Fernando",
  title =        "Adaptive Techniques for hardware Shadow Generation",
  school =       "Cornell University",
  year =         "2002",
  abstract =     "This  thesis presents two adaptive algorithms for shadow generation. 
Both algorithms
  utilize  commercial  graphics  hardware  to  accelerate  the  rendering 
process. The first algorithm, called Adaptive Shadow Maps, deals with removing
  the  aliasing  artifacts  that  typically  result when  using  shadow maps  for 
hard shadow generation.  It achieves this by varying the shadow map resolution
 spatially  throughout  the scene based on  the eye position. The second algorithm,
 called Adaptive Soft Shadows, attempts to generate soft shadows efficiently
 by varying the number of samples needed over the different regions 
of the scene. More samples are devoted to soft shadow regions that subtend a 
large  portion  of  the  image  plane,  and  fewer  samples  are  devoted  to  hard 
shadow regions.  
 
We show that Adaptive Shadow Maps enable dramatic improvements  in 
shadow quality while maintaining interactive rates and being constrained to a 
user-specified memory limit. In the case of Adaptive Soft Shadows, we examine
 the reasons why the approach was not as successful as we had envisioned 
and discuss possible avenues for improvement. The motivation for each algorithm
  is presented  along with  the  corresponding  theoretical  foundation,  implementation,
 results, conclusions, and directions for improvement.  ",
}

@InProceedings{Interrante:1999:HCG,
  author =       "Victoria Interrante and Daniel Kersten and David
                 Brainard and Heinrich H. Buelthoff and James A.
                 Ferwerda and Pawan Sinha",
  title =        "How to cheat and get away with it: what computer
                 graphics can learn from perceptual psychology",
  editor =       "{ACM}",
  booktitle =    "{SIGGRAPH} 99. Proceedings of the 1999 {SIGGRAPH}
                 annual conference: Conference abstracts and
                 applications",
  publisher =    "ACM Press",
  address =      "New York, NY 10036, USA",
  year =         "1999",
  ISBN =         "0-201-48560-5",
  ISSN =         "1069-529X",
  series =       "Computer Graphics",
  pages =        "119--121",
  bibdate =      "Mon Oct 4 10:35:34 MDT 1999",
  url =          "http://www.acm.org/pubs/citations/proceedings/graph/311625/p119-interrante/",
  acknowledgement = ack-nhfb,
}

@InProceedings{EVL-2001-101,
  pages =        "141--148",
  year =         "2001",
  title =        "Lightning-2: {A} High-Performance Display Subsystem
                 for {PC} Clusters",
  url =          "http://visinfo.zib.de/EVlib/Show?EVL-2001-101",
  author =       "Gordon Stoll and Matthew Eldridge and Dan Patterson
                 `and Art Webb and Steven Berman and Richard Levy and
                 Chris Caywood and Milton Taveira and Stephen Hunt and
                 Pat Hanrahan",
  abstract =     "Clusters of PCs are increasingly popular as
                 cost-effective platforms for supercomputer-class
                 applications. Given recent performance improvements in
                 graphics accelerators, clusters are similarly
                 attractive for demanding graphics applications. We
                 describe the design and implementation of Lightning-2,
                 a display subsystem for such a cluster. The system
                 scales in both the number of rendering nodes and the
                 number of displays supported, and allows any pixel data
                 generated from any node to be dynamically mapped to any
                 location on any display. A number of image-compositing
                 functions are supported, including color-keying and
                 depth-compositing. A distinguishing feature of the
                 system is its platform independence: it connects to
                 graphics accelerators via an industry-standard digital
                 video port and requires no modifications to accelerator
                 hardware or device drivers. As a result, rendering
                 clusters that utilize Lightning-2 can be upgraded
                 across multiple generations of graphics accelerators
                 with little effort. We demonstrate a renderer that
                 achieves 106 Mtri/s on an 8-node cluster using
                 Lightning-2 to perform sort-last depth compositing.",
  editor =       "Eugene Fiume",
  keywords =     "Graphics Hardware, Graphics Systems, Parallel
                 Computing, Rendering Hardware, Rendering Systems",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2001, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH",
}

@InProceedings{EVL-2001-128,
  pages =        "387--390",
  year =         "2001",
  title =        "Adaptive Shadow Maps",
  url =          "http://visinfo.zib.de/EVlib/Show?EVL-2001-128",
  author =       "Randima Fernando and Sebastian Fernandez and Kavita
                 Bala and Donald P. Greenberg",
  abstract =     "Shadow maps provide a fast and convenient method of
                 identifying shadows in scenes but can introduce
                 aliasing. This paper introduces the Adaptive Shadow Map
                 (ASM) as a solution to this problem. An ASM removes
                 aliasing by resolving pixel size mismatches between the
                 eye view and the light source view. It achieves this
                 goal by storing the light source view (i.e., the shadow
                 map for the light source) as a hierarchical grid
                 structure as opposed to the conventional flat
                 structure. As pixels are transformed from the eye view
                 to the light source view, the ASM is refined to create
                 higher-resolution pieces of the shadow map when needed.
                 This is done by evaluating the contributions of shadow
                 map pixels to the overall image quality. The
                 improvement process is view-driven, progressive, and
                 confined to a user-specifiable memory footprint. We
                 show that ASMs enable dramatic improvements in shadow
                 quality while maintaining interactive rates.",
  editor =       "Eugene Fiume",
  keywords =     "Rendering, Shadow Algorithms",
  series =       "Annual Conference Series",
  booktitle =    "SIGGRAPH 2001, Computer Graphics Proceedings",
  publisher =    "ACM Press / ACM SIGGRAPH",
}

@InProceedings{Dutre01-AGI*,
  author =       "Philip Dutre and Kavita Bala",
  month =        aug,
  year =         "2001",
  title =        "Advanced Global Illumination",
  booktitle =    "{SIGGRAPH} 2001 Course Notes {CD}-{ROM}",
  note =         "Course 20",
  publisher =    "ACM SIGGRAPH",
  organization = "Association for Computing Machinery",
}

@Article{Trumblin:2001:GEI,
  author =       "Jack Trumblin and James A. Ferwerda",
  title =        "{Guest Editors'} Introduction: Applied Perception",
  journal =      "IEEE Computer Graphics and Applications",
  volume =       "21",
  number =       "5",
  pages =        "20--21",
  month =        sep # "\slash " # oct,
  year =         "2001",
  abstract =	"           
	          ",

  coden =        "ICGADZ",
  ISSN =         "0272-1716",
  bibdate =      "Thu Jan 31 16:01:50 MST 2002",
  url =          "http://dlib.computer.org/cg/books/cg2001/g5020abs.htm;
                 http://dlib.computer.org/cg/books/cg2001/pdf/g5020.pdf",
  acknowledgement = ack-nhfb,
}

@Article{Ferwerda:2001:EEV,
  author =       "James A. Ferwerda",
  title =        "Elements of Early Vision for Computer Graphics",
  journal =      "IEEE Computer Graphics and Applications",
  volume =       "21",
  number =       "5",
  pages =        "22--33",
  month =        sep # "\slash " # oct,
  year =         "2001",
  abstract = 	"Over the past decade, visually based techniques in computer 
		graphics have blossomed. Important advances in perceptually
		driven rendering, realistic image display, high fidelity 
		visualization, and appearance-preserving geometric 
		simplification have all been realized by applying knowledge of
		the limitations and capabilities of human visual processing. 
		Much of this work is grounded in the physiology and 
		psychophysics of early vision, which focuses on how visual 
		mechanisms transduce and code the patterns of light arriving at 
		the eye. This tutorial surveys some of the fundamental findings 
		in the study of early vision including basic visual anatomy and
		physiology, optical properties of the eye, light sensitivity 
		and visual adaptation, and spatial vision.",
  coden =        "ICGADZ",
  ISSN =         "0272-1716",
  bibdate =      "Thu Jan 31 16:01:50 MST 2002",
  url =          "http://dlib.computer.org/cg/books/cg2001/g5022abs.htm;
                 http://dlib.computer.org/cg/books/cg2001/pdf/g5022.pdf",
  acknowledgement = ack-nhfb,
}

@InProceedings{Ferwerda:2001:PMS,
  pages =        "291--301",
  year =         "2001",
  title =        "A psychophysically-based model of surface gloss perception",
  booktitle =	"Proceedings SPIE Human Vision and Electronic Imaging '01",
  author =       "James A. Ferwerda and Fabio Pellacini 
                 and Donald P. Greenberg",
  abstract =     "In this paper we introduce a new model of surface appearance 
		that is based on quantitative studies of gloss perception. We
		use image synthesis techniques to conduct experiments that 
		explore the relationships between the physical dimensions of
		glossy reflectance and the perceptual dimensions of glossy 
		appearance. The product of these experiments is a
		psychophysically-based model of surface gloss, with dimensions 
		that are both physically and perceptually meaningful and
		scales that reflect our sensitivity to gloss variations. We 
		demonstrate that the model can be used to describe and control 
		the 
		appearance of glossy surfaces in synthetic images, allowing 
		prediction of gloss matches and quantification of gloss
		differences. This work represents some initial steps toward 
		developing psychophysical models of the goniometric aspects
		of surface appearance to complement widely-used colorimetric 
		models.",
}

@InProceedings{Tole:2002:IGI,
  author =       "Parag Tole and Fabio Pellacini and Bruce Walter
  		  and Donald P. Greenberg",
  title =        "Interactive Global Illumination in Dynamic Scenes",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  editor =       "John F. Hughes",
  organization = "ACM SIGGRAPH",
  conference =   "San Antonio, Texas, 21-26 July 2002",
  series =       "Annual Conference Series",
  month =        "July",
  year =         "2002",
  pages =        "537--546",
  abstract =     "In this paper, we present a system for interactive computation of
	global illumination in dynamic scenes. Our system uses a novel
	scheme for caching the results of a high quality pixel-based renderer
	such as a bidirectional path tracer. The Shading Cache is an objectspace
	hierarchical subdivision mesh with lazily computed shading
	values at its vertices. A high frame rate display is generated from
	the Shading Cache using hardware-based interpolation and texture
	mapping. An image space sampling scheme refines the Shading
	Cache in regions that have the most interpolation error or those that
	are most likely to be affected by object or camera motion.
	Our system handles dynamic scenes and moving light sources
	efficiently, providing useful feedback within a few seconds and
	high quality images within a few tens of seconds, without the need
	for any pre-computation. Our approach allows us to significantly
	outperform other interactive systems based on caching ray-tracing
	samples, especially in dynamic scenes. Based on our results, we
	believe that the Shading Cache will be an invaluable tool in lighting
	design and modelling while rendering.",
}
@InProceedings{Pellacini:2002:UII,
  author =       "Fabio Pellacini and Parag Tole and Donald P. Greenberg",
  title =        "A User Interface for Interactive Cinematic Shadow Design",
  booktitle =    "SIGGRAPH 2002 Conference Proceedings",
  editor =       "John F. Hughes",
  organization = "ACM SIGGRAPH",
  conference =   "San Antonio, Texas, 21-26 July 2002",
  series =       "Annual Conference Series",
  month =        "July",
  year =         "2002",
  pages =        "563--566",
  abstract =     "Placing shadows is difficult task since shadows depend on the 
	relative positions of lights and objects in an unintuitive manner. 
	To simplify the task of the modeler, we present a user interface 
	for designing shadows in 3d environments.  In our interface, 
	shadows are treated as first-class modeling primitives just like 
	objects and lights. To transform a shadow, the user can simply 
	move, rescale or rotate the shadow as if it was a 2d object on the 
	scene's surfaces. 

	When the user transforms a shadow, the system moves lights or 
	objects in the scene as required and updates the shadows in 
	realtime during mouse movement. To facilitate interaction, the 
	user can also specify constraints that the shadows must obey, such 
	as never casting a shadow on the face of a character. These 
	constraints are then verified in real-time, limiting mouse 
	movement when necessary. We also integrate in our interface fake 
	shadows typically used in computer animation. This allows the 
	user to draw shadowed and non-shadowed regions directly on 
	surfaces in the scene.",

}

@MastersThesis{Selan:2003:MLV,
  author =       "Jeremy Adam Selan",
  title =        "Merging Live Video with Synthetic Imagery",
  school =       "Cornell University",
  year =         "2003",
  abstract =     "Merging live action and synthetic imagery in a realistic manner is becoming increasingly important, and has become ubiquitous to filmmaking and television. However, current techniques to merge live and synthetic imagery typically generate low-quality images in real-time, or high-quality results though off-line processes. Being able to realistically merge live and synthetic imagery in real-time would generate many new applications, particularly in the virtual set, augmented reality, military, and entertainment industries.

This thesis presents a framework for the realistic, real-time merging of live action with synthetic imagery by analyzing the three major components of the process. First, we maintain the necessity of utilizing synthetic imagery that mimics the visual complexity of the real world. Second, we demonstrate that attention must be spent on acquiring live action that is visually compatible with the synthetic imagery, with the emphasis on matching specific illumination characteristics.  Finally, we propose the use of a compositing mechanism that accounts for the missing visual interaction between the live and synthetic components, including occlusion, shadowing, and reflection.

We present the real-time implementation of two virtual set systems that adhere to these principles. An image-based renderer generates realistic imagery in limited interaction environments, while a software-based ray-engine simulates physically based, dynamic environments. The live and synthetic environmental illumination is matched by manipulating the histogram characteristics of the live video. Finally, we implement a compositing system that accounts for the visual interactions between the live and synthetic imagery, synthesizing inter-reflections and shadows using a silhouette reprojection technique.
",
}

@PhdThesis{Pellacini:2002:PBD,
  author =       "Fabio Pellacini",
  title =        "A Perceptually-Based Decision Theoretic Framework for Interactive Rendering",
  school =       "Cornell University",
  year =         "2002",
  abstract =     "",
}

@PhdThesis{Tole:2003:TAP,
  author =       "Parag Prabhakar Tole",
  title =        "Two Algorithms for Progressive Computation of Accurate Global Illumination",
  school =       "Cornell University",
  year =         "2003",
  abstract =     "",
}

@MastersThesis{Fu:2002:IVE,
  author =       "SuAnne Fu",
  title =        "The Impossible Vase: An Exploration In Perception",
  school =       "Cornell University",
  year =         "2002",
  abstract =     "The Impossible Vase is a digital installation
                combining elements of perception
                and computer graphics to create a unique
                visual experience through light
                projection. The projected images are cast
                upon solid objects rather than a
                traditional flat canvas. This installation
                will explore perceptual issues by
                deconstructing visual cues and analyzing
                the way our minds process visual
                information into a coherent story. The
                projected imagery, along with the
                movement of the three dimensional canvas,
                will create physical
                impossibilities to demonstrate when and
                where our perceptual process
                collapses. During these isolated moments,
                we can then analyze the
                paramount elements contributing to our minds'
                interpretation of a cohesive
                image and draw a correlation that may
                be applied to computer graphics.",
}

@InProceedings{Walter:2002:UPT,
  author =       "Bruce Walter and Sumant Pattanaik
                  and Donald P. Greenberg",
  title =        "Using Perceptual Texture Masking for Efficient Image
                  Synthesis",
  booktitle =    "EUROGRAPHICS 2002 Conference Proceedings",
  editor =       "G. Drettakis and H.-P. Seidel",
  organization = "The Eurographics Association",
  conference =   "Computer Graphics Forum",
  month =        Sep,
  year =         "2002",
  volume =      "21(3)",
  keywords =    "Visual Perception and Perceptual Rendering and Texture
                Mapping and JPEG",
  publisher =   "Blackwell Publishers",
  abstract =     "Texture mapping has become indispensable in image synthesis
                as an inexpensive source of rich visual detail. Less
                obvious, but just as useful, is its ability to mask image
                errors due to inaccuracies in geometry or lighting. This
                ability can be used to substantially accelerate rendering by
                eliminating computations when the resulting errors
                will be perceptually insignificant.

                Our new method precomputes the masking ability of textures
                using aspects of the JPEG image compression standard.
                This extra information is stored as threshold elevation
                factors in the texture's mip-map and interpolated
                at image generation time as part of the normal texture lookup
                process. Any algorithm which uses error tolerances
                or visibility thresholds can then take advantage of texture
                masking. Applications to adaptive shadow testing,
                irradiance caching, and path tracing are demonstrated.

                Unlike prior methods, our approach does not require that
                initial images be computed before masking can be
                exploited and incurs only negligible runtime computational
                overhead. Thus, it is much easier to integrate with
                existing rendering systems for both static and dynamic scenes
                and yields computational savings even when only
                small amounts of texture masking are present.",
}

@InProceedings{Walter:2002:EOR,
  author =       "Bruce Walter and George Drettakis and Donald P. Greenberg",
  title =        "Enhancing and Optimizing the Render Cache",
  booktitle =    "Eurographics Workshop on Rendering",
  editor =      "P. Debevec and S. Gibson",
  conference =   "Thirteenth Eurographics Workshop on Rendering",
  year =         "2002",
  keywords =    "Display algorithms",
  publisher =   "Springer-Verlag",
  abstract =     "Interactive rendering often requires the use of simplified
                shading algorithms with reduced illumination fidelity.
                Higher quality rendering algorithms are usually too slow for
                interactive use. The render cache is a technique
                to bridge this performance gap and allow ray-based renderers
                to be used in interactive contexts by providing
                automatic sample interpolation, frame-to-frame sample
                reuse, and prioritized sampling.
                In this paper we present several extensions to the original
                render cache including predictive sampling, reorganized
                computation for better memory coherence, an additional
                interpolation filter to handle sparser data, and SIMD
                acceleration. These optimizations allow the render cache to
                scale to larger resolutions, reduce its visual artifacts,
                and provide better handling of low sample rates. We also
                provide a downloadable binary to allow researchers to
                evaluate and use the render cache.",
}

@InProceedings{Fernandez:2002:LIE,
  author =       "Sebastian Fernandez and Kavita Bala and
                Donald P. Greenberg",
  title =        "Local Illumination Environments for Direct Lighting
                Acceleration",
  booktitle =    "Eurographics Workshop on Rendering",
  editor =      "P. Debevec and S. Gibson",
  conference =   "Thirteenth Eurographics Workshop on Rendering",
  year =         "2002",
  publisher =   "Springer-Verlag",
  pages =        "",
  abstract =     "Computing high-quality direct illumination in scenes with 
                many lights is an open area of research. This paper
                presents a world-space caching mechanism called local
                illumination environments that enables interactive direct
                illumination in complex scenes on a cluster of off-the-shelf
                PCs.

                A local illumination environment (LIE) caches geometric and
                radiometric information related to direct illumination.
                A LIE is associated with every octree cell constructed over
                the scene. Each LIE stores a set of visible lights,
                with associated occluders (if they exist). LIEs are effective
                at accelerating direct illumination because they both
                eliminate shadow rays for fully visible and fully occluded
                regions of the scene, and decrease the cost of shadow
                rays in other regions. Shadow ray computation for the
                partially occluded regions is accelerated using the cached
                potential occluders. One important implication of storing
                occluders is that rendering is accelerated while producing
                accurate hard and soft shadows. This paper also describes a
                simple perceptual metric based on Weber's law
                that further improves the effectiveness of LIEs in the fully
                visible and partially occluded regions.
                LIE construction is view-driven, continuously refined, and
                asynchronous with the shading process. In complex
                scenes of hundreds of thousands of polygons with up to a
                hundred lights, the LIEs improve rendering performance
                by 10x to 30x over a traditional ray tracer.",
}

@InProceedings{Bala:2003:CEP,
  author =       "Kavita Bala and Bruce Walter and Donald P. Greenberg",
  title =        "Combining Edges and Points for Interactive High-Quality
                Rendering",
  booktitle =    "SIGGRAPH 2003 Conference Proceedings",
  editor =       "Jessica Hodgins",
  organization = "ACM SIGGRAPH",
  conference =   "San Diego, California, 27-31 July 2003",
  publisher =   "ACM SIGGRAPH",
  series =       "Annual Conference Series",
  month =        jul,
  year =         "2003",
  abstract =     "This paper presents a new interactive
                rendering and display technique
                for complex scenes with expensive shading, such as global
                illumination. Our approach combines sparsely sampled shading
                (points) and analytically computed
                discontinuities (edges) to interactively
                generate high-quality images. The edge-and-point image is
                a new compact representation that combines edges and points such
                that fast, table-driven interpolation
                of pixel shading from nearby
                point samples is possible, while respecting discontinuities.
                The edge-and-point renderer is extensible, permitting the use of
                arbitrary shaders to collect shading samples.
                Shading discontinuities,
                such as silhouettes and shadow edges, are found at interactive
                rates. Our software implementation
                supports interactive navigation
                and object manipulation in scenes that
                include expensive lighting
                effects (such as global illumination)
                and geometrically complex objects.
                For interactive rendering we show that high-quality images of
                these scenes can be rendered at 8-14 frames per second
                on a desktop
                PC: a speedup of 20-60 over a ray tracer computing a single
                sample per pixel.",
}

@InProceedings{Ismert:2003:DSI,
  author =       "Ryan Ismert and Kavita Bala and Donald P. Greenberg",
  title =        "Detail Synthesis for Image-based Texturing",
  booktitle =    "ACM SIGGRAPH 2003 Symposium on Interactive 3D Graphics",
  organization = "ACM SIGGRAPH",
  conference =   "28 - 30 April 2003, Monterey, California",
  month =        apr,
  year =         "2003",
  pages =        "171--176",
  abstract =     "Image-based modeling techniques
                permit the creation of visually
                interesting geometric models from
                photographs. But traditional
                image-based texturing (IBT)
                techniques often result in extracted
                textures of poor, uneven quality.
                This paper introduces a novel technique
                to improve the quality of
                image-based textures. We compute
                a simple and efficient texture
                quality metric based on the Jacobian
                of the imaging transform. We
                identify the correlation between the
                values of the Jacobian metric
                and the levels of an image pyramid,
                allowing us to formulate a novel
                texture synthesis approach which
                operates over textures from 3D
                surfaces in a scene. Our technique
                allows the creation of uniform,
                high-resolution textures, relieving
                the user of the burden of collecting
                large numbers of images while
                increasing the visual quality of
                image-based models. This improved
                quality is important to create compelling
                visual experiences in interactive environments.",
}

@MastersThesis{Ismert:2003:PSM,
  author =       "Ryan McCloud Ismert",
  title =        "A physical sampling metric for image-based computer graphics",
  school =       "Cornell University",
  month =       jan,
  year =         "2003", 
  abstract =     "Computer models of the real world 
                often use images of the environment to
                capture realistic visual complexity.
                Image-based modeling techniques permit the
                creation of geometric models with a high
                level of visual detail from photographs.
                These models are textured by resampling
                these images of the scene; we call this
                process image-based texturing. The problem
                with traditional image-based texturing
                is the poor quality of the extracted textures,
                which are often blurred or stretched
                due to sampling problems. Furthermore,
                the extent of this degradation varies
                across the scene, due to differences
                in the pose and position of the camera relative
                to each object in each image.
  
                This thesis makes two contributions to
                image-based computer graphics. First,
                it introduces a physically-based metric
                of sampling quality, based on the Jacobian
                matrix of the imaging transform, which 
                captures the interaction of the imaging
                system with the imaged environment. This 
                metric provides a direct, physical
                measure of the quality of resampled textures,
                and suggests a physical interpretation
                of the multi-resolution image representations
                widely used in texture synthesis. The
                second contribution, which builds on this
                insight, is a novel use of the metric for
                extending current texture synthesis methods
                to image-based texturing processes.
                Use of the sampling metric enables detail
                synthesis - the insertion of high spatial
                frequency detail into regions of an
                image-based model's textures where the imaging
                process captures only low frequency texture
                data. Given a small set of input images
                and a geometric model of the scene, this
                technique allows the creation of uniform,
                high-resolution textures. Our synthesis
                approach relieves the user of the burden of
                collecting large numbers of images and
                increases the quality of user-driven image-
                based modeling systems. The research described
                in this thesis allows both the
                quantification of sampling effects in
                image-based computer graphics systems, as
                well as the correction of degradation
                in image-based textures.

                The sampling metric introduced in this
                thesis has usefulness far outside the
                image-based texturing application demonstrated
                here. Such a metric will have a
                potential impact in the fields of
                vision-based geometric reconstruction, material
                measurement, image-based rendering, and
                geometric level-of-detail management.
                The goal of this thesis is merely to introduce
                the metric and validate its usefulness
                for one critical application.",
}
@TechReport{Bala:2002:CEP,
  author =       "Kavita Bala and Bruce Walter and Donald P. Greenberg",
  title =        "Combining Edges and Points for Interactive 
			Anti-Aliased Rendering",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-02-3",
  month =        "Jan",
  year =         "2002",
  abstract =     "This paper presents a new rendering and display
		 	paradigm that uses both discontinuities (edges) 
			and sparsely sampled shading (points) to 
			interactively generate anti-aliased images of 
			complex scenes. Geometric and shadow 
			discontinuities in the image are found at
			interactive rates using a novel data structure, 
			the Normal-Position Interval tree, and algorithms 
			based on interval arithmetic. After projecting 
			discontinuities on to the image plane, shading 
			information is interpolated from nearby point 
			samples called the edge-and-point image. An 
			efficient interpolation algorithm uses this 
			image to generate anti-aliased output images 
			at interactive rates without using supersampling.

			Our rendering technique is extensible, permitting 
			the use of arbitrary shaders to collect radiance 
			samples. Our software implementation supports 
			interactive navigation and object manipulation 
			in scenes that include complex lighting effects 
			(such as global illumination) and geometrically 
			complex objects. WE show that high-quality anti-
			aliased images of these scenes can be rendered 
			at several frames per second on typical desktop 
			machines.",
}

@MastersThesis{Mollis:2004:AGH,
  author =       "John Crane Mollis",
  title =        "REAL-TIME HARDWARE BASED TONE REPRODUCTION",
  school =       "Cornell University",
  month =       jan,
  year =         "2004", 
  abstract =     " The human visual system is exposed to a vast range of illumination conditions,
far greater than any display device can reproduce, and its response to these conditions
varies greatly. To create an immersive impression and accurate portrayal of a scene
on a computer monitor requires complex modeling of visual response through tone
reproduction algorithms and the simulation of adaptation effects in real-time.
However, all current tone reproduction operators are off-line and address only a
portion of the visual phenomena necessary for completeness, thereby limiting their
applicability. A mostly unexplored problem is how perceptually accurate and full
featured tone reproduction can be incorporated into interactive applications where
visual effects will be dynamic and often very dramatic. Previous work in this area has
been constrained with respect to the generality of tone reproduction models used, the
scope of available input and the hardware output performance.


The aim of this thesis is two-fold. First, we create a real-time tone
reproduction operator that includes as many phenomena as possible and is based upon
psychophysical data. This requires a combination and extension of the best operators
for predictive tone mapping and significant acceleration using current commodity
graphics hardware. Care is taken to not restrict available input or compromise the
predictive nature of the operator through artificial approximations. The result is a
widely applicable, fast and comprehensive operator with applications in lighting
engineering, architectural walkthroughs, flight and car simulators, entertainment and
due to it's predictive nature, low vision simulation.

The second aim of this thesis is to use our perceptually based operator to
construct a low vision simulation tool for evaluating real or simulated environments
for suitability with older individuals.

",
}

@PhdThesis{Fernandez:2004:IDI,
  author =       "Sebastian Pablo Fernandez",
  title =        "Interactive Direct Illumination in Complex Environments",
  school =       "Cornell University",
  month =       "June",
  year =         "2004",
  abstract =     "Modeling the interaction of light with real-world environments is a
difficult problem. In particular, the geometric and lighting
complexity required to approximate reality are huge challenges.  The
``Ray Tracing'' algorithm is well-suited to deal with geometric
complexity since its performance is sub-linear in the number of
geometric primitives.  However, its computational cost is linear in
the number of light sources. This leads to poor performance in
environments with complex lighting.

In this thesis we present two algorithms that accelerate the rendering
of direct lighting for complex environments within the context of a
ray tracer. The first algorithm, ``Local Illumination Environments''
addresses direct lighting acceleration in scenes with up to a few dozen
light sources. The second algorithm, ``Hierarchical Light Clusters''
accelerates direct lighting in models with hundreds to thousands of
light sources.

The ``Local Illumination Environments'' algorithm reduces the cost of
computing light visibility, the most expensive part of the direct
lighting computation. It does so through an asynchronous process that
caches, in a spatial data structure, the geometric primitives required
to evaluate light visibility. This approach completely eliminates the
cost of light visibility for fully visible and fully occluded light 
sources. It also substantially reduces the time to evaluate visibility from
partially visible light sources by eliminating the cost of a traditional
acceleration structure.

The ``Hierarchical Light Clusters'' algorithm reduces direct lighting
computation in environments with very large numbers of light sources. 
This is done by using a single bright light to approximate the contribution
of a group of lights. We present a locally adaptive technique that determines
when this approximation is valid. We also introduce three algorithms
that make use of this approach to provide varying levels of quality and
performance. 

``Local Illumination Environments'' and ``Hierarchical Light
Clusters'' both provide order-of-magnitude acceleration in the
computation of direct lighting over traditional ray tracing
approaches. Together, they can be used to interactively generate
images of models of widely varying geometric and lighting complexity.",
}

@InProceedings{Ramanarayanan:2004:FBT,
  author =       "Ganesh Ramanarayanan and Kavita Bala and Bruce Walter",
  title =        "Feature-Based Textures",
  editor =       "H. W. Jensen and A. Keller",
  booktitle =    "Eurographics Workshop on Rendering",
  conference =   "Fifteenth Eurographics Workshop on Rendering",
  year =         "2004",
  abstract =     "This paper introduces feature-based textures, a new image representation 
that combines features and samples for high-quality texture mapping. Features identify 
boundaries within an image where samples change discontinuously. They can be extracted from 
vector graphics representations, or explicitly added to raster images to improve sharpness. 
Texture lookups are then interpolated from samples while respecting these boundaries. We 
present results from a software implementation of this technique demonstrating quality, 
efficiency and low memory overhead.",
}

@MastersThesis{Letteron:2004:PHO,
  author =       "Henry H. Letteron",
  title =        "Polyhedral Hull Online Compositing System: Reconstruction and Shadowing",
  school =       "Cornell University",
  month =        "August",
  year =         "2004",
  abstract =     "A fundamental limitation of traditional two-dimensional compositing is that it
lacks the spatial information necessary for realistically merging live video with
simulated environments. We introduce a novel three-dimensional compositing system
that leverages multiple camera viewpoints to generate a geometric model of
the foreground object. The foreground object can then be merged with a virtual
background environment in three-space. Using the three-dimensional definitions
of the foreground and background geometries, we correctly handle occlusions and
generate physically-based global illumination effects, including shadows and interreflections.
Knowledge of the scene structure also removes the fixed camera constraint
of 2D systems, and we allow the viewer to specify an arbitrary camera
To demonstrate the feasibility of interactive 3D compositing, we have built a
prototype system. Our system consists of four video cameras, four client computers
to perform the image processing operations, and a server that executes the reconstruction
algorithm, computes the global illumination effects, and generates the
final rendered image. Both the reconstruction of the foreground geometry and the
scene compositing occur in real-time, allowing our hardware and software system
to merge live interactive video content with virtual worlds.
This thesis focuses on the geometric reconstruction and shadowing algorithms
used in our system. We compute the intersection of the silhouette cones from
multiple cameras to calculate a polyhedral hull of the foreground geometry. We
implement a shadow generation technique based on the penumbra map algorithm,
and by leveraging the computational power of the GPU, we simulate soft shadows
in hardware. Our system is capable of reconstructing geometry and casting
believable shadows onto the surrounding environment at interactive frame rates.
",
}


@MastersThesis{Stokes:2004:PIC,
  author =       "William Adams Stokes",
  title =        "Perceptual Illumination Components: A New Approach to Efficient, 
                    High-Quality Global Illumination Rendering",
  school =       "Cornell University",
  month =        "August",
  year =         "2004",
  abstract =     "We introduce a new perceptual metric for efficient, high quality, global illumination
rendering. The metric is based on a rendering-by-components framework in which
the direct, and indirect diffuse, glossy, and specular light transport paths are separately
computed and then composited to produce a high quality image. The metric predicts
the perceptual importances of the computationally expensive indirect illumination components
with respect to image quality. To develop the metric we conducted a series of
psychophysical experiments in which we measured and modeled the perceptual importances
of the components. An important property of this new metric is that it predicts
component importances from inexpensive estimates of the reflectance properties of a
scene, and therefore adds negligible overhead to the rendering process. This perceptual
metric should enable the development of an important new class of efficient globalillumination
rendering systems that can intelligently allocate limited computational resources,
to provide high quality images at interactive rates.
",
}

@MastersThesis{Donikian:2004:IAS,
  author =       "Michael Donikian",
  title =        "ITERATIVE ADAPTIVE SAMPLING FOR ACCURATE DIRECT ILLUMINATION", 
  school =       "Cornell University",
  month =        "August",
  year =         "2004",
  abstract =     "This thesis introduces a new multipass algorithm, Iterative Adaptive Sampling, for
effciently computing the direct illumination in scenes with many lights, including
area lights that cause realistic soft shadows. Real world architectural scenes frequently
contain large numbers of lights; however many current algorithms do not
scale well in performance when rendering these types of scenes.
Our algorithm is based upon an observation that although many hundreds of
lights may contribute to the illumination of a single image, much lower lighting
complexity typically exists on a localized basis within subsections of the image.
Since the predominant cost of computing the direct illumination at a point is the
testing of light source visibility, our algorithm works to exploit this observation of
low localized lighting complexity to reduce the number of visibility tests (shadow
rays) needed to accurately render each pixel.
This reduction of shadow rays is made possible by sampling light sources in
proportion to their actual contribution to a pixel's luminance value. We do this
by iteratively modifying a probability density function (PDF) until it adaptively
captures the local lighting configuration. We use sample data collected during
rendering as feedback to drive the optimization of the PDF. Our algorithm takes
advantage of coherence in image space by aggregating sample data on both a perpixel
and per-block level as well as coherence in world space by aggregating sample
data on light clusters. We have tested this algorithm on several complex lighting
environments and demonstrated roughly an order of magnitude improvement over
standard procedures.
",
}

@TechReport{Walter:2005:NWB,
  author =       "Bruce Walter",
  title =        "Notes on the Ward BRDF", 
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-05-06",
  month =        "April",
  year =         "2005",
  abstract =     "The anisotropic BRDF introduced in [Ward 1992] has become
widely used in computer graphics, but some important implementation
details are less widely known. We discuss how to efficiently
evaluate the Ward BRDF. Then we derive the probability density
function for its associated Monte Carlo sampling scheme and the
correct weights to use with the generated samples. Finally for the
isotropic version, we describe how to bound the maximum possible
BRDF value over a region of (direction) space.
",
}

@InProceedings{Stokes:2004:PIA,
  author = "William A. Stokes and James A. Ferwerda and Bruce Walter and Donald P. Greenberg",
  title = "Perceptual illumination components: a new approach to efficient, high quality global illumination rendering",
  journal = "ACM Trans. Graph.",
  booktitle =    "SIGGRAPH 2004 Conference Proceedings",
  volume = "23-3",
  year = "2004",
  issn = "0730-0301",
  pages = "742--749",
  doi = "http://doi.acm.org/10.1145/1015706.1015795",
  publisher = "ACM Press",
  address = "New York, NY, USA",
  abstract = "In this paper we introduce a new perceptual metric for efficient, high
quality, global illumination rendering. The metric is based on a
rendering-by-components framework in which the direct, and indirect
diffuse, glossy, and specular light transport paths are separately
computed and then composited to produce an image. The metric predicts
the perceptual importances of the computationally expensive indirect
illumination components with respect to image quality. To develop the
metric we conducted a series of psychophysical experiments in which we
measured and modeled the perceptual importances of the components. An
important property of this new metric is that it predicts component
importances from inexpensive estimates of the reflectance properties of
a scene, and therefore adds negligible overhead to the rendering process.
This perceptual metric should enable the development of an important new
class of efficient global-illumination rendering systems that can
intelligently allocate limited computational resources, to provide high
quality images at interactive rates.
",
}

@InProceedings{Walter:2005:LSA,
  author =       "Bruce Walter and Sebastian Fernandez and Adam Arbree and Kavita Bala and 
                   Michael Donikian and Donald P. Greenberg",
  title =        "Lightcuts: A Scalable Approach to Illumination",
  organization = "ACM SIGGRAPH",
  booktitle =    "SIGGRAPH 2005 Conference Proceedings",
  conference =   "31 July- 4 August, 2005, Los Angeles, California",
  month =        "July",
  year =         "2005",
  abstract =     "Lightcuts is a scalable framework for computing realistic illumination.
It handles arbitrary geometry, non-diffuse materials, and illumination
from a wide variety of sources including point lights, area
lights, HDR environment maps, sun/sky models, and indirect illumination.
At its core is a new algorithm for accurately approximating
illumination from many point lights with a strongly sublinear
cost. We show how a group of lights can be cheaply approximated
while bounding the maximum approximation error. A binary light
tree and perceptual metric are then used to adaptively partition the
lights into groups to control the error vs. cost tradeoff.

We also introduce reconstruction cuts that exploit spatial coherence
to accelerate the generation of anti-aliased images with complex illumination.
Results are demonstrated for five complex scenes and
show that lightcuts can accurately approximate hundreds of thousands
of point lights using only a few hundred shadow rays. Reconstruction
cuts can reduce the number of shadow rays to tens.

",
}

@TechReport{Li:2005:TGC,
  author =       "Hongsong Li and Sing Choong Foo and Kenneth E. Torrance and Stephen H. Westin",
  title =        "Testing of a Gonioreflectometer for Computer Graphics",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-05-01",
  month =        "April",
  year =         "2005",
  abstract =     "We describe an automated, three-axis BRDF measurement instrument, which can 
help increase the physical realism of computer graphics renderings by providing light scattering 
data for the surfaces in a scene.  The gonioreflectometer performs rapid measurements of the BRDF 
of a flat, isotropic, sample surface over the complete visible spectrum and over most of the 
incident and reflection hemispheres.  To validate the instrument, initial measurements were taken 
and compared with measurements by other instruments.  The accuracy of the BRDF measurements is 
sufficient for computer graphics research, while reciprocity and energy conservation are preserved.
",
}

@TechReport{Li:2005:BDV,
  author =       "Hongsong Li and Kenneth E. Torrance",
  title =        "Background Data for Validation of the He-Torrance Model",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-05-02",
  month =        "April",
  year =         "2005",
  abstract =     "We present an experimental study of the angular distribution of light 
scattered from several rough metallic surfaces, which cover a range of roughness conditions. 
A BRDF model based on the Kirchhoff approximation was used to demonstrate the relation between 
surface-height statistics and the angular distribution of the scattered light. To do this, the 
angular distributions calculated with the BRDF model were fit to the measurements; the 
surface-height statistics were computed with a composite roughness model, and were used as 
inputs to obtain the BRDF predictions. We show that the Kirchhoff approximation can be 
applied to rough metallic surfaces that have multiple scales of roughness and near-, but not 
perfect, Gaussian surface-height distributions.
",
}


@TechReport{Li:2003:VTG,
  author =       "Hongsong Li and Kenneth E. Torrance",
  title =        "Validation of the Gonioreflectometer",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-03-02",
  month =        "May",
  year =         "2003",
  abstract =     "This report describes a series of experiments conducted in the Light Measurement
Laboratory of the Program of Computer Graphics in the summer of 1999 to validate the
Gonioreflectometer. The Gonioreflectometer is an automated device to measure the
BRDF (Bidirectional Reflectance Distribution Function) of a flat test sample. The sample
is illuminated and reflected light collected at multiple preset angles of illumination and/or
reflection. Light detection is at 1024 spectral bands over the visible wavelength range.

The validation experiments described herein include stray light, polarization, and detector
noise and linearity tests. Further tests determined the light source and detector footprints,
the instrument solid angles, and the instrument signature (i.e., instrument response when
scanning the incident beam without a test sample). All parts of the instrument (including
the light source, the positioning mechanism, and the detector) were carefully studied.

Many of the experiments were to explain an unexpected difficulty that was discovered:
the spectral bias of recent BRDF measurements (i.e., after Foo's thesis [1] was
completed). Extensive work showed that the error comes from the chromatic aberrations
of the light source, the nonlinear response of the detector, and the background noise
measurements.

Chapter 7 recommends a new method to obtain reflectance measurements with better
accuracy, and which avoids the spectral bias of the light source. BRDFs are measured
relative to a white reference material (Spectralon). Such a procedure is known as a relative
reflectance method, and is the preferred method for reflectance samples that are
strongly diffusing.

Absolute reflectance measurements are still possible with the Gonioreflectometer,
however, and may be preferred for reflectance samples with strong specular, or mirrorlike,
reflection behavior. For such materials, the peak reflected signal and the incident
source signal might be close in magnitude. A special measurement procedure is
recommended for such surfaces, and is discussed in Chapter 6.

Several samples were measured. Strongly specular reflecting materials were measured
with the absolute reflectance technique (Chapter 6). The materials were a smooth gold
mirror, a smooth black plastic, and a smooth blue plastic. Materials with strong
directional-diffuse reflection were measured using the new relative reflectance method
(Chapter 7). The materials included metals (rough steel Q-panel; two aluminum coated
ground glass surfaces), nonmetals (white Spectralon), and paints (Ford metallic gray;
Krylon blue; Bristol light gray).

The appendix of the report presents an alignment procedure for the Gonioreflectometer.
",
}

@TechReport{Westin:2004:FGB,
  author =       "Stephen H. Westin and Hongsong Li and Kenneth E. Torrance",
  title =        "A Field Guide to BRDF Models",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-04-01",
  month =        "Jan",
  year =         "2004",
  abstract =     "We present a principled approach to selecting a surface reflectance model 
and setting its parameters. The approach is based on fundamental physical principles, 
 comparisons between different models, and
practical insight into the characteristics of real surfaces. 
Four models of surface reflectance were evaluated
by comparing them with physical measurements on five 
different sample surfaces. Conclusions are drawn
about which of the models are best to represent different surfaces, 
since no one model was a clear winner
in all cases. Principles and visual checks are derived to help practitioners 
model a variety of surfaces with good accuracy.
",
}

@TechReport{Westin:2004:CFB,
  author =       "Stephen H. Westin and Hongsong Li and Kenneth E. Torrance",
  title =        "A Comparison of Four BRDF Models",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-04-02",
  month =        "April",
  year =         "2004",
  abstract =     "
We compare four parametric reflectance models that are well-known 
in computer graphics: the Phong, Ward, Lafortune, and
He-Torrance models. We compare the models with physical measurements 
on five representative sample surfaces. The surfaces
span the domain of isotropic, homogeneous surfaces ranging from smooth 
to rough and including metal and dielectric surfaces.
Since no one model was a clear winner in all cases, we draw conclusions 
about which of the models are best to represent various
surfaces. We explain the differences in terms of the basic scattering phenomena involved.
",
}

@article{Dumont:2003:PDD,
author = {Reynald Dumont and Fabio Pellacini and James A. Ferwerda},
title = {Perceptually-driven decision theory for interactive realistic rendering},
journal = {ACM Trans. Graph.},
volume = {22},
number = {2},
year = {2003},
issn = {0730-0301},
pages = {152--181},
doi = {http://doi.acm.org/10.1145/636886.636888},
publisher = {ACM Press},
address = {New York, NY, USA},
abstract =     "
In this paper we introduce a new approach to realistic rendering at interactive rates on 
commodity graphics hardware. The approach uses efficient perceptual metrics within a 
decision theoretic framework to optimally order rendering operations, producing images of 
the highest visual quality within system constraints. We demonstrate the usefulness of 
this approach for various applications such as diffuse texture caching, environment map 
prioritization and radiosity mesh simplification. Although here we address the problem of 
realistic rendering at interactive rates, the perceptually-based decision theoretic 
methodology we introduce can be usefully applied in many areas of computer graphics.
",
}

@InProceedings{Ferwerda:2003:TVR,
  author =       "James A. Ferwerda",
  title =        "Three varieties of realism in computer graphics",
  organization = "The International Society for Optical Engineering",
  booktitle =    "Human Vision and Electronic Imaging VIII",
  editor =       "Bernice E. Rogowitz and Thrasyvoulos N. Pappas",
  month =        "June",
  year =         "2003",
  abstract =     "This paper describes three varieties of realism that need to be 
considered in evaluating computer graphics images and defines the criteria that need to 
be met if each kind of realism is to be achieved. The paper introduces a conceptual 
framework for thinking about realism in images, and describes a set of research tools 
for measuring image realism and assessing its value in graphics applications.
",
}

@inproceedings{Ferwerda:2004:ERS,
author = "James A. Ferwerda and Stephen H. Westin and Randall C. Smith and Richard Pawlicki",
title = "Effects of rendering on shape perception in automobile design",
booktitle = "APGV '04: Proceedings of the 1st Symposium on Applied perception in graphics and visualization",
year = "2004",
isbn = "1-58113-914-4",
pages = "107--114",
location = "Los Angeles, California",
doi = "http://doi.acm.org/10.1145/1012551.1012570",
publisher = "ACM Press",
address = "New York, NY, USA",
abstract =     "The goal of this project was to determine if advanced rendering methods 
such as global illumination allow more accurate discrimination of shape differences than 
standard rendering methods such as OpenGL. 

To address these questions, we conducted two 
psychophysical experiments to measure observers' sensitivity to shape differences between 
a physical model and rendered images of the model. Two results stand out: 

* The rendering 
method used has a significant effect on the ability to discriminate shape. In particular, 
under the conditions tested, global illumination rendering improves sensitivity to shape 
differences. 

* Further, viewpoint appears to have an effect on the ability to discriminate 
shape. In most of the cases studied, sensitivity to small shape variations was poorer when 
the rendering and model viewpoints were different.

The results of this work have important 
implications for our understanding of human shape perception and for the development of 
rendering tools for computer-aided design. 
",
}

@InProceedings{Ferwerda:2003:FDP,
  author =       "James A. Ferwerda and Fabio Pellacini",
  title =        "Functional Difference Predictors (FDPs): Measuring Meaningful Image Differences",
  conference =   "Asilomar Conference on Signals, Systems, and Computers",
  booktitle = "Conference Record of the Thirty-Seventh Asilomar Conference on Signals, Systems, and Computers",
  year =         "2003",
  pages =        "1388-1392",
  abstract =     "In this paper we introduce Functional Difference Predictors (FDPs), 
a new class of perceptually-based image difference metrics that predict how image errors 
affect the ability to perform visual tasks using the images. To define the properties of 
FDPs, we conduct a psychophysical experiment that focuses on two visual tasks: spatial 
layout and material estimation. In the experiment we introduce errors in the positions 
and contrasts of objects reflected in glossy surfaces and ask subjects to make layout and 
material judgments. The results indicate that layout estimation depends only on positional 
errors in the reflections and material estimation depends only on contrast errors. These 
results suggest that in many task contexts, large visible image errors may be tolerated 
without loss in task performance, and that FDPs may be better predictors of the relationship 
between errors and performance than current Visible Difference Predictors (VDPs).
",
}
@PhdThesis{Li:2005:TFP,
  author =       "Hongsong Li",
  title =        "Theoretical Framework And Physical Measurements Of Surface and 
                   Subsurface Light Scattering From Material Surfaces",
  school =       "Cornell University",
  month =       "May",
  year =         "2005",
  abstract =     "This thesis aims to improve fidelity of realistic synthesized images by 
providing practical solutions for simulating the surface and subsurface light scattering 
phenomena. The solutions achieve a good balance between the physical correctness and the 
computational cost, and are verified against light scattering measurements carried out as 
part of the thesis. The proposed theoretical framework includes:

{  * A} BRDF model for simulating first surface reflections

{  * A} BRDF model for simulating local subsurface scattering

{  * A} hybrid method for simulating volumetric subsurface scattering

The first BRDF model accounts for first-surface reflections. The model combines 
highly-efficient wave optics components and rigorous empirical components. Consequently, 
the accuracy and generality of the model are comparable to those of the wave-optics model; 
while its computational cost is much lower. The model correctly predicts various light 
scattering phenomena and applies for to a wide range of materials and surface finishes.

The second BRDF model accounts for local subsurface scattering that shows no volumetric effect. 
The model describes the non-directional and directional subsurface scattering with 
physically-plausible mathematical constructions. The angular dependence of transmission and the 
directionality of the subsurface light transport are taken into consideration.

Both BRDF models compare favorably against extensive, detailed reflectance measurements that 
were carried out as part of this thesis. The models are analytic and suitable for practical 
Computer Graphics applications. Benchmark timings are comparable with that of current less 
comprehensive models (Lafortune, Ward, and Cook-Torrance models).

The proposed hybrid method is a flexible approach that efficiently simulates the appearance 
of a wide range of participating media, which are not well handled by currently available 
methods. The method combines the Monte Carlo technique and the dipole diffuse approximation. 
The first several scattering events inside the volume are critical for rendering, especially 
for highly-curved or optically-thin materials, and can only be well simulated by a pure Monte 
Carlo method. The contribution of the subsequent scattering events, which may not always exist, 
can be approximated by the dipole diffusion approximation with acceptable accuracy. While the 
accuracy of the hybrid method is comparable to a pure Monte Carlo method, its efficiency is 
much higher.
",
}

@MastersThesis{Goel:2005:ACE,
  author =       "Vikash R Goel",
  title =        "Analytical Centerline Extraction and Surface Fitting Using {CT} Scans For 
                   Aortic Aneurysm Repair",
  school =       "Cornell University",
  month =        "May",
  year =         "2005",
  abstract =     "Endovascular aortic aneurysm repair promises to provide great advantages over
traditional open surgery. Though this nascent form of treatment has already been
demonstrated to be safer and easier for the patient, there is a strong need for
technological advances which can improve precision and simultaneously reduce the
amount of human effort involved in planning surgery. Computational analysis is
also essential in predicting the future behavior of endovascular stent grafts, because
at this stage there is very little empirical knowledge of long-term stent dynamics.

We present a geometric analysis procedure which aims to address this need. Our
goal is to begin with CT scan data collected from aortic aneurysm patients and to
produce a fully analytical model of the patient's arterial geometry with minimal
user interaction. The product of this highly automated process can be a powerful
tool for surgery planning and stent design. Furthermore, it provides a basis upon
which computational fluid dynamics and mechanical behavior simulations can be
built. The analytical nature of this representation allows for direct mathematical
analysis or for arbitrarily precise discretization.

Our geometric analysis begins with a voxel segmentation. The segmented data
set is then used as input into a unique robust centerline extraction procedure.
This centerline then serves as the basis for an analytical fitting procedure which
produces a lofted B-spline surface model. After describing this analysis process in
detail, we present results from three input datasets.
",
}

@TechReport{Trumbore:1990:TCG,
  author =       "Ben Trumbore and Wayne Lytle and Donald P. Greenberg",
  title =        "A Testbed for Computer Graphics Research",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-90-01",
  month =        "Sept",
  year =         "1990",
  abstract =     "
",
}

@TechReport{Dykes:1990:PSV,
  author =       "Genes W. Dykes and Tulio N. Bittencourt and David O. Potyondy and 
                  John F. Abel and Donald P. Greenberg",
  title =        "A Prototypes Study of Visualization and Steering With the FPS Model-500",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-90-02",
  month =        "Dec",
  year =         "1990",
  abstract =     "
",
}
@MastersThesis{Kravetz:2005:PHO,
  author =       "Adam Michael Kravetz",
  title =        "POLYHEDRAL HULL ONLINE COMPOSITING SYSTEM: TEXTURING AND REFLECTIONS",
  school =       "Cornell University",
  month =        "August",
  year =         "2005",
  abstract =     "The Polyhedral Hull Online Compositing System is a prototype system which
merges live dynamic video and three dimensional synthetic imagery at interactive
frame-rates. This system captures video from convergent cameras and performs
geometric reconstruction to generate a three dimensional mesh. Utilizing the background
geometry which is generated by an external renderer and the reconstructed
mesh, this system adds shadows and reflections to the final composite image. The
combination creates a perceptual link between the two otherwise disjoint environments.
The computed mesh reconstruction allows this system to be view independent,
which is a major advantage over previous state-of-the-art systems. By
using modern graphics hardware and a distributed computing model to capture
and process live video data with synthetic three dimensional imagery into final
composites, we provide an economic alternative to standard commercial systems.

The texturing and refction processes, two key parts of the Polyhedral Hull
Online Construction System, are described in detail in this thesis. The texturing
processes explore the problem of providing a visually plausible, view-independent
representation with only four video cameras capturing live data. The reection
process calculates the dominant specular highlight of the live object in order to
render visually convincing results. These processes add degrees of realism so that
final composite image is a visually plausible merger of real and synthetic imagery.
",
}

@InProceedings{Li:2005:ESC,
  author =       "Hongsong Li and Kenneth E. Torrance",
  title =        "An experimental study of the correlation between surface roughness
                  and light scattering for rough metallic surfaces",
  booktitle =    "Advanced Characterization Techniques for Optics, Semiconductors, and Nanotechnologies II",
  editor =       "A. Duparre and B. Singh and Z-H Gu",
  organization = "SPIE",
  conference =   "Optics & Photonics Conference, 31 July - 4 August",
  month =        Jul,
  year =         "2005",
  volume =      "Proceedings of SPIE Vol. 5878",
  pages =	"5878-32",
  keywords =    "Optics, scattering, roughness, surfaces, reflectance, BRDF, Kirchhoff approximation, computer graphics",
  publisher =   "SPIE, Bellingham, WA",
  abstract =     "We present an experimental study of the angular distribution of light scattered
		from several rough metallic surfaces, which
		cover a range of roughness conditions. The substrate materials are
		steel or glass; roughened by bead-blasting, grinding, or
		etching; and aluminum-coated. The measured surface-roughness
		statistics are filtered by using a composite roughness
		model. The raw mechanical roughnesses range from 0.21m to 2.66m;
		the high-frequency small-scale roughnesses
		range from 0.13m to 0.86m. The optical wavelength is 550nm,
		so that the roughness-to-wavelength ratio is of order
		one. A BRDF model based on the Kirchhoff approximation is used
		to establish a relationship between surface-height
		statistics and the angular distribution of the scattered light.
		Angular distributions calculated with the BRDF model are fit
		to the measurements. The best-fit roughness statistics from the
		BRDF model agree closely with those measured for the
		high-frequency small-scale roughness component. The latter
		roughness component, which has the highest surface slopes,
		is thus the primary contributor to the angular distribution
		of the reflected light. We show that the Kirchhoff approximation
		can be applied to rough metallic surfaces that have multiple
		scales of roughness and near-, but not perfect, Gaussian
		surface-height distributions.",
}

@InProceedings{Li:2005:ATG,
  author =       "Hongsong Li and Sing Choong Foo and Kenneth E. Torrancei and Stephen H. Westin",
  title =        "Automated three-axis gonioreflectometer for computer graphics applications",
  booktitle =    "Advanced Characterization Techniques for Optics, Semiconductors, and Nanotechnologies II",
  editor =       "A. Duparre and B. Singh and Z-H Gu",
  organization = "SPIE",
  conference =   "Optics & Photonics Conference, 31 July - 4 August",
  month =        Jul,
  year =         "2005",
  volume =      "Proceedings of SPIE Vol. 5878",
  pages =       "5878-29",
  keywords =    "Optics, optical devices, scattering, reflectance, reflectometers, computer graphics",
  publisher =   "SPIE, Bellingham, WA",
  abstract =     "We describe an automated three-axis BRDF measurement
		instrument that can help increase the physical realism of
		computer graphics images by providing light scattering
		data for the surfaces within a synthetic scene that is to be
		rendered. To our knowledge, the instrument is unique in
		combining wide angular coverage (beyond 85 from the
		surface normal), dense sampling of the visible wavelength
		spectrum (1024 samples), and rapid operation (less than ten
		hours for complete measurement of an isotropic sample).
		The gonioreflectometer employs a broadband light source and
		a detector with a diffraction grating and linear diode array.
		Validation was achieved by comparisons against reference
		surfaces and other instruments. The accuracy and spectral
		and angular ranges of the BRDFs are appropriate for
		computer graphics imagery, while reciprocity and energy
		conservation are preserved. Measured BRDFs on rough
		aluminum, metallic silver automotive paint, and a
		glossy yellow paint are reported, and an example rendered automotive
		image is included.
                ",
}
@MastersThesis{Fairbank:2005:VDP,
  author =       "Jeremiah Fairbank",
  title =        "VIEW DEPENDENT PERSPECTIVE IMAGES",
  school =       "Cornell University",
  month =        "August",
  year =         "2005",
  abstract =     "The effects of scalar distortions that result from incorrect viewing location
                  adversely affect a viewer's ability to judge space and scale in a perspective
                  image. A study of the history of the development of the perspective image shows
                  that artists and architects of the Renaissance were sensitive to the location
                  of the viewer. Using this precedent, we place a renewed emphasis on the
                  relationship between the viewer of an image, the image, and the scene the image
                  represents.

                  We have created a computer graphics application that uses a skew camera model to
                  present a viewdependent perspective image. We find the viewer's location using
                  a camera based tracking system. Viewer location data, along with information about
                  display location guide the skew camera's parameters. We create perspective images
                  that do not suffer from the distortions that are commonly present in wideangle
                  perspective images. Our system allows for the display of perspective images that
                  geometrically recreate what the observer would see if they were to view a real scene.
",
}
@TechReport{Ismert:2003:DST,
  author =       "Ryan M. Ismert and Kavita Bala and Donald P. Greenberg",
  title =        "Detail Synthesis for Image-based Texturing",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-03-01",
  month =        "Jan",
  year =         "2003",
  abstract =     "Interactive and immersive environments which model the real world often
                  use images of the environment to capture realistic visual complexity.
                  Image-based modeling techniques permit the creation of visually interesting
                  geometric models from photographs. These models are 
                  textured by resampling these images of the scene; we call this process
                  image-based texturing. The problem with traditional image-based 
                  texturing is the poor quality of the extracted textures, which are often
                  blurred or stretched.

                  This paper introduces a novel technique to improve the quality of image-based
                  texturing processes by introducing a physically-based
                  metric that can be used to extend current texture synthesis methods. We propose
                  a sampling-based metric of texture quality based on the 
                  Jacobian matrix of the imaging transform, which captures the interaction of
                  the imaging system with the imaged environment. This metric 
                  suggests a physical interpretation of the multi-resolution image representations
                  widely used in texture synthesis. Use of this metric enables 
                  synthesis of high spatial frequency detail into regions of an image-based model's
                  textures where the imaging process captures only low 
                  frequency texture data. Given a small set of input images and a geometric
                  model of the scene, this technique allows the creation of uniform, 
                  high-resolution textures. Our technique relieves the user of the burden
                  of collection large numbers of images and increases the quality of 
                  user-driven image-based modeling systems. This improved quality is important in
                  order to create compelling visual experiences in interactive environments.
",
}
@TechReport{Li:2005:PCL,
  author =       "Hongsong Li and Kenneth E. Torrance",
  title =        "A Practical, Comprehensive Light Reflection Model",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-05-03",
  month =        "April",
  year =         "2005",
  abstract =     "A new comprehensive reflectance model is presented. The model
                  accounts for both surface and subsurface local light scattering.
                  The model combines, for the first time, highly-efficient wave
                  optics components and rigorous empirical components. The
                  model displays a wide range of directional and non-directional
                  light scattering phenomena and compares favorably against
                  extensive, detailed reflectance measurements. The model is
                  analytic and suitable for Computer Graphics applications.
                  Benchmark timings are comparable with that of current less
                  comprehensive models (Lafortune, Ward, and Cook-Torrance
                  models).

",
}
@TechReport{Li:2005:VNA,
  author =       "Hongsong Li and Fabio Pellacini and Kenneth E. Torrance and Dhruva Karle",
  title =        "Validation of the Numerical Accuracy and Efficiency of the
                  Hybrid Method",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-05-04",
  month =        "April",
  year =         "2005",
  abstract =     "To characterize the accuracy and efficiency of our hybrid Monte Carlo 
                  scheme, we devised a set of numerical
                  experiments that compare the newly proposed method with full 
                  Monte Carlo simulations as well as the Jensen
                  et al.'s approximation. The results of these tests show 
                  that our method produces results whose numerical accuracy
                  is comparable to Monte Carlo simulations at a much lower 
                  computational cost. These experiments also show the
                  source of the inaccuracy that Jensen et al.approximation 
                  displays when rendering optically-thin materials.
",
}
@InProceedings{Li:2005:HMC,
  author =       "Hongsong Li and Fabio Pellacini and Kenneth E. Torrance",
  title =        "A Hybrid Monte Carlo Method for Accurate and Efficient Subsurface Scattering",
  booktitle =    "Rendering Techniques 2005",
  conference =   "Eurographics Symposium on Rendering;
                 held in Konstanz, Germany; June 29 - July 01, 2005",
  editor =       "Kavita Bala and Philip Dutr",
  publisher =    "Eurographics Association",
  month =        "June",
  year =         "2005",
  pages =        "283--290",
  abstract =    "Subsurface scattering is a fundamental aspect of surface appearance 
                 responsible for the characteristic look of
                 many materials. Monte Carlo path tracing techniques can be employed 
                 with high accuracy to simulate the scattering
                 of light inside a translucent object, albeit at the cost of long 
                 computation times. In a seminal work, Jensen
                 et al. [JMLH01] presented a more efficient technique to simulate 
                 subsurface scattering that, while producing accurate
                 results for translucent, optically-thick, materials, exhibits 
                 artifacts for semi-transparent, optically-thin, ones,
                 especially in regions of high-curvature.

                 This paper presents a hybrid Monte Carlo technique capable 
                 of simulating a wide range of materials exhibiting
                 subsurface scattering, from translucent to semi-transparent 
                 ones, with an accuracy comparable to Monte Carlo
                 techniques but at a much lower computational cost. Our 
                 approach utilizes a Monte Carlo path tracing approach for
                 the first several scattering events, in order to estimate 
                 the directional-diffuse component of subsurface scattering,
                 and switches to a dipole diffusion approximation only when 
                 the path penetrates deeply enough into the surface. By
                 combining the accuracy of Monte Carlo integration with the 
                 efficiency of the dipole diffusion approximation, our
                 hybrid method produces results as accurate as full Monte 
                 Carlo simulations at a speed comparable to the Jensen
                 et al. approximation, thus extending its usefulness to a 
                 much wider range of materials.
",
}
@Article{Donikian:2006:ADI,
author = {Michael Donikian and Bruce Walter and Kavita Bala and
Sebastian Fernandez and Donald P. Greenberg},
title = {Accurate Direct Illumination Using Iterative Adaptive Sampling},
journal = {IEEE Transactions on Visualization and Computer Graphics},
volume = {12},
number = {3},
year = {2006},
issn = {1077-2626},
pages = {353-364},
doi = {http://doi.ieeecomputersociety.org/10.1109/TVCG.2006.41},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
  abstract =    "This paper introduces a new multipass algorithm for
                 efficiently computing direct illumination in scenes with many lights and
                 complex occlusion. Images are first divided into 8 X 8 pixel blocks
                 and for each point to be shaded within a block, a probability density
                 function (PDF) is constructed over the lights and sampled to estimate
                 illumination using a small number of shadow rays. Information from these
                 samples is then aggregated at both the pixel and block level and used to
                 optimize the PDFs for the next pass. Over multiple passes the PDFs and
                 pixel estimates are updated until convergence. Using aggregation and
                 feedback progressively improves the sampling and automatically exploits
                 both visibility and spatial coherence. We also use novel extensions for
                 efficient antialiasing. Our adaptive multipass approach computes
                 accurate direct illumination eight times faster than prior approaches in
                 tests on several complex scenes.
",
}

@Conference{Walter:2005:IMP,
  author =       "Bruce Walter and Sebastian Fernandez and Adam Arbree and Kavita Bala and
                   Michael Donikian and Donald P. Greenberg",
  title =        "Implementing Lightcuts",
  organization = "ACM SIGGRAPH",
  booktitle =    "SIGGRAPH 2005 Technical Sketch",
  conference =   "31 July- 4 August, 2005, Los Angeles, California",
  month =        "July",
  year =         "2005",
  abstract =    "
",
}

@MastersThesis{Wang:2007:ATI,
  author =       "Jeffrey Michael Wang",
  title =        "Animating the Ivory-Billed Woodpecker",
  school =       "Cornell University",
  month =        "Jan",
  year =         "2007",
  abstract =     "The proposed rediscovery of the Ivory-Billed Woodpecker by the Cornell 
Laboratory of Ornithology, while celebrated by some ornithologists, was debated by others.  
Central to the argument is the interpretation of a fuzzy video depicting a large black and 
white bird taking flight.  This thesis describes the creation of a physiologically-accurate 
animation of a flying Ivory-Billed Woodpecker in hope that it can be one day used to verify 
the rediscovery.  A preserved specimen, with its internal organs and skeleton intact, was CT 
scanned and reconstructed.  The resulting volumetric data provided precise measurements and 
proportions of the skin and skeleton for the animation.  To feather the bird, a procedural 
system modeled and animated the important feathers of interest, those which lie on the 
Ivory-Billed's wings.  The animation is currently directed using data adapted from previously 
published ornithological research on the kinematics of bird flight.  However, this thesis 
represents a foundation for research to make animation of avian flight physically accurate as well.
",
}

@MastersThesis{Budsberg:2007:PCD,
  author =       "Jeffrey Blaine Budsberg",
  title =        "PIGMENTED COLORANTS:  DEPENDENCE ON MEDIA AND TIME",
  school =       "Cornell University",
  month =        "Jan",
  year =         "2007",
  abstract =     "We present a physically based model for predicting the visual appearance of 
artists' paint, which is dependent on both time and the material that binds the colorant to a surface.

In our study, we captured the reflectance spectra of a large number of paint samples at different 
intervals in time over the course of six months. These paint samples were handmade to ensure material 
quality, using various pigmented colorants and adhesive binding media. Converting our spectral data 
into different perceptually uniform color spaces, we show very significant perceptual differences in 
two domains: the appearance of paint changes over time; and the appearance of one pigmented colorant 
varies when dispersed in different materials.

Finally, we present an interactive viewer for predictive pigmented color mixture utilizing the paint 
reflectance spectra, Kubelka Munk theory and modern graphics hardware.
",
}

@MastersThesis{Zaman:2007:SBI,
  author =       "Nasheet Zaman",
  title =        "A SKETCH-BASED INTERFACE FOR PARAMETRIC CHARACTER MODELING",
  school =       "Cornell University",
  month =        "Jan",
  year =         "2007",
  abstract =     "We present an innovative modeling technique that allows artists to freely 
sketch changes to a realistically proportioned face mesh. Our concept builds a sketch-based 
interface over a parameterized, topologically optimized, rigged, textured, ready-to-animate 
prototype face model. Parametric modeling and sketch-based mesh editing are two previously 
disjoint areas of research we have merged to develop a unique system. The first component is 
the parametric setup. The prototype is marked with selectable anthropometric landmarks, which 
can be moved to locally reshape the geometry. As the user changes the positions of landmarks, 
facial measurements are recorded internally. Anatomical limits are calculated based on demographic 
data and figure drawing conventions. These limits may be visualized interactively to guide realistic 
modeling, or ignored by the artist for more stylized creations. The second component is the 
sketch-based interface, which streamlines the process of moving landmarks and reshaping the mesh. 
Using a tablet and stylus, the user first sketches a selection curve through some landmarks, and 
then sketches a second curve describing the desired shape of the region defined by the selected 
landmarks. The corresponding region of the mesh is automatically morphed in 3D space to conform 
to the new curve. During this process, the user can continue to use the parametric visualization 
mechanisms to maintain or exaggerate proportions. Thus, the artist can enjoy the freedom and 
simplicity of drawing to quickly design and generate a vast range of complex and original 
characters, using just one simple, intuitive, and familiar tool.
",
}

@article{Walter:2006:MUL,
  author = {Bruce Walter and Adam Arbree and Kavita Bala and Donald P. Greenberg},
  title = {Multidimensional lightcuts},
  journal = {ACM Trans. Graph.},
  volume = {25},
  number = {3},
  year = {2006},
  issn = {0730-0301},
  pages = {1081--1088},
  doi = {http://doi.acm.org/10.1145/1141911.1141997},
  publisher = {ACM Press},
  address = {New York, NY, USA},
  abstract= "Multidimensional lightcuts is a new scalable method for efficiently rendering rich 
visual effects such as motion blur, participating media, depth of field, and spatial antialiasing in 
complex scenes. It introduces a flexible, general rendering framework that unifies the handling of 
such effects by discretizing the integrals into large sets of gather and light points and adaptively 
approximating the sum of all possible gatherlight pair interactions.

We create an implicit hierarchy, the product graph, over the gatherlight pairs to rapidly and 
accurately approximate the contribution from hundreds of millions of pairs per pixel while only 
evaluating a tiny fraction (e.g., 200-1,000). We build upon the techniques of the prior Lightcuts 
method for complex illumination at a point, however, by considering the complete pixel integrals, 
we achieve much greater efficiency and scalability.

Our example results demonstrate efficient handling of volume scattering, camera focus, and motion 
of lights, cameras, and geometry. For example, enabling high quality motion blur with 256 temporal 
sampling requires only a 6.7 increase in shading cost in a scene with complex moving geometry, 
materials, and illumination.
",
}

@article{Hasan:2006:DIT,
author = {Milos Hasan and Fabio Pellacini and Kavita Bala},
title = {Direct-to-indirect transfer for cinematic relighting},
journal = {ACM Trans. Graph.},
volume = {25},
number = {3},
year = {2006},
issn = {0730-0301},
pages = {1089--1097},
doi = {http://doi.acm.org/10.1145/1141911.1141998},
publisher = {ACM Press},
address = {New York, NY, USA},
  abstract= "This paper presents an interactive GPU-based system for
cinematic relighting with multiple-bounce indirect illumination from a
fixed view-point. We use a deep frame-buffer containing a set of view
samples, whose indirect illumination is recomputed from the direct
illumination on a large set of gather samples, distributed around the
scene. This direct-to-indirect transfer is a linear transform which is
particularly large, given the size of the view and gather sets. This
makes it hard to precompute, store and multiply with. We address this
problem by representing the transform as a set of sparse matrices
encoded in wavelet space. A hierarchical construction is used to impose
a wavelet basis on the unstructured gather cloud, and an image-based
approach is used to map the sparse matrix computations to the GPU. We
precompute the transfer matrices using a hierarchical algorithm and a
variation of photon mapping in less than three hours on one processor.
We achieve high-quality indirect illumination at 10-20 frames per second
for complex scenes with over 2 million polygons, with diffuse and glossy
materials, and arbitrary direct lighting models (expressed using
shaders). We compute per-pixel indirect illumination without the need of
irradiance caching or other subsampling techniques.
",
}

@inproceedings{Armendariz:2006:IRC,
author = {Edgar Vel{\`{a}}zquez-Armend{\`{a}}riz and Eugene Lee and Kavita Bala and Bruce Walter},
title = {Implementing the render cache and the edge-and-point image on graphics hardware},
booktitle = {GI '06: Proceedings of the 2006 conference on Graphics interface},
year = {2006},
isbn = {1-56881-308-2},
pages = {211--217},
location = {Quebec, Canada},
publisher = {Canadian Information Processing Society},
address = {Toronto, Ont., Canada, Canada},
abstract= "The render cache and the edge-and-point image (EPI) are alternative point-based 
rendering techniques that combine interactive performance with expensive, high quality shading 
for complex scenes. They use sparse sampling and intelligent reconstruction to enable fast 
framerates and to decouple shading from the display update.

We present a hybrid CPU/GPU multi-pass system that accelerates these techniques by utilizing 
programmable graphics processing units (GPUs) to achieve better framerates while freeing the CPU 
for other uses such as high-quality shading (including global illumination). Because the render 
cache and EPI differ from the traditional graphics pipeline in interesting ways, we encountered 
several challenges in using the GPU effectively. We discuss our optimizations to achieve good 
performance, limitations with the current generation hardware, as well as possibilities for 
future improvements.
",
}

@BOOK{Dutre:2003:AGI,
AUTHOR = {Dutr, Philip and Bekaert, Philippe and Bala, Kavita},
TITLE = {Advanced Global Illumination},
PUBLISHER = {A K Peters},
YEAR = {2003},
PAGES = {340},
ADDRESS = {Natick, USA},
abstract= "This book provides the reader with a fundamental understanding of global illumination 
algorithms. It discusses a broad class of algorithms for realistic image synthesis and introduces 
a theoretical basis for the algorithms presented. 
",
}
@BOOK{Dutre:2006:AGI,
AUTHOR = {Dutr, Philip and Bekaert, Philippe and Bala, Kavita},
TITLE = {Advanced Global Illumination, 2nd Edition},
PUBLISHER = {A K Peters},
YEAR = {2006},
ADDRESS = {Natick, USA},
abstract= "This book provides the reader with a fundamental understanding of global illumination 
algorithms. It discusses a broad class of algorithms for realistic image synthesis and introduces 
a theoretical basis for the algorithms presented. 
",
}

@TechReport{Irawan:2006:SAT,
  author =       "Piti Irawan and Stephen R. Marschner",
  title =        "A Simple, Accurate Texture Model for Woven Cotton Cloth",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-06-01",
  month =        "June",
  year =         "2006",
  abstract =     "Cotton cloth is a commonly encountered material in everyday life, and a realistic 
model for its appearance is needed for rendering clothing and environments in many computer graphics 
applications. For realism it is important to produce the correct texture when the pattern of threads 
is resolved in the image, but cloth must also be rendered efficiently in more distant views when the 
thread pattern is not resolved. This paper introduces a simple model that, for any view and 
illumination directions, reproduces both the small-scale texture (BTF) and the large-scale 
reflectance (BRDF) of wo-ven cloth within a single framework. The model is simple and fast, and it 
can handle any weave pattern using only a small set of param-eters. The model is validated against 
measurements, and it quali-tatively matches both the texture and reflectance observed in real cloth.
",
}

@TechReport{Budsberg:2006:RMP,
  author =       "Jeffrey B. Budsberg and Donald P. Greenberg and Stephen R. Marschner",
  title =        "Reflectance Measurements of Pigmented Colorants",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-06-02",
  month =        "Sept",
  year =         "2006",
  abstract =     "In this report, we present the results of an experimental study on the 
appearance of artists' paint over time.  Paint samples were handmade to ensure material 
quality, using various pigment colorants and adhesive binding media.  We present the results 
of our diffuse reflectance measurements, which show very significant perceptual differences 
in two different domains: how the appearance of paint changes over time; and how the appearance 
of one pigmented colorant varies when dispersed in different materials.
",
}

@TechReport{Pellacini:2002:FDP,
  author =       "Fabio Pellacini and James A. Ferwerda",
  title =        "FDPs: Functional Difference Predictors - Measuring Meaningful Image Differences",
  type =         "Technical report",
  institution =  "Program of Computer Graphics, Cornell University",
  number =       "PCG-02-04",
  month =        "April",
  year =         "2002",
  abstract =     "
",
}

@article{Marschner:2005:MAM,
      author = "Stephen R. Marschner and Stephen H. Westin and
        Adam Arbree and Jonathan T. Moon",
      title = "Measuring and modeling the appearance of finished
        wood",
      year = "2005",
      month = aug,
      journal = "ACM Transactions on Graphics (proceedings of SIGGRAPH)",
      volume = "24",
      number = "3",
      pages = "727--734",
      abstract =     "Wood coated with transparent finish has a beautiful and distinctive 
appearance that is familiar to everyone. Woods with unusual grain patterns, such as tiger, 
burl, and birdseye figures, have a strikingly unusual directional reflectance that is prized 
for decorative applications. With new, high resolution measurements of spatially varying 
BRDFs, we show that this distinctive appearance is due to light scattering that does not 
conform to the usual notion of anisotropic surface reflection. The behavior can be explained 
by scattering from the matrix of wood fibers below the surface, resulting in a subsurface 
highlight that occurs on a cone with an out-of-plane axis. We propose a new shading model 
component to handle reflection from subsurface fibers, which is combined with the standard 
diffuse and specular components to make a complete shading model. Rendered results from fits 
of our model to the measurement data demonstrate that this new model captures the 
distinctive appearance of wood.
",
}

@article{Sen:2005:DUA,
      author = "Pradeep Sen and Billy Chen and Gaurav Garg and
        Stephen R. Marschner and Mark Horowitz and Marc
        Levoy and Hendrik P. A. Lensch",
      title = "Dual photography",
      year = "2005",
      month = aug,
      journal = "ACM Transactions on Graphics (Proceedings of SIGGRAPH)",
      volume = "24",
      number = "3",
      pages = "745--755",
abstract =     "We present a novel photographic technique called dual photography, which 
exploits Helmholtz reciprocity to interchange the lights and cameras in a scene. With a video 
projector providing structured illumination, reciprocity permits us to generate pictures from 
the viewpoint of the projector, even though no camera was present at that location. The 
technique is completely image-based, requiring no knowledge of scene geometry or surface 
properties, and by its nature automatically includes all transport paths, including shadows, 
interreflections and caustics. In its simplest form, the technique can be used to take 
photographs without a camera; we demonstrate this by capturing a photograph using a projector 
and a photo-resistor. If the photo-resistor is replaced by a camera, we can produce a 4D 
dataset that allows for relighting with 2D incident illumination. Using an array of cameras 
we can produce a 6D slice of the 8D reflectance field that allows for relighting with 
arbitrary light fields. Since an array of cameras can operate in parallel without 
interference, whereas an array of light sources cannot, dual photography is fundamentally a 
more efficient way to capture such a 6D dataset than a system based on multiple projectors 
and one camera. As an example, we show how dual photography can be used to capture and 
relight scenes.
",
}

@article{Moon:2006:SMS,
  author = "Jonathan T. Moon and Stephen R. Marschner",
  title = "Simulating multiple scattering in hair using a
    photon mapping approach",
  year = "2006",
  month = jul,
  journal = "ACM Transactions on Graphics (Proceedings of SIGGRAPH)",
  volume = "25",
  number = "3",
  pages = "1067--1074",
  abstract = "Simulating multiple scattering correctly is important for accurate 
rendering of hair. However, a volume of hair is a difficult scene to simulate because 
scattering from an individual fiber is very structured and forward directed, and because 
the radiance distributions that arise from many such scattering events remain quite 
directional. For these reasons, previous methods cannot compute accurate images 
substantially faster than Monte Carlo path tracing.

This paper proposes a new physically accurate method for rendering hair that is based on 
previous volumetric photon mapping methods. The first pass generates a photon map by 
tracing particles through the hair geometry, depositing them along paths rather than 
at scattering events. The second pass ray traces the hair, computing direct illumination 
and looking up indirect radiance in the photon map. Photons are stored and looked up in 
5D position-direction space to allow for the very directional radiance distributions that 
occur in hair. Together with a new radiance caching method for fibers, our method 
simulates difficult scattering problems in hair efficiently and with low noise.

The new algorithm is validated against path tracing and also compared with a 
photograph of light scattering in real hair.
",
}

@inproceedings{Irawan:2005:PBT,
  author = "Piti Irawan and James A. Ferwerda and Stephen R. Marschner",
  title = "Perceptually Based Tone Mapping of High Dynamic Range Image Streams",
  year = "2005",
  month = jun,
  booktitle = "Rendering Techniques 2005: 16th Eurographics Workshop on Rendering",
  pages = "231--242",
  abstract = "This paper presents a new perceptually based tone mapping operator that 
represents scene visibility under timevarying, high dynamic range conditions. The 
operator is based on a new generalized threshold model that extends the conventional 
threshold-versus-intensity (TVI) function to account for the viewer's adaptation state, 
and a new temporal adaptation model that includes fast and slow neural mechanisms as 
well as photopigment bleaching. These new visual models allow the operator to produce 
tone-mapped image streams that represent the loss of visibility experienced under 
changing illumination conditions and in high dynamic range scenes. By varying the 
psychophysical data that the models use, we simulate the differences in scene 
visibility experienced by normal and visually impaired observers.
",
}

@article{Marschner:2003:LSF,
  author = "Stephen R. Marschner and Henrik Wann Jensen and
    Mike Cammarano and Steve Worley and Pat Hanrahan",
  title = "Light Scattering From Human Hair Fibers",
  year = "2003",
  month = jul,
  journal = "ACM Transactions on Graphics",
  volume = "22",
  number = "3",
  pages = "780--791",
  abstract = "Light scattering from hair is normally simulated in computer graphics 
using Kajiya and Kay's classic phenomenological model. We have made new measurements 
of scattering from individual hair fibers that exhibit visually significant effects 
not predicted by Kajiya and Kay's model. Our measurements go beyond previous hair 
measurements by examining out-of-plane scattering, and together with this previous 
work they show a multiple specular highlight and variation in scattering with 
rotation about the fiber axis. We explain the sources of these effects using a model 
of a hair fiber as a transparent elliptical cylinder with an absorbing interior and 
a surface covered with tilted scales. Based on an analytical scattering function for 
a circular cylinder, we propose a practical shading model for hair that qualitatively 
matches the scattering behavior shown in the measurements. In a comparison between a 
photograph and rendered images, we demonstrate the new model's ability to match the 
appearance of real hair.
",
}

@misc{James:2001:UTE,
  author = "Doug L. James and Dinesh K. Pai",
  title = "A Unified Treatment of Elastostatic Contact Simulation for Real Time Haptics",
  journal = "Haptics-e, The Electronic Journal of Haptics Research (www.haptics-e.org)",
  year = "2001",
  volume = "2",
  number = "1",
  url = "www.haptics-e.org/Vol_02/he-v2n1.pdf",
  abstract = "We describe real-time, physically-based simulation algorithms for haptic 
interaction with elastic objects. Simulation of contact with elastic objects has been a 
challenge, due to the complexity of physically accurate simulation and the difficulty of 
constructing useful approximations suitable for real time interaction. We show that this 
challenge can be effectively solved for many applications. In particular global 
deformation of linear elastostatic objects can be efficiently solved with low run-time 
computational costs, using precomputed Green's functions and fast low-rank updates based 
on Capacitance Matrix Algorithms. The capacitance matrices constitute exact force 
response models, allowing contact forces to be computed much faster than global 
deformation behavior. Vertex pressure masks are introduced to support the convenient 
abstraction of localized scale-specific point-like contact with an elastic and/or rigid 
surface approximated by a polyhedral mesh. Finally, we present several examples using 
the CyberGlove and PHANToM haptic interfaces.
",
}

@InProceedings{James:1999:AAR,
    author = "Doug L. James and Dinesh K. Pai",
    title = "ArtDefo - Accurate Real Time Deformable Objects",
    booktitle = "Siggraph 1999, Computer Graphics Proceedings",
    publisher = "Addison Wesley Longman",
    address = "Los Angeles",
    editor = "Alyn Rockwood",
    pages = "65--72",
    year = "1999",
    conference =   "Los Angeles, California, August 8-13, 1999",
    series =       "Annual Conference Series",
    month =        "Aug",
    abstract = " We present an algorithm for fast, physically accurate simulation of 
deformable objects suitable for real time animation and virtual environment interaction. 
We describe the boundary integral equation formulation of static linear elasticity as 
well as the related Boundary Element Method (BEM) discretization technique. In addition, 
we show how to exploit the coherence of typical interactions to achieve low latency; the 
boundary formulation lends itself well to a fast update method when a few boundary 
conditions change. The algorithms are described in detail with examples from ArtDefo, 
our implementation.
",
}

@InProceedings{James:2002:DRT,
    author = "Doug L. James and Dinesh K. Pai",
    title = "DyRT: Dynamic Response Textures for Real Time Deformation Simulation With Graphics Hardware",
    booktitle =    "SIGGRAPH 2002 Conference Proceedings",
    editor =       "John F. Hughes",
    organization = "ACM SIGGRAPH",
    conference =   "San Antonio, Texas, 21-26 July 2002",
    series =       "Annual Conference Series",
    month =        "July",
    year =         "2002",
    pages = "582--585",
    abstract = "In this paper we describe how to simulate geometrically complex, 
interactive, physically-based, volumetric, dynamic deformation models with negligible 
main CPU costs. This is achieved using a Dynamic Response Texture, or DyRT, that can 
be mapped onto any conventional animation as an optional rendering stage using commodity 
graphics hardware. The DyRT simulation process employs precomputed modal vibration models 
excited by rigid body motions. We present several examples, with an emphasis on bone-based 
character animation for interactive applications.
",
}

@InProceedings{Kry:2002:ERT,
	author = "Paul G. Kry and Doug L. James and Dinesh K. Pai",
	title = "EigenSkin: Real Time Large Deformation Character Skinning in Hardware",
	booktitle =    "SIGGRAPH 2002 Conference Proceedings",
	editor =       "John F. Hughes",
	organization = "ACM SIGGRAPH",
	conference =   "San Antonio, Texas, 21-26 July 2002",
	series =       "Annual Conference Series",
	month =        "July",
	year =         "2002",
	pages = "153 - 160",
	abstract = "We present a technique which allows subtle nonlinear quasi-static 
deformations of articulated characters to be compactly approximated by data-dependent 
eigenbases which are optimized for real time rendering on commodity graphics hardware. 
The method extends the common Skeletal-Subspace Deformation (SSD) technique to provide 
efficient approximations of the complex deformation behaviours exhibited in simulated, 
measured, and artist-drawn characters. Instead of storing displacements for key poses 
(which may be numerous), we precompute principal components of the deformation influences 
for individual kinematic joints, and so construct error-optimal eigenbases describing 
each joint's deformation subspace. Pose-dependent deformations are then expressed in 
terms of these reduced eigenbases, allowing precomputed coefficients of the eigenbasis to 
be interpolated at run time. Vertex program hardware can then efficiently render 
nonlinear skin deformations using a small number of eigendisplacements stored in graphics 
hardware. We refer to the final resulting character skinning construct as the model's 
EigenSkin. Animation results are presented for a very large nonlinear finite element 
model of a human hand rendered in real time at minimal cost to the main CPU.
",
}

@Conference{James:2006:MEM,
 author = "Doug L. James and Christopher D. Twigg and Andrew Cove and Robert Y. Wang",
 title = "Mesh ensemble motion graphs",
 organization = "ACM SIGGRAPH",
 booktitle = "SIGGRAPH 2006 Technical Sketch",
 year = "2006",
 isbn = "1-59593-364-6",
 pages = "69",
 location = "Boston, Massachusetts",
 doi = "http://doi.acm.org/10.1145/1177367.1178164",
 publisher = "ACM Press",
 address = "New York, NY, USA",
        abstract = "We describe a technique for using space-time cuts to smoothly 
transition between stochastic mesh animation clips while subject to physical 
noninterpenetration constraints. These transitions are used to construct Mesh 
Ensemble Motion Graphs for interactive data-driven animation of high-dimensional 
mesh animation datasets, such as those arising from expensive physical simulations 
of deformable objects blowing in the wind (see Figure 1). We formulate the transition 
computation as an integer programming problem, and use a novel randomized algorithm 
to compute transitions subject to noninterpenetration constraints.
",
}

@Article{James:2003:MGF,
 author = "Doug L. James and Dinesh K. Pai",
 title = "Multiresolution green's function methods for interactive simulation of 
          large-scale elastostatic objects",
 journal = "ACM Trans. Graph.",
 volume = "22",
 number = "1",
 year = "2003",
 issn = "0730-0301",
 pages = "47--82",
 doi = "http://doi.acm.org/10.1145/588272.588278",
 publisher = "ACM Press",
 address = "New York, NY, USA",
   abstract = "We present a framework for low-latency interactive simulation of 
linear elastostatic models, and other systems arising from linear elliptic partial 
differential equations, which makes it feasible to interactively simulate large-scale 
physical models. The deformation of the models is described using precomputed Green's 
functions (GFs), and runtime boundary value problems (BVPs) are solved using existing 
Capacitance Matrix Algorithms (CMAs). Multiresolution techniques are introduced to 
control the amount of information input and output from the solver thus making it 
practical to simulate and store very large models. A key component is the efficient 
compressed representation of the precomputed GFs using second-generation wavelets on 
surfaces. This aids in reducing the large memory requirement of storing the dense GF 
matrix, and the fast inverse wavelet transform allows for fast summation methods to be 
used at runtime for response synthesis. Resulting GF compression factors are directly 
related to interactive simulation speedup, and examples are provided with hundredfold 
improvements at modest error levels. We also introduce a multiresolution constraint 
satisfaction technique formulated as an hierarchical CMA, so named because of its use 
of hierarchical GFs describing the response due to hierarchical basis constraints. 
This direct solution approach is suitable for hard real time simulation since it 
provides a mechanism for gracefully degrading to coarser resolution constraint 
approximations. The GFs' multiresolution displacement fields also allow for runtime 
adaptive multiresolution rendering.
",
}

@Article{James:2004:OSC,
 author = "Doug L. James and Dinesh K. Pai",
 title = "BD-tree: output-sensitive collision detection for reduced deformable models",
 journal = "ACM Trans. Graph.",
 volume = "23",
 number = "3",
 year = "2004",
 issn = "0730-0301",
 pages = "393--398",
 doi = "http://doi.acm.org/10.1145/1015706.1015735",
 publisher = "ACM Press",
 address = "New York, NY, USA",
 abstract = "We introduce the Bounded Deformation Tree, or BD-Tree, which can perform 
collision detection with reduced deformable models at costs comparable to collision 
detection with rigid objects. Reduced deformable models represent complex deformations 
as linear superpositions of arbitrary displacement fields, and are used in a variety of 
applications of interactive computer graphics. The BD-Tree is a bounding sphere 
hierarchy for output-sensitive collision detection with such models. Its bounding 
spheres can be updated after deformation in any order, and at a cost independent of the 
geometric complexity of the model; in fact the cost can be as low as one multiplication 
and addition per tested sphere, and at most linear in the number of reduced deformation 
coordinates. We show that the BD-Tree is also extremely simple to implement, and performs 
well in practice for a variety of real-time and complex off-line 
deformable simulation examples.
",
}

@Article{James:2006:PAT,
 author = "Doug L. James and Jernej Barbi\u{c} and Dinesh K. Pai",
 title = "Precomputed acoustic transfer: output-sensitive, accurate sound generation for 
          geometrically complex vibration sources",
 journal = "ACM Trans. Graph.",
 volume = "25",
 number = "3",
 year = "2006",
 issn = "0730-0301",
 pages = "987--995",
 doi = "http://doi.acm.org/10.1145/1141911.1141983",
 publisher = "ACM Press",
 address = "New York, NY, USA",
 abstract = "Simulating sounds produced by realistic vibrating objects is challenging 
because sound radiation involves complex diffraction and interreflection effects that 
are very perceptible and important. These wave phenomena are well understood, but have 
been largely ignored in computer graphics due to the high cost and complexity of 
computing them at audio rates.We describe a new algorithm for real-time synthesis of 
realistic sound radiation from rigid objects. We start by precomputing the linear 
vibration modes of an object, and then relate each mode to its sound pressure field, 
or acoustic transfer function, using standard methods from numerical acoustics. Each 
transfer function is then approximated to a specified accuracy using low-order multi-pole 
sources placed near the object. We provide a low-memory, multilevel, randomized algorithm 
for optimized source placement that is suitable for complex geometries. At runtime, we 
can simulate new interaction sounds by quickly summing contributions from each mode's 
equivalent multipole sources. We can efficiently simulate global effects such as 
interreflection and changes in sound due to listener location. The simulation costs can 
be dynamically traded-off for sound quality. We present several examples of sound 
generation from physically based animations.
",
}

@article{James:2003:PID,
 author = "Doug L. James and Kayvon Fatahalian",
 title = "Precomputing interactive dynamic deformable scenes",
 journal = "ACM Trans. Graph.",
 volume = "22",
 number = "3",
 year = "2003",
 issn = "0730-0301",
 pages = "879--887",
 doi = "http://doi.acm.org/10.1145/882262.882359",
 publisher = "ACM Press",
 address = "New York, NY, USA",
 abstract = "We present an approach for precomputing data-driven models of interactive 
physically based deformable scenes. The method permits real-time hardware synthesis of 
nonlinear deformation dynamics, including self-contact and global illumination effects, 
and supports real-time user interaction. We use data-driven tabulation of the system's 
deterministic state space dynamics, and model reduction to build efficient low-rank 
parameterizations of the deformed shapes. To support runtime interaction, we also 
tabulate impulse response functions for a palette of external excitations. Although 
our approach simulates particular systems under very particular interaction conditions, 
it has several advantages. First, parameterizing all possible scene deformations enables 
us to precompute novel reduced coparameterizations of global scene illumination for 
low-frequency lighting conditions. Second, because the deformation dynamics are 
precomputed and parameterized as a whole, collisions are resolved within the scene 
during precomputation so that runtime self-collision handling is implicit. Optionally, 
the data-driven models can be synthesized on programmable graphics hardware, leaving 
only the low-dimensional state space dynamics and appearance data models to be 
computed by the main CPU.
",
}

@inproceedings{James:2002:RTS,
  author = "Doug L. James and Dinesh K. Pai",
  title = "Real time simulation of multizone elastokinematic models",
  booktitle = "IEEE International Conference on Robotics and Automation",
  pages = "927--932",
  address = "Washington, D.C.",
  month = "May",
  year = "2002",
  url = "citeseer.ist.psu.edu/james02real.html",
 abstract = "We introduce precomputed multizone elastokinematic models for interactive 
simulation of multibody kinematic systems which include elastostatic deformations. This 
enables an efficient form of domain decomposition, suitable for interactive simulation 
of stiff flexible structures for real time applications such as interactive assembly. 
One advantage of multizone models is that each zone can have small strains, and hence 
be modeled with linear elasticity, while the entire multizone/multibody system admits 
large nonlinear relative strains. This permits fast capacitance matrix algorithms and 
precomputed Green's functions to be used for efficient real time simulation. Examples 
are given for a human finger modeled as a kinematic chain with a 
compliant elastic covering.
",
}

@article{Barbic:2005:RTS,
	author = "Jernej Barbic and Doug L. James",
	title = "Real-Time Subspace Integration for {S}t. {V}enant-{K}irchhoff Deformable Models",
	year = "2005",
	month = aug,
	journal = "ACM Transactions on Graphics (Proceedings of SIGGRAPH)",
	volume = "24",
	number = "3",
	pages = "982--990",
	abstract = "In this paper, we present an approach for fast subspace integration of 
reduced-coordinate nonlinear deformable models that is suitable for interactive 
applications in computer graphics and haptics. Our approach exploits dimensional model 
reduction to build reduced-coordinate deformable models for objects with complex 
geometry. We exploit the fact that model reduction on large deformation models with 
linear materials (as commonly used in graphics) result in internal force models that 
are simply cubic polynomials in reduced coordinates. Coefficients of these polynomials 
can be precomputed, for efficient runtime evaluation. This allows simulation of nonlinear 
dynamics using fast implicit Newmark subspace integrators, with subspace integration 
costs independent of geometric complexity. We present two useful approaches for 
generating low-dimensional subspace bases: modal derivatives and an interactive sketch. 
Mass-scaled principal component analysis (mass-PCA) is suggested for dimensionality 
reduction. Finally, several examples are given from computer animation to illustrate 
high performance, including force-feedback haptic rendering of a complicated object 
undergoing large deformations.
",
}

@inproceedings{Pai:2001:SPI,
 author = "Dinesh K. Pai and Kees van den Doel and Doug L. James and Jochen Lang and 
           John E. Lloyd and Joshua L. Richmond and Som H. Yau",
 title = "Scanning physical interaction behavior of 3D objects",
 booktitle = "SIGGRAPH '01: Proceedings of the 28th annual conference on Computer 
              graphics and interactive techniques",
 year = "2001",
 isbn = "1-58113-374-X",
 pages = "87--96",
 doi = "http://doi.acm.org/10.1145/383259.383268",
 publisher = "ACM Press",
 address = "New York, NY, USA",
 abstract = "We describe a system for constructing computer models of several aspects 
of physical interaction behavior, by scanning the response of real objects. The 
behaviors we can successfully scan and model include deformation response, contact 
textures for interaction with force-feedback, and contact sounds. The system we 
describe uses a highly automated robotic facility that can scan behavior models of 
whole objects. We provide a comprehensive view of the modeling process, including 
selection of model structure, measurement, estimation, and rendering at interactive 
rates. The results are demonstrated with two examples: a soft stuffed toy which has 
significant deformation behavior, and a hard clay pot which has significant contact 
textures and sounds. The results described here make it possible to quickly construct 
physical interaction models of objects for applications in games, animation, 
and e-commerce.
",
}

@article{James:2005:SMA,
 author = "Doug L. James and Christopher D. Twigg",
 title = "Skinning mesh animations",
 journal = "ACM Trans. Graph.",
 volume = "24",
 number = "3",
 year = "2005",
 issn = "0730-0301",
 pages = "399--407",
 doi = "http://doi.acm.org/10.1145/1073204.1073206",
 publisher = "ACM Press",
 address = "New York, NY, USA",
 abstract = "We extend approaches for skinning characters to the general setting of 
skinning deformable mesh animations. We provide an automatic algorithm for generating 
progressive skinning approximations, that is particularly efficient for pseudo-articulated 
motions. Our contributions include the use of nonparametric mean shift clustering of 
high-dimensional mesh rotation sequences to automatically identify statistically relevant 
bones, and robust least squares methods to determine bone transformations, bone-vertex 
influence sets, and vertex weight values. We use a low-rank data reduction model defined 
in the undeformed mesh configuration to provide progressive convergence with a fixed number 
of bones. We show that the resulting skinned animations enable efficient hardware rendering, 
rest pose editing, and deformable collision detection. Finally, we present numerous examples 
where skins were automatically generated using a single set of parameter values.
",
}

@Conference{James:2004:SCA,
  author = "Doug L. James and Jernej Barbi\v{c} and Christopher D. Twigg",
  title = "Squashing Cubes: Automating Deformable Model Construction for Graphics",
  organization = "ACM SIGGRAPH",
  booktitle = "SIGGRAPH 2004 Technical Sketch",
  year = "2004",
  month = aug,
  location = "Los Angeles, California",
  publisher = "ACM Press",
 abstract = "The vast majority of geometric meshes used in computer graphics 
are optimized for rendering, and not deformable object simulation.
Despite tools for volume (or surface) (re)meshing of geometric models to support 
physical simulation, in practice, the construction of physically based deformable 
models from arbitrary graphical models remains a tedious process for animators.

Squashing Cubes (SC) automates the construction of physically based deformable 
objects from arbitrary geometric models. During preprocess, the geometric model 
(typically a surface mesh) is voxelized into tiny elastic cubes, i.e., the 
squashing cubes model. Second, a generic deformable object simulator is used to 
deform the SC model. Finally, the resulting deformations are interpolated back 
onto the original model, thus producing the final animation. Such domain embedding 
schemes are familiar to graphics [Pentland and Williams 1989; Faloutsos et al. 1997].

SC is simple to implement, practical for complex. . .
",
}

@inproceedings{Kulkarni:2007:OPR,
 author = {Milind Kulkarni and Keshav Pingali and Bruce Walter and Ganesh Ramanarayanan 
           and Kavita Bala and L. Paul Chew},
 title = {Optimistic parallelism requires abstractions},
 booktitle = {PLDI '07: Proceedings of the 2007 ACM SIGPLAN conference on Programming 
             language design and implementation},
 year = {2007},
 isbn = {978-1-59593-633-2},
 pages = {211--222},
 location = {San Diego, California, USA},
 doi = {http://doi.acm.org/10.1145/1250734.1250759},
 publisher = {ACM Press},
 address = {New York, NY, USA},
abstract = "Irregular applications, which manipulate large, pointer-based data
structures like graphs, are difficult to parallelize manually. Automatic
tools and techniques such as restructuring compilers and runtime
speculative execution have failed to uncover much parallelism
in these applications, in spite of a lot of effort by the research community.
These difficulties have even led some researchers to wonder
if there is any coarse-grain parallelism worth exploiting in irregular
applications.

In this paper, we describe two real-world irregular applications:
a Delaunay mesh refinement application and a graphics application
that performs agglomerative clustering. By studying the algorithms
and data structures used in these applications, we show that there
is substantial coarse-grain, data parallelism in these applications,
but that this parallelism is very dependent on the input data and
therefore cannot be uncovered by compiler analysis. In principle,
optimistic techniques such as thread-level speculation can be used
to uncover this parallelism, but we argue that current implementations
cannot accomplish this because they do not use the proper
abstractions for the data structures in these programs.
These insights have informed our design of the Galois system,
an object-based optimistic parallelization system for irregular
applications. There are three main aspects to Galois: (1) a small
number of syntactic constructs for packaging optimistic parallelism
as iteration over ordered and unordered sets, (2) assertions about
methods in class libraries, and (3) a runtime scheme for detecting
and recovering from potentially unsafe accesses to shared memory
made by an optimistic computation.

We show that Delaunay mesh generation and agglomerative
clustering can be parallelized in a straight-forward way using the
Galois approach, and we present experimental measurements to
show that this approach is practical. These results suggest that
Galois is a practical approach to exploiting data parallelism in
irregular programs. 
",

 }
