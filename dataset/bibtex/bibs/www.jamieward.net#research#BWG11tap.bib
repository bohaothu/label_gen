@ARTICLE{BWG11tap,
    author = {Bulling, Andreas and Ward, Jamie A. and Gellersen, Hans},
     title = {Multi-{M}odal {R}ecognition of {R}eading {A}ctivity in {T}ransit {U}sing {B}ody-{W}orn {S}ensors},
   journal = {ACM Transactions on Applied Perception},
      year = {2011},
      note = {to appear},
  abstract = {Reading is one of the most well studied visual activities. Vision research traditionally focuses on understanding the perceptual and cognitive processes involved in reading. In this work we recognise reading activity by jointly analysing eye and head movements of people in an everyday environment. Eye movements are recorded using an electrooculography (EOG) system; body movements using body-worn inertial measurement units. We compare two approaches for continuous recognition of reading: String matching (STR) that explicitly models the characteristic horizontal saccades during reading, and a support vector machine (SVM) that relies on 90 eye movement features extracted from the eye movement data. We evaluate both methods in a study performed with eight participants reading while sitting at a desk, standing, walking indoors and outdoors, and riding a tram. We introduce a method to segment reading activity by exploiting the sensorimotor coordination of eye and head movements during reading. Using person-independent training, we obtain an average precision for recognising reading of 88.9\% (recall 72.3\%) using STR and of 87.7\% (recall 87.9\%) using SVM over all participants. We show that the proposed segmentation scheme improves the performance of recognising reading events by more than 24\%. Our work demonstrates that the joint analysis of multiple modalities is beneÔ¨Åcial for reading recognition and opens up discussion on the wider applicability of this recognition approach to other visual and physical activities.}
}

