<html><head>     
<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1">
<meta http-equiv="cache-control" content="no-cache">
<meta http-equiv="pragma" content="no-cache">
<META HTTP-EQUIV="EXPIRES" CONTENT="Mon, 22 Jul 2002 11:12:01 GMT">

<SCRIPT SRC="/wavemaster.internal/v2.6/tools-eg_bs/cookie.js"></SCRIPT>
 <STYLE TYPE="text/css"><!--
 .hw-annotation { text-decoration: none; color: black; background:#f3ca81; font-weight: bold; }
--></STYLE>
<META NAME="Author" VALUE="hwsystem">
<META NAME="DocumentType" VALUE="text">
<META NAME="GOid" VALUE="0x811bda11_0x000005be">
<META NAME="HW_Checksum" VALUE="beb6a178d4373db0ea5c0c3bd5bc66ad">
<META NAME="HW_ChildAccess" VALUE="NO_ACCESS">
<META NAME="HW_EffectiveAccess" VALUE="READ_ACCESS">
<META NAME="HW_ObjectName" VALUE="cgf19.bib">
<META NAME="MimeType" VALUE="text/plain">
<META NAME="Name" VALUE="EG/DL/BibDB/cgf19.bib">
<META NAME="ObjectID" VALUE="0x00000031">
<META NAME="PLACETemplate" VALUE="egnew/master">
<META NAME="Path" VALUE="DC0x00000437 0x00015124">
<META NAME="Rights" VALUE="R:a, g eg-pub eg-root everyone; W:a, g eg-pub eg-root; A:a">
<META NAME="TimeCreated" VALUE="2007/10/15 08:20:48">
<META NAME="TimeModified" VALUE="2008/01/16 09:54:40">
<META NAME="Title" VALUE="en:cgf19.bib">
<META NAME="Type" VALUE="Document">
<TITLE>cgf19.bib</TITLE>
<BASE HREF="http://diglib.eg.org/EG/DL/BibDB/cgf19.bib">

<style type="text/css">



body,td,p {
	color:#333333;
	font-size:15px;
	font-family: Trebuchet MS, Trebuchet,  Helvetica, Arial, sans-serif;
}

a { text-decoration:none; }

a:link { color:#0099ff; }

a:visited { color:#336699; }

a:active { color:#ff9900; }

a:hover {  color:#ff9900;  }


a.small:link { color:#0099ff;font-size:12px; }

a.small:visited { color:#336699;font-size:12px; }

a.small:active { color:#ff9900;font-size:12px; }

a.small:hover {  color:#ff9900;font-size:12px;  }

.small {
	font-family: Helvetica, Arial, sans-serif;
	font-size:12px;					
	color:#333333;
       }   
h1 {
	font-size: 21px;
	color:#ff9900;
	font-weight: bold;
}
h2 {
	font-size: 18px;
	color:#ff9900;
	font-weight: bold;
	margin-bottom: 0px;
}
h3 {
	margin-bottom: 0px;
	color:#ff9900;
	font-weight: bold;
}
strong {
	color:#666666;
}
.menu{
	background-color:#ffffff;
	font-size:13px;
	font-weight: bold;
	font-family: Trebuchet MS, Trebuchet,  Helvetica, Arial, sans-serif;
	text-align:center;
	line-height: 18px;
        }
.menuselected{
	background-color:#ff9900;
	font-size:13px;
	font-weight: bold;
	color:#000000;
	font-family: Trebuchet MS, Trebuchet, Helvetica, Arial, sans-serif;
	text-align:center;
	line-height: 18px;
        }

.menu a {color:#000000;
		}
.menu a:hover {  color:#ff9900;  
		}
.menu2{
	background-color:#ffffff;
	padding-left:13px; 
	font-size:12px;
	color:#ff9900;
	line-height: 24px;
	font-family: "Trebuchet MS", "Trebuchet", Arial, Helvetica, sans-serif;
        }
.menu2 a {color:#0099ff;
		}
.menu2 a:hover {  color:#ff9900;  
		}
.menu3{
	background-color:#ffffff;
	text-align:center; 
	font-size:13px;
	color:#ff9900;
	line-height: 24px;
	font-family: "Trebuchet MS", "Trebuchet", Arial, Helvetica, sans-serif;
        }
.box1{
	background-color:#ff9900;
	font-size:13px;
	font-weight: bold;
	font-family: Trebuchet MS, Trebuchet,  Helvetica, Arial, sans-serif;
	line-height: 19px;
	color:#ffffff;
	text-align:right;
        }
.box2{
	background-color:#66ccff;
	font-size:13px;
	font-weight: bold;
	font-family: Trebuchet MS, Trebuchet,  Helvetica, Arial, sans-serif;
	line-height: 19px;
	color:#ffffff;
	text-align:right;
        }
.boxtopic{
	text-align:right;
	padding-right:16px; 
        }
.boxcontent {
	font-family: Helvetica, Arial, sans-serif;
	font-size:12px;	
	color:#333333;
	text-align:left;
	padding:16px;
       }
.hr1{
	color:#ff9900;
        }
.hr2{
	color:#66ccff;
        }
.frame1{
	background-color:#ff9900;
        }
.frame2{
	background-color:#66ccff;
        }
.content {border:0; 
	padding-left:12px;
	padding-right:12px;
	}
	

.box3{
   background-color:#66ccff;
   font-size:13px;
   font-weight: bold;
   font-family: Trebuchet MS, Trebuchet,  Helvetica, Arial, sans-serif;
   line-height: 19px;
   color:#ffffff;
   text-align:center;
}

.box4{
   background-color:#66ccff;
   font-size:13px;
   font-weight: bold;
   font-family: Trebuchet MS, Trebuchet,  Helvetica, Arial, sans-serif;
   line-height: 19px;
   color:#ffffff;
   text-align:left;
}

.boxcontent2 {
	font-family: Helvetica, Arial, sans-serif;
	font-size:12px;	
	color:#333333;
	text-align:center;
	padding:10px;
}

.boxcontent3 {
   font-family: Helvetica, Arial, sans-serif;
   font-size:12px;
   color:#333333;
   text-align:right;
   padding:10px;
}

.boxcontent4 {
   font-family: Helvetica, Arial, sans-serif;
   font-size:12px;	
   color:#333333;
   text-align:left;
   padding:10px;
}

	
</style>

</HEAD>
<BODY   alink="#ff9900" bgcolor="#FFFFFF" link="#0099ff" text="#000000" vlink="#336699">






<table width="761" border="0" align="left" cellpadding="0" cellspacing="0">
  <!--DWLayoutTable-->
  <tr> 
    <!--The Logo will be shown next: -->


    <td>

    	<table width="144" border="0" cellspacing="0" cellpadding="1" class=frame1>

    		<tr>

    		<td width="142" align="center"><a href="http://www.eg.org/"><img src="http://diglib.eg.org/v2.6/graphics/new/logo.gif;internal&inline=true" alt="EG - Logo" width="142" height="110" border="0"></a></td>

    		</tr>

    	</table>

    </td>

    <td width="17"><img src="http://diglib.eg.org/v2.6/graphics/new/spacer.gif;internal&inline=true" width="17" height="1"></td>

    <td>

    	<table width="600" border="0" cellspacing="0" cellpadding="1" class=frame1>

    		<tr>

    		<td width="598"><img src="http://diglib.eg.org/v2.6/graphics/new/head.gif;internal&inline=true" alt="EuroGraphics" width="598" height="110"></td>

    		</tr>

    	</table>

    </td>

    

    

    

  </tr>
  <tr> 
    <td colspan="3" width="761" height="17"><img src="news-Dateien/spacer.gif" width="1" height="17"></td>
  </tr>
  <tr> 
    <td width="144" valign="top"> 
           
      <!--The Member Login Box will be shown next: -->
      <table width="100%" border="0" cellspacing="0" cellpadding="1" class=frame1>

<TBODY>
<TR>
   <TD>
            <TABLE border=0 cellPadding=0 cellSpacing=0 width="100%">
              <TBODY>
              <TR>
                <TD align=right bgColor=#cccccc class=box1><SPAN 
                  class=boxtopic>Members</SPAN></TD></TR>
              <TR>
                <TD bgColor=#ffffff>
                  <DIV class=boxcontent>
                  Please 

                  <A  HREF="http://www.eg.org/login">login</A> 
                  
                  
                  
                  <!--(note for <a href="/safari.html">Safari users</a>)-->
                  if you are a member or <a  href="/about/membership">read more</a> about the advantages of an EG membership.
                  <HR class=hr1 noShade SIZE=1>
                  <br>
                  
                  Not yet member? <A HREF="/join">Application</A><br>
                  <A HREF="https://www.eg.org/renew">Renewal</A>
                  <HR class=hr1 noShade SIZE=1>
                  Forgot your password? <A HREF="http://diglib.eg.org/EG/DL/BibDB/cgf19.bib;internal&action=forgot.password.action">Click  here!</A> 
                 </DIV></TD>  
                 </TR></TBODY></TABLE></TD></TR></TBODY>
      </table>
      <br> 
      <!--The New Box will be shown next: -->
      <table width="100%" border="0" cellspacing="0" cellpadding="1" class="frame2">
<tr>
	<td>
		<table border="0" cellpadding="0" cellspacing="0" width="100%">
        	<tbody><tr>
           		<td class="box2" align="right" bgcolor="#cccccc"><span class="boxtopic">EG 2009</span></td>
			</tr>
			<tr>
           		<td bgcolor="#ffffff">
				<div class="boxcontent">
				
                <a href="http://www.eurographics2009.de/">Eurographics 2009:</a> 30th of March to the 3rd of April 2009 in Munich (Germany).
				<hr noshade class="hr2" size="1" >
				<!--<a href="http://www.ics.forth.gr/eg2008/" target="_blank"><img src="/EG/images/eg2k8.png" border="0" height="23" width="103"></a>
			         EG08 will be from 14th to the 18th April 2008
                              <hr class="hr2" noshade="noshade" size="1">-->

                          <!--
                        Eurographics 2007: 3rd to the 7th September 2007 in Prague (Czech Republic).
				<hr noshade class="hr2" size="1" >
				Previous Event: <a href="http://www.cgg.cvut.cz/eg07/">Eurographics 2007</a>
				-->
                       <!-- Eurographics 2006: 4th - 8th of September 2006 in Vienna (Austria)<br>
                        <hr noshade class="hr2" size="1" >-->
			<!--    Previous Event: <a href="http://www.cg.tuwien.ac.at/events/EG06/index.html">Eurographics 2006</a>>-->
                                Previous Event: <a href="http://www.ics.forth.gr/eg2008/">Eurographics 2008</a>
				</div>
				</td>
			</tr>
		</tbody></table>
	</td>
</tr>
      </table>
      <br>

      
    </td>
    <td>&nbsp;</td>

	<td valign="top">

                <PRE>
@article{DeNeve:2000:AAC,
   author = {P. De Neve and K. Denecker and W. Philips and I.
Lemahieu},
   title = {An Advanced Color Representation for Lossy
Compression of {CMYK} Prepress Images},
   volume = {19},
   number = {1},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {March},
   publisher = {Blackwell Publishers},
   pages = {3-12},
   note = {{ISSN} 1067-7055},
   annote = {{CMYK} color images are used extensively in prepress
applications. When compressing those color images one has to deal
with four different color channels. Usually compression
algorithms only take into account the spatial redundancy that is
present in the image data. This approach does not yield an
optimal data reduction since there also exists a high correlation
between the different colors in natural images.\\This paper shows
that a significant gain in data reduction can be achieved by
exploiting this color redundancy. Some popular transform coders,
including DCT-based {JPEG} and the {SPIHT} wavelet coder, were used
for reducing the spatial redundancy. The performance of the
algorithms was evaluated using a quality criterion based on human
perception like the mean CIEL*a*b*E error. },
}
@article{Stamminger:2000:EGG,
      author = {Marc Stamminger and Annette Scheel and Xavier
      Granier and Frederic Perez-Cazorla and George Drettakis and
      Fran{\c{c}}ois X. Sillion},
         title = {Efficient Glossy Global Illumination with Interactive
      Viewing},
         volume = {19},
         number = {1},
         journal = {Computer Graphics Forum},
         year = {2000},
         month = {March},
         publisher = {Blackwell Publishers},
         pages = {13-25},
         note = {{ISSN} 1067-7055},
         annote = {The ability to perform interactive walkthroughs of
      global illumination solutions including glossy effects is a
      challenging open problem. In this paper we overcome certain
      limitations of previous approaches. We first introduce a novel,
      memory- and compute-efficient representation of incoming
      illumination, in the context of a hierarchical radiance
      clustering algorithm. We then represent outgoing radiance with an
      adaptive hierarchical basis, in a manner suitable for interactive
      display. Using appropriate refinement and display strategies, we
      achieve walkthroughs of glossy solutions at interactive rates for
      non-trivial scenes. In addition, our implementation has been
      developed to be portable and easily adaptable as an extension to
      existing, diffuse-only, hierarchical radiosity systems. We
      present results of the implementation of glossy global
      illumination in two independent global illumination systems. },
     }
@article{Sousa:2000:OMO,
   author = {Mario Costa Sousa and John W. Buchanan},
   title = {Observational Models of Graphite Pencil Materials},
   volume = {19},
   number = {1},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {March},
   publisher = {Blackwell Publishers},
   pages = {27-49},
   note = {{ISSN} 1067-7055},
   annote = {This paper presents models for graphite pencil,
drawing paper, blenders, and kneaded eraser that produce
realistic looking pencil marks, textures, and tones. Our models
are based on an observation of how lead pencils interact with
drawing paper, and on the absorptive and dispersive properties of
blenders and erasers interacting with lead material deposited
over drawing paper. The models consider parameters such as the
particle composition of the lead, the texture of the paper, the
position and shape of the pencil materials, and the pressure
applied to them. We demonstrate the capabilities of our approach
with a variety of images and compare them to digitized pencil
drawings. We also present image-based rendering results
implementing traditional graphite pencil tone rendering methods.
},
}
@article{Veryovka:2000:TDM,
   author = {Oleg Veryovka and John W. Buchanan},
   title = {Texture-based Dither Matrices},
   volume = {19},
   number = {1},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {March},
   publisher = {Blackwell Publishers},
   pages = {51-64},
   note = {{ISSN} 1067-7055},
   annote = {Continuous tone images must be halftoned to be
displayed on binary output devices such as printers. Halftoning
algorithms at low resolutions of the output hardware introduce
textures into the resulting display. In this work we control
halftoning texture by generating a threshold matrix from an
image-based texture. We demonstrate that processing textures by
the adaptive histogram equalization algorithm approximates pixel
distribution properties of traditional dither screens. Ordered
dithering with the resulting threshold matrix enables us to
define texture in the halftoned image. We control the appearance
of this texture by a combination of the ordered dither algorithm
with an error diffusion process. We present applications of
texture-based dither screens to both photorealistic and artistic
rendering. In the case of photorealistic tone reproduction our
technique preserves textures and edges of the original image. The
ability to define an arbitrary texture enables us to introduce a
variety of artistic effects, including embossing of images with
textures and text, and approximation of the appearance of of
conventional illustration media. We evaluate the resulting
halftoning using multi-scale edge distortion measures. Our
quantitative evaluation closely corresponds to the visual
observations. },
}
@article{Choi:2000:GIO,
   author = {Min-Hyung Choi and James F. Cremer},
   title = {Geometrically-Aware Interactive Object Manipulation},
   volume = {19},
   number = {1},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {March},
   publisher = {Blackwell Publishers},
   pages = {65-76},
   note = {{ISSN} 1067-7055},
   annote = {This paper describes formulation and management of
constraints, and a nonlinear optimization algorithm that together
enable interactive geometrically aware manipulation of
articulated objects. Going beyond purely kinematic or dynamic
approaches, our solution method directly employs geometric
constraints to ensure non-interpenetration during object
manipulation. We present the formulation of the inequality
constraints used to ensure nonpenetration, describe how to manage
the set of active inequality constraints as objects move, and
show how these results are combined with a nonlinear optimization
algorithm to achieve interactive geometrically aware object
manipulation. Our optimization algorithm handles equality and
inequality constraints and does not restrict object topology. It
is an efficient iterative algorithm, quadratically convergent,
with each iteration bounded by O(nnz(L)), where nnz(L) is the
number of non-zeros in L, a Cholesky factor of a sparse matrix.
},
}
@article{Lee:2000:GA3,
   author = {WonSook Lee and Jin Gu and Nadia Magnenat-Thalmann},
   title = {Generating Animatable {3D} Virtual Humans from
Photographs},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   note = {{ISSN} 1067-7055},
   annote = {We present an easy, practical and efficient full
body cloning methodology. This system utilizes photos taken from
the front, side and back of a person in any given imaging
environment without requiring a special background or a
controlled illuminating condition. A seamless generic body
specified in the {VRML} H-Anim 1.1 format is used to generate an
individualized virtual human. The system is composed of two major
components: face-cloning and body-cloning. The face-cloning
component uses feature points on front and side images and then
applies {DFFD} for shape modification. Next a fully automatic
seamless texture mapping is generated for 360 degree coloring on
a {3D} polygonal model. The body-cloning component has two steps:
(i feature points specification, which enables automatic
silhouette detection in an arbitrary background (ii two-stage
body modification by using feature points and body silhouette
respectively. The final integrated human model has
photo-realistic animatable face, hands, feet and body. The result
can be visualized in any {VRML} compliant browser. },
}
@article{Monzani:2000:UAI,
   author = {Jean-S{\'{e}}bastien Monzani and Paolo Baerlocher
and Ronan Boulic and Daniel Thalmann},
   title = {Using an Intermediate Skeleton and Inverse Kinematics
for Motion Retargeting},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   note = {{ISSN} 1067-7055},
   annote = {In this paper, we present a new method for solving
the Motion Retargeting Problem, by using an intermediate
skeleton. This allows us to convert movements between
hierarchically and geometrically different characters. An Inverse
Kinematics engine is then used to enforce Cartesian constraints
while staying as close as possible to the captured motion. },
}
@article{Rudolf:2000:MTM,
   author = {Marcin J. Rudolf and Jacek Raczkowski},
   title = {Modeling the Motion of Dense Smoke in the Wind
Field},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   note = {{ISSN} 1067-7055},
   annote = {This paper presents a volumetric animation technique
for modeling the turbulent motion of very dense and turbulent
smoke such as one coming from a steam engine. A new method of the
wind field generation is proposed. Gas motion is determined by
the integration of two independent vector layers. The first one
is a combination of flow primitives and the second is created by
stochastically generated turbulence. Special attention is taken
of the proper construction of the turbulent layer. For the
visualization purposes a simple volume raytracer is applied. Many
light sources are taken into account to achieve photorealistic
effects. Finally some interesting animations are overviewed.
Computation times for a {PC} Pentium 200 and an {SGI} O2 workstation
are compared to demonstrate the high efficiency of the method. },
}
@article{Jobard:2000:UFV,
   author = {Bruno Jobard and Wilfrid Lefer},
   title = {Unsteady Flow Visualization by Animating
Evenly-Spaced Streamlines},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   note = {{ISSN} 1067-7055},
   annote = {In recent years the work on vector field
visualization has been concentrated on LIC-based methods. In this
paper we propose an alternative solution for the visualization of
unsteady flow fields. Our approach is based on the computation of
temporal series of correlated images. While other methods are
based on pathlines and try to correlate successive images at the
pixel level, our approach consists in correlating instantaneous
visualizations of the vector field at the streamline level. For
each frame a feed forward algorithm computes a set of
evenly-spaced streamlines as a function of the streamlines
generated for the previous frame. This is achieved by
establishing a correspondence between streamlines at successive
time steps. A cyclical texture is mapped onto every streamline
and textures of corresponding streamlines at different time steps
are correlated together so that, during the animation, they move
along the streamlines, giving the illusion that the flow is
moving in the direction defined by the streamline. Our method
gives full control on the image density so that we are able to
produce smooth animations of arbitrary density, covering the
field of representations from sparse, that is classical
streamline-based images, to dense, that is texture-like images.
},
}
@article{Deussen:2000:FPA,
   author = {Oliver Deussen and Stefan Hiller and Cornelius van
Overveld and Thomas Strothotte},
   title = {Floating Points: A Method for Computing Stipple
Drawings},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   note = {{ISSN} 1067-7055},
   annote = {We present a method for computer generated
pen-and-ink illustrations by the simulation of stippling. In a
stipple drawing, dots are used to represent tone and also
material of surfaces. We create such drawings by generating an
initial dot set which is then processed by a relaxation method
based on Voronoi diagrams. The point patterns generated are
approximations of Poisson disc distributions and can also be used
for integrating functions or the positioning of objects. We
provide an editor similar to paint systems for interactively
creating stipple drawings. This makes it possible to create such
drawings within a matter of hours, instead of days or even weeks
when the drawing is done manually. },
}
@article{Mizuno:2000:AGO,
   author = {S. Mizuno and T. Kasaura and T. Okouchi and S.
Yamamoto and M. Okada and J. Toriwaki},
   title = {Automatic Generation of Virtual Woodblocks and
Multicolor Woodblock Printing},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   note = {{ISSN} 1067-7055},
   annote = {In this paper, we study a method to synthesize a
multicolor virtual woodblock print by using several virtual
woodblocks. It consists of two sections: carving and printing, to
synthesize a virtual print. In the carving section, virtual
woodblocks are generated by a user with supporting of an
automatically carving method based on feature extraction of a
gray value image. And woodblocks are also generated automatically
by using a full-color image as a draft. In the printing section,
a &quot;paper sheet,&quot; a &quot;printing brush&quot; and &quot;ink&quot; are prepared in
addition to the &quot;woodblock&quot; in the virtual space and the user
synthesizes a woodblock print interactively. As the printing
factors, a color of ink, a moisture value and a grain change the
finish of the print. Using several virtual woodblocks and
printing to a paper sheet in succession, a printing image of each
woodblock is combined based on the printing factors and a
multicolor virtual prints is synthesized. },
}
@article{Havran:2000:LRS,
   author = {V. Havran and J. Bittner},
   title = {{LCTS}: Ray Shooting using Longest Common Traversal
Sequences},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   note = {{ISSN} 1067-7055},
   annote = {We describe two new techniques of ray shooting
acceleration that exploit the traversal coherence of a spatial
hierarchy. The first technique determines a sequence of adjacent
leaf-cells of the hierarchy that is pierced by all rays contained
within a certain convex shaft. This sequence is used to
accelerate ray shooting for all remaining rays within the shaft.
The second technique establishes a cut of the hierarchy that
contains nodes where the hierarchy traversal can no longer be
predetermined for all rays contained within a given shaft. This
cut is used to initiate the traversal for all remaining rays
contained in the shaft. The description of the methods is
followed by results evaluated by their practical implementation.
},
}
@article{Thomas:2000:MVC,
   author = {Gwenola Thomas and St{\'{e}}phane Donikian},
   title = {Modelling virtual cities dedicated to behavioural
animation },
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   note = {{ISSN} 1067-7055},
   annote = {In order to populate virtual cities, it is necessary
to specify the behaviour of dynamic entities such as pedestrians
or car drivers. Since a complete mental model based on vision and
image processing cannot be constructed in real time using purely
geometrical information, higher levels of information are needed
in a model of the virtual environment. For example, the
autonomous actors of a virtual world would exploit the knowledge
of the environment topology to navigate through it. In this
article, we present a model of virtual urban environments using
structures and information suitable for behavioural animations.
Thanks to this knowledge, autonomous virtual actors can behave
like pedestrians or car drivers in a complex city environment. A
city modeler has been designed, using this model of urban
environment, and enables complex urban environments for
behavioural animation to be automatically produced. },
}
@article{Smith:2000:BVE,
   author = {Shamus P. Smith and David J. Duke},
   title = {Binding Virtual Environments to Toolkit
Capabilities},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   note = {{ISSN} 1067-7055},
   annote = {There are many toolkits and development environments
that aid the process of constructing virtual environment
applications. Many of these development environments encourage
customising a virtual environment's design while rapid
prototyping within the confines of a toolkit's capabilities. Thus
the choice of the technology and its associated support has been
made independent of the end-use requirements of the final system.
This can bias a virtual environment's design by implementation
based constraints. We propose that an alternative approach is the
consideration of virtual environment requirements in the context
of an inspectable design model, to identify the requirements that
a toolkit will need to support. In the context of an example, we
present a selection of design requirements that we consider
important for virtual environment design in general. We explore
how these requirements might be mapped to different capabilities
using Virtual Reality Modelling Language (VRML) as a concrete
example of a platform technology. },
}
@article{Zeleznik:2000:SCB,
   author = {Bob Zeleznik and Loring Holden and Michael Capps and
Howard Abrams and Tim Miller},
   title = {Scene-Graph-As-Bus: Collaboration between
Heterogeneous Stand-alone 3-D Graphical Applications},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   note = {{ISSN} 1067-7055},
   annote = {We describe the Scene-Graph-As-Bus technique (SGAB),
the first step in a staircase of solutions for sharing software
components for virtual environments. The goals of {SGAB} are to
allow, with minimal effort, independently-designed applications
to share component functionality; and for multiple users to share
applications designed for single users.This paper reports on the
SGAB design for transparently conjoining different applications
by unifying the state information contained in their scene
graphs. {SGAB} monitors and maps changes in the local scene graph
of one application to a neutral scene graph representation (NSG),
distributes the {NSG} changes over the network to remote peer
applications, and then maps the {NSG} changes to the local scene
graph of the remote application. The fundamental contribution of
SGAB is that both the local and remote applications can be
completely unaware of each other; that is, both applications can
interoperate without code or binary modification despite each
having no knowledge of networking or interoperability. },
}
@article{Cuny:2000:ANA,
   author = {Fran{\c{c}}ois Cuny and Laurent Alonso and Nicolas
Holzschuch},
   title = {A Novel Approach Makes Higher Order Wavelets Really
Efficient for Radiosity},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   note = {{ISSN} 1067-7055},
   annote = {Since wavelets were introduced in the radiosity
algorithm, surprisingly little research has been devoted to
higher order wavelets and their use in radiosity algorithms. A
previous study has shown that wavelet radiosity, and especially
higher order wavelet radiosity was not bringing significant
improvements over hierarchical radiosity and was having a very
important extra memory cost, thus prohibiting any effective
computation. In this paper, we present a new implementation of
wavelets in the radiosity algorithm, that is substantially
different from previous implementations in several key areas
(refinement oracle, link storage, resolution algorithm). We show
that, with this implementation, higher order wavelets are
actually bringing an improvement over standard hierarchical
radiosity and lower order wavelets. },
}
@article{Chang:2000:PPF,
   author = {Yao-Xun Chang and Zen-Chung Shih},
   title = {Physically-Based Patination for Underground Objects},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   note = {{ISSN} 1067-7055},
   annote = {Although current photorealistic rendering techniques
can produce very impressive images, the rendered objects are
often too clean and shiny. Thus, the resulting images look
unnatural. This paper proposes a physically-based model to
simulate the appearance of patinas on ancient Chinese bronzes.
Buried in the soil for thousands of years, many patinas are found
on the surface of ancient bronzes as a result of the aging
process and the physical and chemical conditions of the soil
environment. The development of patinas is modulated herein by
L-systems according to tendencies based on the environmental
factors and object geometry. The tendencies are employed to
represent the accumulative effect of all factors on patination.
The proposed model can be extended to simulate a variety of
metallic patinas including the ancient Chinese bronzes discovered
at San-hsing-tui, Sichuan, China. },
}
@article{Tarini:2000:RTA,
   author = {M. Tarini and P. Cignoni and C. Rocchini and Roberto
Scopigno},
   title = {Real Time, Accurate, Multi-Featured Rendering of Bump
Mapped Surfaces},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   note = {{ISSN} 1067-7055},
   annote = {We present a new technique to render in real time
objects which have part of their high frequency geometric detail
encoded in bump maps. It is based on the quantization of
normal-maps, and achieves excellent result both in rendering time
and rendering quality, with respect to other alternative methods.
The method proposed also allows to add many interesting visual
effects, even for object with large bumb maps, including non-s
rendering, chrome effects, shading under multiple lights,
rendering of different materials within a single object, specular
reflections and others. Moreover, the implementation of the
method is not complex and can be eased by software reuse. },
}
@article{Labsik:2000:I3S,
   author = {U. Labsik and G. Greiner},
   title = {Interpolatory sqrt(3)-Subdivision},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   note = {{ISSN} 1067-7055},
   annote = {We present a new interpolatory subdivision scheme
for triangle meshes. Instead of splitting each edge and
performing a 1-to-4 split for every triangle we compute a new
vertex for every triangle and retriangulate the old and the new
vertices. Using this refinement operator the number of triangles
only triples in each step. New vertices are computed with a
Butterfly like scheme. In order to obtain overall smooth surfaces
special rules are necessary in the neighborhood of extraordinary
vertices. The scheme is suitable for adaptive refinement by using
an easy forward strategy. No temporary triangles are produced
here which allows simpler data structures and makes the scheme
easy to implement. },
}
@article{El-Sana:2000:EMV,
   author = {Jihad El-Sana and Yi-Jen Chiang},
   title = {External Memory View-Dependent Simplification},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   note = {{ISSN} 1067-7055},
   annote = {In this paper, we propose a novel external-memory
algorithm to support view-dependent simplification for datasets
much larger than main memory. In the preprocessing phase, we use
a new spanned sub-meshes simplification technique to build
view-dependence trees I/O-efficiently, which preserves the
correct edge collapsing order and thus assures the run-time image
quality. We further process the resulting view-dependence trees
to build the meta-node trees, which can facilitate the run-time
level-of-detail rendering and is kept in disk. During run-time
navigation, we keep in main memory only the portions of the
meta-node trees that are necessary to render the current level of
details, plus some prefetched portions that are likely to be
needed in the near future. The prefetching prediction takes
advantage of the nature of the run-time traversal of the
meta-node trees, and is both simple and accurate. We also employ
the implicit dependencies for preventing incorrect foldovers, as
well as main-memory buffer management and parallel processes
scheme to separate the disk accesses from the navigation
operations, all in an integrated manner. The experiments show
that our approach scales well with respect to the main memory
size available, with encouraging preprocessing and run-time
rendering speeds and without sacrificing the image quality. },
}
@article{Muller:2000:SST,
   author = {Kerstin M{\&quot;{u}}ller and Sven Havemann},
   title = {Subdivision Surface Tesselation on the Fly using a
versatile Mesh Data Structure},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   note = {{ISSN} 1067-7055},
   annote = {Subdivision surfaces have become a standard
technique for freeform shape modeling. They are intuitive to use
and permit designers to flexibly add detail. But with larger
control meshes, efficient adaptive rendering techniques are
indispensable for interactive visualization and shape modeling.
In this paper, we present a realization of tesselation-on-the-fly
for Loop subdivision surfaces as part of a framework for
interactive visualization. },
}
@article{Bimber:2000:ARW,
   author = {Oliver Bimber and L. Miguel Encarna{\c{c}}{\'{a}}o
and Dieter Schmalstieg},
   title = {Augmented Reality with Back-Projection Systems using
Transflective Surfaces},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   note = {{ISSN} 1067-7055},
   annote = {In this paper, we introduce the concept of Extended
VR (extending viewing space and interaction space of
back-projection {VR} systems), by describing the use of a hand-held
semi-transparent mirror to support augmented reality tasks with
back-projection systems. This setup overcomes the problem of
occlusion of virtual objects by real ones linked with such
display systems. The presented approach allows an intuitive and
effective application of immersive or semi-immersive virtual
reality tasks and interaction techniques to an augmented
surrounding space. Thereby, we use the tracked mirror as an
interactive image-plane that merges the reflected graphics, which
are displayed on the projection plane, with the transmitted image
of the real environment. In our implementation, we also address
traditional augmented reality problems, such as real-object
registration and virtual-object occlusion. The presentation is
complemented by a hypothesis of conceivable further setups that
apply transflective surfaces to support an Extended {VR}
environment. },
}
@article{Faconti:2000:HCF,
   author = {G. Faconti and M. Massink and M. Bordegoni and F. De
Angelis and S. Booth},
   title = {Haptic Cues for Image Disambiguation},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   note = {{ISSN} 1067-7055},
   annote = {Haptic interfaces represent a revolution in human
computer interface technology since they make it possible for
users to touch and manipulate virtual objects. In this work we
describe a cross-model interaction experiment to study the effect
of adding haptic cues to visual cues when vision is not enough to
disambiguate the images. We relate the results to those obtained
in experimental psychology as well as to more recent studies on
the subject. },
}
@article{Min:2000:PAM,
   author = {Patrick Min and Thomas Funkhouser},
   title = {Priority-Driven Acoustic Modeling for Virtual
Environments},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   note = {{ISSN} 1067-7055},
   annote = {Geometric acoustic modeling systems spatialize
sounds according to reverberation paths from a sound source to a
receiver to give an auditory impression of a virtual {3D}
environment. These systems are useful for concert hall design,
teleconferencing, training and simulation, and interactive
virtual environments. In many cases, such as in an interactive
walkthrough program, the reverberation paths must be updated
within strict timing constraints - e.g., as the sound receiver
moves under interactive control by a user. In this paper, we
describe a geometric acoustic modeling algorithm that uses a
priority queue to trace polyhedral beams representing
reverberation paths in best-first order up to some termination
criteria (e.g., expired time-slice). The advantage of this
algorithm is that it is more likely to find the highest priority
reverberation paths within a fixed time-slice, avoiding many
geometric computations for lower-priority beams. Yet, there is
overhead in computing priorities and managing the priority queue.
The focus of this paper is to study the trade-offs of the
priority-driven beam tracing algorithm with different priority
functions. During experiments computing reverberation paths
between a source and a receiver in a {3D} building environment, we
find that priority functions incorporating more accurate
estimates of source-to-receiver path length are more likely to
find early reverberation paths useful for spatialization,
especially in situations where the source and receiver cannot
reach each other through trivial reverberation paths. However,
when receivers are added to the environment such that it becomes
more densely and evenly populated, this advantage diminishes. },
}
@article{Kim:2000:RMW,
   author = {Tae-hoon Kim and Jehee Lee and Sung Yong Shin},
   title = {Robust Motion Watermarking based on Multiresolution
Analysis},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   note = {{ISSN} 1067-7055},
   annote = {Digital watermarking is one of commonly used
solutions for copyright protection. A watermark should be
imperceptible and robust to various attacks. In this paper, we
address watermarking for motion data. Our watermarking scheme is
based on two well-known ideas, so called multiresolution
representation and spread spectrum. We embed a watermark into a
motion signal by perturbing large detail coefficients of its
multiresolution representation, and extract the watermark by
analyzing perturbation of coefficients from a suspected signal.
For more effective watermark extraction, we align suspected
motion data to the original using dynamic time warping. Our
scheme has merits of spread spectrum such as the resilience to
common signal processing as well as the robustness to time
warping. },
}
@article{Benedens:2000:TBD,
   author = {Oliver Benedens and Christoph Busch},
   title = {Towards Blind Detection of Robust Watermarks in
Polygonal Models},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   note = {{ISSN} 1067-7055},
   annote = {We describe a Digital Watermarking system dedicated
for embedding watermarks into {3D} polygonal models. The system
consists of three watermarking algorithms, one named Vertex Flood
Algorithm (VFA) suitable for embedding fragile public readable
watermarks with high capacity and offering a way of model
authentication, one realizing affine invariant watermarks, named
Affine Invariant Embedding (AIE) and a third one, named Normal
Bin Encoding (NBE) algorithm, realizing watermarks with
robustness against more complex operations, most noticeably
polygon reduction. The watermarks generated by these algorithms
are stackable. We shortly discuss the implementation of the
system, which is realized as a {3D} Studio {MAX} plugin. },
}
@article{Dafner:2000:CSF,
   author = {Revital Dafner and Daniel Cohen-Or and Yossi
Matias},
   title = {Context-based Space Filling Curves},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   note = {{ISSN} 1067-7055},
   annote = {A context-based scanning technique for images is
presented. An image is scanned along a context-based space
filling curve that is computed so as to exploit inherent
coherence in the image. The resulting one-dimensional
representation of the image has improved autocorrelation compared
with universal scans such as the Peano-Hilbert space filling
curve. An efficient algorithm for computing context-based space
filling curves is presented. We also discuss the potential of
improved autocorrelation of context-based space filling curves
for image and video lossless compression. },
}
@article{Nebel:2000:RCA,
   author = {Jean-Christophe Nebel},
   title = {Realistic Collision Avoidance of Upper Limbs Based on
Neuroscience Models},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {219-228},
   note = {{ISSN} 1067-7055},
   annote = {When articulated figures interact in a {3D}
environment, collisions are highly likely and must often be
avoided. We present a method automatically producing realistic
collision-free animation of the upper arms. Based on the latest
models of collision avoidance provided by neuroscience, our
method allows realistic interpolation of keyframes at interactive
speed. In order to validate our scheme we compared computer
generated motions with motions performed by a sample of ten
humans. These motions were defined by start and final postures
and by an obstacle which had to be passed. In each case the
generated positions are the same as those chosen by 30% of real
humans, we therefore consider our method provides realistic
motions. Moreover, the collision-free paths are automatically
generated in a few seconds. Hence, our method can be very
beneficial to animators by reducing the level of detail needed to
define motions of articulated figures. It can also be used for
the automatic generation of realistic animations for virtual
reality applications. },
}
@article{Baciu:2000:TIG,
   author = {George Baciu and Sai Keung Wong},
   title = {The Impulse Graph: A New Dynamic Structure For Global
Collisions},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {229-238},
   note = {{ISSN} 1067-7055},
   annote = {In interactive virtual environments and dynamic
simulations, collisions between complex objects and articulated
bodies may occur simultaneously at multiple points or regions of
interference. Many solutions to the collision response problem
are formulated based on the local pair-wise contact dynamics. In
this article, we present a new solution to the global
interactions and dynamic response between multiple structures in
a three-dimensional environment. This is based on a new dynamic
impulse graph that tracks the reaction forces through the entire
system and gives a global view of all the interactions in a
multibody system. },
}
@article{Dingliana:2000:GDO,
   author = {John Dingliana and Carol O'Sullivan},
   title = {Graceful Degradation of Collision Handling in
Physically Based Animation},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {239-248},
   note = {{ISSN} 1067-7055},
   annote = {Interactive simulation is made possible in many
applications by simplifying or culling the finer details that
would make real-time performance impossible. This paper examines
detail simplification in the specific problem of collision
handling for rigid body animation. We present an automated method
for calculating consistent collision response at different levels
of detail. The mechanism works closely with a system which uses a
pre-computed hierarchical volume model for collision detection.
},
}
@article{Kobbelt:2000:MSD,
   author = {Leif P. Kobbelt and Thilo Bareuther and Hans-Peter
Seidel},
   title = {Multiresolution Shape Deformations for Meshes with
Dynamic Vertex Connectivity},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {249-260},
   note = {{ISSN} 1067-7055},
   annote = {Multiresolution shape representation is a very
effective way to decompose surface geometry into several levels
of detail. Geometric modeling with such representations enables
flexible modifications of the global shape while preserving the
detail information. Many schemes for modeling with
multiresolution decompositions based on splines, polygonal meshes
and subdivision surfaces have been proposed recently. In this
paper we modify the classical concept of multiresolution
representation by no longer requiring a global hierarchical
structure that links the different levels of detail. Instead we
represent the detail information implicitly by the geometric
difference between independent meshes. The detail function is
evaluated by shooting rays in normal direction from one surface
to the other without assuming a consistent tesselation. In the
context of multiresolution shape deformation, we propose a
dynamic mesh representation which adapts the connectivity during
the modification in order to maintain a prescribed mesh quality.
Combining the two techniques leads to an efficient mechanism
which enables extreme deformations of the global shape while
preventing the mesh from degenerating. During the deformation,
the detail is reconstructed in a natural and robust way. The key
to the intuitive detail preservation is a transformation map
which associates points on the original and the modified geometry
with minimum distortion. We show several examples which
demonstrate the effectiveness and robustness of our approach
including the editing of multiresolution models and models with
texture. },
}
@article{Du:2000:DMA,
   author = {Haixia Du and Hong Qin},
   title = {Direct Manipulation and Interactive Sculpting of {PDE}
Surfaces},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {261-270},
   note = {{ISSN} 1067-7055},
   annote = {This paper presents an integrated approach and a
unified algorithm that combine the benefits of {PDE} surfaces and
powerful physics-based modeling techniques within one single
modeling framework, in order to realize the full potential of {PDE}
surfaces. We have developed a novel system that allows direct
manipulation and interactive sculpting of {PDE} surfaces at
arbitrary location, hence supporting various interactive
techniques beyond the conventional boundary control. Our
prototype software affords users to interactively modify point,
normal, curvature, and arbitrary region of {PDE} surfaces in a
predictable way. We employ several simple, yet effective
numerical techniques including the finite-difference
discretization of the {PDE} surface, the multigrid-like subdivision
on the {PDE} surface, the mass-spring approximation of the elastic
PDE surface, etc. to achieve real-time performance. In addition,
our dynamic {PDE} surfaces can also be approximated using standard
bivariate B-spline finite elements, which can subsequently be
sculpted and deformed directly in real-time subject to intrinsic
PDE constraints. Our experiments demonstrate many attractive
advantages of our dynamic {PDE} formulation such as intuitive
control, real-time feedback, and usability to the general public.
},
}
@article{Ganovelli:2000:AMM,
   author = {Fabio Ganovelli and Paolo Cignoni and Claudio
Montani and Roberto Scopigno},
   title = {A Multiresolution Model for Soft Objects Supporting
Interactive Cuts and Lacerations},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {271-282},
   note = {{ISSN} 1067-7055},
   annote = {Performing a really interactive and physically-based
simulation of complex soft objects is still an open problem in
computer animation/simulation. Given the application domain of
virtual surgery training, a complete model should be quite
realistic, interactive and should enable the user to modify the
topology of the objects. Recent papers propose the adoption of
multiresolution techniques to optimize time performance by
representing at high resolution only the object parts considered
more important or critical. The speed up obtainable at simulation
time are counterbalanced by the need of a preprocessing phase
strongly dependent on the topology of the object, with the
drawback that performing dynamic topology modification becomes a
prohibitive issue. In this paper we present an approach that
couples multiresolution and topological modifications, based on
the adoption of a particle systems approach to the physical
simulation. Our approach is based on a tetrahedral decomposition
of the space, chosen both for its suitability to support a
particle system and for the ready availability of many techniques
recently proposed for the simplification and multiresolution
management of {3D} simplicial decompositions. The multiresolution
simulation system is designed to ensure the required speedup and
to support dynamic changes of the topology, e.g. due to cuts or
lacerations of the represented tissue. },
}
@article{Ivanov:2000:CDA,
   author = {Denis V. Ivanov and Yevgeniy P. Kuzmin},
   title = {Color Distribution - A New Approach to Texture
Compression},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {283-290},
   note = {{ISSN} 1067-7055},
   annote = {Texture compression is recently one of the most
important topics of {3D} scene rendering techniques, because it
allows rendering more complicated high-resolution scenes.
However, because of some special requirements for these type of
techniques, the commonly used block decomposition approach may
introduce visual degradation of image details due to lack of
colors. We present here a new approach to texture compression,
which allows sharing of one color by several blocks providing a
larger number of unique colors in each particular block and the
best compression ratio. We also present an iterative algorithm
for obtaining distributed colors on a texture, and discuss some
advantages of our approach. The paper concludes with comparison
of our technique with {S3TC} and other block decomposition methods.
},
}
@article{Iehl:2000:AAS,
   author = {Jean Claude Iehl and Bernard P{\'{e}}roche},
   title = {An Adaptive Spectral Rendering with a Perceptual
Control},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {291-300},
   note = {{ISSN} 1067-7055},
   annote = {In this paper, we present a spectral rendering
method based on a ray tracing algorithm and guided by a
perceptual control of the error made. An adaptive representation
of spectral data for light sources and materials is used and
induces, for each pixel, the evaluation of an algebraic
expression. For each visible wavelength, the computations of
complex spread in refractive and dispersive materials, based on
several photon maps, are locally restricted by an adaptive
evaluation of the expression. This method allows to simulate high
quality physically-based pictures and, in particular, some
specific phenomena like dispersion in transparent objects and
scattered caustics. },
}
@article{Scheel:2000:TRF,
   author = {A. Scheel and M. Stamminger and Hans-Peter Seidel},
   title = {Tone Reproduction for Interactive Walkthroughs},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {301-312},
   note = {{ISSN} 1067-7055},
   annote = {When a rendering algorithm has created a pixel array
of radiance values the task of producing an image is not yet
completed. In fact, to visualize the result the radiance values
still have to be mapped to luminances, which can be reproduced by
the used display. This step is performed with the help of tone
reproduction operators. These tools have mainly been applied to
still images, but of course they are just as necessary for
walkthrough applications, in which several images are created per
second. In this paper we illuminate the physiological aspects of
tone reproduction for interactive applications. It is shown how
tone reproduction can also be introduced into interactive
radiosity viewers, where the tone reproduction continuously
adjusts to the current view of the user. The overall performance
is decreased only moderately, still allowing walkthroughs of
large scenes. },
}
@article{Frohlich:2000:IOM,
   author = {Torsten Fr{\&quot;{o}}hlich and Marcus Roth},
   title = {Integration of Multidimensional Interaction Devices
in Real-Time Computer Graphics Applications},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {313-320},
   note = {{ISSN} 1067-7055},
   annote = {Modern {CAD}/CAM and Virtual Reality applications
cannot be imagined without the new class of interaction devices
allowing the user direct interaction with computer generated
scenes. Integrating such devices into existing or newly developed
software is a complex task for a number of reasons. The set of
devices is very heterogeneous in functionality and data formats.
Most devices are difficult to handle by inexperienced users or
need careful handling and calibration. After reviewing a number
of existing systems, a novel approach to this problem is
presented. A device interface that allows the flexible, hardware
independent configuration and error robust operation, even
reconfiguration and exchanges of interaction devices during
operation, will be introduced. The system structure is discussed
and novel communication protocols reducing latency are invented.
},
}
@article{Yoon:2000:WRR,
   author = {I. Yoon and U. Neumann},
   title = {Web-Based Remote Rendering with {IBRAC} (Image-Based
Rendering Acceleration and Compression)},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {321-330},
   note = {{ISSN} 1067-7055},
   annote = {Recent advances in Internet and computer graphics
stimulate intensive use and development of {3D} graphics on the
World Wide Web. To increase efficiency of systems using {3D}
graphics on the web, the presented method utilizes previously
rendered and transmitted images to accelerate the rendering and
compression of new synthetic scene images. The algorithm employs
ray casting and epipolar constraints to exploit spatial and
temporal coherence between the current and previously rendered
images. The reprojection of color and visibility data accelerates
the computation of new images. The rendering method intrinsically
computes a residual image, based on a user specified error
tolerance that balances image quality against computation time
and bandwidth. Encoding and decoding uses the same algorithm, so
the transmitted residual image consists only of significant data
without addresses or offsets. We measure rendering speed-ups of
four to seven without visible degradation. Compression ratios per
frame are a factor of two to ten better than {MPEG2} in our test
cases. There is no transmission of {3D} scene data to delay the
first image. The efficiency of the server and client generally
increases with scene complexity or data size since the rendering
time is predominantly a function of image size. This approach is
attractive for remote rendering applications such as web-based
scientific visualization where a client system may be a
relatively low-performance machine and limited network bandwidth
makes transmission of large {3D} data impractical. },
}
@article{Li:2000:VDM,
   author = {Xiangyang Li and Dongming Lu and Yunhe Pan},
   title = {Virtual Dunhuang Mural Restoration System in
Collaborative Network Environment},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {331-340},
   note = {{ISSN} 1067-7055},
   annote = {This paper introduces a virtual Dunhuang mural
restoration system in collaborative network environment. It
describes the style of Dunhuang mural, analyzes the reasons of
mural spoilage, and presents the necessity to develop a
collaborative mural restoration GroupWare. It describes the
components and the workflow of mural restoration in detail,
solves some key technologies in the system. In the end, it
introduces the system architecture, and presents the system
interface and some restored results. },
}
@article{Mroz:2000:IHM,
   author = {Lukas Mroz and Helwig Hauser and Eduard
Gr{\&quot;{o}}ller},
   title = {Interactive High-Quality Maximum Intensity
Projection},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {341-350},
   note = {{ISSN} 1067-7055},
   annote = {Maximum Intensity Projection (MIP) is a volume
rendering technique which is used to visualize high-intensity
structures within volumetric data. At each pixel the highest data
value, which is encountered along a corresponding viewing ray is
depicted. {MIP} is, for example, commonly used to extract vascular
structures from medical data sets (angiography). Due to lack of
depth information in {MIP} images, animation or interactive
variation of viewing parameters is frequently used for
investigation. Up to now no {MIP} algorithms exist which are of
both interactive speed and high quality. In this paper we present
a high-quality {MIP} algorithm (trilinear interpolation within
cells), which is up to 50 times faster than brute-force {MIP} and
at least 20 times faster than comparable optimized techniques.
This speed-up is accomplished by using an alternative storage
scheme for volume cells (sorted by value) and by removing cells
which do not contribute to any {MIP} projection (regardless of the
viewing direction) in a preprocessing step. Also, a fast maximum
estimation within cells is used to further speed up the
algorithm. },
}
@article{Neumann:2000:GEI,
   author = {L{\'{a}}szl{\'{o}} Neumann and Bal{\'{a}}zs
Cs{\'{e}}bfalvi and Andreas K{\&quot;{o}}nig and Eduard
Gr{\&quot;{o}}ller},
   title = {Gradient Estimation in Volume Data using {4D} Linear
Regression},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {351-358},
   note = {{ISSN} 1067-7055},
   annote = {In this paper a new gradient estimation method is
presented which is based on linear regression. Previous
contextual shading techniques try to fit an approximate function
to a set of surface points in the neighborhood of a given voxel.
Therefore a system of linear equations has to be solved using the
computationally expensive Gaussian elimination. In contrast, our
method approximates the density function itself in a local
neighborhood with a {3D} regression hyperplane. This approach also
leads to a system of linear equations but we will show that it
can be solved with an efficient convolution. Our method provides
at each voxel location the normal vector and the translation of
the regression hyperplane which are considered as a gradient and
a filtered density value respectively. Therefore this technique
can be used for surface smoothing and gradient estimation at the
same time. },
}
@article{Dong:2000:FVR,
   author = {Feng Dong and Meleagros Krokos and Gordon
Clapworthy},
   title = {Fast Volume Rendering and Data Classification Using
Multiresolution in Min-Max Octrees},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {359-368},
   note = {{ISSN} 1067-7055},
   annote = {Large-sized volume datasets have recently become
commonplace and users are now demanding that volume-rendering
techniques to visualise such data provide acceptable results on
relatively modest computing platforms. The widespread use of the
Internet for the transmission and/or rendering of volume data is
also exerting increasing demands on software providers.
Multiresolution can address these issues in an elegant way. One
of the fastest volume-rendering alrogithms is that proposed by
Lacroute \&amp; Levoy, which is based on shear-warp factorisation and
min-max octrees (MMOs). Unfortunately, since an {MMO} captures only
a single resolution of a volume dataset, this method is
unsuitable for rendering datasets in a multiresolution form. This
paper adapts the above algorithm to multiresolution volume
rendering to enable near-real-time interaction to take place on a
standard {PC}. It also permits the user to modify classification
functions and/or resolution during rendering with no significant
loss of rendering speed. A newly-developed data structure based
on the {MMO} is employed, the multiresolution min-max octree, {M3O},
which captures the spatial coherence for datasets at all
resolutions. Speed is enhanced by the use of multiresolution
opacity transfer functions for rapidly determining and discarding
transparent dataset regions. Some experimental results on sample
volume datasets are presented. },
}
@article{Gaiani:2000:RTC,
   author = {Marco Gaiani and Marcello Balzani and Federico
Uccelli},
   title = {Reshaping the Coliseum in Rome: An Integrated Data
Capture and Modeling Method at Heritage Sites},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {369-378},
   note = {{ISSN} 1067-7055},
   annote = {The paper describes the process of building
Internet-transmittable, 3-D digital virtual models of ancient
heritage monuments from on-site data, focusing especially on 3-D
dimensional data acquisition techniques and color processing
methods. Section 1 considers project goals and the attendant
problems; Section 2 provides a brief summary of state-of-the-art
experience and the technologies adopted by the Authors; Section 3
illustrates the key features of the 3-D color data acquisition
methods used as well as the shape and color processing pipeline;
Section 4 describes the specific study conducted on single
elements and faades of the Coliseum in Rome, while Section 6
outlines future work. },
}
@article{Cai:2000:CVS,
   author = {Wenli Cai and Stefan Walter and Grigorios Karangelis
and Georgios Sakas},
   title = {Collaborative Virtual Simulation Environment for
Radiotherapy Treatment Planning},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {379-390},
   note = {{ISSN} 1067-7055},
   annote = {The simulation of Radiotherapy Treatment Planning
(RTP) is a normal procedure in oncology clinics carried out on a
Simulator machine. The Virtual Simulation of {RTP} replaces the
real Simulator machine with a virtual one by using the {CT} data
sets of a patient instead of the real patient. In this paper, we
present a collaborative virtual simulation environment of {RTP},
named {EU-VIRTUOSO}, which is based on volume rendering and
telecommunication techniques. The {RTP} procedure is visualised on
a virtual patient, which is created by using the {CT} data of the
patient. Different volume rendering and volume interaction
techniques, such as {DRR}, {MIP}, gradient surface, and iso-surface,
supply physicians with high quality rendering images to simulate
the real working environment of the Simulator machine. In the
collaborative environment, physicians distributed at different
locations can work together via network to plan the treatment or
to validate the treatment plan on-line by a collaborative
application sharing approach. Both concepts virtualised planning
and collaborative planning improve the efficiency and accuracy of
a radiotherapy treatment while reducing the effort for an
individual patient. },
}
@article{Bebie:2000:AV3,
   author = {T. Bebie and H. Bieri},
   title = {A Video-Based 3D-Reconstruction of Soccer Games},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {391-400},
   note = {{ISSN} 1067-7055},
   annote = {In this paper we present SoccerMan, a reconstruction
system designed to generate animated, virtual {3D} views from two
synchronous video sequences of a short part of a given soccer
game. After the reconstruction process, which needs also some
manual interaction, the virtual {3D} scene can be examined and
&amp;lsquo;replayed? from any viewpoint. Players are modeled as
so-called animated texture objects, i.e. {2D} player shapes are
extracted from video and texture-mapped onto rectangles in {3D}
space. Animated texture objects have shown very appropriate as a
3D representation of soccer players in motion, as the visual
nature of the original human motion is preserved. The
trajectories of the players and the ball in {3D} space are
reconstructed accurately. In order to create a {3D} reconstruction
of a given soccer scene, the following steps have to be executed:
1) Camera parameters of all frames of both sequences are computed
(camera calibration). 2) The playground texture is extracted from
the video sequences. 3) Trajectories of the ball and the players'
heads are computed after manually specifying their image
positions in a few key frames. 4) Player textures are extracted
automatically from video. 5) The shapes of colliding or occluding
players are separated automatically. 6) For visualization, player
shapes are texture-mapped onto appropriately placed rectangles in
virtual space. SoccerMan is a novel experimental sports analysis
system with fairly ambitious objectives. Its design decisions, in
particular to start from two synchronous video sequences and to
model players by texture objects, have already proven promising.
},
}
@article{Lao:2000:VAT,
   author = {Zhiqiang Lao and Ling Li},
   title = {Video-based Approach to Human Animation},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {401-410},
   note = {{ISSN} 1067-7055},
   annote = {A method based on computer vision technologies is
presented to determine the 3-D spatial locations of joints or
feature points of a human body from human motion video. The
proposed method first applies the geometric projection theory to
obtain a set of feasible postures in some key frames according to
predefined {2D} video features and 3D-model features
correspondence. Next it makes use of the available skeleton
controlled human model to get a feasible posture for each key
frame. The method is applied to a series of video images to
animate artificial {3D} human models. },
}
@article{Alexa:2000:RAB,
   author = {Marc Alexa and Wolfgang M{\&quot;{u}}ller},
   title = {Representing Animations by Principal Components},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {411-418},
   note = {{ISSN} 1067-7055},
   annote = {In this paper, we present a representation for
three-dimensional geometric animation sequences. Different from
standard key-frame techniques, this approach is based on the
determination of principal animation components and decouples the
animation from the underlying geometry. The new representation
supports progressive animation compression with spatial, as well
as temporal, level-of-detail and high compression ratios. The
distinction of animation and geometry allows for mapping
animations onto other objects. },
}
@article{Froumentin:2000:AVR,
   author = {Max Froumentin and Fr{\'{e}}d{\'{e}}ric Labrosse and
Philip J. Willis},
   title = {A Vector-based Representation for Image Warping},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {419-426},
   note = {{ISSN} 1067-7055},
   annote = {A method for image analysis, representation and
re-synthesis is introduced. Unlike other schemes it is not pixel
based but rather represents a picture as vector data, from which
an altered version of the original image can be rendered.
Representing an image as vector data allows performing operations
such as zooming, retouching or colourising, avoiding common
problems associated with pixel image manipulation. This paper
brings together methods from the areas of computer vision, image
compositing and image based rendering to prove that this type of
image representation is a step towards accurate and efficient
image manipulation. },
}
@article{Maillot:2000:RTL,
   author = {Jerome Maillot},
   title = {Real Time Local Approximation of Deformations using
Rotations},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {427-436},
   note = {{ISSN} 1067-7055},
   annote = {Additional realism can be achieved in computer
generated images using smooth and increasingly complex
deformations. Though significant effort has been spent on
improving these deformations, no general method has been proposed
yet to deal with rigid pieces connected to soft objects. This
paper proposes a general framework to solve this problem. We will
present several types of applications, such as flowing small
objects in a deformation field, animating rigid features
connected to some deformed object, or smoothly attached limbs to
a deforming body. All the calculations presented here can be
applied to any type of deformation, provided that the deformation
at each point only depends on the point itself. Even though we
can directly compute the result for some analytical deformation
fields, we will show that a good sampling of the deformation in
the area of interest is generally enough. One intermediate result
consists of a practical method to find the best rotation that
approximates a linear transformation. The proposed method is a
superset of the Gram-Schmidt orthonormalization process, and is
much easier to compute than global methods based on Taylor
series. },
}
@article{Tak:2000:MBF,
   author = {Seyoon Tak and Oh-young Song and Hyeong-Seok Ko},
   title = {Motion Balance Filtering},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {437-446},
   note = {{ISSN} 1067-7055},
   annote = {This paper presents a new technique called motion
balance filtering, which corrects an unbalanced motion to a
balanced one while preserving the original motion characteristics
as much as possible. Differently from previous approaches that
deal only with the balance of static posture, we solve the
problem of balancing a dynamic motion. We achieve dynamic balance
by analyzing and controlling the trajectory of the zero moment
point (ZMP). Our algorithm consists of three steps. First, it
analyzes the {ZMP} trajectory to find out the duration in which
dynamic balance is violated. Dynamic imbalance is identified by
the {ZMP} trajectory segments lying out of the supporting area.
Next, the algorithm modifies the {ZMP} trajectory by projecting it
into the supporting area. Finally, it generates the balanced
motion that satisfies the new {ZMP} constraint. This process is
formulated as a constrained optimization problem so that the new
motion resembles the original motion as much as possible.
Experiments prove that our motion balance filtering algorithm is
a useful method to add physical realism to a kinematically edited
motion. },
}
@article{Ashraf:2000:GCM,
   author = {G. Ashraf and K. C. Wong},
   title = {Generating Consistent Motion Transition via Decoupled
Framespace Interpolation},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   note = {{ISSN} 1067-7055},
   annote = {The framespace interpolation algorithm abstracts
motion sequences as {1D} signals, and interpolates between them to
create higher dimension signals, with weights drawn from a user
specified curve in a bounded region. We reformulate the algorithm
to achieve motion-state based transition via dynamic warping of
framespaces and automatic transition timing via framespace
frequency interpolation. Basis motions displaying diverse
coordination configurations between upper and lower body-halves,
cannot be consistently corresponded at a macro level. We address
this problem here, through decoupled blending of these halves to
achieve true consistency, and eliminate accumulated phase
differences via cosine phase warp functions. This generalization
enables interpolation of motions with diverse coordinations
between the upper and lower bodies. },
}
@article{Attene:2000:ASR,
   author = {Marco Attene and Michela Spagnuolo},
   title = {Automatic surface reconstruction from point sets in
space},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   note = {{ISSN} 1067-7055},
   annote = {In this paper an algorithm is proposed that takes as
input a generic set of unorganized points, sampled on a real
object, and returns a closed interpolating surface. Specifically,
this method generates a closed 2-manifold surface made of
triangular faces, without limitations on the shape or genus of
the original solid. The reconstruction method is based on
generation of the Delaunay tetrahedralization of the point set,
followed by a sculpturing process constrained to particular
criteria. The main applications of this tool are in medical
analysis and in reverse engineering areas. It is possible, for
example, to reconstruct anatomical parts starting from surveys
based on TACs or magnetic resonance. },
}
@article{Gopiy:2000:SRB,
   author = {M. Gopiy and S. Krishnan and C. T. Silva},
   title = {Surface Reconstruction based on Lower Dimensional
Localized Delaunay Triangulation},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   note = {{ISSN} 1067-7055},
   annote = {We present a fast, memory efficient algorithm that
generates a manifold triangular mesh S passing through a set of
unorganized points P R3. Nothing is assumed about the geometry,
topology or presence of boundaries in the data set except that P
is sampled from a real manifold surface. The speed of our
algorithm is derived from a projection-based approach we use to
determine the incident faces on a point. We define our sampling
criteria to sample the surface and guarantee a topologically
correct mesh after surface reconstruction for such a sampled
surface. We also present a new algorithm to find the normal at a
vertex, when the surface is sampled according our given criteria.
We also present results of our surface reconstruction using our
algorithm on unorganized point clouds of various models. },
}
@article{Kobbelt:2000:AIA,
   author = {Leif P. Kobbelt and Mario Botsch},
   title = {An Interactive Approach to Point Cloud
Triangulation},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {479-487},
   note = {{ISSN} 1067-7055},
   annote = {We present an interactive system for the generation
of high quality triangle meshes that allows us to handle hybrid
geometry (point clouds, polygons, &amp;ctdot;) as input data. In
order to be able to robustly process huge data sets, we exploit
graphics hardware features like the raster manager and the
z-buffer for specific sub-tasks in the overall procedure. By this
we significantly accelerate the stitching of mesh patches and
obtain an algorithm for sub-sampling the data points in linear
time. The target resolution and the triangle alignment in
sub-regions of the resulting mesh can be controlled by adjusting
the screen resolution and viewing transformation. An intuitive
user interface provides a flexible tool for application dependent
optimization of the mesh. },
}
@article{Jimenez:2000:EAF,
   author = {W. F. H. Jim{\'{e}}nez and C. Esperan{\c{c}}a and A.
A. F. Oliveira},
   title = {Efficient Algorithms for Computing Conservative
Portal Visibility Information},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {489-498},
   note = {{ISSN} 1067-7055},
   annote = {The number of polygons in realistic architectural
models is many more than can be rendered at interactive frame
rates. Typically, however, due to occlusion by opaque surfaces
(e.g., walls), only small fractions of such models are visible
from most viewpoints. This fact is used in many popular methods
for preprocessing visibility information which assume a scene
model subdivided into convex cells connected through convex
portals. These methods need to establish which cells or parts
thereof are visible to a generalized observer located within each
cell. The geometry of this information is termed a visibility
volume and its computation is usually quite complex. Conservative
approximations of viewing volumes, however, are simpler and less
expensive to compute. In this paper we present techniques and
algorithms which permit the computation of conservative viewing
volumes incrementally. In particular, we describe an algorithm
for computing the viewing volumes for a given cell through a
sequence of m portals containing a total of n edges in Omn time.
},
}
@article{Andujar:2000:IOC,
   author = {Carlos And{\'{u}}jar and Carlos Saona-V{\'{a}}zquez
and Isabel Navazo and Pere Brunet},
   title = {Integrating Occlusion Culling and Levels of Detail
through Hardly-Visible Sets},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {499-506},
   note = {{ISSN} 1067-7055},
   annote = {Occlusion culling and level-of-detail rendering have
become two powerful tools for accelerating the handling of very
large models in real-time visualization applications. We present
a framework that combines both techniques to improve rendering
times. Classical occlusion culling algorithms compute potentially
visible sets (PVS), which are supersets of the sets of visible
polygons. The novelty of our approach is to estimate the degree
of visibility of each object of the {PVS} using synthesized coarse
occluders. This allows to arrange the objects of each {PVS} into
several Hardly-Visible Sets (HVS) with similar occlusion degree.
According to image accuracy and frame rate requirements, {HVS}
provide a way to avoid sending to the graphics pipeline those
objects whose pixel contribution is low due to partial occlusion.
The image error can be bounded by the user at navigation time. On
the other hand, as {HVS} offer a tighter estimation of the pixel
contribution for each scene object, it can be used for a more
convenient selection of the level-of-detail at which objects are
rendered. In this paper, we describe the new framework technique,
provide details of its implementation using a visibility octree
as the chosen occlusion culling data structure and show some
experimental results on the image quality. },
}
@article{Bernardini:2000:DDO,
   author = {Fausto Bernardini and James T. Klosowski and Jihad
El-Sana},
   title = {Directional Discretized Occluders for Accelerated
Occlusion Culling},
   volume = {19},
   number = {3},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {August},
   publisher = {Blackwell Publishers},
   pages = {507-516},
   note = {{ISSN} 1067-7055},
   annote = {We present a technique for accelerating the
rendering of high depth-complexity scenes. In a preprocessing
stage, we approximate the input model with a hierarchical data
structure and compute simple view-dependent polygonal occluders
to replace the complex input geometry in subsequent visibility
queries. When the user is inspecting and visualizing the input
model, the computed occluders are used to avoid rendering
geometry which cannot be seen. Our method has several advantages
which allow it to perform conservative visibility queries
efficiently and it does not require any special graphics
hardware. The preprocessing step of our approach can also be used
within the framework of other visibility culling methods which
need to pre-select or pre-render occluders. In this paper, we
describe our technique and its implementation in detail, and
provide experimental evidence of its performance. In addition, we
briefly discuss possible extensions of our algorithm. },
}
@article{Velho:2000:VR4,
   author = {Luiz Velho and Jonas Gomes},
   title = {Variable Resolution 4-k Meshes: Concepts and
Applications},
   volume = {19},
   number = {4},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {December},
   publisher = {Blackwell Publishers},
   pages = {195-212},
   note = {{ISSN} 1067-7055},
   keywords = {multiresolution, four-directional grids,
restricted quad-trees, multi-triangulations, adapted meshes},
   annote = {In this paper we introduce variable resolution 4-k
meshes, a powerful structure for the representation of geometric
objects at multiple levels of detail. It combines most properties
of other related descriptions with several advantages, such as
more flexibility and greater expressive power. The main unique
feature of the 4-k mesh structure lies in its variable resolution
capability, which is crucial for adaptive computation. We also
give an overview of the different methods for constructing the
4-k mesh representation, as well as the basic algorithms
necessary to incorporate it in modeling and graphics
applications. },
}
@article{Mueller:2000:ACO,
   author = {Gordon M{\&quot;{u}}ller and Stephan Sch{\&quot;{a}}fer and
Dieter W. Fellner},
   title = {Automatic Creation of Object Hierarchies for
Radiosity Clustering},
   volume = {19},
   number = {4},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {December},
   publisher = {Blackwell Publishers},
   pages = {213-221},
   note = {{ISSN} 1067-7055},
   annote = {Using object clusters for hierarchical radiosity
greatly improves the efficiency and thus usability of radiosity
computations. By eliminating the quadratic starting phase very
large scenes containing about 100k polygons can be handled
efficiently. Although the main algorithm extends rather easily to
using object clusters, the creation of &quot;good&quot; object hierarchies
is a difficult task both in terms of construction time and in the
way how surfaces or objects are grouped to clusters. The quality
of an object hierarchy for clustering depends on its ability to
accurately simulate the hierarchy of the energy flow in a given
scene. Additionally it should support visibility computations by
providing efficient ray acceleration techniques.\\In this paper
we will present a new approach of building hierarchies of object
clusters. Our hybrid structuring algorithm provides accuracy and
speed by combining a highly optimized bounding volume hierarchy
together with uniform spatial subdivisions for nodes with regular
object densities. The algorithm works without user intervention
and is well suited for a wide variety of scenes. First results of
using these hierarchies in a radiosity clustering environment are
very promising and will be presented here.\\The combination of
very deep hierarchies (we use a binary tree) together with an
efficient ray acceleration structure shifts the computational
effort away from form factor and visibility calculation towards
accurately propagating the energy through the hierarchy. We will
show how an efficient single pass gathering can be used to
minimize traversal costs. },
}
@article{Klassen:2000:FJ,
   author = {R. Victor Klassen},
   title = {Filtered Jitter},
   volume = {19},
   number = {4},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {December},
   publisher = {Blackwell Publishers},
   pages = {223-230},
   note = {{ISSN} 1067-7055},
   keywords = {Stochastic sampling, image quality, antialiasing,
Fourier analysis},
   annote = {Jitter is one popular way of generating samples for
stochastic sampling in computer graphics. The Poisson disk
distribution better approximates that of the human photomosaic.
In this paper we examine the spatial and frequency space
behaviour of a number of existing algorithms for generating
stochastic samples and propose a new algorithm based on low pass
filtering a jittered set of displacements. The distribution is at
least as much like that of the human photomosaic as any existing
algorithm, while being fast to compute. },
}
@article{Emering:2000:VTO,
   author = {Luc Emering and Ronan Boulic and Tom Molet and
Daniel Thalmann},
   title = {Versatile Tuning of Humanoid Agent Activity},
   volume = {19},
   number = {4},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {December},
   publisher = {Blackwell Publishers},
   pages = {231-242},
   note = {{ISSN} 1067-7055},
   annote = {In this paper, we present an integration framework
for heterogeneous motion generators. The objective is to outline
issues that are currently easily solved in professional
post-processing systems used in film and game production but
which cannot be transposed as is to real-time systems with
autonomous agents. We summarise our approach for articulated
agent-modelling and their animation by combining heterogeneous
motion generators, such as real-time motion capturing,
key-framing, inverse kinematics, procedural walking. We propose
an agent/action-oriented framework. Activity properties such as
action simultaneity and motion blending, spatial coherence,
motion-flow update schemes, agent attachments, and location
corrections, are the main topics handled by our generic animation
framework. Numerous examples throughout the paper illustrate our
approach and outline encountered problems and solutions or open
research directions. },
}
@article{Schneider:2000:AHA,
   author = {Uwe Schneider},
   title = {A Hybrid Approach for Stroke-Based Letterform
Composition Including Outline-Based Methods},
   volume = {19},
   number = {4},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {December},
   publisher = {Blackwell Publishers},
   pages = {243-256},
   note = {{ISSN} 1067-7055},
   keywords = {digital typography, typeface design, parametric
letterform composition, pen-based, stroke-based, hybrid
approach},
   annote = {For three decades a number of computer-aided systems
have been developed in order to assist in the design of digital
type. Even though some of them are used by typographers in
commercial type design, they are not yet widely accepted. One
reason is the lack of appropriate design metaphors in systems
which provide low-level operations (e.g. the manipulation of
outlines). Another reason is the lack of essential functionality
in high-level approaches (not all characters can be modeled).
While these two reasons correspond with the underlying paradigms
of those systems, namely the outline and the stroke approach, the
presented model provides a synthesis of both. By exploring the
high-level semantics of the stroke-based paradigm, letterforms
can be composed by individual strokes. Properties like round
corners at stroke intersections, as they typically appear in the
design of Western type, can be modeled via outline segments
attached to the associated stroke elements. As a consequence,
Latin characters as well as characters incorporating hand-written
characters, like Kanji, can be expressed using a single model.
These two classes of types are considered by the typographic
community to be fundamentaly different. },
}
@article{Galin:2000:MTB,
   author = {Eric Galin and Antoine Leclercq and Samir Akkouche},
   title = {Morphing the BlobTree},
   volume = {19},
   number = {4},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {December},
   publisher = {Blackwell Publishers},
   pages = {257-270},
   note = {{ISSN} 1067-7055},
   keywords = {animation, BlobTree, implicit surfaces,
metamorphosis, warping},
   annote = {Implicit surfaces have proved to be a particularly
well suited and efficient model for animating and morphing shapes
of arbitrary topologies. The BlobTree model is characterized as a
hierarchical combination of skeletal primitives organized in a
tree. The nodes hold blending, boolean and warping operators,
which allows the design of complex objects.\\In this paper, we
address the metamorphosis of the BlobTree. This appears a
difficult task as the tree data-structures of the initial and
final shapes are completely different in the general case, and
consequently cannot be matched easily. We propose an original
technique that solves the correspondence process and creates an
intermediate generic BlobTree model whose instances interpolate
the initial and final shapes.\\The animator may control the
correspondence between features and can specify both the speed of
transformation and the trajectory of the nodes and the leaves of
the generic BlobTree model. This provides the end user with a
tight control over the transformation so as to achieve good
visual effects. },
}
@article{May:2000:PPA,
   author = {Jon May},
   title = {Perceptual Principles and Computer Graphics},
   volume = {19},
   number = {4},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {December},
   publisher = {Blackwell Publishers},
   pages = {271-279},
   note = {{ISSN} 1067-7055},
   annote = {Now that technology allows us to present
photorealistic animations of scenically lit objects acting in
real-time, the problem of computer graphics has changed from
making displays recognisable, to ensuring that users notice what
they are intended to see, without being distracted by irrelevant
information. Worse than that, the use of veridical displays that
are intended to be lifelike runs the risk of introducing
unpredictable sources of information, that can lead users to
infer all sorts of unwanted details. Traditional visual theory,
based upon bottom-up models of feature extraction from the
retinal image, cannot inform us about these aspects of
perception. Broader based cognitive theories are required that
integrate visual perception with attention, memory, emotion and
inference. Theories such as Barnard's Interacting Cognitive
Subsystems enable phenomena such as change blindness and the
craft principles of film editing to be interpreted within a
common framework, supporting extrapolation to computer graphics.
},
}
@article{Chen:2000:CVG,
   author = {Min Chen and John V. Tucker},
   title = {Constructive Volume Geometry},
   volume = {19},
   number = {4},
   journal = {Computer Graphics Forum},
   year = {2000},
   month = {December},
   publisher = {Blackwell Publishers},
   pages = {281-293},
   note = {{ISSN} 1067-7055},
   keywords = {constructive volume geometry, scalar fields,
volume visualisation, volume data types, volume modelling,
constructive solid geometry},
   annote = {We present an algebraic framework, called
Constructive Volume Geometry (CVG), for modelling complex spatial
objects using combinational operations. By utilising scalar
fields as fundamental building blocks, {CVG} provides high-level
algebraic representations of objects that are defined
mathematically or built upon sampled or simulated datasets. It
models amorphous phenomena as well as solid objects, and
describes the interior as well as the exterior of objects. We
also describe a hierarchical representation scheme for {CVG}, and a
direct rendering method with a new approach for consistent
sampling. The work has demonstrated the feasibility of combining
a variety of graphics data types in a coherent modelling scheme.
},
}

</PRE>
	</td>


	</table>

 
<P>

</BODY>
</HTML>
