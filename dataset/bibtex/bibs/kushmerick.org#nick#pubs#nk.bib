@inproceedings(mccarey-kcds2006,
  author =	 "F. McCarey and \'{O} Cinn\'{e}ide, M. and
                  N. Kushmerick",
  year =	 2006,
  title =	 "Recommending Library Methods: {A}n evaluation of
                  {B}ayesian networks",
  booktitle =	 "Proc. Workshop Supporting Knowledge Collaboration in
                  Software Development",
  note =	 "Int. Conf. Automated Software Engineering",
  zzacceptance = "????%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/mccarey-kcsd2006.pdf",
  topic =	 "corpus-based software engineering; personalization",
  abstract =	 "Programming tasks are often mirrored inside an
                  organisation, across a community or within a
                  specific domain. We propose that final source codes
                  can be mined, that knowledge and insight can be
                  automatically obtained, and that this knowledge can
                  be reused for the benefit of future developments. We
                  focus on reusable software libraries; we wish to
                  learn information about how such libraries are used
                  and then elegantly pass this information onto
                  individual developers. In this paper we investigate
                  a Collaborative Filtering approach of recommending
                  library methods to a individual developer for a
                  particular task. The central idea is that we find
                  source codes that are the most relevant to the task
                  at hand and use these to suggest useful library
                  methods to a developer. To determine the similarity
                  and relevance of source codes, we investigate and
                  compare a number of Bayesian techniques including
                  Bayesian Networks and Naive-Bayes. We present
                  results and discuss the merits and drawbacks of a
                  Bayesian approach."
)

@inproceedings(naughton-ees-aaai06,
  author =	 "M. Naughton and N. Kushmerick and J. Carthy",
  title =	 "Event extraction from heterogeneous news sources",
  topic =	 "information retrieval; text analytics",
  booktitle =	 "Proc. Workshop Event Extraction and Synthesis",
  note =	 "American Nat. Conf. Artificial Intelligence",
  year =	 "2006",
  zzacceptance = "??%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/naughton-ees-aaai06.pdf",
  abstract =	 "With the proliferation of news articles from
                  thousands of different sources now available on
                  theWeb, summarization techniques of such information
                  is becoming increasingly important. Our research
                  focuses on merging descriptions of news events from
                  multiple sources, to provide a concise description
                  that combines the information from each
                  source. Specifically, we describe and evaluate
                  methods for grouping sentences in news articles that
                  refer to the same event. The key idea is to cluster
                  the sentences, using two novel distance metrics. The
                  first distance metric exploits regularities in the
                  sequential structure of events within a
                  document. The second metric uses a TFIDF-like
                  weighting scheme, enhanced to capture word
                  frequencies within events even though the events
                  themselves are not known a priori. Typical news
                  articles contain sentences that do not describe
                  specific events. We use machine learning methods to
                  differentiate between sentences that describe one or
                  more events, and those that do not. We then remove
                  non-event sentences before initiating the clustering
                  process. We demonstrate that this approach achieves
                  significant improvements in overall clustering
                  performance."
)

@inproceedings(kushmerick-aaai06-nectar,
  author =	 "N. Kushmerick and T. Lau and M. Dredze and
                  R. Khoussainov",
  year =	 2006,
  title =	 "Activity-centric email: {A} machine learning
                  approach",
  booktitle =	 "Proc. American Nat. Conf. Artificial Intelligence",
  note =	 "NECTAR paper",
  acceptance =	 "38%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/kushmerick-aaai06-nectar.pdf",
  topic =	 "intelligent email",
  abstract =	 "Our use of ordinary desktop applications (such as
                  email, Web, calendars) is often a manifestation of
                  the activities with which we are engaged (Moran,
                  Cozzi, & Farrell 2005). Planning a conference trip
                  involves sending travel expense forms, and visits to
                  airline and hotel sites. Renovating a kitchen
                  involves sketches, product specifications, emails
                  with the architect and spreadsheets for tracking
                  expenses. Every enterprise has (often implicit)
                  processes for managing customer queries, requesting
                  maintenance, hiring a new employee, purchasing
                  equipment, and so on. Unfortunately, ordinary
                  desktop applications do not know anything about
                  these activities. Within an enterprise, many
                  activities have been formalized into business
                  workflows such as hiring or ordering
                  equipment. However, the way people interact with
                  these workflows is often through email and
                  information collected in desktop applications. If
                  these applications are not aware of the activity
                  context, people bear the burden of organizing their
                  information into activities, typically using crude
                  techniques such as manual search, file directories,
                  and email folders/threads. Email has emerged as the
                  primary tool for people to communicate about their
                  work and manage activities. Motivated by the
                  importance of email in conducting activities, we
                  have recently developed several machine learning
                  algorithms for automatically discovering and
                  tracking activities in email. We observe that
                  activities come in many forms, from structured
                  workflows to informal person-to-person
                  communication. In this paper, we summarize our
                  efforts to provide automated assistance with two
                  types of activities: formalized, structured
                  activities, and unstructured, conversational
                  activities."
)


@inproceedings(mccarey-icsr2006,
  author =	 "F. McCarey and \'{O} Cinn\'{e}ide, M. and
                  N. Kushmerick",
  year =	 2006,
  title =	 "Recommending Library Methods: {A}n Evaluation of the
                  Vector Space Model ({VSM}) and Latent Semantic
                  Indexing ({LSI})",
  booktitle =	 "Proc. Int. Conf. Software Reuse",
  acceptance =	 "50%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/mccarey-icsr2006.pdf",
  topic =	 "corpus-based software engineering; personalization",
  abstract =	 "The development and maintenance of a reuse
                  repository requires significant investment, planning
                  and managerial support. To minimise risk and ensure
                  a healthy return on investment, reusable components
                  should be accessible, reliable and of a high
                  quality. In this paper we concentrate on
                  accessability; we describe a technique which enables
                  a developer to effectively and conveniently make use
                  of large scale libraries. Unlike most previous
                  solutions to component retrieval, our tool, RASCAL,
                  is a proactive component recommender. RASCAL
                  recommends a set of task-relevant reusable
                  components to a developer. Recommendations are
                  produced using Collaborative Filtering (CF). We
                  compare and contrast CF effectiveness when using two
                  information retrieval techniques, namely Vector
                  Space Model (VSM) and Latent Semantic Indexing
                  (LSI). We validate our technique on real world
                  examples and find overall results are encouraging;
                  notably, RASCAL can produce reasonably good
                  recommendations when they are most valuable, i.e. at
                  an early stage in code development."
)

@misc(mclernon-www06-demo,
  author =	 "B. McLernon and N. Kushmerick",
  year =	 2006,
  title =	 "{Tressel: Semantic mark-up of RSS feeds}",
  howpublished = "Demonstration at the Workshop on Collaborative Web
                  Tagging, Int. Conf. World Wide Web",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/mclernon-www06-workshop.pdf",
  acceptance =	 "30%",
  topic =	 "information extraction",
  abstract =	 "The recent explosion in the popularity of RSS and
                  other syndication technologies has led to a wealth
                  of information being published from an increasingly
                  diverse range of sources. However this popularity
                  makes it difficult for users to find interesting
                  documents, and this challenge is compounded by the
                  fact that most RSS clients offer very modest
                  personalization capabilities. We propose Tressel, a
                  collaborative RSS aggregator that extracts
                  semantically meaningful passages of text from RSS
                  feeds. Tressel employs a semi-supervised machine
                  learning algorithm to identify semantic
                  information. The algorithm learns from a small
                  amount of training data provided by the
                  user. Tressel is collaborative in that the input of
                  each user is used to benefit all of the users. One
                  challenge with such an open system is the danger
                  that users could (intentionally or accidentally)
                  introduce noisy training data. In this paper, we
                  describe Tressel's architecture and adaptive
                  information extraction algorithm, and then report on
                  experiments which demonstrate that we can reliably
                  detect noisy training data."
)

@inproceedings(mclernon-eacl06-atem,
  author =	 "B. McLernon and N. Kushmerick",
  title =	 "Transductive pattern learning for information
                  extraction",
  booktitle =	 "Proc. Workshop Adaptive Text Extraction and Mining",
  note =	 "Conf. European Association for Computational
                  Linguistics",
  year =	 2006,
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/mclernon-eacl06-atem.pdf",
  topic =	 "machine learning; information extraction",
  abstract =	 "The requirement for large labelled training corpora
                  is widely recognized as a key bottleneck in the use
                  of learning algorithms for information
                  extraction. We present TPLEX, a semi-supervised
                  learning algorithm for information extraction that
                  can acquire extraction patterns from a small amount
                  of labelled text in conjunction with a large amount
                  of unlabelled text. Compared to previous work, TPLEX
                  has two novel features. First, the algorithm does
                  not require redundancy in the fragments to be
                  extracted, but only redundancy of the extraction
                  patterns themselves. Second, most bootstrapping
                  methods identify the highest quality fragments in
                  the unlabelled data and then assume that they are as
                  reliable as manually labelled data in subsequent
                  iterations. In contrast, TPLEX's scoring mechanism
                  prevents errors from snowballing by recording the
                  reliability of fragments extracted from unlabelled
                  data. Our experiments with several benchmarks
                  demonstrate that TPLEX is usually competitive with
                  various fully-supervised algorithms when very little
                  labelled training data is available.",
  acceptance =	 "64%"
)

@misc(parle-iui06-demo,
  author =	 "R. Parle and R. Khusainov and L. O'Malley and
                  N. Kushmerick",
  year =	 2006,
  title =	 "{Email Activity Assistant: Automated support for
                  managing activities in email}",
  howpublished = "Demonstration at the Int. Conf. Intelligent User
                  Interfaces",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/parle-iui06-demo.pdf",
  topic =	 "intelligent email"
)

@inproceedings(naughton-ecir06,
  author =	 "M. Naughton and J. Carthy and N. Kushmerick",
  title =	 "Clustering sentences for discovering events in news
                  articles",
  note =	 "Poster",
  topic =	 "information retrieval; text analytics",
  booktitle =	 "Proc. European Conf. Information Retrieval",
  year =	 "2006",
  acceptance =	 "39%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/naughton-ecir06.pdf"
)

@inproceedings(dredze-iui06,
  author =	 "M. Dredze and T. Lau and N. Kushmerick",
  title =	 "Automatically classifying emails into activities",
  booktitle =	 "Proc. Int. Conf. Intelligent User Interfaces",
  year =	 2006,
  acceptance =	 "24%",
  abstract =	 "Email-based activity management systems promise to
                  give users better tools for managing increasing
                  volumes of email, by organizing email according to a
                  user.s activities. Current activity management
                  systems do not automatically classify incoming
                  messages by the activity to which they belong,
                  instead relying on simple heuristics (such as
                  message threads), or asking the user to manually
                  classify incoming messages as belonging to an
                  activity. In this paper, we present several
                  algorithms for automatically recognizing emails as
                  part of an ongoing activity. Our baseline methods
                  are the use of message reply-to threads to determine
                  activity membership and a naive Bayes
                  classifier. Our SimSubset and SimOverlap algorithms
                  compare the people involved in an activity against
                  the recipients of each incoming message. Our
                  SimContent algorithm uses IRR (a variant of latent
                  semantic indexing) to classify emails into
                  activities using similarity based on message
                  contents. An empirical evaluation shows that each of
                  these methods provide a significant improvement to
                  the baseline methods. In addition, we show that a
                  combined approach that votes the predictions of the
                  individual methods performs better than each
                  individual method alone.",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/dredze-iui06.pdf",
  topic =	 "intelligent email; machine learning; text analytics"
)

@misc(murdoch-wda2005,
  author =	 "G. Murdoch and N. Kushmerick",
  year =	 2005,
  title =	 "Unsupervised object extraction from data-intensive
                  web sources",
  note =	 "Accepted for workshop publication",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/murdoch-wda2005.pdf",
  topic =	 "Web search",
  abstract =	 "A long-term challenge for the Web extraction
                  community is to devise technologies for
                  automatically converting Web content from raw HTML
                  (which has no explicit semantics and usually
                  contains large quantities of spurious content), into
                  some sort of structured machine-processable format
                  (such as XML conforming to some given schema). We
                  address this question in the context of interactive
                  dataintensiveWeb sites such as e-commerce
                  services. Such sites provide a query interface for
                  retrieving documents that list several objects that
                  satisfy the query."
)

@inproceedings(sogrin-hdir2005-sigir,
  author =	 "M. Sogrin and T. Kechadi and N. Kushmerick",
  title =	 {Latent semantic indexing for text database
                  selection},
  year =	 2005,
  booktitle =	 "Proc. Workshop Heterogeneous and Distributed
                  Information Retrieval",
  note =	 "Int. Conf. Research and Development in Information
                  Retrieval",
  acceptance =	 "70%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/sogrin-hdir2005-sigir.pdf",
  topic =	 "information retrieval",
  abstract =	 {As the Web grows, the number and diversity of search
                  services has rapidly expanded, so that the challenge
                  of Web search has become one finding appropriate
                  search services for any particular query. That is,
                  instead of the first-order problem of finding
                  relevant Web content, users now face a second-order
                  challenge of determining which of the myriad search
                  services are likely to index relevant content. We
                  address these issues by proposing and evaluating
                  novel algorithms for text database selection. We
                  first describe several large-scale real-world
                  experiments which demonstrate that previous
                  techniques for database selection do not fully solve
                  the problem. We then describe our approach, based on
                  latent semantic indexing, for improving these
                  algorithms. Our experiments show that this technique
                  can improve selection accuracy by about 5%.}
)

@inproceedings(khoussainov-ceas05,
  author =	 "R. Khoussainov and N. Kushmerick",
  title =	 {Email task management: An iterative relational
                  learning approach},
  year =	 2005,
  booktitle =	 "Proc. Conf. Email and Anti-Spam",
  acceptance =	 "38%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/khoussainov-ceas2005.pdf",
  topic =	 "text analytics; intelligent email;
                  machine learning",
  abstract =	 {Today's email clients were designed for
                  yesterday's email. Originally, email was merely a
                  communication medium. Today, people engage in a
                  variety of complex behaviours using email, such as
                  project management, collaboration, meeting
                  scheduling, to-do tracking, etc. Our goal is to
                  develop automated techniques to help people manage
                  complex activities in email. The central challenge
                  is that most activities are distributed over
                  multiple messages, yet email clients allow users to
                  manipulate just isolated messages. We describe
                  machine learning approaches to task identification
                  (i.e., grouping messages according to task) and
                  semantic message analysis (i.e., extracting metadata
                  about how messages within a task relate to one
                  another and to the task progress). Our key
                  innovation compared to related work is that we
                  exploit the relational structure of these two
                  tasks. Instead of attacking these two problems
                  separately, in our synergistic iterative approach,
                  task identification is used to assist semantic
                  analysis, and vice versa. Our experiments with
                  real-world email corpora demonstrate an improvement
                  compared to nonrelational benchmarks.}
)

@inproceedings(khoussainov-icml05,
  author =	 "R. Khoussainov and A. He{\ss} and N. Kushmerick",
  title =	 "Ensembles of biased classifiers",
  booktitle =	 "Proc. Int. Conf. Machine Learning",
  year =	 2005,
  acceptance =	 "29%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/khoussainov-icml05.pdf",
  topic =	 "machine learning",
  abstract =	 "We propose a novel ensemble learning algorithm
                  called Triskel, which has two interesting
                  features. First, Triskel learns an ensemble of
                  classifiers that are biased to have high precision
                  (as opposed to, for example, boosting, where the
                  ensemble members are biased to ignore portions of
                  the instance space). Second, Triskel uses weighted
                  voting like most ensemble methods, but the weights
                  are assigned so that certain pairs of biased
                  classifiers outweigh the rest of the ensemble, if
                  their predictions agree. Our experiments on a
                  variety of real-world tasks demonstrate that Triskel
                  often outperforms boosting, in terms of both
                  accuracy and training time. We also present an ROC
                  analysis of Triskel, which shows that Triskel's
                  iterative structure corresponds to a sequence of
                  nested ROC spaces, where each embedded space is
                  defined by the previous iteration's biased
                  classifiers. This analysis predicts that Triskel
                  works best when there are concavities in the ROC
                  curve; this prediction agrees qualitatively with our
                  empirical results."
)

@inproceedings(ireson-icml05,
  author =	 "N. Ireson and F. Ciravegna and M.-E. Califf and
                  A. Lavelli and D. Freitag and N. Kushmerick",
  title =	 "Evaluating machine learning for information
                  extraction",
  booktitle =	 "Proc. Int. Conf. Machine Learning",
  year =	 2005,
  acceptance =	 "29%",
  todo =	 "acceptance might get lower if some conditionals are
                  rejected",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/ireson-icml05.pdf",
  topic =	 "machine learning",
  abstract =	 "Comparative evaluation of Machine Learning (ML)
                  systems used for Information Extraction (IE) has
                  suffered from various inconsistencies in
                  experimental procedures. This paper reports on the
                  results of the Pascal Challenge on Evaluating
                  Machine Learning for Information Extraction, which
                  provides a standardised corpus, set of tasks, and
                  evaluation methodology. The challenge is described
                  and the systems submitted by the ten participants
                  are briefly introduced and their performance is
                  analysed."
)

@inproceedings(mccarey-xp2005,
  author =	 "F. McCarey and \'{O} Cinn\'{e}ide, M. and
                  N. Kushmerick",
  year =	 2005,
  title =	 "An {E}clipse plugin to support agile reuse",
  booktitle =	 "Proc. Int. Conf. Extreme Programming",
  acceptance =	 "35%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/mccarey-xp2005.pdf",
  topic =	 "corpus-based software engineering; personalization",
  abstract =	 "Reuse in an Agile context is largely an unexplored
                  research topic. On the surface, these two software
                  engineering techniques would appear to be
                  incompatible due to contradictory principles. For
                  example, Agile components are usually accompanied
                  with little or no support materials, which is likely
                  to hamper their reuse. However we propose that Agile
                  Reuse is possible and indeed advantageous. We have
                  developed an Eclipse plug-in, named RASCAL, to
                  support Agile Reuse. RASCAL is a recommender agent
                  that infers the need for a reusable component and
                  proactively recommends that component to the
                  developer using a technique consistent with Agile
                  principles. We present the benefits and the
                  challenges encountered when implementing an Agile
                  Reuse tool, paying particular to attention to the XP
                  methodology, and detail our recommendation
                  technique. Our overall results suggest RASCAL is a
                  promising approach for enabling reuse in an Agile
                  environment."
)

@inproceedings(mccarey-seke2005,
  author =	 "F. McCarey and \'{O} Cinn\'{e}ide, M. and
                  N. Kushmerick",
  year =	 2005,
  title =	 {Knowledge reuse --- {S}oftware reuse},
  booktitle =	 "Proc. Int. Conf. Software Engineering and Knowledge
                  Engineering",
  TODOacceptance =	 "??%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/mccarey-seke2005.pdf",
  topic =	 "corpus-based software engineering; personalization",
  abstract =	 "Various intelligent component retrieval techniques
                  have been developed to assist a developer discover
                  or locate components in an efficient manner. These
                  techniques share a common weakness though; the
                  developer must initiate the retrieval process. In
                  our work we shift the focus from component retrieval
                  to component recommendation. We extract knowledge
                  from existing source code repositories and employ
                  this information to recommend a candidate set of
                  components to a developer for future
                  use. Recommendations assist and encourage developers
                  to make full use of large component repositories
                  and, in turn, will likely promote software reuse. We
                  present RASCAL, a software component
                  recommender. RASCAL infers the need for a component
                  and proactively recommends that component to a
                  developer. Recommendations are produced using three
                  techniques, namely, collaborative filtering,
                  content-based filtering and a hybrid of the two. We
                  compare these techniques and establish which
                  algorithm produces the most useful
                  recommendations. Our overall results are encouraging
                  and illustrate RASCAL’s ability to recommend a set
                  of useful components to a developer."
)

@inproceedings(khoussainov-ijcai2005,
  author =	 "R. Khoussainov and N. Kushmerick",
  year =	 2005,
  title =	 "Relational learning for email task management",
  booktitle =	 "Proc. Int. Joint Conf. Artificial Intelligence",
  note =	 "Poster",
  acceptance =	 "22%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/khoussainov-ijcai2005.pdf",
  topic =	 "text analytics; intelligent email;
                  machine learning",
  abstract =	 "Today’s email clients were designed for yesterday’s
                  email. Originally, email was merely a communication
                  medium. Today, email has become a `habitat'
                  [Ducheneaut and Bellotti, 2001]---an environment
                  where users engage in a variety of complex
                  activities. Our goal is to develop automated
                  techniques to help people manage complex activities
                  or tasks in email. In many cases, such activities
                  manifest the user’s participation in various
                  structured processes or workflows. The central
                  challenge is that most processes are distributed
                  over multiple emails, yet email clients are designed
                  mainly to manipulate individual messages."
)

@article(hess-mcs2005,
  author =	 "A. He{\ss} and R. Khoussainov and N. Kushmerick",
  year =	 2005,
  title =	 {Ensemble learning with biased classifiers: The
                  {T}riskel algorithm},
  journal =	 "Lecture Notes in Computer Science",
  volume =	 {3541},
  note =	 {Int. Workshop Multiple Classifier Systems; N. Oza,
                  et al., editors},
  acceptance =	 "75%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/hess-mcs05.pdf",
  topic =	 "machine learning",
  abstract =	 "We propose a novel ensemble learning algorithm
                  called Triskel, which has two interesting
                  features. First, Triskel learns an ensemble of
                  classifiers that are biased to have high precision
                  (as opposed to, for example, boosting, where the
                  ensemble members are biased to ignore portions of
                  the instance space). Second, Triskel uses weighted
                  voting like most ensemble methods, but the weights
                  are assigned so that certain pairs of biased
                  classifiers outweigh the rest of the ensemble, if
                  their predictions agree. Our experiments on a
                  variety of real-world tasks demonstrate that Triskel
                  often outperforms boosting, in terms of both
                  accuracy and training time."
)

@proceedings(kushmerick-dagstuhl2005,
  editor =	 "N. Kushmerick and F. Ciravegna and A. Doan and
                  C. Knoblock and S. Staab",
  year =	 2005,
  title =	 {Proc. Dagstuhl Seminar on Machine Learning for the
                  Semantic Web},
  html =	 "http://www.smi.ucd.ie/Dagstuhl-MLSW/proceedings",
  topic =	 "semantic web; machine learning"
)

@inproceedings(danis-chi2005,
  author =	 "C. Danis and W. Kellogg and T. Lau and M. Dredze and
                  J. Stylos and N. Kushmerick",
  year =	 2005,
  title =	 {Managers’ email: Beyond tasks and to-dos},
  booktitle =	 "Proc. Conf. Human Factors in Computing Systems",
  note =	 "Short paper",
  acceptance =	 "25%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/danis-chi2005.pdf",
  topic =	 "text analytics; intelligent email",
  abstract =	 "In this paper, we describe preliminary findings that
                  indicate that managers and non-mangers think about
                  their email differently. We asked three research
                  managers and three research non-managers to sort
                  about 250 of their own email messages into
                  categories that `would help them to manage their
                  work.' Our analyses indicate that managers create
                  more categories and a more differentiated category
                  structure than non-managers. Our data also suggest
                  that managers create `relationship-oriented'
                  categories more often than non-managers. These
                  results are relevant to research on `email overload'
                  that has highlighted the use of email for activities
                  beyond communication. In particular, our findings
                  suggest that too strong a focus on task management
                  may be incomplete, and that a user’s organizational
                  role has an impact on their conceptualization and
                  likely use of email."
)

@inproceedings(finn-dagstuhl2005,
  author =	 "A. Finn and B. McLernon and N. Kushmerick",
  year =	 2005,
  title =	 {Adaptive information extraction research at {UCD}},
  booktitle =	 "Proc. Dagstuhl Seminar on Machine Learning for the
                  Semantic Web",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/finn-dagstuhl-mlsw-2005.pdf",
  topic =	 "text analytics; information
                  extraction; machine learning",
  abstract =	 "Information extraction (IE) is the process of
                  identifying a set of pre-defined relevant items in
                  text documents. In this paper we describe two
                  systems for adaptive information extraction that are
                  currently under development at UCD."
)

@inproceedings(hess-dagstuhl2005,
  author =	 "A. He{\ss} and E. Johnston and N. Kushmerick",
  title =	 "Machine learning techniques for annotating semantic
                  web services",
  year =	 2005,
  booktitle =	 "Proc. Dagstuhl Seminar on Machine Learning for the
                  Semantic Web",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/hess-dagstuhl-mlsw-2005.pdf",
  topic =	 "corpus-based software engineering; machine learning;
                  semantic web; data integration",
  abstract =	 "The vision of semantic Web Services is to provide
                  the means for fully automated discovery, composition
                  and invocation of loosely coupled software
                  components. One of the key efforts to address this
                  `semantic gap' is the well-known OWLS ontology (The
                  DAML Services Coalition 2003). However, software
                  engineers who are developing Web Services usually do
                  not think in terms of ontologies, but rather in
                  terms of their programming tools. Existing tools for
                  both the Java and .NET environments support the
                  automatic generation of WSDL. We believe that it
                  would boost the semantic service web if similar
                  tools existed to (semi-) automatically generate
                  OWL-S or a similar form of semantic metadata. In
                  this paper we will present a tool called
                  ASSAM---Automated Semantic Service Annotation with
                  Machine Learning---that addresses these needs. ASSAM
                  consists of two parts, a WSDL annotator application,
                  and OATS, a data aggregation algorithm."
)

@article(finn-jasist2006,
  author =	 "A. Finn and N. Kushmerick",
  year =	 2006,
  title =	 "Learning to classify documents according to genre",
  journal =	 "J. American Society for Information Science and
                  Technology",
  volume =	 57,
  number =	 9,
  note =	 "Special issue on Computational Analysis of Style",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/finn-jasist06.pdf",
  topic =	 "text analytics",
  abstract =	 "Current document retrieval tools succeed in locating
                  large numbers of documents relevant to a given
                  query. While search results may be relevant
                  according to the topic of the documents, it is more
                  difficult to identify which of the relevant
                  documents are most suitable for a particular
                  user. Automatic genre analysis---that is, the
                  ability to distinguish documents according to
                  style---would be a useful tool for identifying
                  documents that are most suitable for a particular
                  user. We investigate the use of machine learning for
                  automatic genre classification. We introduce the
                  idea of domain transfer - genre classifiers should
                  be reusable across multiple topics - which doesn’t
                  arise in standard text classification. We
                  investigate different features for building genre
                  classifiers and their ability to transfer across
                  multiple topic domains. We also show how different
                  feature-sets can be used in conjunction with each
                  other to improve performance and reduce the number
                  of documents that need to be labeled."
)

@article(mccarey-air2005,
  author =	 "F. McCarey and \'{O} Cinn\'{e}ide, M. and
                  N. Kushmerick",
  year =	 2005,
  title =	 {RASCAL: A recommender agent for software components
                  in an agile environment},
  journal =	 "Artificial Intelligence Review",
  note =	 "In press",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/mccarey-airev2005.pdf",
  topic =	 "corpus-based software engineering; personalization",
  abstract =	 "As software organisations mature, their repositories
                  of reusable soft- ware components from previous
                  projects will also grow considerably. Remaining
                  conversant with all components in such a repository
                  presents a significant challenge to
                  developers. Indeed the retrieval of a particular
                  component in this large search space may prove
                  problematic. Further to this, the reuse of
                  components developed in an Agile environment is
                  likely to be hampered by the existence of little or
                  no support materials. We propose to infer the need
                  for a component and proactively recommend that
                  component to the developer using a technique which
                  is consistent with the principles of Agile
                  methodologies. Our RASCAL recommender agent tracks
                  usage histories of a group of devel- opers to
                  recommend to an individual developer components that
                  are expected to be needed by that developer. Unlike
                  many traditional recommender systems, we may
                  recommend items that the developer has actually
                  employed previously. We introduce a content-based
                  filtering technique for ordering the set of
                  recommended software components and present a
                  comparative analysis of applying this technique to a
                  number of collaborative filtering algorithms. We
                  also investigate the relationship between the number
                  of usage histories collected and recommendation
                  accuracy. Our overall results indicate that RASCAL
                  is a very promising tool for allowing developers
                  discover reusable components at no additional cost."
)

@inproceedings(kushmerick-iui2005,
  author =	 "N. Kushmerick and T. Lau",
  year =	 2005,
  title =	 {Automated email activity management: An unsupervised
                  learning approach},
  booktitle =	 "Proc. Int. Conf. Intelligent User Interfaces",
  note =	 "Honorable Mention for Outstanding Paper Award",
  acceptance =	 "22%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/kushmerick-iui05.pdf",
  topic =	 "text analytics; machine learning;
                  intelligent email",
  abstract =	 "Many structured activities are managed by email. For
                  instance, a consumer purchasing an item from an
                  e-commerce vendor may receive a message confirming
                  the order, a warning of a delay, and then a shipment
                  notification. Existing email clients do not
                  understand this structure, forcing users to manage
                  their activities by sifting through lists of
                  messages. As a first step to developing email
                  applications that provide high-level support for
                  structured activities, we consider the problem of
                  automatically learning an activity’s structure. We
                  formalize activities as finite-state automata, where
                  states correspond to the status of the process, and
                  transitions represent messages sent between
                  participants. We propose several unsupervised
                  machine learning algorithms in this context, and
                  evaluate them on a collection of e-commerce email."
)

@misc(hess-iswc2004-demo,
  author =	 "A. He{\ss} and N. Kushmerick",
  year =	 2004,
  title =	 {{ASSAM}: A tool for semi-automatically annotating
                  semantic web services},
  howpublished = "Demonstration at the Int. Semantic Web Conf.",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/hess-iswc04-demo.pdf",
  topic =	 "corpus-based software engineering; machine learning;
                  semantic web; data integration",
  abstract =	 "The vision of Semantic Web Services is to provide
                  the means for fully automated discovery, composition
                  and invocation of loosely coupled software
                  components. One of the key efforts to address this
                  `semantic gap' is the well-known OWL-S
                  ontology. However, software engineers who are
                  developing Web Services usually do not think in
                  terms of ontologies, but rather in terms of their
                  programming tools. Existing tools for both the Java
                  and .NET environments support the automatic
                  generation of WSDL. We believe that the semantic
                  service web will flourish only when similar tools
                  existed to (semi-) automatically generate OWL-S or a
                  similar form of semantic metadata. In this demo we
                  present a tool called ASSAM---Automated Semantic
                  Service Annotation with Machine Learning---that
                  addresses these needs. This extended abstract is
                  structured as follows: In the next section, we will
                  introduce the ASSAM annotator application. In
                  section 3, we describe the machine learning
                  algorithm behind ASSAM. Finally, we present some
                  related work and discuss planned future extensions
                  to our current application."
)

@article(khoussainov-ercim2004,
  author =	 "R. Khoussainov and X. Zuo and N. Kushmerick",
  year =	 2004,
  title =	 {Grid-enabled Weka: A toolkit for machine learning on
                  the grid},
  journal =	 "ERCIM News",
  volume =	 59,
  html =
                  "http://www.ercim.org/publication/Ercim_News/enw59/khussainov.html",
  topic =	 "machine learning; corpus-based software engineering",
  abstract =	 "In the end of the day, Grids are about Grid-enabled
                  applications. While a number of general-purpose
                  libraries for scientific computing have been adapted
                  for Grids, many more opportunities remain in various
                  specialist areas. We describe here an ongoing work
                  on Grid-enabled Weka, a widely used toolkit for
                  machine learning and data mining."
)

@inproceedings(khoussainov-widm2004,
  author =	 "R. Khoussainov and N. Kushmerick",
  year =	 2004,
  title =	 "Specialisation dynamics in federated web search",
  booktitle =	 "Proc. Workshop Web Information and Data Management",
  note =	 "Conf. Information and Knowledge Management",
  acceptance =	 "32%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/khoussainov-cikm2004-widm.pdf",
  topic =	 "machine learning; Web search",
  abstract =	 "Organising large-scale Web information retrieval
                  systems into hierarchies of topic-specific search
                  resources can improve both the quality of results
                  and the efficient use of computing resources. A
                  promising way to build such systems involves
                  federations of topicspecific search engines in
                  decentralised search environments. Most of the
                  previous research concentrated on various technical
                  aspects of such environments (e.g. routing of search
                  queries or merging of results from multiple
                  sources). We focus on organisational dynamics: what
                  happens to topical specialisation of search engines
                  in the absence of centralised control, when each
                  engine makes individual and self-interested
                  decisions on its service parameters? We investigate
                  this question in a computational economics
                  framework, where search providers compete for user
                  queries by choosing what topics to index. We provide
                  a formalisation of the competition problem and then
                  analyse theoretically and empirically the
                  specialisation dynamics of such systems."
)

@inproceedings(mccarey-aics2004,
  author =	 "F. McCarey and \'{O} Cinn\'{e}ide, M. and
                  N. Kushmerick",
  year =	 2004,
  title =	 {RASCAL: A recommender agent for software components
                  in an agile environment},
  booktitle =	 "Proc. Irish Conf. Artificial Intelligence and
                  Cognitive Science",
  acceptance =	 "31%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/mccarey-aics2004.pdf",
  topic =	 "personalization; corpus-based software engineering",
  abstract =	 "As software organisations mature, their repository
                  of reusable software components from previous
                  projects will grow considerably. Remaining
                  conversant with all components in such a repository
                  presents a significant challenge to
                  developers. Indeed the retrieval of a particular
                  component in this large search space may prove
                  problematic. We propose to infer the need for a
                  component and proactively recommend that component
                  to the developer using a technique which is
                  consistent with the principles of Agile
                  development. Our RASCAL recommender agent tracks
                  usage histories of a group of users to recommend to
                  an individual user components that are expected to
                  be needed by that user. Unlike many traditional
                  recommender systems we may recommend items which the
                  developer has actually employed previously. We
                  introduce a technique for ordering the set of
                  recommended software components and present a
                  comparative analysis of applying this technique to a
                  number of Collaborative Filtering algorithms. We
                  also investigate the relationship between the number
                  of usage histories collected and recommendation
                  accuracy. Our overall results indicate that RASCAL
                  is a very promising tool for allowing developers
                  discover reusable components at no additional cost."
)

@inproceedings(murdoch-muia2004,
  author =	 "G. Murdoch and N. Kushmerick",
  year =	 2004,
  title =	 "Mapping physical artifacts to their web
                  counterparts: {A} case study with product catalogs",
  booktitle =	 "Proc. Workshop Mobile and Ubiquitous Information
                  Access",
  note =	 "Conf. Mobile Human-Computer Interaction",
  acceptance =	 "60%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/murdoch-mhci04-muia.pdf",
  topic =	 "Web search; machine learning",
  abstract =	 "Many kinds of documents---newspapers, books, product
                  catalogs, directories, etc---exist in both a
                  physical (paper) and virtual (Web) form. Few
                  approaches to knowledgment management fully exploit
                  the opportunities afforded by this fact. Motivated
                  by the goal of seamless integration of physical
                  artifacts and their Web counterparts, we describe a
                  large-scale case study of one aspect of this
                  relationship. Based on a corpus of hundreds of
                  real-world product catalogs, we measure the
                  effectiveness of hand-held scanner/OCR devices for
                  the task of automatically retrieving a catalog’s
                  authoritative Web counterpart (the vendor’s home
                  page). We find that, despite OCR errors, text
                  fragments scanned from product catalogs can serve as
                  reasonably effective queries for retrieving the Web
                  counterparts. Furthermore, the effectiveness of the
                  technique increases with multiple scanned text
                  fragments. Our main technical contribution is a
                  novel machine learning approach to adaptively
                  merging the retrieved documents from multiple
                  scans."
)

@inproceedings(hess-iswc2004,
  author =	 "A. He{\ss} and E. Johnston and N. Kushmerick",
  year =	 2004,
  title =	 {{ASSAM}: A tool for semi-automatically annotating
                  semantic web services},
  booktitle =	 "Proc. Int. Semantic Web Conf.",
  acceptance =	 "23%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/hess-iswc04.pdf",
  topic =	 "corpus-based software engineering; machine learning;
                  semantic web; data integration",
  abstract =	 "The semantic Web Services vision requires that each
                  service be annotated with semantic
                  metadata. Manually creating such metadata is tedious
                  and error-prone, and many software engineers,
                  accustomed to tools that automatically generate
                  WSDL, might not want to invest the additional
                  effort. We therefore propose ASSAM, a tool that
                  assists a user in creating semantic metadata for Web
                  Services. ASSAM is intended for service consumers
                  who want to integrate a number of services and
                  therefore must annotate them according to some
                  shared ontology. ASSAM is also relevant for service
                  producers who have deployed a Web Service and want
                  to make it compatible with an existing
                  ontology. ASSAM’s capabilities to automatically
                  create semantic metadata are supported by two
                  machine learning algorithms. First, we have
                  developed an iterative relational classification
                  algorithm for semantically classifying Web Services,
                  their operations, and input and output
                  messages. Second, to aggregate the data returned by
                  multiple semantically relatedWeb Services, we have
                  developed a schema mapping algorithm that is based
                  on an ensemble of string distance metrics."
)

@inproceedings(hess-iiw2004,
  author =	 "A. He{\ss} and E. Johnston and N. Kushmerick",
  year =	 2004,
  title =	 "Semi-automatically annotating semantic web services
                  (extended abstract)",
  booktitle =	 "Proc. Workshop Information Integration on the Web",
  note =	 "Int. Conf. Very Large Data Bases",
  acceptance =	 "54%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/hess-vldb04-iiweb.pdf",
  topic =	 "corpus-based software engineering; machine learning;
                  semantic web; data integration",
  abstract =	 "The semantic Web Services vision requires that each
                  service be annotated with semantic metadata. Various
                  metadata languages (such as OWL-S (DAML-S Coalition
                  2003)) have been proposed to fill this `semantic
                  gap'. However, manually creating such metadata is
                  tedious and error-prone. Software engineers,
                  accustomed to tools that automatically generate
                  WSDL, might not want to invest the required
                  effort. This extended abstract describes ASSAM, a
                  tool that assists a user in creating semantic
                  metadata for Web Services. ASSAM’s capabilities to
                  automatically create semantic metadata are supported
                  by two machine learning algorithms. First, we have
                  developed an iterative relational classification
                  algorithm for semantically classifying Web Services,
                  their operations, and input and output
                  messages. Second, to aggregate the data returned by
                  multiple semantically relatedWeb Services, we have
                  developed a schema mapping algorithm based ensembles
                  of string distance metrics."
)

@inproceedings(finn-ecml2004,
  author =	 "A. Finn and N. Kushmerick",
  year =	 2004,
  title =	 "Multi-level Boundary Classification for Information
                  Extraction",
  booktitle =	 "Proc. European Conf. Machine Learning",
  acceptance =	 "15%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/finn-ecml04.pdf",
  topic =	 "text analytics; information extraction;
                  machine learning",
  abstract =	 "We investigate the application of classification
                  techniques to the problem of information extraction
                  (IE). In particular we use support vector machines
                  and several different feature-sets to build a set of
                  classifiers for IE. We show that this approach is
                  competitive with current state-of-the-art IE
                  algorithms based on specialized learning
                  algorithms. We also introduce a new technique for
                  improving the recall of our IE algorithm. This
                  approach uses a two-level ensemble of classifiers to
                  improve the recall of the extracted fragments while
                  maintaining high precision. We show that this
                  approach outperforms current state-of-the-art IE
                  algorithms on several benchmark IE tasks."
)

@inproceedings(hess-ecml2004,
  author =	 "A. He{\ss} and N. Kushmerick",
  year =	 2004,
  title =	 "Iterative Ensemble Classification for Relational
                  Data: A Case Study of Semantic Web Services",
  booktitle =	 "Proc. European Conf. Machine Learning",
  acceptance =	 "15%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/hess-ecml04.pdf",
  topic =	 "corpus-based software engineering; machine learning;
                  semantic web; data integration",
  abstract =	 "For the classification of relational data, iterative
                  algorithms that feed back predicted labels of
                  associated objects have been used. In this paper we
                  show two extensions to existing approaches. First,
                  we propose to use two separate classifiers for the
                  intrinsic and the relational (extrinsic) attributes
                  and vote their predictions. Second, we introduce a
                  new way of exploiting the relational structure. When
                  the extrinsic attributes alone are not sufficient to
                  make a prediction, we train specialised classifiers
                  on the intrinsic features and use the extrinsic
                  features as a selector. We apply these techniques to
                  the task of semi-automated Web Service annotation, a
                  task with a rich relational structure."
)

@proceedings(davulcu-iiw2004,
  editor =	 "H. Davulcu and N. Kushmerick",
  year =	 2004,
  title =	 "Proc. Workshop Information Integration on the Web",
  note =	 "Int. Conf. Very Large Data Bases",
  html =	 "http://cips.eas.asu.edu/iiweb.htm",
  topic =	 "data integration; semantic web"
)

@proceedings(muslea-atem2004,
  editor =	 "I. Muslea and M. Craven and F. Ciravegna and
                  N. Kushmerick",
  year =	 2004,
  title =	 "Proc. Workshop Adaptive Text Extraction and
                  Mining",
  note =	 "American Nat. Conf. Artificial Intelligence",
  html =	 "http://www.ai.sri.com/~muslea/ATEM-04.html",
  topic =	 "machine learning; text analytics;
                  information extraction"
)

@inproceedings(johnston-eka2004,
  author =	 "E. Johnston and N. Kushmerick",
  year =	 2004,
  title =	 "Aggregating Web Services with active invocation and
                  ensembles of string distance metrics",
  booktitle =	 "Proc. Int. Conf. Knowledge Engineering and Knowledge
                  Management",
  accept =	 "40%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/johnston-ekaw04.pdf",
  topic =	 "corpus-based software engineering; data integration",
  abstract =	 "The adoption of standards for exchanging information
                  across the web could present a new world of
                  opportunities for data integration and aggregation
                  systems. Although Web Services simplify the
                  discovery and access of information sources, the
                  problem of semantic heterogeneity remains: how to
                  find semantic correspondences within the data being
                  integrated. In this paper, we propose OATS, a novel
                  algorithm for schema matching that is specifically
                  suited to Web Service data aggregation. We show how
                  probing Web Services with a small set of related
                  queries results in semantically correlated data
                  instances which greatly simplifies the matching
                  process, and demonstrate that the use of an ensemble
                  of string distance metrics in matching data
                  instances performs better than individual
                  metrics. We also propose a method for adaptively
                  combining distance metrics, and evaluate OATS on a
                  large number of real-world Web Service operations."
)

@article(ocinneide-ercim2004,
  author =	 "\'{O} Cinn\'{e}ide, M. and N. Kushmerick and
                  T. Veale",
  year =	 2004,
  title =	 "Automated Support for Agile Software Reuse",
  journal =	 "ERCIM News",
  volume =	 58,
  html =
                  "http://www.ercim.org/publication/Ercim_News/enw58/o_cinneide.html",
  topic =	 "corpus-based software engineering",
  abstract =	 "Agile software development methodologies tend
                  towards sparse up-front design and minimal
                  commenting of source code. Researchers in the
                  Department of Computer Science, University College
                  Dublin are investigating ways of providing automated
                  support for software reuse in this code-centric
                  context."
)

@inproceedings(finn-atem2004,
  author =	 "A. Finn and N. Kushmerick",
  year =	 2004,
  title =	 "Information extraction by convergent boundary
                  classification",
  booktitle =	 "Proc. Workshop Adaptive Text Extraction and
                  Mining",
  note =	 "American Nat. Conf. Artificial Intelligence",
  accept =	 "44%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/finn-aaai04-atem.pdf",
  topic =	 "text analytics; machine learning;
                  information extraction",
  abstract =	 "We investigate the application of classification
                  techniques to the problem of information extraction
                  (IE). In particular we use support vector machines
                  and several different feature-sets to build a set of
                  classifiers for information extraction. We show that
                  this approach is competitive with current
                  state-ofthe- art information extraction algorithms
                  based on specialized learning algorithms. We also
                  introduce a new technique for improving the recall
                  of IE systems called convergent boundary
                  classification. We show that this can give
                  significant improvement in the performance of our IE
                  system and gives a system with both high precision
                  and high recall."
)

@inproceedings(lavelli-atem2004,
  author =	 "A. Lavelli and M.-E. Califf and F. Ciravegna and
                  D. Freitag and C. Giuliano and N. Kushmerick and
                  L. Romano",
  year =	 2004,
  title =	 {{IE} evaluation: Criticisms and recommendations},
  booktitle =	 "Proc. Workshop Adaptive Text Extraction and
                  Mining",
  note =	 "American Nat. Conf. Artificial Intelligence",
  accept =	 "44%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/lavelli-aaai04-atem.pdf",
  topic =	 "text analytics; machine learning;
                  information extraction",
  abstract =	 "We survey the evaluation methodology adopted in
                  Information Extraction (IE), as defined in the MUC
                  conferences and in later independent efforts
                  applying machine learning to IE. We point out a
                  number of problematic issues that may hamper the
                  comparison between results obtained by different
                  researchers. Some of them are common to other NLP
                  tasks: e.g., the difficulty of exactly identifying
                  the effects on performance of the data (sample
                  selection and sample size), of the domain theory
                  (features selected), and of algorithm parameter
                  settings. Issues specific to IE evaluation include:
                  how leniently to assess inexact identification of
                  filler boundaries, the possibility of multiple
                  fillers for a slot, and how the counting is
                  performed. We argue that, when specifying an
                  information extraction task, a number of
                  characteristics should be clearly defined. However,
                  in the papers only a few of them are usually
                  explicitly specified. Our aim is to elaborate a
                  clear and detailed experimental methodology and
                  propose it to the IE community. The goal is to reach
                  a widespread agreement on such proposal so that
                  future IE evaluations will adopt the proposed
                  methodology, making comparisons between algorithms
                  fair and reliable. In order to achieve this goal, we
                  will develop and make available to the community a
                  set of tools and resources that incorporate a
                  standardized IE methodology."
)

@inproceedings(mccarey-msr2004,
  author =	 "F. McCarey and \'{O} Cinn\'{e}ide, M. and
                  N. Kushmerick",
  year =	 2004,
  title =	 "A case study on recommending reusable software
                  components using collaborative filtering",
  booktitle =	 "Proc. Workshop Mining Software Repositories",
  note =	 "Int. Conf. Software Engineering",
  accept =	 "68%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/mccarey-icse2004-msr.pdf",
  topic =	 "corpus-based software engineering; personalization",
  abstract =	 "The demand for quality, highly functional software
                  reinforces the need for reusable software
                  components. However, as repositories of reusable
                  components increase in size and complexity, the
                  challenge for developers to remain conversant with
                  all components becomes greater. This paper proposes
                  a software recommendation system based on
                  collaborative filtering, which has been shown to be
                  effective in other domains. Based on the usage
                  patterns of existing classes and the class currently
                  being developed, our system proposes a set of reuse
                  candidates to the programmer. We present the results
                  of our analysis of the usage of Swing classes in
                  several open-source applications and find that the
                  collaborative filtering technique is promising in
                  providing recommendations in this context."
)

@inproceedings(lavelli-lrec2004,
  author =	 "A. Lavelli and M.-E. Califf and F. Ciravegna and
                  D. Freitag and C. Giuliano and N. Kushmerick and
                  L. Romano",
  year =	 2004,
  title =	 "A critical survey of the methodology for {IE}
                  evaluation",
  booktitle =	 "Proc. Conf. Language Resources and Evaluation",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/lavelli-lrec2004.pdf",
  topic =	 "text analytics; machine learning;
                  information extraction",
  abstract =	 "We survey the evaluation methodology adopted in
                  Information Extraction (IE), as defined in the MUC
                  conferences and in later independent efforts
                  applying machine learning to IE. We point out a
                  number of problematic issues that may hamper the
                  comparison between results obtained by different
                  researchers. Some of them are common to other NLP
                  tasks: e.g., the difficulty of exactly identifying
                  the effects on performance of the data (sample
                  selection and sample size), of the domain theory
                  (features selected), and of algorithm parameter
                  settings. Issues specific to IE evaluation include:
                  how leniently to assess inexact identification of
                  filler boundaries, the possibility of multiple
                  fillers for a slot, and how the counting is
                  performed. We argue that, when specifying an
                  information extraction task, a number of
                  characteristics should be clearly defined. However,
                  in the papers only a few of them are usually
                  explicitly specified. Our aim is to elaborate a
                  clear and detailed experimental methodology and
                  propose it to the IE community. The goal is to reach
                  a widespread agreement on such proposal so that
                  future IE evaluations will adopt the proposed
                  methodology, making comparisons between algorithms
                  fair and reliable. In order to achieve this goal, we
                  will develop and make available to the community a
                  set of tools and resources that incorporate a
                  standardized IE methodology."
)

@inproceedings(hess-sssws2004,
  author =	 "A. He{\ss} and N. Kushmerick",
  year =	 2004,
  title =	 "Machine learning for annotating Semantic Web
                  Services",
  booktitle =	 "Proc. AAAI Spring Symposium on Semantic Web
                  Services",
  psgz =
                  "http://www.smi.ucd.ie/nick/research/download/hess-aaaiss2004-sws.ps.gz",
  topic =	 "corpus-based software engineering; machine learning;
                  semantic web; data integration",
  abstract =	 "Emerging Semantic Web standards promise the
                  automated discovery, composition and invocation of
                  Web Services. Un­ fortunately, this vision requires
                  that services describe them­ selves with large
                  amounts of hand­crafted semantic meta­ data. We are
                  investigating the use of machine learning tech­
                  niques for semi­automatically classifying Web
                  Services and their messages into ontologies. "
)

@inproceedings(dimitrova-isko2004,
  author =	 "M. Dimitrova and N. Kushmerick and I. Terziev and
                  A. Gegov",
  year =	 2004,
  title =	 {Web users and web document classifiers: Emergent
                  cognitive phenomena},
  booktitle =	 "Proc. Conf. International Society for Knowledge
                  Organization",
  pfd =
                  "http://www.smi.ucd.ie/nick/research/download/dimitrova-isko2004.pdf",
  topic =	 "personalization; information retrieval",
  abstract =	 "We are currently developing an approach to introduce
                  heuristics based on facts and phenomena from
                  cognitive science in the design of automatic Web
                  document classifiers. The analysis of the results of
                  the study has revealed new and emergent cognitive
                  phenomena of users interacting with present-day Web
                  systems. The interface to the user employs an
                  automatic Web-document classifier, inspired by the
                  word-length and word-frequency effects. The result
                  is faster and efficient document search,
                  classification and retrieval. The paper discusses
                  the encountered insights like leasteffort strategy
                  in user assessment of Web documents, the implicit
                  user expectation for interaction with
                  .intelligent. interface, as well as the increasing
                  demand for document summaries. Some interface design
                  guidelines, falling out from the current study, are
                  outlined."
)

@article(omahony-acmtit2004,
  author =	 "M. O'Mahony and N. Hurley and N. Kushmerick and
                  G. Silvestre",
  year =	 2004,
  title =	 {Collaborative recommendation: A robustness analysis},
  journal =	 "ACM Trans. Internet Technology",
  volume =	 4,
  number =	 4,
  pages =	 "344--377",
  note =	 "Special issue on Machine Learning for the Internet",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/omahony-acmtit2004.pdf",
  topic =	 "personalization; machine learning",
  abstract =	 "Collaborative recommendation has emerged as an
                  effective technique for personalized information
                  access. However, there has been relatively little
                  theoretical analysis of the conditions under which
                  the technique is effective. To explore this issue,
                  we analyse the robustness of collaborative
                  recommendation: the ability to make recommendations
                  despite (possibly intentional) noisy product
                  ratings. There are two aspects to robustness:
                  recommendation accuracy and stability. We formalize
                  recommendation accuracy in machine learning terms
                  and develop theoretically justified models of
                  accuracy. In addition, we present a framework to
                  examine recommendation stability in the context of a
                  widely-used collaborative filtering algorithm. For
                  each case, we evaluate our analysis using several
                  real-world data-sets. Our investigation is both
                  practically relevant for enterprises wondering
                  whether collaborative recommendation leaves their
                  marketing operations open to attack, and
                  theoretically interesting for the light it sheds on
                  a comprehensive theory of collaborative
                  recommendation."
)

@inproceedings(kushmerick-odbase2003,
  author =	 "N. Kushmerick",
  year =	 2003,
  title =	 "Learning to invoke Web forms",
  booktitle =	 "Proc. Int. Conf. Ontologies, Databases and
                  Applications of Semantics",
  accept =	 "23%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/kushmerick-odbase2003.pdf",
  topic =	 "machine learning; semantic web; data integration",
  abstract =	 "Emerging Web standards promise a network of
                  heterogeneous yet interoperable Web Services. Web
                  Services would greatly simplify the development of
                  many kinds of data integration systems, information
                  agents and knowledge management
                  applications. Unfortunately, this vision requires
                  that services provide substantial quantities of
                  explicit semantic metadata “glue”. As a step
                  to automatically generating such metadata, we
                  present an algorithm that learns to attach semantic
                  labels to Web forms, and evaluate our approach on a
                  large collection real Web data. The key idea is to
                  cast Web form classification as Bayesian learning
                  and inference over a generative model of the Web
                  form design process."
)

@proceedings(ciravegna-atem2003,
  editor =	 "F. Ciravegna and N. Kushmerick",
  year =	 2003,
  title =	 "Proc. Workshop Adaptive Text Extraction and
                  Mining",
  note =	 "European Conf. Machine Learning",
  html =	 "http://www.dcs.shef.ac.uk/~fabio/ATEM03",
  topic =	 "text analytics; machine learning;
                  information extraction"
)

@inproceedings(khoussainov-cikm2003,
  author =	 "R. Khoussainov and N. Kushmerick",
  year =	 2003,
  title =	 "Automatic index management for distributed Web
                  search",
  booktitle =	 "Proc. Conf. Information and Knowledge Management",
  acceptance =	 "15%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/khoussainov-cikm2003.pdf",
  topic =	 "machine learning; Web search",
  abstract =	 "Distributed heterogeneous search systems are an
                  emerging phenomenon inWeb search, in which
                  independent topic-specific search engines provide
                  search services, and metasearchers distribute user’s
                  queries to only the most suitable search
                  engines. Previous research has investigated methods
                  for engine selection and merging of search results
                  (i.e. performance improvements from the user’s
                  perspective). We focus instead on performance from
                  the service provider’s point of view (e.g, income
                  from queries processed vs. resources used to answer
                  them). We consider a scenario in which individual
                  search engines compete for user queries by choosing
                  which documents (topics) to index. The difficulty
                  here stems from the fact that the utilities of local
                  engine actions should depend on the uncertain
                  actions of competitors. Thus, naive strategies (e.g,
                  blindly indexing lots of popular documents) are
                  ineffective. We model the competition between search
                  engines as a stochastic game, and propose a
                  reinforcement learning approach to managing search
                  index contents. We evaluate our approach using a
                  large log of user queries to 47 real search
                  engines."
)

@article(khoussainov-dir2004,
  author =	 {R. Khoussainov and N. Kushmerick},
  year =	 {2004},
  title =	 "Distributed Web search as a stochastic game",
  note =	 {Distributed multimedia information retrieval;
                  J. Callan, F. Crestani and M. Sanderson, editors},
  journal =	 {Lecture Notes in Computer Science},
  volume =	 {2924},
  acceptance =	 "69%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/khoussainov-sigir2003-wdir.pdf",
  topic =	 "machine learning; Web search",
  abstract =	 "Distributed search systems are an emerging
                  phenomenon inWeb search, in which independent
                  topic-specific search engines provide search
                  services, and metasearchers distribute user’s
                  queries to only the most suitable search
                  engines. Previous research has investigated methods
                  for engine selection and merging of search results
                  (i.e. performance improvements from the user’s
                  perspective). We focus instead on performance from
                  the service provider’s point of view (e.g, income
                  from queries processed vs. resources used to answer
                  them). We analyse a scenario in which individual
                  search engines compete for user queries by choosing
                  which documents (topics) to index. The challenge is
                  that the utilities of an engine’s actions should
                  depend on the uncertain actions of
                  competitors. Thus, naive strategies (e.g, blindly
                  indexing lots of popular documents) are
                  ineffective. We model the competition between search
                  engines as a stochastic game, and propose a
                  reinforcement learning approach to managing search
                  index contents. We evaluate our approach using a
                  large log of user queries to 47 real search
                  engines."
)

@inproceedings(hess-iswc2003,
  author =	 "A. He{\ss} and N. Kushmerick",
  year =	 2003,
  title =	 "Learning to attach semantic metadata to Web
                  Services",
  booktitle =	 "Proc. Int. Semantic Web Conf.",
  acceptance =	 "24%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/hess-iswc2003.pdf",
  topic =	 "corpus-based software engineering; machine learning;
                  semantic web; data integration",
  abstract =	 "Emerging Web standards promise a network of
                  heteroge- neous yet interoperable Web Services. Web
                  Services would greatly sim- plify the development of
                  many kinds of data integration and knowl- edge
                  management applications. Unfortunately, this vision
                  requires that services describe themselves with
                  large amounts of semantic metadata `glue'. We
                  explore a variety of machine learning techniques to
                  semi- automatically create such metadata. We make
                  three contributions. First, we describe a Bayesian
                  learning and inference algorithm for classifying
                  HTML forms into semantic cat- egories, as well as
                  assigning semantic labels to the form’s
                  fields. These techniques are important as legacy
                  HTML interfaces are migrated to Web
                  Services. Second, we describe the application of the
                  Naive Bayes and SVM algorithms to the task of Web
                  Service classification. We show that an ensemble
                  approach that treatsWeb Services as structured
                  objects is more accurate than an unstructured
                  approach. Finally, we describe a clustering
                  algorithm that automatically discovers the semantic
                  categories of Web Services. All of our algorithms
                  are evaluated using large collec- tions of real HTML
                  forms and Web Services."
)

@inproceedings(finn-atem2003,
  author =	 "A. Finn and N. Kushmerick",
  year =	 2003,
  title =	 "Active learning selection strategies for information
                  extraction",
  booktitle =	 "Proc. Workshop Adaptive Text Extraction and Mining",
  note =	 "European Conf. Machine Learning",
  acceptance =	 "50%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/finn-ecml2003-atem.pdf",
  topic =	 "text analytics; machine learning;
                  information extraction",
  abstract =	 "The need for labeled documents is a key bottleneck
                  in adaptive information extraction. One way to solve
                  this problem is through active learning algorithms
                  that require users to label only the most
                  informative documents. We investigate several
                  document selection strategies that are particularly
                  relevant to information extraction. We show that
                  some strategies are biased toward recall, while
                  others are biased toward precision, but it is
                  difficult to ensure both high recall and
                  precision. We also show that there is plenty of
                  scope for improved selection strategies, and
                  investigate the relationship between the documents
                  selected and the relative performance between two
                  strategies."
)

@inproceedings(masterson-atem2003,
  author =	 "D. Masterson and N. Kushmerick",
  year =	 2003,
  title =	 "Information extraction from multi-document threads",
  booktitle =	 "Proc. Workshop Adaptive Text Extraction and Mining",
  note =	 "European Conf. Machine Learning",
  acceptance =	 "50%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/masterson-ecml2003-atem.pdf",
  topic =	 "text analytics; machine learning;
                  information extraction",
  abstract =	 "Information extraction (IE) is the task of
                  extracting fragments of important information from
                  natural language documents. Most IE research
                  involves algorithms for learning to exploit
                  regularities inherent in the textual information and
                  language use, and such systems generally assume that
                  each document can be processed in isolation. We are
                  extending IE techniques to multi-document extraction
                  tasks, in which the information to be extracted is
                  distributed across several documents. For example,
                  many kinds of work-flow transactions are realized as
                  sequences of electronic mail messages comprising a
                  conversation among several participants. We show
                  that IE performance can be improved by harnessing
                  the structural and temporal relationships between
                  documents."
)

@inproceedings(dimitrova-viip2003,
  author =	 "M. Dimitrova and N. Kushmerick and P. Radeva and
                  J.-J. Villanueva",
  year =	 2003,
  title =	 "User assessment of a visual Web genre classifier",
  booktitle =	 "Proc. Int. Conf. on Visualization, Imaging, and
                  Image Processing",
  acceptance =	 "50%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/dimitrova-viip2003.pdf",
  topic =	 "personalization; information retrieval",
  abstract =	 "Users assess the `appropriateness' of web documents
                  in many ways. Traditionally, appropriateness has
                  been solely a matter of relevance to a particular
                  topic. But users are concerned with other aspects of
                  document `genre', such as the level of expertise
                  assumed by the author, or the amount of detail. In
                  previous work, we have used machine learning to
                  automatically classify documents along a variety of
                  genre dimensions, and we have developed a graphical
                  interface that depicts documents visually along
                  orthogonal genre dimensions. In order to validate
                  the design of our interface, we have performed two
                  experiments---a brainstorming session and a
                  web-based survey---which have shown that users
                  perceive genre dimensions as independent. In the
                  present paper we elaborate in more detail the idea
                  behind the classifier and draw upon the possibility
                  of user `first glance' biases in assessment of web
                  documents."
)

@inproceedings(khoussainov-wi2003,
  author =	 "R. Khoussainov and N. Kushmerick",
  year =	 2003,
  title =	 "Performance management in competitive distributed
                  Web search",
  booktitle =	 "Proc. Int. Conf. Web Intelligence",
  acceptance =	 "23%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/khoussainov-wi2003.pdf",
  topic =	 "machine learning; Web search",
  abstract =	 "Distributed heterogeneous search environments are an
                  emerging phenomenon in Web search. They can be
                  viewed as a federation of independently controlled
                  metasearchers and many specialised search
                  engines. Specialised search engines provide focused
                  search services in a specific domain (e.g. a
                  particular topic). Metasearchers help to process
                  user queries effectively and efficiently by
                  distributing them only to the most suitable search
                  engines for each query. Compared to the traditional
                  search engines like Google or AltaVista, specialised
                  search engines (together) provide access to arguably
                  much larger volumes of high-quality information
                  resources, frequently called the `deep' or
                  `invisible' Web [10]. We envisage that such
                  heterogeneous environments will become more popular
                  and influential."
)

@inproceedings(finn-catss2003,
  author =	 "A. Finn and N. Kushmerick",
  year =	 2003,
  title =	 "Learning to classify documents according to genre",
  booktitle =	 "Proc. Workshop Computational Approaches to Text
                  Style and Synthesis",
  note =	 "Int. Joint Conf. Artificial Intelligence",
  acceptance =	 "77%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/finn-ijcai03-style.pdf",
  topic =	 "text analytics",
  abstract =	 "Genre or style analysis can be used to improve
                  results achieved using standard IR techniques. A
                  genre class is a group of documents that are written
                  in a similar style. Genre classification can
                  identify documents that are written in a style most
                  likely to satisfy a user’s information need. We
                  consider the use of Machine Learning techniques
                  applied to the task of automatic genre
                  classification. We investigate two sample genre
                  classification tasks: whether a news article is
                  subjective or objective; and whether a review is
                  positive or negative. We investigate the use of
                  three different feature-sets for building genre
                  classifiers. We argue that traditional methods of
                  evaluating text classifiers are insufficient for
                  genre classifiers and emphasize domain transfer for
                  the generated classifiers. Domain transfer indicates
                  the ability of a genre classifier to classify
                  documents that are about topics other than those it
                  was trained on. For both sample genre classification
                  tasks, we build classifiers that perform well within
                  a single topic domain. We also investigate and
                  evaluate the performance of these classifiers when
                  transferred to new subject domains. We describe a
                  method of combining evidence based on different
                  feature-sets. We show that an ensemble learner based
                  on different feature-sets improves performance for
                  genre classification. We further combine predictions
                  from different feature-sets to selectively sample
                  which documents to add to the training set and show
                  that this approach improves the learning rate of the
                  resulting genre classifier."
)

@inproceedings(hess-iiw2003,
  author =	 "A. He{\ss} and N. Kushmerick",
  year =	 2003,
  title =	 "Automatically attaching semantic metadata to web
                  services",
  booktitle =	 "Proc. Workshop Information Integration on the Web",
  note =	 "Int. Joint Conf. Artificial Intelligence",
  acceptance =	 "48%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/hess-ijcai03-iiw.pdf",
  topic =	 "corpus-based software engineering; machine learning;
                  semantic web; data integration",
  abstract =	 "Emerging Web standards promise a network of
                  heterogeneous yet interoperable Web Services. Web
                  Services would greatly simplify the development of
                  many kinds of data integration and knowledge
                  management applications. Unfortunately, this vision
                  requires that services provide large amounts of
                  semantic metadata `glue'. As a first step to
                  automatically generating such metadata, we describe
                  how machine learning and clustering techniques can
                  be used to attach attach semantic metadata to Web
                  forms and services."
)

@inproceedings(khoussainov-ecml2003,
  author =	 "R. Khoussainov and N. Kushmerick",
  year =	 2003,
  title =	 "Optimising Performance of Competing Search Engines
                  in Heterogeneous Web Environments",
  booktitle =	 "Proc. European Conf. Machine Learning",
  acceptance =	 "24%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/khoussainov-ecml2003.pdf",
  topic =	 "machine learning; Web search",
  abstract =	 "Distributed heterogeneous search environments are an
                  emerging phenomenon in Web search, in which
                  topic-specific search engines provide search
                  services, and metasearchers distribute user’s
                  queries to only the most suitable search
                  engines. Previous research has explored the
                  performance of such environments from the user’s
                  perspective (e.g., improved quality of search
                  results). We focus instead on performance from the
                  search service provider’s point of view (e.g, income
                  from queries processed vs. resources used to answer
                  them). We analyse a scenario in which individual
                  search engines compete for queries by choosing which
                  documents to index. We propose the COUGAR algorithm
                  that specialised search engines can use to decide
                  which documents to index on each particular
                  topic. COUGAR is based on a game-theoretic analysis
                  of heterogeneous search environments, and uses
                  reinforcement learning techniques to exploit the
                  sub-optimal behaviour of its competitors."
)

@inproceedings(khoussainov-ijcai2003,
  author =	 "R. Khoussainov and N. Kushmerick",
  year =	 2003,
  title =	 {Learning to compete in heterogeneous Web search
                  environments},
  booktitle =	 "Proc. Int. Joint Conf. Artificial Intelligence",
  note =	 "Poster",
  acceptance =	 "22%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/khoussainov-ijcai2003.pdf",
  topic =	 "machine learning; Web search",
  abstract =	 "Previous research in Web search has mainly targeted
                  performance of search engines from the user’s point
                  of view. Parameters such as precision, recall, and
                  freshness of returned results were optimised. On the
                  other hand, a provider of search services is rather
                  interested in parameters like the number of queries
                  processed versus the amount of resources used to
                  process them. We focus on performance optimisation
                  of search engines from the service provider’s point
                  of view."
)

@inproceedings(dimitrova-www20003,
  author =	 "M. Dimitrova and N. Kushmerick",
  year =	 2003,
  title =	 {Dimensions of Web genre},
  booktitle =	 "Proc. World Wide Web Conf.",
  note =	 "Poster",
  acceptance =	 "71%",
  html =
                  "http://www.smi.ucd.ie/nick/research/download/dimitrova-www2003",
  topic =	 "personalization; information retrieval",
  abstract =	 "Users assess the `appropriateness' of Web documents
                  in many ways. Traditionally, appropriateness has
                  been solely a matter of relevance to a particular
                  topic. But users are concerned with other aspects of
                  document `genre', such as the level of expertise
                  assumed by the author, or the amount of detail. In
                  previous work, we have used machine learning to
                  automatically classify documents along a variety of
                  genre dimensions, and we have developed a graphical
                  interface that depicts documents visually along
                  orthogonal genre dimensions. In order to validate
                  the design of our interface, we describe two
                  experiments that measure whether users perceive
                  genre dimensions independently."
)

@article(kushmerick-agentlink2003,
  author =	 "N. Kushmerick and B. Thomas",
  year =	 2003,
  title =	 {Adaptive information extraction: Core technologies
                  for information agents},
  journal =	 "Lecture Notes in Computer Science",
  note =	 {Intelligent information agents: The AgentLink
                  perspective; M. Klusch, S. Bergamaschi, P. Edwards
                  and P. Petta, editors},
  volume =	 2586,
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/kushmerick-agentlink-chapter-2003.pdf",
  topic =	 "text analytics; machine learning;
                  information extraction",
  abstract =	 "For the purposes of this chapter, an information
                  agent can be described as a distributed system that
                  receives a goal through its user interface, gathers
                  information relevant to this goal from a variety of
                  sources, processes this content as appropriate, and
                  delivers the results to the users. We focus on the
                  second stage in this generic architecture. We survey
                  a variety of information extraction techniques that
                  enable information agents to automatically gather
                  information from heterogeneous sources."
)

@inproceedings(toolan-mews2002,
  author =	 "F. Toolan and N. Kushmerick",
  year =	 2002,
  title =	 "Mining web logs for personalized site maps",
  booktitle =	 "Proc. Workshop Mining for Enhanced Web Search",
  note =	 "Int. Conf. Web Information Systems Engineering",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/toolan-mews2002.pdf",
  topic =	 "personalization; information retrieval",
  abstract =	 "Navigating through a large Web site can be a
                  frustrating exercise. Many sites employ Site Maps to
                  help visitors understand the overall structure of
                  the site. However, by their very nature,
                  unpersonalized Site Maps show most visitors large
                  amounts of irrelevant content. We propose techniques
                  based on Web usage mining to deliver Personalized
                  Site Maps that are specialized to the interests of
                  each individual visitor. The key challenge is to
                  resolve the tension between simplicity (showing just
                  relevant content), and comprehensibility (showing
                  sufficient context so that the visitors can
                  understand how the content is related to the overall
                  structure of the site). We develop two baseline
                  algorithms (one that displays just shortest paths,
                  and one that mines the server log for popular
                  paths), and compare them to a novel approach that
                  mines the server log for popular path fragments that
                  can be dynamically assembled to reconstruct popular
                  paths. Our experiments with two large Web sites
                  confirm that the mined path fragments provide much
                  better coverage of visitors sessions than the
                  baseline approach of mining entire paths."
)

@inproceedings(kushmerick-scie2002,
  author =	 "N. Kushmerick",
  year =	 2002,
  title =	 "Finite-state approaches to Web information
                  extraction",
  booktitle =	 "Proc. Summer Convention on Information Extraction",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/kushmerick-scie2002.pdf",
  topic =	 "text analytics; machine learning;
                  information extraction",
  abstract =	 "Information agents are emerging as an important
                  approach to building next-generation value-added
                  information services. An information agent is a
                  distributed system that receives a goal through its
                  user interface, gathers information relevant to this
                  goal from a variety of sources, processes this
                  content as appropriate, and delivers the results to
                  the users. We focus on the second stage in this
                  generic architecture. We survey a variety of
                  information extraction techniques that enable
                  information agents to automatically gather
                  information from heterogeneous sources."
)

@inproceedings(kushmerick-ecml2002,
  author =	 "N. Kushmerick",
  year =	 2002,
  title =	 "Robustness analyses of instance-based collaborative
                  recommendation",
  booktitle =	 "Proc. European Conf. Machine Learning",
  acceptance =	 "37%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/kushmerick-ecml2002.pdf",
  topic =	 "personalization; machine learning",
  abstract =	 "Collaborative recommendation has emerged as an
                  effective technique for a personalized information
                  access. However, there has been relatively little
                  theoretical analysis of the conditions under which
                  the technique is effective. We analyze the
                  robustness of collaborative recommendation: the
                  ability to make recommendations despite (possibly
                  intentional) noisy product ratings. We formalize
                  robustness in machine learning terms, develop two
                  theoretically justified models of robustness, and
                  evaluate the models on real-world data. Our
                  investigation is both practically relevant for
                  enterprises wondering whether collaborative
                  recommendation leaves their marketing operations
                  open to attack, and theoretically interesting for
                  the light it sheds on a comprehensive theory of
                  collaborative recommendation."
)

@inproceedings(mcgowan-ah2002,
  author =	 "J.-P. McGowan and N. Kushmerick and B. Smyth",
  year =	 2002,
  title =	 "Who do you want to be today? {W}eb Personae for
                  personalized information access",
  booktitle =	 "Proc. Int. Conf. Adaptive Hypermedia and Adaptive
                  Web-Based Systems",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/mcgowan-ah2002.pdf",
  topic =	 "personalization; information retrieval",
  abstract =	 "Personalised context sensitivity is the Holy Grail
                  of web information retrieval. As a first step
                  towards this goal, we present the Web Personae
                  personalised search and browsing system. We use
                  well-known information retrieval techniques to
                  develop and track user models. Web Personae differ
                  from previous approaches in that we model users with
                  multiple profiles, each corresponding to a distinct
                  topic or domain. Such functionality is essential in
                  heterogeneous environments such as the Web. We
                  introduce Web Personae, describe an algorithm for
                  learning such models from browsing data, and discuss
                  applications and evaluation methods."
)

@inproceedings(finn-ecir2002,
  author =	 "A. Finn and N. Kushmerick and B. Smyth",
  year =	 2002,
  title =	 "Genre classification and domain transfer for
                  information filtering",
  booktitle =	 "Proc. European Conf. Information Retrieval Research",
  psgz =
                  "http://www.smi.ucd.ie/nick/research/download/finn-ecir2002.ps.gz",
  topic =	 "text analytics",
  abstract =	 "The World Wide Web is a vast repository of
                  information, but the sheer volume makes it diffcult
                  to identify useful documents. We identify document
                  genre is an important factor in retrieving useful
                  documents and focus on the novel document genre
                  dimension of subjectivity. We investigate three
                  approaches to automatically classifying documents by
                  genre: traditional bag of words techniques,
                  part-of-speech statistics, and hand-crafted shallow
                  linguistic features. We are particularly interested
                  in domain transfer: how well the learned classifiers
                  generalize from the training corpus to a new
                  document corpus. Our experiments demonstrate that
                  the part-of-speech approach is better than
                  traditional bag of words techniques, particularly in
                  the domain transfer conditions."
)

@inproceedings(kushmerick-ssmatkw2002,
  author =	 "N. Kushmerick",
  year =	 2002,
  title =	 "Gleaning answers from the Web",
  booktitle =	 "Proc. Spring Syposium on Mining Answers from Texts
                  and Knowledge Bases",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/kushmerick-maftkb-ss02.pdf",
  topic =	 "text analytics; machine learning;
                  information extraction",
  abstract =	 "This position paper summarizes my recent and ongoing
                  research on Web information extraction and
                  retrieval. I describe: wrapper induction and
                  verification techniques for extracting data from
                  structured sources; boosted wrapper induction, an
                  extension of these techniques to handle natural
                  text; ELIXIR, our effcient and expressive language
                  for XML information retrieval; techniques and
                  applications for text genre classification; and
                  stochastic models for XML schema alignment. The
                  unifying theme of these various research projects is
                  to develop enabling technologies that facilitate the
                  rapid development of large Web services for data
                  access and integration."
)

@article(chinenyanga-jasist2002,
  author =	 "T. Chinenyanga and N. Kushmerick",
  year =	 2002,
  title =	 "An expressive and efficient language for {XML}
                  information retrieval",
  journal =	 "J. American Society for Information Science and
                  Technology",
  volume =	 53,
  number =	 6,
  pages =	 "438--453",
  note =	 "Special issue on XML and Information Retrieval",
  psgz =
                  "http://www.smi.ucd.ie/nick/research/download/chinenyanga-jasist02.ps.gz",
  topic =	 "information retrieval; data integration",
  abstract =	 "XML has emerged as a standard for the exchange of
                  structured data and documents. The database
                  community has proposed several languages for
                  querying and transforming XML, including XML-QL
                  [DFF+99a], Quilt [CRF00] and XQL [Rob99]. However,
                  these languages do not support ranked queries based
                  on textual similarity, in the spirit of traditional
                  information retrieval. Several attempts to extend
                  these XML query languages to support keyword search
                  have been made, but the resulting languages cannot
                  express information-retrieval-style queries such as
                  `find books and CDs with similar titles'. In some of
                  these languages keywords are used merely as boolean
                  filters without support for true ranked retrieval;
                  others permit similarity calculations only between a
                  data value and a constant, and thus cannot express
                  the above query. WHIRL [Coh98, Coh00] avoids both
                  problems, but assumes relational data. We propose
                  ELIXIR, an expressive and effcient language for XML
                  information retrieval that extends XML-QL with a
                  textual similarity operator. This operator can be
                  used for similarity joins, so ELIXIR is suffciently
                  expressive to handle the sample query above. ELIXIR
                  thus qualities as a general-purpose XML information
                  retrieval query language. Our central contribution
                  is an effcient algorithm for answering ELIXIR
                  queries. The algorithm rewrites the original ELIXIR
                  query into a series of XML-QL queries that generate
                  intermediate relational data, and uses WHIRL to
                  effciently evaluate the similarity operators on this
                  intermediate data, yielding an XML document with
                  nodes ranked by similarity. Our experiments
                  demonstrate that our prototype scales well with the
                  size of the query and the XML data."
)

@inproceedings(moriarty-prsdl2001,
  author =	 "C. Moriarty and N. Kushmerick and B. Smyth",
  year =	 2001,
  title =	 "Personalised intelligent tutoring for digital
                  libraries",
  booktitle =	 "Proc. Joint DELOS-NSF Workshop Personalisation
                  and Recommender Systems in Digital Libraries",
  acceptance =	 "64%",
  psgz =
                  "http://www.smi.ucd.ie/nick/research/download/moriarty-nsfdelosdiglib01.ps.gz",
  topic =	 "personalization",
  abstract =	 "Computer-based training is a fast-growing
                  multi-billion dollar industry. The possibilities for
                  systems that offer personalised training or
                  tutoring, that dynamically adapt to the training
                  needs of individual students, are immense. This not
                  only means the personalisation of training content
                  but perhaps even the personalisation of exams and
                  student evaluations. In this paper we focus on ways
                  of personalising multiple-choice exams and describe
                  a technique for predicting the exam answers for
                  individual students based on their previous exam
                  history. We describe an evaluation of a
                  collaborative filtering prediction system and
                  demonstrate that accurate predictions can be
                  achieved with limited profiling information."
)

@inproceedings(finn-prsdl2001,
  author =	 "A. Finn and N. Kushmerick and B. Smyth",
  year =	 2001,
  title =	 {Fact or fiction: Content classification for digital
                  libraries},
  booktitle =	 "Proc. Joint DELOS-NSF Workshop Personalisation and
                  Recommender Systems in Digital Libraries",
  acceptance =	 "64%",
  psgz =
                  "http://www.smi.ucd.ie/nick/research/download/finn-nsfdelosdiglib01.ps.gz",
  topic =	 "text analytics; machine learning",
  abstract =	 "The World-Wide Web (WWW) is a vast repository of
                  information, much of which is valuable but very
                  often hidden to the user. The anarchic nature of the
                  WWW presents unique challenges when it comes to
                  information extraction and categorization. We view
                  the WWW as a valuable resource for the gathering of
                  information for Digital Libraries. In this paper we
                  will describe the process of extracting and
                  classifying information from the WWW for the purpose
                  of integrating it into digital libraries. Our
                  efforts focus on ways to automatically classify news
                  articles according to whether they present opinions
                  or reported facts. We describe and evaluate a system
                  in development that automatically classifies and
                  recommends Web news articles from sports and
                  politics domains."
)

@proceedings(ciravegna-atem2001,
  editor =	 "F. Ciravegna and N. Kushmerick and R. Mooney and
                  I. Muslea",
  year =	 2001,
  title =	 "Proc. Workshop Adaptive Text Extraction and Mining",
  note =	 "Int. Joint Conf. Artificial Intelligence",
  html =	 "http://www.smi.ucd.ie/ATEM2001/proceedings/toc.html",
  topic =	 "text analytics; machine learning;
                  information extraction"
)

@inproceedings(chinenyanga-sigir2001,
  author =	 "T. Chinenyanga and N. Kushmerick",
  year =	 2001,
  title =	 {Expressive retrieval from {XML} documents},
  booktitle =	 "Proc. Int. Conf. Research and Development in
                  Information Retrieval",
  acceptance =	 "23%",
  psgz =
                  "http://www.smi.ucd.ie/nick/research/download/chinenyanga-sigir2001.ps.gz",
  topic =	 "information retrieval; data integration",
  abstract =	 "The emergence of XML as a standard interchange
                  format for structured documents/data has given rise
                  to many XML query language proposals. However, some
                  of these languages do not support information
                  retrieval-style ranked queries based on textual
                  similarity. There have been several extensions to
                  these query languages to support keyword search, but
                  the resulting query languages cannot express queries
                  such as `find books and CDs with similar
                  titles'. Either these extensions use keywords as
                  mere boolean filters, or similarities can be
                  calculated only between data values and constants
                  rather than two data values. We propose ELIXIR, an
                  expressive and effcient language for XML information
                  retrieval that extends the query language XML-QL [6,
                  7] with a textual similarity operator. ELIXIR is a
                  general-purpose XML information retrieval language,
                  suffciently ex- pressive to handle the above
                  query. Our algorithm for answering ELIXIR queries
                  rewrites the original ELIXIR query into a series of
                  XML-QL queries that generate intermediate relational
                  data, and uses relational database techniques to
                  effciently evaluate the similarity operators on this
                  intermediate data, yielding an XML document with
                  nodes ranked by similarity. Our experiments
                  demonstrate that our prototype scales well with the
                  size of the XML data and complexity of the query."
)

@inproceedings(kushmerick-atem2001,
  author =	 "N. Kushmerick and E. Johnston and S. McGuinness",
  year =	 2001,
  title =	 "Information extraction by text classification",
  booktitle =	 "Proc. Workshop Adaptive Text Extraction and
                  Mining",
  note =	 "Int. Joint Conf. Artificial Intelligence",
  acceptance =	 "67%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/kushmerick-atem2001.pdf",
  topic =	 "text analytics; machine learning;
                  information extraction; intelligent email",
  abstract =	 "Information extraction and text classification are
                  usually seen as complementary forms of shallow text
                  processing, in that they are aimed at very different
                  tasks. In this paper, we describe two simple but
                  real-world domains in which text classification
                  techniques can be used directly for information
                  extraction. Specifically, we describe systems for
                  extracting information from business cards, and for
                  automatically processing `change of address' email
                  messages, that are based primarily on text
                  classiffication techniques. Our main technical
                  contribution is a novel integration of hidden Markov
                  models and text classiffiers."
)

@inproceedings(chinanyanga-webdb2001,
  author =	 "T. Chinenyanga and N. Kushmerick",
  year =	 2001,
  title =	 "Expressive and efficient ranked querying of {XML}
                  data",
  booktitle =	 "Proc. Workshop Web and Databases",
  note =	 "Conf. Management of Data",
  acceptance =	 "28%",
  psgz =
                  "http://www.smi.ucd.ie/nick/research/download/chinenyanga-webdb2001.ps.gz",
  topic =	 "information retrieval; data integration",
  abstract =	 "Several XML query languages have been developed, but
                  none support ranked/weighted query results based on
                  textual similarity. We propose ELIXIR, a
                  general-purpose language for XML information
                  retrieval that extends Deutsch et al's XML-QL
                  language with a textual similarity operator. Unlike
                  related efforts, ELIXIR is sufficiently expressive
                  to handle queries such as `find books and CDs with
                  similar titles' that require similarity joins. Our
                  query processing algorithm rewrites an ELIXIR query
                  into a series of XML-QL queries that generate
                  intermediate relational data, and then invokes
                  Cohen's WHIRL algorithm to efficiently evaluate the
                  similarity operators on this intermediate data,
                  yielding an XML document with nodes ranked by
                  similarity."
)

@inproceedings(chinanyanga-www2001,
  author =	 "T. Chinenyanga and N. Kushmerick",
  year =	 2001,
  title =	 "Expressive and efficient ranked querying of {XML}
                  data",
  booktitle =	 "Proc. World Wide Web Conf.",
  note =	 "Poster",
  acceptance =	 "20%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/chinenyanga-www10.pdf",
  topic =	 "information retrieval; data integration"
)

@misc(kushmerick-patent2001,
  author =	 "N. Kushmerick and D. Weld and R. Doorenbos",
  year =	 2001,
  title =	 "Method and apparatus of automatically generating a
                  procedure for extracting information from textual
                  information sources",
  note =	 "United States Patent US6,304,870",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/US06304870.pdf",
  html =
                  "http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=/netahtml/search-bool.html&r=1&f=G&l=50&co1=AND&d=ptxt&s1=Kushmerick.INZZ.&OS=IN/Kushmerick&RS=IN/Kushmerick",
  topic =	 "information extraction; machine learning; data
                  integration",
  abstract =	 "A procedure is disclosed for automatically
                  constructing wrappers for performing
                  information-extraction from sites such as Internet
                  resources that display relevant information,
                  interspersed with extraneous text fragments, such as
                  HTML formatting commands or advertisements. The
                  procedure has three basic steps. First, a set of
                  example pages are collected with a subroutine named
                  GatherExamples. GatherExamples is provided with
                  information describing how to pose example queries
                  to the site whose wrapper is to be learned. Second,
                  these example pages are labeled by a subroutine
                  named LabelExamples---i.e., the information to be
                  extracted from each example is identified for use in
                  the third step. The LabelExamples subroutine uses a
                  general framework for labeling pages using
                  site-specific heuristics called recognizers, as well
                  as allowing users to correct and modify the
                  recognized instances. Finally, the labeled example
                  pages are passed to a BuildWrapper subroutine, which
                  constructs a wrapper."
)

@article(kushmerick-wwwj2000,
  author =	 "N. Kushmerick",
  year =	 2000,
  title =	 "Wrapper verification",
  journal =	 "World Wide Web J.",
  volume =	 3,
  number =	 2,
  pages =	 "79--94",
  note =	 "Special issue on Web Data Management",
  psgz =
                  "http://www.smi.ucd.ie/nick/research/download/kushmerick-wwwj2000.ps.gz",
  topic =	 "information extraction; machine learning; data
                  integration",
  abstract =	 "Many Internet information­management applications
                  (e.g., information integration systems) require a
                  library of wrappers, specialized information
                  extraction procedures that translate a source's
                  native format into a structured representation
                  suitable for further application­specific
                  processing. Maintaining wrappers is tedious and
                  error­prone, because the formatting regularities on
                  which wrappers rely change frequently on the
                  decentralized and dynamic Internet. The wrapper
                  verification problem is to determine whether a
                  wrapper is operating correctly. Standard regression
                  testing approaches are inappropriate, because both
                  the formatting regularities on which wrappers rely,
                  and the source's underlying content, may change. We
                  introduce RAPTURE, a fully­implemented,
                  domain­independent wrapper verification
                  algorithm. RAPTURE computes a probabilistic
                  similarity measure between a wrapper's expected and
                  observed output, where similarity is defined in
                  terms of simple numeric features (e.g., the length,
                  or the fraction of punctuation characters) of the
                  extracted strings. Experiments with numerous actual
                  Internet sources demostrate that RAPTURE performs
                  substantially better than standard regression
                  testing."
)

@inproceedings(freitag-aaai2000,
  author =	 "D. Freitag and N. Kushmerick",
  year =	 2000,
  title =	 "Boosted wrapper induction",
  booktitle =	 "Proc. American Nat. Conf. Artificial Intelligence",
  acceptance =	 "33%",
  psgz =
                  "http://www.smi.ucd.ie/nick/research/download/freitag-aaai2000.ps.gz",
  topic =	 "text analytics; information
                  extraction; machine learning",
  abstract =	 "Recent work in machine learning for information
                  extraction has focused on two distinct sub-problems:
                  the conventional problem of filling template slots
                  from natural language text, and the problem of
                  wrapper induction, learning simple extraction
                  procedures (`wrappers') for highly structured text
                  such as Web pages produced by CGI scripts. For
                  suitably regular domains, existing wrapper induction
                  algorithms can effciently learn wrappers that are
                  simple and highly accurate, but the regularity bias
                  of these algorithms makes them unsuitable for most
                  conventional information extraction tasks. Boosting
                  is a technique for improving the performance of a
                  simple machine learning algorithm by repeatedly
                  applying it to the training set with different
                  example weightings. We describe an algorithm that
                  learns simple, low-coverage wrapper-like extraction
                  patterns, which we then apply to conventional
                  information extraction problems using boosting. The
                  result is BWI, a trainable information extraction
                  system with a strong precision bias and F1
                  performance better than state-of-the-art techniques
                  in many domains."
)

@article(kushmerick-aij2000,
  author =	 "N. Kushmerick",
  year =	 2000,
  title =	 {Wrapper induction: Efficiency and expressiveness},
  journal =	 "Artificial Intelligence",
  volume =	 118,
  number =	 "1--2",
  pages =	 "15--68",
  note =	 "Special issue on Intelligent Internet Systems",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/kushmerick-aij2000.pdf",
  topic =	 "information extraction; machine learning; data
                  integration",
  abstract =	 "The Internet presents numerous sources of useful
                  information---telephone directories, product
                  catalogs, stock quotes, event listings,
                  etc. Recently, many systems have been built that
                  automatically gather and manipulate such information
                  on a user’s behalf. However, these resources are
                  usually formatted for use by people (e.g., the
                  relevant content is embedded in HTML pages), so
                  extracting their content is difficult. Most systems
                  use customized wrapper procedures to perform this
                  extraction task. Unfortunately, writing wrappers is
                  tedious and error-prone. As an alternative, we
                  advocate wrapper induction, a technique for
                  automatically constructing wrappers. In this
                  article, we describe six wrapper classes, and use a
                  combination of empirical and analytical techniques
                  to evaluate the computational tradeoffs among
                  them. We first consider expressiveness: how well the
                  classes can handle actual Internet resources, and
                  the extent to which wrappers in one class can mimic
                  those in another. We then turn to efficiency: we
                  measure the number of examples and time required to
                  learn wrappers in each class, and we compare these
                  results to PAC models of our task and asymptotic
                  complexity analyses of our algorithms. Summarizing
                  our results, we find that most of our wrapper
                  classes are reasonably useful (70% of surveyed sites
                  can be handled in total), yet can rapidly learned
                  (learning usually requires just a handful of
                  examples and a fraction of a CPU second per
                  example)."
)

@inproceedings(kushmerick-ah2000,
  author =	 "N. Kushmerick and J. McKee and F. Toolan",
  year =	 2000,
  title =	 "Toward zero-input personalization: Referrer-based
                  page recommendation",
  booktitle =	 "Proc. Int. Conf. Adaptive Hypermedia and Adaptive
                  Web-Based Systems",
  acceptance =	 "42%",
  psgz =
                  "http://www.smi.ucd.ie/nick/research/download/kushmerick-ah2000.ps.gz",
  topic =	 "personalization; information retrieval",
  abstract =	 "Most web services take a ``one size fits all''
                  approach: all visitors see the same generic content,
                  formatted in the same generic manner. But of course
                  each visitor has her own information needs and
                  preferences. In contrast to most personalization
                  systems, we are interested in how effective
                  personalization can be with zero additional user
                  input or feedback. This paper describes PWW, an
                  extensible suite of tools for personalizing web
                  sites, and introduces RBPR, a novel zero­input
                  recommendation technique. RBPR uses information
                  about a visitor's browsing context (specifically,
                  the referrer URL provided by HTTP) to suggest pages
                  that might be relevant to the visitor's underlying
                  information need. Empirical results for an actual
                  web site demonstrate that RBPR makes useful
                  suggestions even though it places no additional
                  burden on web visitors."
)

@inproceedings(kushmerick-www2000,
  author =	 "N. Kushmerick and J. McKee and F. Toolan",
  year =	 2000,
  title =	 "Toward zero-input personalization: Referrer-based
                  page recommendation",
  booktitle =	 "Proc. World Wide Web Conf.",
  note =	 "Poster",
  html =
                  "http://www.smi.ucd.ie/nick/research/download/kushmerick-www9/poster",
  topic =	 "personalization; information retrieval"
)

@article(kushmerick-cilc2000,
  author =	 "N. Kushmerick",
  year =	 2000,
  title =	 "Wrapping up the web",
  journal =	 "Synergy",
  volume =	 2,
  html =
                  "http://www.dcs.napier.ac.uk/coil/news/feature46.html",
  topic =	 "information extraction; machine learning; data
                  integration",
)

@article(fensel-aimag2000,
  author =	 "D. Fensel and C. Knoblock and N. Kushmerick and
                  M.-C. Rousset",
  year =	 2000,
  title =	 "Workshop Intelligent Information Integration",
  journal =	 "AI Magazine",
  volume =	 21,
  number =	 1,
  pages =	 "91--94",
  pdf =
                  "http://www.aaai.org/Library/Magazine/Vol21/21-01/Papers/AIMag21-01-013.pdf",
  topic =	 "data integration",
)

@inproceedings(kushmerick-aaai1999,
  author =	 "N. Kushmerick",
  year =	 1999,
  title =	 "Regression testing for wrapper maintenance",
  booktitle =	 "Proc. American Nat. Conf. Artificial Intelligence",
  acceptance =	 "27%",
  psgz =
                  "http://www.smi.ucd.ie/nick/research/download/kushmerick-aaai99.ps.gz",
  topic =	 "information extraction; machine learning; data
                  integration",
  abstract =	 "Most web services take a ``one size fits all''
                  approach: all visitors see the same generic content,
                  formatted in the same generic manner. But of course
                  each visitor has her own information needs and
                  preferences. In contrast to most personalization
                  systems, we are interested in how effective
                  personalization can be with zero additional user
                  input or feedback. This paper describes PWW, an
                  extensible suite of tools for personalizing web
                  sites, and introduces RBPR, a novel zero­input
                  recommendation technique. RBPR uses information
                  about a visitor's browsing context (specifically,
                  the referrer URL provided by HTTP) to suggest pages
                  that might be relevant to the visitor's underlying
                  information need. Empirical results for an actual
                  web site demonstrate that RBPR makes useful
                  suggestions even though it places no additional
                  burden on web visitors."
)

@inproceedings(kushmerick-agents1999,
  author =	 "N. Kushmerick",
  year =	 1999,
  title =	 "Learning to remove Internet advertisements",
  booktitle =	 "Proc. Int. Conf. Autonomous Agents",
  acceptance =	 "29%",
  psgz =
                  "http://www.smi.ucd.ie/nick/research/download/kushmerick-aa99.ps.gz",
  topic =	 "machine learning",
  abstract =	 "AdEater is a fully implemented browsing assistant
                  that automatically removes advertisement images from
                  Internet pages. Unlike related systems that rely on
                  hand­crafted rules, AdEater takes an inductive
                  learning approach, automatically generating rules
                  from training examples. Our experiments demonstrate
                  that our approach is practical: the off­line
                  training phase takes less than six minutes; on­line
                  classification takes about 70 msec; and
                  classification accuracy exceeds 97% given a modest
                  set of training data."
)

@article(kushmerick-ieeeis1999,
  author =	 "N. Kushmerick",
  year =	 1999,
  title =	 "Gleaning the Web",
  journal =	 "IEEE Intelligent Systems",
  volume =	 14,
  number =	 2,
  pages =	 "20--22",
  note =	 "Special issue on Intelligent Agents",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/kushmerick-ieeeis99.pdf",
  topic =	 "information extraction; machine learning; data
                  integration"
)

@proceedings(califf-mlie1999,
  editor =	 "M.-E. Califf and D. Freitag and N. Kushmerick and
                  I. Muslea",
  year =	 1999,
  title =	 "Proc. Workshop Machine Learning for Information
                  Extraction",
  note =	 "American Nat. Conf. Artificial Intelligence",
  html =	 "http://www.isi.edu/info-agents/RISE/ML4IE/",
  topic =	 "information extraction; machine learning; natural
                  language engineering"
)

@proceedings(fensel-iii1999,
  editor =	 "D. Fensel and C. Knoblock and N. Kushmerick and
                  M.-C. Rousset",
  year =	 1999,
  title =	 "Proc. Workshop Intelligent Information
                  Integration",
  note =	 "Int. Joint Conf. Atificial Intelligence; CEUR
                  Workshop Proceedings (volume 23)",
  html =
                  "http://SunSITE.Informatik.RWTH-Aachen.DE/Publications/CEUR-WS/Vol-23/",
  topic =	 "data integration"
)

@proceedings(levy-aiii1998,
  editor =	 "A. Levy and C. Knoblock and O. Duschka and
                  D. Florescu and N. Kushmerick",
  year =	 1998,
  title =	 "Proc. Workshop AI and Information Integration",
  note =	 "American Nat. Conf. Artificial Intelligence",
  html =
                  "http://www.isi.edu/ariadne/aiii98-wkshp/proceedings.html",
  topic =	 "data integration"
)

@inproceedings(kushmerick-aiii1998-wr,
  author =	 "N. Kushmerick",
  year =	 1998,
  title =	 "(Towards) an extensible wrapper repository standard",
  booktitle =	 "Proc. Workshop AI and Information Integration",
  note =	 "American Nat. Conf. Artificial Intelligence",
  psgz =
                  "http://www.smi.ucd.ie/nick/research/download/kushmerick-aaai98-aiii-panel.ps.gz",
  topic =	 "data integration"
)

@inproceedings(kushmerick-aiii1998-wi,
  author =	 "N. Kushmerick",
  year =	 1998,
  title =	 "Wrapper induction: Efficiency and expressiveness
                  (Extended abstract)",
  booktitle =	 "Proc. Workshop AI and Information Integration",
  note =	 "American Nat. Conf. Artificial Intelligence",
  psgz =
                  "http://www.smi.ucd.ie/nick/research/download/kushmerick-aaai98-aiii.ps.gz",
  topic =	 "information extraction; machine learning; data
                  integration",
  abstract =	 "Recently, many systems have been built that
                  automatically interact with Internet information
                  resources. However, these resources are usually
                  formatted for use by people; e.g., the relevant
                  content is embedded in HTML pages. Wrappers are
                  often used to extract a resource's content, but
                  hand­coding wrappers is tedious and error­prone. We
                  advocate wrapper induction, a technique for
                  automatically constructing wrappers. We have
                  identified several wrapper classes that can be
                  learned quickly (most sites require only a handful
                  of examples, consuming a few CPU seconds of
                  processing), yet which are useful for handling
                  numerous Internet resources (70% of surveyed sites
                  can be handled by our techniques)."
)

@inproceedings(kushmerick-stda1998,
  author =	 "N. Kushmerick and B. Grace",
  year =	 1998,
  title =	 "The Wrapper Induction Environment",
  booktitle =	 "Proc. Workshop Software Tools for Developing Agents",
  note =	 "American Nat. Conf. Artificial Intelligence",
  psgz =
                  "http://www.smi.ucd.ie/nick/research/download/kushmerick-aaai98-stda.ps.gz",
  topic =	 "information extraction; machine learning; data
                  integration",
  abstract =	 "There is much interest in systems that automatically
                  interact with Internet information sites. Such
                  systems are hard to build, partly because they use
                  hand­crafted wrappers to extract a site's
                  content. We advocate wrapper induction, a technique
                  for automatically learning wrappers. Our wrapper
                  induction environment (WIEN) enables users to
                  quickly capture a set of example page; our wrapper
                  learning algorithm then handles the low­level
                  details of constructing the wrapper."
)

@phdthesis(kushmerick-phd1997,
  author =	 "N. Kushmerick",
  year =	 1997,
  title =	 "Wrapper induction for information extraction",
  school =	 "University of Washington",
  note =	 "Department of Computer Science and Engineering",
  psgz =
                  "http://www.smi.ucd.ie/nick/research/download/kushmerick-phd.ps.gz",
  topic =	 "information extraction; machine learning; data
                  integration",
  abstract =	 "The Internet presents numerous sources of useful
                  information---telephone directories, product
                  catalogs, stock quotes, weather forecasts,
                  etc. Recently, many systems have been built that
                  automatically gather and manipulate such information
                  on a user's behalf. However, these resources are
                  usually formatted for use by people (e.g., the
                  relevant content is embedded in HTML pages), so
                  extracting their content is difficult. Wrappers are
                  often used for this purpose. A wrapper is a
                  procedure for extracting a particular resource's
                  content. Unfortunately, hand­coding wrappers is
                  tedious. We introduce wrapper induction, a technique
                  for automatically constructing wrappers. Our
                  techniques can be described in terms of three main
                  contributions. First, we pose the problem of wrapper
                  construction as one of inductive learning . Our
                  algorithm learns a resource's wrapper by reasoning
                  about a sample of the resource's pages. In our
                  formulation of the learning problem, instances
                  correspond to the resource's pages, a page's label
                  corresponds to its relevant content, and hypotheses
                  correspond to wrappers. Second, we identify several
                  classes of wrappers which are reasonably useful, yet
                  efficiently learnable. To assess usefulness, we
                  measured the fraction of Internet resources that can
                  be handled by our techniques. We find that our
                  system can learn wrappers for 70% of the surveyed
                  sites. Learnability is assessed by the asymptotic
                  complexity of our system's running time; most of our
                  wrapper classes can be learned in time that grows as
                  a small­degree polynomial. Third, we describe
                  noise­tolerant techniques for automatically labeling
                  the examples. Our system takes as input a library of
                  recognizers, domain­specific heuristics for
                  identifying a page's content. We have developed an
                  algorithm for automatically corroborating the
                  recognizer's evidence. Our algorithm perform well,
                  even when the recognizers exhibit high levels of
                  noise. Our learning algorithm has been fully
                  implemented. We have evaluated our system both
                  analytically (with the PAC learning model) and
                  empirically. Our system requires 2 to 44 examples
                  for effective learning, and takes about ten seconds
                  of CPU time for most sites. We conclude that wrapper
                  induction is a feasible solution to the scaling
                  problems inherent in the use of wrappers by
                  information­integration systems."
)

@inproceedings(kushmerick-ijcai1997,
  author =	 "N. Kushmerick and D. Weld and B. Doorenbos",
  year =	 1997,
  title =	 "Wrapper induction for information extraction",
  booktitle =	 "Proc. Int. Joint Conf. Artificial Intelligence",
  acceptance =	 "24%",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/kushmerick-ijcai97.pdf",
  topic =	 "information extraction; machine learning; data
                  integration",
  abstract =	 "Many Internet information resources present
                  relational data---telephone directories, product
                  catalogs, etc. Because these sites are formatted for
                  people, mechanically extracting their content is
                  difficult. Systems using such resources typically
                  use hand-coded wrappers, procedures to extract data
                  from information resources. We introduce wrapper
                  induction, a method for automatically constructing
                  wrappers, and identify HLRT, a wrapper class that is
                  efficiently learnable, yet expressive enough to
                  handle 48% of a recently surveyed sample of Internet
                  resources. We use PAC analysis to bound the
                  problem's sample complexity, and show that the
                  system degrades gracefully with imperfect labeling
                  knowledge."
)

@article(kushmerick-jmm1997,
  author =	 "N. Kushmerick",
  year =	 1997,
  title =	 "Software agents and their bodies",
  journal =	 "J. Minds and Machines",
  volume =	 7,
  number =	 2,
  pages =	 "227--47",
  psgz =
                  "http://www.smi.ucd.ie/nick/research/download/kushmerick-mm97.ps.gz",
  topic =	 "foundations of artificial intelligence",
  abstract =	 "Within artificial intelligence and the philosophy of
                  mind, there is considerable disagreement over the
                  relationship between an agent's body and its
                  capacity for intelligent behavior. Some treat the
                  body as peripheral and tangential to intelligence;
                  others argue that embodiment and intelligence are
                  inextricably linked. Software agents---computer
                  programs that interact with software environments
                  such the Internet---provide an ideal context in
                  which to study this tension. I develop a
                  computational framework for analyzing
                  embodiment. The framework generalizes the notion of
                  a body beyond merely having a physical presence. My
                  analysis sheds light on certain claims made about
                  the relevance of the body to intelligence, as well
                  as on embodiment in software worlds."
)

@article(jirousek-jmi1997,
  author =	 "R. Jirou\v{s}ek and N. Kushmerick",
  year =	 1997,
  title =	 "Constructing probabilistic models",
  journal =	 "Int. J. Medical Informatics",
  volume =	 45,
  number =	 "1--2",
  pages =	 "9--18",
  psgz =
                  "http://www.smi.ucd.ie/nick/research/download/jirousek-jmi97.ps.gz",
  topic =	 "probabilistic reasoning",
  abstract =	 "Bayesian networks have become one of the most
                  popular probabilistic techniques in AI, largely due
                  to the development of several efficient inference
                  algorithms. In this paper we describe a heuristic
                  method for constructing Bayesian networks. Our
                  construction method relies on the relationship
                  between Bayesian networks and decomposable models, a
                  special kind of graphical model. We explain this
                  relationship and then show how it can be used to
                  facilitate model construction. Finally, we describe
                  an implemented computer program that illustrates
                  these ideas."
)

@article(kushmerick-cjai1996,
  author =	 "N. Kushmerick",
  year =	 1996,
  title =	 "Situated action and cognitivism: Two views on
                  intelligent agency",
  journal =	 "J. Computers and Artificial Intelligence",
  volume =	 15,
  number =	 5,
  pages =	 "393-417",
  psgz =
                  "http://www.smi.ucd.ie/nick/research/download/kushmerick-cai96.ps.gz",
  topic =	 "foundations of artificial intelligence",
  abstract =	 "Classical approaches to artificial intelligence have
                  in recent years been challenged by several
                  alternative approaches. This review article focuses
                  on one such alternative, which has come to be called
                  `Situated Action' (SA). I analyze recent research
                  allied with this alternative approach, and identify
                  five major themes that distinguish SA from more
                  traditional research. I conclude that though much
                  additional work is needed in order to fully
                  elaborate the SA conception of intelligence and
                  agency, Situated Action does indeed suggest a number
                  of novel research directions, as well as provide
                  important accounts of some aspects of agency that
                  are problematic from the classical perspective."
)

@article(kushmerick-aij1995,
  author =	 "N. Kushmerick and S. Hanks and D. Weld",
  year =	 1995,
  title =	 "An algorithm for probabilistic planning",
  journal =	 "Artificial Intelligence",
  volume =	 76,
  number =	 "1--2",
  pages =	 "239--286",
  note =	 "Special issue on Planning and Scheduling",
  psgz =
                  "http://www.smi.ucd.ie/nick/research/download/kushmerick-aij95.ps.gz",
  topic =	 "planning; probabilistic reasoning",
  abstract =	 "We define the probabilistic planning problem in
                  terms of a probability distribution over initial
                  world states, a boolean combination of propositions
                  representing the goal, a probability threshold, and
                  actions whose effects depend on the execution-time
                  state of the world and on random chance. Adopting a
                  probabilistic model complicates the definition of
                  plan success: instead of demanding a plan that
                  provably achieves the goal, we seek plans whose
                  probability of success exceeds the threshold. In
                  this paper, we present BURIDAN, an implemented
                  least-commitment planner that solves problems of
                  this form. We prove that the algorithm is both sound
                  and complete. We then explore BURIDAN's efficiency
                  by contrasting four algorithms for plan evaluation,
                  using a combination of analytic methods and
                  empirical experiments. We also describe the
                  interplay between generating plans and evaluating
                  them, and discuss the role of search control in
                  probabilistic planning. "
)

@inproceedings(kushmerick-aaai1994,
  author =	 "N. Kushmerick and S. Hanks and D. Weld",
  year =	 1994,
  title =	 "An algorithm for probabilistic least-commitment
                  planning",
  booktitle =	 "Proc. American Nat. Conf. Artificial Intelligence",
  acceptance =	 "22%",
  psgz =
                  "http://www.smi.ucd.ie/nick/research/download/kushmerick-aaai94.ps.gz",
  topic =	 "planning; probabilistic reasoning",
  abstract =	 "We define the probabilistic planning problem in
                  terms of a probability distribution over initial
                  world states, a boolean combination of goal
                  propositions, a probability threshold, and actions
                  whose effects depend on the execution­time state of
                  the world and on random chance. Adopting a
                  probabilistic model complicates the definition of
                  plan success: instead of demanding a plan that
                  provably achieves the goal, we seek plans whose
                  probability of success exceeds the threshold. This
                  paper describes a probabilistic semantics for
                  planning under uncertainty, and presents a fully
                  implemented algorithm that generates plans that
                  succeed with probability no less than a
                  user­supplied probability threshold. The algorithm
                  is sound (if it terminates then the generated plan
                  is sufficiently likely to achieve the goal) and
                  complete (the algorithm will generate a solution if
                  one exists)."
)

@inproceedings(kushmerick-aaai1994-poster,
  author =	 "N. Kushmerick",
  year =	 1994,
  title =	 {Exploiting the environment: Urban navigation as a
                  case study},
  booktitle =	 "Proc. American Nat. Conf. Artificial Intelligence",
  Note =	 "Student abstract",
  psgz =
                  "http://www.smi.ucd.ie/nick/research/download/kushmerick-navigation-aaai94.ps.gz",
  topic =	 "planning",
  abstract =	 "The Situated Action approach to AI emphasizes the
                  role of the environment in the generation and
                  control of behavior; see (Norman 1993) for an
                  introduction. Work to date has focused mainly on
                  activity within spatially and temporally localized
                  environments such as kitchens and video games. How
                  useful is this perspective when larger­scale
                  activities are considered? I attempt to answer this
                  question by considering some issues related to
                  navigation in urban environments."
)

@incollection(anderson-rotm1993a,
  title =	 "Navigation and conflict resolution",
  author =	 "J. Anderson and N. Kushmerick and C. Lebiere",
  chapter =	 "5",
  booktitle =	 "Rules of the mind",
  editor =	 "J. Anderson",
  year =	 1993,
  publisher =	 "Lawrence Erlbaum Associates",
  html =	 "http://act.psy.cmu.edu/ACT/papers/ROM.html",
  topic =	 "cognitive psychology"
)

@incollection(anderson-rotm1993b,
  title =	 {The {T}ower of {H}anoi and goal structures},
  author =	 "J. Anderson and N. Kushmerick and C. Lebiere",
  chapter =	 "6",
  booktitle =	 "Rules of the mind",
  editor =	 "J. Anderson",
  year =	 1993,
  publisher =	 "Lawrence Erlbaum Associates",
  html =	 "http://act.psy.cmu.edu/ACT/papers/ROM.html",
  topic =	 "cognitive psychology"
)

@inproceedings(kotovosky-cogsci1991,
  author =	 "K. Kotovsky and N. Kushmerick",
  year =	 1991,
  title =	 {Processing constraints and problem difficulty: A
                  model},
  booktitle =	 "Proc. Conf. Cognitive Science Society",
  pdf =
                  "http://www.smi.ucd.ie/nick/research/download/kotovsky-cogsci91.pdf",
  ps =
                  "http://www.smi.ucd.ie/nick/research/download/kotovsky-cogsci91.ps",
  topic =	 "cognitive psychology",
  abstract =	 "In this paper we examine the role played by working
                  memory demands in determining problem difficulty
                  during the solution of Tower of Hanoi Problem
                  isomorphs. We do so by describing a production
                  system model that accounts for subjects’ performance
                  on these problems via a dynamic analysis of the
                  memory load imposed by the problem and of changes in
                  that load during the problem solving episode. We
                  also present the results of detailed testing of the
                  model against human subject data. The model uses a
                  highly constrained working memory to account for a
                  number of features of the problem solving behavior,
                  including the dichotomous (exploratory and final
                  path) nature of the problem solving, the relative
                  difficulty of the problems, the particular moves
                  made in each state of the problem space, and the
                  temporal patterning of the final path moves."
)

@article(anderson-bps1990,
  author =	 "J. Anderson and N. Kushmerick",
  year =	 1990,
  title =	 "A rational analysis of production system
                  architecture",
  journal =	 "Bulletin of the Psychonomic Society",
  volume =	 28,
  number =	 6,
  pages =	 "509",
  topic =	 "cognitive psychology"
)
