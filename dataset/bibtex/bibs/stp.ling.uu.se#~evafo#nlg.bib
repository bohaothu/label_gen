%http://www.itri.brighton.ac.uk/projects/rags/rags.bib

%http://www.itri.brighton.ac.uk/~Donia.Scott/publications/lrec.ps.gz
%  date =	{}, % May 29 - June 2
@InProceedings{cahill;doran;evans;kibble;mellish;paiva;reape;scott;tipper:00,
  key =	{Cahill \& Doran \& Evans \& Kibble \& Mellish \& Paiva \& Reape \& Scott \& Tipper 2000},
  author = 	{Cahill, Lynn and Doran, Christy and Evans, Roger and Kibble, Rodger and Mellish, Chris and Paiva, Daniel and Reape, Mike and Scott, Donia and Tipper, Neil},
  title = 	{Enabling Resource Sharing in Generation: an Abstract Reference Architecture},
  booktitle = 	{Proceedings of the 2nd International Conference on Language Resources and Evaluation (LREC'00)},
  address =  {Athens, Greece},
  year =	{2000},
  month =	may,
  pages =	{155--159},
  url = 	{\url{http://www.itri.brighton.ac.uk/projects/rags/lrec-final.ps.gz}},
  last_access = {2003-07-16},
  storage = {Textgenerering},
  keywords = {NLG, RAGS},
  abstract = 	{The RAGS project aims to develop a reference architecture for natural language generation, to facilitate modular development of NLG systems as well as evaluation of components, systems and algorithms. This paper gives an overview of the proposed framework, describing an abstract data model with five levels of representation: Conceptual, Semantic, Rhetorical, Document and Syntactic. We report on a re-implementation of an existing system using the RAGS data model.}
}


%The proceedings of the workshop are published as a DFKI Document, D-99-01. It is available as hardcopy to be ordered from the DFKI library, or electronically as a gzipped tar file. Individual papers can be downloaded from the Workshop Schedule page. 
%Paper from conference proceedings: ``May I speak freely?'' Between templates and free choice in Natural Language Generation: What is the right NLG technology for my application? a workshop of the Special Interest Group 1.3.1 on Natural Language Systems of the Gesellschaft für Informatik e.V. ( Tilman Becker, Stephan Busemann, eds. ) [ September 13-15, 1999 ] 

@InProceedings{calder;evans;mellish;reape:99,
  key =	{Calder \& Evans \& Mellish \& Reape 1999},
  author = 	{Calder, Jo and Evans, Roger and Mellish, Chris and Reape, Mike},
  title = 	{\"Free Choice\" and Templates: How to Get Both at the Same Time},
  booktitle = 	{Proceedings of the workshop ``May I speak freely?'' Between templates and free choice in Natural Language Generation: What is the right NLG technology for my application?, held at the German Annual Conference on Artificial Intelligence, (KI-99)},
  editor =  {Becker, Tilman and Busemann, Stephan},
  address =  {Bonn, Germany},
  year =	{1999},
  month =	sep,
  date =	{13--15},
  pages =	{19--24},
  url = 	{\url{http://www.ltg.ed.ac.uk/papers/99jo_templates.ps}, \url{http://www.ltg.ed.ac.uk/papers/99jo_templates.pdf}},
  last_access = {2003-07-13},
  storage = {Textgenerering},
  keywords = {NLG, data structure, types},
  abstract = 	{This paper presents a procedurally neutral framework for representing the results and states of computations called the \textit{whiteboard}, developed in the context of an investigation of reference architectures for Natural Language Generation (NLG) systems. We show that whiteboards solve a number of data representation problems in NLG, in particular, how to characterize \textit{partial} and \textit{mixed} representations. With these in place, an approach to generalized \"canning\" --- by which we mean the generalisation of its use in \"canned text\" to any datatype --- becomes available which allows inclusion of arbitrary fixed and partial structures of any type which may themselves be realized by structures of other types. We use this mechanism to show that the \"free choice vs. templates debate\" is only a question of degree.}
}


%(1995???) http://www.rau.edu.uy/pedeciba/personas/coch.htm
%Centre de Recherche en Informatique de Nancy,France 
%  pages =	{},
@InProceedings{coch;wonsever:96,
  key =	{Coch \& Wonsever 1996},
  author = 	{Coch, José and Wonsever, Dina},
  title = 	{Improvement of an Algorithm for Planning and Generating Anaphora},
  booktitle = 	{Proceedings of the Second International Colloquium on Deixis: \"Time, Space and Identity\"},
  address =  {Nancy, France},
  year =	{1996},
  month =	mar,
  date =	{28--30},
  url = 	{\url{http://www.loria.fr/~romary/Deixis/PapersDeixis/JoseCoch.ps}},
  last_access = {2003-07-16},
  storage = {Textgenerering},
  keywords = {NLG, AlethGen, anaphora},
  abstract = 	{}
}


%  month =	 dec,
@InProceedings{elhadad:90,
  key =		 {Elhadad 1990},
  author = 	 {Elhadad, Michael},
  title = 	 {Types in Functional Unification Grammars},
  booktitle = {Proceedings of the 28th Meeting of Association for Computational Linguistics (ACL'90)},
  address =  {Pittsburgh, PA, USA},
  year =	 {1990},
  pages =	 {157--164},
  url =	 {\url{http://www.cs.bgu.ac.il/~elhadad/papers/acl90.ps.gz}, \url{http://www.cs.bgu.ac.il/~elhadad/papers/acl90.pdf}},
  last_access = {2003-07-12},
  storage = {Textgenerering},
  keywords = {unification, FUGs, types, NLG},
  abstract =	 {Functional Unification Grammars (FUGs) are popular for natural language applications because the formalism uses very few primitives and is uniform and expressive. In our work on text generation, we have found that it also has annoying limitations: it is not suited for the expression of simple, yet very common, taxonomic relations and it does not allow the specification of completeness conditions. We have implemented an extension of traditional functional unification. This extension addresses these limitations while preserving the desirable properties of FUGs. It is based on the notions of typed features and typed constituents. We show the advantages of this extension in the context of a grammar used for text generation.}
}


@InProceedings{elhadad;robin:92,
  key = 	{Elhadad \& Robin 1992},
  author = 	{Elhadad, Michael and Robin, Jacques},
  title = 	 {Controlling Content Realization with Functional Unification Grammars},
  booktitle = {Aspects of Automated Natural Language Generation: Proceedings of the 6th International Workshop on Natural Language Generation (INLG'92)},
  editor = 	{Dale, Robert and Hovy, Eduard and Rösner, Dietmar and Stock, Oliviero},
  address =  {Trento, Italy},
  year =	 {1992},
  month =	 apr,
  date =	 {5--7},
  pages =	 {89--104},
  publisher = {Springer Verlag},
  series    = {Lecture Notes in Computer Science},
  volume    = {587},
  isbn      = {3-540-55399-1},
  url =	 {\url{http://www.cs.bgu.ac.il/~elhadad/papers/control.ps.gz}, \url{http://www.cs.bgu.ac.il/~elhadad/papers/control.pdf}, \url{http://www.cs.bgu.ac.il/~elhadad/papers/control.dvi}},
  last_access = {2003-07-12},
  storage = {Textgenerering},
  keywords = {unification, FUGs, NLG},
  abstract =	 {Standard Functional Unification Grammars (FUGs) provide a structurally guided top-down control regime for sentence generation. When using FUGs to perform content realization as a whole, including lexical choice, this regime is no longer appropriate for two reasons: (1) the unification of non-lexicalized semantic input with an integrated lexico-grammar requires mapping \"floating\" semantic elements which can trigger extensive backtracking and (2) lexical choice requires accessing external constraint sources on demand to preserve the modularity between conceptual and linguistic knowledge.

We introduce two control tools that we have implemented for FUGs to address these limitations: \texttt{bk-class}, a form of dependency-directed backtracking to efficiently process \"floating\" constraints and \texttt{external}, a co-routine mechanism allowing a FUG to cooperate with external constraint sources during unification. We show how these tools complement the top-down regime of FUGs to control the whole content realization process.}
}


%  month = 	apr,
@TechReport{elhadad;robin:96,
  key = 	{Elhadad \& Robin 1996},
  author = 	{Elhadad, Michael and Robin, Jacques},
  title = 	{An Overview of {SURGE}: A reusable comprehensive syntactic realization component},
  institution = 	{Department of Mathematics and Computer Science, Ben Gurion University},
  year = 	{1996},
  number = 	{96-03},
  address = 	{Beer Sheva, Israel},
  url = 	{\url{http://www.cs.bgu.ac.il/~elhadad/papers/surge.dvi}, \url{http://www.cs.bgu.ac.il/~elhadad/papers/surge.ps.gz}, \url{http://www.cs.bgu.ac.il/~elhadad/papers/surge.pdf}},
  last_access = {2003-07-12},
  storage = {Textgenerering},
  keywords = {NLG, FUGs},
  abstract = 	{This paper describes SURGE, a syntactic realization front-end for natural language generation systems. By gradually integrating complementary aspects of various linguistic theories within the computational framework of functional unification, SURGE has evolved to be one of the most comprehensive grammars of English for language generation available today. It has been successfully re-used in a variety of generators, with very different architectures and application domains.}
}


@Article{mikheev;grover;moens:99,
  key =	{Mikheev \& Grover \& Moens 1999},
  author = 	{Mikheev, Andrei and Grover, Claire and Moens, Marc},
  title = 	 {{XML} tools and architecture for {N}amed {E}ntity recognition},
  journal =	 {Journal of Markup Languages: Theory and Practice},
  year = 	 {1999},
  volume = 	 {1},
  number = 	 {3},
  pages = 	 {89--113},
  url = 	{\url{http://www.ltg.ed.ac.uk/papers/99mikheev_markup.ps}, \url{http://www.ltg.ed.ac.uk/papers/99mikheev_markup.pdf}},
  last_access = {2003-07-13},
  storage = {Textgenerering},
  keywords = {NER, statistical, ME, rule-based, XML},
  abstract = 	{}
}


@InProceedings{mikheev;moens;grover:99,
  key =	{Mikheev \& Moens \& Grover 1999},
  author = 	{Mikheev, Andrei and Moens, Marc and Grover, Claire},
  title = 	{Named Entity Recognition without Gazetteers},
  booktitle = 	{Proceedings of the 9th Conference of the European Chapter of the Association for Computational Linguistics (EACL'99)},
  pages =	{1--8},
  year =	{1999},
  month =	jun,
  date =	{8--12},
  url = 	{\url{http://www.ltg.ed.ac.uk/papers/99mikheev_eacl.ps}, \url{http://www.ltg.ed.ac.uk/papers/99mikheev_eacl.pdf}},
  last_access = {2003-07-13},
  storage = {Textgenerering},
  keywords = {NER, statistical, ME, rule-based},
  abstract = 	{It is often claimed that Named Entity recognition systems need extensive gazetteers--lists of names of people, organisations, locations, and other named entities. Indeed, the compilation of such gazetteers is sometimes mentioned as a bottleneck in the design of Named Entity recognition systems.

We report on a Named Entity recognition system which combines rule-based grammars with statistical (maximum entropy) models. We report on the system's performance with gazetteers of different types and different sizes, using test material from the \texttt{MUC-7} competition. We show that, for the text type and task of this competition, it is sufficient to use relatively small gazetteers of well-known names, rather than large gazetteers of low-frequency names. We conclude with observations about the domain independence of the competition and of our experiments.}
}


@Article{oberlander;Brew:00,
  key =	{Oberlander \& Brew 2000},
  author = 	{Oberlander, Jon and Brew, Chris},
  title = 	 {Stochastic Text Generation},
  journal =	 {Philosophical Transactions: Mathematical, Physical & Engineering Sciences},
  publisher = 	 {The Royal Society},
  year = 	 {2000},
  volume = 	 {358},
  number = 	 {1769},
  pages = 	 {1373--1387},
  url = 	{\url{http://www.ltg.ed.ac.uk/papers/99oberlander.ps}, \url{http://www.ltg.ed.ac.uk/papers/99oberlander.pdf}},
  last_access = {2003-07-13},
  storage = {Textgenerering},
  keywords = {natural language generation, statistical methods, maximum entropy modelling; NLG, statistical, ME},
  abstract = 	{Natural language generation systems must achieve fluency goals, as well as fidelity goals. Fluency helps make systems more usable by, for instance, producing language that is easier for people to process, or which engenders a positive evaluation of the system. Using very simple examples, we have explored one way to achieve specific fluency goals. These goals are stated as norms on 'macroscopic' properties of the text as a whole, rather than on individual words or sentences. Such properties are hard to accommodate within a conventional architecture. One solution is a two-component architecture, which permits independent variation of the components, either or both of which can be stochastic.}
}


@MastersThesis{pretschner:98,
  key = 	{Pretschner 1998},
  author = 	{Pretschner, Alexander},
  title = 	{Ontology Based Personalized Search},
  year = 	{1998},
  school = {University of Kansas, Lawrence},
  url = 	{\url{http://www.ittc.ku.edu/obiwan/publications/papers/alexthesis.pdf}, \url{http://www.ittc.ku.edu/obiwan/publications/papers/alexthesis.ps}},
  last_access = {2003-07-12},
  storage = {Textgenerering},
  keywords = {ontology, IR, IF, UM, personalisation, evaluation},
  abstract = {With the exponentially growing amount of information available on the Internet the task of retrieving documents of interest has become increasingly difficult. Search engines usually report more than 1,500 hits, and out of tthe top twenty results, only one half turn out to be relevant to the user. One reason for this is that the Web queries are in general very short and give an incomplete specification of individual users' information needs. 

This thesis is exploring ways of incorporating users' interests into the search process to improve the results. The user profiles are structured as a concept heirarchy fo 4,400 nodes. These are populated by "watching over a user's shoulder" while he is surfing. No explicit feedback is necessary. 

The obtained profiles are shown to converge and to reflect the actual interests quite well. One possible deployment of these profiles is investigated: re-ranking and filtering search results. The increases in performance are moderate, but they are not noticeable, and they show that fully automatic creation of large hierarchical user profiles is possible.}
}


%%%%%%%%%%%%%%%%



