@String{AAAIP =  "AAAI Press"}

@String{ACM =    "ACM Press"}

@String{AP =     "Academic Press"}

@String{AW =     "Addison-Wesley"}

@String{EH =     "Ellis Horwood"}

@String{IOS =    "IOS Press"}

@String{JWS =    "John Wiley"}

@String{KAC =    "Kluwer Academic Publishers"}

@String{MIT =    "The MIT Press"}

@String{MK =     "Morgan Kaufmann"}

@String{OUP =    "Oxford University Press"}

@String{PIT =    "Pitman"}

@String{SV =     "Springer-Verlag"}

@String{ACMCS =  "ACM Computing Surveys"}

@String{AI =     "Artificial Intelligence"}

@String{AAI =    "Applied Artificial Intelligence"}

@String{CACM =   "Communications of the ACM"}

@String{CI =     "Computational Intelligence"}

@String{IDA =    "Intelligent Data Analysis"}

@String{IJIS =   "International Journal of Intelligent Systems"}

@String{IJMMS =  "International Journal of Man-Machine Studies"}

@String{JAIR =   "Journal of Artificial Intelligence Research"}

@String{JETAI =  "Journal of Experimental and Theoretical Artificial
                 Intelligence"}

@String{JLP =    "Journal of Logic Programming"}

@String{KA =     "Knowledge Acquisition"}

@String{ML =     "Machine Learning"}

@String{JMLR =   "Journal of Machine Learning Research"}

@String{NGC =    "New Generation Computing"}

@String{NJC =    "Nordic Journal of Computing"}

@String{AAAI82 = "Proceedings of the 1st National Conference on
                 Artificial Intelligence"}

@String{AAAI86 = "Proceedings of the 5th National Conference on
                 Artificial Intelligence"}

@String{AAAI87 = "Proceedings of the 6th National Conference on
                 Artificial Intelligence"}

@String{AAAI88 = "Proceedings of the 7th National Conference on
                 Artificial Intelligence"}

@String{AAAI90 = "Proceedings of the 8th National Conference on
                 Artificial Intelligence"}

@String{AAAI91 = "Proceedings of the 9th National Conference on
                 Artificial Intelligence"}

@String{AAAI92 = "Proceedings of the 10th National Conference on
                 Artificial Intelligence"}

@String{AAAI93 = "Proceedings of the 11th National Conference on
                 Artificial Intelligence"}

@String{AAAI93WS = "Proceedings of the AAAI-93 Workshop on Knowledge
                 Discovery in Databases"}

@String{AAAI94 = "Proceedings of the 12th National Conference on
                 Artificial Intelligence"}

@String{AAAI94WS = "Proceedings of the AAAI-94 Workshop on Knowledge
                 Discovery in Databases"}

@String{AAAI95 = "Proceedings of the 13th National Conference on
                 Artificial Intelligence"}

@String{AAAI96 = "Proceedings of the 14th National Conference on
                 Artificial Intelligence"}

@String{AAAI97 = "Proceedings of the 15th National Conference on
                 Artificial Intelligence"}

@String{AAAI98 = "Proceedings of the 16th National Conference on
                 Artificial Intelligence"}

@String{AAAI99 = "Proceedings of the 17th National Conference on
                 Artificial Intelligence"}

@String{AAAI00 = "Proceedings of the 18th National Conference on
                 Artificial Intelligence"}

@String{AAAI01 = "Proceedings of the 19th National Conference on
                 Artificial Intelligence"}

@String{AAAI02 = "Proceedings of the 20th National Conference on
                 Artificial Intelligence"}

@String{ALT90 =  "Proceedings of the 1st Conference on Algorithmic
                 Learning Theory"}

@String{ALT91 =  "Proceedings of the 2nd Conference on Algorithmic
                 Learning Theory"}

@String{ALT92 =  "Proceedings of the 3rd Conference on Algorithmic
                 Learning Theory"}

@String{ALT93 =  "Proceedings of the 4th Conference on Algorithmic
                 Learning Theory"}

@String{ALT94 =  "Proceedings of the 5th Conference on Algorithmic
                 Learning Theory"}

@String{ALT95 =  "Proceedings of the 6th Conference on Algorithmic
                 Learning Theory"}

@String{ALT96 =  "Proceedings of the 7th Conference on Algorithmic
                 Learning Theory"}

@String{ALT97 =  "Proceedings of the 8th Conference on Algorithmic
                 Learning Theory"}

@String{ALT98 =  "Proceedings of the 9th Conference on Algorithmic
                 Learning Theory"}

@String{ALT99 =  "Proceedings of the 10th Conference on Algorithmic
                 Learning Theory"}

@String{ALT00 =  "Proceedings of the 11th Conference on Algorithmic
                 Learning Theory"}

@String{ALT01 =  "Proceedings of the 12th Conference on Algorithmic
                 Learning Theory"}

@String{ALT02 =  "Proceedings of the 13th Conference on Algorithmic
                 Learning Theory"}

@String{ECAI88 = "Proceedings of the 8th European Conference on
                 Artificial Intelligence"}

@String{ECAI90 = "Proceedings of the 9th European Conference on
                 Artificial Intelligence"}

@String{ECAI90WS = "Proceedings of the ECAI-90 Workshop on Validation,
                 Verification and Testing of Knowledge-Based Systems"}

@String{ECAI92 = "Proceedings of the 10th European Conference on
                 Artificial Intelligence"}

@String{ECAI92WS = "Proceedings of the ECAI-92 Workshop on Logical
                 Approaches to Machine Learning"}

@String{ECAI94 = "Proceedings of the 11th European Conference on
                 Artificial Intelligence"}

@String{ECAI96 = "Proceedings of the 12th European Conference on
                 Artificial Intelligence"}

@String{ECAI98 = "Proceedings of the 13th European Conference on
                 Artificial Intelligence"}

@String{ECAI00 = "Proceedings of the 14th European Conference on
                 Artificial Intelligence"}

@String{ECAI02 = "Proceedings of the 15th European Conference on
                 Artificial Intelligence"}

@String{EWSL87 = "Proceedings of the 2nd European Working Session on
                 Learning"}

@String{EWSL88 = "Proceedings of the 3rd European Working Session on
                 Learning"}

@String{EWSL89 = "Proceedings of the 4th European Working Session on
                 Learning"}

@String{EWSL91 = "Proceedings of the 5th European Working Session on
                 Learning"}

@String{ECML93 = "Proceedings of the 6th European Conference on Machine
                 Learning"}

@String{ECML94 = "Proceedings of the 7th European Conference on Machine
                 Learning"}

@String{ECML95 = "Proceedings of the 8th European Conference on Machine
                 Learning"}

@String{ECML97 = "Proceedings of the 9th European Conference on Machine
                 Learning"}

@String{ECML98 = "Proceedings of the 10th European Conference on Machine
                 Learning"}

@String{ECML00 = "Proceedings of the 11th European Conference on Machine
                 Learning"}

@String{ECML01 = "Proceedings of the 12th European Conference on Machine
                 Learning"}

@String{ECML02 = "Proceedings of the 13th European Conference on Machine
                 Learning"}

@String{ECML03 = "Proceedings of the 14th European Conference on Machine
                 Learning"}

@String{PKDD99 = "Proceedings of the 3rd European Conference on
                 Principles of Data Mining and Knowledge Discovery"}

@String{PKDD00 = "Proceedings of the 4th European Conference on
                 Principles of Data Mining and Knowledge Discovery"}

@String{PKDD01 = "Proceedings of the 5th European Conference on
                 Principles of Data Mining and Knowledge Discovery"}

@String{PKDD02 = "Proceedings of the 6th European Conference on
                 Principles of Data Mining and Knowledge Discovery"}

@String{PKDD03 = "Proceedings of the 7th European Conference on
                 Principles of Data Mining and Knowledge Discovery"}

@String{ML87 =   "Proceedings of the 4th International Workshop on
                 Machine Learning"}

@String{ML88 =   "Proceedings of the 5th International Workshop on
                 Machine Learning"}

@String{ML89 =   "Proceedings of the 6th International Workshop on
                 Machine Learning"}

@String{ML90 =   "Proceedings of the 7th International Conference on
                 Machine Learning"}

@String{ML91 =   "Proceedings of the 8th International Workshop on
                 Machine Learning"}

@String{ML92 =   "Proceedings of the 9th International Workshop on
                 Machine Learning"}

@String{ML93 =   "Proceedings of the 10th International Conference on
                 Machine Learning"}

@String{ML94 =   "Proceedings of the 11th International Conference on
                 Machine Learning"}

@String{ML95 =   "Proceedings of the 12th International Conference on
                 Machine Learning"}

@String{ML96 =   "Proceedings of the 13th International Conference on
                 Machine Learning"}

@String{ML96WS = "Proceedings of the MLnet Familiarization Workshop on
                 Data Mining with Inductive Logic Programing"}

@String{ML97 =   "Proceedings of the 14th International Conference on
                 Machine Learning"}

@String{ICML93 = "Proceedings of the 10th International Conference on
                 Machine Learning"}

@String{ICML94 = "Proceedings of the 11th International Conference on
                 Machine Learning"}

@String{ICML95 = "Proceedings of the 12th International Conference on
                 Machine Learning"}

@String{ICML96 = "Proceedings of the 13th International Conference on
                 Machine Learning"}

@String{ICML97 = "Proceedings of the 14th International Conference on
                 Machine Learning"}

@String{ICML98 = "Proceedings of the 15th International Conference on
                 Machine Learning"}

@String{ICML99 = "Proceedings of the 16th International Conference on
                 Machine Learning"}

@String{ICML00 = "Proceedings of the 17th International Conference on
                 Machine Learning"}

@String{ICML01 = "Proceedings of the 18th International Conference on
                 Machine Learning"}

@String{ICML02 = "Proceedings of the 19th International Conference on
                 Machine Learning"}

@String{ICML03 = "Proceedings of the 20th International Conference on
                 Machine Learning"}

@String{IJCAI75 = "Proceedings of the 4th International Joint Conference
                 on Artificial Intelligence"}

@String{IJCAI77 = "Proceedings of the 5th International Joint Conference
                 on Artificial Intelligence"}

@String{IJCAI79 = "Proceedings of the 6th International Joint Conference
                 on Artificial Intelligence"}

@String{IJCAI81 = "Proceedings of the 7th International Joint Conference
                 on Artificial Intelligence"}

@String{IJCAI83 = "Proceedings of the 8th International Joint Conference
                 on Artificial Intelligence"}

@String{IJCAI85 = "Proceedings of the 9th International Joint Conference
                 on Artificial Intelligence"}

@String{IJCAI87 = "Proceedings of the 10th International Joint
                 Conference on Artificial Intelligence"}

@String{IJCAI89 = "Proceedings of the 11th International Joint
                 Conference on Artificial Intelligence"}

@String{IJCAI91 = "Proceedings of the 12th International Joint
                 Conference on Artificial Intelligence"}

@String{IJCAI93 = "Proceedings of the 13th International Joint
                 Conference on Artificial Intelligence"}

@String{IJCAI93WS = "Proceedings of the IJCAI-93 Workshop on Inductive
                 Logic Programming"}

@String{IJCAI95 = "Proceedings of the 14th International Joint
                 Conference on Artificial Intelligence"}

@String{IJCAI97 = "Proceedings of the 15th International Joint
                 Conference on Artificial Intelligence"}

@String{IJCAI99 = "Proceedings of the 16th International Joint
                 Conference on Artificial Intelligence"}

@String{IJCAI01 = "Proceedings of the 17th International Joint
                 Conference on Artificial Intelligence"}

@String{IJCAI03 = "Proceedings of the 18th International Joint
                 Conference on Artificial Intelligence"}

@String{ILP91 =  "Proceedings of the 1st International Workshop on
                 Inductive Logic Programming"}

@String{ILP92 =  "Proceedings of the 2nd International Workshop on
                 Inductive Logic Programming"}

@String{ILP93 =  "Proceedings of the 3rd International Workshop on
                 Inductive Logic Programming"}

@String{ILP94 =  "Proceedings of the 4th International Workshop on
                 Inductive Logic Programming"}

@String{ILP95 =  "Proceedings of the 5th International Workshop on
                 Inductive Logic Programming"}

@String{ILP96 =  "Proceedings of the 6th International Workshop on
                 Inductive Logic Programming"}

@String{ILP96 =  "Proceedings of the 6th International Workshop on
                 Inductive Logic Programming"}

@String{ILP97 =  "Proceedings of the 7th International Workshop on
                 Inductive Logic Programming"}

@String{ILP98 =  "Proceedings of the 8th International Conference on
                 Inductive Logic Programming"}

@String{ILP99 =  "Proceedings of the 9th International Workshop on
                 Inductive Logic Programming"}

@String{ILP00 =  "Proceedings of the 10th International Conference on
                 Inductive Logic Programming"}

@String{ILP00WIP = "Proceedings of the Work-in-Progress Track at the
                 10th International Conference on Inductive Logic
                 Programming"}

@String{ILP01 =  "Proceedings of the 11th International Conference on
                 Inductive Logic Programming"}

@String{ILP01WIP = "Proceedings of the Work-in-Progress Track at the
                 11th International Conference on Inductive Logic
                 Programming"}

@String{ILP02 =  "Proceedings of the 12th International Conference on
                 Inductive Logic Programming"}

@String{ILP02WIP = "Proceedings of the Work-in-Progress Track at the
                 12th International Conference on Inductive Logic
                 Programming"}

@String{ILP03 =  "Proceedings of the 13th International Conference on
                 Inductive Logic Programming"}

@String{ILP03WIP = "Proceedings of the Work-in-Progress Track at the
                 13th International Conference on Inductive Logic
                 Programming"}

@String{MRDM02 = "Proceedings of the First SIGKDD Workshop on
                 Multi-Relational Data Mining (MRDM-2002)"}

@String{MRDM03 = "Proceedings of the Second SIGKDD Workshop on
                 Multi-Relational Data Mining (MRDM-2003)"}

@String{MGTS03 = "Proceedings of the First International Workshop on
                 Mining Graphs, Trees and Sequences (MGTS-2003)"}

@String{ISMIS89 = "Proceedings of the 3rd International Symposium on
                 Methodologies for Intelligent Systems"}

@String{ISMIS90 = "Proceedings of the 4th International Symposium on
                 Methodologies for Intelligent Systems"}

@String{ISMIS91 = "Proceedings of the 5th International Symposium on
                 Methodologies for Intelligent Systems"}

@String{ISMIS93 = "Proceedings of the 7th International Symposium on
                 Methodologies for Intelligent Systems"}

@String{ISMIS94 = "Proceedings of the 8th International Symposium on
                 Methodologies for Intelligent Systems"}

@String{ISMIS95 = "Proceedings of the 9th International Symposium on
                 Methodologies for Intelligent Systems"}

@String{ISMIS96 = "Proceedings of the 10th International Symposium on
                 Methodologies for Intelligent Systems"}

@String{ISSEK92 = "Proceedings of the 6th International School for the
                 Synthesis of Expert Knowledge"}

@String{MSL91 =  "Proceedings of the 1st International Workshop on
                 Multistrategy Learning"}

@String{MSL93 =  "Proceedings of the 2nd International Workshop on
                 Multistrategy Learning"}

@String{MSL96 =  "Proceedings of the 3nd International Workshop on
                 Multistrategy Learning"}

@String{PAP96 =  "Proceedings of the 4th International Conference on the
                 Practical Application of Prolog"}

@String{AIME97 = "Proceedings of the 5th National Conference on
                 Artificial Intelligence in Medicine in Europe"}

@String{ICKDD96 = "Proceedings of the 2nd International Conference on
                 Knowledge Discovery and Data Mining"}

@String{ICKDD97 = "Proceedings of the 3rd International Conference on
                 Knowledge Discovery and Data Mining"}

@String{EWKA96 = "Proceedings of the 1996 European Workshop on Knowledge
                 Acquisition"}

@String{LLL99 =  "Proceedings of the 1st Workshop on Learning Language
                 in Logic"}

@String{LLL00 =  "Proceedings of the 2nd Workshop on Learning Language
                 in Logic"}

@String{LLL01 =  "Proceedings of the 3rd Workshop on Learning Language
                 in Logic"}

@String{RDM =    "Relational Data Mining"}

@String{DzeroskiLavrac = "Sa\v{s}o D\v{z}eroski and Nada Lavra\v{c}"}

@String{BIBLE =  "Machine Learning: An Artificial Intelligence
                 Approach"}

@String{BK =     "Brazdil, P.B. and Konolige, K."}

@String{CISM =   "CISM Courses and Lectures"}

@String{DEPTCW = "Department of Computer Science, Katholieke
                 Universiteit Leuven"}

@String{ILP =    "Inductive Logic Programming"}

@String{JSI =    "J. Stefan Institute"}

@String{KM =     "Kodratoff, Y. and Michalski, R.S."}

@String{LNAI =   "Lecture Notes in Artificial Intelligence"}

@String{LNCS =   "Lecture Notes in Computer Science"}

@String{MCM =    "Michalski, R.S and Carbonell, J.G. and Mitchell,
                 T.M."}

@String{MML =    "Machine Learning, Meta-Reasoning and Logics"}





@Proceedings{cussens05:_proceed_learn_languag_logic_works,
  title = 	 {Proceedings of the 4th Learning Language in Logic Workshop (LLL05)},
  year = 	 2005,
  editor =	 {James Cussens and Claire N\'{e}dellec},
  address =	 {Bonn},
  month =	 {August},
 url = {http://www.cs.york.ac.uk/aig/lll/lll05/proceedings.pdf}
}



@InProceedings{canisius05:_rule_meta_trigr_based_sequen_proces,
  author = 	 {Sander Canisius and van den Bosch, Antal and Walter Daelemans},
  title = 	 {Rule Meta-learning for Trigram-Based Sequence Processing},
  booktitle = 	 {Proceedings of the 4th Learning Language in Logic Workshop (LLL05)},
  pages =	 {3--10},
  year =	 2005,
  editor =	 {James Cussens and Claire N\'{e}dellec},
  address =	 {Bonn},
  month =	 {August},
  url = {http://www.cs.york.ac.uk/aig/lll/lll05/lll05-canisius.pdf}
}

@InProceedings{liakata05:_using_ilp_fsa,
  author = 	 {Maria Liakata and Stephen Pulman},
  title = 	 {Using {ILP} to learn a domain theory in the form of a {FSA}},
  booktitle = 	 {Proceedings of the 4th Learning Language in Logic Workshop (LLL05)},
  pages =	 {11--20},
  year =	 2005,
  editor =	 {James Cussens and Claire N\'{e}dellec},
  address =	 {Bonn},
  month =	 {August},
  url = {http://www.cs.york.ac.uk/aig/lll/lll05/lll05-liakata.pdf}
}

@InProceedings{sato05:_gener_approac_em_learn_symbol_statis_model,
  author = 	 {Taisuke Sato},
  title = 	 {A Generic Approach to {EM} Learning for Symbolic-Statistical Models},
  booktitle = 	 {Proceedings of the 4th Learning Language in Logic Workshop (LLL05)},
  pages =	 {21--28},
  year =	 2005,
  editor =	 {James Cussens and Claire N\'{e}dellec},
  address =	 {Bonn},
  month =	 {August},
  url = {http://www.cs.york.ac.uk/aig/lll/lll05/lll05-sato.pdf}
}

@InProceedings{nedellec:_learn_languag_logic,
  author = 	 {Claire N\'{e}dellec},
  title = 	 {Learning Language in Logic -- Genic Interaction Extraction Challenge},
  booktitle = 	 {Proceedings of the 4th Learning Language in Logic Workshop (LLL05)},
  pages =	 {31--37},
  year =	 2005,
  editor =	 {James Cussens and Claire N\'{e}dellec},
  address =	 {Bonn},
  month =	 {August},
  url = {http://www.cs.york.ac.uk/aig/lll/lll05/lll05-nedellec.pdf}
}

@InProceedings{hakenberg05:_chall,
  author = 	 {J\"{o}rg Hakenberg and Conrad Plake and Ulf Leser and
  Harald Kirsch and Dietrich Rebholz-Schuhmann},
  title = 	 {{LLL}'05 Challenge: Genic Interaction Extraction---Identification of Language Patterns Based on Alignment and Finite State Automata},
  booktitle = 	 {Proceedings of the 4th Learning Language in Logic Workshop (LLL05)},
  pages =	 {38--45},
  year =	 2005,
  editor =	 {James Cussens and Claire N\'{e}dellec},
  address =	 {Bonn},
  month =	 {August},
  url = {http://www.cs.york.ac.uk/aig/lll/lll05/lll05-hakenberg.pdf}
}

@InProceedings{greenwood05:_autom_acquir_linguis_motiv_genic,
  author = 	 {Greenwood, Mark A. and Mark Stevenson and Yikun Guo and Henk Harkema and Angus Roberts},
  title = 	 {Automatically Acquiring a Linguistically Motivated Genic Interaction Extraction System},
  booktitle = 	 {Proceedings of the 4th Learning Language in Logic Workshop (LLL05)},
  pages =	 {46--52},
  year =	 2005,
  editor =	 {James Cussens and Claire N\'{e}dellec},
  address =	 {Bonn},
  month =	 {August},
  url = {http://www.cs.york.ac.uk/aig/lll/lll05/lll05-greenwood.pdf}
}

@InProceedings{katrenko05:_learn_biolog_inter_medlin_abstr,
  author = 	 {Sophia Katrenko and M. Scott Marshall and Marco Roos and Pieter Adriaans},
  title = 	 {Learning Biological Interactions from {M}edline Abstracts},
  booktitle = 	 {Proceedings of the 4th Learning Language in Logic Workshop (LLL05)},
  pages =	 {53--58},
  year =	 2005,
  editor =	 {James Cussens and Claire N\'{e}dellec},
  address =	 {Bonn},
  month =	 {August},
  url = {http://www.cs.york.ac.uk/aig/lll/lll05/lll05-katrenko.pdf}
}

@InProceedings{popelinsky05:_learn,
  author = 	 {Lubo\v{s} Popel\'{\i}nsk\'{y} and Jan Bla\v{t}\'{a}k},
  title = 	 {Learning genic interactions without expert domain knowledge: Comparison of different {ILP} algorithms},
  booktitle = 	 {Proceedings of the 4th Learning Language in Logic Workshop (LLL05)},
  pages =	 {59--61},
  year =	 2005,
  editor =	 {James Cussens and Claire N\'{e}dellec},
  address =	 {Bonn},
  month =	 {August},
  url = {http://www.cs.york.ac.uk/aig/lll/lll05/lll05-popelinsky.pdf}
}

@InProceedings{goadrich05:_learn_extrac_genic_inter_using_glean,
  author = 	 {Mark Goadrich and Louis Oliphant and Jude Shavlik},
  title = 	 {Learning to Extract Genic Interactions Using {G}leaner},
  booktitle = 	 {Proceedings of the 4th Learning Language in Logic Workshop (LLL05)},
  pages =	 {62--68},
  year =	 2005,
  editor =	 {James Cussens and Claire N\'{e}dellec},
  address =	 {Bonn},
  month =	 {August},
  url = {http://www.cs.york.ac.uk/aig/lll/lll05/lll05-goadrich.pdf}
}


@InProceedings{riedel05:_genic_inter_extrac_seman_syntac_chain,
  author = 	 {Sebastian Riedel and Ewan Klein},
  title = 	 {Genic Interaction Extraction with Semantic and Syntactic Chains},
  booktitle = 	 {Proceedings of the 4th Learning Language in Logic Workshop (LLL05)},
  pages =	 {69--74},
  year =	 2005,
  editor =	 {James Cussens and Claire N\'{e}dellec},
  address =	 {Bonn},
  month =	 {August},
  url = {http://www.cs.york.ac.uk/aig/lll/lll05/lll05-riedel.pdf}
}


@InProceedings{liakata_pulman04,
  author =       "Maria Liakata and Stephen Pulman",
  title =        "Learning theories from text",
  booktitle =    "Proceedings of the 20th International Conference
                  for Computational Linguistics",
  pages =        "",
  year =         "2004",
  address =      "Geneva, Switzerland",
  month =        aug,
  abstract =     "In this paper we describe a method of automatically  learning domain theories from parsed corpora of sentences from the  relevant domain and use FSA techniques for the graphical representation  of such a theory.
By a `domain theory' we mean a collection of facts and generalisations  or rules which capture what commonly happens (or does not happen) in  some domain of interest. As language users, we implicitly draw on such  theories in various disambiguation tasks, such as anaphora resolution  and prepositional phrase attachment, and formal encodings of domain  theories can be used for this purpose in natural language processing.  They may also be objects of interest in their own right, that is, as  the output of a knowledge discovery process. The approach is  generizable to different domains provided it is possible to get logical  forms for the text in the domain.",
  URL =           "http://www.ling-phil.ox.ac.uk/people/staff/pulman/pdfpapers/coling04.pdf",
}

@InCollection{pulman_liakata04,
  author =       "Stephen Pulman and Maria Liakata",
  title =        "Learning domain theories",
  year =         "2004",
  pages =        "29--44",
  keywords =     "Language_Learning",
  editor =       "Nicolas Nicolov and Kalina Botcheva and
                Galia Angelova and Ruslan Mitkov",
  booktitle =    "{R}ecent {A}dvances in {N}atural {L}anguage  {P}rocessing
{III}: {S}elected {P}apers from {RANLP} 2003",
  address =      "Amsterdam/Philadelphia",
  publisher =    "Johns Benjamins",
  URL =           "http://www.ling-phil.ox.ac.uk/people/staff/pulman/pdfpapers/ranlp03.pdf",
  abstract =     "By a domain theory we mean a collection of facts and  generalisations
or rules which capture what commonly happens (or does not happen) in
some domain of interest. As language users, we implicitly draw on such
theories in various disambiguation tasks, such as anaphora resolution  and
prepositional phrase attachment, and formal encodings of domain theories
can be used for this purpose in natural language processing. They may  also
be objects of interest in their own right, that is, as the output of a  knowledge
discovery process. We describe a method of automatically learning domain
theories from parsed corpora of sentences from the relevant domain.
",
}


@PhdThesis{liakata04,
  title =        "Inducing domain theories",
  author =       "Maria Liakata",
  number =       "PhD Thesis",
  school =       "Computational Linguistics Group, University of  Oxford",
  address =      "Oxford, UK",
  year =         "2004",
  month =        "October",
  key =          "domain_theories",
  abstract =     "This thesis presents a method for learning a domain  theory automatically
from a corpus of parsed sentences. What is meant by a `domain theory'  is a collection of
facts and generalisations or rules which capture what commonly happens  (or does not happen)
in some domain of interest. As language users we implicitly draw on  such theories in
various disambiguation tasks, such as anaphora resolution and  prepositional phrase attachment,
and formal encodings of domain theories can be used for this purpose in  natural language processing.
Domain theories may also be objects of interest in their own right,  that is, as the output
of a knowledge discovery process, providing previously unobserved  information to aid with
the understanding of the domain. The learning paradigm employed is  Inductive Logic
Programming (ILP), which generalises over examples from the domain to  obtain more general
patterns covering the majority of the input instances. ILP was  preferred over other
machine learning techniques due to the expressive power of the language  specifications guiding
the search for general patterns and the fact that it allows the  inclusion of background knowledge.
Different ILP algorithms were explored in conjunction with the domain  of company succession events.
The relational data mining algorithm WARMR gave the most satisfactory  results as it was able
to capture frequent patterns of complex structure, often encoding  causal relations, consisting of
two or more verbs and information about their respective arguments.  Finite State Automata (FSA)
minimisation techniques were employed to render the rules learnt into a  more compact format.
Thus, sets of rules were represented as weighted FSAs, which are easier  for humans to visualise
than a first order logic representation and incorporate into a system  for disambiguation.
These weighted FSAs can also be converted to simple Bayesian networks.
The approach discussed can be ported to different domains and future  work aspires to focus
on medical texts, which are rich in causal relations.",
URL = "http://users.ox.ac.uk/\~{}sedm1418/mliakata_thesis.pdf",
}


@InBook{NED04,
  author =       "Claire N\'{e}dellec",
  chapter =      "Machine Learning for Information Extraction in
                 Genomics - State of the Art and Perspectives",
  title =        "Text Mining and its Applications: Results of the
                 {NEMIS} Launch Conference Series: Studies in Fuzziness
                 and Soft Computing",
  publisher =    "Spiros",
  year =         "2004",
}

@Article{lemma-aai04,
  author =       "Toma\v{z} Erjavec and Sa\v{s}o D\v{z}eroski",
  title =        "{Machine Learning of Language Structure: Lemmatising
                 Unknown {S}lovene Words}",
  journal =      "Applied Artificial Intelligence",
  publisher =    "Taylor \& Francis",
  volume =       "18",
  number =       "1",
  pages =        "17--41",
  year =         "2004",
  abstract =     "Automatic lemmatisation is a core application for many
                 language processing tasks. In inflectionally rich
                 languages, such as Slovene, assigning the correct lemma
                 (base form) to each word in a running text is not
                 trivial, as, for instance, nouns inflect for number and
                 case, with a complex configuration of endings and stem
                 modifications. The problem is especially difficult for
                 unknown words, as word-forms cannot be matched against
                 a morphological lexicon. The paper discusses a machine
                 learning approach to the automatic lemmatisation of
                 unknown words in Slovene texts. We decompose the
                 problem of learning to perform lemmatisation into two
                 subproblems: learning to perform morphosyntactic
                 tagging of words in a text, and learning to perform
                 morphological analysis, which produces the lemma from
                 the word-form given the correct morphosyntactic tag. A
                 statistics-based trigram tagger is used to learn
                 morphosyntactic tagging and a first-order decision list
                 learning system is used to learn rules for
                 morphological analysis. We train the analyser on
                 open-class inflecting Slovene words, namely nouns,
                 adjectives, and main verbs, together being
                 characterised by more than 400 different
                 morphosyntactic tags. Our training sets consist of a
                 morphological lexicon containing 15,000 lemmas and a
                 manually annotated corpus consisting of 100,000 running
                 words. We evaluate the learned model on word lists
                 extracted from a corpus of Slovene texts containing
                 500,000 words, and show that our morphological analysis
                 module achieves 98.6\% accuracy, while the combination
                 of the tagger and analyser is 92.0\% accurate on
                 unknown inflecting Slovene words.",
}

@InProceedings{bunescu04:_collec_infor_extrac_relat_markov_networ,
  author =       "Razvan Bunescu and Raymond J. Mooney",
  title =        "Collective Information Extraction with Relational
                 {M}arkov Networks",
  booktitle =    "Proceedings of the 42nd Annual Meeting of the
                 Association for Computational Linguistics (ACL-2004)",
  pages =        "439--446",
  year =         "2004",
  address =      "Barcelona, Spain",
  month =        jul,
  abstract =     "Most information extraction (IE) systems treat
                 separate potential extractions as independent. However,
                 in many cases, considering influences between different
                 potential extractions could improve overall accuracy.
                 Statistical methods based on undirected graphical
                 models, such as conditional random fields (CRFs), have
                 been shown to be an effective approach to learning
                 accurate IE systems. We present a new IE method that
                 employs Relational Markov Networks (a generalization of
                 CRFs), which can represent arbitrary dependencies
                 between extractions. This allows for {"}collective
                 information extraction{"} that exploits the mutual
                 influence between possible extractions. Experiments on
                 learning to extract protein names from biomedical text
                 demonstrate the advantages of this approach.",
  URL =          "http://www.cs.utexas.edu/users/ml/publication/paper.cgi?paper=cie-acl-04.ps.gz",
}

@InProceedings{bunescu04:_relat_markov_networ_collec_infor_extrac,
  author =       "Razvan Bunescu and Raymond J. Mooney",
  title =        "Relational {M}arkov Networks for Collective
                 Information Extraction",
  booktitle =    "Proceedings of the ICML-2004 Workshop on Statistical
                 Relational Learning and its Connections to Other Fields
                 (SRL-2004)",
  year =         "2004",
  address =      "Banff, Canada",
  month =        jul,
  abstract =     "Most information extraction (IE) systems treat
                 separate potential extractions as independent. However,
                 in many cases, considering influences between different
                 potential extractions could improve overall accuracy.
                 Statistical methods based on undirected graphical
                 models, such as conditional random fields (CRFs), have
                 been shown to be an effective approach to learning
                 accurate IE systems. We present a new IE method that
                 employs Relational Markov Networks, which can represent
                 arbitrary dependencies between extractions. This allows
                 for {"}collective information extraction{"} that
                 exploits the mutual influence between possible
                 extractions. Experiments on learning to extract protein
                 names from biomedical text demonstrate the advantages
                 of this approach.",
  URL =          "http://www.cs.utexas.edu/users/ml/publication/paper.cgi?paper=cie-icml-wkshp-04.ps.gz",
}

@Unpublished{rohit04:_learn_trans_rules_seman_parsin,
  author =       "Rohit J. Kate and Yuk Wah Wong and Ruifang Ge and
                 Raymond J. Mooney",
  title =        "Learning Transformation Rules for Semantic Parsing",
  note =         "Unpublished Technical Note, April 2004",
  month =        apr,
  year =         "2004",
  abstract =     "This paper presents an approach for inducing
                 transformation rules that map natural-language
                 sentences into a formal semantic representation
                 language. The approach assumes a formal grammar for the
                 target representation language and learns
                 transformation rules that exploit the non-terminal
                 symbols in this grammar. Patterns for the
                 transformation rules are learned using an induction
                 algorithm based on longest-common-subsequences
                 previously developed for an information extraction
                 system. Experimental results are presented on learning
                 to map English coaching instructions for Robocup soccer
                 into an existing formal language for coaching simulated
                 robotic agents.",
  URL =          "http://www.cs.utexas.edu/users/ml/publication/paper.cgi?paper=semantic-submitted-04.ps.gz",
}

@InProceedings{04:_learn_seman_parser,
  author =       "Raymond J. Mooney",
  title =        "Learning Semantic Parsers: An Important But
                 Under-Studied Problem",
  booktitle =    "Papers from the AAAI 2004 Spring Symposium on Language
                 Learning: An Interdisciplinary Perspective",
  pages =        "39--44",
  year =         "2004",
  address =      "Stanford, CA",
  month =        mar,
  abstract =     "Computational systems that learn to transform
                 natural-language sentences into semantic
                 representations have important practical applications
                 in building natural-language interfaces. They can also
                 provide insight into important issues in human language
                 acquisition. However, within AI, computational
                 linguistics, and machine learning, there has been
                 relatively little research on developing systems that
                 learn such semantic parsers. This paper briefly reviews
                 our own work in this area and presents semantic-parser
                 acquistion as an important challenge problem for AI.",
  URL =          "http://www.cs.utexas.edu/users/ml/publication/paper.cgi?paper=chill-aaaiss-04.ps.gz",
}

@Article{bunescu:aimed04,
  title =        "Comparative Experiments on Learning Information
                 Extractors for Proteins and their Interactions",
  author =       "Razvan Bunescu and Ruifang Ge and Rohit J. Kate and
                 Edward M. Marcotte and Raymond J. Mooney and Arun Kumar
                 Ramani and Yuk Wah Wong",
  journal =      "Special Issue in the Journal Artificial Intelligence
                 in Medicine on Summarization and Information Extraction
                 from Medical Documents",
  editors =      "Constantine D. Spyropoulos and Vangelis Karkaletsis",
  publisher =    "Elsevier",
  year =         "2004",
  volume =       "31",
  note =         "To appear",
  abstract =     "Automatically extracting information from biomedical
                 text holds the promise of easily consolidating large
                 amounts of biological knowledge in computer-accessible
                 form. This strategy is particularly attractive for
                 extracting data relevant to genes of the human genome
                 from the 11 million abstracts in Medline. However,
                 extraction efforts have been frustrated by the lack of
                 conventions for describing human genes and proteins. We
                 have developed and evaluated a variety of learned
                 information extraction systems for identifying human
                 protein names in Medline abstracts and subsequently
                 extracting information on interactions between the
                 proteins. We demonstrate that machine learning
                 approaches using support vector machines and hidden
                 Markov models are able to identify human proteins with
                 higher accuracy than several previous approaches. We
                 also demonstrate that various rule induction methods
                 are able to identify protein interactions more
                 accurately than manually-developed rules.",
  URL =          "http://www.cs.utexas.edu/users/ml/publication/paper.cgi?paper=bionlp-aimed-04.ps.gz",
}

@InProceedings{goadrich-ilp04,
  filename =     "goadrich.ilp04.pdf goadrich.ilp04.ppt",
  author =       "Mark Goadrich and Louis Oliphant and Jude Shavlik",
  title =        "Learning Ensembles of First-Order Clauses for
                 Recall-Precision Curves: {A} Case Study in Biomedical
                 Information Extraction",
  booktitle =    "Proceedings of the Fourteenth International Conference
                 on Inductive Logic Programming",
  year =         "2004",
  address =      "Porto, Portugal",
  abstract =     "Many domains in the field of Inductive Logic
                 Programming (ILP) involve highly unbalanced data. Our
                 research has focused on Information Extraction (IE), a
                 task that typically involves many more negative
                 examples than positive examples. IE is the process of
                 finding facts in unstructured text, such as biomedical
                 journals, and putting those facts in an organized
                 system. In particular, we have focused on learning to
                 recognize instances of the protein-localization
                 relationship in Medline abstracts. We view the problem
                 as a machine-learning task: given positive and negative
                 extractions from a training corpus of abstracts, learn
                 a logical theory that performs well on a held-aside
                 testing set. A common way to measure performance in
                 these domains is to use precision and recall instead of
                 simply using accuracy. We propose Gleaner, a randomized
                 search method which collects good clauses from a broad
                 spectrum of points along the recall dimension in
                 recall-precision curves and employs an ''at least N of
                 these M clauses'' thresholding method to combine the
                 selected clauses. We compare Gleaner to ensembles of
                 standard Aleph theories and find that Gleaner produces
                 comparable testset results in a fraction of the
                 training time needed for ensembles.",
  URL =          "http://www.cs.wisc.edu/%7Eshavlik/abstracts/goadrich-ilp04.abstract.html",
}

@PhdThesis{tang:thesis03,
  title =        "Integrating Top-down and Bottom-up Approaches in
                 Inductive Logic Programming: Applications in Natural
                 Language Processing and Relational Data Mining",
  author =       "Lappoon R. Tang",
  number =       "PhD Thesis",
  school =       "Department of Computer Sciences, University of Texas",
  address =      "Austin, TX",
  year =         "2003",
  month =        Aug,
  key =          "TABULATE, BETH",
  abstract =     "Inductive Logic Programming (ILP) is the intersection
                 of Machine Learning and Logic Programming in which the
                 learner's hypothesis space is the set of logic
                 programs. There are two major ILP approaches: top-down
                 and bottom-up. The former searches the hypothesis space
                 from general to specific while the latter the other way
                 round. Integrating both approaches has been
                 demonstrated to be more effective. Integrated ILP
                 systems were previously developed for two tasks:
                 learning semantic parsers (Chillin), and mining
                 relational data (Progol). Two new integrated ILP
                 systems for these tasks that overcome limitations of
                 existing methods will be presented. Cocktail is a new
                 ILP algorithm for inducing semantic parsers. For this
                 task, two features of a parse state, functional
                 structure and context, provide important information
                 for disambiguation. A bottom-up approach is more
                 suitable for learning the former, while top-down is
                 better for the latter. By allowing both approaches to
                 induce program clauses and choosing the best
                 combination of their results, Cocktail learns more
                 effective parsers. Experimental results on learning
                 natural-language interfaces for two databases
                 demonstrate that it learns more accurate parsers than
                 Chillin, the previous best method for this task. Beth
                 is a new integrated ILP algorithm for relational data
                 mining. The Inverse Entailment approach to ILP,
                 implemented in the Progol and Aleph systems, starts
                 with the construction of a bottom clause, the most
                 specific hypothesis covering a seed example. When
                 mining relational data with a large number of
                 background facts, the bottom clause becomes intractably
                 large, making learning very inefficient. A top-down
                 approach heuristically guides the construction of
                 clauses without building a bottom clause; however, it
                 wastes time exploring clauses that cover no positive
                 examples. By using a top-down approach to heuristically
                 guide the construction of generalizations of a bottom
                 clause, Beth combines the strength of both approaches.
                 Learning patterns for detecting potential terrorist
                 activity is a current challenge problem for relational
                 data mining. Experimental results on artificial data
                 for this task with over half a million facts show that
                 Beth is significantly more efficient at discovering
                 such patterns than Aleph and m-Foil, two leading ILP
                 systems.",
  URL =          "http://www.cs.utexas.edu/users/ml/publication/paper.cgi?paper=cocktail-dissertation-03.ps.gz",
}

@InProceedings{bunescu:ml03-wkshp,
  author =       "Razvan Bunescu and Ruifang Ge and Rohit J. Kate and
                 Edward M. Marcotte and Raymond J. Mooney and Arun Kumar
                 Ramani and Yuk Wah Wong",
  title =        "Learning to Extract Proteins and their Interactions
                 from {Medline} Abstracts",
  booktitle =    "Proceedings of the ICML-03 Workshop on Machine
                 Learning in Bioinformatics",
  pages =        "46--53",
  month =        aug,
  year =         "2003",
  address =      "Washington, DC",
  abstract =     "We present results from a variety of learned
                 information extraction systems for identifying human
                 protein names in Medline abstracts and subsequently
                 extracting interactions between the proteins. We
                 demonstrate that machine learning approaches using
                 support vector machines and hidden Markov models are
                 able to identify human proteins with higher accuracy
                 than several previous approaches. We also demonstrate
                 that various rule induction methods are able to
                 identify protein interactions with higher precision
                 than manually-developed rules.",
  URL =          "http://www.cs.utexas.edu/users/ml/publication/paper.cgi?paper=bionlp-icml-wkshp-03.ps.gz",
}

@Article{califf03:_bottom_up_relat_learn_patter,
  title =        "Bottom-Up Relational Learning of Pattern Matching
                 Rules for Information Extraction",
  author =       "Mary Elaine Califf and Raymond J. Mooney",
  journal =      "Journal of Machine Learning Research",
  volume =       "4",
  pages =        "177--210",
  year =         "2003",
  abstract =     "Information Extraction is a form of shallow text
                 processing that locates a specified set of relevant
                 items in a natural-language document. Systems for this
                 task require significant domain-specific knowledge and
                 are time-consuming and difficult to build by hand,
                 making them a good application for machine learning. We
                 present a aystem, RAPIER, that uses pairs of sample
                 documents and filled templates to induce pattern-match
                 rules that directly extract fillers for the slots in
                 the template. RAPIER employs a bottom-up learning
                 algorithm which incorporates techniques from several
                 inductive logic programming systems and acquires
                 unbounded patterns that include constraints on the
                 words, part-of-speech tags, and semantic classes
                 present in the filler and the surrounding text. We
                 present encouraging experimental results on two
                 domains.",
  URL =          "http://www.cs.utexas.edu/users/ml/publication/paper.cgi?paper=rapier-jmlr-03.ps.gz",
}

@Article{thompson:jair03,
  author =       "Cynthia A. Thompson and Raymond J. Mooney",
  title =        "Acquiring Word-Meaning Mappings for Natural Language
                 Interfaces",
  journal =      "Journal of Artificial Intelligence Research",
  volume =       "18",
  pages =        "1--44",
  year =         "2003",
  abstract =     "This paper focuses on a system, Wolfie (WOrd Learning
                 From Interpreted Examples), that acquires a semantic
                 lexicon from a corpus of sentences paired with semantic
                 representations. The lexicon learned consists of
                 phrases paired with meaning representations. Wolfie is
                 part of an integrated system that learns to parse
                 representations such as logical database queries.
                 Experimental results are presented demonstrating
                 Wolfie's ability to learn useful lexicons for a
                 database interface in four different natural languages.
                 The usefulness of the lexicons learned by Wolfie are
                 compared to those acquired by a similar system
                 developed by Siskind (1996), with results favorable to
                 Wolfie. A second set of experiments demonstrates
                 Wolfie's ability to scale to larger and more difficult,
                 albeit artificially generated, corpora. In natural
                 language acquisition, it is difficult to gather the
                 annotated data needed for supervised learning; however,
                 unannotated data is fairly plentiful. Active learning
                 methods (Cohn, Atlas, \& Ladner, 1994) attempt to
                 select for annotation and training only the most
                 informative examples, and therefore are potentially
                 very useful in natural language applications. However,
                 most results to date for active learning have only
                 considered standard classification tasks. To reduce
                 annotation effort while maintaining accuracy, we apply
                 active learning to semantic lexicons. We show that
                 active learning can significantly reduce the number of
                 annotated examples required to achieve a given level of
                 performance.",
  URL =          "http://www.cs.utexas.edu/users/ml/publication/paper.cgi?paper=wolfie-jair-03.ps.gz",
}

@InProceedings{aitken02:_learn_infor_extrac_rules,
  author =       "Stuart Aitken",
  title =        "Learning Information Extraction Rules: An Inductive
                 Logic Programming approach",
  booktitle =    "Proceedings of the 15th European Conference on
                 Artificial Intelligence",
  year =         "2002",
  editor =       "F. van Harmelen",
  address =      "Amsterdam",
  publisher =    "{IOS} Press",
  URL =          "http://www.aiai.ed.ac.uk/%7Estuart/AKT/ilp-ie.html",
}

@TechReport{aitken02:_learn_natur_languag_data_ilp,
  author =       "Stuart Aitken",
  title =        "Learning from Natural Language Data using {ILP}: The
                 Role of Background Knowledge and Negative Examples",
  institution =  "University of Edinburgh",
  year =         "2002",
  URL =          "http://www.aiai.ed.ac.uk/%7Estuart/AKT/ilp-ie.html",
}

@Article{molla.cbgi02,
  author =       "M. Molla and P. Andreae and J. Glasner and F. Blattner
                 and Jude Shavlik",
  title =        "Interpreting Microarray Expression Data Using Text
                 Annotating the Genes",
  journal =      "Information Sciences",
  volume =       "146",
  year =         "2002",
  pages =        "75--88",
  abstract =     "Microarray expression data is being generated by the
                 gigabyte all over the world with undoubted exponential
                 increases to come. Annotated genomic data is also
                 rapidly pouring into public databases. Our goal is to
                 develop automated ways of combining these two sources
                 of information to produce insight into the operation of
                 cells under various conditions. Our approach is to use
                 machine-learning techniques to identify characteristics
                 of genes that are up-regulated or down-regulated in a
                 particular microarray experiment. We seek models that
                 are (a) accurate, (b) easy to interpret, and (c) stable
                 to small variations in the training data. This paper
                 explores the effectiveness of two standard
                 machine-learning algorithms for this task: Naive Bayes
                 (based on probability) and PFOIL (based on building
                 rules). Although we do not anticipate using our learned
                 models to predict expression levels of genes, we cast
                 the task in a predictive framework, and evaluate the
                 quality of the models in terms of their predictive
                 power on genes held out from the training. The paper
                 reports on experiments using actual E. coli microarray
                 data, discussing the strengths and weaknesses of the
                 two algorithms and demonstrating the trade-offs between
                 accuracy, comprehensibility, and stability.",
  URL =          "http://www.cs.wisc.edu/%7Eshavlik/abstracts/molla.cbgi02.abstract.html",
}

@Article{Ned02,
  author =       "Claire N\'{e}dellec",
  title =        "Bibliographical Information Extraction in Genomics",
  journal =      "IEEE Intelligent Systems: Trends \& Controversies -
                 Mining Information for Functional Genomics",
  editor =       "N. Shadbolt",
  pages =        "76--78",
  month =        may # "--" # jun,
  year =         "2002",
}

@Conference{NED02B,
  author =       "Claire N\'{e}dellec",
  title =        "Machine Learning Applied to Information Extraction in
                 specific domains. An Example: gene interaction
                 extraction from bibliography in genomics.",
  booktitle =    "Proceedings of the second 2nd ECML/PKDD'2002 Workshop
                 on Semantic Web Mining, Helsinki, Finland",
  editor =       "Berendt B. et al.",
  pages =        "1--7",
  month =        aug,
  year =         "2002",
}

@InProceedings{CumbyRo03,
  author =       "C. Cumby and Dan Roth",
  title =        "Feature Extraction Languages for Propositionalized
                 Relational Learning",
  booktitle =    "IJCAI Workshop on Learning Statistical Models from
                 Relational Data",
  year =         "2003",
  URL =          "http://l2r.cs.uiuc.edu/%7Edanr/Papers/CumbyRo03.pdf",
}

@InProceedings{CumbyRo03a,
  author =       "C. Cumby and Dan Roth",
  title =        "On Kernel Methods for Relational Learning",
  booktitle =    "Proc. of the International Conference on Machine
                 Learning (ICML)",
  year =         "2003",
  comment =      "Parameterized kernels over structures. Relational
                 Kernels. Advantages and disadvantages of graph
                 kernels.",
  URL =          "http://l2r.cs.uiuc.edu/%7Edanr/Papers/CumbyRo03a.pdf",
}

@InProceedings{BrazRo03,
  author =       "R. de Salvo Braz and Dan Roth",
  title =        "Functional subsumption in Description Logics",
  booktitle =    "The Conference on Advances in Neural Information
                 Processing Systems (NIPS) Workshop on Feature
                 Extraction and Selection",
  month =        dec,
  year =         "2003",
  comment =      "Relational Feature Extraction; Feature Description
                 Logic",
  URL =          "http://l2r.cs.uiuc.edu/%7Edanr/Papers/BrazRo03.pdf",
}

@InProceedings{CumbyRo02,
  author =       "C. Cumby and Dan Roth",
  title =        "Learning with Feature Description Logics",
  booktitle =    "Proc. of the International Conference Inductive Logic
                 Programming",
  year =         "2002",
  comment =      "A Description Logic based Formalism for Feature
                 Extraction; Expressive Features; A language for Feature
                 Extraction",
  URL =          "http://l2r.cs.uiuc.edu/%7Edanr/Papers/ilp02.pdf",
}

@InProceedings{RothYi01,
  author =       "Dan Roth and W. Yih",
  title =        "Relational Learning via Propositional Algorithms: An
                 Information Extraction Case Study",
  booktitle =    "Proc. of the International Joint Conference on
                 Artificial Intelligence (IJCAI)",
  year =         "2001",
  pages =        "1257--1263",
  URL =          "http://l2r.cs.uiuc.edu/%7Edanr/Papers/ijcai01.pdf",
  comment =      "Expressive, Relational Features for Information
                 Extraction",
}

@InProceedings{tang:ecml01,
  title =        "Using Multiple Clause Constructors in Inductive Logic
                 Programming for Semantic Parsing",
  author =       "L. R. Tang and Raymond J. Mooney",
  booktitle =    "Proceedings of the 12th European Conference on Machine
                 Learning",
  address =      "Freiburg, Germany",
  pages =        "466--477",
  year =         "2001",
  abstract =     "In this paper, we explored a learning approach which
                 combines different learning methods in inductive logic
                 programming (ILP) to allow a learner to produce more
                 expressive hypothese than that of each individual
                 learner. Such a learning approach may be useful when
                 the performance of the task depends on solving a large
                 amount of classification problems and each has its own
                 characteristics which may or may not fit a particular
                 learning method. The task of sematnic parser
                 acquisition in two different domains was attempted and
                 preliminary results demonstrated that such an approach
                 is promising.",
  URL =          "http://www.cs.utexas.edu/users/ml/publication/paper.cgi?paper=cocktail-ecml-01.ps.gz",
}

@InProceedings{eliassi-rad.icml01,
  filename =     "eliassi-rad.icml01.pdf eliassi-rad.icml01.ps",
  author =       "T. Eliassi-Rad and Jude Shavlik",
  title =        "A Theory-Refinement Approach to Information
                 Extraction",
  booktitle =    "Proceedings of the Eighteenth International Conference
                 on Machine Learning",
  year =         "2001",
  address =      "Williamstown, MA",
  abstract =     "We investigate applying theory refinement to the task
                 of extracting information from text. In theory
                 refinement, partial domain knowledge (which may be
                 incorrect) is given to a supervised learner. The
                 provided knowledge guides the learner in its task, but
                 the learner can refine or even discard this knowledge
                 during training. Our supervised learner is a
                 knowledge-based neural network that initially contains
                 compiled prior knowledge about a particular information
                 extraction (IE) task. The prior knowledge needs to
                 specify the extraction slots for the specific IE task.
                 Our approach uses generate-and-test to address the IE
                 task. In the generation step, we produce candidate
                 extractions by intelligently searching the space of
                 possible extractions. In the test step, we use the
                 trained network to judge each candidate and output
                 those that exceed a system-selected threshold.
                 Experiments on the CMU seminar-announcements and the
                 Yeast subcellular-localization domains demonstrate our
                 approach's value.",
  URL =          "http://www.cs.wisc.edu/%7Eshavlik/abstracts/eliassi-rad.icml01.abstract.html",
}

@InProceedings{CumbyRo00,
  author =       "C. Cumby and Dan Roth",
  title =        "Relational Representations that facilitate learning",
  booktitle =    "Proc. of the International Conference on the
                 Principles of Knowledge Representation and Reasoning",
  pages =        "425--434",
  year =         "2000",
  URL =          "http://l2r.cs.uiuc.edu/%7Edanr/Papers/kr00.pdf",
  comment =      "FEX: feature extraction language; relational features;
                 relational generation functions",
}

@InProceedings{KhardonRoVa99,
  title =        "Relational Learning for {NLP} using Linear Threshold
                 Elements",
  author =       "Roni Khardon and Dan Roth and L. G. Valiant",
  booktitle =    "Proc. of the International Joint Conference on
                 Artificial Intelligence (IJCAI)",
  year =         "1999",
  pages =        "911--917",
  URL =          "http://l2r.cs.uiuc.edu/%7Edanr/Papers/ijcai99krv.pdf",
}

@InProceedings{ZelMoo93-AAAI93,
  author =       "John M. Zelle and Raymond J. Mooney",
  title =        "Learning Semantic Grammars with Constructive Inductive
                 Logic Programming",
  booktitle =    AAAI93,
  pages =        "817--822",
  publisher =    "AAAI Press/MIT Press",
  year =         "1993",
  keywords =     "Language_Learning",
  month =        jul,
  address =      "Washington, D.C.",
  URL =          "ftp://ftp.cs.utexas.edu/pub/mooney/papers/chill-aaai-93.ps.Z",
  abstract =     "Automating the construction of semantic grammars is a
                 difficult and interesting problem for machine learning.
                 This paper shows how the semantic-grammar acquisition
                 problem can be viewed as the learning of search-control
                 heuristics in a logic program. Appropriate control
                 rules are learned using a new first-order induction
                 algorithm that automatically invents useful syntactic
                 and semantic categories. Empirical results show that
                 the learned parsers generalize well to novel sentences
                 and out-perform previous approaches based on
                 connectionist techniques.",
}

@InProceedings{ZelMoo94-AAAI94,
  author =       "John M. Zelle and Raymond J. Mooney",
  title =        "Inducing Deterministic {P}rolog Parsers from
                 TreeBanks: {A} Machine Learning Approach",
  booktitle =    AAAI94,
  pages =        "748--753",
  publisher =    "AAAI Press/MIT Press",
  year =         "1994",
  keywords =     "Language_Learning",
  month =        aug,
  address =      "Seattle, WA",
  URL =          "ftp://ftp.cs.utexas.edu/pub/mooney/papers/chill-aaai-94.ps.Z",
  abstract =     "This paper presents a method for constructing
                 deterministic, context-sensitive, Prolog parsers from
                 corpora of parsed sentences. Our approach uses recent
                 machine learning methods for inducing Prolog rules from
                 examples (inductive logic programming). We discuss
                 several advantages of this method compared to recent
                 statistical methods and present results on learning
                 complete parsers from portions of the ATIS corpus.",
}

@InProceedings{ZelThoCal95-ILP95,
  keywords =     "Language_Learning",
  author =       "John M. Zelle and Cynthia A. Thompson and Mary Elaine
                 Califf and Raymond J. Mooney",
  title =        "Inducing Logic Programs without Explicit Negative
                 Examples",
  editor =       "Luc De Raedt",
  publisher =    DEPTCW,
  pages =        "403--416",
  booktitle =    ILP95,
  year =         "1995",
  abstract =     "This paper presents a method for learning logic
                 programs without explicit negative examples by
                 exploiting an assumption of {\em output completeness}.
                 A mode declaration is supplied for the target predicate
                 and each training input is assumed to be accompanied by
                 all of its legal outputs. Any other outputs generated
                 by an incomplete program implicitly represent negative
                 examples; however, large numbers of ground negative
                 examples never need to be generated. This method has
                 been incorporated into two ILP systems, CHILLIN and
                 IFOIL, both of which use intensional background
                 knowledge. Tests on two natural language acquisition
                 tasks, case-role mapping and past-tense learning,
                 illustrate the advantages of the approach.",
  URL =          "ftp://ftp.cs.utexas.edu/pub/mooney/papers/chill-ifoil-ml-95.ps.Z",
}

@Article{MooCal95:jrnl,
  author =       "Raymond J. Mooney and Mary Elaine Califf",
  title =        "Induction of First--Order Decision Lists: {R}esults on
                 Learning the Past Tense of {E}nglish Verbs",
  journal =      "Journal of Artificial Intelligence Research",
  volume =       "3",
  pages =        "1--24",
  year =         "1995",
  keywords =     "Language_Learning",
  URL =          "ftp://ftp.cs.utexas.edu/pub/mooney/papers/foidl-jair-95.ps.Z",
  abstract =     "This paper presents a method for inducing logic
                 programs from examples that learns a new class of
                 concepts called first-order decision lists, defined as
                 ordered lists of clauses each ending in a cut. The
                 method, called FOIDL, is based on FOIL but employs
                 intensional background knowledge and avoids the need
                 for explicit negative examples. It is particularly
                 useful for problems that involve rules with specific
                 exceptions, such as learning the past-tense of English
                 verbs, a task widely studied in the context of the
                 symbolic/connectionist debate. FOIDL is able to learn
                 concise, accurate programs for this problem from
                 significantly fewer examples than previous methods
                 (both connectionist and symbolic).",
}

@PhdThesis{zelle:thesis95,
  author =       "John M. Zelle",
  title =        "Using {I}nductive {L}ogic {P}rogramming to Automate
                 the Construction of Natural Language Parsers",
  year =         "1995",
  month =        aug,
  address =      "Austin, TX",
  school =       "Department of Computer Sciences, University of Texas",
  note =         "Also appears as Artificial Intelligence Laboratory
                 Technical Report AI 96-249",
  keywords =     "Language_Learning",
  URL =          "ftp://ftp.cs.utexas.edu/pub/mooney/papers/chill-dissertation-95.ps.Z",
  abstract =     "Designing computer systems to understand natural
                 language input is a difficult task. In recent years
                 there has been considerable interest in corpus-based
                 methods for constructing natural language parsers.
                 These empirical approaches replace hand-crafted
                 grammars with linguistic models acquired through
                 automated training over language corpora. A common
                 thread among such methods to date is the use of
                 propositional or probablistic representations for the
                 learned knowledge. This dissertation presents an
                 alternative approach based on techniques from a
                 subfield of machine learning known as inductive logic
                 programming (ILP). ILP, which investigates the learning
                 of relational (first-order) rules, provides an
                 empirical method for acquiring knowledge within
                 traditional, symbolic parsing frameworks. This
                 dissertation details the architecture, implementation
                 and evaluation of CHILL a computer system for acquiring
                 natural language parsers by training over corpora of
                 parsed text. CHILL treats language acquisition as the
                 learning of search-control rules within a logic program
                 that implements a shift-reduce parser. Control rules
                 are induced using a novel ILP algorithm which handles
                 difficult issues arising in the induction of
                 search-control heuristics. Both the control-rule
                 framework and the induction algorithm are crucial to
                 CHILL's success. The main advantage of CHILL over
                 propositional counterparts is its flexibility in
                 handling varied representations. CHILL has produced
                 parsers for various analyses including case-role
                 mapping, detailed syntactic parse trees, and a logical
                 form suitable for expressing first-order database
                 queries. All of these tasks are accomplished within the
                 same framework, using a single, general learning method
                 that can acquire new syntactic and semantic categories
                 for resolving ambiguities. Experimental evidence from
                 both aritificial and real-world corpora demonstrate
                 that CHILL learns parsers as well or better than
                 previous artificial neural network or probablistic
                 approaches on comparable tasks. In the database query
                 domain, which goes beyond the scope of previous
                 empirical approaches, the learned parser outperforms an
                 existing hand-crafted system. These results support the
                 claim that ILP techniques as implemented in CHILL
                 represent a viable alternative with significant
                 potential advantages over neural-network,
                 propositional, and probablistic approaches to empirical
                 parser construction.",
}

@InProceedings{thompson:acl95,
  author =       "Cynthia A. Thompson",
  title =        "Acquisition of a Lexicon from Semantic Representations
                 of Sentences",
  year =         "1995",
  pages =        "335--337",
  keywords =     "Language_Learning",
  booktitle =    "Proceedings of the 33rd Annual Meeting of the
                 Association for Computational Linguistics",
  address =      "Cambridge, MA",
  URL =          "ftp://ftp.cs.utexas.edu/pub/mooney/papers/wolfie-acl-95.ps.Z",
  abstract =     "A system, WOLFIE, that acquires a mapping of words to
                 their semantic representation is presented and a
                 preliminary evaluation is performed. Tree least general
                 generalizations (TLGGs) of the representations of input
                 sentences are performed to assist in determining the
                 representations of individual words in the sentences.
                 The best guess for a meaning of a word is the TLGG
                 which overlaps with the highest percentage of sentence
                 representations in which that word appears. Some
                 promising experimental results on a non-artificial data
                 set are presented.",
}

@InProceedings{ZelMoo96-AAAI96,
  author =       "John M. Zelle and Raymond J. Mooney",
  title =        "Learning to Parse Database Queries Using Inductive
                 Logic Programming",
  booktitle =    AAAI96,
  pages =        "1050--1055",
  publisher =    "AAAI Press/MIT Press",
  year =         "1996",
  keywords =     "Language_Learning",
  month =        aug,
  address =      "Portland, OR",
  URL =          "ftp://ftp.cs.utexas.edu/pub/mooney/papers/chill-aaai-96.ps.Z",
  abstract =     "This paper presents recent work using the CHILL parser
                 acquisition system to automate the construction of a
                 natural-language interface for database queries. CHILL
                 treats parser acquisition as the learning of
                 search-control rules within a logic program
                 representing a shift-reduce parser and uses techniques
                 from Inductive Logic Programming to learn relational
                 control knowledge. Starting with a general framework
                 for constructing a suitable logical form, CHILL is able
                 to train on a corpus comprising sentences paired with
                 database queries and induce parsers that map subsequent
                 sentences directly into executable queries.
                 Experimental results with a complete database-query
                 application for U.S. geography show that CHILL is able
                 to learn parsers that outperform a pre-existing,
                 hand-crafted counterpart. These results demonstrate the
                 ability of a corpus-based system to produce more than
                 purely syntactic representations. They also provide
                 direct evidence of the utility of an empirical approach
                 at the level of a complete natural language
                 application.",
}

@InProceedings{Moo96-ILP96,
  author =       "Raymond J. Mooney",
  title =        "Inductive Logic Programming for Natural Language
                 Processing",
  booktitle =    ILP96,
  series =       LNAI,
  volume =       "1314",
  editor =       "S. Muggleton",
  publisher =    SV,
  pages =        "3--24",
  year =         "1996",
  keywords =     "Language_Learning",
  URL =          "ftp://ftp.cs.utexas.edu/pub/mooney/papers/chill-ilp-96.ps.Z",
  abstract =     "This paper reviews our recent work on applying
                 inductive logic programming to the construction of
                 natural language processing systems. We have developed
                 a system, CHILL, that learns a parser from a training
                 corpus of parsed sentences by inducing heuristics that
                 control an initial overly-general shift-reduce parser.
                 CHILL learns syntactic parsers as well as ones that
                 translate English database queries directly into
                 executable logical form. The ATIS corpus of airline
                 information queries was used to test the acquisition of
                 syntactic parsers, and CHILL performed competitively
                 with recent statistical methods. English queries to a
                 small database on U.S. geography were used to test the
                 acquisition of a complete natural language interface,
                 and the parser that CHILL acquired was more accurate
                 than an existing hand-coded system. The paper also
                 includes a discussion of several issues this work has
                 raised regarding the capabilities and testing of ILP
                 systems as well as a summary of our current research
                 directions.",
}

@InCollection{zelle:bkchapter96,
  author =       "John M. Zelle and Raymond J. Mooney",
  title =        "Comparative Results on Using Inductive Logic
                 Programming for Corpus-based Parser Construction",
  year =         "1996",
  pages =        "355--369",
  keywords =     "Language_Learning",
  editor =       "S. Wermter and E. Riloff and G. Scheler",
  booktitle =    "Connectionist, Statistical, and Symbolic Approaches to
                 Learning for Natural Language Processing",
  address =      "Berlin",
  publisher =    "Springer",
  URL =          "ftp://ftp.cs.utexas.edu/pub/mooney/papers/chill-bkchapter-95.ps.Z",
  abstract =     "This paper presents results from recent experimenets
                 with CHILL, a corpus-based parser acquisition system.
                 CHILL treats language acquisition as the learning of
                 search-control rules within a logic program. Unlike
                 many current corpus-based approaches that use
                 statistical learning algorithms, CHILL uses techniques
                 from inductive logic programming (ILP) to learn
                 relational representations. CHILL is a very flexible
                 system and has been used to learn parsers that produce
                 syntactic parse trees, case-role analyses, and
                 executable database queries. The reported experiments
                 compare CHILL's performance to that of a more naive
                 application of ILP to parser acquisition. The results
                 show that ILP techniques, as employed in CHILL, are a
                 viable alternative to statistical methods and that the
                 control-rule framework is fundamental to CHILL's
                 success.",
}

@InCollection{mooney:bkchapter96,
  author =       "Raymond J. Mooney and Mary Elaine Califf",
  title =        "Learning the Past Tense of English Verbs Using
                 Inductive Logic Programming",
  year =         "1996",
  pages =        "370--384",
  keywords =     "Language_Learning",
  editor =       "S. Wermter and E. Riloff and G. Scheler",
  booktitle =    "Connectionist, Statistical, and Symbolic Approaches to
                 Learning for Natural Language Processing",
  address =      "Berlin",
  publisher =    "Springer",
  URL =          "ftp://ftp.cs.utexas.edu/pub/mooney/papers/foidl-bkchapter-95.ps.Z",
  abstract =     "This paper presents results on using a new inductive
                 logic programming method called FOIDL to learn the past
                 tense of English verbs. The past tense task has been
                 widely studied in the context of the
                 symbolic/connectionist debate. Previous papers have
                 presented results using various neural-network and
                 decision-tree learning methods. We have developed a
                 technique for learning a special type of Prolog program
                 called a first-order decision list, defined as an
                 ordered list of clauses each ending in a cut. FOIDL is
                 based on FOIL (Quinlan, 1990) but employs intensional
                 background knowledge and avoids the need for explicit
                 negative examples. It is particularly useful for
                 problems that involve rules with specific exceptions,
                 such as the past-tense task. We present results showing
                 that FOIDL learns a more accurate past-tense generator
                 from significantly fewer examples than all other
                 previous methods.",
}

@TechReport{Cus96a:tr,
  author =       "James Cussens",
  title =        "Part-of-speech disambiguation using {ILP}",
  year =         "1996",
  number =       "PRG-TR-25-96",
  institution =  "Oxford University Computing Laboratory",
  keywords =     "Language_Learning",
  URL =          "ftp://ftp.cs.york.ac.uk/pub/ML_GROUP/Papers/prg-tr-25-96.ps.gz",
}

@InProceedings{ZolCsirGyiJel97-ILP97,
  keywords =     "Language_Learning",
  author =       "Zolt\'{a}n Alexin and J\'{a}nos Csirik and Tibor
                 Gyim\'{o}thy and M. Jelasity",
  title =        "Learning Phonetic Rules in Speech Recognition System",
  booktitle =    ILP97,
  series =       LNAI,
  volume =       "1297",
  editor =       "Sa\v{s}o D\v{z}eroski and Nada Lavra\v{c}",
  publisher =    SV,
  pages =        "37--44",
  year =         "1997",
}

@InProceedings{Cus97-ILP97,
  keywords =     "Language_Learning",
  author =       "James Cussens",
  title =        "Part-of-Speech Tagging Using Progol",
  booktitle =    ILP97,
  series =       LNAI,
  volume =       "1297",
  editor =       "Sa\v{s}o D\v{z}eroski and Nada Lavra\v{c}",
  publisher =    SV,
  pages =        "93--108",
  year =         "1997",
  abstract =     "A system for `tagging' words with their part-of-speech
                 (POS) tags is constructed. The system has two
                 components: a lexicon containing the set of possible
                 POS tags for a given word, and rules which use a word's
                 context to {\em eliminate} possible tags for a word.
                 The Inductive Logic Programming (ILP) system Progol is
                 used to induce these rules in the form of definite
                 clauses. The final theory contained 885 clauses. For
                 background knowledge, Progol uses a simple grammar,
                 where the tags are terminals and predicates such as
                 {\tt nounp} (noun phrase) are nonterminals. Progol was
                 altered to allow the caching of information about
                 clauses generated during the induction process which
                 greatly increased efficiency. The system achieved a
                 per-word accuracy of 96.4\% on known words drawn from
                 sentences without quotation marks. This is on a par
                 with other tagging systems induced from the same data
                 %\cite{DaeZavBerGil96-WVLC96,Bri94-AAAI94,CutKupPedSib92-ANLP92}
                 which all have accuracies in the range 96--97\%. The
                 per-sentence accuracy was 49.5\%.",
  URL =          "ftp://ftp.cs.york.ac.uk/pub/ML_GROUP/Papers/ilp97.ps.gz",
}

@InProceedings{DehRae97-ILP97,
  keywords =     "Language_Learning",
  author =       "Luc Dehaspe and Luc De Raedt",
  title =        "Mining Association Rules in Multiple Relations",
  booktitle =    ILP97,
  series =       LNAI,
  volume =       "1297",
  editor =       "Sa\v{s}o D\v{z}eroski and Nada Lavra\v{c}",
  publisher =    SV,
  pages =        "125--132",
  year =         "1997",
}

@InProceedings{DzeErj97-ILP97,
  keywords =     "Language_Learning",
  author =       "Sa\v{s}o D\v{z}eroski and Toma\v{z} Erjavec",
  title =        "Induction of {S}lovene Nominal Paradigms",
  booktitle =    ILP97,
  series =       LNAI,
  volume =       "1297",
  editor =       "Sa\v{s}o D\v{z}eroski and Nada Lavra\v{c}",
  publisher =    SV,
  pages =        "141--148",
  year =         "1997",
}

@TechReport{BosZem97,
  author =       "Henrik Bostr{\"{o}}m and Stefan Zemke",
  title =        "Learning Transfer Rules by Inductive Logic Programming
                 (Preliminary Report)",
  year =         "1997",
  institution =  "Stockholm University",
  keywords =     "Language_Learning",
}

@InProceedings{califf:aclwkshp97,
  author =       "Mary Elaine Califf and Raymond J. Mooney",
  title =        "Relational Learning of Pattern-Match Rules for
                 Information Extraction",
  year =         "1997",
  pages =        "9--15",
  keywords =     "Language_Learning",
  booktitle =    "Proceedings of the ACL Workshop on Natural Language
                 Learning",
  month =        jul,
  address =      "Madrid, Spain",
  URL =          "ftp://ftp.cs.utexas.edu/pub/mooney/papers/rapier-acl-wkshp-97.ps.Z",
  abstract =     "Information extraction systems process natural
                 language documents and locate a specific set of
                 relevant items. Given the recent success of empirical
                 or corpus-based approaches in other areas of natural
                 language processing, machine learning has the potential
                 to significantly aid the development of these
                 knowledge-intensive systems. This paper presents a
                 system, RAPIER, that takes pairs of documents and
                 filled templates and induces pattern-match rules that
                 directly extract fillers for the slots in the template.
                 The learning algorithm incorporates techniques from
                 several inductive logic programming systems and learns
                 unbounded patterns that include constraints on the
                 words and part-of-speech tags surrounding the filler.
                 Encouraging results are presented on learning to
                 extract information from computer job postings from the
                 newsgroup misc.jobs.offered.",
}

@InProceedings{CusPagMugSri97:ECML97,
  author =       "James Cussens and David Page and Stephen Muggleton and
                 Ashwin Srinivasan",
  title =        "Using {Inductive Logic Programming} for {Natural
                 Language Processing}",
  year =         "1997",
  pages =        "25--34",
  note =         "Invited keynote paper",
  keywords =     "Language_Learning",
  editor =       "W. Daelemans and T. Weijters and A. van der Bosch",
  booktitle =    "{ECML'97} -- Workshop Notes on Empirical Learning of
                 Natural Language Tasks",
  address =      "Prague",
  publisher =    "University of Economics",
  URL =          "ftp://ftp.cs.york.ac.uk/pub/ML_GROUP/Papers/ecml97mlnet.ps.gz",
  abstract =     "We summarise recent work on using Inductive Logic
                 Programming (ILP) for Natural Language Processing
                 (NLP). ILP performs learning in a first-order logical
                 setting, and is thus well-suited to induce over the
                 various structured representations used in NLP. We
                 present Stochastic Logic Programs (SLPs) and
                 demonstrate their use in ILP when learning from
                 positive examples only. We also give accounts of work
                 on learning grammars from children's books and
                 part-of-speech tagging.",
}

@TechReport{MilPul97,
  author =       "David Milward and Steve Pulman",
  title =        "Transfer Learning using {QLF}s",
  year =         "1997",
  institution =  "{SRI} International",
  note =         "Prepared for Royal Institute for Technology, Sweden",
  keywords =     "Language_Learning",
}

@InProceedings{Cus98-ILP98,
  keywords =     "Language_Learning",
  author =       "James Cussens",
  title =        "Using Prior Probabilities and Density Estimation for
                 Relational Classification",
  booktitle =    ILP98,
  series =       LNAI,
  volume =       "1446",
  editor =       "D. Page",
  publisher =    SV,
  pages =        "106--115",
  year =         "1998",
}

@InProceedings{EinLin98-ILP98,
  keywords =     "Language_Learning",
  author =       "Martin Eineborg and Nikolaj Lindberg",
  title =        "Induction of Constraint Grammar-Rules Using Progol",
  booktitle =    ILP98,
  series =       LNAI,
  volume =       "1446",
  editor =       "D. Page",
  publisher =    SV,
  pages =        "116--124",
  year =         "1998",
}

@InProceedings{KazMan98-ILP98,
  keywords =     "Language_Learning",
  author =       "Dimitar Kazakov and S. Manandhar",
  title =        "A Hybrid Approach to Word Segmentation",
  booktitle =    ILP98,
  series =       LNAI,
  volume =       "1446",
  editor =       "D. Page",
  publisher =    SV,
  pages =        "125--134",
  year =         "1998",
}

@InProceedings{ManDzeErj98-ILP98,
  keywords =     "Language_Learning",
  author =       "S. Manandhar and Sa\v{s}o D\v{z}eroski and Toma\v{z}
                 Erjavec",
  title =        "Learning Multilingual Morphology with {CLOG}",
  booktitle =    ILP98,
  series =       LNAI,
  volume =       "1446",
  editor =       "D. Page",
  publisher =    SV,
  pages =        "135--144",
  year =         "1998",
}

@Misc{LLL-Kaz,
  author =       "Dimitar Kazakov and Stephen Pulman and Stephen
                 Muggleton",
  title =        "The {F}ra{C}a{S} Dataset and the {LLL} Challenge",
  year =         "1998",
  month =        jul,
  howpublished = "{ILP2} project paper",
  keywords =     "Language_Learning",
}

@InProceedings{ACL98-LinEin,
  author =       "Nikolaj Lindberg and Martin Eineborg",
  title =        "Learning Constraint Grammar-style disambiguation rules
                 using Inductive Logic Programming",
  year =         "1998",
  keywords =     "Language_Learning",
  booktitle =    "Proceedings COLING/ACL98",
}

@PhdThesis{califf:thesis98,
  author =       "Mary Elaine Califf",
  title =        "Relational Learning Techniques for Natural Language
                 Information Extraction",
  year =         "1998",
  month =        aug,
  address =      "Austin, TX",
  school =       "Department of Computer Sciences, University of Texas",
  note =         "Also appears as Artificial Intelligence Laboratory
                 Technical Report AI 98-276 (see
                 http://www.cs.utexas.edu/users/ai-lab)",
  keywords =     "Language_Learning",
  URL =          "ftp://ftp.cs.utexas.edu/pub/mooney/papers/rapier-dissertation-98.ps.Z",
  abstract =     "The recent growth of online information available in
                 the form of natural language documents creates a
                 greater need for computing systems with the ability to
                 process those documents to simplify access to the
                 information. One type of processing appropriate for
                 many tasks is information extraction, a type of text
                 skimming that retrieves specific types of information
                 from text. Although information extraction systems have
                 existed for two decades, these systems have generally
                 been built by hand and contain domain specific
                 information, making them difficult to port to other
                 domains. A few researchers have begun to apply machine
                 learning to information extraction tasks, but most of
                 this work has involved applying learning to pieces of a
                 much larger system. This dissertation presents a novel
                 rule representation specific to natural language and a
                 relational learning system, Rapier, which learns
                 information extraction rules. Rapier takes pairs of
                 documents and filled templates indicating the
                 information to be extracted and learns pattern-matching
                 rules to extract fillers for the slots in the template.
                 The system is tested on several domains, showing its
                 ability to learn rules for different tasks. Rapier's
                 performance is compared to a propositional learning
                 system for information extraction, demonstrating the
                 superiority of relational learning for some information
                 extraction tasks. Because one difficulty in using
                 machine learning to develop natural language processing
                 systems is the necessity of providing annotated
                 examples to supervised learning systems, this
                 dissertation also describes an attempt to reduce the
                 number of examples Rapier requires by employing a form
                 of active learning. Experimental results show that the
                 number of examples required to achieve a given level of
                 performance can be significantly reduced by this
                 method.",
}

@InProceedings{mecaliff:ss98,
  author =       "Mary Elaine Califf and Raymond J. Mooney",
  title =        "Relational Learning of Pattern-Match Rules for
                 Information Extraction",
  year =         "1998",
  pages =        "6--11",
  keywords =     "Language_Learning",
  booktitle =    "Working Notes of AAAI Spring Symposium on Applying
                 Machine Learning to Discourse Processing",
  address =      "Menlo Park, CA",
  publisher =    "AAAI Press",
  URL =          "ftp://ftp.cs.utexas.edu/pub/mooney/papers/rapier-aaaisymp-98.ps.Z",
  abstract =     "Information extraction is a form of shallow text
                 processing which locates a specified set of relevant
                 items in natural language documents. Such systems can
                 be useful, but require domain-specific knowledge and
                 rules, and are time-consuming and difficult to build by
                 hand, making infomation extraction a good testbed for
                 the application of machine learning techniques to
                 natural language processing. This paper presents a
                 system, RAPIER, that takes pairs of documents and
                 filled templates and induces pattern-match rules that
                 directly extract fillers for the slots in the template.
                 The learning algorithm incorporates techniques from
                 several inductive logic programming systems and learns
                 unbounded patterns that include constraints on the
                 words and part-of-speech tags surrounding the filler.
                 Encouraging results are presented on learning to
                 extract information from computer job postings from the
                 newsgroup misc.jobs.offered.",
}

@PhdThesis{thompson:thesis98,
  author =       "Cynthia Ann Thompson",
  title =        "Semantic Lexicon Acquisition for Learning Natural
                 Language Interfaces",
  year =         "1998",
  month =        dec,
  address =      "Austin, TX",
  school =       "Department of Computer Sciences, University of Texas",
  note =         "Also appears as Artificial Intelligence Laboratory
                 Technical Report AI 99-278 (see
                 http://www.cs.utexas.edu/users/ai-lab)",
  keywords =     "Language_Learning",
  URL =          "ftp://ftp.cs.utexas.edu/pub/mooney/papers/wolfie-dissertation-99.ps.Z",
  abstract =     "A long-standing goal for the field of artificial
                 intelligence is to enable computer understanding of
                 human languages. A core requirement in reaching this
                 goal is the ability to transform individual sentences
                 into a form better suited for computer manipulation.
                 This ability, called semantic parsing, requires several
                 knowledge sources, such as a grammar, lexicon, and
                 parsing mechanism. Building natural language parsing
                 systems by hand is a tedious, error-prone undertaking.
                 We build on previous research in automating the
                 construction of such systems using machine learning
                 techniques. The result is a combined system that learns
                 semantic lexicons and semantic parsers from one common
                 set of training examples. The input required is a
                 corpus of sentence/representation pairs, where the
                 representations are in the output format desired. A new
                 system, Wolfie, learns semantic lexicons to be used as
                 background knowledge by a previously developed parser
                 acquisition system, Chill. The combined system is
                 tested on a real world domain of answering database
                 queries. We also compare this combination to a
                 combination of Chill with a previously developed
                 lexicon learner, demonstrating superior performance
                 with our system. In addition, we show the ability of
                 the system to learn to process natural languages other
                 than English. Finally, we test the system on an
                 alternate sentence representation, and on a set of
                 large, artificial corpora with varying levels of
                 ambiguity and synonymy. One difficulty in using machine
                 learning methods for building natural language
                 interfaces is building the required annotated corpus.
                 Therefore, we also address this issue by using active
                 learning to reduce the number of training examples
                 required by both Wolfie and Chill. Experimental results
                 show that the number of examples needed to reach a
                 given level of performance can be significantly reduced
                 with this method.",
}

@Misc{ILP98tut-Cus,
  author =       "James Cussens",
  title =        "Notes on inductive logic programming methods in
                 natural language processing ({E}uropean work)",
  year =         "1998",
  month =        aug,
  note =         "Manuscript",
  URL =          "ftp://ftp.cs.york.ac.uk/pub/ML_GROUP/Papers/ilp98tut.ps.gz",
  abstract =     "The aim of these notes is to analyse ILP methods which
                 have been applied to NLP, drawing exclusively on work
                 conducted in Europe.",
  keywords =     "Language_Learning",
}

@TechReport{BosZem98,
  author =       "Henrik Bostr{\"{o}}m and Stefan Zemke",
  title =        "Report on Recent experiments",
  year =         "1998",
  month =        may,
  institution =  "Stockholm University",
  keywords =     "Language_Learning",
}

@InProceedings{ILP99-Cussens-etal,
  keywords =     "Language_Learning",
  author =       "James Cussens and Sa\v{s}o D\v{z}eroski and Toma\v{z}
                 Erjavec",
  title =        "Morphosyntactic Tagging of {S}lovene Using {P}rogol",
  booktitle =    ILP99,
  series =       LNAI,
  volume =       "1634",
  editor =       "Sa\v{s}o D\v{z}eroski and Peter Flach",
  publisher =    SV,
  year =         "1999",
  ISBN =         "3-540-66109-3",
  pages =        "68--79",
  abstract =     "We consider the task of tagging Slovene words with
                 morphosyntactic descriptions (MSDs). MSDs contain not
                 only part-of-speech information but also attributes
                 such as gender and case. In the case of Slovene there
                 are 2,083 possible MSDs. P-Progol was used to learn
                 morphosyntactic disambiguation rules from annotated
                 data (consisting of 161,314 examples) produced by the
                 MULTEXT-East project. P-Progol produced 1,148 rules
                 taking 36 hours. Using simple grammatical background
                 knowledge, e.g.\ looking for case disagreement,
                 P-Progol induced 4,094 clauses in eight parallel runs.
                 These rules have proved effective at detecting and
                 explaining incorrect MSD annotations in an independent
                 test set, but have not so far produced a tagger
                 comparable to other existing taggers in terms of
                 accuracy.",
}

@InProceedings{ILP99-Kazakov,
  keywords =     "Language_Learning",
  author =       "Dimitar Kazakov",
  title =        "Combining {LAPIS} and {WordNet} for the Learning of
                 {LR} Parsers with Optimal Semantic Constraints",
  booktitle =    ILP99,
  series =       LNAI,
  volume =       "1634",
  editor =       "Sa\v{s}o D\v{z}eroski and Peter Flach",
  publisher =    SV,
  year =         "1999",
  ISBN =         "3-540-66109-3",
  pages =        "140--151",
}

@InProceedings{ILP99-Kazakov-etal,
  keywords =     "Language_Learning",
  author =       "Dimitar Kazakov and Suresh Manandhar and Toma\v{z}
                 Erjavec",
  title =        "Learning Word Segmentation Rules for Tag Prediction",
  booktitle =    ILP99,
  series =       LNAI,
  volume =       "1634",
  editor =       "Sa\v{s}o D\v{z}eroski and Peter Flach",
  publisher =    SV,
  year =         "1999",
  ISBN =         "3-540-66109-3",
  pages =        "152--161",
}

@InProceedings{ILP99-Kijsirikul-Sinthupinyo,
  keywords =     "Language_Learning",
  author =       "B. Kijsirikul and S. Sinthupinyo",
  title =        "Approximate {ILP} Rules by Backpropagation Neural
                 Network: {A} Result on {T}hai Character Recognition",
  booktitle =    ILP99,
  series =       LNAI,
  volume =       "1634",
  editor =       "Sa\v{s}o D\v{z}eroski and Peter Flach",
  publisher =    SV,
  year =         "1999",
  ISBN =         "3-540-66109-3",
  pages =        "162--173",
}

@InProceedings{ILP99-Lindberg-Eineborg,
  keywords =     "Language_Learning",
  author =       "N. Lindberg and M. Eineborg",
  title =        "Improving Part-of-Speech Disambiguation Rules by
                 Adding Linguistic Knowledge",
  booktitle =    ILP99,
  series =       LNAI,
  volume =       "1634",
  editor =       "Sa\v{s}o D\v{z}eroski and Peter Flach",
  publisher =    SV,
  year =         "1999",
  ISBN =         "3-540-66109-3",
  pages =        "186--197",
}

@InProceedings{ILP99-Ramon-DeRaedt,
  keywords =     "Language_Learning",
  author =       "Jan Ramon and Luc De Raedt",
  title =        "Instance Based Function Learning",
  booktitle =    ILP99,
  series =       LNAI,
  volume =       "1634",
  editor =       "Sa\v{s}o D\v{z}eroski and Peter Flach",
  publisher =    SV,
  year =         "1999",
  ISBN =         "3-540-66109-3",
  pages =        "268--278",
  abstract =     "The principles of instance based function learning are
                 presented. In IBFL one is given a set of positive
                 examples of a functional predicate. These examples are
                 true ground facts that illustrate the input output
                 behaviour of the predicate. The purpose is then to
                 predict the output of the predicate given a new input.
                 Further assumptions are that there is no background
                 theory and that the inputs and outputs of the predicate
                 consist of structured terms. IBFL is a novel technique
                 that addresses this problem and that combines ideas
                 from instance based learning, first order distances and
                 analogical or case based reasoning. We also argue that
                 IBFL is especially useful when there is a need for
                 handling complex and deeply nested terms. Though we
                 present the technique in isolation, it might be more
                 useful as a component of a larger system to deal e.g.
                 with the logic, language and learning challenge.",
}

@PhdThesis{1999-kazakov,
  title =        "Natural Language Processing Applications of Machine
                 Learning",
  author =       "Dimitar Kazakov",
  school =       "Department of Cybernetics, Czech Technical University,
                 Prague",
  bpages =       "191",
  rpages =       "16",
  month =        may,
  year =         "1999",
  keywords =     "Bottom_Up_Induction,ILP_Application,Language_Learning",
  abstract =     "This thesis offers an overview of some of the machine
                 learning techniques used for the purposes of natural
                 language processing. The relationship between machine
                 learning and natural language processing is sketched
                 and the mutual importance of the two AI areas outlined.
                 The thesis describes two original projects. The first
                 one introduces the system Lapis aiming at the inductive
                 learning of LR parsers of natural language from
                 treebanks. Lexical semantic tags present in the
                 treebank are used to learn additional semantic
                 constraints for the parsers. The system combines
                 standard tools for parser development with original
                 software for the automatic generation of efficient
                 domain-adapted natural language parsers. In the second
                 project presented in this thesis, the author suggests a
                 bias for unsupervised word segmentation. To make the
                 optimisation process efficient, a genetic algorithm is
                 applied to reduce the search space and draw the first
                 draft of the word segmentations sought after. Then, a
                 set of rules for word segmentation are found and
                 expressed in a high-order formalism (first-order logic)
                 by the means of inductive logic programming techniques;
                 the application of those rules to the training data
                 produces the final word segmentations. The most
                 important advantages of the method are the large scale
                 of languages to which it is applicable, its ability to
                 produce useful results even from relatively small
                 datasets, and also the fact that minimal or no
                 preprocessing of the used data (raw lists of words or
                 tokenised text) is required.",
  pubtype =      "17",
}

@InProceedings{califf:aaai99,
  author =       "Mary Elaine Califf and Raymond J. Mooney",
  title =        "Relational Learning of Pattern-Match Rules for
                 Information Extraction",
  year =         "1999",
  keywords =     "Language_Learning",
  booktitle =    AAAI99,
  month =        jul,
  address =      "Orlando, FL",
  URL =          "ftp://ftp.cs.utexas.edu/pub/mooney/papers/rapier-aaai99.ps.Z",
  abstract =     "Information extraction is a form of shallow text
                 processing that locates a specified set of relevant
                 items in a natural-language document. Systems for this
                 task require significant domain-specific knowledge and
                 are time-consuming and difficult to build by hand,
                 making them a good application for machine learning.
                 This paper presents a system, Rapier, that takes pairs
                 of sample documents and filled templates and induces
                 pattern-match rules that directly extract fillers for
                 the slots in the template. Rapier employs a bottom-up
                 learning algorithm which incorporates techniques from
                 several inductive logic programming systems and
                 acquires unbounded patterns that include constraints on
                 the words, part-of-speech tags, and semantic classes
                 present in the filler and the surrounding text. We
                 present encouraging experimental results on two
                 domains.",
}

@InProceedings{thompson:aaai99,
  author =       "Cynthia A. Thompson and Raymond J. Mooney",
  title =        "Automatic Construction of Semantic Lexicons for
                 Learning Natural Language Interfaces",
  year =         "1999",
  keywords =     "Language_Learning",
  booktitle =    AAAI99,
  month =        jul,
  address =      "Orlando, FL",
  URL =          "ftp://ftp.cs.utexas.edu/pub/mooney/papers/wolfie-aaai99.ps.Z",
  abstract =     "This paper describes a system, Wolfie (WOrd Learning
                 From Interpreted Examples), that acquires a semantic
                 lexicon from a corpus of sentences paired with semantic
                 representations. The lexicon learned consists of words
                 paired with meaning representations. Wolfie is part of
                 an integrated system that learns to parse novel
                 sentences into semantic representations, such as
                 logical database queries. Experimental results are
                 presented demonstrating Wolfie's ability to learn
                 useful lexicons for a database interface in four
                 different natural languages. The lexicons learned by
                 Wolfie are compared to those acquired by a competing
                 system developed by Siskind.",
}

@InProceedings{brill:LLL99,
  author =       "Eric Brill",
  title =        "Toward linguistically sophisticated models of
                 language",
  booktitle =    LLL99,
  editor =       "James Cussens",
  year =         "1999",
  address =      "Bled, Slovenia",
  month =        jun,
  pages =        "5",
  keywords =     "Language_Learning",
  abstract =     "Much of the research done in the area of corpus-based
                 natural language processing over the last decade has
                 concerned itself with applying different machine
                 learning algorithms to core natural language processing
                 tasks. Very little work has gone into dermining what
                 currently unexploited linguistic cues could be used to
                 improve the accuracy at performing these tasks. For
                 example, there have been dozens of papers demonstrating
                 the efficacy of a wide assortment of learning
                 algorithms or part of speech tagging. Yet virtually all
                 of these algorithms use the same naive linguistic cues,
                 namely the words and tags within a window of two of the
                 word being tagged. The same is true for many other NLP
                 problems. We have developed a method for uncovering
                 linguistic cues that can help improve the accuracy of
                 machine-learned NLP systems. We have people postprocess
                 the output of an NLP system to try to make it more
                 accurate, and record the linguistic proficiencies that
                 they use in doing so. We can then measure how much
                 people can improve over the machine, and what
                 linguistic proficiencies are important in doing so. We
                 have applied this method to the outputs of a number of
                 speech recognition systems to help determine what
                 linguistic cues we should strive to include in language
                 models to improve beyond the linguistically naive
                 trigram model. In this talk, I will describe our
                 approach, outline what insight it has provided into
                 developing more sophisticated language models for
                 speech recognition, and discuss how we can generalize
                 these findings to find useful linguistic cues to more
                 accurately solve other NLP problems.",
  note =         "Abstract",
}

@InProceedings{briscoe:LLL99,
  author =       "Ted Briscoe",
  title =        "Bayesian Learning of (Stochastic) Grammars",
  booktitle =    LLL99,
  editor =       "James Cussens",
  year =         "1999",
  address =      "Bled, Slovenia",
  month =        jun,
  pages =        "6",
  keywords =     "Language_Learning",
  abstract =     "Current formulations of grammar learning are
                 inadequate in several ways. In theoretical linguistics,
                 most work dresses the learnability (in the limit / with
                 high probability) of a target grammar from a sequence
                 of triggers (defined as pairings of sentences and
                 meanings) through setting of a finite number of
                 finite-valued parameters via some efficient (and
                 empirically feasible) algorithm. In computational
                 linguistics, most work is based on statistical (usually
                 maximum likelihood) estimation of a stochastic grammar
                 / language model (usually a PCFG) from a sequence of
                 sentences. The former approach ignores the issue of
                 noisy / misclassified data. The latter results in
                 grammatically implausible models and defines the task
                 unrealistically in terms of global maximisation. Both
                 assume (counterfactually) that the data is sampled from
                 a stationary distribution, and that a (universal)
                 category set is available to the learner as background
                 knowledge. In this talk, I'll outline a modified
                 parameter setting model, linked to a constraint-based
                 grammatical representation language, which solves the
                 noisy / misclassified data problem using a simple
                 Bayesian estimation scheme which leads naturally to an
                 incremental learning model, typically conforming to the
                 Minimum Description Length Principle. Although this
                 model is statistical, it does not require global
                 maximisation, a stationary distribution or a universal
                 category set, and what is learnt is not a stochastic
                 grammar in the standard sense. Nevertheless,
                 preliminary work suggests that it is effective.",
  note =         "Abstract",
}

@InProceedings{mooney:LLL99,
  author =       "Ray Mooney",
  title =        "Learning for Semantic Interpretation: Scaling Up
                 Without Dumbing Down",
  booktitle =    LLL99,
  editor =       "James Cussens",
  year =         "1999",
  address =      "Bled, Slovenia",
  month =        jun,
  pages =        "7--15",
  keywords =     "Language_Learning",
  URL =          "http://www.cs.york.ac.uk/mlg/lll/workshop/proceedings/Mooney/Mooney.ps.gz",
}

@InProceedings{watkinson:LLL99,
  author =       "Stephen Watkinson and Suresh Manandhar",
  title =        "Unsupervised Lexical Learning with Categorial Grammars
                 using the {LLL} Corpus",
  booktitle =    LLL99,
  editor =       "James Cussens",
  year =         "1999",
  address =      "Bled, Slovenia",
  month =        jun,
  pages =        "16--27",
  keywords =     "Language_Learning",
  URL =          "http://www.cs.york.ac.uk/mlg/lll/workshop/proceedings/WatkinsonManandhar/WatkinsonManandhar.ps.gz",
}

@InProceedings{nedellec:LLL99,
  author =       "Claire N\'{e}dellec",
  title =        "Corpus-based learning of semantic relations by the
                 {ILP} system, {Asium}",
  booktitle =    LLL99,
  editor =       "James Cussens",
  year =         "1999",
  address =      "Bled, Slovenia",
  month =        jun,
  pages =        "28--39",
  keywords =     "Language_Learning",
  URL =          "http://www.cs.york.ac.uk/mlg/lll/workshop/proceedings/Nedellec/Nedellec.ps.gz",
}

@InProceedings{dehaspe:LLL99,
  author =       "Luc Dehaspe and Maarten Forrier",
  title =        "Transformation-Based Learning meets Frequent Pattern
                 Discovery",
  booktitle =    LLL99,
  editor =       "James Cussens",
  year =         "1999",
  address =      "Bled, Slovenia",
  month =        jun,
  pages =        "40--51",
  keywords =     "Language_Learning",
  URL =          "http://www.cs.york.ac.uk/mlg/lll/workshop/proceedings/DehaspeForrier/DehaspeForrier.ps.gz",
}

@InProceedings{bostrom:LLL99,
  author =       "Henrik Bostr{\"{o}}m",
  title =        "Induction of Recursive Transfer Rules",
  booktitle =    LLL99,
  editor =       "James Cussens",
  year =         "1999",
  address =      "Bled, Slovenia",
  month =        jun,
  pages =        "52--62",
  keywords =     "Language_Learning",
  URL =          "http://www.cs.york.ac.uk/mlg/lll/workshop/proceedings/Bostroem/Bostroem.ps.gz",
}

@InProceedings{osborne:LLL99,
  author =       "Miles Osborne",
  title =        "{DCG} Induction using {MDL} and Parsed Corpora",
  booktitle =    LLL99,
  editor =       "James Cussens",
  year =         "1999",
  address =      "Bled, Slovenia",
  month =        jun,
  pages =        "63--71",
  keywords =     "Language_Learning",
  URL =          "http://www.cs.york.ac.uk/mlg/lll/workshop/proceedings/Osborne/Osborne.ps.gz",
}

@InProceedings{adriaans:LLL99,
  author =       "Pieter Adriaans and Erik Haas",
  title =        "Grammar induction as substructural inductive logic
                 programming",
  booktitle =    LLL99,
  editor =       "James Cussens",
  year =         "1999",
  address =      "Bled, Slovenia",
  month =        jun,
  pages =        "117--127",
  keywords =     "Language_Learning",
  URL =          "http://www.cs.york.ac.uk/mlg/lll/workshop/proceedings/Adriaans/Adriaans.ps.gz",
}

@InProceedings{cussens:LLL99,
  author =       "James Cussens and Stephen Pulman",
  title =        "Experiments in Inductive Chart Parsing",
  booktitle =    LLL99,
  editor =       "James Cussens",
  year =         "1999",
  address =      "Bled, Slovenia",
  month =        jun,
  pages =        "72--83",
  keywords =     "Language_Learning",
  URL =          "http://www.cs.york.ac.uk/mlg/lll/workshop/proceedings/CussensPulman/CussensPulman.ps.gz",
}

@InProceedings{junker:LLL99,
  author =       "Markus Junker and Michael Sintek and Matthias Rinck",
  title =        "Learning for Text Categorization and Information
                 Extraction with {ILP}",
  booktitle =    LLL99,
  editor =       "James Cussens",
  year =         "1999",
  address =      "Bled, Slovenia",
  month =        jun,
  pages =        "84--93",
  keywords =     "Language_Learning",
  URL =          "http://www.cs.york.ac.uk/mlg/lll/workshop/proceedings/Junkeretal/Junkeretal.ps.gz",
}

@InProceedings{jorge:LLL99,
  author =       "Al\'{\i}pio Jorge and Alneu de Andrade Lopes",
  title =        "Iterative Part-of-Speech Tagging",
  booktitle =    LLL99,
  editor =       "James Cussens",
  year =         "1999",
  address =      "Bled, Slovenia",
  month =        jun,
  pages =        "94--105",
  keywords =     "Language_Learning",
  URL =          "http://www.cs.york.ac.uk/mlg/lll/workshop/proceedings/JorgeLopes/JorgeLopes.ps.gz",
}

@InProceedings{popetal:LLL99,
  author =       "Lubo\v{s} Popel\'{\i}nsk\'{y} and Tom\'{a}\v{s}
                 Pavelek and Tom\'{a}\v{s} Pt\'{a}\v{c}n\'{\i}k",
  title =        "Towards Disambiguation in {Czech} Corpora",
  booktitle =    LLL99,
  editor =       "James Cussens",
  year =         "1999",
  address =      "Bled, Slovenia",
  month =        jun,
  pages =        "106--116",
  keywords =     "Language_Learning",
  URL =          "http://www.cs.york.ac.uk/mlg/lll/workshop/proceedings/Popelinskyetal/Popelinskyetal.ps.gz",
}

@InProceedings{bryant:icml2k,
  author =       "Stephen Muggleton and C. H. Bryant and A. Srinivasan",
  title =        "Learning Chomsky-like Grammars for Biological Sequence
                 Families",
  URL =          "ftp://ftp.cs.york.ac.uk/pub/aig/Papers/bryant/bryant_icml2k.ps.gz",
  booktitle =    ICML00,
  pages =        "631--638",
  publisher =    MK,
  year =         "2000",
  ISBN =         "1-55860-707-2",
  keywords =     "ILP_Application,Language_Learning,Molecular_Biology",
  abstract =     "This paper presents a new method of measuring
                 performance when positives are rare and investigates
                 whether Chomsky-like grammar representations are useful
                 for learning accurate comprehensible predictors of
                 members of biological sequence families. The
                 positive-only learning framework of the Inductive Logic
                 Programming (ILP) system CProgol is used to generate a
                 grammar for recognising a class of proteins known as
                 human neuropeptide precursors (NPPs). As far as these
                 authors are aware, this is both the first biological
                 grammar learnt using ILP and the first real-world
                 scientific application of the positive-only learning
                 framework of CProgol. Performance is measured using
                 both predictive accuracy and a new cost function, {\em
                 Relative Advantage} ($RA$). The $RA$ results show that
                 searching for NPPs by using our best NPP predictor as a
                 filter is more than 100 times more efficient than
                 randomly selecting proteins for synthesis and testing
                 them for biological activity. The highest $RA$ was
                 achieved by a model which includes grammar-derived
                 features. This $RA$ is significantly higher than the
                 best $RA$ achieved without the use of the
                 grammar-derived features.",
}

@InProceedings{kietz:LLL00,
  author =       "J{\"o}rg-Uwe Kietz and Raphael Volz and Alexander
                 Maedche",
  title =        "Extracting a Domain-Specific Ontology from a Corporate
                 Intranet",
  editor =       "Claire Cardie and Walter Daelemans and Claire
                 N\'{e}dellec and Erik Tjong Kim Sang",
  booktitle =    "Proceedings of the Fourth Conference on Computational
                 Natural Language Learning and of the Second Learning
                 Language in Logic Workshop",
  year =         "2000",
  address =      "Lisbon, Portugal",
  month =        sep,
  pages =        "167--175",
  keywords =     "Language_Learning",
  abstract =     "This paper describes our actual and ongoing work in
                 supporting semi-automatic ontology acquisition from a
                 corporate intranet of an insurance company. A
                 comprehensive architecture and a system for
                 semi-automatic ontology acquisition supports processing
                 semi-structured information (e.g. contained in
                 dictionaries) and natural language documents and
                 including existing core ontologies (e.g. GermaNet,
                 WordNet). We present a method for acquiring a
                 application-tailored domain ontology from given
                 heterogeneous intranet sources.",
}

@InProceedings{adriaans:LLL00,
  author =       "Pieter Adriaans and Erik de Haas",
  title =        "Learning from a Substructural Perspective",
  editors =      "Claire Cardie and Walter Daelemans and Claire
                 N\'{e}dellec and Tjong Kim Sang, Erik",
  booktitle =    "Proceedings of the Fourth Conference on Computational
                 Natural Language Learning and of the Second Learning
                 Language in Logic Workshop",
  publisher =    "Lisbon, Portugal",
  pages =        "176--183",
  year =         "2000",
  keywords =     "Language_Learning",
  abstract =     "In this paper we study learning from a logical
                 perspective. We show that there is a strong
                 relationship between a learning strategy, its formal
                 learning framework and its logical representational
                 theory. This relationship enables one to translate
                 learnability results from one theory to another.
                 Moreover if we go from a classical logic theory to a
                 substructural logic theory, we can transform
                 learnability results of logical concepts to results for
                 string languages. In this paper we will demonstrate
                 such a translation by transforming the Valiant
                 learnability result for boolean concepts to a
                 learnability result for a class of string pattern
                 languages.",
}

@InProceedings{cussens:LLL00,
  author =       "James Cussens and Stephen Pulman",
  title =        "Incorporating Linguistics Constraints into Inductive
                 Logic Programming",
  editors =      "Claire Cardie and Walter Daelemans and Claire
                 N\'{e}dellec and Tjong Kim Sang, Erik",
  booktitle =    "Proceedings of the Fourth Conference on Computational
                 Natural Language Learning and of the Second Learning
                 Language in Logic Workshop",
  publisher =    "Lisbon, Portugal",
  pages =        "184--193",
  year =         "2000",
  keywords =     "Language_Learning",
  abstract =     "We report work on effectively incorporating linguistic
                 knowledge into grammar induction. We use a highly
                 interactive bottom-up inductive logic programming (ILP)
                 algorithm to learn `missing' grammar rules from an
                 incomplete grammar. Using linguistic constraints on,
                 for example, head features and gap threading, reduces
                 the search space to such an extent that, in the
                 small-scale experiments reported here, we can generate
                 and store all candidate grammar rules together with
                 information about their coverage and linguistic
                 properties. This allows an appealingly simple and
                 controlled method for generating linguistically
                 plausible grammar rules. Starting from a base of highly
                 specific rules, we apply least general generalisation
                 and inverse resolution to generate more general rules.
                 Induced rules are ordered, for example by coverage, for
                 easy inspection by the user and at any point, the user
                 can commit to a hypothesised rule and add it to the
                 grammar. Related work in ILP and computational
                 linguistics is discussed.",
}

@InProceedings{esposito:LLL00,
  author =       "F. Esposito and S. Ferilli and N. Fanizzi and G.
                 Semeraro",
  title =        "Learning from Parsed Sentences with {INTHELEX}",
  editors =      "Claire Cardie and Walter Daelemans and Claire
                 N\'{e}dellec and Tjong Kim Sang, Erik",
  booktitle =    "Proceedings of the Fourth Conference on Computational
                 Natural Language Learning and of the Second Learning
                 Language in Logic Workshop",
  publisher =    "Lisbon, Portugal",
  pages =        "194--198",
  year =         "2000",
  keywords =     "Language_Learning",
  abstract =     "In the context of language learning, we address a
                 logical approach to information extraction. The system
                 INTHELEX, used to carry out this task, requires a logic
                 representation of sentences to run the learning
                 algorithm. Hence, the need for parsers to produce
                 structured representations from raw text. This led us
                 to develop a prototypical Italian language parser, as a
                 pre-processor in order to obtain the structured
                 representation of sentences required for the symbolic
                 learner to work. A preliminary experimentation proved
                 that the logic approach to learning from language is
                 able to capture the semantics underlying the kind of
                 sentences that were processed, even if a comparison
                 with classical methods as regards efficiency has still
                 to be done.",
}

@InProceedings{sebillot:LLL00,
  author =       "Pascale S{\'e}billot and Pierrette Bouillon and
                 C{\'e}cile Fabre",
  title =        "Inductive Logic Programming for Corpus-Based
                 Acquisition of Semantic Lexicons",
  editors =      "Claire Cardie and Walter Daelemans and Claire
                 N\'{e}dellec and Tjong Kim Sang, Erik",
  booktitle =    "Proceedings of the Fourth Conference on Computational
                 Natural Language Learning and of the Second Learning
                 Language in Logic Workshop",
  publisher =    "Lisbon, Portugal",
  pages =        "199--208",
  year =         "2000",
  keywords =     "Language_Learning",
  abstract =     "In this paper, we propose an Inductive Logic
                 Programming learning method which aims at automatically
                 extracting special Noun-Verb (N-V) pairs from a corpus
                 in order to build up semantic lexicons based on
                 Pustejovsky's Generative Lexicon (GL) principles
                 (Pustejovsky, 1995). In one of the components of this
                 lexical model, called the qualia structure, words are
                 described in terms of semantic roles. For example, the
                 telic role indicates the purpose or function of an item
                 (cut for knife), the agentive role its creation mode
                 (build for house), etc. The qualia structure of a noun
                 is mainly made up of verbal associations, encoding
                 relational information. The Inductive Logic Programming
                 learning method that we have developed enables us to
                 automatically extract from a corpus N-V pairs whose
                 elements are linked by one of the semantic relations
                 defined in the qualia structure in GL, and to
                 distinguish them, in terms of surrounding categorial
                 context from N-V pairs also present in sentences of the
                 corpus but not relevant. This method has been
                 theoretically and empirically validated, on a technical
                 corpus. The N-V pairs that have been extracted will
                 further be used in information retrieval applications
                 for index expansion.",
}

@InProceedings{villavicencio:LLL00,
  author =       "Aline Villavicencio",
  title =        "The Acquisition of Word Order by a Computational
                 Learning System",
  editors =      "Claire Cardie and Walter Daelemans and Claire
                 N\'{e}dellec and Tjong Kim Sang, Erik",
  booktitle =    "Proceedings of the Fourth Conference on Computational
                 Natural Language Learning and of the Second Learning
                 Language in Logic Workshop",
  publisher =    "Lisbon, Portugal",
  pages =        "209--218",
  year =         "2000",
  keywords =     "Language_Learning",
  abstract =     "The purpose of this work is to investigate the process
                 of grammatical acquisition from data. We are using a
                 computational learning system that is composed of a
                 Universal Grammar with associated parameters, and a
                 learning algorithm, following the Principles and
                 Parameters Theory. The Universal Grammar is implemented
                 as a Unification-Based Generalised Categorial Grammar,
                 embedded in a default inheritance network of lexical
                 types. The learning algorithm receives input from a
                 corpus annotated with logical forms and sets the
                 parameters based on this input. This framework is used
                 as basis to investigate several aspects of language
                 acquisition. In this paper we are concentrating on the
                 acquisition of word order for different learners. The
                 results obtained show the different learners having a
                 similar performance and converging towards the target
                 grammar given the input data available, regardless of
                 their starting points. It also shows how the amount of
                 noise present in the input data affects the speed of
                 convergence of the learners towards the target.",
}

@InProceedings{zackova:LLL00,
  author =       "Eva Z{\'a}ckov{\'a} and Lubo\v{s} Popel\'{\i}nsk\'{y}
                 and Milos Nepil",
  title =        "Recognition and Tagging of Compound Verb Groups in
                 Czech",
  editors =      "Claire Cardie and Walter Daelemans and Claire
                 N\'{e}dellec and Tjong Kim Sang, Erik",
  booktitle =    "Proceedings of the Fourth Conference on Computational
                 Natural Language Learning and of the Second Learning
                 Language in Logic Workshop",
  publisher =    "Lisbon, Portugal",
  pages =        "219--225",
  year =         "2000",
  keywords =     "Language_Learning",
  abstract =     "n Czech corpora compound verb groups are usually
                 tagged in word-by-word manner. As a consequence, some
                 of the morphological tags of particular components of
                 the verb group lose their original meaning. We present
                 a method for automatic recognition of compound verb
                 groups in Czech. From an annotated corpus 126 definite
                 clause grammar rules were constructed. These rules
                 describe all compound verb groups that are frequent in
                 Czech. Using those rules we can find compound verb
                 groups in unannotated texts with the accuracy 93\%.
                 Tagging compound verb groups in an annotated corpus
                 exploiting the verb rules is described.",
}

@Book{2000-cussens,
  title =        "Learning Language in Logic",
  editor =       "James Cussens and Sa\v{s}o D\v{z}eroski",
  bpages =       "299",
  rpages =       "10",
  series =       LNCS,
  volume =       "1925",
  ISBN =         "3-540-41145-3",
  publisher =    SV,
  month =        jun,
  year =         "2000",
  keywords =     "Language_Learning",
  URL =          "http://www.springer.de/cgi-bin/search_book.pl?isbn=3-540-41145-3",
  pubtype =      "2",
}

@InCollection{2000-dzeroski,
  title =        "An Introduction to Inductive Logic Programming and
                 Learning Language in Logic",
  author =       "Sa\v{s}o D\v{z}eroski and James Cussens and Suresh
                 Manandhar",
  booktitle =    "Learning Language in Logic",
  editor =       "James Cussens and Sa\v{s}o D\v{z}eroski",
  series =       LNCS,
  volume =       "1925",
  ISBN =         "3-540-41145-3",
  publisher =    SV,
  pages =        "3--35",
  month =        jun,
  year =         "2000",
  keywords =     "Language_Learning",
  URL =          "http://www.springer.de/cgi-bin/search_book.pl?isbn=3-540-41145-3",
  pubtype =      "7",
}

@InCollection{2000-thompson,
  title =        "A Brief Introduction to Natural Language Processing
                 for Non-linguists",
  author =       "Cynthia A. Thompson",
  booktitle =    "Learning Language in Logic",
  editor =       "James Cussens and Sa\v{s}o D\v{z}eroski",
  series =       LNCS,
  volume =       "1925",
  ISBN =         "3-540-41145-3",
  publisher =    SV,
  pages =        "36--48",
  month =        jun,
  year =         "2000",
  keywords =     "Language_Learning",
  URL =          "http://www.springer.de/cgi-bin/search_book.pl?isbn=3-540-41145-3",
  pubtype =      "7",
}

@InCollection{2000-brill,
  title =        "A Closer Look at the Automatic Induction of Linguistic
                 Knowledge",
  author =       "Eric Brill",
  booktitle =    "Learning Language in Logic",
  editor =       "James Cussens and Sa\v{s}o D\v{z}eroski",
  series =       LNCS,
  volume =       "1925",
  ISBN =         "3-540-41145-3",
  publisher =    SV,
  pages =        "49--56",
  month =        jun,
  year =         "2000",
  keywords =     "Language_Learning",
  URL =          "http://www.springer.de/cgi-bin/search_book.pl?isbn=3-540-41145-3",
  pubtype =      "7",
}

@InCollection{2000-mooney,
  title =        "Learning for Semantic Interpretation: Scaling Up
                 without Dumbing Down",
  author =       "Raymond J. Mooney",
  booktitle =    "Learning Language in Logic",
  editor =       "James Cussens and Sa\v{s}o D\v{z}eroski",
  series =       LNCS,
  volume =       "1925",
  ISBN =         "3-540-41145-3",
  publisher =    SV,
  pages =        "57--66",
  month =        jun,
  year =         "2000",
  keywords =     "Language_Learning",
  URL =          "http://www.springer.de/cgi-bin/search_book.pl?isbn=3-540-41145-3",
  pubtype =      "7",
}

@InCollection{2000-dzeroski-0,
  title =        "Learning to Lemmatise {S}lovene Words",
  author =       "Sa\v{s}o D\v{z}eroski and Toma\v{z} Erjavec",
  booktitle =    "Learning Language in Logic",
  editor =       "James Cussens and Sa\v{s}o D\v{z}eroski",
  series =       LNCS,
  volume =       "1925",
  ISBN =         "3-540-41145-3",
  publisher =    SV,
  pages =        "69--88",
  month =        jun,
  year =         "2000",
  keywords =     "Language_Learning",
  URL =          "http://www.springer.de/cgi-bin/search_book.pl?isbn=3-540-41145-3",
  pubtype =      "7",
}

@InCollection{2000-kazakov,
  title =        "Achievements and Prospects of Learning Word Morphology
                 with Inductive Logic Programming",
  author =       "Dimitar Kazakov",
  booktitle =    "Learning Language in Logic",
  editor =       "James Cussens and Sa\v{s}o D\v{z}eroski",
  series =       LNCS,
  volume =       "1925",
  ISBN =         "3-540-41145-3",
  publisher =    SV,
  pages =        "89--109",
  month =        jun,
  year =         "2000",
  keywords =     "Language_Learning",
  URL =          "http://www.springer.de/cgi-bin/search_book.pl?isbn=3-540-41145-3",
  pubtype =      "7",
}

@InCollection{2000-sang,
  title =        "Learning the Logic of Simple Phonotactics",
  author =       "Erik F. Tjong Kim Sang and John Nerbonne",
  booktitle =    "Learning Language in Logic",
  editor =       "James Cussens and Sa\v{s}o D\v{z}eroski",
  series =       LNCS,
  volume =       "1925",
  ISBN =         "3-540-41145-3",
  publisher =    SV,
  pages =        "110--124",
  month =        jun,
  year =         "2000",
  keywords =     "Language_Learning",
  URL =          "http://www.springer.de/cgi-bin/search_book.pl?isbn=3-540-41145-3",
  pubtype =      "7",
}

@InCollection{2000-adriaans,
  title =        "Grammar Induction as Substructural Inductive Logic
                 Programming",
  author =       "Pieter W. Adriaans and Erik de Haas",
  booktitle =    "Learning Language in Logic",
  editor =       "James Cussens and Sa\v{s}o D\v{z}eroski",
  series =       LNCS,
  volume =       "1925",
  ISBN =         "3-540-41145-3",
  publisher =    SV,
  pages =        "127--142",
  month =        jun,
  year =         "2000",
  keywords =     "Language_Learning",
  URL =          "http://www.springer.de/cgi-bin/search_book.pl?isbn=3-540-41145-3",
  pubtype =      "7",
}

@InCollection{2000-cussens-0,
  title =        "Experiments in Inductive Chart Parsing",
  author =       "James Cussens and Stephen G. Pulman",
  booktitle =    "Learning Language in Logic",
  editor =       "James Cussens and Sa\v{s}o D\v{z}eroski",
  series =       LNCS,
  volume =       "1925",
  ISBN =         "3-540-41145-3",
  publisher =    SV,
  pages =        "143--156",
  month =        jun,
  year =         "2000",
  keywords =     "Language_Learning",
  URL =          "http://www.springer.de/cgi-bin/search_book.pl?isbn=3-540-41145-3",
  pubtype =      "7",
}

@InCollection{2000-jorge,
  title =        "Iterative Part-of-Speech Tagging",
  author =       "Al\'{\i}pio Jorge and Alneu de Andrade Lopes",
  booktitle =    "Learning Language in Logic",
  editor =       "James Cussens and Sa\v{s}o D\v{z}eroski",
  series =       LNCS,
  volume =       "1925",
  ISBN =         "3-540-41145-3",
  publisher =    SV,
  pages =        "170--183",
  month =        jun,
  year =         "2000",
  keywords =     "Language_Learning",
  URL =          "http://www.springer.de/cgi-bin/search_book.pl?isbn=3-540-41145-3",
  pubtype =      "7",
}

@InCollection{2000-osborne,
  title =        "{DCG} Induction Using {MDL} and Pased Corpora",
  author =       "Miles Osborne",
  booktitle =    "Learning Language in Logic",
  editor =       "James Cussens and Sa\v{s}o D\v{z}eroski",
  series =       LNCS,
  volume =       "1925",
  ISBN =         "3-540-41145-3",
  publisher =    SV,
  pages =        "184--198",
  month =        jun,
  year =         "2000",
  keywords =     "Language_Learning",
  URL =          "http://www.springer.de/cgi-bin/search_book.pl?isbn=3-540-41145-3",
  pubtype =      "7",
}

@InCollection{2000-riezler,
  title =        "Learning Log-Linear Models on Constraint-Based
                 Grammars for Disambiguation",
  author =       "Stefan Riezler",
  booktitle =    "Learning Language in Logic",
  editor =       "James Cussens and Sa\v{s}o D\v{z}eroski",
  series =       LNCS,
  volume =       "1925",
  ISBN =         "3-540-41145-3",
  publisher =    SV,
  pages =        "199--217",
  month =        jun,
  year =         "2000",
  keywords =     "Language_Learning",
  URL =          "http://www.springer.de/cgi-bin/search_book.pl?isbn=3-540-41145-3",
  pubtype =      "7",
}

@InCollection{2000-watkinson,
  title =        "Unsupervised Lexical Learning with Categorical
                 Grammars Using the {LLL} Corpus",
  author =       "Stephen Watkinson and Suresh Manandhar",
  booktitle =    "Learning Language in Logic",
  editor =       "James Cussens and Sa\v{s}o D\v{z}eroski",
  series =       LNCS,
  volume =       "1925",
  ISBN =         "3-540-41145-3",
  publisher =    SV,
  pages =        "218--236",
  month =        jun,
  year =         "2000",
  keywords =     "Language_Learning",
  URL =          "http://www.springer.de/cgi-bin/search_book.pl?isbn=3-540-41145-3",
  pubtype =      "7",
}

@InCollection{2000-bostrm,
  title =        "Induction of Recursive Transfer Rules",
  author =       "Henrik Bostr{\"{o}}m",
  booktitle =    "Learning Language in Logic",
  editor =       "James Cussens and Sa\v{s}o D\v{z}eroski",
  series =       LNCS,
  volume =       "1925",
  ISBN =         "3-540-41145-3",
  publisher =    SV,
  pages =        "237--246",
  month =        jun,
  year =         "2000",
  keywords =     "Language_Learning",
  URL =          "http://www.springer.de/cgi-bin/search_book.pl?isbn=3-540-41145-3",
  pubtype =      "7",
}

@InCollection{2000-junker,
  title =        "Learning for Text Categorization and Information
                 Extraction with {ILP}",
  author =       "Markus Junker and Michael Sintek and Matthias Rinck",
  booktitle =    "Learning Language in Logic",
  editor =       "James Cussens and Sa\v{s}o D\v{z}eroski",
  series =       LNCS,
  volume =       "1925",
  ISBN =         "3-540-41145-3",
  publisher =    SV,
  pages =        "247--258",
  month =        jun,
  year =         "2000",
  keywords =     "Language_Learning",
  URL =          "http://www.springer.de/cgi-bin/search_book.pl?isbn=3-540-41145-3",
  pubtype =      "7",
}

@InCollection{2000-nedellec,
  title =        "Corpus-Based Learning of Semantic Relations by the
                 {ILP} System, Asium",
  author =       "Claire N\'{e}dellec",
  booktitle =    "Learning Language in Logic",
  editor =       "James Cussens and Sa\v{s}o D\v{z}eroski",
  series =       LNCS,
  volume =       "1925",
  ISBN =         "3-540-41145-3",
  publisher =    SV,
  pages =        "259--278",
  month =        jun,
  year =         "2000",
  keywords =     "Language_Learning",
  URL =          "http://www.springer.de/cgi-bin/search_book.pl?isbn=3-540-41145-3",
  pubtype =      "7",
}

@InCollection{2000-thompson-0,
  title =        "Improving Learning by Choosing Examples Intelligently
                 in Two Natural Language Tasks",
  author =       "Cynthia A. Thompson and Mary Elaine Califf",
  booktitle =    "Learning Language in Logic",
  editor =       "James Cussens and Sa\v{s}o D\v{z}eroski",
  series =       LNCS,
  volume =       "1925",
  ISBN =         "3-540-41145-3",
  publisher =    SV,
  pages =        "279--299",
  month =        jun,
  year =         "2000",
  keywords =     "Language_Learning",
  URL =          "http://www.springer.de/cgi-bin/search_book.pl?isbn=3-540-41145-3",
  pubtype =      "7",
}

@InProceedings{ilp01-nepil,
  title =        "Learning to Parse from a Treebank: Combining {TBL} and
                 {ILP}",
  pages =        "179--192",
  author =       "Miloslav Nepil",
  booktitle =    ILP01,
  editor =       "C\'{e}line Rouveirol and Mich\`{e}le Sebag",
  series =       LNAI,
  volume =       "2157",
  ISBN =         "3-540-42538-1",
  publisher =    SV,
  month =        sep,
  year =         "2001",
  keywords =     "ILP_Application,Language_Learning",
  abstract =     "Considering the difficulties inherent in the manual
                 construction of natural language parsers, we have
                 designed and implemented our system GRIND which is
                 capable of learning a sequence of context-dependent
                 parsing actions from an arbitrary corpus containing
                 labelled parse trees. To achieve this, GRIND combines
                 two established methods of machine learning:
                 transformation-based learning (TBL) and inductive logic
                 programming (ILP). Being trained and tested on corpus
                 SUSANNE, Grind reaches the accuracy of 96\% and the
                 recall of 68\%.",
}

@InProceedings{alexin:LLL01,
  title =        "A Rule-Based Tagger Development Framework",
  author =       "Zolt\'{a}n Alexin and P\'{e}ter Leipold and J\'{a}nos
                 Csirik and K\'{a}roly Bibok and Tibor Gyim\'{o}thy",
  booktitle =    LLL01,
  editor =       "Lubo\v{s} Popel\'{\i}nsk\'{y} and Miloslav Nepil",
  address =      "Strasbourg, France",
  pages =        "1--10",
  month =        sep,
  year =         "2001",
  keywords =     "Language_Learning",
  abstract =     "POS (Part-of-speech) tagging is an important step in
                 natural language processing because identically written
                 words may have different meanings. Part-of-speech
                 tagging is the procedure during which the correct
                 morphological annotation (the correct tag) for an
                 ambiguous word is selected. Computer programs able to
                 do the process automatically are called POS taggers. In
                 this paper the RTDF (a Rule-based Tagger Development
                 Framework) is presented that is capable identifying
                 general tagging rules using different machine learning
                 tools given a suitably large training data set. The
                 framework can combine the learned tagging rules, and
                 evaluate the resulted taggers. The authors are
                 participants of a project for developing a medium sized
                 learning corpus for Hungarian. The corpus contains 1
                 million words and -- among others -- can serve as a
                 suitable medium on which the previously developed
                 POS-taggers can be tested. During the project the
                 morphological analyzer for Hungarian has been
                 thoroughly investigated and the MSD encoding has been
                 refined. The development of the corpus is going on and
                 will be completed at the end of 2001.",
  URL =          "http://www.fi.muni.cz/ilpnet2/LLL2001/#proceedings",
}

@InProceedings{besombes:LLL01,
  title =        "Identification of reversible dependency tree
                 languages",
  author =       "J\'{e}r\^{o}me Besombes and Jean-Yves Marion",
  booktitle =    LLL01,
  editor =       "Lubo\v{s} Popel\'{\i}nsk\'{y} and Miloslav Nepil",
  address =      "Strasbourg, France",
  pages =        "11--22",
  month =        sep,
  year =         "2001",
  keywords =     "Language_Learning",
  abstract =     "We investigate learning dependency grammar from
                 positive data, in Gold's identification in the limit
                 model. Examples are dependency trees. For this, we
                 introduce reversible lexical dependency grammars which
                 generate a significant class of languages. We have
                 demonstrated that reversible dependency languages are
                 learnable. We provide a O(n2)-time, in the example
                 size, algorithm.",
  URL =          "http://www.fi.muni.cz/ilpnet2/LLL2001/#proceedings",
}

@InProceedings{bonato:LLL01,
  title =        "Learning Rigid Lamberk Grammars and Minimalist
                 Grammars from Structured Sentences",
  author =       "Roberto Bonato and Christian Retor\'{e}",
  booktitle =    LLL01,
  editor =       "Lubo\v{s} Popel\'{\i}nsk\'{y} and Miloslav Nepil",
  address =      "Strasbourg, France",
  pages =        "23--34",
  month =        sep,
  year =         "2001",
  keywords =     "Language_Learning",
  abstract =     "We present an extension of Buszkowski's learning
                 algorithm for categorial grammars to rigid Lambek
                 grammars and then for minimalist categorial grammars.
                 The Kanazawa proof of the convergence in the Gold sense
                 is simplified and extended to these new algorithms. We
                 thus show that this technique based on principal type
                 algorithm and type unification is quite general and
                 applies to learning issues for different type logical
                 grammars, which are larger, linguistically more
                 accurate and closer to semantics.",
  URL =          "http://www.fi.muni.cz/ilpnet2/LLL2001/#proceedings",
}

@InProceedings{dudau-sofronie:LLL01,
  title =        "From Logic to Grammars via Types",
  author =       "Daniela Dudau-Sofronie and Isabelle Tellier and Marc
                 Tommasi",
  booktitle =    LLL01,
  editor =       "Lubo\v{s} Popel\'{\i}nsk\'{y} and Miloslav Nepil",
  address =      "Strasbourg, France",
  pages =        "35--46",
  month =        sep,
  year =         "2001",
  keywords =     "Language_Learning",
  abstract =     "This paper investigates the inference of Categorial
                 Grammars from a new perspective. To learn such
                 grammars, Kanazawa's approach consists in providing, as
                 input, information about the structure of derivation
                 trees in the target grammar. But this information is
                 hardly arguable as relevant data from a
                 psycholinguistic point of view. We propose instead to
                 provide information about the semantic type associated
                 with the words used. These types are considered as
                 general semantic knowledge and their availability is
                 argued. A new learning algorithm from types is given
                 and discussed.",
  URL =          "http://www.fi.muni.cz/ilpnet2/LLL2001/#proceedings",
}

@InProceedings{nakabasami:LLL01,
  title =        "Interactive Background Knowledge Acquisition for
                 Inducing Differences among Documents",
  author =       "Chieko Nakabasami",
  booktitle =    LLL01,
  editor =       "Lubo\v{s} Popel\'{\i}nsk\'{y} and Miloslav Nepil",
  address =      "Strasbourg, France",
  pages =        "47--57",
  month =        sep,
  year =         "2001",
  keywords =     "Language_Learning",
  abstract =     "This paper presents a case study in which an Inductive
                 Logic Programming (ILP) technique is applied to natural
                 language processing. Aleph, an ILP system, is used to
                 induce differences among documents. A Case-Based
                 Reasoning (CBR) system is proposed for the purpose of
                 compiling the background knowledge inputted into Aleph.
                 In the CBR system, lexical and syntactic information
                 concerning words in close proximity to the target
                 word(s) in training sentences is provided in order to
                 infer new cases effectively. The compiled background
                 knowledge is used to determine the semantic differences
                 in documents that are written in natural language.
                 Tentative experiments with this technique have produced
                 encouraging results.",
  URL =          "http://www.fi.muni.cz/ilpnet2/LLL2001/#proceedings",
}

@InProceedings{nepil:LLL01,
  title =        "Part-of-Speech Tagging by Means of Shallow Parsing,
                 {ILP} and Active Learning",
  author =       "Miloslav Nepil and Lubo\v{s} Popel\'{\i}nsk\'{y} and
                 Eva \v{Z}\'a\v{c}kov\'{a}",
  booktitle =    LLL01,
  editor =       "Lubo\v{s} Popel\'{\i}nsk\'{y} and Miloslav Nepil",
  address =      "Strasbourg, France",
  pages =        "58--66",
  month =        sep,
  year =         "2001",
  keywords =     "ILP_Application,Language_Learning",
  abstract =     "In this paper we describe a part-of-speech tagger for
                 Czech which exploits DIS shallow parser for Czech,
                 manually-coded rules and inductive logic programming.
                 The active learning method used resulted in the
                 decrease in the number of training examples to label as
                 well as in a shorter learning time without the decrease
                 in recall or accuracy. The method was tested on
                 ambiguities that are frequent in Czech. The accuracy
                 reached was higher than 96\% with recall higher than
                 95\%.",
  URL =          "http://www.fi.muni.cz/ilpnet2/LLL2001/#proceedings",
}

@Article{2001-muggleton-0,
  title =        "Are grammatical representations useful for learning
                 from biological sequence data? - a case study",
  author =       "Stephen Muggleton and C. H. Bryant and Ashiwn
                 Srinivasan and A. Whittaker and S. Topp and C.
                 Rawlings",
  journal =      "Journal of Computational Biology",
  volume =       "8",
  number =       "5",
  pages =        "493--522",
  month =        oct,
  year =         "2001",
  keywords =     "ILP_Application,Language_Learning,Molecular_Biology",
  abstract =     "This paper investigates whether Chomsky-like grammar
                 representations are useful for learning cost-effective,
                 comprehensible predictors of members of biological
                 sequence families. The Inductive Logic Programming
                 (ILP) Bayesian approach to learning from positive
                 examples is used to generate a grammar for recognising
                 a class of proteins known as human neuropeptide
                 precursors (NPPs). Collectively, five of the co-authors
                 of this paper, have extensive expertise on NPPs and
                 general bioinformatics methods. Their motivation for
                 generating a NPP grammar was that none of the existing
                 bioinformatics methods could provide sufficient
                 cost-savings during the search for new NPPs. Prior to
                 this project experienced specialists at SmithKline
                 Beecham had tried for many months to hand-code such a
                 grammar but without success. Our best predictor makes
                 the search for novel NPPs {\bf more than 100 times more
                 efficient} than randomly selecting proteins for
                 synthesis and testing them for biological activity. As
                 far as these authors are aware, this is both the first
                 biological grammar learnt using ILP and the first
                 real-world scientific application of the ILP Bayesian
                 approach to learning from positive examples. A group of
                 features is derived from this grammar. Other groups of
                 features of NPPs are derived using other learning
                 strategies. Amalgams of these groups are formed. A
                 recognition model is generated for each amalgam using
                 C4.5 and C4.5rules and its performance is measured
                 using both predictive accuracy and a new cost function,
                 {\em Relative Advantage} ($RA$). The highest $RA$ was
                 achieved by a model which includes grammar-derived
                 features. This $RA$ is significantly higher than the
                 best $RA$ achieved without the use of the
                 grammar-derived features. Predictive accuracy is not a
                 good measure of performance for this domain because it
                 does not discriminate well between NPP recognition
                 models: despite covering varying numbers of (the rare)
                 positives, all the models are awarded a similar (high)
                 score by predictive accuracy because they all exclude
                 most of the abundant negatives.",
  URL =          "http://www.liebertpub.com/",
  pubtype =      "11",
}

@InProceedings{2001-nepil-1,
  title =        "Automated Parser Construction from a Treebank by means
                 of {TBL} and {ILP}",
  author =       "Miloslav Nepil",
  booktitle =    "Proceedings of the Student Research Workshop at
                 ACL/EACL 2001, Toulouse, France",
  editor =       "Eleni Miltsakaki and Christof Monz and Ant\'{o}nio
                 Ribeiro",
  ISBN =         "1-55860-784-6",
  publisher =    "Association for Computational Linguistics",
  address =      "New Brunswick",
  pages =        "19--24",
  month =        jul,
  year =         "2001",
  keywords =     "ILP_Application,Language_Learning",
  abstract =     "Considering the difficulties inherent in the manual
                 construction of natural language parsers, we have
                 designed and implemented our system GRIND which is
                 capable of learning a sequence of context-dependent
                 parsing actions from an arbitrary corpus containing
                 labelled parse trees. Being trained and tested on
                 corpus SUSANNE, GRIND reaches the accuracy of 96\% and
                 the recall of 68\%.",
  URL =          "http://www.fi.muni.cz/%7Enepil",
  pubtype =      "4",
}

@PhdThesis{konstantopoulos03:_using,
  author =       "Stasinos Konstantopoulos",
  title =        "Using {ILP} to Learn Local Linguistic Structures",
  school =       "Rijksuniversiteit Groningen",
  year =         "2003",
  URL =          "http://www.rug.nl/let/onderzoek/onderzoekinstituten/clcg/projects/konstant",
}

@Article{CS-TAL04,
  author =       "Vincent Claveau and Pascale S\'{e}billot",
  title =        "Apprentissage semi-supervis\'{e} de patrons
                 d'extraction de couples nom-verbe",
  journal =      "TAL (traitement automatique des langues)",
  year =         "2004",
  OPTkey =       "",
  volume =       "45",
  number =       "1",
  OPTpages =     "",
  OPTmonth =     "",
  OPTnote =      "",
  OPTannote =    "",
  abstract =     "In the Generative Lexicon (GL) framework [PUS95], some
                 semantic properties of nouns are expressed with the
                 help of verbs. These noun-verb pairs are relevant in
                 various domains, such as Information Retrieval. Their
                 corpus-based acquisition is thus an interesting issue;
                 moreover, discovering the contextual patterns in which
                 these pairs occur can help to understand the GL model.
                 This paper presents two related and fully automated
                 techniques that allow us to acquire from a corpus both
                 noun-verb pairs, and semantic and morpho-syntactic
                 patterns. These techniques combine two different
                 acquisition approaches---the statistical one and the
                 symbolic one---and keep advantages of each approach:
                 robustness and automation of statistical methods,
                 quality of the results and expressiveness of symbolic
                 ones.",
  resume =       "Dans le mod\`{e}le du Lexique g\'{e}n\'{e}ratif (LG)
                 [PUS95], certaines propri\'{e}t\'{e}s s\'{e}mantiques
                 des noms sont exprim\'{e}es \`{a} l'aide de verbes. De
                 tels couples nom-verbe pr\'{e}sentent un
                 int\'{e}r\^{e}t applicatif notamment en recherche
                 d'information. Leur acquisition sur corpus constitue
                 donc un enjeu, mais la d\'{e}couverte des patrons qui
                 les d\'{e}finissent en contexte est \'{e}galement
                 importante pour la compr\'{e}hension m\^{e}me du
                 mod\`{e}le du LG. Cet article pr\'{e}sente deux
                 techniques enti\`{e}rement automatiques r\'{e}pondant
                 \`{a} ce double besoin d'extraction de couples et de
                 patrons contextuels. Elles combinent pour ce faire deux
                 approches d'acquisition --- les approches statistique
                 et symbolique --- en conservant les avantages propres
                 \`{a} chacune d'entre elles : robustesse et
                 automaticit\'{e} des premi\`{e}res, qualit\'{e} et
                 expressivit\'{e} des r\'{e}sultats des secondes.",
  URL =          "http://olst.ling.umontreal.ca/\~{}vincent/publis.html",
}

@InProceedings{CS-coling04,
  author =       "Vincent Claveau and Pascale S\'{e}billot",
  title =        "From Effiency to Portability: Acquisition of Semantic
                 Relations by Semi-Supervised Machine Learning",
  booktitle =    "Proceedings of the 20th International Conference on
                 Computational Linguistics, COLING'04",
  OPTcrossref =  "",
  OPTkey =       "",
  OPTpages =     "",
  year =         "2004",
  OPTeditor =    "",
  OPTvolume =    "",
  OPTnumber =    "",
  OPTseries =    "",
  address =      "Geneva, Switzerland",
  OPTadresse =   "Gen\`{e}ve, Suisse",
  month =        aug,
  OPTmois =      "ao\^{u}t",
  OPTorganization = "",
  OPTpublisher = "",
  OPTnote =      "",
  OPTannote =    "",
  abstract =     "Numeric approaches to the corpus-based acquisition of
                 lexical semantic relations offer robust and portable
                 techniques, but poor explanations of their results. On
                 the other hand, symbolic machine learning approaches
                 can infer patterns of a target relation from examples
                 of elements that verify this relation; the produced
                 patterns are efficient and expressive, but such
                 techniques are often supervised, i.e. require to be
                 (manually) fed by examples. This paper presents two
                 original algorithms to combine one technique from each
                 of these approaches, and keep advantages of both
                 (meaningful patterns, efficient extraction,
                 portability). Moreover the extraction results of these
                 two semi-supervised hybrid systems, when applied in an
                 illustrative purpose to the acquisition of semantic
                 noun-verb relations defined in the Generative Lexicon
                 framework (Pustejovsky 95), rival those of supervised
                 methods.",
  URL =          "http://olst.ling.umontreal.ca/\~{}vincent/publis.html",
}

@InProceedings{CL-computerm04,
  author =       "Vincent Claveau and Marie-Claude L'Homme",
  title =        "Discovering Specific Semantic Relationships between
                 Nouns and Verb in a Specialized French Corpus",
  booktitle =    "Proceedings of the 3rd International Workshop on
                 Computational Terminology, CompuTerm'04",
  OPTcrossref =  "",
  OPTkey =       "",
  OPTpages =     "",
  year =         "2004",
  OPTeditor =    "",
  OPTvolume =    "",
  OPTnumber =    "",
  OPTseries =    "",
  address =      "Geneva, Switzerland",
  OPTadresse =   "Gen\`{e}ve, Suisse",
  month =        aug,
  OPTmois =      "ao\^{u}t",
  OPTorganization = "",
  OPTpublisher = "",
  OPTnote =      "",
  OPTannote =    "",
  abstract =     "Recent literature in computational terminology has
                 shown an increasing interest in identifying various
                 semantic relationships between terms. In this paper, we
                 propose an original strategy to find specific noun-verb
                 combinations in a specialized corpus. We focus on verbs
                 that convey a meaning of realization. To acquire these
                 noun-verb pairs, we use ASARES, a machine learning
                 technique that automatically infers extraction patterns
                 from examples and counter-examples of realization
                 noun-verb pairs. The patterns are then applied to the
                 corpus to retrieve new pairs. Results, measured with a
                 large test set, show that our acquisition technique
                 outperforms classical statistical methods used for
                 collocation acquisition. Moreover, the inferred
                 patterns yield interesting clues on which structures
                 are more likely to convey the target semantic link.",
  URL =          "http://olst.ling.umontreal.ca/\~{}vincent/publis.html",
}

@InProceedings{CS-TALN04,
  author =       "Vincent Claveau and Pascale S\'{e}billot",
  title =        "Extension de requ\^{e}tes par lien s\'{e}mantique
                 nom-verbe acquis sur corpus",
  booktitle =    "Actes de la 11\`{e}me conf\'{e}rence de Traitement
                 automatique des langues naturelles, TALN'04",
  OPTcrossref =  "",
  OPTkey =       "",
  OPTpages =     "",
  year =         "2004",
  OPTeditor =    "",
  OPTvolume =    "",
  OPTnumber =    "",
  OPTseries =    "",
  address =      "Fez, Morrocco",
  OPTadresse =   "F\^{e}s, Maroc",
  month =        apr,
  OPTmois =      "avril",
  OPTorganization = "",
  OPTpublisher = "",
  OPTnote =      "",
  OPTannote =    "",
  abstract =     "In the information retrieval field, managing the
                 equivalent reformulations of a same idea is a key point
                 to improve the performances of existing retrieval
                 systems. One way to reach this goal is to use
                 specialised semantic resources that are suited to the
                 document database on which the queries are processed.
                 In this paper, we show that the semantic links between
                 nouns and verbs called qualia links, defined in the
                 Generative lexicon framework (Pustejovsky, 1995),
                 enable us to improve the results of retrieval systems.
                 To achieve this goal, we automatically extract from the
                 document database noun-verb pairs that are in qualia
                 relation with the acquisition system ASARES (Claveau,
                 2003a). These pairs are then used to expand the queries
                 of a retrieval system. With the help of the Amaryllis
                 evaluation campaign data, we show that these expansions
                 actually lead to better results, especially for the
                 first documents proposed to the user.",
  resume =       "En recherche d'information, savoir reformuler une
                 id-b\'{e}e par des termes diff\'{e}rents est une des
                 clefs pour l'am\'{e}lioration des performances des
                 syst\`{e}mes de recherche d'information (SRI)
                 existants. L'un des moyens pour r\'{e}soudre ce
                 probl\`{e}me est d'utiliser des ressources
                 s\'{e}mantiques sp\'{e}cialis\'{e}es et adapt\'{e}es
                 \`{a} la base documentaire sur laquelle les recherches
                 sont faites. Nous proposons dans cet article de montrer
                 que les liens s\'{e}mantiques entre noms et verbes
                 appel\'{e}s liens qualia, d\'{e}finis dans le
                 mod\`{e}le du Lexique g\'{e}n\'{e}ratif (Pustejovsky,
                 1995), peuvent effectivement am\'{e}liorer les
                 r\'{e}sultats des SRI. Pour cela, nous extrayons
                 automatiquement des couples nom-verbe en relation
                 qualia de la base documentaire \`{a} l'aide du
                 syst\`{e}me d'acquisition ASARES (Claveau, 2003a). Ces
                 couples sont ensuite utilis\'{e}s pour \'{e}tendre les
                 requ\^{e}tes d'un syst\`{e}me de recherche. Nous
                 montrons, \`{a} l'aide des donn\'{e}es de la campagne
                 d'\'{e}valuation Amaryllis, que cette extension permet
                 effectivement d'obtenir des r\'{e}ponses plus
                 pertinentes, et plus particuli\`{e}rement pour les
                 premiers documents retourn\'{e}s \`{a} l'utilisateur.",
  URL =          "http://olst.ling.umontreal.ca/\~{}vincent/publis.html",
}

@PhdThesis{Cla-thesis03,
  author =       "Vincent Claveau",
  title =        "Acquisition automatique de lexiques s\'{e}mantiques
                 pour la recherche d'information",
  school =       "Universit\'{e} de Rennes 1",
  year =         "2003",
  OPTkey =       "",
  OPTtype =      "",
  address =      "Rennes, France",
  month =        dec,
  OPTmois =      "d\'{e}cembre",
  OPTnote =      "Th\`{e}se de doctorat",
  OPTannote =    "",
  resume =       "De nombreuses applications du traitement automatique
                 des langues (recherche d'information, traduction
                 automatique, etc.) requi-b\`{e}rent des ressources
                 s\'{e}mantiques sp\'{e}cifiques \`{a} leur tche et
                 \`{a} leur domaine. Pour r\'{e}pondre \`{a} ces besoins
                 sp\'{e}cifiques, nous avons d\'{e}velopp\'{e} ASARES,
                 un syst\`{e}me d'acquisition d'informations
                 s\'{e}mantiques lexicales sur corpus. Celui-ci
                 r\'{e}pond \`{a} un triple objectif : il permet de
                 fournir des r\'{e}sultats de bonne qualit\'{e}, ses
                 r\'{e}sultats et le processus ayant conduit \`{a} leur
                 extraction sont interpr\'{e}tables, et enfin, il est
                 assez g\'{e}n\'{e}rique et automatique pour \^{e}tre
                 ais\'{e}ment portable d'un corpus \`{a} un autre. Pour
                 ce faire, ASARES s'appuie sur une technique
                 d'apprentissage artificiel symbolique --- la
                 programmation logique inductive --- qui lui permet
                 d'inf\'{e}rer des patrons d'extraction
                 morphosyntaxiques et s\'{e}mantiques \`{a} partir
                 d'exemples des \'{e}l\'{e}ments lexicaux
                 s\'{e}mantiques que l'on souhaite acqu\'{e}rir. Ces
                 patrons sont ensuite utilis\'{e}s pour extraire du
                 corpus de nouveaux \'{e}l\'{e}ments. Nous montrons
                 \'{e}galement qu'il est possible de combiner cette
                 approche symbolique avec des techniques d'acquisition
                 statistiques qui conf\`{e}rent une plus grande
                 automaticit\'{e} \`{a} ASARES. Pour \'{e}valuer la
                 validit\'{e} de notre m\'{e}thode, nous l'avons
                 appliqu\'{e}e \`{a} l'extraction d'un type de relations
                 s\'{e}mantiques entre noms et verbes d\'{e}finies au
                 sein du Lexique g\'{e}n\'{e}ratif appel\'{e}es
                 relations qualia. Cette tche d'acquisition rev\^{e}t
                 deux int\'{e}r\^{e}ts principaux. D'une part, ces
                 relations ne sont d\'{e}finies que de mani\`{e}re
                 th\'{e}orique ; l'interpr\'{e}tabilit\'{e} linguistique
                 des patrons inf\'{e}r\'{e}s permet donc d'en
                 pr\'{e}ciser le fonctionnement et les r\'{e}alisations
                 en contexte. D'autre part, plusieurs auteurs ont
                 not\'{e} l'int\'{e}r\^{e}t de ce type de relations dans
                 le domaine de la recherche d'information pour donner
                 acc\`{e}s \`{a} des reformulations s\'{e}mantiquement
                 \'{e}quivalentes d'une m\^{e}me id\'{e}e. Grce \`{a}
                 une exp\'{e}rience d'extension de requ\^{e}tes, nous
                 v\'{e}rifions exp\'{e}rimentalement cette affirmation :
                 nous montrons que les r\'{e}sultats d'un syst\`{e}me de
                 recherche exploitant ces relations qualia, acquises par
                 ASARES, sont am\'{e}lior\'{e}s de mani\`{e}re
                 significative quoique localis\'{e}e.",
  abstract =     "Many applications in the field of Natural Language
                 Processing (information retrieval, machine translation,
                 etc.) need semantic resources that are specific to
                 their tasks and domains. To satisfy this need we have
                 developed ASARES, a corpus-based lexical semantic
                 acquisition system. It fulfills three objectives: it
                 has good extraction results; these results and the
                 whole acquisition process are interpretable; and it is
                 generic and automatic enough to be easily portable from
                 a corpus to another. To achieve these goals, ASARES
                 uses a machine learning method ---inductive logic
                 programming--- which makes possible to infer
                 part-of-speech and semantic patterns from examples of
                 the semantic elements we want to acquire. These
                 patterns are then used to extract new elements from the
                 corpus. We also show that it is possible to combine
                 this symbolic method with statistical acquisition
                 methods to make ASARES more automatic. To validate our
                 system, we have used it to acquire a kind of semantic
                 relations between nouns and verbs defined in the
                 Generative Lexicon and called qualia relations. This
                 task has two main interests. On one hand, these
                 relations are defined only in a theoretical point of
                 view; the linguistic interpretation of the patterns
                 thus allows to have a deeper understanding of their
                 contextual realizations. On the other hand, several
                 authors have noticed that such relations can be useful
                 in information retrieval tasks because they make
                 semantically equivalent reformulations of ideas
                 accessible. With the help of a query expansion
                 experiment using qualia relations extracted with
                 ASARES, we show that this assumption is true to a
                 certain extend: the performances of an information
                 retrieval system are significantly improved though
                 localized.",
  URL =          "http://olst.ling.umontreal.ca/\~{}vincent/publis.html",
}

@Article{CSBF-JMLR03,
  author =       "Vincent Claveau and Pascale S\'{e}billot and
                 C\'{e}cile Fabre and Pierrette Bouillon",
  title =        "Learning Semantic Lexicons from a Part-of-Speech and
                 Semantically Tagged Corpus using Inductive Logic
                 Programming",
  journal =      "Journal of Machine Learning Research (JMLR), special
                 issue on ILP",
  year =         "2003",
  volume =       "4",
  pages =        "493--525",
  month =        aug,
  mois =         "ao\^{u}t",
  abstract =     "This paper describes an inductive logic programming
                 learning method designed to acquire from a corpus
                 specific Noun-Verb (N-V) pairs---relevant in
                 information retrieval applications to perform index
                 expansion---in order to build up semantic lexicons
                 based on Pustejovsky's generative lexicon (GL)
                 principles (Pustejovsky, 1995). In one of the
                 components of this lexical model, called the qualia
                 structure, words are described in terms of semantic
                 roles. For example, the telic role indicates the
                 purpose or function of an item (cut for knife), the
                 agentive role its creation mode (build for house), etc.
                 The qualia structure of a noun is mainly made up of
                 verbal associations, encoding relational information.
                 The learning method enables us to automatically
                 extract, from a morpho-syntactically and semantically
                 tagged corpus, N-V pairs whose elements are linked by
                 one of the semantic relations defined in the qualia
                 structure in GL. It also infers rules explaining what
                 in the surrounding context distinguishes such pairs
                 from others also found in sentences of the corpus but
                 which are not relevant. Stress is put here on the
                 learning efficiency that is required to be able to deal
                 with all the available contextual information, and to
                 produce linguistically meaningful rules.",
  URL =          "http://olst.ling.umontreal.ca/\~{}vincent/publis.html",
}

@InProceedings{Cla-TALN03,
  author =       "Vincent Claveau",
  title =        "Extraction de couples nom-verbe : une technique
                 symbolique automatique",
  booktitle =    "Actes de la 10\`{e}me conf\'{e}rence de Traitement
                 automatique des langues naturelles (TALN'03)",
  year =         "2003",
  address =      "Batz-sur-Mer, France",
  month =        jun,
  mois =         "juin",
  abstract =     "In the Generative Lexicon framework (Pustejovsky,
                 1995), some semantic properties of common nouns are
                 expressed with the help of verbs. These noun-verb pairs
                 are relevant in various domains, especially in
                 Information Retrieval. Their corpus-based acquisition
                 is thus an interesting issue; moreover discovering the
                 contextual patterns in which these pairs can occur is
                 also important in order to understand the Generative
                 Lexicon model. This paper presents a fully automated
                 technique that allows us to acquire from a corpus both
                 noun-verb pairs, and semantic and morpho-syntactic
                 patterns. This technique combines two acquisition
                 approaches--the statistical one and the symbolic
                 one--and keeps advantages of each approach: robustness
                 and automation of statistical methods, quality of the
                 results and expressiveness of symbolic ones.",
  resume =       "Dans le mod\`{e}le du Lexique g\'{e}n\'{e}ratif
                 (Pustejovsky, 1995), certaines propri\'{e}t\'{e}s
                 s\'{e}mantiques des noms sont exprim\'{e}es \`{a} l
                 aide de verbes. Les couples nom-verbe ainsi form\'{e}s
                 pr\'{e}sentent un int\'{e}r\^{e}t applicatif notamment
                 en recherche d information. Leur acquisition sur corpus
                 constitue donc un enjeu, mais la d\'{e}couverte des
                 patrons qui les d\'{e}finissent en contexte est
                 \'{e}galement importante pour la compr\'{e}hension
                 m\^{e}me du mod\`{e}le du Lexique g\'{e}n\'{e}ratif.
                 Cet article pr\'{e}sente une technique enti\`{e}rement
                 automatique permettant de r\'{e}pondre \`{a} ce double
                 besoin d extraction sur corpus de couples et de patrons
                 morpho-syntaxiques et s\'{e}mantiques. Elle combine
                 pour ce faire deux approches d acquisition l approche
                 statistique et l approche symbolique en conservant les
                 avantages propres \`{a} chacune d entre elles :
                 robustesse et automatisation des m\'{e}thodes
                 statistiques, qualit\'{e} et expressivit\'{e} des
                 r\'{e}sultats des techniques symboliques.",
  URL =          "http://olst.ling.umontreal.ca/\~{}vincent/publis.html",
}

@InProceedings{CS-AFIA03,
  author =       "Vincent Claveau and Pascale S\'{e}billot",
  title =        "Apprentissage symbolique pour l'acquisition de
                 ressources linguistiques",
  booktitle =    "Actes de l'atelier {"}Acquisition, apprentissage et
                 exploitation de connaissances s\'{e}mantiques pour
                 l'acc\`{e}s au contenu textuel{"} de la plateforme
                 AFIA",
  OPTcrossref =  "",
  OPTkey =       "",
  OPTpages =     "",
  year =         "2003",
  OPTeditor =    "",
  OPTvolume =    "",
  OPTnumber =    "",
  OPTseries =    "",
  address =      "Laval, France",
  month =        jul,
  OPTmois =      "juillet",
  OPTorganization = "",
  OPTpublisher = "",
  OPTnote =      "",
  OPTannote =    "",
  resume =       "Cet article pr\'{e}sente une approche originale pour
                 l'extraction sur corpus d'un type de ressources
                 linguistiques issues du Lexique g\'{e}n\'{e}ratif
                 (Pustejovsky, 1995), les couples qualia, qui
                 pr\'{e}sentent un grand int\'{e}r\^{e}t pour la
                 recherche d information. Cette approche s'appuie sur la
                 programmation logique inductive (PLI) pour inf\'{e}rer
                 des patrons d'extraction \`{a} partir d'exemples de
                 couples qualia en contexte. Cette technique
                 d'acquisition donne des r\'{e}sultats tr\`{e}s
                 sup\'{e}rieurs aux techniques statistiques
                 habituellement employ\'{e}es pour ce type de tche.
                 Elle permet aussi, grce \`{a} l'aspect symbolique de
                 la PLI, de pr\'{e}ciser le concept m\^{e}me de r\^{o}le
                 qualia. Nous proposons \'{e}galement deux modifications
                 de cette technique afin de supprimer la phase manuelle
                 de construction des exemples. Les deux syst\`{e}mes
                 r\'{e}sultants sont ainsi enti\`{e}rement automatiques
                 et pr\'{e}sentent des r\'{e}sultats similaires \`{a} la
                 version originale.",
  URL =          "http://olst.ling.umontreal.ca/\~{}vincent/publis.html",
}

@InProceedings{BCFS-LREC02,
  author =       "Pierrette Bouillon and Vincent Claveau and C\'{e}cile
                 Fabre and Pascale S\'{e}billot",
  title =        "Acquisition of Qualia Elements from Corpora -
                 Evaluation of a Symbolic Learning Method",
  booktitle =    "Proceedings of the Lexical Ressources and Evaluation
                 Conference (LREC'02)",
  year =         "2002",
  address =      "Las Palmas de Gran Canaria, Spain",
  adresse =      "Las Palmas de Gran Canaria, Espagne",
  month =        may,
  mois =         "mai",
  abstract =     "This paper presents and evaluates a system extracting
                 from a corpus noun-verb pairs whose components are
                 related by a special kind of link: the qualia roles as
                 defined in the Generative Lexicon. This system is based
                 on a symbolic learning method that automatically
                 learns, from noun-verb pairs that are or are not
                 related by a qualia link, rules characterizing positive
                 examples from negative ones in terms of their
                 surrounding part-of-speech or semantic contexts. The
                 qualia noun-verb pair extraction is thus performed by
                 applying the learnt rules on a part-of-speech or
                 semantically tagged text. Stress is put on the quality
                 of the learning when compared with traditional
                 statistical or syntactical-based approaches. The
                 linguistic relevance of the rules is also evaluated
                 through a comparison with manually acquired qualia
                 patterns.",
  URL =          "http://olst.ling.umontreal.ca/\~{}vincent/publis.html",
}

@Article{CSBF-TAL01,
  author =       "Vincent Claveau and Pascale S\'{e}billot and Pierrette
                 Bouillon and C\'{e}cile Fabre",
  title =        "Acqu\'{e}rir des \'{e}l\'{e}ments du lexique
                 g\'{e}n\'{e}ratif : quels r\'{e}sultats et \`{a} quels
                 co\^{u}ts ?",
  journal =      "TAL (traitement automatique des langues), num\'{e}ro
                 sp\'{e}cial Lexiques s\'{e}mantiques dans les
                 applications du TAL",
  year =         "2001",
  volume =       "42",
  number =       "3",
  resume =       "Dans cet article, nous montrons, \`{a} travers
                 l'expos\'{e} de quatre exp\'{e}riences d'apprentissage
                 manipulant diverses informations cat\'{e}gorielles et
                 s\'{e}mantiques relatives aux mots d'un corpus, qu'il
                 est possible d'acqu\'{e}rir automatiquement certains
                 \'{e}l\'{e}ments du Lexique G\'{e}n\'{e}ratif (sous
                 forme de listes de couples nom-verbe dont les
                 constituants sont li\'{e}s par un des r\^{o}les de la
                 structure des qualia), pr\'{e}sentant un grand
                 int\'{e}r\^{e}t applicatif, en particulier en recherche
                 d'information. Si l'exploitation des seules
                 informations cat\'{e}gorielles par une m\'{e}thode
                 d'apprentissage de type programmation logique inductive
                 offre d\'{e}j\`{a} de bons r\'{e}sultats, nos travaux
                 prouvent que le meilleur compromis qualit\'{e} de
                 l'apprentissage/co\^{u}t de la m\'{e}thode est obtenu
                 en utilisant un \'{e}tiquetage cat\'{e}goriel
                 coupl\'{e} \`{a} un \'{e}tiquetage s\'{e}mantique des
                 mots autres que les noms.",
  abstract =     "This paper demonstrates the feasibility of automatic
                 acquisition of generative lexicons from corpora through
                 the report of four experiments in machine learning in
                 which various levels of word tagging (categorial and
                 semantic) are handled. The lexical information that is
                 learnt consists of lists of noun-verb couples related
                 by one of the roles of the qualia structure. They
                 provide linguistic knowledge useful in many
                 applications such as information retrieval. We first
                 show that satisfactory results are obtained on the
                 basis of categorial information only, exploited by
                 means of a learning method in the Inductive Logic
                 Programming framework. We further demonstrate that the
                 balance between quality and cost of the learning method
                 is reached by the combination of a categorial tagging
                 and a semantic tagging of words others than nouns.",
  URL =          "http://olst.ling.umontreal.ca/\~{}vincent/publis.html",
}

@InProceedings{BCFS-GL01,
  author =       "Pierrette Bouillon and Vincent Claveau and C\'{e}cile
                 Fabre and Pascale S\'{e}billot",
  title =        "Using Part-of-Speech and Semantic Tagging for the
                 Corpus-Based Learning of Qualia Structure Elements",
  booktitle =    "First international workshop on Generative Approaches
                 to the Lexicon (GL'01)",
  year =         "2001",
  address =      "Geneva, Switzerland",
  adresse =      "Gen\`{e}ve, Suisse",
  month =        apr,
  mois =         "avril",
  resume =       "Cet article d\'{e}crit l'impl\'{e}mentation et les
                 r\'{e}sultats d'une m\'{e}thode d'apprentissage
                 automatique, d\'{e}velopp\'{e}e dans le cadre de la
                 programmation logique inductive (PLI - ILP), pour
                 extraire automatiquement d'un corpus \'{e}tiquet\'{e}
                 cat\'{e}goriellement et s\'{e}mantiquement, des paires
                 Nom-Verbe dont les composants sont li\'{e}s par une des
                 relations d\'{e}finies dans la structure des qualia
                 dans le Lexique G\'{e}n\'{e}ratif [Pustejovsky 95].
                 Nous montrons que l'\'{e}tiquetage s\'{e}mantique
                 am\'{e}liore la qualit\'{e} de l'apprentissage, \`{a}
                 la fois d'un point de vue th\'{e}orique et empirique.
                 Nous mettons aussi en \'{e}vidence la pertinence de la
                 signification linguistique de certaines des r\`{e}gles
                 apprises en ce qui concerne la d\'{e}tection
                 d'\'{e}l\'{e}ments distinguant, en termes de contexte
                 cat\'{e}goriel et s\'{e}mantique, les paires Nom-Verbe
                 li\'{e}es par une des relations qualia des paires qui
                 ne sont pas reli\'{e}es s\'{e}mantiquement.",
  abstract =     "This paper describes the implementation and results of
                 a machine learning method, developed within the
                 inductive logic programming (ILP) framework [Muggleton
                 94], to automatically extract, from a corpus tagged
                 with parts of speech (POS) and semantic classes,
                 noun-verb pairs whose components are bound by one of
                 the relations defined in the qualia structure in the
                 Generative Lexicon [Pustejovsky 95]. We demonstrate
                 that the semantic tagging of the corpus improves the
                 quality of the learning, both on a theoretical and an
                 empirical point of view. We also show that a set of the
                 rules learnt by our ILP method have a linguistic
                 significance regarding the detection of the clues that
                 distinguish, in terms of POS and semantic surrounding
                 context, noun-verb pairs that are linked by one qualia
                 role from others that are not semantically related.",
  URL =          "http://olst.ling.umontreal.ca/\~{}vincent/publis.html",
}

@InProceedings{sebillot00:_aeppr,
  author =       "Pascale S\'{e}billot and Pierrette Bouillon and
                 Vincent Claveau and C\'{e}cile Fabre and Laurence
                 Jacqmin and Jacques Nicolas",
  title =        "Apprentissage en corpus de couples nom-verbe pour la
                 construction d'un lexique g\'{e}n\'{e}ratif",
  booktitle =    "Actes des Journ\'{e}es internationales d'analyse de
                 donn\'{e}es textuelles (JADT 2000)",
  year =         "2000",
  address =      "Lausanne, Switzerland",
  adresse =      "Lausanne, Suisse",
  month =        mar,
  mois =         "mars",
  resume =       "D\'{e}sambigu{\"{}\i}ser, paraphraser sont des
                 activit\'{e}s qui n\'{e}cessitent pour les syst\`{e}mes
                 de TAL de s'appuyer sur des descriptions lexicales
                 fines. Dans ce but, cet article propose une m\'{e}thode
                 pour extraire automatiquement \`{a} partir de corpus
                 des informations lexicales d\'{e}finies par Pustejovsky
                 dans le cadre du Lexique G\'{e}n\'{e}ratif. Dans une
                 des composantes de ce mod\`{e}le lexical, la structure
                 des qualia, les noms sont d\'{e}crits \`{a} l aide de
                 r\^{o}les s\'{e}mantiques, principalement en termes d
                 associations verbales. Par exemple, le mot mesurer
                 exprime le r\^{o}le t\'{e}lique du nom jaugeur. Notre
                 m\'{e}thode consiste \`{a} extraire automatiquement,
                 pour un nom (N) donn\'{e}, les verbes (V) qui
                 permettent de remplir cette structure des qualia. Elle
                 est bas\'{e}e sur une technique d'apprentissage dans le
                 cadre de la Programmation Logique Inductive, et nous
                 permet de distinguer les paires N-V li\'{e}es par une
                 relation s\'{e}mantique de celles qui ne le sont pas.
                 Les r\'{e}sultats obtenus, compar\'{e}s \`{a} un test
                 du Chi2 sont encourageants \`{a} deux titres : cette
                 technique rep\`{e}re une proportion importante de
                 paires pertinentes et fournit des informations qui
                 peuvent \^{e}tre utilis\'{e}es pour construire des
                 r\`{e}gles linguistiques.",
  abstract =     "NLP systems involving disambiguation and rephrasing
                 require a fine-grained description of the semantics of
                 lexical units. In this paper we describe a means for
                 automatically extracting such information from corpora,
                 in the framework of Pustejovsky s Generative Lexicon.
                 In one of the components of this lexical model, called
                 the qualia structure, words are described in terms of
                 semantic roles. The qualia structure of a noun is
                 mainly made up of verbal associations, encoding
                 relational information. For example, the French verb
                 mesurer refers to the telic role of the noun jaugeur.
                 Our aim is, for a given noun (N), to be able to
                 automatically extract from a corpus the verbs (V) that
                 could belong to its qualia structure. More precisely,
                 in this paper, we describe a method based on learning
                 techniques within the Inductive Logic Programming
                 framework, that permits us to distinguish in the corpus
                 between N-V pairs that are linked by a semantic
                 relation and pairs that are not. Results compared with
                 a Chi2 score demonstrate that the method is very
                 promising, not only because an important proportion of
                 relevant pairs are detected, but also because it
                 provides information that can be used to build
                 linguistic rules.",
  URL =          "http://olst.ling.umontreal.ca/\~{}vincent/publis.html",
}

@InCollection{cussens02:_issues_learn_languag_logic,
  author =       "James Cussens",
  title =        "Issues in Learning Language in Logic",
  booktitle =    "Computational Logic: Logic Programming and Beyond",
  pages =        "491--505",
  publisher =    "Springer",
  year =         "2002",
  editor =       "Antonis C. Kakas and Fariba Sadri",
  volume =       "2408",
  series =       "{LNAI}",
  address =      "Berlin",
  abstract =     "Selected issues concerning the use of logical
                 representations in machine learning of natural language
                 are discussed. It is argued that the flexibility and
                 expressivity of logical representations are
                 particularly useful in more complex natural language
                 learning tasks. A number of inductive logic programming
                 (ILP) techniques for natural language are analysed
                 including the CHILL system, abduction and the
                 incorporation of linguistic knowledge, including active
                 learning. Hybrid approaches integrating ILP with manual
                 development environments and probabilistic techniques
                 are advocatd.",
  URL =          "http://link.springer.de/link/service/series/0558/bibs/2408/24080491.htm",
}
