% This file was created with JabRef 2.6.
% Encoding: UTF8

@ARTICLE{chen2010,
  author = {Chen, Shen-yi and Qian, Hui and Fan, Jia and Jin, Zhuo-jun and Zhu,
	Miao-liang},
  title = {Modified reward function on abstract features in inverse reinforcement
	learning},
  journal = {JOURNAL OF ZHEJIANG UNIVERSITY-SCIENCE C-COMPUTERS \& ELECTRONICS},
  year = {2010},
  volume = {11},
  pages = {718-723},
  number = {9},
  month = {SEP},
  abstract = {We improve inverse reinforcement learning (IRL) by applying dimension
	reduction methods to automatically extract abstract features from
	human-demonstrated policies, to deal with the cases where features
	are either unknown or numerous. The importance rating of each abstract
	feature is incorporated into the reward function. Simulation is performed
	on a task of driving in a five-lane highway, where the controlled
	car has the largest fixed speed among all the cars. Performance is
	almost 10.6\% better on average with than without importance ratings.},
  address = {{EDITORIAL BOARD, 20 YUGU RD, HANGZHOU, 310027, PEOPLES R CHINA}},
  affiliation = {{Chen, SY (Reprint Author), Zhejiang Univ, Sch Comp Sci \& Technol,
	Hangzhou 310027, Peoples R China. {[}Chen, Shen-yi; Qian, Hui; Fan,
	Jia; Jin, Zhuo-jun; Zhu, Miao-liang] Zhejiang Univ, Sch Comp Sci
	\& Technol, Hangzhou 310027, Peoples R China.}},
  author-email = {{charles\_csy@zju.edu.cn}},
  doc-delivery-number = {{648YY}},
  doi = {10.1631/jzus.C0910486},
  issn = {{1869-1951}},
  journal-iso = {{J. Zhejiang Univ.-SCI. C.}},
  keywords = {Importance rating; Abstract feature; Feature extraction; Inverse reinforcement
	learning (IRL); Markov decision process (MDP)},
  language = {{English}},
  number-of-cited-references = {{19}},
  publisher = {{ZHEJIANG UNIV}},
  subject-category = {{Computer Science, Information Systems; Computer Science, Software
	Engineering; Engineering, Electrical \& Electronic}},
  times-cited = {{1}},
  type = {{Article}},
  unique-id = {{ISI:000281732700005}}
}

