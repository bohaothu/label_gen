@InProceedings{daume10multilingual,
  author =       {Jagadeesh Jagarlamudi and Hal {Daum\'e III}},
  title =        {Extracting Multilingual Topics from Unaligned Corpora},
  booktitle =    {Proceedings of the European Conference on Information Retrieval (ECIR)},
  year =         {2010},
  address =      {Milton Keynes, United Kingdom},
  abstract =     {
    Topic models have been studied extensively in the context of
    monolingual corpora. Though there are some attempts to mine topical
    structure from cross-lingual corpora, they require clues about document
    alignments. In this paper we present a generative model called JointLDA
    which uses a bilingual dictionary to mine multilingual topics from an
    unaligned corpus. Experiments conducted on different data sets confirm
    our conjecture that jointly modeling the cross-lingual corpora offers several
    advantages compared to individual monolingual models. Since the
    JointLDA model merges related topics in different languages into a single
    multilingual topic: a) it can fit the data with relatively fewer topics. b)
    it has the ability to predict related words from a language different than
    that of the given document. In fact it has better predictive power compared
    to the bag-of-word based translation model leaving the possibility
    for JointLDA to be preferred over bag-of-word model for cross-lingual
    IR applications. We also found that the monolingual models learnt while
    optimizing the cross-lingual copora are more effective than the corresponding
    LDA models.
  },
  keywords = {nlp ml},
  tagline = {We show how topic models can be used to model unaligned multilingual corpora, such as Wikipedia.},
  url = {http://pub.hal3.name/#daume10multilingual}
}
