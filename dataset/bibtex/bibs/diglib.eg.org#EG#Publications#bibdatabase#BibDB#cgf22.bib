<html><head>     
<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1">
<meta http-equiv="cache-control" content="no-cache">
<meta http-equiv="pragma" content="no-cache">
<META HTTP-EQUIV="EXPIRES" CONTENT="Mon, 22 Jul 2002 11:12:01 GMT">

<SCRIPT SRC="/wavemaster.internal/v2.6/tools-eg_bs/cookie.js"></SCRIPT>
 <STYLE TYPE="text/css"><!--
 .hw-annotation { text-decoration: none; color: black; background:#f3ca81; font-weight: bold; }
--></STYLE>
<META NAME="Author" VALUE="hwsystem">
<META NAME="DocumentType" VALUE="text">
<META NAME="GOid" VALUE="0x811bda11_0x000008dd">
<META NAME="HW_Checksum" VALUE="886022caaa1427281d15e5138ea0f65e">
<META NAME="HW_ChildAccess" VALUE="NO_ACCESS">
<META NAME="HW_EffectiveAccess" VALUE="READ_ACCESS">
<META NAME="HW_ObjectName" VALUE="cgf22.bib">
<META NAME="MimeType" VALUE="text/plain">
<META NAME="Name" VALUE="EG/DL/BibDB/cgf22.bib">
<META NAME="ObjectID" VALUE="0x0000000d">
<META NAME="PLACETemplate" VALUE="egnew/master">
<META NAME="Path" VALUE="DC0x00000756 0x00017bf7">
<META NAME="Rights" VALUE="R:a, g eg-pub eg-root everyone; W:a, g eg-pub eg-root; A:a">
<META NAME="TimeCreated" VALUE="2007/10/15 08:23:14">
<META NAME="TimeModified" VALUE="2008/01/16 09:54:48">
<META NAME="Title" VALUE="en:cgf22.bib">
<META NAME="Type" VALUE="Document">
<TITLE>cgf22.bib</TITLE>
<BASE HREF="http://diglib.eg.org/EG/DL/BibDB/cgf22.bib">

<style type="text/css">



body,td,p {
	color:#333333;
	font-size:15px;
	font-family: Trebuchet MS, Trebuchet,  Helvetica, Arial, sans-serif;
}

a { text-decoration:none; }

a:link { color:#0099ff; }

a:visited { color:#336699; }

a:active { color:#ff9900; }

a:hover {  color:#ff9900;  }


a.small:link { color:#0099ff;font-size:12px; }

a.small:visited { color:#336699;font-size:12px; }

a.small:active { color:#ff9900;font-size:12px; }

a.small:hover {  color:#ff9900;font-size:12px;  }

.small {
	font-family: Helvetica, Arial, sans-serif;
	font-size:12px;					
	color:#333333;
       }   
h1 {
	font-size: 21px;
	color:#ff9900;
	font-weight: bold;
}
h2 {
	font-size: 18px;
	color:#ff9900;
	font-weight: bold;
	margin-bottom: 0px;
}
h3 {
	margin-bottom: 0px;
	color:#ff9900;
	font-weight: bold;
}
strong {
	color:#666666;
}
.menu{
	background-color:#ffffff;
	font-size:13px;
	font-weight: bold;
	font-family: Trebuchet MS, Trebuchet,  Helvetica, Arial, sans-serif;
	text-align:center;
	line-height: 18px;
        }
.menuselected{
	background-color:#ff9900;
	font-size:13px;
	font-weight: bold;
	color:#000000;
	font-family: Trebuchet MS, Trebuchet, Helvetica, Arial, sans-serif;
	text-align:center;
	line-height: 18px;
        }

.menu a {color:#000000;
		}
.menu a:hover {  color:#ff9900;  
		}
.menu2{
	background-color:#ffffff;
	padding-left:13px; 
	font-size:12px;
	color:#ff9900;
	line-height: 24px;
	font-family: "Trebuchet MS", "Trebuchet", Arial, Helvetica, sans-serif;
        }
.menu2 a {color:#0099ff;
		}
.menu2 a:hover {  color:#ff9900;  
		}
.menu3{
	background-color:#ffffff;
	text-align:center; 
	font-size:13px;
	color:#ff9900;
	line-height: 24px;
	font-family: "Trebuchet MS", "Trebuchet", Arial, Helvetica, sans-serif;
        }
.box1{
	background-color:#ff9900;
	font-size:13px;
	font-weight: bold;
	font-family: Trebuchet MS, Trebuchet,  Helvetica, Arial, sans-serif;
	line-height: 19px;
	color:#ffffff;
	text-align:right;
        }
.box2{
	background-color:#66ccff;
	font-size:13px;
	font-weight: bold;
	font-family: Trebuchet MS, Trebuchet,  Helvetica, Arial, sans-serif;
	line-height: 19px;
	color:#ffffff;
	text-align:right;
        }
.boxtopic{
	text-align:right;
	padding-right:16px; 
        }
.boxcontent {
	font-family: Helvetica, Arial, sans-serif;
	font-size:12px;	
	color:#333333;
	text-align:left;
	padding:16px;
       }
.hr1{
	color:#ff9900;
        }
.hr2{
	color:#66ccff;
        }
.frame1{
	background-color:#ff9900;
        }
.frame2{
	background-color:#66ccff;
        }
.content {border:0; 
	padding-left:12px;
	padding-right:12px;
	}
	

.box3{
   background-color:#66ccff;
   font-size:13px;
   font-weight: bold;
   font-family: Trebuchet MS, Trebuchet,  Helvetica, Arial, sans-serif;
   line-height: 19px;
   color:#ffffff;
   text-align:center;
}

.box4{
   background-color:#66ccff;
   font-size:13px;
   font-weight: bold;
   font-family: Trebuchet MS, Trebuchet,  Helvetica, Arial, sans-serif;
   line-height: 19px;
   color:#ffffff;
   text-align:left;
}

.boxcontent2 {
	font-family: Helvetica, Arial, sans-serif;
	font-size:12px;	
	color:#333333;
	text-align:center;
	padding:10px;
}

.boxcontent3 {
   font-family: Helvetica, Arial, sans-serif;
   font-size:12px;
   color:#333333;
   text-align:right;
   padding:10px;
}

.boxcontent4 {
   font-family: Helvetica, Arial, sans-serif;
   font-size:12px;	
   color:#333333;
   text-align:left;
   padding:10px;
}

	
</style>

</HEAD>
<BODY   alink="#ff9900" bgcolor="#FFFFFF" link="#0099ff" text="#000000" vlink="#336699">






<table width="761" border="0" align="left" cellpadding="0" cellspacing="0">
  <!--DWLayoutTable-->
  <tr> 
    <!--The Logo will be shown next: -->


    <td>

    	<table width="144" border="0" cellspacing="0" cellpadding="1" class=frame1>

    		<tr>

    		<td width="142" align="center"><a href="http://www.eg.org/"><img src="http://diglib.eg.org/v2.6/graphics/new/logo.gif;internal&inline=true" alt="EG - Logo" width="142" height="110" border="0"></a></td>

    		</tr>

    	</table>

    </td>

    <td width="17"><img src="http://diglib.eg.org/v2.6/graphics/new/spacer.gif;internal&inline=true" width="17" height="1"></td>

    <td>

    	<table width="600" border="0" cellspacing="0" cellpadding="1" class=frame1>

    		<tr>

    		<td width="598"><img src="http://diglib.eg.org/v2.6/graphics/new/head.gif;internal&inline=true" alt="EuroGraphics" width="598" height="110"></td>

    		</tr>

    	</table>

    </td>

    

    

    

  </tr>
  <tr> 
    <td colspan="3" width="761" height="17"><img src="news-Dateien/spacer.gif" width="1" height="17"></td>
  </tr>
  <tr> 
    <td width="144" valign="top"> 
           
      <!--The Member Login Box will be shown next: -->
      <table width="100%" border="0" cellspacing="0" cellpadding="1" class=frame1>

<TBODY>
<TR>
   <TD>
            <TABLE border=0 cellPadding=0 cellSpacing=0 width="100%">
              <TBODY>
              <TR>
                <TD align=right bgColor=#cccccc class=box1><SPAN 
                  class=boxtopic>Members</SPAN></TD></TR>
              <TR>
                <TD bgColor=#ffffff>
                  <DIV class=boxcontent>
                  Please 

                  <A  HREF="http://www.eg.org/login">login</A> 
                  
                  
                  
                  <!--(note for <a href="/safari.html">Safari users</a>)-->
                  if you are a member or <a  href="/about/membership">read more</a> about the advantages of an EG membership.
                  <HR class=hr1 noShade SIZE=1>
                  <br>
                  
                  Not yet member? <A HREF="/join">Application</A><br>
                  <A HREF="https://www.eg.org/renew">Renewal</A>
                  <HR class=hr1 noShade SIZE=1>
                  Forgot your password? <A HREF="http://diglib.eg.org/EG/DL/BibDB/cgf22.bib;internal&action=forgot.password.action">Click  here!</A> 
                 </DIV></TD>  
                 </TR></TBODY></TABLE></TD></TR></TBODY>
      </table>
      <br> 
      <!--The New Box will be shown next: -->
      <table width="100%" border="0" cellspacing="0" cellpadding="1" class="frame2">
<tr>
	<td>
		<table border="0" cellpadding="0" cellspacing="0" width="100%">
        	<tbody><tr>
           		<td class="box2" align="right" bgcolor="#cccccc"><span class="boxtopic">EG 2009</span></td>
			</tr>
			<tr>
           		<td bgcolor="#ffffff">
				<div class="boxcontent">
				
                <a href="http://www.eurographics2009.de/">Eurographics 2009:</a> 30th of March to the 3rd of April 2009 in Munich (Germany).
				<hr noshade class="hr2" size="1" >
				<!--<a href="http://www.ics.forth.gr/eg2008/" target="_blank"><img src="/EG/images/eg2k8.png" border="0" height="23" width="103"></a>
			         EG08 will be from 14th to the 18th April 2008
                              <hr class="hr2" noshade="noshade" size="1">-->

                          <!--
                        Eurographics 2007: 3rd to the 7th September 2007 in Prague (Czech Republic).
				<hr noshade class="hr2" size="1" >
				Previous Event: <a href="http://www.cgg.cvut.cz/eg07/">Eurographics 2007</a>
				-->
                       <!-- Eurographics 2006: 4th - 8th of September 2006 in Vienna (Austria)<br>
                        <hr noshade class="hr2" size="1" >-->
			<!--    Previous Event: <a href="http://www.cg.tuwien.ac.at/events/EG06/index.html">Eurographics 2006</a>>-->
                                Previous Event: <a href="http://www.ics.forth.gr/eg2008/">Eurographics 2008</a>
				</div>
				</td>
			</tr>
		</tbody></table>
	</td>
</tr>
      </table>
      <br>

      
    </td>
    <td>&nbsp;</td>

	<td valign="top">

                <PRE>

@article{Masso:2003:AHH,
author = {Masso,J. P. Molina and Lopez,P. Gonzalez},
title = {Automatic Hybrid Hierarchy Creation: a Cost-model Based Approach},
journal = {Computer Graphics Forum},
volume = {22},
number = {1},
pages = {5-5},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue1/22005.pdf},
abstract = { Abstract  While using hierarchical search structures has been proved as one of the most efficient acceleration techniques when rendering complex scenes, automatic creation of appropriate hierarchies is not solved yet. Well-known algorithms for automatic creation of bounding volume hierarchies are not enough. Higher performance is achieved by introducing spatial uniform subdivision, although algorithms proposed up to now are not truly automatic, as they need some parameters to be adjusted. In this paper we present a full-automatic hierarchy creation scheme that structures the scene in a hybrid way, combining bounding volumes and voxel grids in the same tree, selecting the search structure that best fits to each scene region. It uses no parameters at all. This efficient proposal relies on a new cost model that estimates the goodness of a hybrid hierarchy if used for rendering the scene.  {ACM} {CSS}: I.3.7 Computer Graphics-Three-Dimensional Graphics and Realism }}
@article{Kim:2003:TPS,
author = {Kim,Ku-Jin and Lee,In-Kwon},
title = {The Perspective Silhouette of a Canal Surface},
journal = {Computer Graphics Forum},
volume = {22},
number = {1},
pages = {15-15},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue1/22015.pdf},
abstract = { Abstract  We present an efficient and robust algorithm for parameterizing the perspective silhouette of a canal surface and detecting each connected component of the silhouette. A canal surface is the envelope of a moving sphere with varying radius, defined by the trajectoryC(t)of its center and a radius functionr(t). This moving sphere,S(t), touches the canal surface at a characteristic circleK(t). We decompose the canal surface into a set of characteristic circles, compute the silhouette points on each characteristic circle, and then parameterize the silhouette curve. The perspective silhouette of the sphereS(t)from a given viewpoint consists of a circleQ(t); by identifying the values oftat whichK(t)andQ(t)touch, we can find all the connected components of the silhouette curve of the canal surface.  {ACM} {CSS}: I.3.7 Computer Graphics-Three Dimensional Graphics and Realism }}
@article{Barthe:2003:TDP,
author = {Barthe,L. and Dodgson,N. A. and Sabin,M. A. and Wyvill,B. and Gaildrat,V.},
title = {Two-dimensional Potential Fields for Advanced Implicit Modeling Operators},
journal = {Computer Graphics Forum},
volume = {22},
number = {1},
pages = {23-23},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue1/22023.pdf},
abstract = { Abstract  Current methods for building models using implicit volume techniques present problems defining accurate and controllable blend shapes between implicit primitives. We present new methods to extend the freedom and controllability of implicit volume modeling. The main idea is to use a free-form curve to define the profile of the blend region between implicit primitives.  The use of a free-form implicit curve, controlled point-by-point in the Euclidean user space, allows us to group boolean composition operators with sharp transitions or smooth free-form transitions in a single modeling metaphor. This idea is generalized for the creation, sculpting and manipulation of volume objects, while providing the user with simplicity, controllability and freedom in implicit modeling.  {ACM} {CSS}: I.3.5 Computational Gemoetry and Object Modeling-Curve, surface, solid, and object representations }}
@article{Southern:2003:CAC,
author = {Southern,Richard and Gain,James},
title = {Creation and Control of Real-time Continuous Level of Detail on Programmable Graphics Hardware},
journal = {Computer Graphics Forum},
volume = {22},
number = {1},
pages = {35-35},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue1/22035.pdf},
abstract = { Abstract  Continuity in level of detail sequences is essential in hiding visual artefacts that occur when switching between discrete levels of detail. However, construction and implementation of these sequences is prohibitively complex. We present a new structure, the g-mesh, which greatly simplifies the implementation of continuous level of detail in large scenes. We also introduce a novel greedy predictive level of detail control system suited to the g-mesh. Finally we achieve a dramatic improvement in the rendering of morphing sequences by exploiting current graphics hardware.  {ACM} {CSS}: I.3.5 Computational Geometry and Object Modeling-Geometric Transformations, Object Hierarchies, I.3.6 Methodology and Techniques-Graphics Data Structures }}
@article{Ruttkay:2003:EDA,
author = {Ruttkay,Zsofia and Noot,Han and ten Hagen,Paul},
title = {Emotion Disc and Emotion Squares: Tools to Explore the Facial Expression Space},
journal = {Computer Graphics Forum},
volume = {22},
number = {1},
pages = {49-49},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue1/22049.pdf},
abstract = { Abstract  In the paper we present two novel interactive tools, Emotion Disc and Emotion Squares, to explore the facial expression space. They map navigation in a two-dimensional circle, by the first tool, or in two two-dimensional squares, by the second tool, to the high-dimensional parameter space of facial expressions, by using a small number of predefined reference expressions. They can be used as exploration tools by researchers, or as control devices by end-users to put expressions on the face of embodied agents or avatars in applications like games, telepresence and education. }}
@article{Damez:2003:SOT,
author = {Damez,Cyrille and Dmitriev,Kirill and Myszkowski,Karol},
title = {State of the Art in Global Illumination for Interactive Applications and High-quality Animations},
journal = {Computer Graphics Forum},
volume = {22},
number = {1},
pages = {55-55},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue1/22055.pdf},
abstract = { Abstract  Global illumination algorithms are regarded as computationally intensive. This cost is a practical problem when producing animations or when interactions with complex models are required. Several algorithms have been proposed to address this issue. Roughly, two families of methods can be distinguished. The first one aims at providing interactive feedback for lighting design applications. The second one gives higher priority to the quality of results, and therefore relies on offline computations. Recently, impressive advances have been made in both categories. In this report, we present a survey and classification of the most up-to-date of these methods.  {ACM} {CSS}: I.3.7 Computer Graphics-Three-Dimensional Graphics and Realism }}
@article{Stam:2003:QTS,
author = {Stam,Jos and Loop,Charles},
title = {Quad/Triangle Subdivision},
journal = {Computer Graphics Forum},
volume = {22},
number = {1},
pages = {79-79},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue1/22079.pdf},
abstract = { Abstract  In this paper we introduce a new subdivision operator that unifies triangular and quadrilateral subdivision schemes. Designers often want the added flexibility of having both quads and triangles in their models. It is also well known that triangle meshes generate poor limit surfaces when using a quad scheme, while quad-only meshes behave poorly with triangular schemes. Our new scheme is a generalization of the well known Catmull-Clark and Loop subdivision algorithms. We show that our surfaces areC1everywhere and provide a proof that it is impossible to construct such aC2scheme at the quad/triangle boundary. However, we provide rules that produce surfaces with bounded curvature at the regular quad/triangle boundary and provide optimal masks that minimize the curvature divergence elsewhere. We demonstrate the visual quality of our surfaces with several examples.  {ACM} {CSS}: I.3.5 Computer Graphics-Curve, surface, solid, and object representations }}
@article{Nasri:2003:IAU,
author = {Nasri,Ahmed H.},
title = {Interpolating an Unlimited Number of Curves Meeting at Extraordinary Points on Subdivision Surfaces},
journal = {Computer Graphics Forum},
volume = {22},
number = {1},
pages = {87-87},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue1/22087.pdf},
abstract = { Abstract  Interpolating curves by subdivision surfaces is one of the major constraints that is partially addressed in the literature. So far, no more than two intersecting curves can be interpolated by a subdivision surface such as Doo-Sabin or Catmull-Clark surfaces. One approach that has been used in both of theses surfaces is the polygonal complex approach where a curve can be defined by a control mesh rather than a control polygon. Such a definition allows a curve to carry with it cross derivative information which can be naturally embodied in the mesh of a subdivision surface. This paper extends the use of this approach to interpolate an unlimited number of curves meeting at an extraordinary point on a subdivision surface. At that point, the curves can all meet with eitherC0orC1continuity, yet still have common tangent plane. A straight forward application is the generation of subdivision surfaces through 3-regular meshes of curves for which an easy interface can be used. }}
@article{Gotsman:2003:OTO,
author = {Gotsman,Craig},
title = {On the Optimality of Valence-based Connectivity Coding},
journal = {Computer Graphics Forum},
volume = {22},
number = {1},
pages = {99-99},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue1/22099.pdf},
abstract = { Abstract  We show that the average entropy of the distribution of valences in valence sequences for the class of manifold {3D} triangle meshes and the class of manifold {3D} polygon meshes is strictly less than the entropy of these classes themselves. This implies that, apart from a valence sequence, another essential piece of information is needed for valence-based connectivity coding of manifold {3D} meshes. Since there is no upper bound on the size of this extra piece of information, the result implies that the question of optimality of valence-based connectivity coding is still open. }}
@article{Platis:2003:PHF,
author = {Platis,Nikos and Theoharis,Theoharis},
title = {Progressive Hulls for Intersection Applications},
journal = {Computer Graphics Forum},
volume = {22},
number = {2},
pages = {107-107},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue2/22107.pdf},
abstract = { Abstract  Progressive meshes are an established tool for triangle mesh simplification. By suitably adapting the simplification process, progressive hulls can be generated which enclose the original mesh in gradually simpler, nested meshes. We couple progressive hulls with a selective refinement framework and use them in applications involving intersection queries on the mesh. We demonstrate that selectively refinable progressive hulls considerably speed up intersection queries by efficiently locating intersection points on the mesh. Concerning the progressive hull construction, we propose a new formula for assigning edge collapse priorities that significantly accelerates the simplification process, and enhance the existing algorithm with several conditions aimed at producing higher quality hulls. Using progressive hulls has the added advantage that they can be used instead of the enclosed object when a lower resolution of display can be tolerated, thus speeding up the rendering process.  {ACM} {CSS}: I.3.3 Computer Graphics-Picture/Image Generation, I.3.5 Computer Graphics-Computational Geometry and Object Modeling, I.3.7 Computer Graphics-Three-Dimensional Graphics and Realism }}
@article{Laycock:2003:RDA,
author = {Laycock,S. D. and Day,A. M.},
title = {Recent Developments and Applications of Haptic Devices},
journal = {Computer Graphics Forum},
volume = {22},
number = {2},
pages = {117-117},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue2/22117.pdf},
abstract = { Abstract  Over recent years a variety of haptic feedback devices have been developed and are being used in a number of important applications. They range from joysticks used in the entertainment industry to specialised devices used in medical applications. This paper will describe the recent developments of these devices and show how they have been applied. It also examines how haptic feedback has been combined with visual display devices, such as virtual reality walls and workbenches, in order to improve the immersive experience.  {ACM} {CSS}: H.5.2 Information Interfaces and Presentation-Haptic I/O; I.3.8 Computer Graphics-Applications; I.6 Simulation and Modelling-Applications }}
@article{Kipfer:2003:LEP,
author = {Kipfer,Peter and Reck,Frank and Greiner,Gunther},
title = {Local Exact Particle Tracing on Unstructured Grids},
journal = {Computer Graphics Forum},
volume = {22},
number = {2},
pages = {133-133},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue2/22133.pdf},
abstract = { Abstract  For analyzing and interpreting results of flow simulations, particle tracing is a well established visualization method. In addition, it is a preliminary step for more advanced techniques such as line integral convolution. For interactive exploration of large data sets, a very efficient and reliable particle tracing method is needed. For wind channel experiments or flight simulations, large unstructured computational grids have become common practice. Traditional approachs, based on numerical integration methods of ordinary differential equations however fail to deliver sufficiently accurate path calculation at the speed required for interactive use. In this paper we extend the local exact approach of Nielson and Jung in such a way that it can be used for interactive particle tracing in large data sets of steady flow simulation experiments. This will be achieved by sophisticated preprocessing using additional memory. For further visual enhancement of the streamline we construct an implicitly defined smooth Bezier curve that is used for ray tracing. This allows us to visualize additional scalar values of the simulation as attributes to the trajectory and enables the display of high-quality smooth curves without creating any visualization geometry and providing a good impression of the spatial situation at the same time.  {ACM} {CSS}: I.3.3 Computer Graphics-Line and curve generation; I .3.7 Computer Graphics-Raytracing; G.1.2 Numerical Analysis-Spline and piecewise polynomial approximation }}
@article{Hsu:2003:TSM,
author = {Hsu,P.-C. and Lee,C.},
title = {The Scale Method for Blending Operations in Functionally-Based Constructive Geometry},
journal = {Computer Graphics Forum},
volume = {22},
number = {2},
pages = {143-143},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue2/22143.pdf},
abstract = { Abstract  This paper presents a scale method for developing high dimensional scale functions to blend implicitly defined objects. Scale functions are differentiable on the entire domain except the origin, provide blending range control, and behave like Min/Max operators everywhere, so even a successive composition of blending operations containing overlapped blending regions can be generated smoothly. Because the scale method is a generalized method, implicit or parametric curves, such as cubic Bezier curves, rational conic curves, and implicit conics and hyper-ellipsoids, can be used to develop scale functions. As a result, it can enhance the flexibility of generating the implicitly blending surfaces in Ricci's constructive geometry, soft objects modeling, and implicit sweep objects.  {ACM} {CSS}: I.3.5 Computer Graphics-Computational Geometry and Object Modeling - Curve, surface, solid and object representations }}
@article{Zhang:2003:EMO,
author = {Zhang,Yu and Prakash,Edmond C. and Sung,Eric},
title = {Efficient Modeling of An Anatomy-Based Face and Fast {3D} Facial Expression Synthesis},
journal = {Computer Graphics Forum},
volume = {22},
number = {2},
pages = {159-159},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue2/22159.pdf},
abstract = { Abstract  This paper presents new methods for efficient modeling and animation of an hierarchical facial model that conforms to the human face anatomy for realistic and fast {3D} facial expression synthesis. The facial model has a skin-muscle-skull structure. The deformable skin model directly simulates the nonlinear visco-elastic behavior of soft tissue and effectively prevents model collapse. The construction of facial muscles is achieved by using an efficient muscle mapping approach. Based on a cylindrical projection of the texture-mapped facial surface and wire-frame skin and skull meshes, this approach ensures different muscles to be located at the anatomically correct positions between the skin and skull layers. For computational efficiency, we devise an adaptive simulation algorithm which uses either a semi-implicit integration scheme or a quasi-static solver to compute the relaxation by traversing the designed data structures in a breadth-first order. The algorithm runs in real-time and has successfully synthesized realistic facial expressions.  {ACM} {CSS}: I.3.5 Computer Graphics: Computational Geometry and Object Modelling-physically based modelling; I.3.7 Computer Graphics: Three-Dimensional Graphics and Realism-animation; }}
@article{Figueiredo:2003:APC,
author = {Henrique de Figueiredo,Luiz and Stolfi,Jorge and Velho,Luiz},
title = {Approximating Parametric Curves With Strip Trees Using Affine Arithmetic},
journal = {Computer Graphics Forum},
volume = {22},
number = {2},
pages = {171-171},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue2/22171.pdf},
abstract = { Abstract  We show how to use affine arithmetic to represent a parametric curve with a strip tree. The required bounding rectangles for pieces of the curve are computed by exploiting the linear correlation information given by affine arithmetic. As an application, we show how to compute approximate distance fields for parametric curves.  {ACM} {CSS}: I.3.3 Computer Graphics-Curve, surface, solid, and object representations, G.1.2 Numerical Analysis-Approximation of surfaces and contours, G.1.0 Numerical Analysis-Interval arithmetic }}
@article{Wurmlin:2003:3DV,
author = {Wurmlin,Stephan and Lamboray,Edouard and Staadt,Oliver G. and Gross,Markus H.},
title = {{3D} Video Recorder: a System for Recording and Playing Free-Viewpoint Video},
journal = {Computer Graphics Forum},
volume = {22},
number = {2},
pages = {181-181},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue2/22181.pdf},
abstract = { Abstract  We present the {3D} Video Recorder, a system capable of recording, processing, and playing three-dimensional video from multiple points of view. We first record {2D} video streams from several synchronized digital video cameras and store pre-processed images to disk. An off-line processing stage converts these images into a time-varying {3D} hierarchical point-based data structure and stores this {3D} video to disk. We show how we can trade-off {3D} video quality with processing performance and devise efficient compression and coding schemes for our novel {3D} video representation. A typical sequence is encoded at less than 7 Mbps at a frame rate of 8.5 frames per second. The {3D} video player decodes and renders {3D} videos from hard-disk in real-time, providing interaction features known from common video cassette recorders, like variable-speed forward and reverse, and slow motion. {3D} video playback can be enhanced with novel {3D} video effects such as freeze-and-rotate and arbitrary scaling. The player builds upon point-based rendering techniques and is thus capable of rendering high-quality images in real-time. Finally, we demonstrate the {3D} Video Recorder on multiple real-life video sequences.  {ACM} {CSS}: I.3.2 Computer Graphics-Graphics Systems, I.3.5 Computer Graphics-Computational Geometry and Object Modelling, I.3.7 Computer Graphics-Three-Dimensional Graphics and Realism }}
@article{Lensch:2003:IRO,
author = {Lensch,Hendrik P.A. and Goesele,Michael and Bekaert,Philippe and Kautz,Jan and Magnor,Marcus A. and Lang,Jochen and Seidel,Hans-Peter},
title = {Interactive Rendering of Translucent Objects},
journal = {Computer Graphics Forum},
volume = {22},
number = {2},
pages = {195-195},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue2/22195.pdf},
abstract = { Abstract  This paper presents a rendering method for translucent objects, in which viewpoint and illumination can be modified at interactive rates. In a preprocessing step, the impulse response to incoming light impinging at each surface point is computed and stored in two different ways: The local effect on close-by surface points is modeled as a per-texel filter kernel that is applied to a texture map representing the incident illumination. The global response (i.e. light shining through the object) is stored as vertex-to-vertex throughput factors for the triangle mesh of the object. During rendering, the illumination map for the object is computed according to the current lighting situation and then filtered by the precomputed kernels. The illumination map is also used to derive the incident illumination on the vertices which is distributed via the vertex-to-vertex throughput factors to the other vertices. The final image is obtained by combining the local and global response. We demonstrate the performance of our method for several models.  {ACM} {CSS}:I.3.7 Computer Graphics-Three-Dimensional Graphics and Realism Color Radiosity }}
@article{Yang:2003:RTC,
author = {Yang,Ruigang and Welch,Greg and Bishop,Gary},
title = {Real-Time Consensus-Based Scene Reconstruction Using Commodity Graphics Hardware},
journal = {Computer Graphics Forum},
volume = {22},
number = {2},
pages = {207-207},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue2/22207.pdf},
abstract = { Abstract  We present a novel use of commodity graphics hardware that effectively combines a plane-sweeping algorithm with view synthesis for real-time, online {3D} scene acquisition and view synthesis. Using real-time imagery from a few calibrated cameras, our method can generate new images from nearby viewpoints, estimate a dense depth map from the current viewpoint, or create a textured triangular mesh. We can do each of these without any prior geometric information or requiring any user interaction, in real time and online. The heart of our method is to use programmable Pixel Shader technology to square intensity differences between reference image pixels, and then to choose final colors (or depths) that correspond to the minimum difference, i.e. the most consistent color. In this paper we describe the method, place it in the context of related work in computer graphics and computer vision, and present some results.  {ACM} {CSS}: I.3.3 Computer Graphics-Bitmap and framebuffer operations, I.4.8 Image Processing and Computer Vision-Depth cues, Stereo }}
@article{Reinhard:2003:FEW,
author = {Reinhard,Erik},
title = {Fourth Eurographics Workshop on Parallel Graphics and Visualisation},
journal = {Computer Graphics Forum},
volume = {22},
number = {2},
pages = {218-218},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue2/22218.pdf}}
@article{Bajaj:2003:VFM,
author = {Bajaj,Chandrajit},
title = {Volumetric Filtering, Modeling and Visualization for Nano-Medicine},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {xvii-xvii},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/cgf_666.pdf},
abstract = { Abstract  The {3D} structures of individual proteins or small complexes, such as most of the Protein Data Bank entries, are still unable to yield the ''full picture'' of a functional biological complex. The study of large macromolecular complexes, such as viruses, ion channels, the ribosome and other macromolecular machines of various types, offer more complete structural and functional description of the nano-machinery of life.  In addition to x-ray crystallography. {NMR} spectroscopy, electron cryomicroscopy (cryoEM) imaging of single particles, and in-vivo molecular tomographic imaging has become indispensable at revealing the structures of large macromolecular complexes at subnanometer resolutions.  In this talk, I shall describe some of the recent computational advances in filtering, modeling, analysis and visualization, that have propelled structure determination by cryoEM and tomographic imaging, to steadily increasing accuracy. }}
@article{Kobbelt:2003:FSR,
author = {Kobbelt,Leif},
title = {Freeform Shape Representations for Efficient Geometry Processing},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {xviii-xviii},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/cgf_667.pdf},
abstract = { Abstract  The most important concepts for the handling and storage of freeform shapes in geometry processing applications are parametric representations and volumetric representations. Both have their specific advantages and drawbacks. While the algebraic complexity of volumetric representations is independent from the shape complexity, the domain of a parametric representation usually has to have the same structure as the surface itself (which sometimes makes it necessary to update the domain when the surface is modified).  On the other hand, the topology of a parametrically defined surface can be controlled explicitly while in a volumetric representation, the surface topology can change accidentally during deformation. A volumetric representation reduces distance queries or inside/outside tests to mere function evaluations but the geodesic neighborhood relation between surface points is difficult to resolve. As a consequence, it seems promising to combine parametric and volumetric representations to effectively exploit both advantages.  In this talk, a number of projects are presented and discussed in which such a combination leads to efficient and numerically stable algorithms for the solution of various geometry processing tasks. Applications include global error control for mesh decimation and smoothing, topology control for level-set surfaces, and shape modeling with unstructured point clouds. }}
@article{Purgathofer:2003:OII,
author = {Purgathofer,Werner},
title = {Open Issues in Photo-realistic Rendering},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {xix-xix},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/cgf_668.pdf},
abstract = { Abstract  For more than two decades Computer graphics researchers have tried to achieve photo-realism in their images as reliable as possible, mainly by simulating the physical laws of light and adding one effect after the other. The recent years have brought a change of efforts towards real-time methods, easy-to-use systems, integration with vision, modelling tools and the like. The quality of images is mostly accepted as sufficient for real world applications, but where are we really? There are still numerous problems to be solved, and there is notable progress in these areas. No question, the plug-in philosophy of some commercial products has enabled several of these new techniques to be distributed quite fast. But unfortunately, many other of these developments happen in isolated systems for the pure purpose of publication, and never make it into commercial software. This presentation wants to make people more aware of such activities, and evaluate the steps we still have to go towards perfect photo-realism.  The talk will start with an attempt to give a brief overview of the rendering history, highlighting the main research directions at different times. It will explain the driving forces of the developments, which are complexity, speed, and accuracy, and maybe also expression in recent years. Solved and unsolved areas are examined, and compared to practically solved but theoretically incomplete topics such as translucency, tone mapping, light source and {BTF} descriptions, and error metrics for image quality evaluation. The difference lies mainly in the difference between believable, correct, and predictive images. Also, for really realistic images modelling complexity is still an issue. Finally, some recent work on polarization and fluorescence is presented. }}
@article{Chen:2003:OVS,
author = {Chen,Ding-Yun and Tian,Xiao-Pei and Shen,Yu-Te and Ouhyoung,Ming},
title = {On Visual Similarity Based {3D} Model Retrieval},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {223-223},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper278.pdf},
abstract = { Abstract  A large number of {3D} models are created and available on the Web, since more and more {3D} modelling anddigitizing tools are developed for ever increasing applications. The techniques for content-based {3D} model retrievalthen become necessary. In this paper, a visual similarity-based {3D} model retrieval system is proposed.This approach measures the similarity among {3D} models by visual similarity, and the main idea is that if two 3Dmodels are similar, they also look similar from all viewing angles. Therefore, one hundred orthogonal projectionsof an object, excluding symmetry, are encoded both by Zernike moments and Fourier descriptors as features forlater retrieval. The visual similarity-based approach is robust against similarity transformation, noise, model degeneracyetc., and provides 42%, 94% and 25% better performance (precision-recall evaluation diagram) thanthree other competing approaches: (1) the spherical harmonics approach developed by Funkhouser et al., (2) theMPEG-7 Shape {3D} descriptors, and (3) the {MPEG-7} Multiple View Descriptor. The proposed system is on the Webfor practical trial use ( http://3d.csie.ntu.edu.tw ), and the database contains more than 10,000 publicly available3D models collected from {WWW} pages. Furthermore, a user friendly interface is provided to retrieve {3D} modelsby drawing {2D} shapes. The retrieval is fast enough on a server with Pentium {IV} 2.4 GHz {CPU}, and it takes about2 seconds and 0.1 seconds for querying directly by a {3D} model and by hand drawn {2D} shapes, respectively.  Categories and Subject Descriptors (according to {ACM} CCS): H.3.1 [Information Storage and Retrieval]: Indexing Methods }}
@article{Hsu:2003:FFF,
author = {Hsu,P. C. and Lee,C.},
title = {Field Functions for Blending Range Controls on Soft Objects},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {233-233},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper146.pdf},
abstract = { Abstract  This paper proposes new field functions that have adjustable inner radius and outer radius of influence. Incorporatingthe proposed field functions with soft object modeling, soft blending, Ricci's super-ellipsoid blends, Perlin'sset operations, and R-functions, etc. can have blending range controls by adjusting the inner and the outer radiiof influence of given field functions. As a result, the sizes of the resulting blending surfaces on soft objects willnot be restricted by the sizes of the blended primitive soft objects and can be enlarged and shrunk freely withoutdeforming the overall shapes of blended primitive soft objects. In addition, a small soft object can have a largeblending region, and a large one can have a small blending region  Categories and Subject Descriptors (according to {ACM} CCS): I.3.5 [Computer Graphics]: Computational Geometry and Object Modeling - Curve, surface, solid and object representations }}
@article{Qin:2003:FPR,
author = {Qin,Xueying and Nakamae,Eihachiro and Tadamura,Katsumi and Nagai,Yasuo},
title = {Fast Photo-Realistic Rendering of Trees in Daylight},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {243-243},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper250.pdf},
abstract = { Abstract  We propose a fast approach for photo-realistic rendering of trees under various kinds of daylight, which is particularlyuseful for the environmental assessment of landscapes. In our approach the {3D} tree models are transformedto a quasi-3D tree database registering geometrical and shading information of tree surfaces, i.e. their normalvectors, relative depth, and shadowing of direct sunlight and skylight, by using a combination of {2D} buffers.Thus the rendering speed of quasi-3D trees depends on their display sizes only, regardless of the complexity oftheir original {3D} tree models. By utilizing a two-step shadowing algorithm, our proposed method can create highquality forest scenes illuminated by both sunlight and skylight at a low cost. It can generate both umbrae andpenumbrae on a tree cast by other trees and any other objects such as buildings or clouds. Transparency, specularreflection and inter-reflection of leaves, which influence the delicate shading effects of trees, can also be simulatedwith verisimilitude.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.7 [Computer Graphics]: Three dimensional Graphics and Realism }}
@article{Hong:2003:AOB,
author = {Hong,Jeong-Mo and Kim,Chang-Hun},
title = {Animation of Bubbles in Liquid},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {253-253},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper261},
abstract = { Abstract  We present a new fluid animation technique in which liquid and gas interact with each other, using the exampleof bubbles rising in water. In contrast to previous studies which only focused on one fluid, our system considersboth the liquid and the gas simultaneously. In addition to the flowing motion, the interactions between liquid andgas cause buoyancy, surface tension, deformation and movement of the bubbles. For the natural manipulationof topological changes and the removal of the numerical diffusion, we combine the volume-of-fluid method andthe front-tracking method developed in the field of computational fluid dynamics. Our minimum-stress surfacetension method enables this complementary combination. The interfaces are constructed using the marching cubesalgorithm. Optical effects are rendered using vertex shader techniques.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.7 [Computer Graphics]: Animation }}
@article{Pritchard:2003:CMC,
author = {Pritchard,D. and Heidrich,W.},
title = {Cloth Motion Capture},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {263-263},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper252.pdf},
abstract = { Abstract  Recent years have seen an increased interest in motion capture systems. Current systems, however, are limitedto only a few degrees of freedom, so that effectively only the motion of linked rigid bodies can be acquired. Wepresent a system for the capture of deformable surfaces, most notably moving cloth, including both geometry andparameterisation. We recover geometry using stereo correspondence, and use the Scale Invariant Feature Transform(SIFT) to identify an arbitrary pattern printed on the cloth, even in the presence of fast motion. We describea novel seed-and-grow approach to adapt the {SIFT} algorithm to deformable geometry. Finally, we interpolatefeature points to parameterise the complete geometry.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.5 [Computer Graphics]: Physically based modelingI.4.8 [Image Processing and Computer Vision]: Scene analysis }}
@article{Bischoff:2003:SVT,
author = {Bischoff,Stephan and Kobbelt,Leif},
title = {Sub-Voxel Topology Control for Level-Set Surfaces},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {273-273},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper369.pdf},
abstract = { Active contour models are an efficient, accurate, and robust tool for the segmentation of {2D} and {3D} image data.In particular, geometric deformable models (GDM) that represent an active contour as the level set of an implicitfunction have proven to be very effective. GDMs, however, do not provide any topology control, i.e. contours maymerge or split arbitrarily and hence change the genus of the reconstructed surface. This behavior is inadequate insettings like the segmentation of organic tissue or other objects whose genus is known beforehand. In this paperwe describe a novel method to overcome this limitation while still preserving the favorable properties of the GDMsetup. We achieve this by adding (sparse) topological information to the volume representation at locations whereit is necessary to locally resolve topological ambiguities. Since the sparse topology information is attached to theedges of the voxel grid, we can reconstruct the interfaces where the deformable surface touches itself at sub-voxelaccuracy. We also demonstrate the efficiency and robustness of our method. }}
@article{Pauly:2003:MSF,
author = {Pauly,Mark and Keiser,Richard and Gross,Markus},
title = {Multi-scale Feature Extraction on Point-Sampled Surfaces},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {281-281},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper289.pdf},
abstract = { Abstract  We present a new technique for extracting line-type features on point-sampled geometry. Given an unstructuredpoint cloud as input, our method first applies principal component analysis on local neighborhoods toclassify points according to the likelihood that they belong to a feature. Using hysteresis thresholding, we thencompute a minimum spanning graph as an initial approximation of the feature lines. To smooth out the featureswhile maintaining a close connection to the underlying surface, we use an adaptation of active contour models.Central to our method is a multi-scale classification operator that allows feature analysis at multiplescales, using the size of the local neighborhoods as a discrete scale parameter. This significantly improves thereliability of the detection phase and makes our method more robust in the presence of noise. To illustrate theusefulness of our method, we have implemented a non-photorealistic point renderer to visualize point-sampledsurfaces as line drawings of their extracted feature curves. }}
@article{Navazo:2003:STC,
author = {Navazo,I. and Rossignac,J. and Jou,J. and  Shariff,R.},
title = {ShieldTester: Cell-to-Cell Visibility Test for Surface Occluders},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {291-291},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper171.pdf},
abstract = { Abstract  We present a novel Cell-To-Cell Visibility (C2CV) algorithm, which given two polyhedra, AandBand a connectedand oriented manifold triangle mesh, S offers a simple, fast and conservative test for detecting when A and B areoccluded from each other by S. Previously disclosed {C2CV} algorithms either relied on costly occlusion fusion orwere restricted to convex or &quot;apparently convex&quot; occluders, which makes them inappropriate for scenes wherepotential occluders are arbitrary triangulated surfaces, such as the body of a car or a portion of a terrain. Thesimplicity of our {C2CV} algorithm, named ShieldTester, stems from a new Occlusion Theorem, introduced herewhich permits to establish occlusion by computing the intersection of S with a single ray from a vertex ofAtoa vertex ofB. ShieldTester may be used to establish that pairs of cells in a subdivision of space are hidden fromeach other by a relatively large surface occluder, so that when the viewer is in one cell, the objects in the othercell need not be displayed.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.3 [Computer Graphics]: Computational Geometryand Object Modeling: Occlussion Culling, Visibility Test, Triangle Meshes }}
@article{Haumont:2003:VCA,
author = {Haumont,D. and Debeir,O. and Sillion,F.},
title = {Volumetric cell-and-portal generation},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {303-303},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper237.pdf},
abstract = { Abstract  We present an algorithm to generate a cell-and-portal decomposition of general indoor scenes. The method is an adaptation of the {3D} watershed transform, computed on a distance-to-geometry sampled field. The watershed is processed using a flooding analogy in the distance field space. Flooding originates from local minima, each minimum producing a region. Portals are built as needed to avoid the merging of regions during their growth. As a result, the cell-and-portal decomposition is closely linked to the structure of the models. In a building, the algorithm finds all the rooms, doors and windows. To restrict the memory load, a hierarchical implementation of the algorithm is presented. We also explain how to handle possible model degeneracies -such as cracks, holes and interpenetrating geometries- using a pre-voxelisation step. The hierarchical algorithm, preceded when necessary by the pre-voxelisation, was tested on a large range of models. We show that it is able to deal with classical architectural models, as well as cave-like environments and large mixed indoor/outdoor scenes. Thanks to the intermediate distance field representation, the algorithm can be used regardless of the way the model is represented: it deals with parametric curves, implicit surfaces, volumetric data and polygon soups in a unified way. }}
@article{Kallmann:2003:PCF,
author = {Kallmann,Marcelo and Aubel,Amaury and Abaci,Tolga and Thalmann,Daniel},
title = {Planning Collision-Free Reaching Motions for Interactive Object Manipulation and Grasping},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {313-313},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper222},
abstract = { Abstract  We present new techniques that use motion planning algorithms based on probabilistic roadmaps to control 22 degrees of freedom (DOFs) of human-like characters in interactive applications. Our main purpose is the automatic synthesis of collision-free reaching motions for both arms, with automatic column control and leg flexion. Generated motions are collision-free, in equilibrium, and respect articulation range limits. In order to deal with the high (22) dimension of our configuration space, we bias the random distribution of configurations to favor postures most useful for reaching and grasping. In addition, extensions are presented in order to interactively generate object manipulation sequences: a probabilistic inverse kinematics solver for proposing goal postures matching pre-designed grasps; dynamic update of roadmaps when obstacles change position; online planning of object location transfer; and an automatic stepping control to enlarge the character's reachable space. This is, to our knowledge, the first time probabilistic planning techniques are used to automatically generate collision-free reaching motions involving the entire body of a human-like character at interactive frame rates.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism }}
@article{Niederberger:2003:HAH,
author = {Niederberger,C. and Gross,M.},
title = {Hierarchical and Heterogenous Reactive Agents for Real-Time Applications},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {323-323},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper288},
abstract = { Abstract  We present a generic concept for autonomous agents with reactive behavior based on situation recognition in real-time environments. Our approach facilitates behavior development through specialization of existing behavior types or weighted multiple inheritance in order to create new types. Additionally, the system allows for the simultaneous generation of hierarchical and semi-individual group organizations using specification and recursive or modulo-based patterns. Our framework is designed to support the creation of large numbers of secondary characters with individual and group behavior in simulation environments such as game engines. The engine allows for the specification of a maximal time-per-run in order to guarantee a minimal and constant frame-rate. We demonstrate the usefulness of our approach by various examples with up to hundreds of individuals.   Categories and Subject Descriptors (according to {ACM} CCS): 1.2.11 [Distributed Artificial Intelligence]: Multiagent systems, I.6.7 [Simulation Support Systems]: Environments }}
@article{Theisel:2003:C2D,
author = {Theisel,H. and Rossl,Ch. and Seidel,H.-P.},
title = {Compression of {2D} Vector Fields Under Guaranteed Topology Preservation},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {333-333},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper109.pdf},
abstract = { Abstract  In this paper we introduce a new compression technique for {2D} vector fields which preserves the complete topology, i.e., the critical points and the connectivity of the separatrices. As the theoretical foundation of the algorithm, we show in a theorem that for local modifications of a vector field, it is possible to decide entirely by a local analysis whether or not the global topology is preserved. This result is applied in a compression algorithm which is based on a repeated local modification of the vector field - namely a repeated edge collapse of the underlying piecewise linear domain. We apply the compression technique to a number of data sets with a complex topology and obtain significantly improved compression ratios in comparison to pre-existing topology-preserving techniques. }}
@article{Ibarria:2003:OOC,
author = {Ibarria,Lawrence and Lindstrom,Peter and Rossignac,Jarek and Szymczak,Andrzej},
title = {Out-of-core compression and decompression of large n-dimensional scalar fields},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {343-343},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper211.pdf},
abstract = { Abstract  We present a simple method for compressing very large and regularly sampled scalar fields. Our method is particularlyattractive when the entire data set does not fit in memory and when the sampling rate is high relative to thefeature size of the scalar field in all dimensions. Although we report results foranddata sets, the proposedapproach may be applied to higher dimensions. The method is based on the new Lorenzo predictor, introducedhere, which estimates the value of the scalar field at each sample from the values at processed neighbors. The predictedvalues are exact when the n-dimensional scalar field is an implicit polynomial of degreen- 1 . Surprisingly,when the residuals (differences between the actual and predicted values) are encoded using arithmetic coding,the proposed method often outperforms wavelet compression in anLoosense. The proposed approach may beused both for lossy and lossless compression and is well suited for out-of-core compression and decompression,because a trivial implementation, which sweeps through the data set reading it once, requires maintaining only asmall buffer in core memory, whose size barely exceeds a single (n-1)-dimensional slice of the data.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.5 [Computer Graphics]: Compression, scalar fields,out-of-core. }}
@article{Bar-Joseph:2003:HCB,
author = {Bar-Joseph,Ziv and Cohen-Or,Daniel},
title = {Hierarchical Context-based Pixel Ordering},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {349-349},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper288},
abstract = { Abstract  We present a context-based scanning algorithm which reorders the input image using a hierarchical representationof the image. Our algorithm optimally orders (permutes) the leaves corresponding to the pixels, by minimizing thesum of distances between neighboring pixels. The reordering results in an improved autocorrelation betweennearby pixels which leads to a smoother image. This allows us, for the first time, to improve image compressionrates using context-based scans. The results presented in this paper greatly improve upon previous work in bothcompression rate and running time.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.5 [Computer Graphics]: Computational Geometryand Object Modeling I.3.6 [Computer Graphics]: Methodology and Techniques }}
@article{Duke:2003:RAA,
author = {Duke,D.J. and Barnard,P.J. and Halper,N. and Mellin,M.},
title = {Rendering and Affect},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {359-359},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper322.pdf},
abstract = { Abstract  Previous studies at the intersection between rendering and psychology have concentrated on issues such as realismand acuity. Although such results have been useful in informing development of realistic rendering techniques,studies have shown that the interpretation of images is influenced by factors that have little to do with realism. Inthis paper, we summarize a series of experiments, the most recent of which are reported in a separate paper, thatinvestigate affective (emotive) qualities of images. These demonstrate significant effects that can be utilized withininteractive graphics, particularly via non-photorealistic rendering (NPR). We explain how the interpretation ofthese results requires a high-level model of cognitive information processing, and use such a model to account forrecent empirical results on rendering and judgement.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.m [Computer Graphics]: Miscellaneous }}
@article{Sousa:2003:PID,
author = {Sousa,Mario Costa and Foster,Kevin and Wyvill,Brian and Samavati,Faramarz},
title = {Precise Ink Drawing of {3D} Models},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {369-369},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper116},
abstract = { Abstract  Drawings made with precise pen strokes accurately reveal the geometric forms that give subjects their characteristicshape. We present a system for non-photorealistic rendering of precise drawing strokes over dense 3Dtriangle meshes with arbitrary topology. During an automatic pre-process, we construct an extended version ofthe edge-buffer data structure to allow the calculation of shape measures at each mesh edge, by adapting numericalmethods used in geomorphology. At runtime, feature edges related to shape measures are extracted andrendered as strokes with varying thickness and pen marking styles. Stroke thickness is automatically adjusted byconsidering surface curvature. Pen marking styles and visual effects of ink distribution are both controlled by theuser. We demonstrate precise drawing strokes over complex meshes revealing a variety of shape characteristics. }}
@article{Sousa:2003:AFG,
author = {Sousa,Mario Costa and Prusinkiewicz,Przemyslaw},
title = {A Few Good Lines: Suggestive Drawing of {3D} Models},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {381-381},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper160.pdf},
abstract = { Abstract  We present a method for rendering {3D} models in the traditionalline-drawing style used in artistic and scientificillustrations. The goal is to suggest the {3D} shape of the objectsusing a small number of lines drawn with carefullychosen line qualities. The system combines several known techniquesinto a simple yet effective non-photorealisticline renderer. Feature edges related to the outline and interiorof a given {3D} mesh are extracted, segmented, andsmoothed, yielding chains of lines with varying path, length, thickness,gaps, and enclosures. The paper includessample renderings obtained for a variety of models. }}
@article{Takahashi:2003:RAO,
author = {Takahashi,Tsunemi and Fujii,Hiroko and Kunimatsu,Atsushi and Hiwada,Kazuhiro and Saito,Takahiro and Tanaka,Ken and Ueki,Heihachi},
title = {Realistic Animation of Fluid with Splash and Foam},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {391-391},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper127},
abstract = { Abstract  In this paper we describe a method for modeling and rendering dynamic behavior of fluids withsplashes and foam. A particle system is built into a fluid simulation system to represent an ocean wavecresting and spraying over another object. We use the Cubic Interpolated Propagation (CIP) method asthe fluid solver. The {CIP} method can solve liquid and gas together in the framework of fluid dynamicsand has high accuracy in the case of relatively coarse grids. This enables us to simulate the fluids in ashort time and describe the motion of splashes in the air that is associated with the liquid motion well.The foam floating on the water also can be described using the particle system. We integrate the rigidbody simulation with the fluid and particle system to create sophisticated scenes including splashes andfoam. We construct state change rules that are used with the particle system. This controls the generation,vanishing and transition rule of splashes and foam. The transition rule makes the seamless connection betweena splash and foam. We employed a fast volume rendering method with scattering effect for particles.One of the important features of our method is the combination of fast simulation and rendering techniques,which provides dynamic and realistic scenes in a short time. }}
@article{Premzoe:2003:PBS,
author = {Premzoe,Simon and Tasdizen,Tolga and Bigler,James and Lefohn,Aaron and Whitaker,Ross T.},
title = {Particle-Based Simulation of Fluids},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {401-401},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper396.pdf},
abstract = { Abstract  Due to our familiarity with how fluids move and interact, as well as their complexity, plausible animation of fluidsremains a challenging problem. We present a particle interaction method for simulating fluids. The underlyingequations of fluid motion are discretized using moving particles and their interactions. The method allows simulationand modeling of mixing fluids with different physical properties, fluid interactions with stationary objects, andfluids that exhibit significant interface breakup and fragmentation. The gridless computational method is suitedfor medium scale problems since computational elements exist only where needed. The method fits well into thecurrent user interaction paradigm and allows easy user control over the desired fluid motion. }}
@article{Bando:2003:AHW,
author = {Bando,Yosuke and Chen,Bing-Yu and Nishita,Tomoyuki},
title = {Animating Hair with Loosely Connected Particles},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {411-411},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper140},
abstract = { Abstract  This paper presents a practical approach to the animation of hair at an interactive frame rate. In our approach,we model the hair as a set of particles that serve as sampling points for the volume of the hair, which covers thewhole region where hair is present. The dynamics of the hair, including hair-hair interactions, is simulated usingthe interacting particles. The novelty of this approach is that, as opposed to the traditional way of modeling hair,we release the particles from tight structures that are usually used to represent hair strands or clusters. Therefore,by making the connections between the particles loose while maintaining their overall stiffness, the hair can bedynamically split and merged during lateral motion without losing its lengthwise coherence.  Categories and Subject Descriptions (according to {ACM} CCS): I.3.7 [Computer Graphics]: Three-DimensionalGraphics and Realism, I.3.3 [Computer Graphics]: Picture/Image Generation }}
@article{Drago:2003:ALM,
author = {Drago,F. and Myszkowski,K. and Annen,T. and Chiba,N.},
title = {Adaptive Logarithmic Mapping For Displaying High Contrast Scenes},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {419-419},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper187.pdf},
abstract = { Abstract  We propose a fast, high quality tone mapping technique to display high contrast images on devices with limited dynamicrange of luminance values. The method is based on logarithmic compression of luminance values, imitatingthe human response to light. A bias power function is introduced to adaptively vary logarithmic bases, resultingin good preservation of details and contrast. To improve contrast in dark areas, changes to the gamma correctionprocedure are proposed. Our adaptive logarithmic mapping technique is capable of producing perceptually tunedimages with high dynamic content and works at interactive speed. We demonstrate a successful application of ourtone mapping technique with a high dynamic range video player enabling to adjust optimal viewing conditions forany kind of display while taking into account user preference concerning brightness, contrast compression, anddetail reproduction.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.3 [Image Processing and Computer Vision]: Image Representation }}
@article{GavilanRuiz:2003:ICU,
author = {Gavilan Ruiz,David and Takahashi,Hiroki and Nakajima,Masayuki},
title = {Image Categorization using Color Blobs in a Mobile Environment},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {427-427},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper302.pdf},
abstract = { Abstract  This paper generalizes the basic idea of blobs in preattentive perception using color information. This is usedas the base of a basic classification of low resolution pictures taken with mobile phones. This classification, theblob-like representation of the image and other information in user's context, such as {GPS} information, can beused in the presented framework as the basis of a new graphical interface for {HCI} (Human Computer Interaction).Similar systems whether they work with global properties of the image, which leads to inaccurate results, or withcomplex segmentation process that fails to capture expected objects in the scene. Most of those systems do notpay attention on other information involved in the creation of the image, such as time or location. We describe asystem which uses geographical information associated with a picture in a mobile phone terminal, and with a fastsegmentation based on color categorization. }}
@article{Brabec:2003:SVO,
author = {Brabec,Stefan and Seidel,Hans-Peter},
title = {Shadow Volumes on Programmable Graphics Hardware},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {433-433},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper228.pdf},
abstract = { Abstract  One of the best choices for fast, high quality shadows is the shadow volume algorithm. However, for real timeapplications the extraction of silhouette edges can significantly burden the {CPU}, especially with highly tessellatedinput geometry or when complex geometry shaders are applied.  In this paper we show how this last, expensive part of the shadow volume method can be implemented on programmablegraphics hardware. This way, the originally hybrid shadow volumes algorithm can now be reformulatedas a purely hardware-accelerated approach.  The benefits of this implementation is not only the increase in speed. Firstly, all computations now run on thesame hardware resulting in consistent precision within all steps of the algorithm. Secondly, programmable vertextransformations are no longer problematic when applied to shadow casting objects.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.1 [Computer Graphics]: Hardware Architecture;I.3.3 [Computer Graphics]: Picture/Image Generation; I.3.7 [Computer Graphics]: Three-Dimensional Graphicsand Realism }}
@article{Denny:2003:SGO,
author = {Denny,Markus},
title = {Solving Geometric Optimization Problems using Graphics Hardware},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {441-441},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper292.pdf},
abstract = { Abstract  We show how to use graphics hardware for tackling optimization problems arising in the field of computationalgeometry. We exemplarily discuss three problems, where combinatorial algorithms are inefficient or hard to implement.Given a set S of n point in the plane, the first two problems are to determine the smallest homotheticscaling of a star shaped polygon P enclosing S and to find the largest empty homothetic scaling of P completelycontained inside an arbitrary polygonal region. Pixel-exact solutions for both problems are computed in real-time.The third problem is a facility location problem and more difficult to solve. Given the Voronoi diagram VoD(S) ofthe n points, we try to position another point p in the plane, such that the resulting Voronoi region of p has maximalarea. As far as we know there exists no traditional solution for this problem for which we present pixel-exactsolutions.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.5 [Computer Graphics]: Geometric algorithms,languages, and systems I.3.3 [Computer Graphics]: Display algorithms }}
@article{Guthe:2003:ATA,
author = {Guthe,M. and Klein,R.},
title = {Automatic texture atlas generation from trimmed {NURBS} models},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {453-453},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper123.pdf},
abstract = { Abstract  A Texture Atlas is a two dimensional representation of a {3D} model usable for paint systems or as a sewing pattern.The field of texture atlas generation from polygonal models has been well exploited in the recent years. The developedalgorithms work on piecewise linear surface representations, but not on parametric surfaces like {NURBS},that are still the main surface representation in {CAD} systems. If a texture atlas is generated from a triangulatedNURBS model, the result cannot be edited further in a {CAD} system, since the separation into charts is not basedon the separate {NURBS} patches of the original model. We present a method for automatic generation of a textureatlas directly from trimmed {NURBS} models, while preserving the original {NURBS} representation. The resultingtexture atlas is build of several charts, each consisting of the original {NURBS} patches sewn together.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.3 [Computer Graphics]: Picture/Image Generation;I.3.5 [Computer Graphics]: Computational Geometry and Object Modeling; I.3.7 [Computer Graphics]: Three-DimensionalGraphics and Realism - Color, Shading and Texture; J.6 [Computer-aided Engineering]: Computer-aideddesign (CAD) }}
@article{Suykens:2003:IRW,
author = {Suykens,Frank and Berge,Karl and Lagae,Ares and Dutre,Philip},
title = {Interactive Rendering with Bidirectional Texture Functions},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {463-463},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper374.pdf},
abstract = { Abstract  We propose a new technique for efficiently rendering bidirectional texture functions (BTFs). A {6D} {BTF} describesthe appearance of a material as a texture that depends on the lighting and viewing directions. As such, a BTFaccommodates self-shadowing, interreflection, and masking effects of a complex material without needing anexplicit representation of the small scale geometry. Our method represents the {BTF} as a set of spatially varyingapparent BRDFs, that each encode the reflectance field of a single pixel in the {BTF}. Each apparent {BRDF} isdecomposed into a product of three or more two-dimensional positive factors using a novel factorization technique,which we call chained matrix factorization (CMF). The proposed factorization technique is fully automatic andsuitable for both BRDFs and apparent BRDFs (which typically exhibit off-specular peaks and non-reciprocity).The main benefit of {CMF} is that it delivers factors well suited for the limited dynamic range of conventionaltexture maps. After factorization, an efficient representation of the {BTF} is obtained by clustering the factors intoa compact set of {2D} textures. With this compact representation, BTFs can be rendered on recent consumer levelhardware with arbitrary viewing and lighting directions at interactive rates.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.7 [Computer Graphics]: Three-DimensionalGraphics and Realism }}
@article{Lensch:2003:PSO,
author = {Lensch,Hendrik P.A. and Lang,Jochen and Sa,Asla M. and Seidel,Hans-Peter},
title = {Planned Sampling of Spatially Varying BRDFs},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {473-473},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper317.pdf},
abstract = { Abstract  Measuring reflection properties of a {3D} object involves capturing images for numerous viewing and lightingdirections. We present a method to select advantageous measurement directions based on analyzing the estimationof the bi-directional reflectance distribution function (BRDF). The selected directions minimize the uncertaintyin the estimated parameters of the {BRDF}. As a result, few measurements suffice to produce models that describethe reflectance behavior well. Moreover, the uncertainty measure can be computed fast on modern graphics cardsby exploiting their capability to render into a floating-point frame buffer. This forms the basis of an acquisitionplanner capable of guiding experts and non-experts alike through the {BRDF} acquisition process. We demonstratethat spatially varying reflection properties can be captured more efficiently for real-world applications using ouracquisition planner.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.7 [Computer Graphics]: Three-DimensionalGraphics and Realism Virtual Reality I.4.1 [Computer Vision]: Digitization and Image Capture, Reflectance }}
@article{Botsch:2003:MSR,
author = {Botsch,Mario and Kobbelt,Leif},
title = {Multiresolution Surface Representation Based on Displacement Volumes},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {483-483},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper363.pdf},
abstract = { Abstract  We propose a new representation for multiresolution models which uses volume elements enclosed between thedifferent resolution levels to encode the detail information. Keeping these displacement volumes locally constantduring a deformation of the base surface leads to a natural behaviour of the detail features. The correspondingreconstruction operator can be implemented efficiently by a hierarchical iterative relaxation scheme, providingclose to interactive response times for moderately complex models.  Based on this representation we implement a multiresolution editing tool for irregular polygon meshes that allowsthe designer to freely edit the base surface of a multiresolution model without having to care about self-intersectionsin the respective detailed surface. We demonstrate the effectiveness and robustness of the reconstructionby several examples with real-world data. }}
@article{Chiang:2003:PSO,
author = {Chiang,Yi-Jen and Lu,Xiang},
title = {Progressive Simplification of Tetrahedral Meshes Preserving All Isosurface Topologies},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {493-493},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper141.pdf},
abstract = { Abstract  In this paper, we propose a novel technique for constructing multiple levels of a tetrahedral volume dataset whilepreserving the topologies of all isosurfaces embedded in the data. Our simplification technique has two majorphases. In the segmentation phase, we segment the volume data into topological-equivalence regions, that is, thesub-volumes within each of which all isosurfaces have the same topology. In the simplification phase, we simplifyeach topological-equivalence region independently, one by one, by collapsing edges from the smallest to the largesterrors (within the user-specified error tolerance, for a given error metrics), and ensure that we do not collapseedges that may cause an isosurface-topology change. We also avoid creating a tetrahedral cell of negative volume(i.e., avoid the fold-over problem). In this way, we guarantee to preserve all isosurface topologies in the entiresimplification process, with a controlled geometric error bound. Our method also involves several additionalnovel ideas, including using the Morse theory and the implicit fully augmented contour tree, identifying typesof edges that are not allowed to be collapsed, and developing efficient techniques to avoid many unnecessary orexpensive checkings, all in an integrated manner. The experiments show that all the resulting isosurfaces preservethe topologies, and have good accuracies in their geometric shapes. Moreover, we obtain nice data-reductionrates, with competitively fast running times. }}
@article{Cignoni:2003:BDAM,
author = {Cignoni,P. and Ganovelli,F. and Gobbetti,E. and Marton,F. and Ponchio,F. and Scopigno,R.},
title = {{BDAM} Batched Dynamic Adaptive Meshes for High Performance Terrain Visualization},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {505-505},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper166},
abstract = { Abstract  This paper describes an efficient technique for out-of-core rendering and management of large textured terrainsurfaces. The technique, called Batched Dynamic Adaptive Meshes (BDAM), is based on a paired tree structure:a tiled quadtree for texture data and a pair of bintrees of small triangular patches for the geometry. These smallpatches are TINs and are constructed and optimized off-line with high quality simplification and tristrippingalgorithms. Hierarchical view frustum culling and view-dependent texture and geometry refinement is performedat each frame through a stateless traversal algorithm. Thanks to the batched {CPU}/GPU communication model,the proposed technique is not processor intensive and fully harnesses the power of current graphics hardware.Both preprocessing and rendering exploit out-of-core techniques to be fully scalable and to manage large terraindatasets.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.3 [Computer Graphics]: Picture and Image Generation;I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism. }}
@article{Hiller:2003:BSM,
author = {Hiller,Stefan and Hellwig,Heino and Deussen,Oliver},
title = {Beyond Stippling - Methods for Distributing Objects on the Plane},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {515-515},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper385.pdf},
abstract = { Abstract  Conventionally, stippling is an effective technique for representing surfaces in pen-and-ink. We present new efficientmethods for stipple drawings by computer. In contrast to already existing techniques, arbitrary shapes canbe used in place of dots. An extension of Lloyd's Method enables us to position small objects on a plane in a visuallypleasing form. This allows us to generate new illustration styles. Similar methods can be used for positioningobjects in other applications. }}
@article{Diepstraten:2003:ICI,
author = {Diepstraten,J. and Weiskopf,D. and Ertl,T.},
title = {Interactive Cutaway Illustrations},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {523-523},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper112},
abstract = { Abstract  In this paper we discuss different approaches to generate cutaway illustrations. The purpose of such a drawingis to allow the viewer to have a look into an otherwise solid opaque object. Traditional methods to draw thesekinds of illustrations are evaluated to extract a small and effective set of rules for a computer-based renderingof cutaway illustrations. We show that our approaches are not limited to a specific rendering style but can besuccessfully combined with a great variety of well-known artistic or technical illustration techniques. All methodsof this paper make use of modern graphics hardware functionality to achieve interactive frame rates. }}
@article{Xu:2003:ADF,
author = {Xu,Songhua and Lau,Francis C.M. and Tang,Feng and Pan,Yunhe},
title = {Advanced Design for a Realistic Virtual Brush},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {533-533},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper120.pdf},
abstract = { Abstract  This paper proposes a novel algorithmic framework for an advanced virtual brush to be used in interactive digitalpainting. The framework comprises the following components: a geometry model of the brush using a hierarchicalrepresentation that leads to substantial savings in every step of the painting process; fast online brush motionsimulation assisted by offline calibration that guarantees an accurate and stable simulation of the brush's dynamicbehavior; a new pigment model based on a diffusion process of random molecules that considers delicateand complex pigment behavior at dipping time as well as during painting; and a user-adaptation component thatenables the system to cater for the personal painting habits of different users. A prototype system has been implementedbased on this framework. Compared with other virtual brushes, this new system is designed to presenta realistic brush in the sense that the system accurately and stably simulates the complex painting functionalityof a running brush, and therefore is capable of creating high-quality digital paintings with minute aesthetic detailsthat can rival the real artwork. The advanced features also give rise to a high degree of expressiveness ofthe virtual brush that the user can comfortably manipulate.  http://www.csis.hku.hk/songhuale-brush/  providessupplementary materials for this paper.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.6 [Methodology and Techniques]: Interactiontechniques; I.3.5 [Computational Geometry and Object Modeling]: Physically based modeling; I.3.4 [GraphicsUtilities]: Paint systems; }}
@article{Christensen:2003:RDA,
author = {Christensen,Per H. and Laur,David M. and Fong,Julia and Wooten,Wayne L. and Batali,Dana},
title = {Ray Differentials and Multiresolution Geometry Caching for Distribution Ray Tracing in Complex Scenes},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {543-543},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper249.pdf},
abstract = { Abstract  When rendering only directly visible objects, ray tracing a few levels of specular reflection from large, low-curvaturesurfaces, and ray tracing shadows from point-like light sources, the accessed geometry is coherentand a geometry cache performs well. But in many other cases, the accessed geometry is incoherent and a standardgeometry cache performs poorly: ray tracing of specular reflection from highly curved surfaces, tracing rays thatare many reflection levels deep, and distribution ray tracing for wide glossy reflection, global illumination, widesoft shadows, and ambient occlusion. Fortunately, less geometric accuracy is necessary in the incoherent cases.This observation can be formalized by looking at the ray differentials for different types of scattering: coherentrays have small differentials, while incoherent rays have large differentials. We utilize this observation to obtainefficient multiresolution caching of geometry and textures (including displacement maps) for classic and distributionray tracing in complex scenes. We use an existing multiresolution caching scheme (originally developed forscanline rendering) for textures and displacement maps, and introduce a multiresolution geometry caching schemefor tessellated surfaces. The multiresolution geometry caching scheme makes it possible to efficiently render scenesthat, if fully tessellated, would use 100 times more memory than the geometry cache size. }}
@article{Mueller:2003:ART,
author = {Muller,Kerstin and Techmann,Torsten and Fellner,Dieter},
title = {Adaptive Ray Tracing of Subdivision Surfaces},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {553-553},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper175.pdf},
abstract = { Abstract  Subdivision Surfaces as well as (interactive) ray tracing have become an important issue in computer graphics.But ray tracing of subdivision surfaces has received only little attention. We present a new approach for raytracing of subdivision surfaces. The algorithm uses a projection of the ray onto the surface and works mainly intwo dimensions along this projection. While proceeding from patch to patch, we examine the bounding volume oftheir borders: the lower the distance between ray and subdivision surface, the more refinement steps are adaptivelyapplied to the surface but only along the projection of the ray. The adaptive refinement of a patch is controlled bycurvature, size, its membership to the silhouette, and its potential contribution to the light transport. The algorithmis simple and mainly consists of elementary geometric computations. Hence it is fast and easy to implementwithout the need for elaborate preprocessing. The algorithm is robust in the sense that it deals with all features ofsubdivision surfaces like creases and corners.  Categories and Subject Descripters (according to {ACM} CCS): I.3.7 [Computer Graphics]: Raytracing }}
@article{Gobbetti:2003:HHO,
author = {Gobbetti,Enrico and Spano,Leonardo and Agus,Marco},
title = {Hierarchical Higher Order Face Cluster Radiosity for Global Illumination Walkthroughs of Complex Non-Diffuse Environments},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {563-563},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper102},
abstract = { Abstract  We present an algorithm for simulating global illumination in scenes composed of highly tessellated objects withdiffuse or moderately glossy reflectance. The solution method is a higher order extension of the face cluster radiositytechnique. It combines face clustering, multiresolution visibility, vector radiosity, and higher order baseswith a modified progressive shooting iteration to rapidly produce visually continuous solutions with limited memoryrequirements. The output of the method is a vector irradiance map that partitions input models into areaswhere global illumination is well approximated using the selected basis. The programming capabilities of moderncommodity graphics architectures are exploited to render illuminated models directly from the vector irradiancemap, exploiting hardware acceleration for approximating view dependent illumination during interactive walkthroughs.Using this algorithm, visually compelling global illumination solutions for scenes of over one millioninput polygons can be computed in minutes and examined interactively on common graphics personal computers.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.3 [Computer Graphics]: Picture and Image Generation; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism. }}
@article{EversSenne:2003:IBI,
author = {Evers-Senne,J.-F. and Koch,R.},
title = {Image Based Interactive Rendering with View Dependent Geometry},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {573-573},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper220.pdf},
abstract = { Abstract  In this paper we present a novel approach for interactive rendering of virtual views from real image sequences.Combining the concepts of light fields, depth-compensated image warping and view dependent texture mapping,this plenoptic modeling approach can handle large and complex scenes. A portable, handheld multi-camera systemhas been developed that allows to record multiple image streams by simply walking around the scene. Theseimage streams are automatically calibrated and depth maps for all views are generated as input to the renderingstage. For rendering a view dependent warping surface is constructed on the fly and depth-compensated imageinterpolation is applied with view-dependent texture mapping. Rendering quality is scalable to allow fast previewand to achieve high-end quality with the same approach. The system can handle large and geometrically complexscenes with hundreds of real images at interactive rates.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.3 [Computer Graphics]: Viewing algorithms, I.4.1[Image Processing and Computer Vision]: Digitization and Image Capture, I.4.8 [Image Processing and ComputerVision]: Scene Analysis }}
@article{Tarrin:2003:TSH,
author = {Tarrin,N. and Coquillart,S. and Hasegawa,S. and Bouguila,L. and Sato,M.},
title = {The Stringed Haptic Workbench: a New Haptic Workbench Solution},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {583-583},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper225.pdf},
abstract = { Abstract  The workbench is an interesting semi-immersive configuration for interactive tasks. However, haptic feedback, i.e.force and tactile feedback, is one important cue which is missing. To the authors' knowledge, the sole proposedsolution consists in installing an arm force feedback device on one-screen workbenches. This solution, however,has several drawbacks. The arm can perturb the stereoscopic display, cross virtual objects or hide parts of thevisualization space. Furthermore, the interaction space is limited by the size of the arm, which may also damagethe screen or perturb the electromagnetic tracking system. Some of these difficulties may even be worth with a two-screenworkbench. This paper discusses an alternative solution, which consists in integrating a stringed hapticdevice on a workbench. This approach is less invasive, more flexible and well-suited to a two-screen workbench. }}
@article{Boudon:2003:IDO,
author = {Boudon,Frederic and Prusinkiewicz,Przemyslaw and Federl,Pavol and Godin,Christophe and Karwowski,Radoslaw},
title = {Interactive Design of Bonsai Tree Models},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {591-591},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper391},
abstract = { Abstract  Because of their complexity, plant models used in computer graphics are commonly created with proceduralmethods. A difficult problem is the user control of these models: a small number of parameters is insufficient tospecify plant characteristics in detail, while large numbers of parameters are tedious to manipulate and difficultto comprehend. To address this problem, we propose a method for managing parameters involved in plant modelmanipulation. Specifically, we introduce decomposition graphs as multiscale representations of plant structuresand present interactive tools for designing trees that operate on decomposition graphs. The supported operationsinclude browsing of the parameter space, editing of generalized parameters (scalars, functions, and branchingsystem silhouettes), and the definition of dependencies between parameters. We illustrate our method by creatingmodels of bonsai trees.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.6 [Computer Graphics]: Methodology and Techniques }}
@article{Iwasaki:2003:AFR,
author = {Iwasaki,Kei and Dobashi,Yoshinori and Nishita,Tomoyuki},
title = {A Fast Rendering Method for Refractive and Reflective Caustics Due to Water Surfaces},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {601-601},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper215},
abstract = { Abstract  In order to synthesize realistic images of scenes that include water surfaces, the rendering of optical effectscaused by waves on the water surface, such as caustics and reflection, is necessary. However, rendering causticsis quite complex and time-consuming. In recent years, the performance of graphics hardware has made significantprogress. This fact encourages researchers to study the acceleration of realistic image synthesis. We present herea method for the fast rendering of refractive and reflective caustics due to water surfaces. In the proposed method,an object is expressed by a set of texture mapped slices. We calculate the intensities of the caustics on the objectby using the slices and store the intensities as textures. This makes it possible to render caustics at interactive rateby using graphics hardware. Moreover, we render objects that are reflected and refracted due to the water surfaceby using reflection/refraction mapping of these slices.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.1 [Computer Graphics]: Hardware Architecture I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism }}
@article{Wand:2003:RTC,
author = {Wand,M. and Strasser,W.},
title = {Real-Time Caustics},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {611-611},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper202},
abstract = { Abstract  We present a new algorithm to render caustics. The algorithm discretizes the specular surfaces into samplepoints. Each of the sample points is treated as a pinhole camera that projects an image of the incoming lightonto the diffuse receiver surfaces. Anti-aliasing is performed by considering the local surface curvature at thesample points to filter the projected images. The algorithm can be implemented using programmable texturemapping hardware. It allows to render caustics in fully dynamic scenes in real-time on current {PC} hardware.  Categories and Subject Descriptors: I.3.3 [Computer Graphics]: Picture/Image Generation - Display Algorithms;I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism }}
@article{Benthin:2003:ASA,
author = {Benthin,Carsten and Wald,Ingo and Slusallek,Philipp},
title = {A Scalable Approach to Interactive Global Illumination},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {621-621},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper305.pdf},
abstract = { Abstract  The addition of global illumination can dramatically increase the realism achievable when rendering virtual environments.In particular with interactive applications we expect the environment to reflect changes in the scenedue to global lighting effects instead of it being just a static backdrop. However, a sufficiently fast and accuratecomputation of global illumination at interactive rates has been difficult even with recent approaches based onrealtime ray tracing.  In this paper we present a highly scalable approach to interactive global illumination. It fully recomputes a high-qualitysolution for each frame and thus offers immediate feedback even for dynamic scenes, achieving more than20 fps for simple scenes. Compared to previous systems we increased the raw performance by a factor of up toeight and removed the bottlenecks that were limiting scalability. The system now scales linearly in quality andavailable computing resources, tested with up to 48 CPUs in a commodity PC-cluster. Due to its logarithmicscaling property with respect to scene complexity it even supports lighting simulation in complex scenes with morethan 50 million triangles. This scalability allows applications to perform flexible performance trade-offs. We alsoargue that the realism achievable through interactive global illumination will make it a standard feature of future3D graphics systems once the required computing resources are readily available. }}
@article{Kshirsagar:2003:VBS,
author = {Kshirsagar,Sumedha and Magnenat-Thalmann,Nadia},
title = {Visyllable Based Speech Animation},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {631-631},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper108},
abstract = { Abstract  Visemes are visual counterpart of phonemes. Traditionally, the speech animation of {3D} synthetic faces involvesextraction of visemes from input speech followed by the application of co-articulation rules to generate realisticanimation. In this paper, we take a novel approach for speech animation - using visyllables, the visual counterpartof syllables. The approach results into a concatenative visyllable based speech animation system. The key contributionof this paper lies in two main areas. Firstly, we define a set of visyllable units for spoken English along withthe associated phonological rules for valid syllables. Based on these rules, we have implemented a syllabificationalgorithm that allows segmentation of a given phoneme stream into syllables and subsequently visyllables. Secondly,we have recorded the database of visyllables using a facial motion capture system. The recorded visyllableunits are post-processed semi-automatically to ensure continuity at the vowel boundaries of the visyllables. We defineeach visyllable in terms of the Facial Movement Parameters (FMP). The FMPs are obtained as a result of thestatistical analysis of the facial motion capture data. The FMPs allow a compact representation of the visyllables.Further, the FMPs also facilitate the formulation of rules for boundary matching and smoothing after concatenatingthe visyllables units. Ours is the first visyllable based speech animation system. The proposed technique iseasy to implement, effective for real-time as well as non real-time applications and results into realistic speechanimation.  Categories and Subject Descriptors (according to {ACM} CCS): 1.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism }}
@article{Blanz:2003:RFI,
author = {Blanz,V. and Basso,C. and Poggio,T. and Vetter,T.},
title = {Reanimating Faces in Images and Video},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {641-641},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper241},
abstract = { Abstract  This paper presents a method for photo-realistic animation that can be applied to any face shown in a single imageor a video. The technique does not require example data of the person's mouth movements, and the image to beanimated is not restricted in pose or illumination. Video reanimation allows for head rotations and speech in theoriginal sequence, but neither of these motions is required.  In order to animate novel faces, the system transfers mouth movements and expressions across individuals, basedon a common representation of different faces and facial expressions in a vector space of {3D} shapes and textures.This space is computed from {3D} scans of neutral faces, and scans of facial expressions.  The {3D} model's versatility with respect to pose and illumination is conveyed to photo-realistic image and videoprocessing by a framework of analysis and synthesis algorithms: The system automatically estimates {3D} shape andall relevant rendering parameters, such as pose, from single images. In video, head pose and mouth movements aretracked automatically. Reanimated with new mouth movements, the {3D} face is rendered into the original images.  Categories and Subject Descriptors (according to {ACM} CCS): I.3.7 [Computer Graphics]: Animation }}
@article{Rieger:2003:NUO,
author = {Rieger,Thomas and Braun,Norbert},
title = {Narrative Use of Sign Language by a Virtual Character for the Hearing Impaired},
journal = {Computer Graphics Forum},
volume = {22},
number = {3},
pages = {651-651},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue3/paper326.pdf},
abstract = { Abstract  This paper describes the concept and control of a 3d virtual character system with facial expressions and gesturesas a conversational user interface with narrative expressiveness for the hearing impaired. The gestures and facialexpressions are based on morphing techniques. The system allows the generation of sign language and mouthmotion in real time from text at the level of lip reading quality. The concept of Narrative Extended Speech Acts(NESA) is introduced, based on Interactive Storytelling techniques and the concepts of Narrative Conflict andSuspense Progression. We define a choice of annotation tags to be used with NESAs. We use the NESAs to classifyconversation fragments and to enhance computer generated sign language. We note, how the sign language gesturesare generated and show the possibilities for editing sign language gestures. Furthermore, we give details onhow the NESAs are mapped to gestures. We show the possibilities of controlling the virtual character's behaviourand gestures in a human-oriented way and provide an outlook on future work.  Categories and Subject Descriptors (according to {ACM} CCS): 1.3.6 [Computer Graphics]: Methodology and Techniques }}
@article{Patow:2003:ASO,
author = {G. Patow and X. Pueyo},
title = {A Survey of Inverse Rendering Problems },
journal = {Computer Graphics Forum},
volume = {22},
number = {4},
pages = {},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue4/22663.pdf},
abstract = { }}

@article{Vazquez:2003:AVS,
author = {P.-P. Vazquez and M. Feixas and M. Sbert and W. Heidrich
},
title = {Automatic View Selection Using Viewpoint Entropy and its Applications to Image-based Modelling },
journal = {Computer Graphics Forum},
volume = {22},
number = {4},
pages = {},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue4/22689.pdf},
abstract = { }}

@article{Claustres:2003:BRDF,
author = {L. Claustres and M. Paulin and Y. Boucher},
title = {{BRDF} Measurement Modelling using Wavelets for Efficient Path Tracing 
},
journal = {Computer Graphics Forum},
volume = {22},
number = {4},
pages = {},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue4/22701.pdf},
abstract = { }}

@article{Li:2003:SOM,
author = {Y. Li and K. Brodlie},
title = {Soft Object Modelling with Generalised ChainMail - Extending the Boundaries of Web-based Graphics },
journal = {Computer Graphics Forum},
volume = {22},
number = {4},
pages = {},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue4/22717.pdf},
abstract = { }}

@article{Schregle:2003:BCF,
author = {R. Schregle},
title = {Bias Compensation for Photon Maps },
journal = {Computer Graphics Forum},
volume = {22},
number = {4},
pages = {},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue4/22729.pdf},
abstract = { }}

@article{Balsys:2003:RTS,
author = {R. J. Balsys and K. G. Suffern},
title = {Ray Tracing Surfaces with Contours },
journal = {Computer Graphics Forum},
volume = {22},
number = {4},
pages = {},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue4/22743.pdf},
abstract = { }}

@article{Hasenfratz:2003:ASO,
author = {J.-M. Hasenfratz and M. Lapierre and N. Holzschuch and F. Sillion
},
title = {A Survey of Real-time Soft Shadows Algorithms},
journal = {Computer Graphics Forum},
volume = {22},
number = {4},
pages = {},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue4/22753.pdf},
abstract = { }}

@article{Post:2003:TSO,
author = {F. H. Post and B. Vrolijk and H. Hauser and R. S. Laramee and H. Doleisch
},
title = {The State of the Art in Flow Visualisation: Feature Extraction and Tracking },
journal = {Computer Graphics Forum},
volume = {22},
number = {4},
pages = {},
year = {2003},
URL = {http://www.eg.org/EG/CGF/volume22/issue4/22775.pdf},
abstract = { }}

</PRE>
	</td>


	</table>

 
<P>

</BODY>
</HTML>
