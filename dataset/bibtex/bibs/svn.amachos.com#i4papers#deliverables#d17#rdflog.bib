%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Tim Furche at 2007-12-11 16:01:28 +0100 

%% Saved with string encoding Western (ASCII) 


@techreport{online-version,
	Author = {Fran{\c c}ois Bry and Tim Furche and Clemens Ley and Benedikt Linse},
	Date-Added = {2007-12-14 14:27:37 +0100},
	Date-Modified = {2007-12-14 14:33:15 +0100},
	Institution = {University of Munich},
	Number = {PMS-FB-2008-01},
	Title = {RDFLog: Filling in the Blanks in RDF Querying},
	Url = {http://www.pms.ifi.lmu.de/publikationen#PMS-FB-2008-01},
	Year = {2007}}


@inproceedings{182604,
 author = {Surajit Chaudhuri and Moshe Y. Vardi},
 title = {On the complexity of equivalence between recursive and nonrecursive Datalog programs},
 booktitle = {PODS '94: Proceedings of the thirteenth ACM SIGACT-SIGMOD-SIGART symposium on Principles of database systems},
 year = {1994},
 isbn = {0-89791-642-5},
 pages = {107--116},
 location = {Minneapolis, Minnesota, United States},
 doi = {http://doi.acm.org/10.1145/182591.182604},
 publisher = {ACM},
 address = {New York, NY, USA},
 }


@misc{dantsin-expressive,
  author = "Evgeny Dantsin and Andrei Voronkov",
  title = "Expressive Power and Data Complexity of Nonrecursive Logic Programming",
  url = "citeseer.ist.psu.edu/dantsin98expressive.html" }


@string{aaai = {Proc. Nat'l. Conf. on Artificial Intelligence (AAAI)}}

@string{addison = {Addison-Wesley Publishing Co.}}

@string{ai = {Artificial Intelligence}}

@string{amai = {Annals of Mathematics and Artificial Intelligence}}

@string{ams = {American Mathematical Society}}

@string{apal = {Annals of Pure and Applied Logic}}

@string{bncod = {Proc. British National Conf. on Databases (BNCOD)}}

@string{cacm = {Communications of the ACM}}

@string{cade = {Proc. Int'l. Conf. on Automated Deduction (CADE)}}

@string{cikm = {Proc. Int'l. Conf. on Information and Knowledge Management (CIKM)}}

@string{csur = {ACM Computing Surveys}}

@string{dblp = {Proc. Int'l. Workshop on Database Programming Languages (DBLP)}}

@string{dke = {Data \& Knowledge Engineering (DKE)}}

@string{dood = {Proc. Int'l. Conf. on Object-Oriented and Deductive Databases (DOOD)}}

@string{edbt = {Proc. Int'l. Conf. on Extending Database Technology (EDBT)}}

@string{elsevier = {Elsevier Science}}

@string{eml = {Proc. Extreme Markup Languages (Int'l. Conf. on Markup Theory \& Practice)}}

@string{eswc = {Proc. European Semantic Web Conf. (ESWC)}}

@string{fi = {Fundamenta Informaticae}}

@string{focs = {Proc. IEEE Int'l. Conf. of Foundations of Computer Science (FOCS)}}

@string{fundi = {Fundamenta Informaticae}}

@string{iandc = {Information and Computation}}

@string{icalp = {Proc. Int'l. Symp. on Automata, Languages and Programming (ICALP)}}

@string{icde = {Proc. Int'l. Conf. on Data Engineering (ICDE)}}

@string{icdt = {Proc. Int'l. Conf. on Database Theory (ICDT)}}

@string{iclp = {Proc. Int'l. Conf. on Logic Programming (ICLP)}}

@string{ieee = {IEEE Computer Society Press}}

@string{ijcai = {Proc. Int'l. Joint Conf. on Artificial Intelligence (IJCAI)}}

@string{ipl = {Information Processing Letters}}

@string{is = {Information Systems}}

@string{iswc = {Proc. Int'l. Semantic Web Conf. (ISWC)}}

@string{jacm = {Journal of the ACM}}

@string{jar = {Journal of Automated Reasoning}}

@string{jcss = {Journal of Computer and System Sciences}}

@string{jlc = {Journal of Logic and Computation}}

@string{jlp = {Journal of Logic Programming}}

@string{jsc = {Journal of Symbolic Computation}}

@string{jsl = {Journal of Symbolic Logic}}

@string{kluwer = {Kluwer Academic Publishers}}

@string{krdb = {Proc. Int'l. Workshop on Knowledge Representation meets Databases (KRDB)}}

@string{lics = {Proc. IEEE Conf. on Logic in Computer Science (LICS)}}

@string{lnai = {Lecture Notes in Artificial Intelligence}}

@string{lncs = {Lecture Notes in Computer Science}}

@string{lnm = {Lecture Notes in Mathematics}}

@string{mit = {The MIT Press}}

@string{planx = {Informal Proc. ACM SIGPLAN Workshop on Programming Language Technologies for XML (Plan-X)}}

@string{pods = {Proc. ACM Symp. on Principles of Database Systems (PODS)}}

@string{popl = {Proc. ACM Symp. on Principles of Programming Languages (POPL)}}

@string{ppswr = {Proc. Int'l. Workshop on Principles and Practice of Semantic Web Reasoning (PPSWR)}}

@string{rr = {Proc.\@ Int'l.\@ Conf.\@ on Web Reasoning and Rule Systems (RR)}}

@string{rw = {Tutorial Lectures Int'l. Summer School `Reasoning Web'}}

@string{sac = {Proc. ACM Symp. on Applied Computing (SAC)}}

@string{siam = {SIAM Journal of Computing}}

@string{sigmod = {Proc. ACM Symp. on Management of Data (SIGMOD)}}

@string{spe = {Software --- Practice and Experience}}

@string{springer = {Springer Verlag}}

@string{stoc = {Proc. ACM Symp. on Theory of Computing (STOC)}}

@string{swdb = {Proc.\ Semantic Web and Databases Workshop (SWDB)}}

@string{tcs = {Theoretical Computer Science}}

@string{tkde = {IEEE Transactions on Knowledge and Data Engineering}}

@string{tocl = {ACM Transactions on Computational Logics}}

@string{tods = {ACM Transactions on Database Systems}}

@string{toplas = {ACM Transactions on Programming Languages and Systems}}

@string{tse = {IEEE Transactions on Software Engineering}}

@string{vldb = {Proc. Int'l. Conf. on Very Large Data Bases (VLDB)}}

@string{vldbj = {VLDB Journal}}

@string{webdb = {Proc. Int'l. Workshop on the Web and Databases (WebDB)}}

@string{widm = {Proc. ACM Int'l. Workshop on Web Information and Data Management (WIDM)}}

@string{www = {Proc. Int'l. World Wide Web Conf. (WWW)}}

@book{Ebinghaus,
	Author = {H.-D. Ebbinghaus and J. Flum and W. Thomas},
	Date-Added = {2007-12-14 14:36:34 +0100},
	Date-Modified = {2007-12-14 14:37:40 +0100},
	Keywords = {lean semantics},
	Publisher = springer,
	Title = {Mathematical Logic},
	Year = {1994}}


@book{lloyd,
	Author = {Lloyd, JW},
	Date-Added = {2007-12-11 16:00:38 +0100},
	Date-Modified = {2007-12-11 16:01:28 +0100},
	Publisher = springer,
	Title = {{Foundations of Logic Programming}},
	Year = {1987}}

@incollection{Broekstra2006An-RDF-Query-and-Transformation-Language,
	Abstract = {RDF Query Language proposals are numerous. However, the most prominent proposals are query languages that were conceived as first generation tryouts of RDF querying, with little or no RDF-specific implementation and use experience to guide design, and based on an ever changing set of syntactical and semantic specifications.
In this chapter, we introduce a set of general requirements for an RDF query language. This set is compiled from discussions between RDF implementors, our own experience and user feedback that we received on our work in Sesame, as well as general principles of query language design. We go on to show how we have compiled these requirements into designing the SeRQL query language, and conclude that SeRQL can be considered a real second generation RDF querying and transformation language.},
	Author = {Jeen Broekstra and Arjohn Kampman},
	Booktitle = {Semantic Web and Peer-to-Peer},
	Chapter = {2},
	Date-Added = {2007-12-11 15:29:59 +0100},
	Date-Modified = {2007-12-11 15:31:41 +0100},
	Pages = {23--39},
	Publisher = springer,
	Title = {An RDF Query and Transformation Language},
	Year = {2006}}

@article{Kifer1995Logical-Foundations-of-Object-oriented-and-Frame-based-Languages,
	Abstract = {We propose a novel formalism, called Frame Logic (abbr., F-logic), that accounts in a clean and declarative fashion for most of the structural aspects of object-oriented and frame-based languages. These features include object identity, complex objects, inheritance, polymorphic types, query methods, encapsulation, and others. In a sense, F-logic stands in the same relationship to the object-oriented paradigm as classical predicate calculus stands to relational programming. F-logic has a model-theoretic semantics and a sound and complete resolution-based proof theory. A small number of fundamental concepts that come from object-oriented programming have direct representation in F-logic; other, secondary aspects of this paradigm are easily modeled as well. The paper also discusses semantic issues pertaining to programming with a deductive object-oriented language based on a subset of F-logic.},
	Address = {New York, NY, USA},
	Author = {Michael Kifer and Georg Lausen and James Wu},
	Date-Added = {2007-12-11 15:12:10 +0100},
	Date-Modified = {2007-12-11 15:12:51 +0100},
	Doi = {http://doi.acm.org/10.1145/210332.210335},
	Issn = {0004-5411},
	Journal = jacm,
	Number = {4},
	Pages = {741--843},
	Publisher = {ACM},
	Title = {{Logical Foundations of Object-oriented and Frame-based Languages}},
	Volume = {42},
	Year = {1995}}

@article{Yang2003Reasoning-about-Anonymous-Resources-and-Meta-Statements-on-the-Semantic-Web,
	Author = {Yang, G. and Kifer, M.},
	Date-Added = {2007-12-11 15:09:13 +0100},
	Date-Modified = {2007-12-11 15:10:13 +0100},
	Journal = {Journal of Data Semantics},
	Pages = {69--97},
	Publisher = {Springer},
	Title = {{Reasoning about Anonymous Resources and Meta Statements on the Semantic Web}},
	Volume = {1},
	Year = {2003}}

@inproceedings{Polleres2007From-SPARQL-to-rules-and-back,
	Abstract = {As the data and ontology layers of the Semantic Web stack have achieved a certain level of maturity in standard recommendations such as RDF and OWL, the current focus lies on two related aspects. On the one hand, the definition of a suitable query language for RDF, SPARQL, is close to recommendation status within the W3C. The establishment of the rules layer on top of the existing stack on the other hand marks the next step to be taken, where languages with their roots in Logic Programming and Deductive Databases are receiving considerable attention. The purpose of this paper is threefold. First, we discuss the formal semantics of SPARQLextending recent results in several ways. Second, weprovide translations from SPARQL to Datalog with negation as failure. Third, we propose some useful and easy to implement extensions of SPARQL, based on this translation. As it turns out, the combination serves for direct implementations of SPARQL on top of existing rules engines as well as a basis for more general rules and query languages on top of RDF.

},
	Address = {New York, NY, USA},
	Author = {Axel Polleres},
	Booktitle = www,
	Date-Added = {2007-12-11 15:06:26 +0100},
	Date-Modified = {2007-12-11 15:06:47 +0100},
	Doi = {http://doi.acm.org/10.1145/1242572.1242679},
	Isbn = {978-1-59593-654-7},
	Location = {Banff, Alberta, Canada},
	Pages = {787--796},
	Publisher = {ACM},
	Title = {From SPARQL to Rules (and Back)},
	Year = {2007}}

@inproceedings{Harris2005SPARQL-Query-Processing-with-Conventional-Relational-Database-Systems,
	Author = {Harris, S. and Shadbolt, N.},
	Booktitle = {Proc. Int'l. Workshop on Scalable Semantic Web Knowledge Base Systems (SSWS)},
	Date-Added = {2007-12-11 14:58:27 +0100},
	Date-Modified = {2007-12-11 15:06:22 +0100},
	Journal = {Lecture notes in computer science},
	Pages = {235--244},
	Publisher = springer,
	Series = {LNCS},
	Title = {{SPARQL Query Processing with Conventional Relational Database Systems}},
	Volume = {3807},
	Year = {2005}}

@techreport{Cyganiak2005A-Relational-Algebra-for-Sparql,
	Author = {R. Cyganiak},
	Date-Added = {2007-12-11 14:57:29 +0100},
	Date-Modified = {2007-12-11 14:57:55 +0100},
	Institution = {HP-Labs},
	Number = {HPL-2005-170},
	Title = {{A Relational Algebra for Sparql}},
	Url = {http://www.hpl.hp.com/techreports/2005/HPL-2005-170.html},
	Year = {2005}}

@article{Munro1976Sorting-and-Searching-in-Multisets,
	Abstract = {In this paper the problem of sorting multisets is considered. An information theoretic lower bound on the number of three branch comparisons is obtained, and it is shown that this bound is asymptotically attainable. It is shown that the multiplicities of a set can only be obtained by comparisons if the total order is discovered in the process. A lower bound on finding the mode of a multiset as a function of the actual multiplicity is given, and it is demonstrated that the bound can be achieved to within a multiplicative constant. The determination of the intersection of two multisets is also discussed, and partial results, including a generalization of Reingold's result for determining whether or not two sets have a nonempty intersection, are obtained.},
	Author = {Ian Munro and Philip M. Spira},
	Date-Added = {2007-12-11 13:07:05 +0100},
	Date-Modified = {2007-12-11 13:08:25 +0100},
	Journal = siam,
	Keywords = {sorting, multiset, duplicate elimination, lower bounds},
	Number = {1},
	Pages = {1--8},
	Title = {Sorting and Searching in Multisets},
	Volume = {5},
	Year = {1976}}

@article{Hsu2003PC-trees-and-circular-ones-arrangements,
	Abstract = {A 0-1 matrix has the consecutive-ones property if its columns can be ordered so that the ones in every row are consecutive. It has the circular-ones property if its columns can be ordered so that, in every row, either the ones or the zeros are consecutive. PQ trees are used for representing all consecutive-ones orderings of the columns of a matrix that have the consecutive-ones property. We give an analogous structure, called a PC tree, for representing all circular-ones orderings of the columns of a matrix that has the circular-ones property. No such representation has been given previously. In contrast to PQ trees, PC trees are unrooted. We obtain a much simpler algorithm for computing PQ trees that those that were previously available, by adding a zero column, x, to a matrix, computing the PC tree, and then picking the PC tree up by x to root it.},
	Address = {Essex, UK},
	Author = {Wen-Lian Hsu and Ross M. McConnell},
	Date-Added = {2007-11-26 13:03:06 +0100},
	Date-Modified = {2007-11-26 13:04:37 +0100},
	Doi = {http://dx.doi.org/10.1016/S0304-3975(02)00435-8},
	Issn = {0304-3975},
	Journal = tcs,
	Keywords = {interval, pc-tree, pq-tree, circular ones property, consecutive ones propertyn},
	Number = {1},
	Pages = {99--116},
	Publisher = {Elsevier Science Publishers Ltd.},
	Title = {{PC Trees and Circular-ones Arrangements}},
	Volume = {296},
	Year = {2003}}

@inproceedings{Shalem2008The-Space-Complexity-of-Processing-XML-Twig-Queries-over-Indexed-Documents,
	Abstract = {Current twig join algorithms incur high mem- ory costs on queries that involve child-axis nodes. In this paper we provide an analytical explanation for this phenomenon. In a first large-scale study of the space complexity of evaluating XPath queries over indexed XML documents we show the space to depend on three factors: (1) whether the query is a path or a tree; (2) the types of axes occurring in the query and their occurrence pattern; and (3) the mode of query evaluation (filtering, full-fledged, or ``pattern matching''). Our lower bounds imply that evaluation of a large class of queries that have child-axis nodes indeed requires large space. 
Our study also reveals that on some queries there is a large gap between the space needed for pattern matching and the space needed for full-fledged evaluation or filtering. This implies that many existing twig join algorithms, which work in the pattern matching mode, incur significant space overhead. We present a new twig join algorithm that avoids this overhead. On certain queries our algorithm is exceedingly more space-efficient than existing algorithms, sometimes bringing the space down from linear in the document size to constant.
},
	Author = {Mirit Shalem and Ziv Bar-Yossef},
	Booktitle = icde,
	Date-Added = {2007-11-23 22:50:41 +0100},
	Date-Modified = {2007-11-23 22:52:44 +0100},
	Keywords = {xpath, xml, twig queries, lower bound, complexity, space},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Shalem2008The-Space-Complexity-of-Processing-XML-Twig-Queries-over-Indexed-Documents.pdf},
	Title = {The Space Complexity of Processing XML Twig Queries over Indexed Documents},
	Year = {2008}}

@inproceedings{Gottlob2004Conjunctive-Queries-over-Trees,
	Abstract = {We study the complexity and expressive power of conjunctive queries over unranked labeled trees, where the tree structure are represented using "axis relations" such as "child", "descendant", and "following" (we consider a superset of the XPath axes) as well as unary relations for node labels. (Cyclic) conjunctive queries over trees occur in a wide range of data management scenarios related to XML, the Web, and computational linguistics. We establish a framework for characterizing structures representing trees for which conjunctive queries can be evaluated efficiently. Then we completely chart the tractability frontier of the problem for our axis relations, i.e., we find all subset maximal sets of axes for which query evaluation is in polynomial time. All polynomial-time results are obtained immediately using the proof techniques from our framework. Finally, we study the expressiveness of conjunctive queries over trees and compare it to the expressive power of fragments of XPath. We show that for each conjunctive query, there is an equivalent acyclic positive query (i.e., a set of acyclic conjunctive queries), but that in general this query is not of polynomial size.},
	Address = {New York, NY, USA},
	Author = {Georg Gottlob and Christoph Koch and Klaus U. Schulz},
	Booktitle = pods,
	Date-Added = {2007-11-09 21:36:16 +0100},
	Date-Modified = {2007-11-09 21:36:58 +0100},
	Doi = {http://doi.acm.org/10.1145/1055558.1055585},
	Isbn = {158113858X},
	Keywords = {conjunctive queries, tree, complexity, graph queries},
	Location = {Paris, France},
	Pages = {189--200},
	Publisher = {ACM},
	Title = {Conjunctive Queries over Trees},
	Year = {2004}}

@inproceedings{Altinel2000Efficient-Filtering-of-XML-Documents-for-Selective-Dissemination-of-Information,
	Address = {San Francisco, CA, USA},
	Author = {Altinel, Mehmet and Franklin, Michael J.},
	Booktitle = vldb,
	Date-Added = {2007-11-08 18:44:25 +0100},
	Date-Modified = {2007-11-08 18:44:49 +0100},
	Isbn = {1-55860-715-3},
	Keywords = {stream, XPath, XML, XFilter,},
	Pages = {53--64},
	Publisher = {Morgan Kaufmann Publishers Inc.},
	Title = {Efficient Filtering of XML Documents for Selective Dissemination of Information},
	Year = {2000}}

@article{Fagin1977Multivalued-Dependencies-and-a-New-Normal-Form-for-Relational-Databases,
	Abstract = {A new type of dependency, which includes the well-known functional dependencies as a special case, is defined for relational databases. By using this concept, a new (``fourth'') normal form for relation schemata is defined. This fourth normal form is strictly stronger than Codd's ``improved third normal form'' (or ``Boyce-Codd normal form''). It is shown that every relation schema can be decomposed into a family of relation schemata in fourth normal form without loss of information (that is, the original relation can be obtained from the new relations by taking joins).},
	Address = {New York, NY, USA},
	Author = {Fagin, Ronald},
	Date-Added = {2007-11-08 17:51:14 +0100},
	Date-Modified = {2007-11-08 17:53:04 +0100},
	Doi = {http://doi.acm.org/10.1145/320557.320571},
	Issn = {0362-5915},
	Journal = tods,
	Keywords = {multivalued dependencies, join dependencies, },
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Fagin1977Multivalued-Dependencies-and-a-New-Normal-Form-for-Relational-Databases.pdf},
	Number = {3},
	Pages = {262--278},
	Publisher = {ACM},
	Title = {Multivalued Dependencies and a New Normal Form for Relational Databases},
	Volume = {2},
	Year = {1977}}

@inproceedings{Dietz1987Two-Algorithms-for-Maintaining-Order-in-a-List,
	Abstract = {The order maintenance problem is that of maintaining a list under a sequence of Insert and Delete operations, while answering Order queries (determine which of two elements comes first in the list). We give two new algorithms for this problem. The first algorithm matches the O(1) amortized time per operation of the best previously known algorithm, and is much simpler. The second algorithm permits all operations to be performed in O(1) worst-case time.},
	Address = {New York, NY, USA},
	Author = {Dietz, P. and Sleator, D.},
	Booktitle = stoc,
	Date-Added = {2007-11-08 17:25:50 +0100},
	Date-Modified = {2007-11-08 17:27:12 +0100},
	Doi = {http://doi.acm.org/10.1145/28395.28434},
	Isbn = {0-89791-221-7},
	Keywords = {tree, index, interval, order, list},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Dietz1987Two-Algorithms-for-Maintaining-Order-in-a-List.pdf},
	Location = {New York, New York, United States},
	Pages = {365--372},
	Publisher = {ACM},
	Title = {Two Algorithms for Maintaining Order in a List},
	Year = {1987}}

@inproceedings{Dietz1982Maintaining-Order-in-a-Linked-List,
	Abstract = {We present a new representation for linked lists. This representation allows one to efficiently insert objects into the list and to quickly determine the order of list elements. The basic data structure, called an indexed 2-3 tree, allows one to do n inserts in O(nlogn) steps and to determine order in constant time. We speed up the algorithm by dividing the data structure up into log*n layers. The improved algorithm does n insertions and comparisons in O(nlog*n) steps. The paper concludes with two applications: determining ancestor relationships in a growing tree and maintaining a tree structured environment (context tree).},
	Address = {New York, NY, USA},
	Author = {Dietz, Paul F.},
	Booktitle = stoc,
	Date-Added = {2007-11-08 17:23:11 +0100},
	Date-Modified = {2007-11-08 17:24:07 +0100},
	Doi = {http://doi.acm.org/10.1145/800070.802184},
	Isbn = {0-89791-070-2},
	Keywords = {interval, index, tree, },
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Dietz1982Maintaining-Order-in-a-Linked-List.pdf},
	Location = {San Francisco, California, United States},
	Pages = {122--127},
	Publisher = {ACM},
	Title = {Maintaining Order in a Linked List},
	Year = {1982}}

@inproceedings{Agrawal1989Efficient-Management-of-Transitive-Relationships-in-Large-Data,
	Abstract = {We argue that accessing the transitive closure of relationships is an important component of both databases and knowledge representation systems in Artificial Intelligence. The demands for efficient access and management of large relationships motivate the need for explicitly storing the transitive closure in a compressed and local way, while allowing updates to the base relation to be propagated incrementally. We present a transitive closure compression technique, based on labeling spanning trees with numeric intervals, and provide both analytical and empirical evidence of its efficacy, including a proof of optimality.},
	Address = {New York, NY, USA},
	Author = {Agrawal, R. and Borgida, A. and Jagadish, H. V.},
	Booktitle = sigmod,
	Date-Added = {2007-11-08 13:55:28 +0100},
	Date-Modified = {2007-11-08 13:56:16 +0100},
	Doi = {http://doi.acm.org/10.1145/67544.66950},
	Isbn = {0-89791-317-5},
	Keywords = {graph,graph indices, indexing, reachability, interval},
	Location = {Portland, Oregon, United States},
	Pages = {253--262},
	Publisher = {ACM},
	Title = {Efficient Management of Transitive Relationships in Large Data and Knowledge Bases},
	Year = {1989}}

@inproceedings{Trissl2007Fast-and-Practical-Indexing-and-Querying-of-Very-Large,
	Abstract = {Many applications work with graph-structured data. As graphs grow in size, indexing becomes essential to ensure sufficient query performance. We present the GRIPP index structure (GRaph Indexing based on Pre- and Postorder numbering) for answering reachability queries in graphs.

GRIPP requires only linear time and space. Using GRIPP, we can answer reachability queries on graphs with 5 million nodes on average in less than 5 milliseconds, which is unrivaled by previous methods. We evaluate the performance and scalability of our approach on real and synthetic random and scale-free graphs and compare our approach to existing indexing schemes. GRIPP is implemented as stored procedure inside a relational database management system and can therefore very easily be integrated into existing graph-oriented applications.},
	Address = {New York, NY, USA},
	Author = {Tri{\ss}l, Silke and Leser, Ulf},
	Booktitle = sigmod,
	Date-Added = {2007-11-08 12:59:12 +0100},
	Date-Modified = {2007-11-08 13:20:35 +0100},
	Doi = {http://doi.acm.org/10.1145/1247480.1247573},
	Isbn = {978-1-59593-686-8},
	Keywords = {graphs, indexing, reachability, interval, labeling},
	Location = {Beijing, China},
	Pages = {845--856},
	Publisher = {ACM},
	Title = {Fast and Practical Indexing and Querying of Very Large Graphs},
	Year = {2007}}

@article{Paige1987Three-Partition-Refinement-Algorithms,
	Abstract = {We present improved partition refinement algorithms for three problems: lexicographic sorting, relational coarsest partition, and double lexical ordering. Our double lexical ordering algorithm uses a new, efficient method for unmerging two sorted sets.},
	Address = {Philadelphia, PA, USA},
	Author = {Paige, Robert and Tarjan, Robert E.},
	Date-Added = {2007-11-08 11:00:11 +0100},
	Date-Modified = {2007-11-08 11:01:05 +0100},
	Doi = {http://dx.doi.org/10.1137/0216062},
	Issn = {0097-5397},
	Journal = siam,
	Keywords = {reachability, shortest path,},
	Number = {6},
	Pages = {973--989},
	Publisher = {Society for Industrial and Applied Mathematics},
	Title = {Three Partition Refinement Algorithms},
	Volume = {16},
	Year = {1987}}

@inproceedings{Wang2006Dual-Labeling:-Answering-Graph-Reachability-Queries,
	Abstract = {Graph reachability is fundamental to a wide range of applications, including XML indexing, geographic navigation, Internet routing, ontology queries based on RDF/OWL, etc. Many applications involve huge graphs and require fast answering of reachability queries. Several reachability labeling methods have been proposed for this purpose. They assign labels to the vertices, such that the reachability between any two vertices may be decided using their labels only. For sparse graphs, 2-hop based reachability labeling schemes answer reachability queries efficiently using relatively small label space. However, the labeling process itself is often too time consuming to be practical for large graphs. In this paper, we propose a novel labeling scheme for sparse graphs. Our scheme ensures that graph reachability queries can be answered in constant time. Furthermore, for sparse graphs, the complexity of the labeling process is almost linear, which makes our algorithm applicable to massive datasets. Analytical and experimental results show that our approach is much more efficient than stateof- the-art approaches. Furthermore, our labeling method also provides an alternative scheme to tradeoff query time for label space, which further benefits applications that use tree-like graphs.},
	Address = {Washington, DC, USA},
	Author = {Wang, Haixun and He2, Hao and Yang, Jun and Yu, Philip S. and Yu, Jeffrey Xu},
	Booktitle = icde,
	Date-Added = {2007-11-08 10:57:01 +0100},
	Date-Modified = {2007-11-08 10:57:40 +0100},
	Doi = {http://dx.doi.org/10.1109/ICDE.2006.53},
	Isbn = {0-7695-2570-9},
	Keywords = {labeling, reachability, graph indices, dual labeling, interval, pre/post encoding},
	Pages = {75},
	Publisher = {IEEE Computer Society},
	Title = {Dual Labeling: Answering Graph Reachability Queries in Constant Time},
	Year = {2006}}

@inproceedings{Weigel2005The-BIRD-Numbering-Scheme-for-XML-and-Tree-Databases--Deciding-and-Reconstructing-Tree-Relations-Using,
	Abstract = {This paper introduces the BIRD family of numbering schemes for tree databases, which is based on a structural summary such as the DataGuide. Given the BIRD IDs of two database nodes and the corresponding nodes in the structural summary we decide the extended XPath relations Child, Child, Child, Following, NextSibling, NextSibling, NextSibling for the nodes without access to the database. Similarly we can reconstruct the parent node and neighbouring siblings of a given node. All decision and reconstruction steps are based on simple arithmetic operations. The BIRD scheme offers high expressivity and efficiency paired with modest storage demands. Compared to other identification schemes with similar expressivity, BIRD performs best in terms of both storage consumption and execution time, with experiments underlining the crucial role of ID reconstruction in query evaluation. A very attractive feature of the BIRD scheme is that all extended XPath relations can be decided and reconstructed in constant time, i.e., independent of tree position and distance of the nodes involved. All results are shown to scale up to the multi-Gigabyte level.},
	Author = {Weigel, Felix and Schulz, Klaus U. and Meuss, Holger},
	Booktitle = {Proc. Int'l. XML Database Symposium (XSym)},
	Date-Added = {2007-11-07 23:14:28 +0100},
	Date-Modified = {2007-11-07 23:17:26 +0100},
	Keywords = {XML, indexing, BIRD, interval},
	Pages = {49-67},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {The BIRD Numbering Scheme for XML and Tree Databases -- Deciding and Reconstructing Tree Relations Using Efficient Arithmetic Operations},
	Volume = {3671},
	Year = {2005}}

@inproceedings{Jiang2003XR-Tree,
	Author = {Jiang, H. and Lu, H. and Wang, W. and Ooi, B.},
	Booktitle = icde,
	Date-Added = {2007-11-07 23:12:34 +0100},
	Date-Modified = {2007-11-07 23:13:12 +0100},
	Keywords = {XML, XR-Tree, indexing},
	Pages = {253--264},
	Text = {H. Jiang , H. Lu, W. Wang, and B. C. Ooi, XR-Tree: Indexing XML Data for Efficient Structural Join, Proc. of ICDE, India, 2003.},
	Title = {XR-Tree: Indexing XML Data for Efficient Structural Join},
	Url = {citeseer.ist.psu.edu/jiang03xrtree.html},
	Year = {2003}}

@article{Chen2007Index-structures-for-matching-XML-twigs-using-relational-query-processors,
	Abstract = {Various index structures have been proposed to speed up the evaluation of XML path expressions. However, existing XML path indices suffer from at least one of three limitations: they focus only on indexing the structure (relying on a separate index for node content), they are useful only for simple path expressions such as root-to-leaf paths, or they cannot be tightly integrated with a relational query processor. Moreover, there is no unified framework to compare these index structures. In this paper, we present a framework defining a family of index structures that includes most existing XML path indices. We also propose two novel index structures in this family, with different space-time tradeoffs, that are effective for the evaluation of XML branching path expressions (i.e., twigs) with value conditions. We also show how this family of index structures can be implemented using the access methods of the underlying relational database system. Finally, we present an experimental evaluation that shows the performance tradeoff between index space and matching time. The experimental results show that our novel indices achieve orders of magnitude improvement in performance for evaluating twig queries, albeit at a higher space cost, over the use of previously proposed XML path indices that can be tightly integrated with a relational query processor.},
	Address = {Amsterdam, The Netherlands, The Netherlands},
	Author = {Chen, Zhiyuan and Gehrke, Johannes and Korn, Flip and Koudas, Nick and Shanmugasundaram, Jayavel and Srivastava, Divesh},
	Date-Added = {2007-11-07 23:08:35 +0100},
	Date-Modified = {2007-11-07 23:10:25 +0100},
	Doi = {http://dx.doi.org/10.1016/j.datak.2006.03.003},
	Issn = {0169-023X},
	Journal = dke,
	Keywords = {twig join, structural join, indexing, XR-Tree},
	Number = {2},
	Pages = {283--302},
	Publisher = {Elsevier Science Publishers B. V.},
	Title = {Index Structures for Matching XML Twigs using Relational Query Processors},
	Volume = {60},
	Year = {2007}}

@inproceedings{Goldman1997DataGuides:-Enabling-Query-Formulation-and-Optimization-in-Semistructured-Databases,
	Address = {San Francisco, CA, USA},
	Author = {Goldman, Roy and Widom, Jennifer},
	Booktitle = vldb,
	Date-Added = {2007-11-07 23:06:23 +0100},
	Date-Modified = {2007-11-07 23:06:52 +0100},
	Isbn = {1-55860-470-7},
	Keywords = {path indices, XML, DataGuides},
	Pages = {436--445},
	Publisher = {Morgan Kaufmann Publishers Inc.},
	Title = {DataGuides: Enabling Query Formulation and Optimization in Semistructured Databases},
	Year = {1997}}

@article{Olteanu2007Forward-node-selecting-queries-over-trees,
	Abstract = {Node-selecting queries over trees lie at the core of several important XML languages for the web, such as the node-selection language XPath, the query language XQuery, and the transformation language XSLT. The main syntactic constructs of such queries are the backward predicates, for example, ancestor and preceding, and the forward predicates, for example, descendant and following. Forward predicates are included in the depth-first, left-to-right preorder relation associated with the input tree, whereas backward predicates are included in the inverse of this preorder relation.

This work is devoted to an expressiveness study of node-selecting queries with proven theoretical and practical applicability, especially in the field of query evaluation against XML streams. The main question it answers positively is whether, for each input query with forward and backward predicates, there exists an equivalent forward-only output query. This question is then positively answered for input and output queries of varying structural complexity, using LOGLIN and PSPACE reductions.

Various existing applications based on the results of this work are reported, including query optimization and streamed evaluation.},
	Address = {New York, NY, USA},
	Author = {Olteanu, Dan},
	Date-Added = {2007-11-06 12:49:14 +0100},
	Date-Modified = {2007-11-06 12:50:32 +0100},
	Doi = {http://doi.acm.org/10.1145/1206049.1206052},
	Issn = {0362-5915},
	Journal = tods,
	Keywords = {XPath, rewriting, forward XPath, tree, graph},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Olteanu2007Forward-node-selecting-queries-over-trees.pdf},
	Number = {1},
	Pages = {3},
	Publisher = {ACM},
	Title = {Forward Node-selecting Queries over Trees},
	Volume = {32},
	Year = {2007}}

@article{Kanza2002Querying-Incomplete-Information-in-Semistructured-Data,
	Abstract = {Semistructured data occur in situations where information lacks a homogeneous structure and is incomplete. Yet, up to now the incompleteness of information has not been reflected by special features of query languages. Our goal is to investigate the principles of queries that allow for incomplete answers.},
	Author = {Kanza, Yaron and Nutt, Werner and Sagiv, Yehoshua},
	Date-Added = {2007-09-25 20:40:12 +0200},
	Date-Modified = {2007-09-25 20:41:29 +0200},
	Journal = jcss,
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Kanza2002Querying-Incomplete-Information-in-Semistructured-Data.pdf},
	Pages = {655-693},
	Title = {Querying Incomplete Information in Semistructured Data},
	Volume = {64},
	Year = {2002}}

@inproceedings{Mendelzon1989Finding-regular-simple-paths-in-graph-databases,
	Address = {San Francisco, CA, USA},
	Author = {Mendelzon, A. O. and Wood, P. T.},
	Booktitle = vldb,
	Date-Added = {2007-09-25 20:37:58 +0200},
	Date-Modified = {2007-09-25 20:38:50 +0200},
	Isbn = {1-55860-101-5},
	Keywords = {graph indices, graph pattern matching, pattern matching, paths, regular path expressions},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Mendelzon1989Finding-regular-simple-paths-in-graph-databases.pdf},
	Location = {Amsterdam, The Netherlands},
	Pages = {185--193},
	Publisher = {Morgan Kaufmann Publishers Inc.},
	Title = {Finding Regular Simple Paths in Graph Databases},
	Year = {1989}}

@inproceedings{Shasha2002Algorithmics-and-applications-of-tree-and-graph-searching,
	Abstract = {Modern search engines answer keyword-based queries extremely efficiently. The impressive speed is due to clever inverted index structures, caching, a domain-independent knowledge of strings, and thousands of machines. Several research efforts have attempted to generalize keyword search to keytree and keygraph searching, because trees and graphs have many applications in next-generation database systems. This paper surveys both algorithms and applications, giving some emphasis to our own work.},
	Address = {New York, NY, USA},
	Author = {Shasha, Dennis and Wang, Jason T. L. and Giugno, Rosalba},
	Booktitle = pods,
	Date-Added = {2007-09-25 20:35:37 +0200},
	Date-Modified = {2007-09-25 20:37:07 +0200},
	Doi = {http://doi.acm.org/10.1145/543613.543620},
	Isbn = {1-58113-507-6},
	Keywords = {graph searching, graph indices, tree search, keywords},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Shasha2002Algorithmics-and-applications-of-tree-and-graph-searching.pdf},
	Location = {Madison, Wisconsin},
	Pages = {39--52},
	Publisher = {ACM Press},
	Title = {Algorithmics and Applications of Tree and Graph Searching},
	Year = {2002}}

@inproceedings{Chen2005Stack-based-Algorithms-for-Pattern-Matching-on-DAGs,
	Abstract = {Existing work for query processing over graph data models often relies on pre-computing the transitive closure or path indexes. In this paper, we propose a family of stack-based algorithms to handle path, twig, and dag pattern queries for directed acyclic graphs (DAGs) in particular. Our algorithms do not precompute the transitive closure nor path indexes for a given graph, however they achieve an optimal runtime complexity quadratic in the average size of the query variable bindings. We prove the soundness and completeness of our algorithms and present the experimental results.},
	Author = {Chen, Li and Gupta, Amarnath and Kurul, M. Erdem},
	Booktitle = vldb,
	Date-Added = {2007-09-25 20:03:49 +0200},
	Date-Modified = {2007-09-25 20:10:48 +0200},
	Isbn = {1-59593-154-6},
	Keywords = {pattern matching, tree queries, DAG queries, twig join, DAG join, stack},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Chen2005Stack-based-Algorithms-for-Pattern-Matching-on-DAGs.pdf},
	Location = {Trondheim, Norway},
	Pages = {493--504},
	Publisher = {VLDB Endowment},
	Title = {Stack-based Algorithms for Pattern Matching on DAGs},
	Year = {2005}}

@inproceedings{Chen2006RDFRDFS-based-Relational-Database-Integration,
	Abstract = {We study the problem of answering queries through a RDF/RDFS ontology, given a set of view-based mappings between one or more relational schemas and this target ontology. Particularly, we consider a set of RDFS semantic constraints such as rdfs:subClassof, rdfs:subPropertyof, rdfs:domain, and rdfs:range, which are present in RDF model but neither XML nor relational models. We formally define the query semantics in such an integration scenario, and design a novel query rewriting algorithm to implement the semantics. On our approach, we highlight the important role played by RDF Blank Node in representing incomplete semantics of relational data. A set of semantic tools supporting relational data integration by RDF are also introduced. The approach have been used to integrate 70 relational databases at China Academy of Traditional Chinese Medicine.},
	Address = {Washington, DC, USA},
	Author = {Chen, Huajun and Wu, Zhaohui and Wang, Heng and Mao, Yuxin},
	Booktitle = icde,
	Date-Added = {2007-09-24 14:21:23 +0200},
	Date-Modified = {2007-09-24 14:23:08 +0200},
	Doi = {http://dx.doi.org/10.1109/ICDE.2006.127},
	Isbn = {0-7695-2570-9},
	Keywords = {RDF, database, existential, blank nodes},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Chen2006RDFRDFS-based-Relational-Database-Integration.pdf},
	Pages = {94},
	Publisher = {IEEE Computer Society},
	Title = {RDF/RDFS-based Relational Database Integration},
	Year = {2006}}

@inproceedings{Cox1980A-Complete-Nonredundant-Algorithm-for-Reversed-Skolemization,
	Address = {London, UK},
	Author = {Cox, Philip T. and Pietrzykowski, Tomasz},
	Booktitle = cade,
	Date-Added = {2007-09-24 12:42:56 +0200},
	Date-Modified = {2007-09-24 12:43:24 +0200},
	Isbn = {3-540-10009-1},
	Pages = {374--385},
	Publisher = {Springer-Verlag},
	Title = {A Complete, Nonredundant Algorithm for Reversed Skolemization},
	Year = {1980}}

@article{McCune1988Un-skolemizing-clause-sets,
	Abstract = {This article addresses the following problem. Given a set S of clauses and a set of constant and function symbols F that occur in the clauses of S, obtain a fully quantified (closed) formula S' from S by replacing expressions starting with symbols in F with existentially quantified variables. S' must be unsatisfiable if and only if S is unsatisfiable. A sound (but not complete) solution is given in the form of an outline of an algorithm. },
	Address = {Amsterdam, The Netherlands, The Netherlands},
	Author = {McCune, William W.},
	Date-Added = {2007-09-24 12:40:38 +0200},
	Date-Modified = {2007-09-24 12:41:19 +0200},
	Issn = {0020-0190},
	Journal = ipl,
	Keywords = {skolemization, unskolemization, rdf, rdflog, existential},
	Number = {5},
	Pages = {257--263},
	Publisher = {Elsevier North-Holland, Inc.},
	Title = {Un-skolemizing clause sets},
	Volume = {29},
	Year = {1988}}

@inproceedings{Chadha1993Finding-Logical-Consequences-Using-Unskolemization,
	Abstract = {This paper presents a method for deriving logical consequences of first-order formulas based on resolution and a novel unskolemization algorithm. In general, it is not possible to derive certain logical consequences of a first-order formula by resolution without using tautologies or unskolemization. Therefore, if a formula H implies a formula W, we will not attempt to derive W from H; instead we derive a formula F such that H implies F and F implies W, and such that F is "close" to W. A measure of closeness is defined such that the number of formulas F "close" to any given formula W is finite A number of interesting applications are discussed, including a mehtod for mechanically generating loop invariants for program verification and a technique for learning characteristic descriptions of objects. },
	Address = {London, UK},
	Author = {Chadha, Ritu and Plaisted, David A.},
	Booktitle = {Proc. Int'l. Symposium on Methodologies for Intelligent Systems (ISMIS)},
	Date-Added = {2007-09-24 12:36:34 +0200},
	Date-Modified = {2007-09-24 12:37:28 +0200},
	Isbn = {3-540-56804-2},
	Keywords = {skolemization, unskolemization, rdflog, RDF, existential},
	Pages = {255--264},
	Publisher = {Springer-Verlag},
	Title = {Finding Logical Consequences Using Unskolemization},
	Year = {1993}}

@incollection{Baader1994Unification-theory,
	Address = {New York, NY, USA},
	Author = {Baader, Franz and Siekmann, J\"{o}rg H.},
	Booktitle = {Handbook of logic in artificial intelligence and logic programming},
	Date-Added = {2007-09-20 12:50:37 +0200},
	Date-Modified = {2007-09-20 12:51:52 +0200},
	Isbn = {0-19-853746-8},
	Keywords = {unification, algorithm, complexity, equality},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Baader1994Unification-theory.pdf},
	Pages = {41--125},
	Publisher = {Oxford University Press, Inc.},
	Title = {Unification theory},
	Year = {1994}}

@article{Martelli1982An-Efficient-Unification-Algorithm,
	Address = {New York, NY, USA},
	Author = {Martelli, Alberto and Montanari, Ugo},
	Date-Added = {2007-09-20 12:45:40 +0200},
	Date-Modified = {2007-09-20 12:50:25 +0200},
	Issn = {0164-0925},
	Journal = toplas,
	Keywords = {unification, logic, equality, complexity},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Martelli1982An-Efficient-Unification-Algorithm.pdf},
	Number = {2},
	Pages = {258--282},
	Publisher = {ACM Press},
	Title = {An Efficient Unification Algorithm},
	Volume = {4},
	Year = {1982}}

@inproceedings{Paterson1976Linear-unification,
	Abstract = {A unification algorithm is described which tests a set of expressions for unifiability and which requires time and space which are only linear in the size of the input.},
	Address = {New York, NY, USA},
	Author = {Paterson, M. S. and Wegman, M. N.},
	Booktitle = stoc,
	Date-Added = {2007-09-20 12:35:06 +0200},
	Date-Modified = {2007-09-20 12:36:41 +0200},
	Keywords = {unification, complexity, equality, graphs, directed acylic graphs},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Paterson1976Linear-unification.pdf},
	Location = {Hershey, Pennsylvania, United States},
	Pages = {181--186},
	Publisher = {ACM Press},
	Title = {Linear unification},
	Year = {1976}}

@inproceedings{Gottlob2006Bounded-Treewidth-as-a-Key-to-Tractability-of-Knowledge-Representation-and-Reasoning,
	Abstract = {Several forms of reasoning in AI -- like abduction, closed world reasoning, circumscription, and disjunctive logic programming -- are well known to be intractable. In fact, many of the relevant problems are on the second or third level of the polynomial hierarchy. In this paper, we show how the powerful notion of treewidth can be fruitfully applied to this area. In particular, we show that all these problems become tractable (actually, even solvable in linear time), if the treewidth of the involved formulae (or of the disjunctive logic programs, resp.) is bounded by some constant. Experiments with a prototype implementation prove the feasibility of this new approach, in principle, and also give us hints for necessary improvements. In many areas of computer science, bounded treewidth has been shown to be a realistic and practically relevant restriction. We thus argue that bounded treewidth is a key factor in the development of efficient algorithms also in knowledge representation and reasoning -- despite the high worst case complexity of the problems of interest.},
	Author = {Gottlob, Georg and Pichler, Reinhard and Wei, Fang},
	Booktitle = aaai,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {hypertree width, tractability, reasoning, datalog},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Gottlob2006Bounded-Treewidth-as-a-Key-to-Tractability-of-Knowledge-Representation-and-Reasoning.pdf},
	Title = {Bounded Treewidth as a Key to Tractability of Knowledge Representation and Reasoning},
	Year = {2006}}

@inproceedings{Gottlob2007Monadic-Datalog-over-Finite-Structures-with,
	Abstract = {Bounded treewidth and Monadic Second Order (MSO) logic have proved to be key concepts in establishing fixed-para-meter tractability results. Indeed, by Courcelle's Theorem we know: Any property of finite structures, which is expressible by an MSO sentence, can be decided in linear time (data complexity) if the structures have bounded treewidth.

In principle, Courcelle's Theorem can be applied directly to construct concrete algorithms by transforming the MSO evaluation problem into a tree language recognition problem. The latter can then be solved via a finite tree automaton (FTA). However, this approach has turned out to be problematical, since even relatively simple MSO formulae may lead to a "state explosion" of the FTA.

In this work we propose monadic datalog (i.e., data log where all intentional predicate symbols are unary) as an alternative method to tackle this class of fixed-parameter tractable problems. We show that if some property of finite structures is expressible in MSO then this property can also be expressed by means of a monadic datalog program over the structure plus the treedecomposition. Moreover, we show that the resulting fragment of datalogcan be evaluated in linear time (both w.r.t. the program size and w.r.t. the data size). This new approach is put to work by devising a new algorithm for the PRIMALITY problem (i.e., testing if some attribute in a relational schema is part of a key). We also report on experimental results with a prototype implementation.

},
	Address = {New York, NY, USA},
	Author = {Gottlob, Georg and Pichler, Reinhard and Wei, Fang},
	Booktitle = pods,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1265530.1265554},
	Isbn = {978-1-59593-685-1},
	Keywords = {hypertree decomposition,finite structures, monadic datalog, treewidth},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Gottlob2007Monadic-Datalog-over-Finite-Structures-with.pdf},
	Location = {Beijing, China},
	Pages = {165--174},
	Publisher = {ACM Press},
	Title = {Monadic Datalog over Finite Structures with Bounded Treewidth},
	Year = {2007}}

@inproceedings{Benedikt2007XPath-Leashed,
	Author = {Benedikt, Michael and Koch, Christoph},
	Booktitle = {ACM Computing Surveys},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XPath, formal, complexity,containment, survey,XML},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Benedikt2007XPath-Leashed.pdf},
	Title = {XPath Leashed},
	Year = {2007}}

@inproceedings{Asmann2007Modular-Web-QueriesFrom-Rules-to-Stores,
	Abstract = {Even with all the progress in Semantic technology, accessing Web 
data remains a challenging issue with new Web query languages and approaches 
appearing regularly. Yet most of these languages, including W3C approaches 
such as XQuery and SPARQL, do little to cope with the explosion of the data 
size and schemata diversity and richness on the Web. In this paper we propose 
a straightforward step toward the improvement of this situation that is simple to 
realize and yet effective: Advanced module systems that make partitioning of (a) 
the evaluation and (b) the conceptual design of complex Web queries possible. 
They provide the query programmer with a powerful, but easy to use high-level 
abstraction for packaging, encapsulating, and reusing conceptually related parts 
(in our case, rules) of a Web query. The proposed module system combines ease 
of use thanks to a simple core concept, the partitioning of rules and their con- 
sequences in flexible ``stores'', with ease of deployment thanks to a reduction 
semantics. We focus on extending the rule-based Semantic Web query language 
Xcerpt with such a module system though the same approach can be applied to 
other (rule-based) languages as well. 
},
	Author = {A{\ss}mann, Uwe and Berger, Sacha and Bry, Fran{\c c}ois and Furche, Tim and Henriksson, Jakob and Johannes, Jendrik},
	Booktitle = {Proc. Int'l. Workshop on Scalable Semantic Web Knowledge Base Systems (SSWS)},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-10-12 10:27:45 +0200},
	Keywords = {modules, logic programming, rule languages, Xcerpt},
	Title = {Modular Web Queries---From Rules to Stores},
	Url = {http://www.pms.ifi.lmu.de/publikationen/},
	Year = {2007}}

@techreport{Kay2007XSL-Transformations-Version-2.0,
	Abstract = {This specification defines the syntax and semantics of XSLT 2.0, a language for transforming XML documents into other XML documents.

XSLT 2.0 is a revised version of the XSLT 1.0 Recommendation [XSLT 1.0] published on 16 November 1999.

XSLT 2.0 is designed to be used in conjunction with XPath 2.0, which is defined in [XPath 2.0]. XSLT shares the same data model as XPath 2.0, which is defined in [Data Model], and it uses the library of functions and operators defined in [Functions and Operators].

XSLT 2.0 also includes optional facilities to serialize the results of a transformation, by means of an interface to the serialization component described in [XSLT and XQuery Serialization].},
	Author = {Kay, Michael},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {XSLT, query language, XML, transformation},
	Title = {{XSL Transformations, Version 2.0}},
	Type = {Recommendation},
	Year = {2007}}

@techreport{Giasson2007Music-Ontology-Specification,
	Abstract = {The Music Ontology Specification provides main concepts and properties fo describing music (i.e. artists, albums and tracks) on the Semantic Web. This document contains a detailed description of the Music Ontology.},
	Author = {Giasson, Fr{\'e}d{\'e}rick and Raimond, Yves},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {Zitgist LLC},
	Keywords = {music, ontology},
	Title = {Music Ontology Specification},
	Type = {Specification},
	Url = {http://purl.org/ontology/mo/},
	Year = {2007}}

@inproceedings{Asmann2007A-Generic-Module-System-for-Web-Rule-Languages,
	Abstract = {An essential feature in practically usable programming languages is 
the ability to encapsulate functionality in reusable modules. Modules make large 
scale projects tractable by humans. For Web and Semantic Web programming, 
many rule-based languages, e.g. XSLT, CSS, Xcerpt, SWRL, SPARQL, and RIF 
Core, have evolved or are currently evolving. Rules are easy to comprehend 
and specify, even for non-technical users, e.g. business managers, hence eas- 
ing the contributions to the Web. Unfortunately, those contributions are arguably 
doomed to exist in isolation as most rule languages are conceived without mod- 
ularity, hence without an easy mechanism for integration and reuse. In this paper 
a generic module system applicable to many rule languages is presented. We 
demonstrate and apply our generic module system to a Datalog-like rule lan- 
guage, close in spirit to RIF Core. The language is gently introduced along the 
EU-Rent use case. Using the Reuseware Composition Framework, the module 
system for a concrete language can be achieved almost for free, if it adheres to 
the formal notions introduced in this paper. },
	Author = {A{\ss}mann, Uwe and Berger, Sacha and Bry, Fran{\c c}ois and Furche, Tim and Henriksson, Jakob and Patranjan, Paula-Lavinia},
	Booktitle = {Proc. Int'l. RuleML Symp. on Rule Interchange and Applications},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {modules, logic programming, rule languages},
	Title = {A Generic Module System for Web Rule Languages: Divide and Rule},
	Url = {http://www.pms.ifi.lmu.de/publikationen/},
	Year = {2007}}

@inproceedings{Nakata2006Recursive-Modules-for-Programming,
	Address = {New York, NY, USA},
	Author = {Nakata, Keiko and Garrigue, Jacques},
	Booktitle = {Proc. ACM Int'l. Conf. on Functional programming (ICFP)},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1159803.1159813},
	Isbn = {1-59593-309-3},
	Keywords = {modules, functional programming, reuse},
	Location = {Portland, Oregon, USA},
	Pages = {74--86},
	Publisher = {ACM Press},
	Title = {Recursive Modules for Programming},
	Year = {2006}}

@inproceedings{Correl1995On-Isolation-Concurrency-and-the-Venus-Rule-Language,
	Address = {New York, NY, USA},
	Author = {Correl, Stephen and Miranker, Daniel P.},
	Booktitle = cikm,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/221270.221591},
	Isbn = {0-89791-812-6},
	Keywords = {modules, logic programming, active rules, reuse},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Correl1995On-Isolation-Concurrency-and-the-Venus-Rule-Language.pdf},
	Location = {Baltimore, Maryland, United States},
	Pages = {281--289},
	Publisher = {ACM Press},
	Title = {On Isolation, Concurrency, and the Venus Rule Language},
	Year = {1995}}

@article{Sannella1992A-Calculus-for-the-Construction-of-Modular-Prolog-Programs,
	Address = {New York, NY, USA},
	Author = {Sannella, D. T. and Wallen, L. A.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1016/0743-1066(92)90042-2},
	Issn = {0743-1066},
	Journal = jlp,
	Keywords = {modules, prolog, logic programming},
	Number = {1-2},
	Pages = {147--177},
	Publisher = {Elsevier Science Inc.},
	Title = {A Calculus for the Construction of Modular Prolog Programs},
	Volume = {12},
	Year = {1992}}

@article{Wirsing1986Structured-Algebraic-Specifications-A-Kernel-Language,
	Address = {Essex, UK},
	Author = {Wirsing, Martin},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Issn = {0304-3975},
	Journal = tcs,
	Keywords = {modules, algebraic specification,},
	Number = {2},
	Pages = {123--244},
	Publisher = {Elsevier Science Publishers Ltd.},
	Title = {Structured Algebraic Specifications: A Kernel Language},
	Volume = {42},
	Year = {1986}}

@incollection{Bowen1983Amalgamating-Language-and-Metalanguage-in-Logic-Programming,
	Author = {Bowen, K. A. and Kowalski, R. A.},
	Booktitle = {Logic Programming},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Editor = {Clark, K. and Tarnlund, S. A.},
	Keywords = {modules, logic programming, reuse},
	Publisher = {Academic Press, Inc.},
	Series = {Apic Studies in Data Processing},
	Title = {Amalgamating Language and Metalanguage in Logic Programming},
	Year = {1983}}

@inproceedings{Giurca2001An-Algebra-of-Logic-Programs-with-Applications-in-Distributed,
	Author = {Giurca, Adrian and Savulea, Dorel},
	Booktitle = {Annales of Craiova University},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {modules, logic programming, algebra},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Giurca2001An-Algebra-of-Logic-Programs-with-Applications-in-Distributed.pdf},
	Pages = {147--159},
	Series = {Mathematics and Computer Science Series},
	Title = {An Algebra of Logic Programs with Applications in Distributed Environments},
	Volume = {XXVIII},
	Year = {2001}}

@inproceedings{Miller1986A-Theory-of-Modules-for-Logic-Programming,
	Author = {Miller, Dale},
	Booktitle = {Proc. IEEE Symp. on Logic Programming},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {modules, logic programming, reuse, prolog},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Miller1986A-Theory-of-Modules-for-Logic-Programming.pdf},
	Pages = {106--114},
	Title = {A Theory of Modules for Logic Programming},
	Year = {1986}}

@article{Chirkova2002A-Formal-Perspective-on-the-View-Selection-Problem,
	Abstract = {The view selection problem is to choose a set of views to materialize over a database schema, such that the cost of evaluating a set of workload queries is minimized and such that the views fit into a prespecified storage constraint. The two main applications of the view selection problem are materializing views in a database to speed up query processing, and selecting views to materialize in a data warehouse to answer decision support queries. In addition, view selection is a core problem for intelligent data placement over a wide-area network for data integration applications and data management for ubiquitous computing. We describe several fundamental results concerning the view selection problem. We consider the problem for views and workloads that consist of equality-selection, project and join queries, and show that the complexity of the problem depends crucially on the quality of the estimates that a query optimizer has on the size of the views it is considering to materialize. When a query optimizer has good estimates of the sizes of the views, we show a somewhat surprising result, namely, that an optimal choice of views may involve a number of views that is exponential in the size of the database schema. On the other hand, when an optimizer uses standard estimation heuristics, we show that the number of necessary views and the expression size of each view are polynomially bounded.

},
	Address = {Secaucus, NJ, USA},
	Author = {Chirkova, Rada and Halevy, Alon Y. and Suciu, Dan},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Issn = {1066-8888},
	Journal = vldbj,
	Keywords = {view, materialization, formal},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/20110216.pdf},
	Number = {3},
	Pages = {216--237},
	Publisher = {Springer-Verlag New York, Inc.},
	Title = {A Formal Perspective on the View Selection Problem},
	Volume = {11},
	Year = {2002}}

@article{Baralis1996Modularization-techniques-for-active-rules-design,
	Abstract = {Active database systems can be used to establish and enforce data management policies. A large amount of the semantics that normally needs to be coded in application programs can be abstracted and assigned to active rules. This trend is sometimes called ``knowledge independence'' a nice consequence of achieving full knowledge independence is that data management policies can then effectively evolve just by modifying rules instead of application programs. Active rules, however, may be quite complex to understand and manage: rules react to arbitrary event sequences, they trigger each other, and sometimes the outcome of rule processing may depend on the order in which events occur or rules are scheduled. Although reasoning on a large collection of rules is very difficult, the task becomes more manageable when the rules are few. Therefore, we are convinced that modularization, similar to what happens in any software development process, is the key principle for designing active rules; however, this important notion has not been addressed so far. This article introduces a modularization technique for active rules called stratification; it presents a theory of stratification and indicates how stratification can be practically applied. The emphasis of this article is on providing a solution to a very concrete and practical problem; therefore, our approach is illustrated by several examples.},
	Address = {New York, NY, USA},
	Author = {Baralis, Elena and Ceri, Stefano and Paraboschi, Stefano},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/227604.227605},
	Issn = {0362-5915},
	Journal = tods,
	Keywords = {modules, logic programming},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Baralis1996Modularization-techniques-for-active-rules-design.pdf},
	Number = {1},
	Pages = {1--29},
	Publisher = {ACM Press},
	Title = {Modularization Techniques for Active Rules Design},
	Volume = {21},
	Year = {1996}}

@inproceedings{Codish1993Compositional-analysis-of-modular-logic-programs,
	Abstract = {This paper describes a semantic basis for a compositional approach to the analysis of logic programs. A logic program is viewed as consisting of a set of modules, each module defining a subset of the program's predicates. Analyses are constructed by considering abstract interpretations of a compositional semantics. The abstract meaning of a module corresponds to its analysis and composition of abstract meanings corresponds to composition of analyses. Such an approach is essential for large program development so that altering one module does not require re-analysis of the entire program. We claim that for a substantial class of programs, compositional analyses which are based on a notion of abstract unfolding provide the same precision as non-compositional analysis. A compositional analysis for ground dependencies is included to illustrate the approach. To the best of our knowledge this is the first account of a compositional framework for the analysis of logic programs.},
	Address = {New York, NY, USA},
	Author = {Codish, Michael and Debray, Saumya K. and Giacobazzi, Roberto},
	Booktitle = popl,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/158511.158703},
	Isbn = {0-89791-560-7},
	Keywords = {modules, logic programming},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Codish1993Compositional-analysis-of-modular-logic-programs.pdf},
	Location = {Charleston, South Carolina, United States},
	Pages = {451--464},
	Publisher = {ACM Press},
	Title = {Compositional analysis of modular logic programs},
	Year = {1993}}

@article{Duran2000Maudes-Module-Algebra,
	Author = {Dur{\'a}n, F. and Meseguer, J.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {?},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Duran2000Maudes-Module-Algebra.pdf},
	Note = {submitted for publication},
	Number = {?},
	Pages = {?-?},
	Title = {{Maude's} Module Algebra},
	Volume = {?},
	Year = {2000}}

@article{Bergstra1990Module-algebra,
	Abstract = {An axiomatic algebraic calculus of modules is given that is based on the operators combination/union, export, renaming, and taking the visible signature. Four different models of module algebra are discussed and compared.},
	Address = {New York, NY, USA},
	Author = {Bergstra, J. A. and Heering, J. and Klint, P.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/77600.77621},
	Issn = {0004-5411},
	Journal = jacm,
	Keywords = {modules, logic programming},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Bergstra1990Module-algebra.pdf},
	Number = {2},
	Pages = {335--372},
	Publisher = {ACM Press},
	Title = {Module algebra},
	Volume = {37},
	Year = {1990}}

@article{Miller1989A-logical-analysis-of-modules-in-logic-programming,
	Address = {New York, NY, USA},
	Author = {Miller, Dale},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1016/0743-1066(89)90031-9},
	Issn = {0743-1066},
	Journal = jlp,
	Keywords = {modules, logic programming,},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Miller1989A-logical-analysis-of-modules-in-logic-programming.pdf},
	Number = {1-2},
	Pages = {79--108},
	Publisher = {Elsevier Science Inc.},
	Title = {A logical analysis of modules in logic programming},
	Volume = {6},
	Year = {1989}}

@article{Brogi1994Modular-logic-programming,
	Abstract = {Modularity is a key issue in the design of modern programming languages. When designing modular features for declarative languages in general, and for logic programming languages in particular, the challenge lies in avoiding the superimposition of a complex syntactic and semantic structure over the simple structure of the basic language. The modular framework defined here for logic programming consists of a small number of operations over modules which are (meta-) logically defined and semantically justified in terms of the basic logic programming semantics. The operations enjoy a number of algebraic properties, thus yielding an algebra of modules. Despite its simplicity, the suite of operations is shown capable of capturing the core features of modularization: information hiding, import/export relationships, and construction of module hierarchies. A metalevel implementation and a compilation-oriented implementation of the operations are provided and proved sound with respect to the semantics. The compilation-oriented implementation is based on manipulation of name spaces and provides the basis for an efficient implementation.},
	Address = {New York, NY, USA},
	Author = {Brogi, Antonio and Mancarella, Paolo and Pedreschi, Dino and Turini, Franco},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/183432.183528},
	Issn = {0164-0925},
	Journal = {ACM Trans. Program. Lang. Syst.},
	Keywords = {modules, rules, logic programming},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Brogi1994Modular-logic-programming.pdf},
	Number = {4},
	Pages = {1361--1398},
	Publisher = {ACM Press},
	Title = {Modular logic programming},
	Volume = {16},
	Year = {1994}}

@inproceedings{Karali1993A-versatile-module-system-for-Prolog,
	Address = {New York, NY, USA},
	Author = {Karali, Isambo and Pelecanos, Evangelos and Halatsis, Constantin},
	Booktitle = sac,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/162754.168687},
	Isbn = {0-89791-567-4},
	Keywords = {modules, rules, prolog, logic programming},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Karali1993A-versatile-module-system-for-Prolog.pdf},
	Location = {Indianapolis, Indiana, United States},
	Pages = {578--585},
	Publisher = {ACM Press},
	Title = {A Versatile Module system for Prolog Mapped to Flat Prolog},
	Year = {1993}}

@inproceedings{Benedikt2006Interpreting-Tree-to-Tree-Queries,
	Author = {Benedikt, Michael and Koch, Christoph},
	Booktitle = icalp,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {xquery, semantics, xpath, evaluation, complexity},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Benedikt2006Interpreting-Tree-to-Tree-Queries.pdf},
	Pages = {552-564},
	Title = {Interpreting Tree-to-Tree Queries},
	Year = {2006}}

@incollection{Bry2007Querying-the-Web-Reconsidered,
	Abstract = {A decade of experience with research proposals as well as standardized
	 query languages for the conventional Web and the recent emergence of
	 query languages for the Semantic Web call for a reconsideration of
	 design principles for Web and Semantic Web query languages. This
	 article first argues that a new generation of versatile Web query
	 languages is needed for solving the challenges posed by the changing
	 Web: We call versatile those query languages able to cope with both
	 Web and Semantic Web data expressed in any (Web or Semantic Web)
	 markup language. This article further suggests that (well-known)
	 referential transparency and (novel) answer-closedness are essential
	 features of versatile query languages. Indeed, they allow queries to be
	 considered like forms and answers like form-fillings in the spirit of the
	 ?query-by-example? paradigm. This article finally suggests that the
	 decentralized and heterogeneous nature of the Web requires incomplete
	 data specifications (or ?incomplete queries?) and incomplete data
	 selections (or ?incomplete answers?): the form-like query can be
	 specified without precise knowledge of the queried data and answers
	 can be restricted to contain only an excerpt of the queried data.},
	Author = {Bry, Fran{\c c}ois and Furche, Tim and Badea, Liviu and Koch, Christoph and Schaffert, Sebastian and Berger, Sacha},
	Booktitle = {Semantic Web-Based Information Systems: State-of-the-Art Applications},
	Chapter = {8},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Editor = {Sheth, Amit and Lytras, Miltiadis D.},
	Keywords = {Semantic Web, versatility, Xcerpt, vision, design principles},
	Publisher = {CyberTech Publishing},
	Title = {{Querying the Web Reconsidered: Design Principles for Versatile Web Query Languages}},
	Year = {2007}}

@incollection{Berger2006The-Web-and-Semantic-Web-Query-Language-Xcerpt,
	Author = {Berger, Sacha and Bry, Fran\c{c}ois and Furche, Tim and Linse, Benedikt and Schaffert, Sebastian},
	Booktitle = {AIS SIGSEMIS and OSR Semantic Web Fact Book 2005},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Title = {{The Web and Semantic Web Query Language Xcerpt}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2006-16},
	Year = {2006}}

@inproceedings{PMS-FB-2006-15,
	Author = {Bry, Fran\c{c}ois and Furche, Tim and Linse, Benedikt},
	Booktitle = {Proc. of Workshop on Information Integration on the Web},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {Xcerpt, integration, versatility},
	Title = {{Let's Mix It: Versatile Access to Web Data in Xcerpt}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2006-15},
	Year = {2006}}

@inproceedings{PMS-FB-2006-14,
	Abstract = {Access to Web data has become an integral part of many applications and services. In the past, such data has usually been accessed through human-tailored HTML interfaces. Nowadays, rich client interfaces in desktop applications or, increasingly, in browser-based clients ease data access and allow more complex client processing based on XML or RDF data retrieved through Web service interfaces. Convenient specifications of the data processing on the client and flexible, expressive service interfaces for data access become essential in this context. Web query languages such as XQuery, XSLT, SPARQL, or Xcerpt have been tailored specifically for such a setting: declarative and efficient access and processing of Web data. This tutorial introduces, compares, and classifies the most relevant exemplars of Web query languages for XML, RDF, and/or TopicMaps data. Interesting features as well as differences in expressiveness and adequacy are digested along practical and concrete use cases. Emphasis is placed on recent W3C standardization activities, contrasted with alternative approaches from industry and academia.},
	Author = {Bailey, James and Bry, Fran\c{c}ois and Furche, Tim and Linse, Benedikt and P\u{a}tr\^anjan, Paula-Lavinia and Schaffert, Sebastian},
	Booktitle = {Proc. of German XML-Tage},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Howpublished = {Tutorial},
	Title = {{Rich Clients need Rich Interfaces: Query Languages for XML and RDF Access on the Web}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2006-14},
	Year = {2006}}

@inproceedings{PMS-FB-2005-16,
	Author = {Berger, Sacha and Bry, Fran\c{c}ois and Bolzer, Oliver and Furche, Tim and Schaffert, Sebastian and Wieser, Christoph},
	Booktitle = eswc,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Howpublished = {Demonstration},
	Keywords = {Xcerpt, visXcerpt, demonstration},
	Title = {{Querying the Standard and Semantic Web using Xcerpt and visXcerpt}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2005-16},
	Year = {2005}}

@incollection{Bry2007Foundations-of-Rule-Based-Query-Answering,
	Abstract = {A number of techniques have been developed to
	 facilitate powerful data retrieval on the Web and Semantic Web. Three
	 categories of Web query languages can be distinguished, according to
	 the format of the data they can retrieve: XML, RDF and Topic Maps.
	 This article introduces the spectrum of languages falling into these
	 categories and summarises their salient aspects. The languages are
	 introduced using common sample data and query types. Key aspects
	 of the query languages considered are stressed in a conclusion. },
	Author = {Bry, Fran{\c c}ois and Eisinger, Norbert and Eiter, Thomas and Furche, Tim and Gottlob, Georg and Ley, Clemens and Linse, Benedikt and Pichler, Reinhard and Wei, Fang},
	Booktitle = rw,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Editor = {Antoniou, Grigoris and A{\ss}mann, Uwe and Baroglio, Cristina and Decker, Stefan and Henze, Nicola and P{\u a}tr{\^a}njan, Paula-Lavinia and Tolksdorf, Robert},
	Keywords = {logic, query languages, complexity, semantics, evaluation, optimization},
	Number = {3564},
	Publisher = springer,
	Series = lncs,
	Title = {{Foundations of Rule-Based Query Answering}},
	Year = {2007}}

@inproceedings{Berger2006Beyond-XML-and-RDF,
	Author = {Berger, Sacha and Bry, Fran\c{c}ois and Furche, Tim and Linse, Benedikt and Schroeder, Andreas},
	Booktitle = WWW,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Howpublished = {Demonstration},
	Keywords = {Xcerpt, visXcerpt, versatility},
	Pages = {1053-1054},
	Title = {{Beyond XML and RDF: The Versatile Web Query Language Xcerpt}},
	Year = {2006}}

@inproceedings{Furche2006RDF-Querying,
	Author = {Furche, Tim and Linse, Benedikt and Bry, Fran\c{c}ois and Plexousakis, Dimitris and Gottlob, Georg},
	Booktitle = rw,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {querying, RDF, tutorial, lecture, constructs, optional},
	Pages = {1-52},
	Publisher = springer,
	Series = lncs,
	Title = {{RDF Querying: Language Constructs and Evaluation Methods Compared}},
	Volume = {4126},
	Year = {2006}}

@inproceedings{Bry-Hauser2006Data-Model-and-Query-Constructs-for-Versatile-Web,
	Author = {Bry-Hau{\ss}er, Fran\c{c}ois and Furche, Tim and Linse, Benedikt},
	Booktitle = ppswr,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {Xcerpt, RDF, constructs, versatility},
	Pages = {90-104},
	Title = {{Data Model and Query Constructs for Versatile Web Query Languages: State-of-the-Art and Challenges for Xcerpt}},
	Year = {2006}}

@inproceedings{Berger2006Effective-and-Efficient-Data-Access,
	Author = {Berger, Sacha and Bry-Hau{\ss}er, Fran\c{c}ois and Furche, Tim and Linse, Benedikt and Schroeder, Andreas},
	Booktitle = ppswr,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Howpublished = {Demonstration},
	Keywords = {Xcerpt, visXcerpt, demonstration},
	Pages = {219-224},
	Title = {{Effective and Efficient Data Access in the Versatile Web Query Language Xcerpt}},
	Year = {2006}}

@incollection{Royer2006Querying-the-Semantic-Web,
	Author = {Royer, Lo{\"\i}c and Linse, Benedikt and W\"achter, Thomas and Furche, Tim and Bry, Fran\c{c}ois and Schroeder, Michael},
	Booktitle = {Revolutionizing Knowledge Discovery in the Life Sciences},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {Xcerpt, bioinformatics, semantic web, querying, prova},
	Publisher = springer,
	Title = {{Querying the Semantic Web: A Case Study}},
	Year = {2006}}

@inproceedings{Bry2006AMachoS,
	Author = {Bry, Fran\c{c}ois and Furche, Tim and Linse, Benedikt},
	Booktitle = ppswr,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {Xcerpt, Amachos, Algebra, Abstract Machine},
	Pages = {105-119},
	Title = {{AMachoS - Abstract Machine for Xcerpt: Architecture and Principles}},
	Year = {2006}}

@inproceedings{Berger2006Xcerpt-and-visXcerpt,
	Author = {Berger, Sacha and Bry, Fran\c{c}ois and Furche, Tim},
	Booktitle = planx,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Howpublished = {Demonstration},
	Keywords = {Xcerpt, visXcerpt, demonstration},
	Pages = {84},
	Title = {{Xcerpt and visXcerpt: Integrating Web Querying}},
	Year = {2006}}

@inproceedings{Berger2006Vorfuhrung-von-Xcerpt-und-visXcerpt,
	Author = {Berger, Sacha and Bry, Fran\c{c}ois and Furche, Tim and Linse, Benedikt and Schroeder, Andreas},
	Booktitle = {Proc. GI-Workshop on Grundlagen von Datenbanken},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Howpublished = {Demonstration},
	Keywords = {Xcerpt, visXcerpt, demo},
	Pages = {12},
	Title = {{Vorf{\"u}hrung von Xcerpt und visXcerpt, Anfragesprachen f{\"u}r das Web}},
	Year = {2006}}

@inproceedings{Bry2007GRDDLing-with-Xcerpt,
	Author = {Bry, Fran{\c c}ois and Furche, Tim and Hang, Alina and Linse, Benedikt},
	Booktitle = eswc,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Howpublished = {Demonstration},
	Keywords = {demo, Xcerpt, GRDDL, RDF, versatility},
	Title = {{GRDDLing with Xcerpt: Learn one, get one free!}},
	Year = {2007}}

@inproceedings{Antova2007From-Complete-to-Incomplete-Information-and-Back,
	Author = {Antova, Lyublena and Koch, Christoph and Olteanu, Dan},
	Booktitle = sigmod,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {incomplete information, wordset decomposition, null values, b-nodes},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Antova2007From-Complete-to-Incomplete-Information-and-Back.pdf},
	Title = {From Complete to Incomplete Information and Back},
	Year = {2007}}

@article{Paredaens1992Converting-Nested-Algebra-Expressions-into-Flat,
	Abstract = {Nested relations generalize ordinary flat relations by allowing tuple values to be either atomic or set valued. The nested algebra is a generalization of the flat relational algebra to manipulate nested relations. In this paper we study the expressive power of the nested algebra relative to its operation on flat relational databases. We show that the flat relational algebra is rich enough to extract the same ``flat information'' from a flat database as the nested algebra does. Theoretically, this result implies that recursive queries such as the transitive closure of a binary relation cannot be expressed in the nested algebra. Practically, this result is relevant to (flat) relational query optimization.},
	Address = {New York, NY, USA},
	Author = {Paredaens, Jan and Gucht, Dirk Van},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/128765.128768},
	Issn = {0362-5915},
	Journal = tods,
	Keywords = {nested relational algebra, complex values, algebra},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Paredaens1992Converting-Nested-Algebra-Expressions-into-Flat.pdf},
	Number = {1},
	Pages = {65--93},
	Publisher = {ACM Press},
	Title = {Converting Nested Algebra Expressions into Flat Algebra Expressions},
	Volume = {17},
	Year = {1992}}

@inproceedings{Bultzingsloewen1987Translating-and-Optimizing-SQL,
	Address = {San Francisco, CA, USA},
	Author = {von B{\"u}ltzingsloewen, G{\"u}nter},
	Booktitle = vldb,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {0-934613-46-X},
	Keywords = {aggregates, null values, SQL, order},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Bultzingsloewen1987Translating-and-Optimizing-SQL.pdf},
	Pages = {235--243},
	Publisher = {Morgan Kaufmann Publishers Inc.},
	Title = {Translating and Optimizing SQL Queries Having Aggregates},
	Year = {1987}}

@article{Ceri1985Translating-SQL-into-Relational-Algebra,
	Address = {Piscataway, NJ, USA},
	Author = {Ceri, Stefano and Gottlob, Georg},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Issn = {0098-5589},
	Journal = tse,
	Keywords = {SQL, relational algebra, semantics, optimization, sequence, order},
	Number = {4},
	Pages = {324--345},
	Publisher = {IEEE Press},
	Title = {Translating SQL into Relational Algebra: Optimization, Semantics, and Equivalence of SQL Queries},
	Volume = {11},
	Year = {1985}}

@inproceedings{Brown1999Implementing-the-Spirit-of-SQL-99,
	Abstract = {This paper describes the current INFORMIX IDS/UD release (9.2 or Centaur) and compares and contrasts its functionality with the features of the SQL-99 language standard. INFORMIX and Illustra have been shipping DBMSs implementing the spirit of the SQL-99 standard for five years. In this paper, we review our experience working with ORDBMS technology, and argue that while SQL-99 is a huge improvement over SQL-92, substantial further work is necessary to make object-relational DBMSs truly useful. Specifically, we describe several interesting pieces of functionality unique to IDS/UD, and several dilemmas our customers have encountered that the standard does not address.},
	Address = {New York, NY, USA},
	Author = {Brown, Paul},
	Booktitle = sigmod,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/304182.304236},
	Isbn = {1-58113-084-8},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Brown1999Implementing-the-Spirit-of-SQL-99.pdf},
	Location = {Philadelphia, Pennsylvania, United States},
	Pages = {515--518},
	Publisher = {ACM Press},
	Title = {{Implementing the Spirit of SQL-99}},
	Year = {1999}}

@article{Negri1991Formal-Semantics-of-SQL-Queries,
	Abstract = {The semantics of SQL queries is formally defined by stating a set of rules that determine a syntax-driven translation of an SQL query to a formal model. The target model, called Extended Three Valued Predicate Calculus (E3VPC), is largely based on a set of well-known mathematical concepts. The rules which allow the transformation of a general E3VPC expression to a Canonical Form, which can be manipulated using traditional, two-valued predicate calculus are also given; in this way, problems like equivalence analysis of SQL queries are completely solved. Finally, the fact that reasoning about the equivalence of SQL queries using two-valued predicate calculus, without taking care of the real SQL semantics can lead to errors is shown, and the reasons for this are analyzed.},
	Address = {New York, NY, USA},
	Author = {Negri, M. and Pelagatti, G. and Sbattella, L.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/111197.111212},
	Issn = {0362-5915},
	Journal = tods,
	Keywords = {SQL, formal semantics, algebra, order},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Negri1991Formal-Semantics-of-SQL-Queries.pdf},
	Number = {3},
	Pages = {513--534},
	Publisher = {ACM Press},
	Title = {{Formal Semantics of SQL Queries}},
	Volume = {16},
	Year = {1991}}

@inproceedings{Paparizos2005Pattern-Tree-Algebras,
	Abstract = {XML and XQuery semantics are very sensitive to the order of the produced output. Although pattern-tree based algebraic approaches are becoming more and more popular for evaluating XML, there is no universally accepted technique which can guarantee both a correct output order and a choice of efficient alternative plans.We address the problem using hybrid collections of trees that can be either sets or sequences or something in between. Each such collection is coupled with an Ordering Specification that describes how the trees are sorted (full, partial or no order). This provides us with a formal basis for developing a query plan having parts that maintain no order and parts with partial or full order.It turns out that duplicate elimination introduces some of the same issues as order maintenance: it is expensive and a single collection type does not always provide all the flexibility required to optimize this properly. To solve this problem we associate with each hybrid collection a Duplicate Specification that describes the presence or absence of duplicate elements in it. We show how to extend an existing bulk tree algebra, TLC [12], to use Ordering and Duplicate specifications and produce correctly ordered results. We also suggest some optimizations enabled by the flexibility of our approach, and experimentally demonstrate the performance increase due to them.},
	Author = {Paparizos, Stelios and Jagadish, H. V.},
	Booktitle = vldb,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {1-59593-154-6},
	Keywords = {XML, algebra, order, identity, pattern matching, query optimization},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Paparizos2005Pattern-Tree-Algebras.pdf},
	Location = {Trondheim, Norway},
	Pages = {349--360},
	Publisher = {VLDB Endowment},
	Title = {{Pattern Tree Algebras: Sets or Sequences?}},
	Url = {http://portal.acm.org/citation.cfm?id=1083635},
	Year = {2005}}

@article{Graefe1993Query-Evaluation-Techniques-Large-Databases,
	Abstract = {Database management systems will continue to manage large data volumes. Thus, efficient algorithms for accessing and manipulating large sets and sequences will be required to provide acceptable performance. The advent of object-oriented and extensible database systems will not solve this problem. On the contrary, modern data models exacerbate the problem: In order to manipulate large sets of complex objects as efficiently as today's database systems manipulate simple records, query-processing algorithms and software will become more complex, and a solid understanding of algorithm and architectural issues is essential for the designer of database management software. This survey provides a foundation for the design and implementation of query execution facilities in new database management systems. It describes a wide array of practical query evaluation techniques for both relational and postrelational database systems, including iterative execution of complex query evaluation plans, the duality of sort- and hash-based set-matching algorithms, types of parallel query execution and their implementation, and special operators for emerging database application domains.},
	Address = {New York, NY, USA},
	Author = {Graefe, Goetz},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/152610.152611},
	Issn = {0360-0300},
	Journal = csur,
	Keywords = {query evaluation, query optimization, survey, RDBMS, relational algebra},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Graefe1993Query-Evaluation-Techniques-Large-Databases.pdf},
	Number = {2},
	Pages = {73--169},
	Publisher = {ACM Press},
	Rating = {0},
	Read = {No},
	Title = {Query Evaluation Techniques for Large Databases},
	Volume = {25},
	Year = {1993}}

@article{Dawar1995Infinitary-Logic-and-Inductive-Definability-over-Finite,
	Abstract = {The extensions of first-order logic with a least fixed point operator (FO + LFP) and with a partial fixed point operator (FO + PFP) are known to capture the complexity classes P and PSPACE respectively in the presence of an ordering relation over finite structures. Recently, Abiteboul and Vianu [Abiteboul and Vianu, 1991b] investigated the relationship of these two logics in the absence of an ordering, using a machine model of generic computation. In particular, they showed that the two...},
	Address = {Duluth, MN, USA},
	Author = {Dawar, Anuj and Lindell, Steven and Weinstein, Scott},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1006/inco.1995.1084},
	Issn = {0890-5401},
	Journal = iandc,
	Keywords = {infinitary logic, while, fixpoint},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Dawar1995Infinitary-Logic-and-Inductive-Definability-over-Finite.pdf},
	Number = {2},
	Pages = {160--175},
	Publisher = {Academic Press, Inc.},
	Title = {Infinitary Logic and Inductive Definability over Finite Structures},
	Volume = {119},
	Year = {1995}}

@article{Abiteboul1997Fixpoint-Logics-Relational-Machines-and-Computational-Complexity,
	Abstract = {We establish a general connection between fixpoint logic and complexity. On one side, we have fixpoint logic, parameterized by the choices of 1st-order operators (inflationary or noninflationary) and iteration constructs (deterministic, nondeterministic, or alternating). On the other side, we have the complexity classes between P and EXPTIME. Our parameterized fixpoint logics capture the complexity classes P, NP, PSPACE, and EXPTIME, but equally is achieved only over ordered structures. There is, however, an inherent mismatch between complexity and logic---while computational devices work on encodings of problems, logic is applied directly to the underlying mathematical structures. To overcome this mismatch, we use a theory of relational complexity, which bridges the gap between standard complexity and fixpoint logic. On one hand, we show that questions about containments among standard complexity classes can be translated to questions about containments among relational complexity classes. On the other hand, the expressive power of fixpoint logic can be precisely characterized in terms of relational complexity classes. This tight, three-way relationship among fixpoint logics, relational complexity and standard complexity yields in a uniform way logical analogs to all containments among the complexity classes P, NP, PSPACE, and EXPTIME. The logical formulation shows that some of the most tantalizing questions in complexity theory boil down to a single question: the relative power of inflationary vs. noninflationary 1st-order operators.},
	Address = {New York, NY, USA},
	Author = {Abiteboul, Serge and Vardi, Moshe Y. and Vianu, Victor},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/256292.256295},
	Issn = {0004-5411},
	Journal = jacm,
	Keywords = {infinitary logic, fixpoint logics, relational machines, complexity, recursion},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Abiteboul1997Fixpoint-Logics-Relational-Machines-and-Computational-Complexity.pdf},
	Number = {1},
	Pages = {30--56},
	Publisher = {ACM Press},
	Title = {Fixpoint Logics, Relational Machines, and Computational Complexity},
	Volume = {44},
	Year = {1997}}

@article{Hella2001Logics-with-Aggregate-Operators,
	Abstract = {We study adding aggregate operators, such as summing up elements of a column of a relation, to logics with counting mechanisms. The primary motivation comes from database applications, where aggregate operators are present in all real life query languages. Unlike other features of query languages, aggregates are not adequately captured by the existing logical formalisms. Consequently, all previous approaches to analyzing the expressive power of aggregation were only capable of producing partial results, depending on the allowed class of aggregate and arithmetic operations.We consider a powerful counting logic, and extend it with the set of all aggregate operators. We show that the resulting logic satisfies analogs of Hanf's and Gaifman's theorems, meaning that it can only express local properties. We consider a database query language that expresses all the standard aggregates found in commercial query languages, and show how it can be translated into the aggregate logic, thereby providing a number of expressivity bounds, that do not depend on a particular class of arithmetic functions, and that subsume all those previously known. We consider a restricted aggregate logic that gives us a tighter capture of database languages, and also use it to show that some questions on expressivity of aggregation cannot be answered without resolving some deep problems in complexity theory.},
	Address = {New York, NY, USA},
	Author = {Hella, Lauri and Libkin, Leonid and Nurmonen, Juha and Wong, Limsoon},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/502090.502100},
	Issn = {0004-5411},
	Journal = jacm,
	Keywords = {infinitary logic, aggregation, counting},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Hella2001Logics-with-Aggregate-Operators.pdf},
	Number = {4},
	Pages = {880--907},
	Publisher = {ACM Press},
	Title = {Logics with Aggregate Operators},
	Volume = {48},
	Year = {2001}}

@article{Libkin2000Logics-with-Counting-and-Local-Properties,
	Abstract = {The expressive power of first-order logic over finite structures is limited in two ways: it lacks a recursion mechanism, and it cannot count. Overcoming the first limitation has been a subject of extensive study. A number of fixpoint logics have been introduced. and shown to be subsumed by an infinitary logic Lwinfw. This logic is easier to analyze than fixpoint logics, and it still lacks counting power, as it has a 0-1 law. On the counting side, there is no analog of Lwinfw . There are a number of logics with counting power, usually introduced via generalized quantifiers. Most known expressivityy bounds are based on the fact that counting extensions of first-order logic preserve the locality properties. This article has three main goals. First, we introduce a new logic L*infw (C) that plays the same role for counting asLwinfw does for recursion---it subsumes a number of extensions of first-order logic with counting, and has nice properties that make it easy to study. Second, we give simple direct proof thatLwinfw (C) expresses only local properties: those that depend on the properties of small neighborhoods, but cannot grasp a structure as a whole. This is a general way of saying that a logic lacks a recursion mechanism. Third, we consider a finer analysis of locality of counting logics. In particular, we address the question of how local a logic is, that is, how big are those neighborhoods that local properties depend on. We get a uniform answer for a variety of logics between first-order and L*infw (C). This is done by introducing a new form of locality that captures the tightest condition that the duplicator needs to maintain in order to win a game. We also use this technique to give bounds on outputs of L*infw (C)-definable queries.},
	Address = {New York, NY, USA},
	Author = {Libkin, Leonid},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/343369.343376},
	Issn = {1529-3785},
	Journal = tocl,
	Keywords = {fixpoint, while, infinitary logic, counting, local property},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Libkin2000Logics-with-Counting-and-Local-Properties.pdf},
	Number = {1},
	Pages = {33--59},
	Publisher = {ACM Press},
	Title = {Logics with Counting and Local Properties},
	Volume = {1},
	Year = {2000}}

@article{Abiteboul1995Computing-with-Infinitary-Logic,
	Abstract = {Most recursive extensions of relational calculus converge around two central classes of queries: fixpoint and while. Infinitary logic (with finitely many variables) is a very powerful extension of these languages which provides an elegant unifying formalism for a wide variety of query languages. However, neither the syntax nor the semantics of infinitary logic are effective, and its connection to practical query languages has been largely unexplored. We relate infinitary logic to another...},
	Address = {Essex, UK},
	Author = {Abiteboul, Serge and Vardi, Moshe Y. and Vianu, Victor},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1016/0304-3975(95)00027-T},
	Issn = {0304-3975},
	Journal = tcs,
	Keywords = {infinitary logic, query languages, fixpoint, while},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Abiteboul1995Computing-with-Infinitary-Logic.pdf},
	Number = {1},
	Pages = {101--128},
	Publisher = {Elsevier Science Publishers Ltd.},
	Title = {Computing with Infinitary Logic},
	Volume = {149},
	Year = {1995}}

@inproceedings{Bry1989Quantifier-Disjunction-Processing,
	Abstract = {Database applications often require to evaluate queries containing quantifiers or disjunctions, e.g., for handling general integrity constraints. Existing efficient methods for processing quantifiers depart from the relational model as they rely on non-algebraic procedures. Looking at quantified query evaluation from a new angle, we propose an approach to process quantifiers that makes use of relational algebra operators only. Our approach performs in two phases. The first phase normalizes the queries producing a canonical form. This form permits to improve the translation into relational algebra performed during the second phase. The improved translation relies on a new operator - the complement-join - that generalizes the set difference, on algebraic expressions of universal quantifiers that avoid the expensive division operator in many cases, and on a special processing of disjunctions by means of constrained outer-joins. Our method achieves an efficiency at least comparable with that of previous proposals, better in most cases. Furthermore, it is considerably simpler to implement as it completely relies on relational data structures and operators.},
	Address = {New York, NY, USA},
	Author = {Bry, Francois},
	Booktitle = sigmod,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/67544.66944},
	Isbn = {0-89791-317-5},
	Keywords = {quantification, semi-joins, algebra, complement-join, difference},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Bry1989Quantifier-Disjunction-Processing.pdf},
	Location = {Portland, Oregon, United States},
	Pages = {193--204},
	Publisher = {ACM Press},
	Title = {Towards an Efficient Evaluation of General Queries: Quantifier and Disjunction Processing Revisited},
	Year = {1989}}

@article{Abiteboul1991Datalog-Extensions-for-Database-Queries-and-Updates,
	Address = {Orlando, FL, USA},
	Author = {Abiteboul, Serge and Vianu, Victor},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1016/0022-0000(91)90032-Z},
	Issn = {0022-0000},
	Journal = jcss,
	Keywords = {value invention, datalog, updates, identity},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Abiteboul1991Datalog-Extensions-for-Database-Queries-and-Updates.pdf},
	Number = {1},
	Pages = {62--124},
	Publisher = {Academic Press, Inc.},
	Title = {Datalog Extensions for Database Queries and Updates},
	Volume = {43},
	Year = {1991}}

@inproceedings{Perez2006Semantics-and-Complexity-of-SPARQL,
	Abstract = {SPARQL is the W3C candidate recommendation query language for RDF. In this paper we address systematically the formal study of SPARQL, concentrating in its graph pattern facility. We consider for this study a fragment without literals and a simple version of filters which encompasses all the main issues yet is simple to formalize. We provide a compositional semantics, prove there are normal forms, prove complexity bounds, among others that the evaluation of SPARQL patterns is PSPACE-complete, compare our semantics to an alternative operational semantics, give simple and natural conditions when both semantics coincide and discuss optimizations procedures.},
	Author = {Perez, Jorge and Arenas, Marcelo and Gutierrez, Claudio},
	Booktitle = iswc,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {SPARQL, complexity, b-nodes, semantics},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Perez2006Semantics-and-Complexity-of-SPARQL.pdf},
	Title = {Semantics and Complexity of SPARQL},
	Year = {2006}}

@article{Hull1994Domain-Independence-and-the-Relational-Calculus,
	Abstract = {Several alternative semantics (or interpretations) of the relational (domain) calculus are studied here. It is shown that they all have the same expressive power, i.e., the selection of any of the semantics neither gains nor loses expressive power. Since the domain is potentially infinite, the answer to a relational calculus query is sometimes infinite (and hence not a relation). The following approaches which guarantee the finiteness of answers to queries are studied here: output-restricted},
	Address = {Secaucus, NJ, USA},
	Author = {Hull, Richard and Su, Jianwen},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1007/BF01213204},
	Issn = {0001-5903},
	Journal = {Acta Informatica},
	Keywords = {value invention, domain independece, relational calculus, b-nodes},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Hull1994Domain-Independence-and-the-Relational-Calculus.pdf},
	Number = {6},
	Pages = {513--524},
	Publisher = {Springer-Verlag New York, Inc.},
	Title = {Domain Independence and the Relational Calculus},
	Volume = {31},
	Year = {1994}}

@article{Cabibbo1998The-Expressive-Power-of-Stratified-Logic-Programs,
	Abstract = {The expressive power of the family wILOG (:) of relational query languages is investigated. The languages are rule based, with value invention and stratified negation. The semantics for value invention is based on Skolem functor terms. We study a hierarchy of languages based on the number of strata allowed in programs. We first show that, in presence of value invention, the class of stratified programs made of two strata has the whole expressive power of the family, thus expressing the},
	Address = {Duluth, MN, USA},
	Author = {Cabibbo, Luca},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1006/inco.1998.2734},
	Issn = {0890-5401},
	Journal = {Information and Computation},
	Keywords = {value invention, b-nodes, expressiveness, complexity},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Cabibbo1998The-Expressive-Power-of-Stratified-Logic-Programs.pdf},
	Number = {1},
	Pages = {22--56},
	Publisher = {Academic Press, Inc.},
	Title = {The Expressive Power of Stratified Logic Programs with Value Invention},
	Volume = {147},
	Year = {1998}}

@book{Hopcroft2006Introduction-to-Automata-Theory-Languages-and-Computation,
	Address = {Boston, MA, USA},
	Author = {Hopcroft, John E. and Motwani, Rajeev and Ullman, Jeffrey D.},
	Booktitle = {Introduction to Automata Theory, Languages, and Computation},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Edition = {3rd},
	Isbn = {0321462254},
	Keywords = {automata, languages, complexity, turing machine, multistack machine},
	Publisher = {Addison-Wesley Longman Publishing Co., Inc.},
	Title = {Introduction to Automata Theory, Languages, and Computation},
	Year = {2006}}

@article{Hell1992The-Core-of-a-Graph,
	Address = {Amsterdam, The Netherlands, The Netherlands},
	Author = {Hell, Pavol and Ne{\v s}et{\v r}il, Jaroslav},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1016/0012-365X(92)90282-K},
	Issn = {0012-365X},
	Journal = {Discrete Mathematics},
	Keywords = {core, lean semantics, graph isomorphism},
	Number = {1-3},
	Pages = {117--126},
	Publisher = {Elsevier Science Publishers B. V.},
	Title = {The Core of a Graph},
	Volume = {109},
	Year = {1992}}

@techreport{Manola2004RDF-Primer,
	Abstract = {The Resource Description Framework (RDF) is a language for representing information about resources in the World Wide Web. This Primer is designed to provide the reader with the basic knowledge required to effectively use RDF. It introduces the basic concepts of RDF and describes its XML syntax. It describes how to define RDF vocabularies using the RDF Vocabulary Description Language, and gives an overview of some deployed RDF applications. It also describes the content and purpose of other RDF specification documents.},
	Author = {Manola, Frank and Miller, Eric and McBride, Brian},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {RDF, semantic web},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Manola2004RDF-Primer.pdf},
	Title = {RDF Primer},
	Type = {Recommendation},
	Year = {2004}}

@techreport{Hayes2007RDF-Semantics,
	Abstract = {This is a specification of a precise semantics, and corresponding complete systems of inference rules, for the Resource Description Framework (RDF) and RDF Schema (RDFS).},
	Author = {Hayes, Patrick and McBride, Brian},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {RDF, semantics, lean semantics, model theory, semantic web},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Hayes2007RDF-Semantics.pdf},
	Title = {RDF Semantics},
	Type = {Recommendation},
	Year = {2004}}

@techreport{Klyne2004RDF-Concepts,
	Abstract = {The Resource Description Framework (RDF) is a framework for representing information in the Web.

RDF Concepts and Abstract Syntax defines an abstract syntax on which RDF is based, and which serves to link its concrete syntax to its formal semantics. It also includes discussion of design goals, key concepts, datatyping, character normalization and handling of URI references.},
	Author = {Klyne, Graham and Carroll, Jeremy J. and McBride, Brian},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {RDF, syntax, Semantic Web},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Klyne2004RDF-Concepts.pdf},
	Title = {{Resource Description Framework (RDF): Concepts and Abstract Syntax}},
	Type = {Recommendation},
	Year = {2004}}

@article{Fagin2005Data-Exchange-Getting-to-the-Core,
	Abstract = {Data exchange is the problem of taking data structured under a source schema and creating an instance of a target schema that reflects the source data as accurately as possible. Given a source instance, there may be many solutions to the data exchange problem, that is, many target instances that satisfy the constraints of the data exchange problem. In an earlier article, we identified a special class of solutions that we call universal. A universal solution has homomorphisms into every possible solution, and hence is a ``most general possible'' solution. Nonetheless, given a source instance, there may be many universal solutions. This naturally raises the question of whether there is a ``best'' universal solution, and hence a best solution for data exchange. We answer this question by considering the well-known notion of the core of a structure, a notion that was first studied in graph theory, and has also played a role in conjunctive-query processing. The core of a structure is the smallest substructure that is also a homomorphic image of the structure. All universal solutions have the same core (up to isomorphism); we show that this core is also a universal solution, and hence the smallest universal solution. The uniqueness of the core of a universal solution together with its minimality make the core an ideal solution for data exchange. We investigate the computational complexity of producing the core. Well-known results by Chandra and Merlin imply that, unless P &equals; NP, there is no polynomial-time algorithm that, given a structure as input, returns the core of that structure as output. In contrast, in the context of data exchange, we identify natural and fairly broad conditions under which there are polynomial-time algorithms for computing the core of a universal solution. We also analyze the computational complexity of the following decision problem that underlies the computation of cores: given two graphs G and H, is H the core of G? Earlier results imply that this problem is both NP-hard and coNP-hard. Here, we pinpoint its exact complexity by establishing that it is a DP-complete problem. Finally, we show that the core is the best among all universal solutions for answering existential queries, and we propose an alternative semantics for answering queries in data exchange settings.},
	Address = {New York, NY, USA},
	Author = {Fagin, Ronald and Kolaitis, Phokion G. and Popa, Lucian},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1061318.1061323},
	Issn = {0362-5915},
	Journal = tods,
	Keywords = {core, RDF, incomplete information, data exchange},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Fagin2005Data-Exchange-Getting-to-the-Core.pdf},
	Number = {1},
	Pages = {174--210},
	Publisher = {ACM Press},
	Title = {Data Exchange: Getting to the Core},
	Volume = {30},
	Year = {2005}}

@inproceedings{Sintek2002TRIPLE,
	Abstract = {This paper presents TRIPLE, a layered and modular rule language for the Semantic Web [1]. TRIPLE is based on Horn logic and borrows many basic features from F-Logic [5] but is especially designed for querying and transforming RDF models [8]. TRIPLE can be viewed as a successor of SiLRI (Simple Logic-based RDF Interpreter [3]). One of the most important differences to F-Logic and SiLRI is that TRIPLE does not have a fixed semantics for object-oriented features like classes and inheritance. Its layered architecture allows such features to be easily defined for different object-oriented and other data models like UML, Topic Maps, or RDF Schema [7]. Description logics extensions of RDF (Schema) like OIL [6] and DAML+OIL [2] that cannot be fully handled by Horn logic are provided as modules that interact with a description logic classifier, e.g. FaCT [4], resulting in a hybrid rule language. This paper sketches syntax and semantics of TRIPLE.},
	Author = {Sintek, Michael and Decker, Stefan},
	Booktitle = iswc,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {RDF, TRIPLE, query languages, recursion, F-logic},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Sintek2002TRIPLE.pdf},
	Title = {TRIPLE---A Query, Inference, and Transformation Language for the Semantic Web},
	Year = {2002}}

@inproceedings{Karvounarakis2002RQL,
	Abstract = {Real-scale Semantic Web applications, such as Knowledge Portals and E-Marketplaces, require the management of large volumes of metadata, i.e., information describing the available Web content and services. Better knowledge about their meaning, usage, accessibility or quality will considerably facilitate an automated processing of Web resources. The Resource Description Framework (RDF) enables the creation and exchange of metadata as normal Web data. Although voluminous RDF descriptions are already appearing, sufficiently expressive declarative languages for querying both RDF descriptions and schemas are still missing. In this paper, we propose a new RDF query language called RQL. It is a typed functional language (a la OQL) and relies on a formal model for directed labeled graphs permitting the interpretation of superimposed resource descriptions by means of one or more RDF schemas. RQL adapts the functionality of semistructured/XML query languages to the peculiarities of RDF but, foremost, it enables to uniformly query both resource descriptions and schemas. We illustrate the RQL syntax, semantics and typing system by means of a set of example queries and report on the performance of our persistent RDF Store employed by the RQL interpreter.},
	Address = {New York, NY, USA},
	Author = {Karvounarakis, Gregory and Alexaki, Sofia and Christophides, Vassilis and Plexousakis, Dimitris and Scholl, Michel},
	Booktitle = www,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/511446.511524},
	Isbn = {1-58113-449-5},
	Keywords = {RQL, RDF, query language},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Karvounarakis2002RQL.pdf},
	Location = {Honolulu, Hawaii, USA},
	Pages = {592--603},
	Publisher = {ACM Press},
	Title = {RQL: a Declarative Query Language for RDF},
	Year = {2002}}

@techreport{Noy2006Defining-N-ary-Relations-on-the-Semantic-Web,
	Abstract = {In Semantic Web languages, such as RDF and OWL, a property is a binary relation: it is used to link two individuals or an individual and a value. However, in some cases, the natural and convenient way to represent certain concepts is to use relations to link an individual to more than just one individual or value. These relations are called n-ary relations. For example, we may want to represent properties of a relation, such as our certainty about it, severity or strength of a relation, relevance of a relation, and so on. Another example is representing relations among multiple individuals, such as a buyer, a seller, and an object that was bought when describing a purchase of a book. This document presents ontology patterns for representing n-ary relations in RDF and OWL and discusses what users must consider when choosing these patterns.},
	Author = {Noy, Natasha and Rector, Alan and Hayes, Pat and Welty, Chris},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {RDF, n-ary relations, b-nodes, grouping},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Noy2006Defining-N-ary-Relations-on-the-Semantic-Web.pdf},
	Title = {Defining N-ary Relations on the Semantic Web},
	Type = {Working Group Note},
	Url = {http://www.w3.org/TR/swbp-n-aryRelations/},
	Year = {2006}}

@inproceedings{Gutierrez2004Foundations-of-semantic-web-databases,
	Abstract = {The Semantic Web is based on the idea of adding more machine-readable semantics to web information via annotations written in a language called the Resource Description Framework (RDF). RDF resembles a subset of binary first-order logic including the ability to refer to anonymous objects. Its extended version, RDFS, supports reification, typing and inheritance. These features introduce new challenges into the formal study of sets of RDF/RDFS statements and languages for querying them. Although several such query languages have been proposed, there has been little work on foundational aspects. We investigate these, including computational aspects of testing entailment and redundancy. We propose a query language with well-defined semantics and study the complexity of query processing, query containment, and simplification of answers.},
	Address = {New York, NY, USA},
	Author = {Gutierrez, Claudio and Hurtado, Carlos and Mendelzon, Alberto O.},
	Booktitle = pods,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1055558.1055573},
	Isbn = {158113858X},
	Keywords = {semantic web, rdf, complexity, semantics, answer semantics},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Gutierrez2004Foundations-of-semantic-web-databases.pdf},
	Location = {Paris, France},
	Pages = {95--106},
	Publisher = {ACM Press},
	Title = {Foundations of Semantic Web Databases},
	Year = {2004}}

@inproceedings{Gutierrez2003Formal-Aspects-of-Querying-RDF,
	Abstract = {We study formal aspects of querying databases containing RDF data. We present a formal definition of a query language for RDF and compare it with other proposals. Our language is intended to make it easy to formalize and prove results about its properties. We study novel features of query languages derived from the presence of blank nodes and reification. Finally we provide complexity results for query processing, static optimization of queries, and redundancy elimination in answers.},
	Author = {Guti{\'e}rrez, Claudio and Hurtado, Carlos A. and Mendelzon, Alberto O.},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = swdb,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {RDF, querying, lean answer, complexity, answer semantics},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Gutierrez2003Formal-Aspects-of-Querying-RDF.pdf},
	Pages = {293-307},
	Title = {Formal Aspects of Querying RDF Databases},
	Year = {2003}}

@inproceedings{Gottlob2006Data-exchange-Computing-Cores,
	Abstract = {Data exchange deals with inserting data from one database into another database having a different schema. We study and solve a central computational problem of data exchange, namely, computing the core of a universal solution to a data exchange problem. Fagin, Kolaitis, and Popa [9], have shown that among the universal solutions of a solvable data exchange problem, there exists a most compact one (up to isomorphism), "the core" (of any universal solution), and have convincingly argued that this core should be the solution of choice. They stated as an important open problem whether the core of a universal solution can be computed in polynomial time in the general setting where the source-to-target constraints are arbitrary tuple generating dependencies (TGDs) and the target constraints consist of equation generating dependencies (EGDs) and weakly-acyclic TGDs. In this paper we solve this problem by developing new efficient methods for computing the core of a universal solution. This positive result shows that the core approach of Fagin, Kolaitis, and Popa is feasible and applicable in a very general setting and thus provides a further momentum to the use of cores in data exchange.},
	Address = {New York, NY, USA},
	Author = {Gottlob, Georg and Nash, Alan},
	Booktitle = pods,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1142351.1142358},
	Isbn = {1-59593-318-2},
	Keywords = {data exchange, core, lean answer},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Gottlob2006Data-exchange-Computing-Cores.pdf},
	Location = {Chicago, IL, USA},
	Pages = {40--49},
	Publisher = {ACM Press},
	Title = {Data exchange: Computing Cores in Polynomial Time},
	Year = {2006}}

@inproceedings{Berger2007Completing-Queries:-Rewriting-of-Incomplete-Web-Queries,
	Abstract = {Web queries have been and will remain an essential tool for accessing, processing, and, ultimately, reasoning with data on the Web. With the vast data size on the Web and Semantic Web, reducing costs of data transfer and query evaluation for Web queries is crucial. To reduce costs, it is necessary to narrow the data candidates to query, simplify complex queries and reduce intermediate results.

This article describes a static approach to optimization of web queries. We introduce a set of rules which achieves the desired optimization by schema and type based query rewriting. The approach consists in using schema information for removing incompleteness (as expressed by `descendant' constructs and disjunctions) from queries. The approach is presented on the query language Xcerpt, though applicable to other query languages like XQuery. The approach is an application of rules in many aspects---query rules are optimized using rewriting rules based on schema or type information specified in grammar rules.
},
	Annote = {Short paper},
	Author = {Berger, Sacha and Bry, Fran{\c c}ois and Furche, Tim and H{\"a}usler, Andreas J.},
	Booktitle = rr,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Editor = {Marchiori, Massimo and Pan, Jeff Z. and de Sainte Marie, Christian},
	Keywords = {optimization, types, Xcerpt, rewriting},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/berger-incomplete.pdf},
	Title = {Completing Queries: Rewriting of Incomplete Web Queries under Schema Constraints},
	Year = {2007}}

@inproceedings{Beeri1987Sets-and-Negation-in-a-Logic-Data-Base,
	Address = {New York, NY, USA},
	Author = {Beeri, C. and Naqvi, S. and Ramakrishnan, R. and Shmueli, O. and Tsur, S.},
	Booktitle = pods,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/28659.28662},
	Isbn = {0-89791-223-3},
	Keywords = {complex values, algebra, sets, ldl},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Beeri1987Sets-and-Negation-in-a-Logic-Data-Base.pdf},
	Location = {San Diego, California, United States},
	Pages = {21--37},
	Publisher = {ACM Press},
	Title = {Sets and Negation in a Logic Data Base Language (LDL1)},
	Year = {1987}}

@conference{Vardi1982The-Complexity-of-Relational-Query-Languages,
	Address = {San Francisco},
	Author = {Vardi, M.},
	Booktitle = STOC,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {complexity, relational, query languages, combined complexity, query complexity, data complexity},
	Pages = {137-146},
	Title = {The Complexity of Relational Query Languages},
	Year = 1982}

@article{Buneman1995Principles-of-programming-with-complex-objects,
	Address = {Essex, UK},
	Author = {Buneman, Peter and Naqvi, Shamim and Tannen, Val and Wong, Limsoon},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1016/0304-3975(95)00024-Q},
	Issn = {0304-3975},
	Journal = tcs,
	Keywords = {complex values, monad algebra,},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Buneman1995Principles-of-programming-with-complex-objects.pdf},
	Number = {1},
	Pages = {3--48},
	Publisher = {Elsevier Science Publishers Ltd.},
	Title = {Principles of programming with complex objects and collection types},
	Volume = {149},
	Year = {1995}}

@inproceedings{Dantsin2000Expressive-power-and-data-complexity-of-nonrecursive,
	Abstract = {We extend the traditional query languages by primitives for handling lists and trees. Our main results characterize the expressive power and data complexity of the following extended languages: (1) relational algebra with lists and trees, (2) nonrecursive Datalog@@@@ with lists and trees, (3) nonrecursive Prolog with lists and trees, (4) first-order logic over lists and trees.Languages (2)-(4) turn out to have the same expressive power; their range-restricted fragments have the same expressive power as (1). Every query in these languages is a boolean combination of range-restricted queries.We also prove that these query languages have polynomial data complexity under any ``reasonable'' encoding of inputs. Furthermore, under a natural encoding of inputs, languages (2)-(4) have the same expressive power as first-order logic over finite structures, therefore their data complexity is in A Co. Thus, the use of lists and trees in nonrecursive query languages gives no gain in the expressiveness. This contrasts with a huge difference between the nonelementary program complexity of extended languages (2)-(4) and the PSPA CE program complexity of their relational counterparts.Our results partly explain why lists and trees are not so widely used in nonrecursive query languages as other collection types.

},
	Address = {New York, NY, USA},
	Author = {Dantsin, Evgeny and Voronkov, Andrei},
	Booktitle = {PODS '00: Proceedings of the nineteenth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/335168.335218},
	Isbn = {1-58113-214-X},
	Keywords = {complex values, lists, trees, complexity},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Dantsin2000Expressive-power-and-data-complexity-of-nonrecursive.pdf},
	Location = {Dallas, Texas, United States},
	Pages = {157--165},
	Publisher = {ACM Press},
	Title = {Expressive power and data complexity of nonrecursive query languages for lists and trees (extended abstract)},
	Year = {2000}}

@article{Grumbach1996Query-languages-for-bags,
	Address = {New York, NY, USA},
	Author = {Grumbach, St\&\#233;phane and Libkin, Leonid and Milo, Tova and Wong, Limsoon},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/235767.235770},
	Issn = {0163-5700},
	Journal = {SIGACT News},
	Keywords = {query languages, algebra, bags, complexity, complex values},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Grumbach1996Query-languages-for-bags.pdf},
	Number = {2},
	Pages = {30--44},
	Publisher = {ACM Press},
	Title = {Query languages for bags: expressive power and complexity},
	Volume = {27},
	Year = {1996}}

@inproceedings{Grumbach1991Tractable-query-languages-for-complex-object,
	Address = {New York, NY, USA},
	Author = {Grumbach, St\&\#233;phane and Vianu, Victor},
	Booktitle = pods,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/113413.113442},
	Isbn = {0-89791-430-9},
	Keywords = {complex values, algebra, evaluation, nested relational algebra},
	Location = {Denver, Colorado, United States},
	Pages = {315--327},
	Publisher = {ACM Press},
	Title = {Tractable Query Languages for Complex Object Databases},
	Year = {1991}}

@article{Libkin1997Query-languages-for-bags-and-aggregate-functions,
	Address = {Orlando, FL, USA},
	Author = {Libkin, Leonid and Wong, Limsoon},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1006/jcss.1997.1523},
	Issn = {0022-0000},
	Journal = {J. Comput. Syst. Sci.},
	Keywords = {algebra, bags, aggregation, query language, complex values},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Libkin1997Query-languages-for-bags-and-aggregate-functions.pdf},
	Number = {2},
	Pages = {241--272},
	Publisher = {Academic Press, Inc.},
	Title = {{Query Languages for Bags and Aggregate Functions}},
	Volume = {55},
	Year = {1997}}

@inproceedings{Suciu1994A-Query-Language-for-NC,
	Abstract = {We show that a form of divide and conquer recursion on sets together with the relational algebra expresses exactly the queries over ordered relational databases which are NC-computable. At a finer level, we relate k nested uses of recursion exactly to ACk, k>=1. We also give corresponding results for complex objects.},
	Address = {New York, NY, USA},
	Author = {Suciu, Dan and Breazu-Tannen, Val},
	Booktitle = pods,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/182591.182610},
	Isbn = {0-89791-642-5},
	Keywords = {algebra, complex value, query language,},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Suciu1994A-Query-Language-for-NC.pdf},
	Location = {Minneapolis, Minnesota, United States},
	Pages = {167--178},
	Publisher = {ACM Press},
	Title = {A Query Language for NC},
	Year = {1994}}

@inproceedings{Vorobyov1998Complexity-of-logic-programs-with-complex-values,
	Address = {New York, NY, USA},
	Author = {Vorobyov, Sergei and Voronkov, Andrie},
	Booktitle = pods,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/275487.275515},
	Isbn = {0-89791-996-3},
	Keywords = {complex values, bags, sequences, algebra,},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/p244-vorobyov.pdf},
	Location = {Seattle, Washington, United States},
	Pages = {244--253},
	Publisher = {ACM Press},
	Title = {Complexity of nonrecursive logic programs with complex values},
	Year = {1998}}

@article{Bernstein1981Using-Semi-Joins-to-Solve-Relational-Queries,
	Address = {New York, NY, USA},
	Author = {Bernstein, Philip A. and Chiu, Dah-Ming W.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/322234.322238},
	Issn = {0004-5411},
	Journal = jacm,
	Keywords = {semi-join, tree queries, optimization,},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Bernstein1981Using-Semi-Joins-to-Solve-Relational-Queries.pdf},
	Number = {1},
	Pages = {25--40},
	Publisher = {ACM Press},
	Title = {Using Semi-Joins to Solve Relational Queries},
	Volume = {28},
	Year = {1981}}

@article{Codd1972Relational-Completeness-of-Data-Base-Sublanguages,
	Author = {Codd, Edgar F.},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Ee = {db/labs/ibm/RJ987.html},
	Journal = {Database Systems},
	Keywords = {RDBMS, relational algebra, relational completeness},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Codd1972Relational-Completeness-of-Data-Base-Sublanguages.pdf},
	Pages = {65-98},
	Title = {Relational Completeness of Data Base Sublanguages.},
	Year = {1972}}

@inproceedings{Antova2007World-Set-Decompositions-Expressiveness-and-Efficient-Algorithms,
	Abstract = {Uncertain information is commonplace in real-world data management scenarios. An important challenge in this context is the ability to represent large sets of possible instances (worlds) while sup- porting efficient storage and processing. The recent formalism of world- set decompositions (WSDs) provides a space-efficient representation for uncertain data that also supports scalable processing. WSDs are com- plete for finite world-sets in that they can represent any finite set of possible worlds. For possibly infinite world-sets, we show that a natu- ral generalization of WSDs precisely captures the expressive power of c-tables. We then give evidence that WSDs are a practically more re- alistic representation system for incomplete information than c-tables and other recent representation systems. We show that several impor- tant problems are efficiently solvable on WSDs while they are NP-hard on c-tables. Finally, we give a polynomial-time algorithm for factorizing WSDs, i.e. an efficient algorithm for minimizing such representations.
},
	Author = {Antova, Lyublena and Koch, Christoph and Olteanu, Dan},
	Booktitle = icdt,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {incomplete information, possible worlds, null values, b-nodes},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Antova2007World-Set-Decompositions-Expressiveness-and-Efficient-Algorithms.pdf},
	Title = {World-Set Decompositions: Expressiveness and Efficient Algorithms},
	Year = {2007}}

@inproceedings{Antova200710106-Worlds-and-Beyond-Efficient-Representation,
	Abstract = {We present a decomposition-based approach to managing incomplete information. We introduce world-set decompositions (WSDs), a space-efficient and complete representation system for finite sets of worlds. We study the problem of efficiently evaluating relational algebra queries on world-sets represented byWSDs. We also evaluate our technique experimentally in a large census data scenario and show that it is both scalable and efficient.},
	Author = {Antova, Lyublena and Koch, Christoph and Olteanu, Dan},
	Booktitle = icde,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {incomplete information, possible worlds, null-values, b-nodes},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Antova200710106-Worlds-and-Beyond-Efficient-Representation.pdf},
	Title = {$10^{10^6}$ Worlds and Beyond: Efficient Representation and Processing of Incomplete Information},
	Year = {2007}}

@article{Abiteboul1991On-the-Representation-and-Querying-of-Sets-of-Possible-Worlds,
	Address = {Essex, UK},
	Author = {Abiteboul, Serge and Kanellakis, Paris and Grahne, G\&\#246;sta},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1016/0304-3975(51)90007-2},
	Issn = {0304-3975},
	Journal = tcs,
	Keywords = {incomplete information, null values, b-nodes},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Abiteboul1991On-the-Representation-and-Querying-of-Sets-of-Possible-Worlds.pdf},
	Number = {1},
	Pages = {159--187},
	Publisher = {Elsevier Science Publishers Ltd.},
	Title = {On the Representation and Querying of Sets of Possible Worlds},
	Volume = {78},
	Year = {1991}}

@book{Grahne1991Problem-of-Incomplete-Information-in-Relational-Databases,
	Abstract = {In a relational database the information is recorded as rows in tables. However, in many practical situations the available information is incomplete and the values for some columns are missing. Yet few existing database management systems allow the user to enter null values in the database. This monograph analyses the problems raised by allowing null values in relational databases. The analysis covers semantical, syntactical, and computational aspects. Algorithms for query evaluation, dependency enforcement and updates in the presence of null values are also given. The analysis of the computational complexity of the algorithms suggests that from a practical point of view the database should be stored as Horn tables, which are generalizations of ordinary relations, allowing null values and Horn clause-like restrictions on these null values. Horn tables efficiently support a large class of queries, dependencies and updates.},
	Address = {Secaucus, NJ, USA},
	Author = {Grahne, G.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {0387549196},
	Keywords = {incomplete information, b-nodes, null values},
	Publisher = {Springer-Verlag New York, Inc.},
	Title = {Problem of Incomplete Information in Relational Databases},
	Year = {1991}}

@article{Imielinski1984Incomplete-Information-in-Relational-Databases,
	Address = {New York, NY, USA},
	Author = {Imieli{\'n}ski, Tomasz and Witold Lipski, Jr.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1634.1886},
	Issn = {0004-5411},
	Journal = jacm,
	Keywords = {incomplete information, b-nodes, null values, RDBMS},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Imielinski1984Incomplete-Information-in-Relational-Databases.pdf},
	Number = {4},
	Pages = {761--791},
	Publisher = {ACM Press},
	Title = {Incomplete Information in Relational Databases},
	Volume = {31},
	Year = {1984}}

@inproceedings{Abiteboul1987On-the-Representation-and-Querying-of-Sets-of-Possible-Worlds,
	Abstract = {We represent a set of possible worlds using an incomplete information database. The representation techniques that we study form a hierarchy, which generalizes relations of constants. This hierarchy ranges from the very simple Codd-table, (i e , a relation of constants and distinct variables called nulls, which stand for values present but unknown), to much more complex mechanisms involving views on conditioned-tables, (i e , queries on Codd-tables together with conditions). The views we consider are the queries that have polynomial data-complexity on complete information databases. Our conditions are conjunctions of equalities and inequalities. (1) We provide matching upper and lower bounds on the data-complexity of testing containement, membership, and uniqueness for sets of possible worlds and we fully classify these problems with respect to our representation hierarchy. The most surprising result in this classification is that it is complete in &Pgr;2p, whether a set of possible worlds represented by a Codd-table is a subset of a set of possible worlds represented by a Codd-table with one conjuction of inequalities. (2) We investigate the data-complexity of querying incomplete information databases. We examine both asking for certain facts and for possible facts. Our approach is algebraic but our bounds also apply to logical databases. We show that asking for a certain fact is coNP-complete, even for a fixed first order query on a Codd-table. We thus strengthen a lower bound of [16], who showed that this holds for a Codd-table with a conjunction of inequalities. For each fixed positive existential query we present a polynomial algorithm solving the bounded possible fact problem of this query on conditioned-tables. We show that our approach is, in a sense, the best possible, by deriving two NP-completeness lower bounds for the bounded possible fact problem when the fixed query contains either negation or recursion.},
	Address = {New York, NY, USA},
	Author = {Abiteboul, Serge and Kanellakis, Paris and Grahne, Gosta},
	Booktitle = sigmod,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/38713.38724},
	Isbn = {0-89791-236-5},
	Keywords = {possible worlds, null values, c-tables, b-nodes},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Abiteboul1987On-the-Representation-and-Querying-of-Sets-of-Possible-Worlds.pdf},
	Location = {San Francisco, California, United States},
	Pages = {34--48},
	Publisher = {ACM Press},
	Title = {On the Representation and Querying of Sets of Possible Worlds},
	Year = {1987}}

@book{Garcia-Molina2002Database-Systems-The-Complete-Book,
	Author = {Garcia-Molina, Hector and Ullman, Jeffrey D. and Widom, Jennifer},
	Booktitle = {Hector Garcia-Molina and Jeffrey D. Ullman and Jennifer Widom},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {database systems, RDBMS, SQL, query evaluation},
	Publisher = {Prentice Hall},
	Title = {Database Systems: The Complete Book},
	Year = {2002}}

@inproceedings{Breazu-Tannen1992Naturally-Embedded-Query-Languages,
	Abstract = {We investigate the properties of a simple programming language whose main computational engine is structural recursion on sets. We describe a progression of sublanguages in this paradigm that (1) have increasing expressive power, and (2) illustrate robust conceptual restrictions thus exhibiting interesting additional properties. These properties suggest that we consider our sublanguages as candidates for ``query languages''. Viewing query languages as restrictions of our more general programming language has several advantages. First, there is no ``impedance mismatch'' problem; the query languages are already there, so they share common semantic foundation with the general language. Second, we suggest a uniform characterization of nested relational and complex-object algebras in terms of some surprisingly simple operators; and we can make comparisons of expressiveness in a general framework. Third, we exhibit differences in expressive power that are not always based on complexity arguments, but use the idea that a query in one language may not be polymorphically expressible in another. Fourth, ideas of category theory can be profitably used to organize semantics and syntax, in particular our minimal (core) language is a well-understood categorical construction: a cartesian category with a strong monad on it. Finally, we bring out an algebraic perspective, that is, our languages come with equational theories, and categorical ideas can be used to derive a number of rather general identities that may serve as optimizations or as techniques for discovering optimizations.},
	Author = {Breazu-Tannen, Val and Buneman, Peter and Wong, Limsoon},
	Booktitle = icdt,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Breazu-Tannen1992Naturally-Embedded-Query-Languages.pdf},
	Pages = {140--154},
	Title = {Naturally Embedded Query Languages},
	Year = {1992}}

@inproceedings{Gyssens1988The-Powerset-Algebra-as-a-Result-of-Adding-Programming,
	Abstract = {In this paper, we discuss augmentations of the nested relational algebra with programming constructs, such as while-loops and for-loops. We show that the algebras obtained in this way are equivalent to a slight extension of the powerset algebra, thus emphasizing both the strength and the naturalness of the powerset algebra as a tool to manipulate nested relations, and, at the same time, indicating more direct ways to implement this algebra.},
	Address = {New York, NY, USA},
	Author = {Gyssens, Marc and van Gucht, Dirk},
	Booktitle = sigmod,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/50202.50230},
	Isbn = {0-89791-268-3},
	Keywords = {powerset operator, relational algebra, complex value, nested relational algebra},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Gyssens1988The-Powerset-Algebra-as-a-Result-of-Adding-Programming.pdf},
	Location = {Chicago, Illinois, United States},
	Pages = {225--232},
	Publisher = {ACM Press},
	Title = {The Powerset Algebra as a Result of Adding Programming Constructs to the Nested Relational Algebra},
	Year = {1988}}

@inproceedings{Kuper1988On-the-Expressive-Power-of-Logic-Programming-Languages,
	Address = {New York, NY, USA},
	Author = {Kuper, Gabriel M.},
	Booktitle = pods,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/308386.308397},
	Isbn = {0-89791-263-2},
	Keywords = {logic programming, complex value, sets, expressiveness},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Kuper1988On-the-Expressive-Power-of-Logic-Programming-Languages.pdf},
	Location = {Austin, Texas, United States},
	Pages = {10--14},
	Publisher = {ACM Press},
	Title = {On the Expressive Power of Logic Programming Languages with Sets},
	Year = {1988}}

@inproceedings{Suciu1994Powserset-needs-Exponential-Space-Transitive-Closure,
	Abstract = {The Abiteboul and Beeri algebra for complex objects can express a query whose meaning is transitive closure, but the algorithm is naturally associated to this query needs exponential space. We show that any other query in the algebra which expresses transitive closure needs exponential space. This proves that in general the powerset is an intractable operator for implementing fixpoint queries.},
	Address = {New York, NY, USA},
	Author = {Suciu, Dan and Paredaens, Jan},
	Booktitle = pods,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/182591.182613},
	Isbn = {0-89791-642-5},
	Keywords = {relational algebra, complex value, powerset operator, complexity},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Suciu1994Powserset-needs-Exponential-Space-Transitive-Closure.pdf},
	Location = {Minneapolis, Minnesota, United States},
	Pages = {201--209},
	Publisher = {ACM Press},
	Title = {Any Algorithm in the Complex Object Algebra with Powerset needs Exponential Space to Compute Transitive Closure},
	Year = {1994}}

@article{Makinouchi1977A-consideration-of-normal-form-of-not-necessarily-normalized-relations,
	Abstract = {In this paper definitions of unnormalized relation, functional dependency on it and Normal Form are presented. The Normal Form plays a key role in our relational data model in which unnormalized relations are admitted as does the Third Normal Form of Codd in the data model of normalized relation.

Properties pertaining to Normal Form are discussed emphasizing comparison with 3NF along with analysis of some typical examples.

Similarity and dissimilarity between new functional dependency and Fagin's multivalued dependency are also discussed and presented in the form of proposition.},
	Author = {Makinouchi, Akifumi},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = vldb,
	Keywords = {relational algebra, nested relational algebra, nest, unnest},
	Pages = {447--453},
	Title = {A consideration of normal form of not-necessarily-normalized relations in the relational data model.},
	Url = {http://cdserv4.inria.fr/Volumes/VLDB7588/VLDB77/P447.PDF},
	Year = {1977}}

@inproceedings{Jaeschke1982Remarks-on-the-Algebra-of-Non-First-Normal-Form,
	Abstract = {Usually, the first normal form condition of the relational model of data is imposed. Presently, a broader class of data base applications like office information systems is considered where this restriction is not convenient. Therefore, an extension of the relational model is proposed consisting of Non First Normal Form (NF2) relations. The relational algebra is enriched mainly by so called nest and unnest operations which transform between NF2 relations and the usual ones. We state some properties of these operations and some rules which occur in combination with the operations of the usual relational algebra. Since we propose to use the NF2 model also for the internal data model these rules are important not only for theoretical reasons but also for a practical implementation.},
	Address = {New York, NY, USA},
	Author = {Jaeschke, G. and Schek, H. J.},
	Booktitle = pods,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/588111.588133},
	Isbn = {0-89791-070-2},
	Keywords = {relational algebra, nested relational algebra, nest, unnest, algebra, RDBMS},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Jaeschke1982Remarks-on-the-Algebra-of-Non-First-Normal-Form.pdf},
	Location = {Los Angeles, California},
	Pages = {124--138},
	Publisher = {ACM Press},
	Title = {Remarks on the Algebra of Non First Normal Form Relations},
	Year = {1982}}

@inproceedings{Lammel2007Scrap-your-Boilerplate-with-XPath-like-Combinators,
	Abstract = {XML programming involves idioms for expressing 'structure shyness' such as the descendant axis of XPath or the default templates of XSLT. We initiate a discussion of the relationships between such XML idioms and generic functional programming, while focusing on the (Haskell-based) 'Scrap your boilerplate' style of generic programming (SYB). This work gives insight into mechanisms for traversal and selection. We compare SYB and XSLT. We approximate XPath in SYB. We make a case for SYB's programmability, when compared to XPath's fixed combinators. We allude to strengthened type checking for SYB traversals so as to reject certain, trivial behaviors.},
	Address = {New York, NY, USA},
	Annote = {Transformation vs. Query: 
"Generic transformations and queries are functions that
are polymorphic in their argument type; transformations preserve
the type in the result; queries compute a result of a fixed type"

input type gives output type in transformation, in query not},
	Author = {L{\"a}mmel, Ralf},
	Booktitle = popl,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1190216.1190240},
	Isbn = {1-59593-575-4},
	Keywords = {XPath, axes, generic programming, functional programming, Haskell},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Lammel2007Scrap-your-Boilerplate-with-XPath-like-Combinators.pdf},
	Location = {Nice, France},
	Pages = {137--142},
	Publisher = {ACM Press},
	Title = {Scrap your Boilerplate with XPath-like Combinators},
	Year = {2007}}

@inproceedings{Abiteboul1984Non-First-Normal-Form-Relations-to-represent,
	Address = {New York, NY, USA},
	Author = {Abiteboul, Serge and Bidoit, Nicole},
	Booktitle = pods,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/588011.588038},
	Isbn = {0-89791-128-8},
	Keywords = {nested relational algebra, hierarchy, relational algebra},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Abiteboul1984Non-First-Normal-Form-Relations-to-represent.pdf},
	Location = {Waterloo, Ontario, Canada},
	Pages = {191--200},
	Publisher = {ACM Press},
	Title = {Non First Normal Form Relations to represent Hierarchically organized Data},
	Year = {1984}}

@article{Klug1982Equivalence-of-Relational-Algebra-and-Relational-Calculus,
	Address = {New York, NY, USA},
	Author = {Klug, Anthony},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/322326.322332},
	Issn = {0004-5411},
	Journal = jacm,
	Keywords = {relational algebra, relational, RDBMS, relational calculus,},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Klug1982Equivalence-of-Relational-Algebra-and-Relational-Calculus.pdf},
	Number = {3},
	Pages = {699--717},
	Publisher = {ACM Press},
	Title = {Equivalence of Relational Algebra and Relational Calculus Query Languages Having Aggregate Functions},
	Volume = {29},
	Year = {1982}}

@article{Abiteboul1995The-Power-of-Languages-for-the-Manipulation-of-Complex-Values,
	Abstract = {Various models and languages for describing and manipulating hierarchically structured data have been proposed. Algebraic, calculus-based, and logic-programming oriented languages have all been considered. This article presents a general model for complex values (i.e., values with hierarchical structures), and languages for it based on the three paradigms. The algebraic language generalizes those presented in the literature; it is shown to be related to the functional style of programming advocated by Backus (1978). The notion of domain independence (from relational databases) is defined, and syntactic restrictions (referred to as safety conditions) on calculus queries are formulated to guarantee domain independence. The main results are: The domain-independent calculus, the safe calculus, the algebra, and the logic-programming oriented language have equivalent expressive power. In particular, recursive queries, such as the transitive closure, can be expressed in each of the languages. For this result, the algebra needs the powerset operation. A more restricted version of safety is presented, such that the restricted safe calculus is equivalent to the algebra without the powerset. The results are extended to the case where arbitrary functions and predicates are used in the languages.},
	Address = {Secaucus, NJ, USA},
	Author = {Abiteboul, Serge and Beeri, Catriel},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1007/BF01354881},
	Issn = {1066-8888},
	Journal = vldbj,
	Keywords = {complex values, nested relational algebra, expressiveness, powerset operator},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Abiteboul1995The-Power-of-Languages-for-the-Manipulation-of-Complex-Values.pdf},
	Number = {4},
	Pages = {727--794},
	Publisher = {Springer-Verlag New York, Inc.},
	Title = {The Power of Languages for the Manipulation of Complex Values},
	Volume = {4},
	Year = {1995}}

@article{Gelder1991Safety-and-Translation-of-Relational-Calculus,
	Abstract = {Not all queries in relational calculus can be answered sensibly when disjunction, negation, and universal quantification are allowed. The class of relation calculus queries or formulas that have sensible answers is called the domain independent class which is known to be undecidable. Subsequent research has focused on identifying large decidable subclasses of domain independent formulas. In this paper we investigate the properties of two such classes: the evaluable formulas and the allowed formulas. Although both classes have been defined before, we give simplified definitions, present short proofs of their main properties, and describe a method to incorporate equality. Although evaluable queries have sensible answers, it is not straightforward to compute them efficiently or correctly. We introduce relational algebra normal form for formulas from which form the correct translation into relational algebra is trivial. We give algorithms to transform an evaluable formula into an equivalent allowed formula and from there into relational algebra normal form. Our algorithms avoid use of the so-called Dom relation, consisting of all constants appearing in the database or the query. Finally, we describe a restriction under which every domain independent formula is evaluable and argue that the class of evaluable formulas is the largest decidable subclass of the domain independent formulas that can be efficiently recognized.},
	Address = {New York, NY, USA},
	Author = {Gelder, Allen Van and Topor, Rodney W.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/114325.103712},
	Issn = {0362-5915},
	Journal = tods,
	Keywords = {safety, domain independence, relational calculus, relational algebra},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Gelder1991Safety-and-Translation-of-Relational-Calculus.pdf},
	Number = {2},
	Pages = {235--278},
	Publisher = {ACM Press},
	Title = {Safety and Translation of Relational Calculus},
	Volume = {16},
	Year = {1991}}

@article{Chandra1982Structure-and-Complexity-of-Relational-Queries,
	Author = {Chandra, Ashok and Harel, David},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = jcss,
	Keywords = {relational algebra, relational queries, complexity, expressiveness},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Chandra1982Structure-and-Complexity-of-Relational-Queries.pdf},
	Number = {1},
	Pages = {99--128},
	Title = {Structure and Complexity of Relational Queries},
	Volume = {25},
	Year = {1982}}

@article{Codd1970A-Relational-Model-of-Data-for-Large-Shared,
	Abstract = {Future users of large data banks must be protected from having to know how the data is organized in the machine (the internal representation). A prompting service which supplies such information is not a satisfactory solution. Activities of users at terminals and most application programs should remain unaffected when the internal representation of data is changed and even when some aspects of the external representation are changed. Changes in data representation will often be needed as a result of changes in query, update, and report traffic and natural growth in the types of stored information. Existing noninferential, formatted data systems provide users with tree-structured files or slightly more general network models of the data. In Section 1, inadequacies of these models are discussed. A model based on n-ary relations, a normal form for data base relations, and the concept of a universal data sublanguage are introduced. In Section 2, certain operations on relations (other than logical inference) are discussed and applied to the problems of redundancy and consistency in the user's model.},
	Address = {New York, NY, USA},
	Author = {Codd, E. F.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/362384.362685},
	Issn = {0001-0782},
	Journal = cacm,
	Keywords = {relational algebra, RDBMS, relational data model},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Codd1970A-Relational-Model-of-Data-for-Large-Shared.pdf},
	Number = {6},
	Pages = {377--387},
	Publisher = {ACM Press},
	Title = {A Relational Model of Data for Large Shared Data Banks},
	Volume = {13},
	Year = {1970}}

@inproceedings{Chaudhuri1993Optimization-of-Real-Conjunctive-Queries,
	Address = {New York, NY, USA},
	Author = {Chaudhuri, Surajit},
	Booktitle = pods,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/153850.153856},
	Isbn = {0-89791-593-3},
	Keywords = {conjunctive queries, bags, relational, relational algebra, optimization},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Chaudhuri1993Optimization-of-Real-Conjunctive-Queries.pdf},
	Location = {Washington, D.C., United States},
	Pages = {59--70},
	Publisher = {ACM Press},
	Title = {Optimization of Real Conjunctive Queries},
	Year = {1993}}

@article{Steinbrunn1997Heuristic-and-Randomized-Optimization-for-the-Join-Ordering,
	Abstract = {Recent developments in database technology, such as deductive database systems, have given rise to the demand for new, cost-effective optimization techniques for join expressions. In this paper many different algorithms that compute approximate solutions for optimizing join orders are studied since traditional dynamic programming techniques are not appropriate for complex problems. Two possible solution spaces, the space of left-deep and bushy processing trees, are evaluated from a statistical point of view. The result is that the common limitation to left-deep processing trees is only advisable for certain join graph types. Basically, optimizers from three classes are analysed: heuristic, randomized and genetic algorithms. Each one is extensively scrutinized with respect to its working principle and its fitness for the desired application. It turns out that randomized and genetic algorithms are well suited for optimizing join expressions. They generate solutions of high quality within a reasonable running time. The benefits of heuristic optimizers, namely the short running time, are often outweighed by merely moderate optimization performance.},
	Address = {Secaucus, NJ, USA},
	Author = {Steinbrunn, Michael and Moerkotte, Guido and Kemper, Alfons},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1007/s007780050040},
	Issn = {1066-8888},
	Journal = vldbj,
	Keywords = {join processing, query optimization, join ordering, relational, relational algebra},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Steinbrunn1997Heuristic-and-Randomized-Optimization-for-the-Join-Ordering.pdf},
	Number = {3},
	Pages = {191--208},
	Publisher = {Springer-Verlag New York, Inc.},
	Title = {Heuristic and Randomized Optimization for the Join Ordering Problem},
	Volume = {6},
	Year = {1997}}

@inproceedings{Scarcello2004Weighted-Hypertree-Decompositions,
	Abstract = {Hypertree width [22, 25] is a measure of the degree of cyclicity of hypergraphs. A number of relevant problems from different areas, e.g., the evaluation of conjunctive queries in database theory or the constraint satisfaction in AI, are tractable when their underlying hypergraphs have bounded hypertree width. However, in practical contexts like the evaluation of database queries, we have more information besides the structure of queries. For instance, we know the number of tuples in relations, the selectivity of attributes and so on. In fact, all commercial query-optimizers are based on quantitative methods and do not care about structural properties.In this paper, we define the notion of weighted hypertree decomposition, in order to combine structural decomposition methods with quantitative approaches. Weighted hypertree decompositions are equipped with cost functions, that can be used for modelling many situations where we have further information on the given problem, besides its hypergraph representation. We analyze the complexity of computing the hypertree decompositions having the smallest weights, called minimal hypertree decompositions. We show that, in many cases, adding weights we loose tractability. However, we prove that, under some - not very severe - restrictions on the allowed cost functions and on the target hypertrees, optimal weighted hypertree decompositions can be computed in polynomial time. For some easier hypertree weighting functions, this problem is also highly parallelizable. Then, we provide a cost function that models query evaluation costs and show how to exploit weighted hypertree decompositions for determining (logical) query plans for answering conjunctive queries. Finally, we present the results of an experimental comparison of this query optimization technique with the query optimization of a commercial DBMS. These preliminary results are very promising, as for some large queries (with many joins) our hybrid technique clearly outperforms the commercial optimizer.},
	Address = {New York, NY, USA},
	Author = {Scarcello, Francesco and Greco, Gianluigi and Leone, Nicola},
	Booktitle = pods,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1055558.1055587},
	Isbn = {158113858X},
	Keywords = {decomposition, hypertree decomposition, relational, relational algebra, query evaluation},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Scarcello2004Weighted-Hypertree-Decompositions.pdf},
	Location = {Paris, France},
	Pages = {210--221},
	Publisher = {ACM Press},
	Title = {Weighted Hypertree Decompositions and Optimal Query Plans},
	Year = {2004}}

@inproceedings{Gottlob1999Hypertree-Decompositions,
	Address = {New York, NY, USA},
	Author = {Gottlob, Georg and Leone, Nicola and Scarcello, Francesco},
	Booktitle = pods,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/303976.303979},
	Isbn = {1-58113-062-7},
	Keywords = {decomposition, hypertree decomposition, relational, relational algebra, query evaluation},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Gottlob1999Hypertree-Decompositions.pdf},
	Location = {Philadelphia, Pennsylvania, United States},
	Pages = {21--32},
	Publisher = {ACM Press},
	Title = {Hypertree Decompositions and Tractable Queries},
	Year = {1999}}

@article{Flum2002Query-Evaluation-via-Tree-Decompositions,
	Abstract = {A number of efficient methods for evaluating first-order and monadic-second order queries on finite relational structures are based on tree-decompositions of structures or queries. We systematically study these methods.In the first part of the article, we consider arbitrary formulas on tree-like structures. We generalize a theorem of Courcelle [1990] by showing that on structures of bounded tree-width a monadic second-order formula (with free first- and second-order variables) can be evaluated in time linear in the structure size plus the size of the output.In the second part, we study tree-like formulas on arbitrary structures. We generalize the notions of acyclicity and bounded tree-width from conjunctive queries to arbitrary first-order formulas in a straightforward way and analyze the complexity of evaluating formulas of these fragments. Moreover, we show that the acyclic and bounded tree-width fragments have the same expressive power as the well-known guarded fragment and the finite-variable fragments of first-order logic, respectively.},
	Address = {New York, NY, USA},
	Author = {Flum, J\"{o}rg and Frick, Markus and Grohe, Martin},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/602220.602222},
	Issn = {0004-5411},
	Journal = jacm,
	Keywords = {query evaluation, decomposition, tree decomposition, relational, relational algebra},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Flum2002Query-Evaluation-via-Tree-Decompositions.pdf},
	Number = {6},
	Pages = {716--752},
	Publisher = {ACM Press},
	Title = {Query Evaluation via Tree-Decompositions},
	Volume = {49},
	Year = {2002}}

@article{Wong1976Decomposition,
	Abstract = {Strategy for processing multivariable queries in the database management system INGRES is considered. The general procedure is to decompose the query into a sequence of one-variable queries by alternating between (a) reduction: breaking off components of the query which are joined to it by a single variable, and (b) tuple substitution: substituting for one of the variables a tuple at a time. Algorithms for reduction and for choosing the variable to be substituted are given. In most cases the latter decision depends on estimation of costs; heuristic procedures for making such estimates are outlined.},
	Address = {New York, NY, USA},
	Author = {Wong, Eugene and Youssefi, Karel},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/320473.320479},
	Issn = {0362-5915},
	Journal = tods,
	Keywords = {query evaluation, decomposition, join processing, RDBMS, relational algebra},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Wong1976Decomposition.pdf},
	Number = {3},
	Pages = {223--241},
	Publisher = {ACM Press},
	Title = {Decomposition---a Strategy for Query Processing},
	Volume = {1},
	Year = {1976}}

@article{Astrahan1976System-R,
	Abstract = {System R is a database management system which provides a high level relational data interface. The systems provides a high level of data independence by isolating the end user as much as possible from underlying storage structures. The system permits definition of a variety of relational views on common underlying data. Data control features are provided, including authorization, integrity assertions, triggered transactions, a logging and recovery subsystem, and facilities for maintaining data consistency in a shared-update environment. This paper contains a description of the overall architecture and design of the system. At the present time the system is being implemented and the design evaluated. We emphasize that System R is a vehicle for research in database architecture, and is not planned as a product.},
	Address = {New York, NY, USA},
	Author = {Astrahan, M. M. and Blasgen, M. W. and Chamberlin, D. D. and Eswaran, K. P. and Gray, J. N. and Griffiths, P. P. and King, W. F. and Lorie, R. A. and McJones, P. R. and Mehl, J. W. and Putzolu, G. R. and Traiger, I. L. and Wade, B. W. and Watson, V.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/320455.320457},
	Issn = {0362-5915},
	Journal = tods,
	Keywords = {relational, RDBMS, System/R, system},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Astrahan1976System-R.pdf},
	Number = {2},
	Pages = {97--137},
	Publisher = {ACM Press},
	Title = {System R: Relational Approach to Database Management},
	Volume = {1},
	Year = {1976}}

@inproceedings{Selinger1979Access-Path-Selection-RDBMS,
	Abstract = {In a high level query and data manipulation language such as SQL, requests are stated non-procedurally, without reference to access paths. This paper describes how System R chooses access paths for both simple (single relation) and complex queries (such as joins), given a user specification of desired data as a boolean expression of predicates. System R is an experimental database management system developed to carry out research on the relational model of data. System R was designed and built by members of the IBM San Jose Research Laboratory.

},
	Address = {New York, NY, USA},
	Author = {Selinger, P. Griffiths and Astrahan, M. M. and Chamberlin, D. D. and Lorie, R. A. and Price, T. G.},
	Booktitle = sigmod,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/582095.582099},
	Isbn = {0-89791-001-X},
	Keywords = {query optimization, query evaluation, System/R, RDBMS, relational},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Selinger1979Access-Path-Selection-RDBMS.pdf},
	Location = {Boston, Massachusetts},
	Pages = {23--34},
	Publisher = {ACM Press},
	Title = {Access Path Selection in a Relational Database Management System},
	Year = {1979}}

@article{Mishra1992Join-Processing-in-Relational-Databases,
	Abstract = {The join operation is one of the fundamental relational database query operations. It facilitates the retrieval of information from two different relations based on a Cartesian product of the two relations. The join is one of the most diffidult operations to implement efficiently, as no predefined links between relations are required to exist (as they are with network and hierarchical systems). The join is the only relational algebra operation that allows the combining of related tuples from relations on different attribute schemes. Since it is executed frequently and is expensive, much research effort has been applied to the optimization of join processing. In this paper, the different kinds of joins and the various implementation techniques are surveyed. These different methods are classified based on how they partition tuples from different relations. Some require that all tuples from one be compared to all tuples from another; other algorithms only compare some tuples from each. In addition, some techniques perform an explicit partitioning, whereas others are implicit.},
	Address = {New York, NY, USA},
	Author = {Mishra, Priti and Eich, Margaret H.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/128762.128764},
	Issn = {0360-0300},
	Journal = csur,
	Keywords = {join, join processing, RDBMS, relational algebra},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Mishra1992Join-Processing-in-Relational-Databases.pdf},
	Number = {1},
	Pages = {63--113},
	Publisher = {ACM Press},
	Title = {Join Processing in Relational Databases},
	Volume = {24},
	Year = {1992}}

@article{Jarke1984Query-Optimization-in-Database-Systems,
	Address = {New York, NY, USA},
	Author = {Jarke, Matthias and Koch, Jurgen},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/356924.356928},
	Issn = {0360-0300},
	Journal = csur,
	Keywords = {query optimization, query evaluation, RDBMS, relational algebra},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Jarke1984Query-Optimization-in-Database-Systems.pdf},
	Number = {2},
	Pages = {111--152},
	Publisher = {ACM Press},
	Title = {Query Optimization in Database Systems},
	Volume = {16},
	Year = {1984}}

@article{Graefe1995Fast-Algorithms-for-Universal-Quantification,
	Abstract = {Universal quantification is not supported directly in most database systems despite the fact that it adds significant power to a system's query processing and inference capabilities, in particular for the analysis of many-to-many relationships and of set-valued attributes. One of the main reasons for this omission has been that universal quantification algorithms and their performance have not been explored for large databases. In this article, we describe and compare three known algorithms and one recently proposed algorithm for relational division, the algebra operator that embodies universal quantification. For each algorithm, we investigate the performance effects of explicit duplicate removal and referential integrity enforcement, variants for inputs larger than memory, and parallel execution strategies. Analytical and experimental performance comparisons illustrate the substantial differences among the algorithms. Moreover, comparisons demonstrate that the recently proposed division algorithm evaluates a universal quantification predicate over two relations as fast as hash (semi-) join evaluates an existential quantification predicate over the same relations. Thus, existential and universal quantification can be supported with equal efficiency by adding the recently proposed algorithm to a query evaluation system. A second result of our study is that universal quantification should be expressed directly in a database query language, because most query optimizers do not recognize the rather indirect formulations available in SQL as relational division and therefore produce very poor evaluation plans for many universal quantification queries.},
	Address = {New York, NY, USA},
	Author = {Graefe, Goetz and Cole, Richard L.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/210197.210202},
	Issn = {0362-5915},
	Journal = tods,
	Keywords = {query evaluation, universal quantification, RDBMS, relational algebra, algorithms},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Graefe1995Fast-Algorithms-for-Universal-Quantification.pdf},
	Number = {2},
	Pages = {187--236},
	Publisher = {ACM Press},
	Rating = {0},
	Title = {Fast Algorithms for Universal Quantification in Large Databases},
	Volume = {20},
	Year = {1995}}

@article{Gradel2002Back-and-Forth-Between-Guarded-and-Modal,
	Abstract = {Guarded fixed-point logic mGF extends the guarded fragment by means of least and greatest fixed points, and thus plays the same role within the domain of guarded logics as the modal m-calculus plays within the modal domain. We provide a semantic characterization of mGF within an appropriate fragment of second-order logic, in terms of invariance under guarded bisimulation. The corresponding characterization of the modal m-calculus, due to Janin and Walukiewicz, is lifted from the modal to the guarded domain by means of model theoretic translations. Guarded second-order logic, the fragment of second-order logic which is introduced in the context of our characterization theorem, captures a natural and robust level of expressiveness with several equivalent characterizations. For a wide range of issues in guarded logics it may take up a role similar to that of monadic second-order in relation to modal logics. At the more general methodological level, the translations between the guarded and modal domains make the intuitive analogy between guarded and modal logics available as a tool in the further analysis of the model theory of guarded logics.},
	Address = {New York, NY, USA},
	Author = {Gr{\"a}del, Erich and Hirsch, Colin and Otto, Martin},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/507382.507388},
	Issn = {1529-3785},
	Journal = tocl,
	Keywords = {guarded fragment, logic, semi-join algebra},
	Number = {3},
	Pages = {418--463},
	Publisher = {ACM Press},
	Title = {Back and Forth Between Guarded and Modal Logics},
	Volume = {3},
	Year = {2002}}

@article{Andreka1998Modal-Languages-and-Bounded-Fragments-of-Predicate,
	Author = {Andr{\'e}ka, Hajnal and van Benthem, Johan and N{\'e}meti, Istv{\'a}n},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {Journal of Philosophical Logic},
	Keywords = {guarded fragment, first order logic, logic, semi-join algebra},
	Number = {3},
	Pages = {217--274},
	Title = {Modal Languages and Bounded Fragments of Predicate Logic},
	Volume = {27},
	Year = {1998}}

@article{Leinders2005Semijoin-Algebra-and-the-Guarded-Fragment,
	Abstract = {In the 1970s Codd introduced the relational algebra, with operators selection, projection, union, difference and product, and showed that it is equivalent to first-order logic. In this paper, we show that if we replace in Codd's relational algebra the product operator by the "semijoin" operator, then the resulting "semijoin algebra" is equivalent to the guarded fragment of first-order logic. We also define a fixed point extension of the semijoin algebra that corresponds to GF.},
	Author = {Leinders, Dirk and Marx, Maarten and Tyszkiewicz, Jerzy and den Bussche, Jan Van},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {Journal of Logic, Language and Information},
	Keywords = {semi-join algebra, logic, guarded fragment, semi-join, algebra},
	Number = {3},
	Pages = {331--343},
	Title = {The Semijoin Algebra and the Guarded Fragment},
	Volume = {14},
	Year = {2005}}

@techreport{REWERSE-TR-2007-01,
	Author = {Berger, Sacha},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {Institute for Computer Science, University of Munich, Germany},
	Number = {REWERSE-TR-2007-01},
	Title = {{An Automaton Model for Xcerpt Type Checking and XML Schema Validation}},
	Type = {{research report}},
	Url = {\url{http://idefix.pms.ifi.lmu.de:8080/rewerse/index.html#REWERSE-TR-2007-01}},
	Year = {2007}}

@inproceedings{PMS-FB-2005-12,
	Author = {Berger, Sacha and Bry, Fran\c{c}ois},
	Booktitle = {Proceedings of 17. Workshop {\"u}ber Grundlagen von Datenbanken, W{\"o}rlitz, Germany (17th--20th May 2005)},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Organization = {GI},
	Title = {{Towards Static Type Checking of Web Query Language}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2005-12},
	Year = {2005}}

@book{Abiteboul2000Data-on-the-Web,
	Address = {San Francisco, CA, USA},
	Author = {Abiteboul, Serge and Buneman, Peter and Suciu, Dan},
	Booktitle = {{Data on the Web: From Relations to Semistructured Data and XML}},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {1-55860-622-X},
	Keywords = {XML, simulation, semi-structured data},
	Publisher = {Morgan Kaufmann Publishers Inc.},
	Title = {{Data on the Web: From Relations to Semistructured Data and XML}},
	Year = {2000}}

@article{Olteanu2007SPEX,
	Author = {Olteanu, Dan},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = tkde,
	Keywords = {SPEX, XML, XML streams, streams, query evaluation, buffering, memory},
	Title = {{SPEX: Streamed and Progressive Evaluation of XPath}},
	Year = {2007}}

@unpublished{hedge01,
	Author = {Br{\"u}ggemann-Klein, A. and Murata, M. and Wood, D.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Month = {April},
	Note = {Technical Report HKUST-TCSC-2001-0, The Hongkong University of Science and Technology},
	Title = {Regular Tree and Regular Hedge Languages over Unranked Alphabets},
	Year = {2001}}

@unpublished{tata99,
	Author = {Common, H. and Dauchet, M. and Gilleron, R. and and D. Lugiez, F. Jacquemard and Tison, S. and Tommasi, M.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Note = {http://www.grappa.univ-lille3.fr/tata/},
	Title = {Tree Automata Techniques and Applications},
	Year = {1999}}

@inproceedings{Buneman2000Query-Optimization-for-Semistructured-Data,
	Address = {London, UK},
	Author = {Buneman, Peter and Fan, Wenfei and Weinstein, Scott},
	Booktitle = dblp,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {3-540-41481-9},
	Keywords = {path constraints, query optimization, integrity constraints, semi-structured data, XML, type-based optimization},
	Pages = {208--223},
	Publisher = {Springer-Verlag},
	Title = {{Query Optimization for Semistructured Data Using Path Constraints in a Deterministic Data Model}},
	Year = {2000}}

@inproceedings{Wood2001Minimising-Simple-XPath-Expressions,
	Abstract = {We consider a subset of XPath expressions, called simple XPath expressions, which correspond to a class of conjunctive queries. We show that, in the absence of a DTD, each simple XPath expression has a unique minimal equivalent expression which can be found in polynomial time. We then consider D-equivalence, the equivalence of expressions with respect to the set of documents valid for a given DTD D. We show that a simple XPath expression P does not necessarily have a unique minimal D-equivalent},
	Author = {Wood, Peter T.},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = webdb,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XPath, minimization, containment, query rewriting, type-based optimization},
	Pages = {13-18},
	Read = {Yes},
	Title = {{Minimising Simple XPath Expressions}},
	Year = {2001}}

@inproceedings{Wood1999Optimising-Web-Queries-using-Document-Type,
	Abstract = {A document type definition (DTD) D defines the structure of elements permitted in any web document valid with respect to D. From a given DTD D we show how to derive a number of simple structural constraints which are implied by D. Using a relational abstraction of web databases, we consider a class of conjunctive queries which retrieve elements from web documents stored in a database D. For simplicity, we assume that all documents in D are valid with respect to the same DTDD. The main contribution of the paper is the use of the constraints derived from D to optimise conjunctive queries on D by removing redundant conjuncts. The relational abstraction allows us to show that the constraints derived from a DTD are equivalent to tuple-generating and equality-generating dependencies which hold on D. Having done so, we can use the chase algorithm to show equivalence between a query and its reduced form.},
	Address = {New York, NY, USA},
	Author = {Wood, Peter T.},
	Booktitle = widm,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/319759.319773},
	Isbn = {1-58113-221-2},
	Keywords = {XPath, XML, DTDs, type-based optimization, minimization, containment},
	Location = {Kansas City, Missouri, United States},
	Pages = {28--32},
	Publisher = {ACM Press},
	Title = {{Optimising Web Queries using Document Type Definitions}},
	Year = {1999}}

@inproceedings{Flesca2003Minimization-of-XPath-Queries,
	Abstract = {XML queries are usually expressed by means of XPath expressions identifying portions of the selected documents. An XPath expression defines a way of navigating an XML tree and returns the set of nodes which are reachable from one or more starting nodes through the paths specied by the expression. The prob- lem of efficiently answering XPath queries is very interesting and has recently received in- creasing attention by the research community. In particular, an increasing effort has been devoted to dene effective optimization tech- niques for XPath queries. One of the main issues related to the optimization of XPath queries is their minimization. The minimiza- tion of XPath queries has been studied for lim- ited fragments of XPath, containing only the descendent, the child and the branch opera- tors. In this work, we address the problem of minimizing XPath queries for a more general fragment, containing also the wildcard oper- ator. We characterize the complexity of the minimization of XPath queries, stating that it is NP-hard, and propose an algorithm for computing minimum XPath queries. More- over, we identify an interesting tractable case and propose an ad hoc algorithm handling the minimization of this kind of queries in poly- nomial time.},
	Author = {Flesca, Sergio and Furfaro, Filippo and Masciari, Elio},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = vldb,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Ee = {http://www.vldb.org/conf/2003/papers/S06P02.pdf},
	Keywords = {XPath, XML, minimization, containment, query rewriting},
	Pages = {153-164},
	Title = {{On the Minimization of XPath Queries}},
	Year = {2003}}

@inproceedings{Su2005Semantic-Query-Optimization-XQuery-Streams,
	Abstract = {We study XML stream-specific schema-based optimization. We assume a widely-adopted automata-based execution model for XQuery evaluation. Criteria are established regarding what schema constraints are useful to a particular query. How to apply multiple optimization techniques on an XQuery is then addressed. Finally we present how to correctly and efficiently execute a plan enhanced with our SQO techniques. Our experimentation on both real and synthetic data illustrates that these techniques bring significant performance improvement with little overhead.},
	Author = {Su, Hong and Rundensteiner, Elke A. and Mani, Murali},
	Booktitle = vldb,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {1-59593-154-6},
	Keywords = {XQuery, XML streams, optimization, query rewriting, pruning, streaming},
	Location = {Trondheim, Norway},
	Pages = {277--288},
	Publisher = {VLDB Endowment},
	Title = {{Semantic Query Optimization for XQuery over XML Streams}},
	Year = {2005}}

@article{Che2006Query-Optimization-XML-Databases,
	Abstract = {While the information published in the form of XML-compliant documents keeps fast mounting up, efficient and effective query processing and optimization for XML have now become more important than ever. This article reports our recent advances in XML structured-document query optimization. In this article, we elaborate on a novel approach and the techniques developed for XML query optimization. Our approach performs heuristic-based algebraic transformations on XPath queries, represented as PAT algebraic expressions, to achieve query optimization. This article first presents a comprehensive set of general equivalences with regard to XML documents and XML queries. Based on these equivalences, we developed a large set of deterministic algebraic transformation rules for XML query optimization. Our approach is unique, in that it performs exclusively deterministic transformations on queries for fast optimization. The deterministic nature of the proposed approach straightforwardly renders high optimization efficiency and simplicity in implementation. Our approach is a logical-level one, which is independent of any particular storage model. Therefore, the optimizers developed based on our approach can be easily adapted to a broad range of XML data/information servers to achieve fast query optimization. Experimental study confirms the validity and effectiveness of the proposed approach.},
	Address = {Secaucus, NJ, USA},
	Author = {Che, Dunren and Aberer, Karl and {\"O}zsu, Tamer},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1007/s00778-005-0172-6},
	Issn = {1066-8888},
	Journal = {The VLDB Journal},
	Keywords = {type-based optimization, heuristic optimisation, algebra, PAT, XQuery},
	Number = {3},
	Pages = {263--289},
	Publisher = {Springer-Verlag New York, Inc.},
	Title = {{Query Optimization in XML Structured-document Databases}},
	Volume = {15},
	Year = {2006}}

@article{Amer-Yahia2002Tree-Pattern-Query-Minimization,
	Address = {Secaucus, NJ, USA},
	Author = {Amer-Yahia, S. and Cho, S. and Lakshmanan, L. V. S. and Srivastava, D.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1007/s00778-002-0076-7},
	Issn = {1066-8888},
	Journal = vldbj,
	Keywords = {XPath, query rewriting, containment, minimization, tree pattern queries},
	Number = {4},
	Pages = {315--331},
	Publisher = {Springer-Verlag New York, Inc.},
	Title = {{Tree Pattern Query Minimization}},
	Volume = {11},
	Year = {2002}}

@inproceedings{Chaudhuri1992Equivalence-Recursive-Nonrecursive-Datalog-Programs,
	Address = {New York, NY, USA},
	Author = {Chaudhuri, Surajit and Vardi, Moshe Y.},
	Booktitle = pods,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/137097.137109},
	Isbn = {0-89791-519-4},
	Keywords = {containment, equivalence, query rewriting, datalog, recursive datalog, decidability},
	Location = {San Diego, California, United States},
	Pages = {55--66},
	Publisher = {ACM Press},
	Title = {{On the Equivalence of Recursive and Nonrecursive Datalog Programs}},
	Year = {1992}}

@inproceedings{Bonatti2004Decidability-Containment-Recursive-Datalog,
	Abstract = {The problem of deciding query containment has important applications in classical query optimization and heterogeneous database systems. Query containment is undecidable for unrestricted recursive queries, and decidable for recursive monadic queries and conjunctive queries over regular path expressions. In this paper, we identify a new class of recursive queries with decidable containment. Our framework extends the aforementioned query classes by supporting recursive predicates with more than two arguments and nonlinear recursion.},
	Address = {New York, NY, USA},
	Author = {Bonatti, Piero A.},
	Booktitle = pods,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1055558.1055600},
	Isbn = {158113858X},
	Keywords = {containment, datalog, recursive datalog, query rewriting, complexity, decidability},
	Location = {Paris, France},
	Pages = {297--306},
	Publisher = {ACM Press},
	Title = {{On the Decidability of Containment of Recursive Datalog Queries - Preliminary Report}},
	Year = {2004}}

@article{Shmueli1993Equivalence-of-Datalog-Undecidable,
	Address = {New York, NY, USA},
	Author = {Shmueli, Oded},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1016/0743-1066(93)90040-N},
	Issn = {0743-1066},
	Journal = jlp,
	Keywords = {equivalence, containment, datalog, decidability, query rewriting},
	Number = {3},
	Pages = {231--241},
	Publisher = {Elsevier Science Inc.},
	Title = {{Equivalence of Datalog Queries is Undecidable}},
	Volume = {15},
	Year = {1993}}

@inproceedings{Levy1997Containment-Queries-with-Complex-Objects,
	Address = {New York, NY, USA},
	Author = {Levy, Alon Y. and Suciu, Dan},
	Booktitle = pods,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/263661.263665},
	Isbn = {0-89791-910-6},
	Keywords = {query rewriting, containment, complex value, type-based optimization},
	Location = {Tucson, Arizona, United States},
	Pages = {20--31},
	Publisher = {ACM Press},
	Title = {{Deciding Containment for Queries with Complex Objects}},
	Year = {1997}}

@article{Klug1988Conjunctive-Queries-Containing-Inequalities,
	Abstract = {Conjunctive queries are generalized so that inequality comparisons can be made between elements of the query. Algorithms for containment and equivalence of such ``inequality queries'' are given, under the assumption that the data domains are dense and totally ordered. In general, containment does not imply the existence of homomorphisms (containment mappings), but the homomorphism property does exist for subclasses of inequality queries. A minimization algorithm is defined using the equivalence algorithm. It is first shown that the constants appearing in a query can be divided into ``essential'' and ``nonessential'' subgroups. The minimum query can be nondeterministically guessed using only the essential constants of the original query.},
	Address = {New York, NY, USA},
	Author = {Klug, Anthony},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/42267.42273},
	Issn = {0004-5411},
	Journal = jacm,
	Keywords = {conjunctive queries, inequality, containment, type-based optimization, evaluation, expressiveness},
	Number = {1},
	Pages = {146--160},
	Publisher = {ACM Press},
	Title = {{On Conjunctive Queries containing Inequalities}},
	Volume = {35},
	Year = {1988}}

@article{Aho1979Efficient-Optimization-Relational-Expressions,
	Abstract = {The design of several database query languages has been influenced by Codd's relational algebra. This paper discusses the difficulty of optimizing queries based on the relational algebra operations select, project, and join. A matrix, called a tableau, is proposed as a useful device for representing the value of a query, and optimization of queries is couched in terms of finding a minimal tableau equivalent to a given one. Functional dependencies can be used to imply additional equivalences among tableaux. Although the optimization problem is NP-complete, a polynomial time algorithm exists to optimize tableaux that correspond to an important subclass of queries.},
	Address = {New York, NY, USA},
	Author = {Aho, A. V. and Sagiv, Y. and Ullman, J. D.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/320107.320112},
	Issn = {0362-5915},
	Journal = tods,
	Keywords = {query rewriting, containment, type-based optimization, conjunctive queries, relational algebra},
	Number = {4},
	Pages = {435--454},
	Publisher = {ACM Press},
	Title = {{Efficient Optimization of a Class of Relational Expressions}},
	Volume = {4},
	Year = {1979}}

@article{Sagiv1980Equivalences-Relational-Expressions-Union-Difference,
	Address = {New York, NY, USA},
	Author = {Sagiv, Yehoshua and Yannakakis, Mihalis},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/322217.322221},
	Issn = {0004-5411},
	Journal = jacm,
	Keywords = {query rewriting, containment, conjunctive queries, union, difference, type-based optimization},
	Number = {4},
	Pages = {633--655},
	Publisher = {ACM Press},
	Title = {{Equivalences Among Relational Expressions with the Union and Difference Operators}},
	Volume = {27},
	Year = {1980}}

@inproceedings{Abiteboul1997Regular-Path-Queries-with-Constraints,
	Address = {New York, NY, USA},
	Author = {Abiteboul, Serge and Vianu, Victor},
	Booktitle = pods,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/263661.263676},
	Isbn = {0-89791-910-6},
	Keywords = {regular path expressions, query rewriting, containment, type-based optimization, complexity},
	Location = {Tucson, Arizona, United States},
	Pages = {122--133},
	Publisher = {ACM Press},
	Title = {{Regular Path Queries with Constraints}},
	Year = {1997}}

@inproceedings{Fernandez1998Optimizing-RPEs-Using-Graph-Schemas,
	Address = {Washington, DC, USA},
	Author = {Fernandez, Mary F. and Suciu, Dan},
	Booktitle = icde,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {0-8186-8289-2},
	Keywords = {type-based optimization, regular path expressions, graph schemata, query rewriting},
	Pages = {14--23},
	Publisher = {IEEE Computer Society},
	Title = {{Optimizing Regular Path Expressions Using Graph Schemas}},
	Year = {1998}}

@article{Chekuri2000Conjunctive-Query-Containment-Revisited,
	Address = {Essex, UK},
	Author = {Chekuri, Chandra and Rajaraman, Anand},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1016/S0304-3975(99)00220-0},
	Issn = {0304-3975},
	Journal = tcs,
	Keywords = {conjunctive queries, containment, acyclic queries, tree-width, complexity, type-based optimization},
	Number = {2},
	Pages = {211--229},
	Publisher = {Elsevier Science Publishers Ltd.},
	Title = {{Conjunctive Query Containment Revisited}},
	Volume = {239},
	Year = {2000}}

@article{Biskup1995Optimization-Subclass-of-Conjunctive-Queries,
	Address = {Secaucus, NJ, USA},
	Author = {Biskup, Joachim and Dublish, Pratul and Sagiv, Yehoshua},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1007/BF01185403},
	Issn = {0001-5903},
	Journal = {Acta Inf.},
	Keywords = {query rewriting, containment, complexity, conjunctive queries},
	Number = {1},
	Pages = {1--26},
	Publisher = {Springer-Verlag New York, Inc.},
	Title = {{Optimization of a Subclass of Conjunctive Queries}},
	Volume = {32},
	Year = {1995}}

@article{Grust2004Accelerating-XPath-Evaluation,
	Abstract = {This article is a proposal for a database index structure, the XPath accelerator, that has been specifically designed to support the evaluation of XPath path expressions. As such, the index is capable to support all XPath axes (including ancestor, following, preceding-sibling, descendant-or-self, etc.). This feature lets the index stand out among related work on XML indexing structures which had a focus on the child and descendant axes only. The index has been designed with a close eye on the XPath semantics as well as the desire to engineer its internals so that it can be supported well by existing relational database query processing technology: the index (a) permits set-oriented (or, rather, sequence-oriented) path evaluation, and (b) can be implemented and queried using well-established relational index structures, notably B-trees and R-trees.We discuss the implementation of the XPath accelerator on top of different database backends and show that the index performs well on all levels of the memory hierarchy, including disk-based and main-memory based database systems.},
	Address = {New York, NY, USA},
	Author = {Grust, Torsten and Keulen, Maurice Van and Teubner, Jens},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/974750.974754},
	Issn = {0362-5915},
	Journal = TODS,
	Keywords = {XML, XPath, pre/post encoding, indexing, evaluation},
	Number = {1},
	Pages = {91--131},
	Publisher = {ACM Press},
	Title = {{Accelerating XPath Evaluation in any RDBMS}},
	Volume = {29},
	Year = {2004}}

@inproceedings{Grust2006MonetDBXQuery,
	Abstract = {Relational XQuery systems try to re-use mature relational data management infrastructures to create fast and scalable XML database technology. This paper describes the main features, key contributions, and lessons learned while implementing such a system. Its architecture consists of (i) a range-based encoding of XML documents into relational tables, (ii) a compilation technique that translates XQuery into a basic relational algebra, (iii) a restricted (order) property-aware peephole relational query optimization strategy, and (iv) a mapping from XML update statements into relational updates. Thus, this system implements all essential XML database functionalities (rather than a single feature) such that we can learn from the full consequences of our architectural decisions. While implementing this system, we had to extend the state-of-the-art with a number of new technical contributions, such as loop-lifted staircase join and efficient relational query evaluation strategies for XQuery theta-joins with existential semantics. These contributions as well as the architectural lessons learned are also deemed valuable for other relational back-end engines. The performance and scalability of the resulting system is evaluated on the XMark benchmark up to data sizes of 11GB. The performance section also provides an extensive benchmark comparison of all major XMark results published previously, which confirm that the goal of purely relational XQuery processing, namely speed and scalability, was met.},
	Address = {New York, NY, USA},
	Author = {Boncz, Peter and Grust, Torsten and van Keulen, Maurice and Manegold, Stefan and Rittinger, Jan and Teubner, Jens},
	Booktitle = sigmod,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1142473.1142527},
	Isbn = {1-59593-434-0},
	Keywords = {XML, XPath, XQuery, evaluation, MonetDB, pathfinder, pre/post encoding,indexing},
	Location = {Chicago, IL, USA},
	Pages = {479--490},
	Publisher = {ACM Press},
	Title = {{MonetDB/XQuery: a fast XQuery Processor powered by a Relational Engine}},
	Year = {2006}}

@article{Ioannidis1995Containment-CQs-Beyond-Relations,
	Address = {New York, NY, USA},
	Author = {Ioannidis, Yannis E. and Ramakrishnan, Raghu},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/211414.211419},
	Issn = {0362-5915},
	Journal = {ACM Transactions on Database Systems},
	Keywords = {containment, conjunctive queries, query rewriting, type-based optimization},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Ioannidis1995Containment-CQs-Beyond-Relations.pdf},
	Number = {3},
	Pages = {288--324},
	Publisher = {ACM Press},
	Title = {{Containment of Conjunctive Queries: Beyond Relations as Sets}},
	Volume = {20},
	Year = {1995}}

@inproceedings{Wei2002Containment-CQs-with-Negation,
	Address = {London, UK},
	Author = {Wei, Fang and Lausen, Georg},
	Booktitle = {Proc. Int. Conf. on Database Theory},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {3-540-00323-1},
	Keywords = {containment, conjunctive queries, negation, query rewriting},
	Pages = {346--360},
	Publisher = {Springer-Verlag},
	Title = {{Containment of Conjunctive Queries with Safe Negation}},
	Year = {2002}}

@inproceedings{Florescu1998Containment-CQ-RegularExpressions,
	Address = {New York, NY, USA},
	Author = {Florescu, Daniela and Levy, Alon and Suciu, Dan},
	Booktitle = {Proc. ACM Symp. on Principles of Database Systems},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/275487.275503},
	Isbn = {0-89791-996-3},
	Keywords = {containment, conjunctive queries, regular expressions, query rewriting},
	Location = {Seattle, Washington, United States},
	Pages = {139--148},
	Publisher = {ACM Press},
	Title = {{Query Containment for Conjunctive Queries with Regular Expressions}},
	Year = {1998}}

@inproceedings{Kolaitis1998Complexity-Containment-CQ-BuiltIn,
	Address = {New York, NY, USA},
	Author = {Kolaitis, Phokion G. and Martin, David L. and Thakur, Madhukar N.},
	Booktitle = {Proc. ACM Symp. on Principles of Database Systems},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/275487.275510},
	Isbn = {0-89791-996-3},
	Keywords = {complexity, containment, query rewriting, conjunctive queries, built-in predicates},
	Location = {Seattle, Washington, United States},
	Pages = {197--204},
	Publisher = {ACM Press},
	Title = {{On the Complexity of the Containment Problem for Conjunctive Queries with built-in Predicates}},
	Year = {1998}}

@inproceedings{Kolaitis1998Conjunctive-Query-Containment,
	Address = {New York, NY, USA},
	Author = {Kolaitis, Phokion G. and Vardi, Moshe Y.},
	Booktitle = {Proc. ACM Symp. on Principles of Database Systems},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/275487.275511},
	Isbn = {0-89791-996-3},
	Keywords = {conjunctive queries, containment, integrity constraints, query rewriting},
	Location = {Seattle, Washington, United States},
	Pages = {205--213},
	Publisher = {ACM Press},
	Title = {{Conjunctive-Query Containment and Constraint Satisfaction}},
	Year = {1998}}

@inproceedings{Calvanese1998Decidability-of-Query-Containment,
	Address = {New York, NY, USA},
	Author = {Calvanese, Diego and Giacomo, Giuseppe De and Lenzerini, Maurizio},
	Booktitle = {Proc. ACM Symp. on Principles of Database Systems},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/275487.275504},
	Isbn = {0-89791-996-3},
	Keywords = {containment, conjunctive queries, integrity constraints, decidability},
	Location = {Seattle, Washington, United States},
	Pages = {149--158},
	Publisher = {ACM Press},
	Title = {{On the Decidability of Query Containment under Constraints}},
	Year = {1998}}

@article{Wadler2000A-Formal-Semantics-of-Patterns-in-XSLT,
	Address = {Cambridge, MA, USA},
	Author = {Wadler, Philip},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1162/10996620052104302},
	Issn = {1099-6621},
	Journal = {Markup Lang.},
	Keywords = {XSLT, XPath, formal semantics, rewriting},
	Number = {2},
	Pages = {183--202},
	Publisher = {MIT Press},
	Title = {{A Formal Semantics of Patterns in XSLT and XPath}},
	Volume = {2},
	Year = {2000}}

@inproceedings{Geneves2004Logic-based-XPath-optimization,
	Abstract = {XPath [5] was introduced by the W3C as a standard language for specifying node selection, matching conditions, and for computing values from an XML document. XPath is now used in many XML standards such as XSLT [4] and the forthcoming XQuery [10] database access language. Since efficient XML content querying is crucial for the performance of almost all XML processing architectures, a growing need for studying high performance XPath-based querying has emerged. Our approach aims at optimizing XPath performance through static analysis and syntactic transformation of XPath expressions.},
	Address = {New York, NY, USA},
	Author = {Geneves, Pierre and Vion-Dury, Jean-Yves},
	Booktitle = {Proc. ACM Symp. on Document Engineering},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1030397.1030437},
	Isbn = {1-58113-938-1},
	Keywords = {XPath, optimization, query rewriting, type-based optimization, INRIA},
	Location = {Milwaukee, Wisconsin, USA},
	Pages = {211--219},
	Publisher = {ACM Press},
	Title = {{Logic-based XPath optimization}},
	Year = {2004}}

@inproceedings{Vion-Dury2003Containment-of-XPath-expressions,
	Abstract = {XPath is simple query language for XML documents which allows navigating in
XML trees and returning a set of matching nodes. It is used in XML Schema to
define keys and in XLink and XPointer to reference portions of documents.
XPath is a fundamental part of the XSLT and XQuery languages as it allows
definition of matching expressions for patterns and provides node selectors to
filter elements in the transformations.
We propose to study the containment and equivalence of XPath expressions
using an inference system combined with a rewriting system. The inference
system allows assertion and proof of properties on a class of expressions. In
order to keep the proof system compact, we propose a re-writing architecture
which allows transformation of remaining expressions in a disjunctive normal
form compatible with this class. In contrast with model based approaches, the
inference and rewriting systems are applied to the XPath language directly. We
believe this will help understanding the underlying issues of deciding
containment on the language itself.},
	Author = {Vion-Dury, Jean-Yves and Layaida, Nabil},
	Booktitle = {Proc. Extreme Markup Languages},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML, XPath, query rewriting, containment, inference, INRIA},
	Publisher = {Mulberry Tech},
	Title = {Containment of XPath expressions: an inference and rewriting based approach},
	Year = {2003}}

@inproceedings{Wood2002Containment-for-XPath-Fragments,
	Address = {London, UK},
	Author = {Wood, Peter T.},
	Booktitle = icdt,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {3-540-00323-1},
	Keywords = {XPath, DTD, query reformulation, fragments, integrity constraints},
	Pages = {300--314},
	Publisher = {Springer-Verlag},
	Title = {{Containment for XPath Fragments under DTD Constraints}},
	Year = {2002}}

@inproceedings{Deutsch2003Reformulation-of-XML-Queries-and-Constraints,
	Abstract = {We state and solve the query reformulation problem for XML
publishing in a general setting that allows mixed (XML and relational)
storage for the proprietary data and exploits redundancies (material-
ized views, indexes and caches) to enhance performance. The correspon-
dence between published and proprietary schemas is specied by views in
both directions, and the same algorithm performs rewriting-with-views,
composition-with-views, or the combined eect of both, unifying the
Global-As-View and Local-As-View approaches to data integration. We
prove a completeness theorem which guarantees that under certain con-
ditions, our algorithm will nd a minimal reformulation if one exists.
Moreover, we identify conditions when this algorithm achieves optimal
complexity bounds. We solve the reformulation problem for constraints
by exploiting a reduction to the problem of query reformulation.},
	Address = {London, UK},
	Author = {Deutsch, Alin and Tannen, Val},
	Booktitle = icdt,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {3-540-00323-1},
	Keywords = {query rewriting, query reformulation, integrity constraints, type-based optimization},
	Pages = {225--241},
	Publisher = {Springer-Verlag},
	Title = {{Reformulation of XML Queries and Constraints}},
	Year = {2003}}

@inproceedings{Abiteboul1998Complexity-of-Answering-Queries-using-Materialized,
	Address = {New York, NY, USA},
	Author = {Abiteboul, Serge and Duschka, Oliver M.},
	Booktitle = {Proc. ACM Symp. on Principles of Database Systems},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/275487.275516},
	Isbn = {0-89791-996-3},
	Keywords = {complexity, views, query evaluation, query answering, view materialization, rewriting},
	Location = {Seattle, Washington, United States},
	Pages = {254--263},
	Publisher = {ACM Press},
	Title = {{Complexity of Answering Queries using Materialized Views}},
	Year = {1998}}

@article{Halevy2001Answering-Queries-using-Views-Survey,
	Address = {Secaucus, NJ, USA},
	Author = {Halevy, Alon Y.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1007/s007780100054},
	Issn = {1066-8888},
	Journal = {The VLDB Journal},
	Keywords = {views, query evaluation, query rewriting, query reformulation, survey},
	Number = {4},
	Pages = {270--294},
	Publisher = {Springer-Verlag New York, Inc.},
	Title = {{Answering Queries using Views: A Survey}},
	Volume = {10},
	Year = {2001}}

@article{Deutsch2006Query-Reformulation-with-Constraints,
	Abstract = {Let S1, S2 be two schemas, which may overlap, C be a set of constraints on the joint schema S1 UNION S2, and q1 be a S1-query. An (equivalent) reformulation of q1 in the presence of C is a S2-query, q2, such that q2 gives the same answers as q1 on any S1 UNION S2-database instance that satisfies C. In general, there may exist multiple such reformulations and choosing among them may require, for example, a cost model.},
	Address = {New York, NY, USA},
	Author = {Deutsch, Alin and Popa, Lucian and Tannen, Val},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1121995.1122010},
	Issn = {0163-5808},
	Journal = {SIGMOD Record},
	Keywords = {query reformulation, rewriting, type-based optimization, integrity constraints},
	Number = {1},
	Pages = {65--73},
	Publisher = {ACM Press},
	Title = {{Query Reformulation with Constraints}},
	Volume = {35},
	Year = {2006}}

@article{Deutsch2005XML-Queries-Containment-and-Reformulation,
	Abstract = {Starting from the XQuery language we define XBind, an XML analog of relational conjunctive
queries as well as a related class of XML integrity constraints (dependencies).We identify a fragment
of XBind for which containment is decidable, in fact p2-complete, and a further fragment for which
containment is NP-complete. We extend the containment algorithm to take XML dependencies into
account. We give an algorithm for the reformulation of XBind queries under combinations of GAV
and LAV XQuery views, as well as additional dependencies.We prove a completeness theorem which
guarantees that under certain conditions, our algorithm will find a minimal reformulation if one exists.
Moreover, we identify conditions when this algorithm achieves optimal complexity bounds. Our
results on containment and reformulation depend on certain restrictions on the query and constraint
languages.We calibrate the results by showing that lifting these restrictions significantly changes the
complexity of the problems.},
	Address = {Essex, UK},
	Author = {Deutsch, Alin and Tannen, Val},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1016/j.tcs.2004.10.032},
	Issn = {0304-3975},
	Journal = {Theoretical Computer Science},
	Keywords = {XML, XPath, containment, integrity constraints, rewriting, type-based optimization},
	Number = {1},
	Pages = {57--87},
	Publisher = {Elsevier Science Publishers Ltd.},
	Title = {{XML Queries and Constraints, Containment and Reformulation}},
	Volume = {336},
	Year = {2005}}

@inproceedings{Neven2002XPath-Containment,
	Abstract = {XPath is a simple language for navigating an XML tree and returning a set of answer nodes. The focus in this paper is on the complexity of the containment problem for various fragments of XPath. In addition to the basic operations (child, descendant, filter, and wildcard), we consider disjunction, DTDs and variables. W.r.t. variables we study two semantics: (1) the value of variables is given by an outer context; (2) the value of variables is defined existentially. We establish an almost complete classification of the complexity of the containment problem w.r.t. these fragments.},
	Address = {London, UK},
	Author = {Neven, Frank and Schwentick, Thomas},
	Booktitle = {Proc. Int. Conf. on Database Theory},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {3-540-00323-1},
	Keywords = {XPath, containment, complexity, type-based optimization, optimization},
	Pages = {315--329},
	Publisher = {Springer-Verlag},
	Title = {{XPath Containment in the Presence of Disjunction, DTDs, and Variables}},
	Year = {2002}}

@inproceedings{Martens2004Complexity-Decisions-Regular-Expressions,
	Abstract = {We study the complexity of the inclusion, equivalence, and intersection problem for simple regular expressions arising in practical XML schemas. These basically consist of the concatenation of factors where each factor is a disjunction of strings possibly extended with ` ' or ` '. We obtain lower and upper bounds for various fragments of simple regular expressions. Although we show that inclusion and intersection are already intractable for very weak expressions, we also identify some tractable cases. For equivalence, we only prove an initial tractability result leaving the complexity of more general cases open. The main motivation for this research comes from database theory, or more specifically XML and semi-structured data. We namely show that all lower and upper bounds for inclusion and equivalence, carry over to the corresponding decision problems for extended context-free grammars and single-type tree grammars, which are abstractions of DTDs and XML Schemas, respectively. For intersection, we show that the complexity only carries over for DTDs.},
	Author = {Martens, Wim and Neven, Frank and Schwentick, Thomas},
	Booktitle = {Proc. Int. Symp. on Mathematical Foundations of Computer Science},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {complexity, rewriting, equivalence, containment, schema, XML Schema, DTDs},
	Pages = {889--900},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{Complexity of Decisions Problems for Simple Regular Expressions}},
	Volume = {3153},
	Year = {2004}}

@article{Habib2000Lex-BFS-and-Partition-Refinement,
	Abstract = {By making use of a lexicographic breadth first search (Lex-BFS) and partition refinement with pivots, we obtain very simple algorithms for some well-known problems in graph theory. 
We give an O(n + m log n) algorithm for transitive orientation of a comparability graph, and simple linear algorithms to recognize interval graphs, convex graphs, Y-semichordal graphs and matrices that have the consecutive-ones property. 
Previous approaches to these problems used difficult preprocessing steps, such as computing PQ trees or modular decomposition. The algorithms we give are easy to understand and straightforward to prove. They do not make use of sophisticated data structures, and the complexity analysis is straightforward.},
	Address = {Essex, UK},
	Author = {Habib, Michel and McConnell, Ross and Paul, Christophe and Viennot, Laurent},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1016/S0304-3975(97)00241-7},
	Issn = {0304-3975},
	Journal = {Theoretical Computer Science},
	Keywords = {interval graphs, consecutive ones property, graph theory},
	Number = {1-2},
	Pages = {59--84},
	Publisher = {Elsevier Science Publishers Ltd.},
	Title = {{Lex-BFS and Partition Refinement, with Applications to Transitive Orientation, Interval Graph Recognition and Consecutive Ones Testing}},
	Volume = {234},
	Year = {2000}}

@inproceedings{Hsu2001PC-Trees-vs-PQ-Trees,
	Abstract = {A data structure called PC-tree is introduced as a generalization of PQ-trees. PC-trees were originally introduced in a planarity test of Shih and Hsu where they represent partial embeddings of planar graphs. PQ-trees were invented by Booth and Lueker to test the consecutive ones property in matrices. The original implementation of the PQ-tree algorithms by Booth and Lueker using nine templates in each bottom-up iteration is rather complicated. Also the complexity analysis is rather intricate. We give a very simple PC-tree algorithm with the following advantages: (1) it does not use any template; (2) it does all necessary operations at each iteration in one batch and does not involve the cumbersome bottom-up operation. PC-trees can be used naturally to test the circular ones property in matrices. And the induced PQ-tree algorithm can considerably simplify Booth and Lueker's modification of Lempel, Even and Cederbaum's planarity test.},
	Author = {Hsu, Wen-Lian},
	Booktitle = {Proc. Int'l. Conf. on Computing and Combinatorics},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {consecutive ones property, circular ones property, linear graphs, PQ trees, PC trees},
	Series = {LNCS},
	Title = {{PC-Trees vs. PQ-Trees}},
	Volume = {2108},
	Year = {2001}}

@article{Fulkerson1965Incidence-Matrices-and-Interval-Graphs,
	Abstract = {According to present genetic theory, the fine structure of genes consists of linearly ordered elements. A mutant gene is obtained by alteration of some connected portion of this structure. By examining data obtained from suitable experiments, it can be determined whether or not the blemished portions of two mutant genes intersect or not, and thus intersection data for a large number of mutants can be represented as an undirected graph. If this graph is an "interval graph," then the observed data is consistent with a linear model of the gene. 
The problem of determining when a graph is an interval graph is a special case of the following problem concerning (0, l)-matrices: When can the rows of such a matrix be per- muted so as to make the l's in each column appear consecutively? A complete theory is obtained for this latter problem, culminating in a decomposition theorem which leads to a rapid algorithm for deciding the question, and for constructing the desired permutation when one exists.
},
	Author = {Fulkerson, D. R. and Gross, O. A.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {Pacific Journal of Mathematics},
	Keywords = {consecutive ones property, interval graphs, graph theory},
	Number = {3},
	Pages = {835--855},
	Title = {{Incidence Matrices and Interval Graphs}},
	Volume = {15},
	Year = {1965}}

@article{Gottlob2006Conjunctive-Queries-over-Trees,
	Abstract = {We study the complexity and expressive power of conjunctive queries over unranked labeled trees 
represented using a variety of structure relations such as ``child'', ``descendant'', and ``following'' 
as well as unary relations for node labels. We establish a framework for characterizing structures 
representing trees for which conjunctive queries can be evaluated efficiently. Then we completely 
chart the tractability frontier of the problem and establish a dichotomy theorem for our axis 
relations, i.e., we find all subset-maximal sets of axes for which query evaluation is in polynomial 
time and show that for all other cases, query evaluation is NP-complete. All polynomial-time 
results are obtained immediately using the proof techniques from our framework. Finally, we 
study the expressiveness of conjunctive queries over trees and show that for each conjunctive 
query, there is an equivalent acyclic positive query (i.e., a set of acyclic conjunctive queries), but 
that in general this query is not of polynomial size. },
	Author = {Gottlob, Georg and Koch, Christoph and Schulz, Klaus U.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {Journal of the ACM},
	Keywords = {complexity, query evaluation, tree, conjunctive queries},
	Number = {2},
	Title = {{Conjunctive Queries over Trees}},
	Volume = {53},
	Year = {2006}}

@article{Hsu2002Simple-Test-for-Consecutive-Ones-Property,
	Abstract = {A (0, 1)-matrix satisfies the consecutive ones property if there exists a column permutation such that the ones in each row of the resulting matrix are consecutive. Booth and Lueker (1976, J. Comput. System Sci. 13, 335-378) designed a linear time- testing algorithm for this property based on a data structure called "PQ-trees." This procedure is quite complicated and the linear-time-amortized analysis is also rather involved. We developed an off-line linear time test for the consecutive ones property without using PQ-trees and the corresponding template matching, which makes ours considerably simpler. A simplification of the consecutive ones test will immediately simplify algorithms (and computer codes) for interval-graph and planar-graph recognition. Our approach is based on a decomposition technique that separates the rows into prime subsets, each of which admits essentially a unique column ordering that realizes the consecutive ones property. The success of this approach is based on finding a good "row ordering" to be tested iteratively.},
	Address = {Duluth, MN, USA},
	Author = {Hsu, Wen-Lian},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1006/jagm.2001.1205},
	Issn = {0196-6774},
	Journal = {Journal of Algorithms},
	Keywords = {consecutive ones property, linear graphs, algorithm,},
	Number = {1},
	Pages = {1--16},
	Publisher = {Academic Press, Inc.},
	Title = {{A Simple Test for the Consecutive Ones Property}},
	Volume = {43},
	Year = {2002}}

@inproceedings{Booth1975Linear-Interval-Graphs-Consecutive-Ones,
	Abstract = {A matrix of zeroes and ones is said to have the consecutive ones property if there is a permutation of its rows such that the ones in each column appear consecutively. This paper develops a data structure which may be used to test a matrix for the consecutive ones property, and produce the desired permutation of the rows, in linear time. One application of the consecutive ones property is in recognizing interval graphs. A graph is an interval graph if there exists a 1-1 correspondence between its vertices and a set of intervals on the real line such that two vertices are adjacent if and only if the corresponding intervals have a nonempty intersection. Fulkerson and Gross have characterized interval graphs as those for which the clique versus vertex incidence matrix has the consecutive ones property. In testing this particular matrix for the consecutive ones property we may process the columns in a special order to simplify the algorithm. This yields the interval graph recognition algorithm which is presented in section 2; section 3 indicates how this algorithm may be extended to the general consecutive ones problem.},
	Address = {New York, NY, USA},
	Author = {Booth, Kellogg S. and Lueker, George S.},
	Booktitle = {Proc. of ACM Symposium on Theory of Computing},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/800116.803776},
	Keywords = {interval graphs, consecutive ones property, complexity, linear, intervals},
	Location = {Albuquerque, New Mexico, United States},
	Pages = {255--265},
	Publisher = {ACM Press},
	Title = {{Linear Algorithms to Recognize Interval Graphs and Test for the Consecutive Ones Property}},
	Year = {1975}}

@inproceedings{Foggia2001GraphIsomorphism,
	Author = {Foggia, P. and Sansone, C. and Vento, M.},
	Booktitle = {Proc. Int'l. Workshop on Graph-based Representations},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {VF2, graph isomorphism, fast, complexity},
	Title = {{An Improved Algorithm for Matching Large Graphs}},
	Year = {2001}}

@inproceedings{McKay1980Practical-Graph-Isomorphism,
	Author = {McKay, B. D.},
	Booktitle = {Proc. Conf. on Numerical Mathematics and Computing},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {graph isomorphism, nauty, fast, complexity},
	Title = {{Practical Graph Isomorphism}},
	Year = {1980}}

@inproceedings{Hopcroft1974IsomorphismPlanarGraphs,
	Abstract = {The isomorphism problem for graphs G1 and G2 is to determine if there
exists a one-to-one mapping of the vertices of G1 onto the vertices of
G2 such that two vertices of G1 are adjacent if and only if their
images in G2 are adjacent. In addition to determining the existence of
such an isomorphism, it is useful to be able to produce an
isomorphism-inducing mapping in the case where one exists. The
isomorphism problem for triconnected planar graphs is particularly
simple since a triconnected planar graph has a unique embedding on a
sphere [6]. Weinberg [5] exploited this fact in developing an
algorithm for testing isomorphism of triconnected planar graphs in
O(|V|2) time where V is the set consisting of the vertices of both
graphs. The result has been extended to arbitrary planar graphs and
improved to O(|V|log|V|) steps by Hopcroft and Tarjan [2,3]. In this
paper, the time bound for planar graph isomorphism is improved to
O(|V|). In addition to determining the isomorphism of two planar
graphs, the algorithm can be easily extended to partition a set of
planar graphs into equivalence classes of isomorphic graphs in time
linear in the total number of vertices in all graphs in the set. A
random access model of computation (see Cook [1]) is assumed. Although
the proposed algorithm has a linear asymptotic growth rate, at the
present stage of development it appears to be inefficient on account
of a rather large constant. This paper is intended only to establish
the existence of a linear algorithm which subsequent work might make
truly efficient.
},
	Address = {New York, NY, USA},
	Author = {Hopcroft, J. E. and Wong, J. K.},
	Booktitle = {Proc. ACM Symposium on Theory of Computing},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/800119.803896},
	Keywords = {complexity, tree isomorphism, graph isomorphism, planar graphs, linear, algorithm},
	Location = {Seattle, Washington, United States},
	Pages = {172--184},
	Publisher = {ACM Press},
	Title = {{Linear time algorithm for isomorphism of planar graphs}},
	Year = {1974}}

@techreport{Horrocks2004SWRL:-A-Semantic-Web-Rule-Language-Combining,
	Abstract = {This document contains a proposal for a Semantic Web Rule Language (SWRL) based on a combination of the OWL DL and OWL Lite sublanguages of the OWL Web Ontology Language with the Unary/Binary Datalog RuleML sublanguages of the Rule Markup Language. SWRL includes a high-level abstract syntax for Horn-like rules in both the OWL DL and OWL Lite sublanguages of OWL. A model-theoretic semantics is given to provide the formal meaning for OWL ontologies including rules written in this abstract syntax. An XML syntax based on RuleML and the OWL XML Presentation Syntax as well as an RDF concrete syntax based on the OWL RDF/XML exchange syntax are also given, along with several examples.
},
	Author = {Horrocks, Ian and Patel-Schneider, Peter F. and Boley, Harold and Tabet, Said and Grossof, Benjamin and Dean, Mike},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {SWRL, rules, ontologies, OWL, RuleML},
	Title = {{SWRL: A Semantic Web Rule Language Combining OWL and RuleML}},
	Type = {Member Submission},
	Url = {http://www.w3.org/Submission/SWRL/},
	Year = {2004}}

@article{Rossati2005On-the-Decidability-and-Complexity-of-Integrating-Ontologies-and-Rules,
	Author = {Rossati, Ricardo},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {Journal of Web Semantics},
	Keywords = {complexity, description logics, OWL, rules, integration, decidability},
	Number = {1},
	Pages = {61--73},
	Title = {{On the Decidability and Complexity of Integrating Ontologies and Rules}},
	Volume = {3},
	Year = {2005}}

@inproceedings{Eiter2006Effective-Integration-of-Declarative-Rules-with,
	Author = {Eiter, Thomas and Ianni, Giovambattista and Schindlauer, Roman and Tompits, Hans},
	Booktitle = {Proc. European Conf. on Semantic Web},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {dlvhex, rules, ontologies, external predicates, integration},
	Title = {{Effective Integration of Declarative Rules with External Evaluations for Semantic Web Reasoning}},
	Year = {2006}}

@inproceedings{Bry2006Efficient-Evaluation-of-n-ary-Conjunctive-Queries,
	Abstract = {N-ary conjunctive queries, i.e., queries with any number of answer variables, are the formal core of many Web query languages including XSLT, XQuery, SPARQL, and Xcerpt. Despite a considerable body of research on the optimization of such queries over tree-shaped XML data, little attention has been paid so far to efficient access to graph-shaped XML, RDF, or Topic Maps. We propose the first evaluation technique for n-ary conjunctive queries that applies to both tree- and graph-shaped data and retains the same complexity as the best known approaches that are restricted to tree-shaped data only. Furthermore, the approach treats tree and graph-shaped queries uniformly without sacrificing evaluation complexity on the restricted query class. The core of the evaluation technique is based on dynamic programming using a memoization data structure, called "memoization matrix". It can be populated and consumed in different ways. For each of population and consumption, we propose two resp. three algorithms each having their own advantages. The complexity of the algorithms is compared analytically and experimentally.},
	Author = {Bry, Fran\c{c}ois and Furche, Tim and Linse, Benedikt and Schroeder, Andreas},
	Booktitle = widm,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {complexity, evaluation, conjunctive queries, trees, graphs},
	Publisher = {ACM Press},
	Title = {{Efficient Evaluation of n-ary Conjunctive Queries over Trees and Graphs}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2006-32},
	Year = {2006}}

@article{Dantsin2001Complexity-and-Expressive-Power-of-Logic-Programming,
	Abstract = {This article surveys various complexity and expressiveness results on different forms of logic programming. The main focus is on decidable forms of logic programming, in particular, propositional logic programming and datalog, but we also mention general logic programming with function symbols. Next to classical results on plain logic programming (pure Horn clause programs), more recent results on various important extensions of logic programming are surveyed. These include logic programming with different forms of negation, disjunctive logic programming, logic programming with equality, and constraint logic programming.},
	Address = {New York, NY, USA},
	Author = {Dantsin, Evgeny and Eiter, Thomas and Gottlob, Georg and Voronkov, Andrei},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 12:37:35 +0200},
	Doi = {http://doi.acm.org/10.1145/502807.502810},
	Issn = {0360-0300},
	Journal = {ACM Comput. Surv.},
	Keywords = {complexity, expressiveness, conjunctive queries, datalog, non-recursive, logic programming},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Dantsin2001Complexity-and-Expressive-Power-of-Logic-Programming.pdf},
	Number = {3},
	Pages = {374--425},
	Publisher = {ACM Press},
	Title = {{Complexity and Expressive Power of Logic Programming}},
	Volume = {33},
	Year = {2001}}

@book{Kobler1993Graph-Isomorphism-Complexity,
	Author = {K{\"o}bler, Johannes and Sch{\"o}ning, Uwe and Tor{\'a}n, Jacobo},
	Booktitle = {{The Graph Isomorphism Problem: Its Structural Complexity}},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {graph isomorphism,complexity,problem,theoretical foundations,},
	Publisher = {Birkh{\"a}user/Springer-Verlag},
	Series = {Progress in Theoretical Computer Science},
	Title = {{The Graph Isomorphism Problem: Its Structural Complexity}},
	Year = {1993}}

@book{Aho1974Design-Analysis-Computer-Algorithms,
	Address = {Boston, MA, USA},
	Author = {Aho, Alfred V. and Hopcroft, John E. and Ullman, Jeffrey D.},
	Booktitle = {{The Design and Analysis of Computer Algorithms}},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {0201000296},
	Keywords = {algorithms, design, analysis, tree isomorphism},
	Publisher = {Addison-Wesley Longman Publishing Co., Inc.},
	Title = {{The Design and Analysis of Computer Algorithms}},
	Year = {1974}}

@inproceedings{Nash2004Unions-of-CQs-Negation,
	Abstract = {We study the problem of answering queries over sources with limited access patterns. The problem is to decide whether a given query Q is feasible, i.e., equivalent to an executable query Q' that observes the limited access patterns given by the sources. We characterize the complexity of deciding feasibility for the classes CQ[not] (conjunctive queries with negation) and UCQ[not] (unions of CQ[not] queries): Testing feasibility is just as hard as testing containment and therefore Pi[p]2-complete. We also provide a uniform treatment for CQ, UCQ, CQ[not], and UCQ[not] by devising a single algorithm which is optimal for each of these classes. In addition, we show how one can often avoid the worst-case complexity by certain approximations: At compile-time, even if a query Q is not feasible, we can find efficiently the minimal executable query containing Q. For query answering at runtime, we devise an algorithm which may report complete answers even in the case of infeasible plans and which can indicate to the user the degree of completeness for certain incomplete answers.},
	Author = {Nash, Alan and Lud{\"a}scher, Bertram},
	Booktitle = {Proc. Extending Database Technology},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {conjunctive queries, unions of conjunctive queries, access patterns, negation},
	Number = {2992},
	Pages = {422--440},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{Processing Unions of Conjunctive Queries with Negation under Limited Access Patterns}},
	Year = {2004}}

@article{Atserias2006Homomorphisms-Unions-of-CQs,
	Address = {New York, NY, USA},
	Author = {Atserias, Albert and Dawar, Anuj and Kolaitis, Phokion G.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1131342.1131344},
	Issn = {0004-5411},
	Journal = {J. ACM},
	Keywords = {conjunctive queries, CQ, UCQ, unions of conjunctive queries, homomorphism},
	Number = {2},
	Pages = {208--237},
	Publisher = {ACM Press},
	Title = {{On Preservation under Homomorphisms and Unions of Conjunctive Queries}},
	Volume = {53},
	Year = {2006}}

@article{Bitton.DeWitt_DupElim_TODS_1983,
	Author = {Bitton, Dina and DeWitt, David J.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/319983.319987},
	Issn = {0362-5915},
	Journal = {ACM Transactions on Database Systems},
	Number = {2},
	Pages = {255--265},
	Publisher = {ACM Press},
	Title = {Duplicate record elimination in large data files},
	Volume = {8},
	Year = {1983}}

@article{dechter87csp,
	Address = {Essex, UK},
	Author = {Dechter, R. and Pearl, J.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {Int. J. on Artificial Intelligence},
	Number = {1},
	Pages = {1--38},
	Publisher = {Elsevier Science Publishers Ltd.},
	Title = {Network-based heuristics for constraint-satisfaction problems},
	Volume = {34},
	Year = {1987}}

@inproceedings{Yannakakis1981Algorithms-for-Acyclic-Database-Schemes,
	Author = {Yannakakis, M.},
	Booktitle = {Proc. Int. Conf. on Very Large Data Bases},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {conjunctive queries, complexity, acyclic queries, tree queries},
	Pages = {82--94},
	Title = {{Algorithms for Acyclic Database Schemes}},
	Year = {1981}}

@inproceedings{Chandra1977Conjunctive-Queries-in-RelationalSTOC,
	Abstract = { We define the class of conjunctive queries in relational data bases, and the generalized join operator on relations. The generalized join plays an important part in answering conjunctive queries, and it can be implemented using matrix multiplication. It is shown that while answering conjunctive queries is NP complete (general queries are PSPACE complete), one can find an implementation that is within a constant of optimal. The main lemma used to show this is that each conjunctive query has a unique minimal equivalent query (much like minimal finite automata).
},
	Address = {New York, NY, USA},
	Author = {Chandra, Ashok K. and Merlin, Philip M.},
	Booktitle = stoc,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/800105.803397},
	Keywords = {complexity, conjunctive queries, first order queries, minimization, query evaluation},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Chandra1977Conjunctive-Queries-in-RelationalSTOC.pdf},
	Location = {Boulder, Colorado, United States},
	Pages = {77--90},
	Publisher = {ACM Press},
	Title = {{Optimal Implementation of Conjunctive Queries in Relational Data Bases}},
	Year = {1977}}

@inproceedings{Grohe2001Evaluation-of-conjunctive-queriesSTOC,
	Abstract = { We define the class of conjunctive queries in relational data bases, and the generalized join operator on relations. The generalized join plays an important part in answering conjunctive queries, and it can be implemented using matrix multiplication. It is shown that while answering conjunctive queries is NP complete (general queries are PSPACE complete), one can find an implementation that is within a constant of optimal. The main lemma used to show this is that each conjunctive query has a unique minimal equivalent query (much like minimal finite automata).
},
	Address = {New York, NY, USA},
	Author = {Grohe, Martin and Schwentick, Thomas and Segoufin, Luc},
	Booktitle = {Proc. ACM Symp. on Theory of Computing},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/380752.380867},
	Isbn = {1-58113-349-9},
	Keywords = {conjunctive queries, tree-width, complexity, relational queries, parameterized complexity},
	Location = {Hersonissos, Greece},
	Pages = {657--666},
	Publisher = {ACM Press},
	Title = {{When is the Evaluation of Conjunctive Queries Tractable?}},
	Year = {2001}}

@inproceedings{Ianni2004Answer-Set-Programming-with-Templates,
	Abstract = {The work aims at extending Answer Set Programming (ASP) with the possibility of quickly introducing new predefined constructs and to deal with compound data structures: we show how ASP can be extended with `template' predicate's definitions. We present language syntax and give its operational semantics. We show that the theory supporting our ASP extension is sound, and that program encodings are evaluated as efficiently as ASP programs. Examples show how the extended language increases declarativity, readability, compactness of program encodings and code reusability.},
	Author = {Ianni, Giovambattista and Ielpa, Giuseppe and Pietramala, Adriana and Santoro, Maria Carmela and Calimeri, Francesco},
	Booktitle = {Proc. Int'l. Workshop on Non-Monontonic Reasoning},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {answer-set programming, templates, generics, reuse, modularization},
	Title = {{Enhancing Answer Set Programming with Templates}},
	Url = {http://www.pims.math.ca/science/2004/NMR/papers/paper31.pdf},
	Year = {2004}}

@article{Neven2002Expressiveness-of-Structured-Document-Query-Languages,
	Author = {Neven, Frank and van den Bussche, Jan},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = jacm,
	Keywords = {XML,semi-structured,grammar,attribute grammar,derivation tree,query language,formal,expressiveness},
	Number = {1},
	Organization = {ACM Press},
	Pages = {56--100},
	Title = {{Expressiveness of Structured Document Query Languages Based on Attribute Grammars}},
	Volume = {49},
	Year = {2002}}

@article{Slivinskas2002Bringing-Order-to-Query-Optimization,
	Abstract = {A variety of developments combine to highlight the need for respecting order when manipulating relations. For example, new functionality is being added to SQL to support OLAP-style querying in which order is frequently an important aspect. The set- or multiset-based frameworks for query optimization that are currently being taught to database students are increasingly inadequate.This paper presents a foundation for query optimization that extends existing frameworks to also capture ordering. A list-based relational algebra is provided along with three progressively stronger types of algebraic equivalences, concrete query transformation rules that obey the different equivalences, and a procedure for determining which types of transformation rules are applicable for optimizing a query. The exposition follows the style chosen by many textbooks, making it relatively easy to teach this material in continuation of the material covered in the textbooks, and to integrate this material into the textbooks.},
	Author = {Slivinskas, Giedrius and Jensen, Christian S. and Snodgrass, Richard T.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {SIGMOD Record},
	Keywords = {order,sequence,query optimization,relational},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Slivinskas2002Bringing-Order-to-Query-Optimization.pdf},
	Number = {2},
	Organization = {ACM Press},
	Pages = {5--14},
	Title = {{Bringing Order to Query Optimization}},
	Volume = {31},
	Year = {2002}}

@article{Bille2005Survey-Tree-Edit-Distance,
	Abstract = {We survey the problem of comparing labeled trees based on simple local operations of deleting, inserting, and relabeling nodes. These operations lead to the tree edit distance, alignment distance, and inclusion problem. For each problem we review the results available and present, in detail, one or more of the central algorithms for solving the problem.},
	Address = {Essex, UK},
	Author = {Bille, Philip},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1016/j.tcs.2004.12.030},
	Issn = {0304-3975},
	Journal = {Theoretical Computer Science},
	Keywords = {tree edit,tree inclusion,complexity,tree},
	Number = {1-3},
	Pages = {217--239},
	Publisher = {Elsevier Science Publishers Ltd.},
	Title = {{A Survey on Tree Edit Distance and Related Problems}},
	Volume = {337},
	Year = {2005}}

@article{Matousek1992Complexity-of-Finding-Isomorphisms-Trees,
	Address = {Amsterdam, The Netherlands, The Netherlands},
	Author = {Matou{\v s}ek, Ji{\v r}{\'\i} and Thomas, Robin},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1016/0012-365X(92)90687-B},
	Issn = {0012-365X},
	Journal = {Discrete Mathematics},
	Keywords = {isomorphism,tree inclusion,unordered tree inclusion,unordered,complexity},
	Number = {1-3},
	Pages = {343--364},
	Publisher = {Elsevier Science Publishers B. V.},
	Title = {{On the Complexity of Finding Iso- and other Morphisms for Partial k-trees}},
	Volume = {108},
	Year = {1992}}

@inproceedings{Halevy2006Principles-of-Dataspace-Systems,
	Abstract = {The most acute information management challenges today stem from organizations relying on a large number of diverse, interrelated data sources, but having no means of managing them in a convenient, integrated, or principled fashion. These challenges arise in enterprise and government data management, digital libraries, "smart" homes and personal information management. We have proposed dataspaces as a data management abstraction for these diverse applications and DataSpace Support Platforms (DSSPs) as systems that should be built to provide the required services over dataspaces. Unlike data integration systems, DSSPs do not require full semantic integration of the sources in order to provide useful services. This paper lays out specific technical challenges to realizing DSSPs and ties them to existing work in our field. We focus on query answering in DSSPs, the DSSP's ability to introspect on its content, and the use of human attention to enhance the semantic relationships in a dataspace.},
	Address = {New York, NY, USA},
	Annote = {* Form of data integration system, but no upfront semantic integration needed. 
* Rather: base functionality regardless of the integration of data sources
* More sophisticated operations require better integration, "pay-as-you-go"},
	Author = {Halevy, Alon and Franklin, Michael and Maier, David},
	Booktitle = {Proc. ACM Symposium on Principles of Database Systems},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1142351.1142352},
	Isbn = {1-59593-318-2},
	Keywords = {dataspace, distributed data, data integration, personal information management},
	Location = {Chicago, IL, USA},
	Pages = {1--9},
	Publisher = {ACM Press},
	Title = {{Principles of Dataspace Systems}},
	Year = {2006}}

@article{Kilpelainen1995TreeInclusion,
	Abstract = {The following tree-matching problem is considered: Given labeled trees $P$ and $T$, can $P$ be obtained from $T$ by deleting nodes? Deleting a node $u$ entails removing all edges incident to $u$ and, if $u$ has a parent $v$, replacing the edge from $v$ to $u$ by edges from $v$ to the children of $u$. The problem is motivated by the study of query languages for structured text databases. Simple solutions to this problem require exponential time. For ordered trees an algorithm is presented that requires $O(|P| |T|)$ time and space. The corresponding problem for unordered trees is also considered and a proof of its NP-completeness is given. An algorithm is presented for the unordered problem. This algorithm works in $O(|P| |T|)$ time if the out-degrees of the nodes in $P$ are bounded by a constant, and in polynomial time if they are $O(\log |T|)$.},
	Address = {Philadelphia, PA, USA},
	Author = {Kilpelainen, Pekka and Mannila, Heikki},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1137/S0097539791218202},
	Issn = {0097-5397},
	Journal = {SIAM J. Comput.},
	Keywords = {XML, tree queries, complexity, tree inclusion, injectivity},
	Number = {2},
	Pages = {340--356},
	Publisher = {Society for Industrial and Applied Mathematics},
	Title = {{Ordered and Unordered Tree Inclusion}},
	Volume = {24},
	Year = {1995}}

@article{Beeri1983Acyclic-Database-Schemes,
	Address = {New York, NY, USA},
	Author = {Beeri, Catriel and Fagin, Ronald and Maier, David and Yannakakis, Mihalis},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/2402.322389},
	Issn = {0004-5411},
	Journal = {Journal of the ACM},
	Keywords = {conjunctive queries, semi-joins, tree queries, relational theory},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Beeri1983On%20the%20Desirability%20of%20Acyclic%20Database%20Schemes},
	Number = {3},
	Pages = {479--513},
	Publisher = {ACM Press},
	Title = {{On the Desirability of Acyclic Database Schemes}},
	Volume = {30},
	Year = {1983}}

@inproceedings{Franconi_RDFSemantics_PPSWR2005,
	Author = {de Bruijn, Jos and Franconi, Enrico and Tessaris, Sergio},
	Booktitle = {Workshop on Principles and Practice of Semantic Web Reasoning},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {RDF Semantics reconstruction},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{Logical Reconstruction of RDF and Ontology Languages}},
	Volume = {3703},
	Year = {2005}}

@inproceedings{Lu_TwigDewey_VLDB_2005,
	Abstract = {Finding all the occurrences of a twig pattern in an XML database is a core operation for efficient evaluation of XML queries. A number of algorithms have been proposed to process a twig query based on region encoding labeling scheme. While region encoding supports efficient determination of structural relationship between two elements, we observe that the information within a single label is very limited. In this paper, we propose a new labeling scheme, called extended Dewey. This is a powerful labeling scheme, since from the label of an element alone, we can derive all the elements names along the path from the root to the element. Based on extended Dewey, we design a novel holistic twig join algorithm, called TJFast. Unlike all previous algorithms based on region encoding, to answer a twig query, TJFast only needs to access the labels of the leaf query nodes. Through this, not only do we reduce disk access, but we also support the efficient evaluation of queries with wildcards in branching nodes, which is very difficult to be answered by algorithms based on region encoding. Finally, we report our experimental results to show that our algorithms are superior to previous approaches in terms of the number of elements scanned, the size of intermediate results and query performance.},
	Author = {Lu, Jiaheng and Ling, Tok Wang and Chan, Chee-Yong and Chen, Ting},
	Booktitle = {Proc. Int'l. Conf. on Very Large Data Bases},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {1-59593-154-6},
	Keywords = {XML query optimization evaluation twig holistic joins dewey tree encoding},
	Location = {Trondheim, Norway},
	Pages = {193--204},
	Publisher = {VLDB Endowment},
	Title = {{From Region Encoding to Extended Dewey: On Efficient Processing of XML Twig Pattern Matching}},
	Year = {2005}}

@article{Bry_XChange_JWE_2006,
	Abstract = {Reactivity on the Web is an emerging research issue covering: updating data on the Web, exchanging information about events (such as executed updates) between Web sites, and reacting to combinations of such events. Reactivity plays an important role for upcoming Web systems such as online marketplaces, adaptive Web and Semantic Web systems, as well as Web services and Grids. This article introduces the paradigms upon which the high-level language XChange for programming reactive behaviour and distributed applications on the Web relies. Then, it briefly presents the main syntactical constructs of XChange and their declarative and operational semantics.},
	Author = {Bry, Fran{\c c}ois and Eckert, Michael and P{\u a}tr{\^a}njan, Paula-Lavinia},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {Journal of Web Engineering},
	Number = {1},
	Pages = {3--24},
	Title = {{Reactivity on the Web: Paradigms and Applications of the Language XChange}},
	Url = {http://www.pms.ifi.lmu.de/publikationen#PMS-FB-2006-3},
	Volume = {5},
	Year = {2006}}

@inproceedings{Bry_TenTheses_RLI_2005,
	Abstract = {This articles discusses the logic, or logic-based, languages required for a full deployment of the Semantic Web. It presents ten theses addressing (1) the kinds of logic languages needed, (2) data and data processing, (3) semantics, and (4) engineering and rendering issues.},
	Author = {Bry, Fran{\c c}ois and Marchiori, Massimo},
	Booktitle = {Proc. of W3C Workshop on Rule Languages for Interoperability},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Organization = {W3C},
	Title = {{Ten Theses on Logic Languages for the Semantic Web}},
	Url = {http://www.pms.ifi.lmu.de/publikationen#PMS-FB-2005-7},
	Year = {2005}}

@mastersthesis{Linse_XQuery2Xcerpt_DA_2006,
	Author = {Linse, Benedikt},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XQuery Xcerpt translation nested construction},
	School = {Institute for Informatics, University of Munich},
	Title = {{Automatic Translation between XQuery and Xcerpt}},
	Type = {{Diplomarbeit/Master thesis}},
	Url = {http://www.pms.ifi.lmu.de/publikationen#DA_Benedikt.Linse},
	Year = {2006}}

@inproceedings{Regin_AllDifferent_AAAI_1994,
	Abstract = {Many real-life Constraint Satisfaction Problems (CSPs) involve some constraints similar to the alldifferent constraints. These constraints are called constraints of difference. They are defined on a subset of variables by a set of tuples for which the values occuring in the same tuple are all different. In this paper, a new filtering algorithm for these constraints is presented. It achieves the generalized arc-consistency condition for these non-binary constraints. It is based on matching theory and its complexity is low. In fact, for a constraint defined on a subset of p variables having domains of cardinality at most d, its space complexit is O(pd) and its time complexity is O(p2d2). This filtering algorithm has been successfully used in the system RESYN, to solve the subgraph isomorphism problem.},
	Author = {R{\'e}gin, Jean-Charles},
	Booktitle = {Proc. Conf. on Artificial Intelligence},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Editor = {AAAI},
	Keywords = {evaluation, optimization, CSP, all-different, inequality, injectivity},
	Pages = {362--367},
	Title = {{A Filtering Algorithm for Constraints of Difference in CSPs}},
	Year = {1994}}

@book{Abiteboul1995Foundations-of-Databases,
	Abstract = {This database theory book provides a focused presentation of the core material on relational databases, and presents a number of advanced topics in a unified framework. Some of the advanced material has never before been presented in book form. The style is rigorous, with detailed proofs and many exercises. The text and numerous examples highlight the intuition underlying the development. As a textbook, the book is aimed at graduate students and seniors who would use it as the main text in a database theory course, or as complementary material in a database systems course. It can also serve as a reference for database researchers and for other computer scientists interested in databases.},
	Address = {Boston, MA, USA},
	Annote = {Database theory is a relative newcomer to the field of computer science. Early data management systems were based on techniques from several classical areas of computer science, ranging from hardware and operating systems to data structures and programming languages. In the early seventies, a leap of abstraction from file systems produced relational databases and its accompanying theory, with logic as the catalyst. We believe that database theory has matured--that is has emerged as an elegant and robust part of science with its own identity. As such, it embodies its own peculiar brand of wisdom that deserves to be communicated not just to insiders, but to the computer science community at large.
In a nutshell, a database management system is a software system that enables the creation, maintenance, and use of large amounts of data. In contrast with many programming applications, the logical data structure--the "database schema"--used to structure a given data set is usually much smaller than the volume of that set. Furthermore, the data is persistent, evolving over time and surviving multiple invocations of the database management software. To increase usability, concurrent access to the data is usually supported with specialized protocols that guarantee a form of noninterference between interleaved transactions. Importantly, modern database management systems embody a distinction between the logical level and the physical level. The logical level focuses on an abstract representation of the data, along with languages to create, query and modify it; the physical level focuses on the underlying implementation, including the physical layout used to store the data, the indexing and clustering schemes, and the concurrency and recovery protocols.

Database theory has developed primarily around the logical level of database. (A notable exception is concurrency control, which is not addressed in this volume.) A core of fundamental material on the relational model has become well established. It consists primarily of three paradigms for query languages (algebraic, calculus-based, and deductive) and the theory of dependencies. The theory of query languages, including issues of expressiveness and complexity specific to databases, is well developed. The marriage between databases and logic programming produced deductive databases, with the main focus on the deductive query languages. Dependency theory focused initially on formalizing and applying the disparate integrity constraints that commonly arise in practice, and it went on to relate constraints with query optimization and to develop a unifying perspective for them.

As a field, database theory draws on several areas, including mathematical logic, complexity, and programming languages. But the database context brings with it different assumptions, perspectives, and emphases. Relations can be viewed as predicates in the sense of logic, and the relational calculus as a specialization of the first-order predicate calculus. However, the database area emphasizes finite structures and has developed the notions of "domain independence" and "safety" to capture intuitive properties related to this finitude. The questions and techniques in dependency theory borrow heavily from logic., with a focus on practically motivated, relatively weak classes of sentences. Query languages provide an interesting contrast with conventional, imperative programming languages. Query languages typically embody a set-at-a-time focus as opposed to an object-at-a-time focus. Also, they are largely declarative in nature, and failing that, are more applicative than imperative. Because of the emphasis on tractability in the face of large volumes of data, there is considerable interest in query languages that do not have full computational power, which gives rise to a rich interplay between query languages and complexity theory. Specialized notions of complexity have arisen, stemming from the practical reality of large volumes of data and the theoretical interest in different query languages. Also, the important notion of 'genericity," which captures a form of abstraction stemming from the separation of the logical and physical levels, has led to new perspectives on complexity theory, involving formalisms that circumvent the ordering of input data implicit in traditional Turing machines.

Exciting new research directions have continued to emerge in database theory, stemming primarily from unanswered questions about query languages and from an interest in expanding beyond the limitations of the relational model. Current research includes investigations motivated by connections with object-orientation, artificial intelligence, and graphics interfaces. And as the database field matures, it, in turn, influences adjacent areas in computer science, notably finite model theory, programming languages, and logic programming.},
	Author = {Abiteboul, Serge and Hull, Richard and Vianu, Victor},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {0-201-53771-0},
	Keywords = {database theory, complexity, query languages, datalog, magic sets, QSQ, negation},
	Publisher = addison,
	Title = {{Foundations of Databases}},
	Url = {http://db.bell-labs.com/user/hull/FoundDB.html},
	Year = {1995}}

@mastersthesis{Schroeder_Algebra_DA_2005,
	Author = {Schroeder, Andreas},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML Xcerpt optimization algebra efficicency},
	School = {Institute for Informatics, University of Munich},
	Title = {{An Algebra and Optimization Techniques for Simulation Unification}},
	Type = {{Diplomarbeit/Master thesis}},
	Url = {http://www.pms.ifi.lmu.de/publikationen#DA_Andreas.Schroeder},
	Year = {2005}}

@techreport{Pepper_RDFTM_W3C_2006,
	Author = {Pepper, Steve and Vitali, Fabio and Garshol, Lars Marius and Gessa, Nicola and Presutti, Valentina},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {RDF Topic Maps interoperability versatility conversion},
	Title = {{A Survey of RDF/Topic Maps Interoperability Proposals}},
	Type = {Working Group Note},
	Url = {http://www.w3.org/TR/rdftm-survey/},
	Year = {2006}}

@inproceedings{Furche_XMLRDF_GVD_2005,
	Author = {Furche, Tim and Bry, Fran{\c c}ois and Bolzer, Oliver},
	Booktitle = {Proc. GI-Workshop on Grundlagen von Datenbanken},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML RDF transformation integration veratility serialization},
	Pages = {43-47},
	Title = {{XML Perspectives on RDF Querying: Towards integrated Access to Data and Metadata on the Web}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2005-13},
	Year = {2005}}

@inproceedings{Furche_MarriagesRDF_PPSWR_2005,
	Author = {Furche, Tim and Bry, Fran{\c c}ois and Bolzer, Oliver},
	Booktitle = ppswr,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {RDF XML versatility triple graphs logical view},
	Pages = {72-84},
	Publisher = springer,
	Series = lncs,
	Title = {{Marriages of Convenience: Triples and Graphs, RDF and XML}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2005-38},
	Volume = {3703},
	Year = {2005}}

@article{Zloof_Query-by-Example-DataBase_IBMSJ_1977,
	Abstract = {Discussed is a high-level data base management language that provides the user with a convenient and unified interface to query, update, define, and control a data base. When the user performs an operation against the data base, he fills in an example of a solution to that operation in skeleton tables that can be associated with actual tables in the data base. The system is currently being used experimentally for various applications.},
	Author = {Zloof, Moshe M.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {IBM Systems Journal},
	Myurl = {http://www.research.ibm.com/j ournal/sj/164/ibmsj1604C.pdf},
	Number = {4},
	Pages = {324--343},
	Title = {{Query By Example: A Data Base Language}},
	Volume = {16},
	Year = {1977}}

@techreport{Backett_Turtle_2005,
	Abstract = {he Resource Description Framework (RDF) is a general-purpose language for representing information in the Web.

This document defines a text syntax for RDF called Turtle as an extension of the N-Triples ([N-TRIPLES]) test case format carefully taking the most useful and appropriate things added from Notation 3 ([NOTATION3]) while keeping the syntax describing only RDF graphs.},
	Author = {Backett, Dave},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {RDF syntax text serialization},
	Title = {{Turtle---Terse RDF Triple Language}},
	Url = {http://www.w3.org/2001/sw/DataAccess/df1/},
	Year = {2005}}

@inproceedings{Beckett_Modernising_2004,
	Annote = {The Resource Description Framework (RDF) web metadata format has an XML syntax RDF/XML which has been described as a ugly and flawed, mainly as a consequence of it being an early XML format, dating from 1998. This presentation will describe the perceived and real problems and select appropriate modern XML and web best practices for improving RDF markup that can be better used with the latest XML technologies such as XSLT 2 and XQuery.

The presentation will distinguish a semantic web markup format rather than a format intended solely for software as one intended to be easier for end users to author and more clearly be appropriate for typical application areas of lightweight web metadata and authored web ontologies.

XML best practice in any area is a tricky subject to discuss and get agreement on but the XML technologies considered include XML Namespaces, XML QNames in content, omitting some darker corners of the XML specification along with use of clear user-friendly technologies such as the RELAXNG grammar-based XML schema language, part of the ISO DSDL work. The presentation will also discuss approaches starting from XHTML to generate semantic web data.},
	Author = {Backett, Dave},
	Booktitle = {Proc XML Europe},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {RDF serialization format RXR XML},
	Month = {April},
	Myurl = {http://www.idealliance.org/pa pers/dx_xmle04/papers/03-08-0 3/03-08-03.html},
	Title = {{Modernising Semantic Web Markup}},
	Year = {2004}}

@techreport{Adida_RDFA_W3C_2006,
	Abstract = {This document introduces the RDF/A syntax for expressing RDF metadata within XHTML. The reader is expected to be fairly familiar with XHTML, and somewhat familiar with RDF.

This is an internal draft produced by the RDF-in-HTML task force [RDFHTML], a joint task force of the Semantic Web Best Practices and Deployment Working Group [SWBPD-WG] and HTML Working Group [HTML-WG].

This document is for internal review only and is subject to change without notice. This document has no formal standing within the W3C.},
	Author = {Adida, Ben and Birbeck, Mark},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {RDF XHTML metadata embedding syntax serialization},
	Title = {{RDF/A Primer 1.0---Embedding RDF in XHTML}},
	Type = {Internal Draft},
	Url = {http://www.w3.org/2001/sw/BestPractices/HTML/2006-01-24-rdfa-primer},
	Year = {2006}}

@techreport{W3C_RDFXML_Rec_2004,
	Abstract = {The Resource Description Framework (RDF) is a general-purpose language for representing information in the Web.

This document defines an XML syntax for RDF called RDF/XML in terms of Namespaces in XML, the XML Information Set and XML Base. The formal grammar for the syntax is annotated with actions generating triples of the RDF graph as defined in RDF Concepts and Abstract Syntax. The triples are written using the N-Triples RDF graph serializing format which enables more precise recording of the mapping in a machine processable form. The mappings are recorded as tests cases, gathered and published in RDF Test Cases.},
	Author = {Beckett, Dave and McBride, Brian},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {RDF syntax RDF/XML serialization},
	Organization = {W3C},
	Title = {{RDF/XML Syntax Specification (Revised)}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/rdf-synt ax-grammar/},
	Year = {2004}}

@techreport{W3C_XInclude_Rec_2004,
	Abstract = {This document specifies a processing model and syntax for general purpose inclusion. Inclusion is accomplished by merging a number of XML information sets into a single composite infoset. Specification of the XML documents (infosets) to be merged and control over the merging process is expressed in XML-friendly syntax (elements, attributes, URI references).},
	Author = {Marsh, Jonathan and Orchard, David},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {XML inclusion transformation recommendation},
	Organization = {W3C},
	Title = {{XML Inclusions (XInclude) Version 1.0}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/xinclude/},
	Year = {2004}}

@inproceedings{PatelSchneider_XMLSyntaxRDFSemantics_WWW_2002,
	Abstract = {XML is the W3C standard document format for writing and exchanging information on the Web. RDF is the W3C standard model for describing the semantics and reasoning about information on the Web. Unfortunately, RDF and XML---although very close to each other---are based on two different paradigms. We argue that in order to lead the Semantic Web to its full potential, the syntax and the semantics of information needs to work together. To this end, we develop a model-theoretic semantics for the XML XQuery 1.0 and XPath 2.0 Data Model, which provides a unified model for both XML and RDF. This unified model can serve as the basis for Web applications that deal with both data and semantics. We illustrate the use of this model on a concrete information integration scenario. Our approach enables each side of the fence to benefit from the other, notably, we show how the RDF world can take advantage of XML query languages, and how the XML world can take advantage of the reasoning capabilities available for RDF.},
	Author = {Patel-Schneider, Peter and Simeon, Jerome},
	Booktitle = {Proc. Intl. World Wide Web Conference},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML RDF data model semantics integration},
	Month = {May},
	Title = {{The Yin/Yang Web: XML Syntax and RDF Semantics}},
	Url = {http://www2002.org/CDROM/refereed/231/},
	Year = {2002}}

@techreport{McGuiness_OWL_W3C_2004,
	Author = {McGuinness, Deborah L. and van Harmelen, Frank},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {OWL, RDF, ontology, description logics, W3C},
	Title = {{OWL Web Ontology Language---Overview}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/owl-features/},
	Year = {2004}}

@techreport{Brickley_RDFS_W3C_2004,
	Author = {Brickley, Dan and Guha, R.V.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {RDF RDFS ontology schema vocabulary},
	Title = {{RDF Vocabulary Description Language}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/rdf-schema/},
	Year = {2004}}

@inproceedings{Berger_ea_TypingXcerpt_PPSWR2005,
	Author = {Berger, Sacha and Coquery, Emmanuel and Drabent, W\lodzimierz and Wilk, Artur},
	Booktitle = {Proc. of Workshop on Principles and Practice of Semantic Web Reasoning},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML xcerpt typing R2G2},
	Number = {3703},
	Organization = {REWERSE},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{Descriptive Typing Rules for Xcerpt}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2005-39},
	Year = {2005}}

@article{Gottlob2001The-Complexity-of-Acyclic-Conjunctive-Queries,
	Abstract = {This paper deals with the evaluation of acyclic Boolean conjunctive queries in relational databases. By well-known results of Yannakakis [1981], this problem is solvable in polynomial time; its precise complexity, however, has not been pinpointed so far. We show that the problem of evaluating acyclic Boolean conjunctive queries is complete for LOGCFL, the class of decision problems that are logspace-reducible to a context-free language. Since LOGCFL is contained in AC1 and NC2, the evaluation problem of acyclic Boolean conjunctive queries is highly parallelizable. We present a parallel database algorithm solving this problem with a logarithmic number of parallel join operations. The algorithm is generalized to computing the output of relevant classes of non-Boolean queries. We also show that the acyclic versions of the following well-known database and AI problems are all LOGCFL-complete: The Query Output Tuple problem for conjunctive queries, Conjunctive Query Containment, Clause Subsumption, and Constraint Satisfaction. The LOGCFL-completeness result is extended to the class of queries of bounded treewidth and to other relevant query classes which are more general than the acyclic queries.},
	Address = {New York, NY, USA},
	Author = {Gottlob, Georg and Leone, Nicola and Scarcello, Francesco},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/382780.382783},
	Group = {Matrix Method},
	Issn = {0004-5411},
	Journal = {Journal of the ACM},
	Keywords = {hypertree decomposition, acyclic queries, complexity, tractability},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Gottlob2001The-Complexity-of-Acyclic-Conjunctive-Queries.pdf},
	Number = {3},
	Pages = {431--498},
	Publisher = {ACM Press},
	Title = {{The Complexity of Acyclic Conjunctive Queries}},
	Url = {http://portal.acm.org/citation.cfm?id=382783},
	Volume = {48},
	Year = {2001}}

@inproceedings{Filiot_ComposingMonadicQueries_PLANX2006,
	Abstract = {Node selection in trees is a fundamental operation to XML databases, programming languages, and information extraction. We propose a new class of querying languages to define n-ary node selection queries as compositions of monadic queries. The choice of the underlying monadic querying language is parametric. We show that compositions of monadic MSO-definable queries capture n-ary MSO-definable queries, and distinguish an MSO-complete n-ary query language that enjoys an efficient query answering algorithm.},
	Author = {Filiot, Emmanuel and Niehren, Joachim and Talbot, Jean-Marc and Tison, Sophie},
	Booktitle = {Proc. Intl. Workshop on Programming Language Technologies for XML},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Group = {Matrix Method},
	Title = {{Composing Monadic Queries in Trees}},
	Url = {http://www.lifl.fr/~filiot/publiprivate/Plan-X-final-version.pdf},
	Year = {2006}}

@inproceedings{Abraham.Chaudhari.ea_XMLQueryAlgebra_10C_2004,
	Abstract = {For querying the XML data, XQuery is nowadays
	 accepted as the language of choice. However, no query algebra for XML
	 is not yet accepted widely. In this paper, we discuss the need for
	 and progress of query algebras as well as the specific requirements
	 of semi-structured data. Next, we introduce various algebras that
	 have been proposed to date with a particular emphasis on Niagara
	 Algebra. We discuss implementation of the operators in the Niagara
	 algebra. This paper proposes an improvement to the logical view of
	 the selection operator. We demonstrate the improvement due to our
	 implementation by experimental results. We find that the degree of
	 improvement depends on the nature of the XML data. The new operator is
	 particularly better at working with data that has a large number of elements
	 that need to be unnested in order to run a select. In addition, it
	 shows a significant improvement in situations where a large number of
	 elements must be evaluated to check if the selection criteria are met.},
	Author = {Abraham, Jacob and Chaudhari, Narendra S. and Prakash, Edmond C.},
	Booktitle = {IEEE Int. Region 10 Conference (TENCON)},
	Conference-Abbr = {TENCON},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XQuery algebra operators implementation survey},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Abraham.Chaudhari.ea_XMLQueryAlgebra_TENCON_2004.pdf},
	Title = {{XML Query Algebra Operators, and Strategies for their Implementation}},
	Url = {http://www.ntu.edu.sg/home/asnarendra/lect_slides/SwatiFiles/TENCON04-Jacob.pdf},
	Year = {2004}}

@inproceedings{AlKhalifa.Jagadish_MultiLevelOp_CIKM_2002,
	Abstract = {A core set of efficient access methods is central to the development of
	 any database system. In the context of an XML database, there has
	 been considerable effort devoted to defining a good set of primitive
	 operators and inventing efficient access methods for each individual
	 operator. These primitive operators have been defined either at the
	 macro-level (using a "pattern tree" to specify a selection, for example)
	 or at the micro-level (using multiple explicit containment joins
	 to instantiate a single XPath expression).In this paper we argue
	 that it is valuable to consider operations at each level. We do this
	 through a study of operator merging: the development of a new access
	 method to implement a combination of two or more primitive operators.
	 It is frequently the case that access methods for merged operators
	 are superior to a pipelined execution of separate access methods
	 for each operator. We show operator merging to be valuable at both
	 the micro-level and the macro-level. Furthermore, we show that the
	 corresponding merged operators are hard to reason with at the other
	 level.Specifically, we consider the influence of projections and set
	 operations on pattern-based selections and containment joins. We show,
	 through both analysis and extensive experimentation, the benefits of
	 considering these operations all together. Even though our experimental
	 verification is only with a native XML database, we have reason to believe
	 that our results apply equally to RDBMS-based XML query engines.},
	Address = {New York, NY, USA},
	Author = {Al-Khalifa, Shurug and Jagadish, H. V.},
	Booktitle = {Proc. Int. Conf. Information and Knowledge Management},
	Conference-Abbr = {CIKM},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/584792.584817},
	Isbn = {1-58113-492-4},
	Keywords = {XML XQuery algebra selection operators granularity},
	Location = {McLean, Virginia, USA},
	Pages = {134--141},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Al-Khalifa.Jagadish_Multi-levelOperatorCombination_CIKM_2002.pdf},
	Publisher = {ACM Press},
	Title = {{Multi-level Operator Combination in XML Query Processing}},
	Url = {http://www.eecs.umich.edu/db/timber/files/cikm02.pdf},
	Year = {2002}}

@inproceedings{Al-Khalifa.Jagadish.ea_StructJoins_ICDE_2002,
	Abstract = {XML queries typically specify patterns of selection predicates on multiple
	 elements that have some specified tree structured relationships.
	 The primitive tree structured relationships are parent-child and
	 ancestor-descendant, and finding all occurrences of these relationships in an
	 XML database is a core operation for XML query processing.In this
	 paper, we develop two families of structural join algorithms for this
	 task: tree-merge and stack-tree. The tree-merge algorithms are a
	 natural extension of traditional merge joins and the recently proposed
	 multi-predicate merge joins, while the stack-tree algorithms have no
	 counterpart in traditional relational join processing. We present
	 experimental results on a range of data and queries using the TIMBER
	 native XML query engine built on top of SHORE. We show that while, in
	 some cases, tree-merge algorithms can have performance comparable to
	 stack-tree algorithms, in many cases they are considerably worse.
	 This behavior is explained by analytical results that demonstrate
	 that, on sorted inputs, the stack-tree algorithms have worst-case I/O
	 and CPU complexities linear in the sum of the sizes of inputs and
	 output, while the tree-merge algorithms do not have the same guarantee.},
	Address = {Washington, DC, USA},
	Author = {Al-Khalifa, Shurug and Jagadish, H. V. and Koudas, Nick and Patel, Jignesh M. and Srivastava, Divesh and Wu, Yuqing},
	Booktitle = {Proc. Int. Conf. on Data Engineering},
	Conference-Abbr = {ICDE},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML join processing operators algebra query optimization},
	Pages = {141},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/StructuralJoins/Al-Khalifa.Jagadish.ea_StructJoins_ICDE_2002.pdf},
	Publisher = {IEEE Computer Society},
	Title = {{Structural Joins: A Primitive for Efficient XML Query Pattern Matching}},
	Url = {http://www.eecs.umich.edu/~jignesh/publ/xmljoin-ICDE.pdf},
	Year = {2002}}

@inproceedings{AmerYahia.Cho.ea_MinimizingTreePat_SIGMOD_2001,
	Abstract = {Tree patterns form a natural
	 basis to query tree-structured data such as XML and LDAP. Since the
	 efficiency of tree pattern matching against a tree-structured database
	 depends on the size of the pattern, it is essential to identify and
	 eliminate redundant nodes in the pattern and do so as quickly as
	 possible. In this paper, we study tree pattern minimization both in the
	 absence and in the presence of integrity constraints (ICs) on the
	 underlying tree-structured database. When no ICs are considered, we
	 call the process of minizing a tree pattern, constraint-independent
	 minimization. We develop a polynomial time algorithm called CIM for this
	 purpose. CIM's efficiency stems from two key properties: (i) a node
	 cannot be redundant unless its children are, and (ii) the order of
	 elimination of redundant nodes is immaterial. When ICs are considered for
	 minimization, we refer to it as constraint-dependent minimization.
	 For tree-structured databases, required child/descendant andd type
	 co-occurrence ICs are very natural. Under such ICs, we show that the
	 minimal equivalent query is unique. We show the surprising result
	 that the algorithm obtained by first augmenting the tree pattern
	 using ICs, and then applying CIM, always finds the unique minimal
	 equivalent query; we refer to this algorithm as ACIM. While ACIM is
	 also polynomial time, it can be expensive in practice because of its
	 inherent non-locality. We then present a fast algorithm, CDM, that
	 identifies and eliminates local redundancies due to ICs, based on
	 propagating "information labels" up the tree pattern. CDM can be
	 applied prior to ACIM for improving the minimization efficiency. We
	 complement our analytical results with an experimental study that
	 shows the effectiveness of our tree pattern minimization techniques.},
	Address = {New York, NY, USA},
	Author = {Amer-Yahia, Sihem and Cho, SungRan and Lakshmanan, Laks V. S. and Srivastava, Divesh},
	Booktitle = sigmod,
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/375663.375730},
	Isbn = {1-58113-332-4},
	Keywords = {XML tree pattern queries minimization},
	Location = {Santa Barbara, California, United States},
	Pages = {497--508},
	Pdf = {QueryEvaluation/XML/Containment/AmerYahia.Cho.ea_MinimizingTreePat_SIGMOD_2001.pdf},
	Publisher = {ACM Press},
	Title = {{Minimization of Tree Pattern Queries}},
	Url = {http://portal.acm.org/citation.cfm?id=375730},
	Year = {2001}}

@inproceedings{Babcock.Chaudhuri_RobustOpti_SIGMOD_2005,
	__Markedentry = {0},
	Abstract = {Research on query optimization has focused almost exclusively
	 on reducing query execution time, while important qualities such
	 as consistency and predictability have largely been ignored, even
	 though most database users consider these qualities to be at least as
	 important as raw performance. In this paper, we explore how the query
	 optimization process can be made more robust, focusing on the important
	 subproblem of cardinality estimation. The robust cardinality estimation
	 technique that we propose allows for a user- or application-specified
	 trade-off between performance and predictability, and it captures
	 multi-dimensional correlations while remaining space- and time-efficient.},
	Address = {New York, NY, USA},
	Author = {Babcock, Brian and Chaudhuri, Surajit},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of Dataime},
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1066157.1066172},
	Isbn = {1-59593-060-4},
	Keywords = {query optimization query evaluation robustness},
	Location = {Baltimore, Maryland},
	Pages = {119--130},
	Pdf = {QueryEvaluation/Babcock.Chaudhuri_RobustOpti_SIGMOD_2005.pdf},
	Publisher = {ACM Press},
	Title = {{Towards a Robust Query Optimizer: A Principled and Practical Approach}},
	Url = {http://portal.acm.org/citation.cfm?id=1066157.1066172},
	Year = {2005}}

@inproceedings{Babu.Bizarro.ea_ProactiveReopt_SIGMOD_2005,
	Abstract = {Traditional query optimizers rely
	 on the accuracy of estimated statistics to choose good execution
	 plans. This design often leads to suboptimal plan choices for complex
	 queries, since errors in estimates for intermediate subexpressions
	 grow exponentially in the presence of skewed and correlated data
	 distributions. Re-optimization is a promising technique to cope with such
	 mistakes. Current re-optimizers first use a traditional optimizer
	 to pick a plan, and then react to estimation errors and resulting
	 suboptimalities detected in the plan during execution. The effectiveness of
	 this approach is limited because traditional optimizers choose plans
	 unaware of issues affecting re-optimization. We address this problem
	 using proactive re-optimization, a new approach that incorporates
	 three techniques: (1) the uncertainty in estimates of statistics is
	 computed in the form of bounding boxes around these estimates, (2) these
	 bounding boxes are used to pick plans that are robust to deviations
	 of actual values from their estimates, (3) accurate measurements
	 of statistics are collected quickly and efficiently during query
	 execution. We present an extensive evaluation of these techniques using
	 a prototype proactive re-optimizer named Rio. In our experiments
	 Rio outperforms current re-optimizers by up to a factor of three.},
	Author = {Babu, Shivnath and Bizarro, Pedro and DeWitt, David},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML algebra query optimization query plan},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Babu.Bizarro.ea_ProactiveReopt_SIGMOD_2005.pdf},
	Title = {{Proactive Re-Optimization}},
	Url = {http://dbpubs.stanford.edu:8090/pub/2005-6},
	Year = {2005}}

@inproceedings{BarYossef.Fontoura.ea_MemReqXPath_PODS_2004,
	Abstract = {The important challenge of evaluating XPath queries
	 over XML streams has sparked much interest in the past two years, A
	 number of algorithms have been proposed, supporting wider fragments of
	 the query language, and exhibiting better performance and memory
	 utilization. Nevertheless, all the algorithms known to date use a
	 prohibitively large amount of memory for certain types of queries. A natural
	 question then is whether this memory bottleneck is inherent or just
	 an artifact of the proposed algorithms.In this paper we initiate
	 the first systematic and theoretical study of lower bounds on the
	 amount of memory required to evaluate XPath queries over XML streams.
	 We present a general lower bound technique, which given a query,
	 specifies the minimum amount of memory that any algorithm evaluating the
	 query on a stream would need to incur. The lower bounds are stated in
	 terms of new graph-theoretic properties of queries. The proof is
	 based on tools from communication complexity.We then exploit insights
	 learned from the lower bounds to obtain a new algorithm for XPath
	 evaluation on streams. The algorithm uses space close to the optimum. Our
	 algorithm deviates from the standard paradigm of using automata or
	 transducers, thereby avoiding the need to store large transition tables.},
	Address = {New York, NY, USA},
	Author = {Bar-Yossef, Ziv and Fontoura, Marcus and Josifovski, Vanja},
	Booktitle = {Proc. ACM SIGMOD Symposium on Principles of Database Systems},
	Conference-Abbr = {PODS},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1055558.1055584},
	Isbn = {158113858X/04/06},
	Keywords = {XML XPath memory complexity stream},
	Location = {Paris, France},
	Pages = {177--188},
	Pdf = {QueryEvaluation/XML/Comlexity/BarYossef.Fontoura.ea_MemReqXPath_PODS_2004.pdf},
	Publisher = {ACM Press},
	Title = {{On the Memory Requirements of XPath Evaluation over XML Streams}},
	Url = {http://www.ee.technion.ac.il/people/zivby/papers/xml/xmlfull.pdf},
	Year = {2004}}

@inproceedings{Beeri.Tzaban_SAL_WebDB_1999,
	Abstract = {--},
	Author = {Beeri, Catriel and Tzaban, Yariv},
	Booktitle = {Proc. Int. Workshop on the Web and Databases},
	Conference-Abbr = {WebDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML SAL algebra semi-structured XAL},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Beeri.Tzaban_SAL_WebDB_1999.pdf},
	Title = {{SAL: An Algebra for Semistructured Data and XML}},
	Url = {http://www-rocq.inria.fr/~cluet/WEBDB/beeri.ps},
	Year = {1999}}

@article{Berlea.Seidl_BinaryQueriesDocument_NJC_2004,
	Abstract = {Motivated by XML applications, we address the problem of answering k-ary queries, i.e.
	 simultaneously locating k nodes of an input tree as specified by a given
	 relation. In particular, we discuss how binary queries can be used as a
	 means of navigation in XML document transformations. We introduce a
	 grammar-based approach to specifying k-ary queries. An efficient
	 tree-automata based implementation of unary queries is reviewed and the
	 extensions needed in order to implement k-ary queries are presented. In
	 particular, an efficient solution for the evaluation of binary queries
	 is provided and proven correct. We introduce fxgrep, a practical
	 implementation of unary and binary queries for XML. By means of fxgrep
	 and of the fxt XML transformation language we suggest how binary
	 queries can be used in order to increase expressivity of rule-based
	 transformations. We compare our work with other querying languages
	 and discuss how our ideas can be used for other existing settings.},
	Author = {Berlea, Alexandru and Seidl, Helmut},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {Nordic Journal of Computing},
	Journal-Abbr = {NJC},
	Keywords = {XML query languages evluation binary queries fxt fxgrep},
	Number = {1},
	Pages = {41--71},
	Pdf = {QueryEvaluation/XML/Comlexity/Berlea.Seidl_BinaryQueriesDocument_NJC_2004.pdf},
	Title = {{Binary Queries for Document Trees}},
	Url = {http://atseidl2.informatik.tu-muenchen.de/~berlea/publications/njc/binaries.pdf},
	Volume = {11},
	Year = {2004}}

@inproceedings{Beyer.Cochrane.ea_XQueryAnalytics_XIME-P_2004,
	Abstract = {XML has emerged as the industry standard for
	 representing and exchanging data and is already predominant in several
	 applications today. Business, analytic, and structured data will
	 be exchanged as XML between applications and web services. XQuery
	 is a query language that is emerging as the standard for querying
	 XML data. The current version of the XQuery standard contains many
	 features for navigating the hierarchical and ordered content of XML
	 data. However, as compared to SQL, it lacks some key constructs which
	 makes it di cult to succinctly express and e ciently execute some
	 simple classes of analytic queries. In this paper, we describe some
	 of the limitations of the current XQuery language and argue that
	 extensions to XQuery are necessary to overcome these limitations.},
	Author = {Beyer, Kevin S. and Cochrane, Roberta and Colby, Latha S. and Ozcan, Fatma and Pirahesh, Hamid},
	Booktitle = {Proc. of Int. Workshop on XQuery Implementation, Experience and Perspectives ?XIME-P/?},
	Conference-Abbr = {XIME-P},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XQuery XML grouping analytics use cases group-by},
	Owner = {Tim Furche},
	Pages = {3-8},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/XQuery/Beyer.Cochrane.ea_XQueryAnalytics_XIME-P_2004.pdf},
	Title = {{XQuery for Analytics: Challenges and Requirements}},
	Url = {http://www-rocq.inria.fr/gemo/Gemo/Projects/XIME-P/CR/PDF/BeyerCR.pdf},
	Year = {2004}}

@techreport{Boncz.Grust.ea_LoopStaircase_TR_2005,
	Abstract = {Various techniques have been proposed for efficient evaluation of XPath expressions,
	 where the XPath location steps are rooted in a single sequence of
	 context nodes. Among these techniques, the staircase join allows
	 to evaluate XPath location steps along arbitrary axes in at most
	 one scan over the XML document, exploiting the XPath accelerator
	 encoding (aka. pre/post encoding). In XQuery, however, embedded XPath
	 sub-expressions occur in arbitrarily nested for-loops. Thus, they are rooted in
	 multiple sequences of context nodes (one per iteration). Consequently,
	 the previously proposed algorithms need to be applied repeatedly,
	 requiring multiple scans over the XML document encoding. In this
	 work, we present loop-lifted staircase join, an extension of the
	 staircase join that allows to efficiently evaluate XPath sub-expressions
	 in arbitrarily nested XQuery iteration scopes with only a single
	 scan over the document. We implemented the loop-lifted staircase
	 join in MonetDB/XQuery, that uses the XQuery-to-Relational Algebra
	 compiler Pathfinder on top of the extensible RDBMS MonetDB. Performance
	 results indicate that the proposed technique allows to build a system
	 that is capable of efficiently evaluating XQuery queries including
	 embedded XPath expressions, obtaining interactive query execution
	 times for all XMark queries even on multi-gigabyte XML documents.},
	Author = {Boncz, Peter and Grust, Torsten and van Keulen, Maurice and Manegold, Stefan and Rittinger, Jan and Teubner, Jens},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {CWI},
	Keywords = {XML staircase join structural join loop-lifting},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/StructuralJoins/Boncz.Grust.ea_LoopStaircase_TR_2005.pdf},
	Title = {{Loop-lifted Staircase Join: from XPath to XQuery}},
	Url = {http://www.inf.uni-konstanz.de/~rittinge/publications/INS-E0510.pdf},
	Year = {2005}}

@techreport{Boncz.Grust.ea_Pathfinder_TR_2005,
	Abstract = {Pathfinder/MonetDB is a collaborative effort
	 of the University of Konstanz, the University of Twente, and the
	 Centrum voor Wiskunde en Informatica (CWI) in Amsterdam to develop
	 an XQuery compiler that targets an RDBMS back-end. The author of
	 this abstract is student at the University of Konstanz and spent
	 six months as an intern at the CWI, designing and implementing a
	 translation of XQuery Core to (a variant of) relational algebra. His
	 work continues in the research group at the University of Konstanz.},
	Address = {Amsterdam, The Netherlands},
	Author = {Boncz, Peter and Grust, Torsten and Manegold, Stefan and Rittinger, Jan and Teubner, Jens},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {CWI},
	Keywords = {XML Pathfinder joins relational implementation},
	Number = {INS-E0503},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Boncz.Grust.ea_Pathfinder_TR_2005.pdf},
	Title = {{Pathfinder: Relational XQuery Over Multi-Gigabyte XML Inputs In Interactive Time}},
	Url = {http://www.inf.uni-konstanz.de/~rittinge/publications/INS-E0503.pdf},
	Year = {2005}}

@inproceedings{Bothner_XQuery2Java_XIME-P_2004,
	Abstract = {--},
	Author = {Bothner, Per},
	Booktitle = {Proc. of Int. Workshop on XQuery Implementation, Experience and Perspectives <XIME-P/>},
	Conference-Abbr = {XIME-P},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XQuery Bytecode Java translation},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Translating/Bothner_XQuery2Java_XIME-P_2004.pdf},
	Title = {{Compiling XQuery to Java Bytecodes}},
	Url = {http://per.bothner.com/papers/Qexo04/},
	Year = {2004}}

@inproceedings{Brantner.Helmer.ea_AlgebraicXPath_ICDE_2005,
	Abstract = {We present the first complete translation of XPath into an algebra, paving the way for a
	 comprehensive, state-of-the-art XPath (and later on, XQuery) compiler based
	 on algebraic optimization techniques. Our translation includes all
	 XPath features such as nested expressions, position-based predicates
	 and node-set functions. The translated algebraic expressions can
	 be executed using the proven, scalable, iterator-based approach,
	 as we demonstrate in form of a corresponding physical algebra in
	 our native XML DBMS Natix. A first glance at performance results
	 shows that even without further optimization of the expressions,
	 we provide a competitive evaluation technique for XPath queries.},
	Address = {Washington, DC, USA},
	Author = {Brantner, Matthias and Helmer, Sven and Kanne, Carl-Christian and Moerkotte, Guido},
	Booktitle = {Proc. Inst. Conf. on Data Engineering},
	Conference-Abbr = {ICDE},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1109/ICDE.2005.69},
	Isbn = {0-7695-2285-8},
	Keywords = {XML native database algebra natix XPath},
	Pages = {705--716},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Brantner.Helmer.ea_Full-FledgedAlgebraicXPath_ICDE_2005.pdf},
	Publisher = {IEEE Computer Society},
	Title = {{Full-Fledged Algebraic XPath Processing in Natix}},
	Url = {http://pi3.informatik.uni-mannheim.de/publications/xpath_icde2005.pdf},
	Year = {2005}}

@inproceedings{Brantner.Kanne.ea_CostReorderNavi_SIGMOD_2005,
	Abstract = {We present a method to evaluate path queries
	 based on the novel concept of partial path instances. Our method (1)
	 maximizes performance by means of sequential scans or asynchronous I/O,
	 (2) does not require a special storage format, (3) relies on simple
	 navigational primitives on trees, and (4) can be complemented by existing
	 logical and physical optimizations such as duplicate elimination,
	 duplicate prevention and path rewriting. We use a physical algebra which
	 separates those navigation operations that require I/O from those that do
	 not. All I/O operations necessary for the evaluation of a path are
	 isolated in a single operator, which may employ ef cient I/O scheduling
	 strategies such as sequential scans or asynchronous I/O. Performance
	 results for queries from the XMark benchmark show that reordering the
	 navigation operations can increase performance up to a factor of four.},
	Author = {Brantner, Matthias and Kanne, Carl-Christian and Moerkotte, Guido},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XPath query optimization Natix navigational reordering},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Brantner.Kanne.ea_CostReorderNavi_SIGMOD_2005.pdf},
	Title = {{Cost-Sensitive Reordering of Navigational Primitives}},
	Url = {http://pi3.informatik.uni-mannheim.de/publications/xassembly_sigmod2005.pdf},
	Year = {2005}}

@inproceedings{Bruno.Maitre.ea_ExtXQueryTransform_DocEng_2003,
	Abstract = {In this paper, we propose to extend XQuery - the
	 XML query language - with a set of transformation operators which
	 will produce a copy of an XML tree in which some subtrees will be
	 inserted, replaced or deleted. These operators - very similar to the
	 ones proposed for updating an XML document - greatly simplify the
	 expression of some queries in making it possible to express only
	 the modified part of a tree instead of its whole reconstruction. We
	 compare the expressivity of XQuery extended in this way with XSLT.},
	Author = {Bruno, Emmanuel and Maitre, Jacques Le and Murisasco, Elisabeth},
	Booktitle = {Proc. ACM symposium on Document Engineering},
	Conference-Abbr = {DocEng},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/958220.958223},
	Isbn = {1-58113-724-9},
	Keywords = {XML XQuery transformations document engineering query languages},
	Location = {Grenoble, France},
	Pages = {1--8},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/XQuery/Bruno.Maitre.ea_ExtXQueryTransform_DocEng_2003.pdf},
	Publisher = {ACM Press},
	Title = {{Extending XQuery with Transformation Operators}},
	Url = {http://www.univ-tln.fr/~lemaitre/doceng2003.pdf},
	Year = {2003}}

@inproceedings{Bruno.Koudas.ea_HolisticTwigJoins_SIGMOD_2002,
	Abstract = {XML employs a tree-structured data model, and, naturally, XML queries specify patterns of
	 selection predicates on multiple elements related by a tree structure.
	 Finding all occurrences of such a twig pattern in an XML database is a
	 core operation for XML query processing. Prior work has typically
	 decomposed the twig pattern into binary structural (parent-child and
	 ancestor-descendant) relationships, and twig matching is achieved by: (i) using
	 structural join algorithms to match the binary relationships against
	 the XML database, and (ii) stitching together these basic matches.
	 A limitation of this approach for matching twig patterns is that
	 intermediate result sizes can get large, even when the input and
	 output sizes are more manageable.In this paper, we propose a novel
	 holistic twig join algorithm, TwigStack, for matching an XML query twig
	 pattern. Our technique uses a chain of linked stacks to compactly
	 represent partial results to root-to-leaf query paths, which are
	 then composed to obtain matches for the twig pattern. When the twig
	 pattern uses only ancestor-descendant relationships between elements,
	 TwigStack is I/O and CPU optimal among all sequential algorithms
	 that read the entire input: it is linear in the sum of sizes of the
	 input lists and the final result list, but independent of the sizes
	 of intermediate results. We then show how to use (a modification
	 of) B-trees, along with TwigStack, to match query twig patterns in
	 sub-linear time. Finally, we complement our analysis with experimental
	 results on a range of real and synthetic data, and query twig patterns.},
	Address = {New York, NY, USA},
	Author = {Bruno, Nicolas and Koudas, Nick and Srivastava, Divesh},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/564691.564727},
	Isbn = {1-58113-497-5},
	Keywords = {XML structural joins twig joins query optimization pattern matching},
	Location = {Madison, Wisconsin},
	Pages = {310--321},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/StructuralJoins/Bruno.Koudas.ea_HolisticTwigJoins_SIGMOD_2002.pdf},
	Publisher = {ACM Press},
	Title = {{Holistic Twig Joins: Optimal XML Pattern Matching}},
	Url = {http://www.research.att.com/~divesh/papers/bks2002-twigjoin.pdf},
	Year = {2002}}

@article{Buneman.Fernandez.ea_UnQL_VLDBJ_2000,
	Abstract = {This paper presents structural recursion as the basis of the syntax and semantics of query
	 languages for semistructured data and XML. We describe a simple and
	 powerful query language based on pattern matching and show that it can
	 be expressed using structural recursion, which is introduced as a
	 top-down, recursive function, similar to the way XSL is defined on XML
	 trees. On cyclic data, structural recursion can be defined in two
	 equivalent ways: as a recursive function which evaluates the data top-down
	 and remembers all its calls to avoid infinite loops, or as a bulk
	 evaluation which processes the entire data in parallel using only
	 traditional relational algebra operators. The latter makes it possible for
	 optimization techniques in relational queries to be applied to structural
	 recursion. We show that the composition of two structural recursion
	 queries can be expressed as a single such query, and this is used as
	 the basis of an optimization method for mediator systems. Several
	 other formal properties are established: structural recursion can be
	 expressed in first-order logic extended with transitive closure; its data
	 complexity is PTIME; and over relational data it is a conservative
	 extension of the relational calculus. The underlying data model is based
	 on value equality, formally defined with bisimulation. Structural
	 recursion is shown to be invariant with respect to value equality.},
	Address = {Secaucus, NJ, USA},
	Author = {Buneman, Peter and Fernandez, Mary and Suciu, Dan},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1007/s007780050084},
	Issn = {1066-8888},
	Journal = {VLDB Journal},
	Journal-Abbr = {VLDBJ},
	Keywords = {XML UnQL algebra query language query optimization structural recursion},
	Number = {1},
	Pages = {76--110},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/Buneman.Fernandez.ea_UnQL_VLDBJ_2000.pdf},
	Publisher = {Springer-Verlag New York, Inc.},
	Title = {{UnQL: a query language and algebra for semistructured data based on structural recursion}},
	Url = {http://portal.acm.org/citation.cfm?id=765224},
	Volume = {9},
	Year = {2000}}

@inproceedings{Catania.Wang.ea_LazyXML_SIGMOD_2005,
	Abstract = {XML documents are normally stored as plain text files. Hence,
	 the natural and most convenient way to update XML documents is to
	 simply edit the text files. But efficient query evaluation algorithms
	 require XML documents to be in- dexed. Every element is given a unique
	 identifier based on its location in the document or its preorder-traversal
	 order, and this identifier is later used as (part of) the key in the
	 index. Reassigning orders of possibly a large number of elements is
	 therefore necessary when the original XML documents are updated.
	 Immutable dynamic labeling schemes have been proposed to solve this
	 problem, that, however, require very long labels and may decrease query
	 performance. If we con- sider a real-world scenario, we note that many
	 relatively small ad-hoc XML segments are inserted/deleted into/from an
	 existing XML database. In this paper, we start from this consideration
	 and we propose a new lazy approach to handle XML updates that also
	 improves query performance. The lazy approach: (i) completely avoids
	 reassigning existing el- ement orders after updates; (ii) improves
	 query processing by taking advantages from segments. Experimental
	 results show that our approach is much more efficient in handling
	 updates than using immutable labeling and, at the same time, it also
	 improves the performance of recently defined structural join algorithms.},
	Author = {Catania, Barbara and Wang, Wenqiang and Ooi, Beng Chin and Wang, Xiaoling},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML updates structural join laziness query optimization},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/NestedQueries/Catania.Wang.ea_LazyXML_SIGMOD_2005.pdf},
	Title = {{Lazy XML Updates: Laziness as a Virtue of Update and Structural Join Efficiency}},
	Url = {http://www.comp.nus.edu.sg/~ooibc/sigmod386.pdf},
	Year = {2005}}

@inproceedings{Chan.Fan.ea_TamingXPathQueries_VLDB_2004,
	Abstract = {This paper presents a novel and complementary
	 technique to optimize an XPath query by minimizing its wildcard steps.
	 Our approach is based on using a general composite axis called the
	 layer axis, to rewrite a sequence of XPath steps (all of which are
	 wildcard steps except for possibly the last) into a single layer-axis
	 step. We describe an efficient implementation of the layer axis and
	 present a novel and efficient rewriting algorithm to minimize both
	 non-branching as well as branching wildcard steps in XPath queries. We also
	 demonstrate the usefulness of wildcard-step elimination by proposing an
	 optimized evaluation strategy for wildcard-free XPath queries that
	 enables selective loading of only the relevant input XML data for
	 query evaluation. Our experimental results not only validate the
	 scalability and efficiency of our optimized evaluation strategy, but also
	 demonstrate the effectiveness of our rewriting algorithm for minimizing
	 wildcard steps in XPath queries. To the best of our knowledge, this
	 is the first effort that addresses this new optimization problem.},
	Author = {Chan, Chee-Yong and Fan, Wenfei and Zeng, Yiming},
	Booktitle = vldb,
	Conference-Abbr = {VLDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML, query rewriting, containment, minimization, XPath, type-based optimization},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Containment/Chan.Fan.ea_TamingXPathQueries_VLDB_2004.pdf},
	Title = {{Taming XPath Queries by Minimizing Wildcard Steps}},
	Url = {http://www.vldb.org/conf/2004/RS4P4.PDF},
	Year = {2004}}

@inproceedings{Chen.Rundensteiner_XQueryVar_WWW_2005,
	Abstract = {Semantic caching is an important technology
	 for improving the response time of future user queries specified
	 over remote servers. This paper deals with the fundamental query
	 containment problem in an XQuery-based semantic caching system. To our best
	 knowledge, the impact of subtle differences in XQuery semantics caused
	 by different ways of specifying variables on query containment has
	 not yet been studied. We introduce the concept of variable binding
	 dependencies for representing the hierarchical element dependencies
	 preserved by an XQuery. We analyze the problem of XQuery containment in
	 the presence of such dependencies. We propose a containment mapping
	 technique for nested XQuery in presence of variable binding dependencies.
	 The implication of the nested block structure on XQuery containment
	 is also considered. We mention the performance gains achieved by a
	 semantic caching system we build based on the proposed technique.},
	Address = {New York, NY, USA},
	Author = {Chen, Li and Rundensteiner, Elke A.},
	Booktitle = {Proc. Int. World Wide Web Conf.},
	Conference-Abbr = {WWW},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1060745.1060789},
	Isbn = {1-59593-046-9},
	Keywords = {XML containment XQuery variables},
	Location = {Chiba, Japan},
	Pages = {288--297},
	Pdf = {QueryEvaluation/XML/Containment/Chen.Rundensteiner_XQueryVar_WWW_2005.pdf},
	Publisher = {ACM Press},
	Title = {{XQuery Containment in Presence of Variable Binding Dependencies}},
	Year = {2005}}

@inproceedings{Chen2002ACE-XQ:-A-CachE-aware-XQuery-Answering-System,
	Abstract = {Caching popular queries and reusing results of these previously
	 computed queries to speed up query processing is one important query
	 optimization technique for distributed environments such as the Web.
	 However, exisiting query-based cache systems, based on query containment
	 and rewriting techniques developed for relational queries, are not
	 appropriate for supporting more powerful XML queries. We hence propose the
	 first solution for XML query processing using cached XQuery views.
	 In particular, we describe in this paper an XQuery-based semantic
	 caching system called ACE-XQ, that we have implemented to realize the
	 proposed containment mapping and query rewriting techniques. Preliminary
	 experiments confirm the feasibility of our approach and also illustrate the
	 performance gains achievable by ACE-XQ over the original XQuery engine.},
	Author = {Chen, Li and Rundensteiner, Elke A.},
	Booktitle = webdb,
	Conference-Abbr = {WebDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-11-09 21:26:27 +0100},
	Keywords = {XML, XQuery, views, processing, evaluation},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Containment/Chen.Rundensteiner_ACEXQ_WebDB_2002.pdf},
	Title = {{ACE-XQ: A CachE-aware XQuery Answering System}},
	Url = {http://www.cs.wpi.edu/~lichen/papers/webdb02-acexq.ps},
	Year = {2002}}

@inproceedings{Chen.Lu.ea_BoostingHolism_SIGMOD_2005,
	Abstract = {Searching for all occurrences of a twig pattern in
	 an XML document is an important operation in XML query processing.
	 Recently a holistic method TwigStack. [2] has been proposed. The
	 method avoids generating large intermediate results which do not
	 contribute to the final answer and is CPU and I/O optimal when twig
	 patterns only have ancestor-descendant relationships. Another important
	 direction of XML query processing is to build structural indexes
	 [3][8][13][15] over XML documents to avoid unnecessary scanning of
	 source documents. We regard XML structural indexing as a technique to
	 partition XML documents and call it streaming scheme in our paper.
	 In this paper we develop a method to perform holistic twig pattern
	 matching on XML documents partitioned using various streaming schemes.
	 Our method avoids unnecessary scanning of irrelevant portion of XML
	 documents. More importantly, depending on different streaming schemes
	 used, it can process a large class of twig patterns consisting of
	 both ancestor-descendant and parent-child relationships and avoid
	 generating redundant intermediate results. Our experiments demonstrate
	 the applicability and the performance advantages of our approach.},
	Address = {New York, NY, USA},
	Author = {Chen, Ting and Lu, Jiaheng and Ling, Tok Wang},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1066157.1066209},
	Isbn = {1-59593-060-4},
	Keywords = {XML XPath holistic joins twig joins structural joins},
	Location = {Baltimore, Maryland},
	Pages = {455--466},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/StructuralJoins/Chen.Lu.ea_BoostingHolism_SIGMOD_2005.pdf},
	Publisher = {ACM Press},
	Title = {{On Boosting Holism in XML Twig Pattern Matching using Structural Indexing Techniques}},
	Url = {http://portal.acm.org/citation.cfm?id=1066157.1066209},
	Year = {2005}}

@inproceedings{Chen.Davidson.ea_BLAS_SIGMOD_2004,
	Abstract = {We present BLAS, a Bi-LAbeling based System, for efficiently processing
	 complex XPath queries over XML data. BLAS uses P-labeling to process
	 queries involving consecutive child axes, and D-labeling to process
	 queries involving descendant axes traversal. The XML data is stored in
	 labeled form, and indexed to optimize descendent axis traversals. Three
	 algorithms are presented for translating complex XPath queries to SQL
	 expressions, and two alternate query engines are provided. Experimental
	 results demonstrate that the BLAS system has a substantial performance
	 improvement compared to traditional XPath processing using D-labeling.},
	Address = {New York, NY, USA},
	Author = {Chen, Yi and Davidson, Susan B. and Zheng, Yifeng},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of data},
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1007568.1007577},
	Isbn = {1-58113-859-8},
	Keywords = {XML XPath BLAS labelling indexing query optimization},
	Location = {Paris, France},
	Pages = {47--58},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/Chen.Davidson.ea_BLAS_SIGMOD_2004.pdf},
	Publisher = {ACM Press},
	Title = {{BLAS: An Efficient XPath Processing System}},
	Url = {http://www.cis.upenn.edu/~yicn/blas.pdf},
	Year = {2004}}

@inproceedings{Chen.Jagadish.ea_GeneralizedTreePats_VLDB_2003,
	Abstract = {XQuery is the de facto standard XML
	 query language, and it is important to have e cient query evaluation
	 techniques available for it. A core operation in the evaluation of XQuery
	 is the nding of matches for speci ed tree patterns, and there has
	 been much work towards algorithms for nding such matches e ciently.
	 Multiple XPath expressions can be evaluated by computing one or more
	 tree pattern matches. However, relatively little has been done on
	 e - cient evaluation of XQuery queries as a whole. In this paper,
	 we argue that there is much more to XQuery evaluation than a tree
	 pattern match. We propose a structure called generalized tree pat-
	 tern (GTP) for concise representation of a whole XQuery expression.
	 Evaluating the query reduces to nding matches for its GTP. Using this
	 idea we develop e cient evaluation plans for XQuery expressions,
	 possibly involving join, quanti ers, grouping, aggregation, and nesting.
	 XML data often conforms to a schema. We show that using relevant
	 constraints from the schema, one can optimize queries signi cantly, and
	 give algorithms for automatically inferring GTP simpli cations given
	 a schema. Finally, we show, through a detailed set of experiments
	 using the TIMBER XML database system, that plans via GTPs (with or
	 without schema knowledge) signi cantly outperform plans based on
	 navigation and straightforward plans obtained directly from the query.},
	Author = {Chen, Zhimin and Jagadish, H. V. and Lakshmanan, Laks V.S. and Paparizos, Stelios},
	Booktitle = {Proc. Int. Conf. on Very Large Databases},
	Conference-Abbr = {VLDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XQuery optimization generalized tree patterns nested queries},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Chen.Jagadish.ea_GeneralizedTreePats_VLDB_2003.pdf},
	Title = {{From Tree Patterns to Generalized Tree Patterns: On Efficient Evaluation of XQuery}},
	Url = {http://www.vldb.org/conf/2003/papers/S08P03.pdf},
	Year = {2003}}

@article{Christophides.ea_QueryStructured_SIGR_1994,
	Abstract = {Structured documents (e.g., SGML) can benefit a lot from
	 database support and more specifically from object-oriented database
	 (OODB) management systems. This paper describes a natural mapping
	 from SGML documents into OODB's and a formal extension of two OODB
	 query languages (one SQL-like and the other calculus) in order to
	 deal with SGML document retrieval.Although motivated by structured
	 documents, the extensions of query languages that we present are
	 general and useful for a variety of other OODB applications. A key
	 element is the introduction of paths as first class citizens. The new
	 features allow to query data (and to some extent schema) without
	 exact knowledge of the schema in a simple and homogeneous fashion.},
	Address = {New York, NY, USA},
	Author = {Christophides, V. and Abiteboul, S. and Cluet, S. and Scholl, M.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/191843.191901},
	Issn = {0163-5808},
	Journal = {SIGMOD Record},
	Journal-Abbr = {SIGR},
	Keywords = {XML semi-structured data query path expressions O2SQL path variables},
	Number = {2},
	Pages = {313--324},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/PathVariables/Christophides.Abiteboul.ea_StructuredDocsQuery_SIGR_1994.pdf},
	Publisher = {ACM Press},
	Title = {{From Structured Documents to Novel Query Facilities}},
	Url = {http://portal.acm.org/citation.cfm?id=191843.191901},
	Volume = {23},
	Year = {1994}}

@inproceedings{Cohen.Halperin.ea_Reachability2Hop_SODA_2002,
	Abstract = {Reachability and distance queries in graphs are fundamental to
	 numerous applications, ranging from geographic navigation systems to
	 Internet routing. Some of these applications involve huge graphs and
	 yet require fast query answering. We propose a new data structure
	 for representing all distances in a graph. The data structure is
	 distributed in the sense that it may be viewed as assigning labels to the
	 vertices, such that a query involving vertices u and v may be answered
	 using only the labels of u and v.Our labels are based on 2-hop covers
	 of the shortest paths, or of all paths, in a graph. For shortest
	 paths, such a cover is a collection S of shortest paths such that for
	 every two vertices u and v, there is a shortest path from u to v that
	 is a concatenation of two paths from S. We describe an efficient
	 algorithm for finding an almost optimal 2-hop cover of a given collection
	 of paths. Our approach is general and can be applied to directed
	 or undirected graphs, exact or approximate shortest paths, or to
	 reachability queries.We study the proposed data structure using a
	 combination of theoretical and experimental means. We implemented our
	 algorithm and checked the size of the resulting data structure on several
	 real-life networks from different application areas. Our experiments
	 show that the total size of the labels is typically not much larger
	 than the network itself, and is usually considerably smaller than an
	 explicit representation of the transitive closure of the network.},
	Address = {Philadelphia, PA, USA},
	Author = {Cohen, Edith and Halperin, Eran and Kaplan, Haim and Zwick, Uri},
	Booktitle = {Proc. ACM Symposium on Discrete Algorithms},
	Conference-Abbr = {SODA},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {0-89871-513-X},
	Keywords = {transitive closure reachability graph 2-hop labelling indexing},
	Location = {San Francisco, California},
	Pages = {937--946},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/Cohen.Halperin.ea_Reachability2Hop_SODA_2002.pdf},
	Publisher = {Society for Industrial and Applied Mathematics},
	Title = {{Reachability and Distance Queries via 2-hop Labels}},
	Url = {http://portal.acm.org/citation.cfm?id=545381.545503},
	Year = {2002}}

@inproceedings{Cohen.Kaplan.ea_LabelingDynamicXML_PODS_2002,
	Abstract = {We present algorithms to
	 label the nodes of an XML tree which is subject to insertions and
	 deletions of nodes. The labeling is done such that (1) we label each node
	 immediately when it is inserted and this label remains unchanged, and (2)
	 from a pair of labels alone, we can decide whether one node is an
	 ancestor of the other. This problem arises in the context of XML
	 databases that support queries on the structure of the documents as
	 well us on the changes made to the documents over time. We prove
	 that our algorithms assign the shortest possible labels (up to a
	 constant factor) which satisfy these requirements.We also consider the
	 same problem when "clues" that provide guarantees on possible future
	 insertions are given together with newly inserted nodes. Such clues can be
	 derived from the DTD or from statistics on similar XML trees. We
	 present algorithms that use the clues to assign shorter labels. We also
	 prove that the length of our labels is close to the minimum possible.},
	Address = {New York, NY, USA},
	Author = {Cohen, Edith and Kaplan, Haim and Milo, Tova},
	Booktitle = {Proc. ACM SIGMOD Symposium on Principles of Database Systems},
	Conference-Abbr = {PODS},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/543613.543648},
	Isbn = {1-58113-507-6},
	Keywords = {XML labeling indexing dynamic 2-hop reachability},
	Location = {Madison, Wisconsin},
	Pages = {271--281},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/Cohen.Kaplan.ea_LabelingDynamicXML_PODS_2002.pdf},
	Publisher = {ACM Press},
	Title = {{Labeling Dynamic XML Trees}},
	Url = {http://portal.acm.org/citation.cfm?id=543648},
	Year = {2002}}

@inproceedings{Cooper.Sample.ea_FastIndexSSD_VLDB_2001,
	Abstract = {Queries navigate semistructured data
	 via path expressions, and can be accelerated using an index. Our
	 solution encodes paths as strings, and inserts those strings into a
	 special index that is highly optimized for long and complex keys. We
	 describe the Index Fabric, an indexing structure that provides the
	 efficiency and flexibility we need. We discuss how "raw paths" are
	 used to optimize ad hoc queries over semistructured data, and how
	 "refined paths" optimize specific access paths. Although we can use
	 knowledge about the queries and structure of the data to create refined
	 paths, no such knowledge is needed for raw paths. A performance study
	 shows that our techniques, when implemented on top of a commercial
	 relational database system, outperform the more traditional approach of
	 using the commercial system?s indexing mechanisms to query the XML.},
	Address = {San Francisco, CA, USA},
	Author = {Cooper, Brian and Sample, Neal and Franklin, Michael J. and Hjaltason, Gisli R. and Shadmon, Moshe},
	Booktitle = {Proc. Int. Conf. on Very Large Databases},
	Conference-Abbr = {VLDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {1-55860-804-4},
	Keywords = {XML semi-structured data index fast},
	Pages = {341--350},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/Cooper.Sample.ea_FastIndexSSD_VLDB_2001.pdf},
	Publisher = {Morgan Kaufmann Publishers Inc.},
	Title = {{A Fast Index for Semistructured Data}},
	Url = {http://www.vldb.org/conf/2001/P341.pdf},
	Year = {2001}}

@inproceedings{Deutsch.Papakonst.ea_NestedQueries_ICDE_2004,
	Abstract = {We describe and evaluate a query minimization technique that applies to
	 XQueries, which are nested, perform arbi- trary joins, and freely mix
	 bag and set semantics. These features create key challenges that
	 fundamentally extend the problem of minimizing conjunctive queries
	 (no nesting, no mixed semantics) or tree pattern XPath expressions
	 (no nesting, no joins, no bag semantics). The technique detects and
	 removes redundant navigation across and within nested subqueries.
	 An important application of this technique is group-by detection.},
	Author = {Deutsch, Alin and Papakonstantinou, Yannis and Xu, Yu},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {Proc. Int. Conf. on Data Engineering},
	Conference-Abbr = {ICDE},
	Crossref = {DBLP:conf/icde/2004},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Ee = {http://csdl.computer.org/comp/proceedings/icde/2004/2065/00/20650839.pdf},
	Keywords = {XML XQuery query optimization algebra query unnesting},
	Pages = {839},
	Pdf = {QueryEvaluation/XML/NestedQueries/Deutsch.Papakonst.ea_NestedQueries_ICDE_2004.pdf},
	Title = {{Minimization and Group-By Detection for Nested XQueries}},
	Url = {http://www.db.ucsd.edu/CSE232BS03/nested-xquery-minimization.pdf},
	Year = {2004}}

@inproceedings{Deutsch2001Containment-and-Integrity-Constraints-for-XPath-Fragments,
	Abstract = {XPath is a W3C standard that plays a crucial role in several in uential query transformation and schema standards for XML Motivated by the larger challenge of XML query optimization we investigate the problem of containment of XPath expressions under integrity constraints that are in turn formulated with the help of XPath expressions Our core formalism consists of a fragment of XPath that we call simple and a corresponding class of of integrity constraints that we call simple XPath integrity constraints SXIC SXIC s can express many database style con straints including key and foreign key constraints speci ed in the XML Schema standard proposal as well as many constraints implied by DTDs We identify a subclass of bounded SXIC s under which containment of simple XPath expres sions is decidable but we show that even modest use of unbounded SXIC s makes the problem undecidable In particular the addition of unbounded constraints implied by DTDs leads to undecidability. We give tight P-bounds for the simple XPath containment problem and tight NP bounds for the disjunction free subfragment while even identifying a PTIME subcase We also show that decidability of containment under SXIC s still holds if the expressions contain certain additional features, e.g. wildcard although the complexity jumps to P even for the disjunction free subfragment. We know that our results can be extended to some but not all of the XPath features that depend on document order The decidability of containment of simple XPath expressions in the presence of DTDs only remains open although we can show that the problem is PSPACE hard as well as the problem for full edged XPath expressions even in the absence of integrity constraints.},
	Author = {Deutsch, Alin and Tannen, Val},
	Booktitle = krdb,
	Conference-Abbr = {KRDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML, XPath, containment, integrity constraints, type-based optimization},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Containment/Deutsch.Tannen_ContainmentXPath_KRDB_2001.pdf},
	Title = {{Containment and Integrity Constraints for XPath Fragments}},
	Url = {http://ceur-ws.org/Vol-45/01-deutsch.ps},
	Year = {2001}}

@inproceedings{Diao.Florescu.ea_MemoizationXQuery_XSym_2004,
	Abstract = {In this paper, we describe an approach to boosting the
	 performance of an XQuery engine by identifying and exploiting opportunities
	 to share processing both within and across XML queries. We first
	 explain where sharing opportunities arise in the world of XML query
	 processing. We then describe an approach to shared XQuery processing
	 based on memoization, providing details of an implementation that we
	 built by extending the streaming XQuery processor that BEA Systems
	 incorporates as part of their BEA WebLogic Integration 8.1 product. To
	 explore the potential performance gains offered by our approach, we
	 present results from an experimental study of its performance over a
	 collection of use-case-inspired synthetic query workloads. The performance
	 results show that significant overall gains are indeed available.},
	Author = {Diao, Yanlei and Florescu, Daniela and Kossmann, Donald and Carey, Michael J. and Franklin, Michael J.},
	Booktitle = {Proc. Int. Database Symposium},
	Conference-Abbr = {XSym},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XQuery memoization processor implementation},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Diao.Florescu.ea_MemoizationXQuery_XSym_2004.pdf},
	Title = {{Implementing Memoization in a Streaming XQuery Processor}},
	Url = {http://www.cs.berkeley.edu/~franklin/Papers/MemoXSym.pdf},
	Year = {2004}}

@inproceedings{Dong.Bailey_StaticAnalysisXSLT_ADC_2004,
	Abstract = {XML is becoming the dominant
	 standard for representing and exchanging data on the World Wide Web. The
	 ability to transform and present data in XML is crucial and XSLT
	 (Extensible Stylesheet Language Transformations) is the principal
	 programming language that supports this activity. Methods for analysis of
	 XSLT programs are currently an important open issue. In this paper,
	 we discuss new methods for analysing XSLT programs, which return
	 information about reachability, invalid calling relationships and
	 termination properties. Our methods are based on the determination of the
	 associations which can exist between components of an XSLT program,
	 refined by the knowledge from a DTD. Such analysis is important for
	 debugging and verification of XSLT programs and also their optimisation.},
	Author = {Dong, Ce and Bailey, James},
	Booktitle = {Proc. Australasian Database Conf.},
	Conference-Abbr = {ADC},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {1-111-11111-1},
	Keywords = {XML XSLT error checking typing query languages},
	Location = {Dunedin, New Zealand},
	Pages = {151--160},
	Pdf = {QueryEvaluation/XML/Containment/Dong.Bailey_StaticAnalysisXSLT_ADC_2004.pdf},
	Publisher = {Australian Computer Society, Inc.},
	Title = {{Static Analysis of XSLT Programs}},
	Url = {http://www.cs.mu.oz.au/~jbailey/papers/adc.pdf},
	Year = {2004}}

@inproceedings{El-Sayed.Dimitrova.ea_EfficientOrder_WIDM_2003,
	Abstract = {Query processing over XML data sources has
	 emerged as a popular topic. XML is an ordered data model and XQuery
	 expressions return results that have a well-defined order. However
	 little work on how order is supported in XML query processing has
	 been done to date. In this paper we study the challenges related
	 to handling order in the XML context, namely challenges imposed by
	 the XML data model, by the variety of distinct XML operators and by
	 incremental view maintenance. We have proposed an efficient solution
	 that addresses these issues. We use a key encoding for XML nodes
	 that supports both node identity and node order. We have designed
	 order encoding rules based on the XML algebraic query execution data
	 model and on node encodings that does not require any actual sorting
	 for intermediate results during execution. Our approach supports
	 more efficient incremental view maintenance as it makes most XML
	 operators distributive with respect to bag union. Our approach is
	 implemented in the context of Rainbow [25], an XML data management system
	 developed at WPI. We prove the correctness of our order encoding
	 approach, namely that it ensures order handling for query processing and
	 for view maintenance. We also show, through experiments, that the
	 overhead of maintaining order in our approach is indeed neglectible.},
	Address = {New York, NY, USA},
	Author = {El-Sayed, Maged and Dimitrova, Katica and Rundensteiner, Elke A.},
	Booktitle = {Proc. Int. Workshop on Web Information and Data Management},
	Conference-Abbr = {WIDM},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/956699.956731},
	Isbn = {1-58113-725-7},
	Keywords = {XML query processing order optimization operators},
	Location = {New Orleans, Louisiana, USA},
	Pages = {147--154},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/OrderDuplicates/El-Sayed.Dimitrova.ea_EfficientOrder_WIDM_2003.pdf},
	Publisher = {ACM Press},
	Title = {{Efficiently Supporting Order in XML Query Processing}},
	Url = {http://davis.wpi.edu/~dsrg/rainbow/publications/XMLorder_8-1-04.pdf},
	Year = {2003}}

@inproceedings{Fegaras.Levine.ea_QueryStreamedXML_CIKM_2002,
	Abstract = {We are addressing the efficient
	 processing of continuous XML streams, in which the server broadcasts
	 XML data to multiple clients concurrently through a multicast data
	 stream, while each client is fully responsible for processing the
	 stream. In our framework, a server may disseminate XML fragments from
	 multiple documents in the same stream, can repeat or replace fragments,
	 and can introduce new fragments or delete invalid ones. A client
	 uses a light-weight database based on our proposed XML algebra to
	 cache stream data and to evaluate XML queries against these data. The
	 synchronization between clients and servers is achieved through annotations
	 and punctuations transmitted along with the data streams. We are
	 presenting a framework for processing XML queries in XQuery form
	 over continuous XML streams. Our framework is based on a novel XML
	 algebra and a new algebraic optimization framework based on query
	 decorrelation, which is essential for non-blocking stream processing.},
	Address = {New York, NY, USA},
	Author = {Fegaras, Leonidas and Levine, David and Bose, Sujoe and Chaluvadi, Vamsi},
	Booktitle = {Proc. Int. Conf. on Information and Knowledge Management},
	Conference-Abbr = {CIKM},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/584792.584816},
	Isbn = {1-58113-492-4},
	Keywords = {XML stream algebra query decorrelation non-blocking stream},
	Location = {McLean, Virginia, USA},
	Pages = {126--133},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Fegaras.Levine.ea_QueryStreamedXML_CIKM_2002.pdf},
	Publisher = {ACM Press},
	Title = {{Query Processing of Streamed XML Data}},
	Url = {http://lambda.uta.edu/cikm02.pdf},
	Year = {2002}}

@article{Fiebig.Moerkotte_AlgebraicXMLConstr_WWWJ_2001,
	Abstract = {While using an algebra that acts on sets of variable bindings for evaluating
	 XML queries, the problem of constructing XML from these bindings
	 arises. One approach is to define a powerful operator that is able to
	 perform a complex construction of a representation of the XML result
	 document. The drawback is that such an operator in its generality is
	 hard to implement and disables algebraic optimization since it has
	 to be executed last in the plan. Therefore we suggest to construct
	 XML documents by special query execution plans called construction
	 plans built from simple, easy to implement and efficient operators.
	 The paper proposes four simple algebraic operators needed for XML
	 document construction. Further, we introduce an optimizing translation
	 algorithm of construction clauses into algebraic expressions and
	 briefly point out algebraic optimizations enabled by our approach.},
	Address = {Hingham, MA, USA},
	Author = {Fiebig, Thorsten and Moerkotte, Guido},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1023/A:1013831700817},
	Issn = {1386-145X},
	Journal = {World Wide Web},
	Journal-Abbr = {WWWJ},
	Keywords = {XML XQuery Natix construction algebraic},
	Number = {3},
	Pages = {167--187},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Fiebig.Moerkotte_AlgebraicXMLConstr_WWWJ_2001.pdf},
	Publisher = {Kluwer Academic Publishers},
	Title = {{Algebraic XML Construction and its Optimization in Natix}},
	Url = {http://portal.acm.org/citation.cfm?id=598761},
	Volume = {4},
	Year = {2001}}

@article{Florescu.Hillery.ea_BEAXQuery_VLDBJ_2004,
	Abstract = {This paper describes the design, implementation, and performance characteristics
	 of a commercial XQuery processing engine, the BEA streaming XQuery
	 processor. This XQuery engine was designed to provide high performance for
	 message-processing applications, i.e., for transforming XML data
	 streams. The engine is a central component of the 8.1 release of BEA?s
	 WebLogic Integration (WLI) product. The BEA XQuery engine is fully
	 compliant with the August 2002 draft of the W3C XML Query Language
	 specification and we are currently porting it to the latest version of the
	 XQuery language (July 2004). A goal of this paper is to describe how a
	 fully compliant yet efficient XQuery engine has been built from a
	 few relatively simple components and well-understood technologies.},
	Author = {Florescu, Daniela and Hillery, Chris and Kossmann, Donald and Lucas, Paul and Riccardi, Fabio and Westmann, Till and Carey, Michael J. and Sundararajan, Arvind},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1007/s00778-004-0137-1},
	Issn = {1066-8888},
	Journal = {VLDB Journal},
	Journal-Abbr = {VLDBJ},
	Keywords = {XML XQuery query processing implementation query languages},
	Number = {3},
	Pages = {294--315},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Florescu.Hillery.ea_BEAXQuery_VLDBJ_2004.pdf},
	Publisher = {Springer-Verlag New York, Inc.},
	Title = {{The BEA Streaming XQuery Processor}},
	Url = {http://www-dbs.informatik.uni-heidelberg.de/publications/vldbj.pdf},
	Volume = {13},
	Year = {2004}}

@inproceedings{Fokoue.Rose.ea_XSLT2XQuery_WWW_2005,
	Abstract = {As XQuery is gathering momentum as the standard query language for XML, there
	 is a growing interest in using it as an integral part of the XML
	 application development infrastructure. In that context, one question
	 which is often raised is how well XQuery interoperates with other XML
	 languages, and notably with XSLT. XQuery 1.0 [16] and XSLT 2.0 [7]
	 share a lot in common: they share XPath 2.0 as a common sub-language
	 and have the same expressiveness. However, they are based on fairly
	 different programming paradigms. While XSLT has adopted a highly
	 declarative template based approach, XQuery relies on a simpler, and more
	 operational, functional approach.In this paper, we present an approach to
	 compile XSLT 2.0 into XQuery 1.0, and a working implementation of that
	 approach. The compilation rules explain how XSLT's template-based
	 approach can be implemented using the functional approach of XQuery and
	 underpins the tight connection between the two languages. The resulting
	 compiler can be used to migrate a XSLT code base to XQuery, or to
	 enable the use of XQuery runtimes (e.g., as will soon be provided
	 by most relational database management systems) for XSLT users. We
	 also identify a number of areas where compatibility between the two
	 languages could be improved. Finally, we show experiments on actual XSLT
	 stylesheets, demonstrating the applicability of the approach in practice.},
	Address = {New York, NY, USA},
	Author = {Fokoue, Achille and Rose, Kristoffer and Simeon, Jerome and Villard, Lionel},
	Booktitle = {Proc. Int. World Wide Web Conf.},
	Conference-Abbr = {WWW},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1060745.1060844},
	Isbn = {1-59593-046-9},
	Keywords = {XML XSLT XQuery translation compilation expressiveness},
	Location = {Chiba, Japan},
	Pages = {682--691},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Translating/Fokoue.Rose.ea_XSLT2XQuery_WWW_2005.pdf},
	Publisher = {ACM Press},
	Title = {Compiling XSLT 2.0 into XQuery 1.0},
	Url = {http://portal.acm.org/citation.cfm?id=1060745.1060844},
	Year = {2005}}

@inproceedings{Frasincar.Houben.ea_XALAlgebra_CRPITS_2002,
	Abstract = {This paper proposes XAL, an XML
	 ALgebra. Its novelty is based on the simplicity of its data model
	 and its well-defined logical operators, which makes it suitable for
	 composability, optimizability, and semantics definition of a query
	 language for XML data. At the heart of the algebra resides the notion of
	 collection, a concept similar to the mathematician's monad or functional
	 programmer's comprehension. The operators are classified in three
	 clusters: extraction operators retrieve the needed information from XML
	 documents, meta-operators control the evaluation of expressions, and
	 construction operators build new XML documents from the extracted data. The
	 resulting algebra has optimization laws similar to the known laws for
	 transforming relational queries. As a consequence, we propose a heuristic
	 optimization algorithm similar to its relational algebra counterpart.},
	Address = {Darlinghurst, Australia, Australia},
	Author = {Frasincar, Flavius and Houben, Geert-Jan and Pau, Cristian},
	Booktitle = {Proc. Australasian Conf. on Database Technologies},
	Conference-Abbr = {CRPITS},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {0-909925-83-6},
	Keywords = {XML XQuery XAL XML algebra optimization},
	Location = {Melbourne, Victoria, Australia},
	Pages = {49--56},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Frasincar.Houben.ea_XALAlgebra_CRPITS_2002.pdf},
	Publisher = {Australian Computer Society, Inc.},
	Title = {{XAL: an Algebra for XML Query Optimization}},
	Url = {http://portal.acm.org/citation.cfm?id=563906.563912},
	Year = {2002}}

@techreport{Galanis.Viglas.ea_FollowingPathsof_TR_2002,
	Abstract = {This paper introduces an algebraic framework for expressing
	 and evaluating queries over XML data. It presents the underlying
	 assumptions of the framework, describes the input and output of the
	 algebraic operators, and de nes these operators and their semantics. It
	 evaluates the framework with regard to other proposed XML query algebras.
	 Examples show that this framework is flexible enough to capture queries
	 expressed in Quilt, one of the dominant XML query languages. We have used
	 this algebra in the context of an Internet query engine, in which it
	 is used to formulate logical plans for XML-QL queries. We define
	 equivalence rules that provide opportunities for optimization, and
	 give example cases that point out the usefulness of these rules.},
	Author = {Galanis, Leonidas and Viglas, Efstratios and Dewitt, David J. and Naughton, Jeffrey. F. and Maier, David},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {University of Wisconsin},
	Keywords = {XML Quilt algebra xml query optimization niagara},
	Number = {363},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Galanis.Viglas.ea_FollowingPathsof_TR_2002.pdf},
	Title = {{Following the Paths of XML Data: An Algebraic Framework for XML Query Evaluation}},
	Url = {http://www.csd.uch.gr/~hy561/Papers/algebraicXMLframework01.pdf},
	Year = {2002}}

@inproceedings{Gottlob2004Monadic-Datalog-and-the-Expressive-Power-of-Languages,
	Abstract = {Research on information extraction from Web pages (wrapping) has seen much activity recently (particularly systems implementations), but little work has been done on formally studying the expressiveness of the formalisms proposed or on the theoretical foundations of wrapping. In this paper, we first study monadic datalog over trees as a wrapping language. We show that this simple language is equivalent to monadic second order logic (MSO) in its ability to specify wrappers. We believe that MSO has the right expressiveness required for Web information extraction and propose MSO as a yardstick for evaluating and comparing wrappers. Along the way, several other results on the complexity of query evaluation and query containment for monadic datalog over trees are established, and a simple normal form for this language is presented. Using the above results, we subsequently study the kernel fragment Elog- of the Elog wrapping language used in the Lixto system (a visual wrapper generator). Curiously, Elog- exactly captures MSO, yet is easier to use. Indeed, programs in this language can be entirely visually specified.},
	Author = {Gottlob, Georg and Koch, Christoph},
	Booktitle = jacm,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Editor = {51},
	Keywords = {monadic datalog, elog, Web inforation extraction, MSO, complexity, Web querying, XML, XPath},
	Owner = {Tim Furche},
	Pages = {74--113},
	Title = {{Monadic Datalog and the Expressive Power of Languages for Web Information Extraction}},
	Volume = {1},
	Year = {2004}}

@article{Gottlob.Koch.ea_ComplexityXPath_JACM_2005,
	Abstract = {We study the complexity of two central XML processing problems. The rst is XPath 1.0 query processing, which has been shown to be in PTime in previous work. We prove that both the data complexity and the query complexity of XPath 1.0 fall into lower (highly parallelizable) complexity classes, while the combined complexity is PTime-hard. Subsequently, we study the sources of this hardness and identify a large and practically important fragment of XPath 1.0 for which the combined complexity is LogCFL-complete and, therefore, in the highly parallelizable complexity class NC2. The second problem is the complexity of validating XML documents against various typing schemes like Document Type De nitions (DTDs), XML Schema De nitions (XSDs), and tree automata, both with respect to data and to combined complexity. For data complexity, we prove that validation is in LogSpace and depends crucially on how XML data is represented. For the combined complexity, we show that the complexity ranges from LogSpace to LogCFL, depending on the typing scheme.},
	Author = {Gottlob, Georg and Koch, Christoph and Pichler, Reinhard and Segoufin, Luc},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Group = {Matrix Method},
	Journal = {Journal of the ACM},
	Journal-Abbr = {JACM},
	Keywords = {XML XPath complexity querying typing},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Comlexity/Gottlob.Koch.ea_ComplexityXPath_JACM_2005.pdf},
	Title = {{The Complexity of XPath Query Evaluation and XML Typing}},
	Url = {http://www-db.cs.uni-sb.de/~koch/download/jacm2.pdf},
	Year = {2005}}

@inproceedings{Grinev.Lizorkin_FunctionInlXQ_ADBIS_2004,
	Author = {Grinev, Maxim and Lizorkin, Dmitry},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {East-European Conf. on Advances in Databases and Information Systems},
	Conference-Abbr = {ADBIS},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Ee = {http://www.sztaki.hu/conferences/ADBIS/4-Lizorkin.pdf},
	Keywords = {XML XQuery function inlining optimization rewriting},
	Pdf = {QueryEvaluation/XML/Compilation/Grinev.Lizorkin_FunctionInlXQ_ADBIS_2004.pdf},
	Title = {{XQuery Function Inlining for Optimizing XQuery Queries}},
	Url = {http://www.sztaki.hu/conferences/ADBIS/4-Lizorkin.pdf},
	Year = {2004}}

@inproceedings{Grinev.Pleshachkov_RewrTransf_IDEAS_2005,
	Abstract = {The modern XML query language called XQuery includes
	 advanced facilities both to query and to transform XML data. An XQuery
	 query optimizer should be able to optimize any query. For ?querying?
	 queries almost all techniques inherited from SQLoriented DBMS may be
	 applied. The XQuery transformation facilities are XML-specific and
	 have no counterparts in other query languages. That is why XQuery
	 transformational queries need to be optimized with novel techniques.
	 In this paper two kinds of such techniques (namely push predicates
	 down XML element constructors and projection of transformation) are
	 considered. A subset of XQuery for which these techniques can be fully
	 implemented is identified. This subset seems to be the most intersting
	 from the practical viewpoint. Rewriting rules for this subset are
	 proposed and the correctness of these rules is formally justified. For
	 the rest of the language we propose solutions that works for the
	 most of common cases or consider the problems we have encountered.},
	Author = {Grinev, Maxim and Pleshachkov, Peter},
	Booktitle = {Proc. Int. Database Engineering and Application Symposium},
	Conference-Abbr = {IDEAS},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XQuery rewriting transformation query},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Containment/Grinev.Pleshachkov_RewrTransf_IDEAS_2005.pdf},
	Title = {{Rewriting-based Optimization for XQuery Transformational Queries}},
	Url = {http://www.ispras.ru/~grinev/mypapers/rewrite-transformation-ext.pdf},
	Year = {2005}}

@inproceedings{Grohe.Koch.ea_LowerBoundsMem_ICALP_2005,
	Abstract = {We study a clean machine model for external memory and stream
	 processing. We show that the number of scans of the external data induces a
	 strict hierarchy (as long as work space is su ciently small, e.g.,
	 polylogarithmic in the size of the input). We also show that neither joins
	 nor sorting are feasible if the product of the number r(n) of scans
	 of the external memory and the size s(n) of the internal memory bu
	 ers is su ciently small, e.g., of size o(p5 n). We also establish
	 tight bounds for the complexity of XPath evaluation and ltering.},
	Author = {Grohe, Martin and Koch, Christoph and Schweikardt, Nicole},
	Booktitle = {Proc. Int. Colloquium on Automata, Languages, and Programming},
	Conference-Abbr = {ICALP},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML lower bounds memory streaming XPath},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Comlexity/Grohe.Koch.ea_LowerBoundsMem_ICALP_2005.pdf},
	Title = {{Tight Lower Bounds for Query Processing on Streaming and External Memory Data}},
	Url = {http://www.infosys.uni-sb.de/~koch/download/icalp05B075.pdf},
	Year = {2005}}

@inproceedings{Grust2002Accelerating-XPath-Location-Steps,
	Abstract = {This work is a proposal for a database index structure that has been speci cally designed to support the evaluation of XPath queries. As such, the index is capable to support all XPath axes (including ancestor, following, precedingsibling, descendant-or-self, etc.). This feature lets the index stand out among related work on XML indexing structures which had a focus on regular path expressions (which correspond to the XPath axes children and descendantor- self plus name tests). Its ability to start traversals from arbitrary context nodes in an XML document additionally enables the index to support the evaluation of path traversals embedded in XQuery expressions. Despite its exibility, the new index can be implemented and queried using purely relational techniques, but it performs especially well if the underlying database host provides support for R-trees. A performance assessment which shows quite promising results completes this proposal.},
	Author = {Grust, Thorsten},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML, XPath, query evaluation, indexing, pre/post encoding},
	Owner = {Tim Furche},
	Title = {{Accelerating XPath Location Steps}},
	Url = {http://www.in.tu-clausthal.de/~grust/files/xpath-accel.pdf},
	Year = {2002}}

@inproceedings{Grust.Keulen.ea_StaircaseJoin_VLDB_2003,
	Abstract = {Relational query processors derive much of their e ectiveness from
	 the awareness of speci c table properties like sort order, size, or
	 absence of duplicate tuples. This text applies (and adapts) this
	 successful principle to database-supported XML and XPath processing: the
	 relational system is made tree aware, i.e., tree properties like
	 subtree size, intersection of paths, inclusion or disjointness of
	 subtrees are made explicit. We propose a local change to the database
	 kernel, the staircase join, which encapsulates the necessary tree
	 knowledge needed to improve XPath performance. Staircase join operates on
	 an XML encoding which makes this knowledge available at the cost
	 of simple integer operations. We finally report on quite promising
	 experiments with a staircase join enhanced main-memory database kernel.},
	Author = {Grust, Torsten and van Keulen, Maurice and Teubner, Jens},
	Booktitle = {Proc. Int. Conf. on Very Large Databases},
	Conference-Abbr = {VLDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML staircase join structural join relational},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/StructuralJoins/Grust.Keulen.ea_StaircaseJoin_VLDB_2003.pdf},
	Title = {{Staircase Join: Teach A Relational DBMS to Watch its (Axis) Steps}},
	Url = {http://www.inf.uni-konstanz.de/~teubner/publications/watch-axis-steps.pdf},
	Year = {2003}}

@inproceedings{Grust.Sakr.ea_XQueryOnSQL_VLDB_2004,
	Abstract = {Relational database systems may be turned
	 into efficient XML and XPath processors if the system is provided
	 with a suitable relational tree encoding. This paper extends this
	 relational XML processing stack and shows that an RDBMS can also serve
	 as a highly efficient XQuery runtime environment. Our approach is
	 purely relational: XQuery expressions are compiled into SQL code which
	 operates on the tree encoding. The core of the compilation procedure
	 trades XQuery's notions of variable scopes and nested iteration (FLWOR
	 blocks) for equi-joins. The resulting relational XQuery processor
	 closely adheres to the language semantics, e.g., it obeys node identity
	 as well as document and sequence order, and can support XQuery's
	 full axis feature. The system exhibits quite promising performance
	 figures in experiments. Somewhat unexpectedly, we will also see that
	 the XQuery compiler can make good use of SQL's OLAP functionality.},
	Author = {Grust, Torsten and Sakr, Sherif and Teubner, Jens},
	Booktitle = {Proc. Int. Conf. on Very Large Databases},
	Conference-Abbr = {VLDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XQuery relational implementation SQL},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Translating/Grust.Sakr.ea_XQueryOnSQL_VLDB_2004.pdf},
	Title = {{XQuery on SQL Hosts}},
	Url = {http://www.in.tu-clausthal.de/~grust/files/sql-mapping.pdf},
	Year = {2004}}

@inproceedings{Grust.Teubner_RAXQuery_TDM_2004,
	Abstract = {This work may be seen as a further proof of the
	 versatility of the relational database model. Here, we add XQuery to the
	 catalog of languages which RDBMSs are able to "speak" fluently. Given
	 suitable relational encodings of sequences and ordered, unranked
	 trees the two data structures that form the backbone of the XML and
	 XQuery data models we describe a compiler that translates XQuery
	 expressions into a simple and quite standard relational algebra which
	 we expect to be efficiently implementable on top of any relational
	 query engine. The compilation procedure is fully compositional and
	 emits algebraic code that strictly adheres to the XQuery language
	 semantics: document and sequence order as well as node identity are
	 obeyed. We exercise special care in translating arbitrarily nested
	 XQuery FLWOR iteration constructs into equi-joins, an operation which
	 RDBMSs can perform particularly fast. The resulting purely relational
	 XQuery processor shows promising performance figures in experiments.},
	Author = {Grust, Torsten and Teubner, Jens},
	Booktitle = {Proc. Twente Data Management Workshop on XML Databases and Information Retrieval},
	Conference-Abbr = {TDM},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XQuery relational algebra SQL translation},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Translating/Grust.Teubner_RAXQuery_TDM_2004.pdf},
	Title = {{Relational Algebra: Mother Tongue - XQuery: Fluent}},
	Url = {http://www.in.tu-clausthal.de/~grust/files/algebra-mapping.pdf},
	Year = {2004}}

@inproceedings{Guo.Li.ea_ScalableXSLT_APWEB_2004,
	Abstract = {XSLT is an increasingly
	 popular language for processing XML data. It is widely supported by
	 application platform software. However, little optimization effort has been
	 made inside the current XSLT processing engines. Evaluating a very
	 simple XSLT program on a large XML document with a simple schema may
	 result in extensive usage of memory. In this paper, we present a novel
	 notion of Streaming Processing Model (SPM) to evaluate a subset of
	 XSLT programs on XML documents, especially large ones. With SPM, an
	 XSLT processor can transform an XML source document to other formats
	 without extra memory buffers required. Therefore, our approach can not
	 only tackle large source documents, but also produce large results.
	 We demonstrate with a performance study the advantages of the SPM
	 approach. Experimental results clearly confirm that SPM improves
	 XSLT evaluation typically 2 to 10 times better than the existing
	 approaches. Moreover, the SPM approach also features high scalability.},
	Author = {Guo, Zhimao and Li, Min and Wang, Xiaoling and Zhou, Aoying},
	Booktitle = {Proc. Asia Pacific Web Conference},
	Conference-Abbr = {APWEB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XSLT evaluation optimization query languages},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Streaming/Guo.Li.ea_ScalableXSLT_APWEB_2004.pdf},
	Title = {{Scalable XSLT Evaluation}},
	Url = {http://arxiv.org/abs/cs.DB/0408051},
	Year = {2004}}

@article{Hamilton.Selinger_ConversationwithPat_ACMQ_2005,
	Abstract = {Take Pat Selinger of IBM and James Hamilton of Microsoft and put
	 them in a conversation together, and you may hear everything you
	 wanted to know about database technology and weren?t afraid to ask.},
	Author = {Hamilton, James and Selinger, Pat},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {ACM Queue},
	Journal-Abbr = {ACMQ},
	Keywords = {database, vision, metadata, unstructured information},
	Month = {April},
	Number = {3},
	Owner = {Tim Furche},
	Title = {{A Conversation with Pat Selinger}},
	Url = {http://www.acmqueue.org/modules.php?name=Content&pa=showpage&pid=297&page=1},
	Volume = {3},
	Year = {2005}}

@inproceedings{Helmer.Kanne.ea_ParamTranslXPath_WISE_2002,
	Abstract = {We propose a new approach for the efficient
	 evaluationof XPath expressions. This is important, since XPath is
	 notonly used as a simple, stand-alone query language, but isalso an
	 essential ingredient of XQuery and XSLT.The main idea of our approach
	 is to translate XPath intoalgebraic expressions parameterized with
	 programs. Theseprograms are mainly built from navigational primitives
	 likeaccessing the first child or the next sibling. The goals ofthe
	 approach are 1) to enable pipelined evaluation, 2) toavoid producing
	 duplicate (intermediate) result nodes, 3) tovisit as few document
	 nodes as possible, and 4) to avoidvisiting nodes more than once. This
	 improves the existingapproaches, because our method is highly efficient.},
	Address = {Washington, DC, USA},
	Author = {Helmer, Sven and Kanne, Carl-Christian and Moerkotte, Guido},
	Booktitle = {Proc. Int. Conf. on Web Information Systems Engineering},
	Conference-Abbr = {WISE},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {0-7695-1766-8},
	Keywords = {XML XPath algebra Natix translation navgiation},
	Pages = {215--224},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Helmer.Kanne.ea_ParamTranslXPath_WISE_2002.pdf},
	Publisher = {IEEE Computer Society},
	Title = {{Optimized Translation of XPath into Algebraic Expressions Parameterized by Programs Containing Navigational Primitives}},
	Url = {http://www.csd.uch.gr/~hy561/Papers/XPath-Natix-wise02.pdf},
	Year = {2002}}

@inproceedings{Helmer.May.ea_QueryDecorrel_XSym_2003,
	Abstract = {We present algebraic equivalences that
	 allow to unnest nested algebraic expressions for order-preserving
	 algebraic operators. We illustrate how these equivalences can be applied
	 successfully to unnest nested queries given in the XQuery language.
	 Measurements illustrate the performance gains possible by unnesting.},
	Author = {Helmer, Sven and May, Norman and Moerkotte, Guido},
	Booktitle = {Proc. Int. XML Database Symposium},
	Conference-Abbr = {XSym},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XQuery nested queries query decorrelation},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/NestedQueries/Helmer.May.ea_QueryDecorrel_XSym_2003.pdf},
	Title = {{Three Cases for Query Decorrelation in XQuery}},
	Url = {http://pi3.informatik.uni-mannheim.de/~norman/unnesting_xmlsym03.pdf},
	Year = {2003}}

@inproceedings{Hung.Deng.ea_TOSS-TAX_SIGMOD_2004,
	Abstract = {TAX is perhaps the best known extension of the relational algebra to handle
	 queries to XML databases. One problem with TAX (as with many existing
	 relational DBMSs) is that the semantics of terms in a TAX DB are not
	 taken into account when answering queries. Thus, even though TAX
	 answers queries with 100% precision, the recall of TAX is relatively
	 low. Our TOSS system improves the recall of TAX via the concept of a
	 similarity enhanced ontology (SEO). Intuitively, an ontology is a
	 set of graphs describing relationships (such as isa, partof, etc.)
	 between terms in a DB. An SEO also evaluates how similarities between
	 terms (e.g. "J. Ullman", "Jeff Ullman", and "Jeffrey Ullman") affect
	 ontologies. Finally, we show how the algebra proposed in TAX can
	 be extended to take SEOs into account. The result is a system that
	 provides a much higher answer quality than TAX does alone (quality is
	 defined as the square root of the product of precision and recall).
	 We experimentally evaluate the TOSS system on the DBLP and SIGMOD
	 bibliographic databases and show that TOSS has acceptable performance.},
	Address = {New York, NY, USA},
	Author = {Hung, Edward and Deng, Yu and Subrahmanian, V. S.},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of data},
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1007568.1007649},
	Isbn = {1-58113-859-8},
	Keywords = {XML query TAX algebra optimization ontologies similarity queries},
	Location = {Paris, France},
	Pages = {719--730},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Hung.Deng.ea_TOSS-TAX_SIGMOD_2004.pdf},
	Publisher = {ACM Press},
	Title = {{TOSS: An Extension of TAX with Ontologies and Similarity Queries}},
	Url = {http://portal.acm.org/citation.cfm?id=1007649},
	Year = {2004}}

@inproceedings{Iacob.Dekhtyar_TowardsQueryLanguage_WebDB_2005,
	Abstract = {In recent years it has been argued that when XML encodings become complex,
	 DOM trees are no longer adequate for query processing. Alternative
	 representations of XML documents, such as multi-colored trees have
	 been proposed as a replacement for DOM trees for complex markup. In
	 this paper we consider the use of Generalized Ordered-Descendant
	 Directed Acyclic Graphs (GODDAGs) for the purpose of storing and
	 querying complex document- centric XML. GODDAGs are designed to store
	 multihierarchical XML markup over the shared PCDATA content. They support
	 representation of overlapping markup, which otherwise cannot be represented
	 easily in DOM. We describe how the semantics of XPath axes can be
	 modified to define path expressions over GODDAG, and enhance it with
	 the facilities to traverse and query overlapping markup. We provide
	 efficient algorithms for axis evaluation over GODDAG and describe the
	 implementation of the query processor based on our definitions and algorithms.},
	Author = {Iacob, Ionut and Dekhtyar, Alex},
	Booktitle = {Proc. Int. Workshop on the Web and Databases},
	Conference-Abbr = {WebDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XPath multi-hiearchy document-oriented information retrieval text ranges GODDAG},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/XPath/Iacob.Dekhtyar_TowardsQueryLanguage_WebDB_2005.pdf},
	Title = {{Towards a Query Language for Multihierarchical XML: Revisiting XPath}},
	Url = {http://dblab.csr.uky.edu/~eiaco0/publications/webdb05.pdf},
	Year = {2005}}

@article{Jagadish.Al-Khalifa.ea_TIMBER_VLDBJ_2002,
	Abstract = {This paper describes the overall design and architecture
	 of the Timber XML database system currently being implemented at
	 the University of Michigan. The system is based upon a bulk algebra
	 for manipulating trees, and natively stores XML. New access methods
	 have been developed to evaluate queries in the XML context, and new
	 cost estimation and query optimization techniques have also been
	 developed. We present performance numbers to support some of our design
	 decisions. We believe that the key intellectual contribution of this
	 system is a comprehensive set-at-a-time query processing ability in a
	 native XML store, with all the standard components of relational query
	 processing, including algebraic rewriting and a cost-based optimizer.},
	Address = {Secaucus, NJ, USA},
	Author = {Jagadish, H. V. and Al-Khalifa, S. and Chapman, A. and Lakshmanan, L. V. S. and Nierman, A. and Paparizos, S. and Patel, J. M. and Srivastava, D. and Wiwatwattana, N. and Wu, Y. and Yu, C.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1007/s00778-002-0081-x},
	Issn = {1066-8888},
	Journal = {VLDB Journal},
	Journal-Abbr = {VLDBJ},
	Keywords = {XML XQuery TIMBER native database XML TAX algebra},
	Number = {4},
	Pages = {274--291},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Jagadish.Al-Khalifa.ea_TIMBER_VLDBJ_2002.pdf},
	Publisher = {Springer-Verlag New York, Inc.},
	Title = {{TIMBER: A native XML Database}},
	Url = {http://www.eecs.umich.edu/db/timber/files/timber.pdf},
	Volume = {11},
	Year = {2002}}

@inproceedings{Jagadish.Lakshmanan.ea_ColorfulXML_SIGMOD_2004,
	Abstract = {XML has a tree-structured data model, which is used to
	 uniformly represent structured as well as semi-structured data, and
	 also enable concise query specification in XQuery, via the use of
	 its XPath (twig) patterns. This in turn can leverage the recently
	 developed technology of structural join algorithms to evaluate the query
	 efficiently. In this paper, we identify a fundamental tension in XML data
	 modeling: (i) data represented as deep trees (which can make effective
	 use of twig patterns) are often un-normalized, leading to update
	 anomalies, while (ii) normalized data tends to be shallow, resulting in
	 heavy use of expensive value-based joins in queries.Our solution
	 to this data modeling problem is a novel multi-colored trees (MCT)
	 logical data model, which is an evolutionary extension of the XML data
	 model, and permits trees with multi-colored nodes to signify their
	 participation in multiple hierarchies. This adds significant semantic
	 structure to individual data nodes. We extend XQuery expressions to
	 navigate between structurally related nodes, taking color into account,
	 and also to create new colored trees as restructurings of an MCT
	 database. While MCT serves as a significant evolutionary extension
	 to XML as a logical data model, one of the key roles of XML is for
	 information exchange. To enable exchange of MCT information, we develop
	 algorithms for optimally serializing an MCT database as XML. We discuss
	 alternative physical representations for MCT databases, using relational
	 and native XML databases, and describe an implementation on top of
	 the Timber native XML database. Experimental evaluation, using our
	 prototype implementation, shows that not only are MCT queries/updates
	 more succinct and easier to express than equivalent shallow tree
	 XML queries, but they can also be significantly more efficient to
	 evaluate than equivalent deep and shallow tree XML queries/updates.},
	Address = {New York, NY, USA},
	Author = {Jagadish, H. V. and Lakshmanan, Laks V. S. and Scannapieco, Monica and Srivastava, Divesh and Wiwatwattana, Nuwee},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1007568.1007598},
	Isbn = {1-58113-859-8},
	Keywords = {XML XQuery multiple hiearchies colored trees graph data model},
	Location = {Paris, France},
	Pages = {251--262},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/XQuery/Jagadish.Lakshmanan.ea_ColorfulXML_SIGMOD_2004.pdf},
	Publisher = {ACM Press},
	Title = {{Colorful XML: One Hierarchy isn't enough}},
	Url = {http://www.research.att.com/~divesh/papers/jlssw2004-mct.pdf},
	Year = {2004}}

@inproceedings{Jagadish.Lakshmanan.ea_TAX_DBPL_2001,
	Abstract = {Querying XML has been the subject of much
	 recent investigation. A formal bulk algebra is essential for applying
	 database-style optimization to XML queries. We develop such an algebra,
	 called TAX (Tree Algebra for XML), for manipulating XML data, modeled
	 as forests of labeled ordered trees. Motivated both by aesthetic
	 considerations of intuitiveness, and by efficient computability and
	 amenability to optimization, we develop TAX as a natural extension of
	 relational algebra, with a small set of operators. TAX is complete for
	 relationl algebra extended with aggregation, and can express most queries
	 expressible in popular XML query langauges. It forms the basis for
	 the TIMBER XML database system currently under development by us.},
	Author = {Jagadish, H. V. and Lakshmanan, Laks V. S. and Srivastava, Divesh and Thompson, Keith},
	Booktitle = {Proc. Int. Workshop on Database Programming Languages},
	Conference-Abbr = {DBPL},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML TAX algebra TIMBER optimization},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Jagadish.Lakshmanan.ea_TAX_DBPL_2001.pdf},
	Title = {{TAX: A Tree Algebra for XML}},
	Url = {http://www.cs.ubc.ca/~laks/tax-dbpl01-cr.pdf},
	Year = {2001}}

@inproceedings{Kaushik.Bohannon.ea_FBIndex_SIGMOD_2002,
	Abstract = {In this paper, we ask if the
	 traditional relational query acceleration techniques of summary tables and
	 covering indexes have analogs for branching path expression queries
	 over tree- or graph-structured XML data. Our answer is yes --- the
	 forward-and-backward index already proposed in the literature can
	 be viewed as a structure analogous to a summary table or covering
	 index. We also show that it is the smallest such index that covers all
	 branching path expression queries. While this index is very general, our
	 experiments show that it can be so large in practice as to offer
	 little performance improvement over evaluating queries directly on the
	 data. Likening the forward-and-backward index to a covering index on
	 all the attributes of several tables, we devise an index definition
	 scheme to restrict the class of branching path expressions being
	 indexed. The resulting index structures are dramatically smaller and
	 perform better than the full forward-and-backward index for these
	 classes of branching path expressions. This is roughly analogous
	 to the situation in multidimensional or OLAP workloads, in which
	 more highly aggregated summary tables can service a smaller subset
	 of queries but can do so at increased performance. We evaluate the
	 performance of our indexes on both relational decompositions of XML and a
	 native storage technique. As expected, the performance benefit of
	 an index is maximized when the query matches the index definition.},
	Address = {New York, NY, USA},
	Author = {Kaushik, Raghav and Bohannon, Philip and Naughton, Jeffrey F and Korth, Henry F},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/564691.564707},
	Isbn = {1-58113-497-5},
	Keywords = {XML XPath XQuery index forward-backward branching tree},
	Location = {Madison, Wisconsin},
	Pages = {133--144},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/Kaushik.Bohannon.ea_FBIndex_SIGMOD_2002.pdf},
	Publisher = {ACM Press},
	Title = {{Covering indexes for Branching Path Queries}},
	Url = {http://portal.acm.org/citation.cfm?id=564691.564707},
	Year = {2002}}

@inproceedings{Koch.Scherzinger.ea_FluXQueryT_VLDB_2004,
	Abstract = {We introduce an extension of the XQuery language, FluX, that supports
	 event-based query processing and the conscious handling of main memory bu
	 ers. Purely event-based queries of this language can be executed on
	 streaming XML data in a very direct way. We then develop an algorithm
	 that allows to e ciently rewrite XQueries into the event-based FluX
	 language. This algorithm uses order constraints from a DTD to schedule
	 event handlers and to thus minimize the amount of bu ering required
	 for evaluating a query. We discuss the various technical aspects of
	 query optimization and query evaluation within our framework. This
	 is complemented with an experimental evaluation of our approach.},
	Author = {Koch, Christoph and Scherzinger, Stefanie and Schweikardt, Nicole and Stegmaier, Bernhard},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {Proc. Int. Conf. Very Large Databases},
	Conference-Abbr = {VLDB},
	Crossref = {DBLP:conf/vldb/2004},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Ee = {http://www.vldb.org/conf/2004/RS6P2.PDF},
	Keywords = {XML streaming buffer minimization event scheduling FluXQuery},
	Pages = {228-239},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Streaming/Koch.Scherzinger.ea_FluXQueryT_VLDB_2004.pdf},
	Title = {{Schema-based Scheduling of Event Processors and Buffer Minimization for Queries on Structured Data Streams}},
	Url = {http://www.vldb.org/conf/2004/RS6P2.PDF},
	Year = {2004}}

@article{Koch2006Complexity-of-Nonrecursive-XQuery,
	Abstract = {This paper studies the complexity of evaluating functional query languages for complex values such as monad algebra and the recursion-free fragment of XQuery. We show that monad algebra with equality restricted to atomic values is complete for the class TA[2O(n),O(n)] of problems solvable in linear exponential time with a linear number of alternations. The monotone fragment of monad algebra with atomic value equality but without negation is complete for nondeterministic exponential time. For monad algebra with deep equality, we establish TA[2O(n),O(n)] lower and exponential-space upper bounds. Then we study a fragment of XQuery, Core XQuery, that seems to incorporate all the features of a query language on complex values that are traditionally deemed essential. A close connection between monad algebra on lists and Core XQuery (with ?child? as the only axis) is exhibited, and it is shown that these languages are expressively equivalent up to representation issues. We show that Core XQuery is just as hard as monad algebra w.r.t. combined complexity, and that it is in TC0 if the query is assumed fixed.},
	Author = {Koch, Christoph},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {tods},
	Keywords = {XML, XQuery, comlex values, monad algebra, complexity, evaluation},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/tods2-5.pdf},
	Number = {4},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Comlexity/Koch_ComplexityNonRecXQ_PODS_2005.pdf},
	Title = {{On the Complexity of Nonrecursive XQuery and Functional Query Languages on Complex Values}},
	Url = {http://www.infosys.uni-sb.de/~koch/download/0503062.pdf},
	Volume = {31},
	Year = {2006}}

@inproceedings{Koch_CompositionXQuery_WebDB_2005,
	Abstract = {Nonrecursive XQuery is known to be hard for nondeterministic exponential
	 time. Thus it is commonly believed that any algorithm for evaluating
	 XQuery has to require exponential amounts of working memory and doubly
	 exponential time in the worst case. In this paper we present a property
	 - the lack of a certain form of composition - that virtually all
	 real-world XQueries have and that allows for query evaluation in singly
	 exponential time and polynomial space. Still, we are able to show for an
	 important special case - our nonrecursive XQuery fragment restricted to
	 atomic value equality - that the composition-free language is just as
	 expressive as the language with composition. Thus, under widely-held
	 complexity-theoretic assumptions, the composition-free language is an
	 exponentially less succinct version of the language with composition.},
	Author = {Koch, Christoph},
	Booktitle = {Proc. Int. Workshop on the Web and Databases},
	Conference-Abbr = {WebDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XQuery composition expressiveness},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Comlexity/Koch_CompositionXQuery_WebDB_2005.pdf},
	Title = {{On the Role of Composition in XQuery}},
	Url = {http://www-db.cs.uni-sb.de/~koch/download/webdb2005.pdf},
	Year = {2005}}

@inproceedings{Krishnamurthy.Kaushik.ea_X2S_VLDB_2004,
	Abstract = {We consider the e ciency of queries generated by
	 XML to SQL translation. We rst show that published XML-to-SQL query
	 translation algorithms are suboptimal in that they often translate simple
	 path expressions into complex SQL queries even when much simpler
	 equivalent SQL queries exist. There are two logical ways to deal
	 with this problem. One could generate suboptimal SQL queries using a
	 fairly naive translation algorithm, and then attempt to optimize
	 the resulting SQL; or one could use a more intelligent translation
	 algorithm with the hopes of generating e cient SQL directly. We show that
	 optimizing the SQL after it is generated is problematic, becoming
	 intractable even in simple scenarios; by contrast, designing a translation
	 algorithm that exploits information readily available at translation
	 time is a promising alternative. To support this claim, we present a
	 translation algorithm that exploits translation time information to
	 generate e cient SQL for path expression queries over tree schemas.},
	Author = {Krishnamurthy, Rajasekar and Kaushik, Raghav and Naughton, Jeffrey F.},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {Proc. Int. Conf. on Very Large Databases},
	Conference-Abbr = {VLDB},
	Crossref = {DBLP:conf/vldb/2004},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Ee = {http://www.vldb.org/conf/2004/RS4P3.PDF},
	Keywords = {XML translation relational SQL},
	Pages = {144-155},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Translating/Krishnamurthy.Kaushik.ea_X2S_VLDB_2004.pdf},
	Title = {{Efficient XML-to-SQL Query Translation: Where to Add the Intelligence?}},
	Url = {http://www.vldb.org/conf/2004/RS4P3.PDF},
	Year = {2004}}

@inproceedings{Krishnamurthy.Chakaravarthy.ea_X2S_ICDE_2004,
	Abstract = {We consider the problem of translating XML
	 queries intoSQL when XML documents have been stored in an RDBMSusing a
	 schema-based relational decomposition. Surprisingly,there is no published
	 XML-to-SQL query translationalgorithm for this scenario that handles
	 recursive XMLschemas. We present a generic algorithm to translate
	 pathexpression queries into SQL in the presence of recursionin the schema and
	 queries. This algorithm handles a generalclass of XML-to-Relational
	 mappings, which includesall techniques proposed in literature. Some of
	 the salientfeatures of this algorithm are: (i) It translates a path
	 expressionquery into a single SQL query, irrespective of howcomplex
	 the XML schema is, (ii) It uses the "with" clause inSQL99 to handle
	 recursive queries even over non-recursiveschemas, (iii) It reconstructs
	 recursive XML subtrees witha single SQL query and (iv) It shows that
	 the support forlinear recursion in SQL99 is sufficient for handling
	 pathexpression queries over arbitrarily complex recursive XMLschema.},
	Address = {Washington, DC, USA},
	Author = {Krishnamurthy, Rajasekar and Chakaravarthy, Venkatesan T. and Kaushik, Raghav and Naughton, Jeffrey F.},
	Booktitle = {Proc. Int. Conf. on Data Engineering},
	Conference-Abbr = {ICDE},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {0-7695-2065-0},
	Keywords = {XML translation XML query SQL recursive views},
	Pages = {42},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Translating/Krishnamurthy.Chakaravarthy.ea_X2S_ICDE_2004.pdf},
	Publisher = {IEEE Computer Society},
	Title = {{Recursive XML Schemas, Recursive XML Queries, and Relational Storage: XML-to-SQL Query Translation}},
	Url = {http://www.cs.wisc.edu/~sekar/research/recursiveqt.pdf},
	Year = {2004}}

@inproceedings{Krishnamurthy.Kaushik.ea_2SDupl_WebDB_2004,
	Abstract = {We consider the scenario where existing relational
	 data is exported as XML. In this context, we look at the problem of
	 translating XML queries into SQL. XML query languages have two different
	 notions of duplicates: node-identity based and value-based. Path
	 expression queries have an implicit node-identity based duplicate
	 elimination built into them. On the other hand, SQL only supports
	 value-based duplicate elimination. In this paper, using a simple
	 path expression query we illustrate the problems that arise when we
	 attempt to simulate the node-identity based duplicate elimination
	 using value-based duplicate elimination in the SQL queries. We show
	 how a general solution for this problem covering the class of views
	 considered in published literature requires a fairly complex mechanism.},
	Address = {New York, NY, USA},
	Author = {Krishnamurthy, Rajasekar and Kaushik, Raghav and Naughton, Jeffrey F},
	Booktitle = {Proc. Int. Workshop on the Web and Databases},
	Conference-Abbr = {WebDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1017074.1017088},
	Keywords = {XML translation SQL XML},
	Location = {Paris, France},
	Pages = {49--54},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Translating/Krishnamurthy.Kaushik.ea_2SDupl_WebDB_2004.pdf},
	Publisher = {ACM Press},
	Title = {{Unraveling the Duplicate-elimination Problem in XML-to-SQL Query Translation}},
	Url = {http://webdb2004.cs.columbia.edu/papers/4-2.pdf},
	Year = {2004}}

@inproceedings{Lam.Shui.ea_SkippingStrucJ_DASFA_2004,
	Abstract = {The structural join is considered a core operation in
	 processing and optimizing XML queries. Various techniques have been
	 proposed for efficiently finding structural relationships between a
	 list of potential ancestors and a list of potential descendants.
	 This paper presents a novel algorithm for efficiently processing
	 structural joins. Moreover, previous work which performs well usually
	 relies on external index structures such as a B-tree, which increases
	 both the storage and memory overheads. Our proposal in this paper
	 does not require any such data structures, and hence can be easily
	 implemented and incorporated in any existing system. Experiments
	 show that our method significantly outperforms previous algorithms.},
	Author = {Lam, Franky and Shui, William M. and Fisher, Damien K. and Wong, Raymond K.},
	Booktitle = {Int. Conf. on Database Systems for Advanced Applications},
	Conference-Abbr = {DASFA},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XQuery structural joins algorithms efficient evaluation},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/StructuralJoins/Lam.Shui.ea_SkippingStrucJ_DASFA_2004.pdf},
	Title = {{Skipping Strategies for Efficient Structural Joins}},
	Url = {ftp://ftp.cse.unsw.edu.au/pub/doc/papers/UNSW/0320.pdf},
	Year = {2004}}

@inproceedings{Lechner.Preuner.ea_XQuery2XSLT_DASWIS_2002,
	Abstract = {The WWW Consortium (W3C) has recently presented a working draft of
	 XQuery, which is intended to serve as standardized query language for
	 XML. XQuery and other high-level query languages for XML documents
	 are not yet implemented by commercial products. Yet many browsers
	 have already built-in XSLT support for transforming XML documents.
	 XSLT is a standard way of performing structural rearrangement or
	 presentational transformation of XML documents, but formulating complex
	 queries is, compared to XQuery, difficult and error-prone. If XQuery
	 expressions could be translated into XSLT (e.g. by a translator written in
	 Java or XSLT itself), the benefits of Xquery would be immediately
	 available to a wide range of commercial products. This paper introduces a
	 process for translating queries formulated in XQuery syntax into XSL
	 stylesheets. The process is described independently from a particular
	 implementation by means of an ASM (Abstract State Machine). The ASM
	 traverses the parse tree of a particular query and translates each node
	 into corresponding XSLT commands. The result of this translation
	 process is an XSL stylesheet that can be applied to an XML document in
	 order to perform the given query. The presented ASM can be easily
	 coded in Java or XSLT to implement a prototype XQ2XSL translator.},
	Address = {London, UK},
	Author = {Lechner, Stephan and Preuner, G{\"u}nter and Schrefl, Michael},
	Booktitle = {Proc. Int. Workshop on Data Semantics in Web Information Systems},
	Conference-Abbr = {DASWIS},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {3-540-44122-0},
	Keywords = {XML XQuery XSLT translation abstract machine},
	Pages = {239--252},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Translating/Lechner.Preuner.ea_XQuery2XSLT_DASWIS_2002.pdf},
	Publisher = {Springer-Verlag},
	Title = {{Translating XQuery into XSLT}},
	Url = {http://www.dke.jku.at/research/projects/xq2xsl/xq2xslDASWIS01.pdf},
	Year = {2002}}

@inproceedings{Li.Ferreira.ea_CompileXML_ICS_2003,
	Abstract = {Declarative, high-level, and/or
	 application-class specific languages are often successful in easing
	 application development. In this paper, we report our experiences
	 in compiling a recently developed XML Query Language, XQuery for
	 applications that process scientific datasets.Though scientific data
	 processing applications can be conveniently represented in XQuery,
	 compiling them to achieve efficient execution involves a number of
	 challenges. These are, 1) analysis of recursive functions to identify
	 reduction computations involving only associative and commutative
	 operations, 2) replacement of recursive functions with iterative
	 constructs, 3) parallelization of generalized reduction functions, which
	 particularly requires the synthesis of global reduction functions, 4)
	 application of data-centric transformations on the structure of XQuery,
	 and 5) translation of XQuery processing to an imperative language
	 like C/C++, which is required for using a middleware that offers
	 low-level functionality.This paper describes our solutions towards
	 these problems. By implementing the techniques in a compiler and
	 generating code for a runtime system called Active Data Repository
	 (ADR), we are able to achieve efficient processing of disk-resident
	 datasets and parallelization on a cluster of machines. Our experimental
	 results show that: 1) restructuring transformations, i.e. removing
	 recursion and applying data-centric execution, result in several-folds
	 improvement in performance, and 2) parallel versions achieve good
	 load-balance, and incur no significant overheads besides communication.},
	Address = {New York, NY, USA},
	Author = {Li, Xiaogang and Ferreira, Renato and Agrawal, Gagan},
	Booktitle = {Proc. Int. Conf. on Supercomputing},
	Conference-Abbr = {ICS},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/782814.782823},
	Isbn = {1-58113-733-8},
	Keywords = {XML XQuery compiler support query optimization},
	Location = {San Francisco, CA, USA},
	Pages = {42--52},
	Publisher = {ACM Press},
	Title = {{Compiler Support for Efficient Processing of XML Datasets}},
	Url = {http://portal.acm.org/citation.cfm?id=782823},
	Year = {2003}}

@inproceedings{Li.Yu.ea_Schema-FreeXQuery_VLDB_2004,
	Abstract = {The widespread adoption of XML holds out the promise that document structure can be
	 exploited to specify precise database queries. However, the user may
	 have only a limited knowledge of the XML structure, and hence may
	 be unable to create a correct XQuery, particularly in the context
	 of a heterogeneous information collection. The default is to use
	 keyword-based search and we are all too familiar with how difficult
	 it is to obtain precise answers by these means. We seek to address
	 these problems by introducing the notion of Meaningful Lowest Common
	 Ancestor Structure (MLCAS) for finding related nodes within an XML
	 document. By automatically computing MLCAS and expanding ambiguous
	 tag names, we add new functionalities to XQuery and enable users to
	 take full advantage of XQuery in querying XML data precisely and
	 efficiently without requiring (perfect) knowledge of the document
	 structure. Such a Schema-Free XQuery is potentially of value not just in
	 casual users with partial knowledge of schema, but also in a data
	 integration or data evolution context where one would like a query
	 written once to apply ?forever? as the schema of the data source
	 changes. Our experimental evalua- tion found that it was possible
	 to express a wide variety of queries in a Schema-Free manner and
	 have them return correct results over a broad diversity of schemas.
	 Furthermore, the evaluation of a Schema-Free query is not expensive using a
	 novel stack-based algorithm we develop for computing MLCAS: from 1
	 to 4 times the execution time of an equivalent schema-aware query.},
	Author = {Li, Yunyao and Yu, Cong and Jagadish, H. V.},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {Proc. Int. Conf. on Very Large Data Bases},
	Conference-Abbr = {VLDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Ee = {http://www.vldb.org/conf/2004/RS2P3.PDF},
	Keywords = {XML XQuery schema-free lowest common ancestor approximate query},
	Pages = {72-83},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/XQuery/Li.Yu.ea_Schema-FreeXQuery_VLDB_2004.pdf},
	Title = {{Schema-Free XQuery}},
	Url = {http://www.vldb.org/conf/2004/RS2P3.PDF},
	Year = {2004}}

@inproceedings{Liu.Vincent_XSLT2SQL_DEAS_2003,
	Abstract = {XML has been accepted as a universal
	 format for data interchange and publication. It can be applied in the
	 applications in which the data of a database needs to be viewed in
	 XML format so that the data being viewed takes more semantics and
	 is easily understood. In these applications, the user of the data
	 to be viewed sees only XML data, not the database. He may use XML
	 query languages such as XSLT to query data and the retrieved data is
	 presented in XML format to them. We are interested in the connection
	 between the data that the user sees and the data in the database. More
	 specifically, we are interested in translating XSLT queries to SQL queries.},
	Author = {Liu, Jixue and Vincent, Millist},
	Booktitle = {Proc. Int. Database Engineering and Applications Symposium},
	Conference-Abbr = {DEAS},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XSLT relational implementation SQL query evaluation},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XSLT/Liu.Vincent_Querytranslationfrom_DEAS_2003.pdf},
	Title = {{Query Translation from XSLT to SQL}},
	Url = {http://intl.ieeexplore.ieee.org/xpl/abs_free.jsp?arNumber=1214914},
	Year = {2003}}

@article{Lu.Yu.ea_BenchmarkXMLDB_TOIS_2005,
	Abstract = {XML is emerging as a major standard for
	 representing data on the World Wide Web. Recently, many XML storage models
	 have been proposed to manage XML data. In order to assess an XML
	 database's abilities to deal with XML queries, several benchmarks have
	 also been proposed, including XMark and XMach. However, no reported
	 studies using those benchmarks were found that can provide users with
	 insights on the impacts of a variety of storage models on XML query
	 performance. In this article, we report our first set of results on
	 benchmarking a set of XML database implementations using two XML
	 benchmarks. The selected implementations represent a wide range of
	 approaches, including RDBMS-based systems with document-independent and
	 document-dependent XML-relational schema mapping approaches, and XML native
	 engines based on an Object-Oriented Model and the Document Object
	 Model. Comprehensive experiments were conducted to study relative
	 performance of different approaches and the important issues that affect
	 XML query performance, such as path expression query processing,
	 effectiveness of various partitioning, label-path, and indexing structures.},
	Address = {New York, NY, USA},
	Author = {Lu, Hongjun and Yu, Jeffrey Xu and Wang, Guoren and Zheng, Shihui and Jiang, Haifeng and Yu, Ge and Zhou, Aoying},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1052934.1052940},
	Issn = {1533-5399},
	Journal = {ACM Transactions on Internet Technologies},
	Journal-Abbr = {TOIS},
	Keywords = {XML benchmarking query optimization processor XML databases},
	Number = {1},
	Pages = {154--194},
	Pdf = {QueryEvaluation/XML/Lu.Yu.ea_BenchmarkXMLDB_TOIS_2005.pdf},
	Publisher = {ACM Press},
	Title = {{What Makes the Differences: Benchmarking XML Database Implementations}},
	Url = {http://www.cs.ust.hk/~jianghf/files/bencharmk.pdf},
	Volume = {5},
	Year = {2005}}

@inproceedings{Lu.Chen.ea_TwigsLA_CIKM_2004,
	Abstract = {With the growing importance of
	 semi-structure data in information exchange, much research has been done
	 to provide an effective mechanism to match a twig query in an XML
	 database. A number of algorithms have been proposed recently to process a
	 twig query holistically. Those algorithms are quite efficient for
	 quires with only ancestor-descendant edges. But for queries with mixed
	 ancestor-descendant and parent-child edges, the previous approaches
	 still may produce large intermediate results, even when the input and
	 output size are more manageable. To overcome this limitation, in
	 this paper, we propose a novel holistic twig join algorithm, namely
	 <i>TwigStackList</i>. Our main technique is to look-ahead read some
	 elements in input data steams and cache limited number of them to
	 <i>lists</i> in the main memory. The number of elements in any list is
	 bounded by the length of the longest path in the XML document. We
	 show that <i>TwigStackList</i> is I/O optimal for queries with only
	 ancestor-descendant relationships below branching nodes. Further, even when
	 queries contain parent-child relationship below branching nodes, the
	 set of intermediate results in <i>TwigStackList</i> is guaranteed
	 to be a subset of that in previous algorithms. We complement our
	 experimental results on a range of real and synthetic data to show
	 the significant superiority of <i>TwigStackList</i> over previous
	 algorithms for queries with <i>parent</i>-<i>child</i> relationships.},
	Address = {New York, NY, USA},
	Author = {Lu, Jiaheng and Chen, Ting and Ling, Tok Wang},
	Booktitle = {Proc. Conf. on Information and Knowledge Management},
	Conference-Abbr = {CIKM},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1031171.1031272},
	Isbn = {1-58113-874-1},
	Keywords = {XML query processing twig joins structural joins query optimization},
	Location = {Washington, D.C., USA},
	Pages = {533--542},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/StructuralJoins/Lu.Chen.ea_TwigsLA_CIKM_2004.pdf},
	Publisher = {ACM Press},
	Title = {{Efficient Processing of XML Twig Patterns with Parent Child Edges: A Look-ahead Approach}},
	Url = {http://portal.acm.org/citation.cfm?id=1031272},
	Year = {2004}}

@inproceedings{Marx_FirstOrderPaths_ICDT_2005,
	Abstract = {We give two sufficient conditions on XPath like languages for having first order
	 expressivity, meaning that every first order definable set of paths in
	 an ordered node-labeled tree is definable in that XPath language.
	 They are phrased in terms of expansions of navigational (sometimes
	 called ?Core?) XPath. Adding either complementation, or the more
	 elegant conditional paths is sufficient. A conditional path is an axis
	 relation of the form (one step axis::n[F])+, denoting the transitive
	 closure of the relation expressed by one step axis::n[F]. As neither is
	 expressible in navigational XPath we also give characterizations in
	 terms of first order logic of the answer sets and the sets of paths
	 navigational XPath can define. The first in terms of a suitable two
	 variable fragment, the second in terms of unions of conjunctive queries.},
	Author = {Marx, Maarten},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {Proc. Int. Conf. on Database Theory},
	Conference-Abbr = {ICDT},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Ee = {http://springerlink.metapress.com/openurl.asp?genre=article{\&}issn=0302-9743{\&}volume=3363{\&}spage=114},
	Keywords = {XML XPath completeness first-order logic conditional axes core xpath},
	Pages = {114-128},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/XPath/Marx_FirstOrderPaths_ICDT_2005.pdf},
	Title = {{First Order Paths in Ordered Trees}},
	Url = {http://staff.science.uva.nl/~marx/pub/recent/icdt05.pdf},
	Year = {2005}}

@inproceedings{Marx_ConditionalXPathFirst_PODS_2004,
	Abstract = {XPath is the W3C-standard node addressing
	 language for XML documents. XPath is still under development and
	 its technical aspects are intensively studied. What is missing at
	 present is a clear characterization of the expressive power of XPath,
	 be it either semantical or with reference to some well established
	 existing (logical) formalism. Core XPath (the logical core of XPath 1.0
	 defined by Gottlob et al.) cannot express queries with conditional
	 paths as exemplified by ?do a child step, while test is true at the
	 resulting node.? In a first-order complete extension of Core XPath,
	 such queries are expressible. We add conditional axis relations to
	 Core XPath and show that the resulting language, called conditional
	 XPath, is equally expressive as first-order logic when interpreted on
	 ordered trees. Both the result, the extended XPath language, and the
	 proof are closely related to temporal logic. Specifically, while Core
	 XPath may be viewed as a simple temporal logic, conditional XPath
	 extends this with (counterparts of) the since and until operators.},
	Author = {Marx, Maarten},
	Booktitle = {Proc. ACM Symposium on Principles of Database Systems},
	Conference-Abbr = {PODS},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XPath Qualified Descendant Conditional Axes},
	Month = {6},
	Organization = {ACM},
	Owner = {Tim Furche},
	Pages = {13--22},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/XPath/Marx_ConditionalXPathFirst_PODS_2004.pdf},
	Title = {{Conditional XPath, the First Order Complete XPath Dialect}},
	Url = {http://turing.wins.uva.nl/~marx/pub/recent/pods04.pdf},
	Year = {2004}}

@inproceedings{Marx_XPathwithConditional_EDBT_2004,
	Abstract = {This paper is about the W3C standard
	 node-addressing language for XML documents, called XPath. XPath is still under
	 development. Version 2.0 appeared in 2001 while the theoretical foundations
	 of Version 1.0 (dating from 1998) are still being widely studied.
	 The paper aims at bringing XPath to a ?stable fixed point? in its
	 development: a version which is expressively complete, still manageable
	 computationally, with a user-friendly syntax and a natural semantics. We
	 focus on an important axis relation which is not expressible in XPath
	 1.0 and is very useful in practice: the conditional axis. With it
	 we can express paths specified by for instance ?do a child step,
	 while test is true at the resulting node?. We study the effect of
	 adding conditional axis relations to XPath on its expressive power
	 and the complexity of the query evaluation and query equivalence
	 problems. We define an XPath dialect XCPath which is expressively
	 complete, has a linear time query evaluation algorithm and for which
	 query equivalence given a DTD can be decided in exponential time.},
	Author = {Marx, Maarten},
	Booktitle = {Proc. Extending Database Technology},
	Conference-Abbr = {EDBT},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XPath Qualified Descendant Conditional Axes},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/XPath/Marx_XPathwithConditional_EDBT_2004.pdf},
	Title = {{XPath with Conditional Axis Relations}},
	Url = {http://turing.wins.uva.nl/~marx/pub/edbt04.pdf},
	Year = {2004}}

@article{Marx.Rijke_SemanticCharacterizations_SIGR_2005,
	Abstract = {We give semantic characterizations of the
	 expressive power of navigational XPath (a.k.a. Core XPath) in terms of
	 first order logic. XPath can be used to specify sets of nodes and
	 sets of paths in an XML document tree. We consider both uses. For
	 sets of nodes, XPath is equally expressive as first order logic in
	 two variables. For paths, XPath can be defined using four simple
	 connectives, which together yield the class of first order definable
	 relations which are safe for bisimulation. Furthermore, we give a
	 characterization of the XPath expressible paths in terms of conjunctive queries.},
	Author = {Marx, Maarten and de Rijke, Maarten},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {ACM SIGMOD Record},
	Journal-Abbr = {SIGR},
	Keywords = {XML XPath completeness first-order logic conditional XPath core XPath},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/XPath/Marx.Rijke_SemanticCharacterizations_SIGR_2005.pdf},
	Title = {{Semantic Characterizations of Navigational XPath}},
	Url = {http://turing.wins.uva.nl/~marx/pub/recent/sigmod_record.pdf},
	Year = {2005}}

@inproceedings{May.Helmer.ea_XQueryNatix_XIME-P_2004,
	Abstract = {We give an overview on how XQuery processing works
	 in our native XML database system Natix. After a brief description
	 of the query compiler we focus on the aspect of join ordering when
	 generating query execution plans. Here we show that better plans
	 can be found when extending the search space of the plan generator.},
	Author = {May, Norman and Helmer, Sven and Kanne, Carl-Christian and Moerkotte, Guido},
	Booktitle = {Proc. of Int. Workshop on XQuery Implementation, Experience and Perspectives},
	Conference-Abbr = {XIME-P},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XQuery Natix query optimization order processing},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/OrderDuplicates/May.Helmer.ea_XQueryNatix_XIME-P_2004.pdf},
	Title = {{XQuery Processing in Natix with an Emphasis on Join Ordering}},
	Url = {http://pi3.informatik.uni-mannheim.de/old/publications/ximep2004-joinorder.ps},
	Year = {2004}}

@inproceedings{May.Helmer.ea_NestedQueries_ICDE_2004,
	Abstract = {We present algebraic equivalences that
	 allow to unnest nested algebraic expressions for order-preserving
	 algebraic operators. We illustrate how these equivalences can be applied
	 successfully to unnest nested queries given in the XQuery language.
	 Measurements illustrate the performance gains possible by unnesting.},
	Author = {May, Norman and Helmer, Sven and Moerkotte, Guido},
	Booktitle = {Proc. Int. Conf. on Data Engineering},
	Conference-Abbr = {ICDE},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML nested queries algebra query optimization},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/May.Helmer.ea_NestedQueries_ICDE_2004.pdf},
	Title = {{Nested Queries and Quantifiers in an Ordered Context}},
	Url = {http://pi3.informatik.uni-mannheim.de/old/publications/unnesting_icde2004.pdf},
	Year = {2004}}

@article{McHugh.Abiteboul.ea_Lore-SSDBMS_SIGRec_1997,
	Abstract = {Lore (for Lightweight Object Repository) is a
	 DBMS designed specifically for managing semistructured information.
	 Implementing Lore has required rethinking all aspects of a DBMS, including
	 storage management, indexing, query processing and optimization, and
	 user interfaces. This paper provides an overview of these aspects of
	 the Lore system, as well as other novel features such as dynamic
	 structural summaries and seamless access to data from external sources.},
	Author = {McHugh, Jason and Abiteboul, Serge and Goldman, Roy and Quass, Dallan and Widom, Jennifer},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {SIGMOD Record},
	Journal-Abbr = {SIGRec},
	Keywords = {XML Lore semi-structured data database management algebra optimization graph-shaped},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/McHugh.Abiteboul.ea_Lore-SSDBMS_SIGRec_1997.pdf},
	Title = {{Lore: A Database Management System for Semistructured Data}},
	Url = {http://www-db.stanford.edu/lore/pubs/lore97.pdf},
	Year = {1997}}

@article{Meuss.Schulz_CAAs_TOIS_2001,
	Abstract = {The use of markup languages like SGML, HTML or XML
	 for encoding the strucutre of documents or linguistic data has lead
	 to many databases where entries are adequately described as trees.
	 In this context querying formalisms are interesting that offer the
	 possiblity to refer both to textual content and logical structure. We
	 consider models where the strucutre specified in a query is not only
	 used as a filter, but also for selecting and presenting different
	 parts of the data. If answers are formalized as mapping from query
	 nodes to the database, a simple enumeration of all mappings in the
	 answer set will often suffer from the effect that many answers have
	 common subparts. From a theoretical point of view this may lead to an
	 exponential time complexity of the computation and presentation of all
	 answers. Concentration on the language of so called tree queries?a
	 variant and extension of Kilpelinen's Tree Matching formalism?we
	 introduce the notion of a ?complete answer aggregate? for a given
	 query. This new data strucutre offers a compact view of the set of
	 all answer and supports active exploration of the ansewer space.
	 Since complete answer aggregates use a powerful structure-sharing
	 mechanism their maximal size is of order &sgr;(d?h?q) where d and q
	 respectively denote the size of the database and the query, and h is
	 the maximal depth of a path of the database. An algorithm is given
	 that computes a complete answer aggregate for a given treee query
	 in time &sgr;(d?log(d)?h?). For the sublanguage of so-called rigid
	 tree queries, as well as for so-called ?nonrecursive? databases, an
	 improved bound of :&sgr;(d?log(d)?q) is obtained. The algorithm is based
	 on a specific index structure that supports practical efficiency.},
	Author = {Meuss, Holger and Schulz, Klaus U.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/382979.383042},
	Issn = {1046-8188},
	Journal = {ACM Transactions on Information Systems},
	Journal-Abbr = {TOIS},
	Keywords = {XML query languages visualization navigation browsing CAA complexity},
	Number = {2},
	Pages = {161--215},
	Pdf = {QueryEvaluation/XML/Comlexity/Meuss.Schulz_CAAs_TOIS_2001.pdf},
	Publisher = {ACM Press},
	Title = {{Complete Answer Aggregates for Treelike Databases: A Novel Approach to Combine Querying and Navigation}},
	Url = {http://www.cis.uni-muenchen.de/people/Meuss/Pub/TOIS01.pdf},
	Volume = {19},
	Year = {2001}}

@article{Miklau2004Containment-Equivalence-Fragment-of-XPath,
	Abstract = {XPath is a language for navigating an XML document and selecting a set of element nodes. XPath expressions are used to query XML data, describe key constraints, express transformations, and reference elements in remote documents. This article studies the containment and equivalence problems for a fragment of the XPath query language, with applications in all these contexts.In particular, we study a class of XPath queries that contain branching, label wildcards and can express descendant relationships between nodes. Prior work has shown that languages that combine any two of these three features have efficient containment algorithms. However, we show that for the combination of features, containment is coNP-complete. We provide a sound and complete algorithm for containment that runs in exponential time, and study parameterized PTIME special cases. While we identify one parameterized class of queries for which containment can be decided efficiently, we also show that even with some bounded parameters, containment remains coNP-complete. In response to these negative results, we describe a sound algorithm that is efficient for all queries, but may return false negatives in some cases.},
	Address = {New York, NY, USA},
	Author = {Miklau, Gerome and Suciu, Dan},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/962446.962448},
	Issn = {0004-5411},
	Journal = jacm,
	Journal-Abbr = {JACM},
	Keywords = {XML, XPath, containment, equivalence, type-based optimization},
	Number = {1},
	Pages = {2--45},
	Pdf = {QueryEvaluation/XML/Containment/Miklau.Suciu_ContainmentEquivalence_JACM_2004.pdf},
	Publisher = {ACM Press},
	Title = {{Containment and Equivalence for a Fragment of XPath}},
	Url = {http://portal.acm.org/citation.cfm?id=962448},
	Volume = {51},
	Year = {2004}}

@inproceedings{ONeil.ONeil.ea_ORDPATH_SIGMOD_2004,
	Abstract = {We introduce a hierarchical labeling scheme called ORDPATH that is
	 implemented in the upcoming version of Microsoft{\textregistered} SQL
	 Server?. ORDPATH labels nodes of an XML tree without requiring a
	 schema (the most general case---a schema simplifies the problem). An
	 example of an ORDPATH value display format is "1.5.3.9.1". A compressed
	 binary representation of ORDPATH provides document order by simple
	 byte-by-byte comparison and ancestry relationship equally simply.
	 In addition, the ORDPATH scheme supports insertion of new nodes at
	 arbitrary positions in the XML tree, their ORDPATH values "careted in"
	 between ORDPATHs of sibling nodes, without relabeling any old nodes.},
	Author = {O'Neil, Patrick and O'Neil, Elizabeth and Pal, Shankar and Cseri, Istvan and Schaller, Gideon and Westbury, Nigel},
	Booktitle = sigmod,
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-11-09 21:29:51 +0100},
	Doi = {http://doi.acm.org/10.1145/1007568.1007686},
	Isbn = {1-58113-859-8},
	Keywords = {XML encoding XQuery relational implementation},
	Location = {Paris, France},
	Pages = {903--908},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/ONeil.ONeil.ea_ORDPATH_SIGMOD_2004.pdf},
	Publisher = {ACM Press},
	Title = {{ORDPATHs: Insert-friendly XML Node Labels}},
	Url = {http://www.cs.umb.edu/~poneil/ordpath.pdf},
	Year = {2004}}

@inproceedings{Ordonez_RecursiveSQL_SIGMOD_2005,
	Abstract = {Recursion represents an important addition to the SQL language.
	 This work focuses on the optimization of linear recursive queries in
	 SQL. To provide an abstract framework for discussion, we focus on
	 computing the transitive closure of a graph. Three optimizations
	 are studied: (1) Early evaluation of row selection conditions. (2)
	 Eliminating duplicate rows in intermediate tables. (3) Defining an enhanced
	 index to accelerate join computation. Optimizations are evaluated on
	 two types of graphs: binary trees and sparse graphs. Binary trees
	 represent an ideal graph with no cycles and a linear number of edges.
	 Sparse graphs represent an average case with some cycles and a linear
	 number of edges. In general, the proposed optimizations produce a
	 significant reduction in the evaluation time of recursive queries.},
	Address = {New York, NY, USA},
	Author = {Ordonez, Carlos},
	Booktitle = {Proc. ACM SIGMOD Int. Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1066157.1066260},
	Isbn = {1-59593-060-4},
	Keywords = {SQL recursive queries},
	Location = {Baltimore, Maryland},
	Pages = {834--839},
	Pdf = {QueryEvaluation/RecursiveQueries/Ordonez_RecursiveSQL_SIGMOD_2005.pdf},
	Publisher = {ACM Press},
	Title = {{Optimizing Recursive Queries in SQL}},
	Url = {http://portal.acm.org/citation.cfm?id=1066157.1066260},
	Year = {2005}}

@inproceedings{Page.Hidders.ea_NodeConstr_WebDB_2005,
	Abstract = {In the relational model it has been shown that the flat relational algebra has the
	 same expressive power as the nested relational algebra, as far as
	 queries over flat relations and with flat results are concerned [6].
	 Hence, for each query that uses the nested relational model and that,
	 with a flat table as input always has a flat table as output, there
	 exists an equivalent flat query that only uses the flat relational
	 model. In analogy, we study a related flat-flat problem for XQuery:
	 for each expression containing operations that construct new nodes
	 and whose XML result contains only original nodes, there exists an
	 equivalent ?flat? expression in XQuery that does not construct new nodes.},
	Author = {Page, Wim Le and Hidders, Jan and Michiels, Philippe and Paredaens, Jan and Vercammen, Roel},
	Booktitle = {Proc. Int. Workshop on the Web and Databases},
	Conference-Abbr = {WebDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XQuery node construction expressive power},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Comlexity/Page.Hidders.ea_NodeConstr_WebDB_2005.pdf},
	Title = {{On the Expressive Power of Node Construction in XQuery}},
	Url = {http://www.adrem.ua.ac.be/~rvcamm/publications/WebDB2005.pdf},
	Year = {2005}}

@inproceedings{Paparizos.AlKhalifa.ea_GroupingXML_XMLDM_2002,
	Abstract = {XML permits repeated and missing sub-elements, and missing
	 attributes. We discuss the consequent implications on grouping, both with
	 respect to specification and with respect to implementation. The
	 techniques described here have been implemented in the TIMBER native
	 XML database system being developed at the University of Michigan.},
	Author = {Paparizos, Stelios and Al-Khalifa, Shurug and Jagadish, H. V. and Lakshmanan, Laks V.S. and Nierman, Andrew and Srivastava, Divesh and Wu, Yuqing},
	Booktitle = {EDBT Workshop on XML Data Management},
	Conference-Abbr = {XMLDM},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XQuery, grouping, query optimization, algebra, TAX, XML},
	Number = {2490},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/XQuery/Paparizos.AlKhalifa.ea_GroupingXML_XMLDM_2002.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{Grouping in XML}},
	Url = {http://www.cs.indiana.edu/~yuqwu/papers/XMLDB02-Grouping.pdf},
	Year = {2002}}

@techreport{Paparizos.Al-Khalifa.ea_TIMBERPhysAlg_TR_2002,
	Abstract = {We present a physical algebra for
	 the manipulation of XML in a database. We show how to map logical
	 algebra operators to this physical algebra. We also present several
	 physical algebra identities that are useful for query optimization.
	 This physical algebra is the basis for the implementation of the
	 TIMBER native XML database system at the University of Michigan.},
	Author = {Paparizos, Stelios and Al-Khalifa, Shurug and Jagadish, H.V. and Nierman, Andrew and Wu, Yuqing},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {EECS Department, Univ. of Michigan},
	Keywords = {XML TIMBER physical algebra TAX},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Paparizos.Al-Khalifa.ea_TIMBERPhysAlg_TR_2002.pdf},
	Title = {{A Physical Algebra for XML}},
	Url = {http://www.eecs.umich.edu/db/timber/files/physical.pdf},
	Year = {2002}}

@inproceedings{Paparizos.Wu.ea_TreeLogical_SIGMOD_2004,
	Abstract = {XML is widely praised for its flexibility in allowing
	 repeated and missing sub-elements. However, this flexibility makes it
	 challenging to develop a bulk algebra, which typically manipulates sets
	 of objects with identical structure. A set of XML elements, say of
	 type book, may have members that vary greatly in structure, e.g. in
	 the number of author sub-elements. This kind of heterogeneity may
	 permeate the entire document in a recursive fashion: e.g., different
	 authors of the same or different book may in turn greatly vary in
	 structure. Even when the document conforms to a schema, the flexible
	 nature of schemas for XML still allows such significant variations in
	 structure among elements in a collection. Bulk processing of such
	 heterogeneous sets is problematic.In this paper, we introduce the notion
	 of logical classes (LC) of pattern tree nodes, and generalize the
	 notion of pattern tree matching to handle node logical classes. This
	 abstraction pays off significantly in allowing us to reason with an
	 inherently heterogeneous collection of elements in a uniform, homogeneous
	 way. Based on this, we define a Tree Logical Class (TLC) algebra
	 that is capable of handling the heterogeneity arising in XML query
	 processing, while avoiding redundant work. We present an algorithm
	 to obtain a TLC algebra expression from an XQuery statement (for a
	 large fragment of XQuery). We show how to implement the TLC algebra
	 efficiently, introducing the nest-join as an important physical operator for
	 XML query processing. We show that evaluation plans generated using
	 the TLC algebra not only are simpler but also perform better than
	 those generated by competing approaches. TLC is the algebra used
	 in the Timber [8] system developed at the University of Michigan.},
	Author = {Paparizos, Stelios and Wu, Yuqing and Lakshmanan, Laks V. S. and Jagadish, H. V.},
	Booktitle = {Proc. ACM SIGMOD Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1007568.1007579},
	Isbn = {1-58113-859-8},
	Keywords = {XML XQuery optimization tree locical classes efficiency},
	Location = {Paris, France},
	Pages = {71--82},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Paparizos.Wu.ea_TreeLogical_SIGMOD_2004.pdf},
	Publisher = {ACM Press},
	Title = {{Tree Logical Classes for Efficient Evaluation of XQuery}},
	Url = {http://www.cs.indiana.edu/~yuqwu/papers/SIGMOD04-TLC.pdf},
	Year = {2004}}

@inproceedings{Park.Min.ea_FunInlStrRecXQ_VLDB_2002,
	Abstract = {Structurally recursive XML queries are an important query class that follows the
	 structure of XML data. At present, it is difficult for XQuery to type
	 and optimize structurally recursive queries because of polymorphic
	 recursive functions involved in the queries. In this paper, we propose
	 a new technique called structural function inlining which inlines
	 recursive functions used in a query by making good use of available type
	 information. Based on the technique, we develop a new approach to typing and
	 optimizing structurally recursive queries. The new approach yields
	 a more precise result type for a query. Furthermore, it produces
	 an optimal algebraic expression for the query with respect to the
	 type information. When a structurally recursive query is applied to
	 non-recursive XML data, our approach translates the query into a
	 finitely nested iterations. We conducted several experiments with
	 commonly used real-life and synthetic datasets. The experimental
	 results show that the number of node lookups by our approach is on the
	 average 3.7 times and up to 279.8 times smaller than that by the XQuery
	 core?s current approach in evaluating structurally recursive queries.},
	Author = {Park, Chang-Won and Min, Jun-Ki and Chung, Chin-Wan},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {Proc. Int. Conf. on Very Large Databases},
	Conference-Abbr = {VLDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Ee = {http://www.vldb.org/conf/2002/S04P01.pdf},
	Keywords = {XML XQuery function inlining structurally recursive queries},
	Pages = {83-94},
	Pdf = {QueryEvaluation/XML/Compilation/Park.Min.ea_FunInlStrRecXQ_VLDB_2002.pdf},
	Title = {{Structural Function Inlining Technique for Structurally Recursive XML Queries}},
	Url = {http://www.vldb.org/conf/2002/S04P01.pdf},
	Year = {2002}}

@inproceedings{Pirahesh.Kleewein.ea_SystemRX_SIGMOD_2005,
	Abstract = {This paper describes the overall
	 architecture and design aspects of a hybrid relational and XML database
	 system called System RX. We believe that such a system is fundamental
	 in the evolution of enterprise data management solutions: XML and
	 relational data will co-exist and complement each other in enterprise
	 solutions. Furthermore, a successful XML repository requires much of the
	 same infrastructure that already exists in a relational database
	 management system. Finally, XML query languages have con-siderable
	 conceptual and functional overlap with relational data-flow engines.
	 System RX is the first truly hybrid system that co-mingles XML and
	 relational data, giving them equal footing. The new support for XML
	 includes native support for storage and indexing as well as query
	 compilation and evaluation support for the latest industry-standard
	 query languages, SQL/XML and XQuery. By building a hybrid system, we
	 leverage more than 20 years of data management research to advance XML
	 technology to the same standards expected from mature relational systems.},
	Author = {Pirahesh, Mir Hamid and Kleewein, Jim and Cochrane, Roberta J. and Ozcan, Fatma and Beyer, Kevin S. and Josifovski, Vanja and Lapis, George and Lohman, Guy M. and Lyle, Bob and Seemann, Normen and Truong, Tuong and der Linden, Bert Van and Vickery, Brian and Zhang, Chun},
	Booktitle = {Proc. ACM SIGMOD Int Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML relational database System RX},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Pirahesh.Kleewein.ea_SystemRX_SIGMOD_2005.pdf},
	Title = {{System RX: One Part Relational, One Part XML}},
	Url = {http://www-db.stanford.edu/~widom/cs346/ozcan-paper1.pdf},
	Year = {2005}}

@inproceedings{Ramanan_MinimizingTreePat_SIGMOD_2002,
	Abstract = {We consider the problem of minimizing tree pattern queries (TPQ) that arise in XML and in LDAP-style network directories. In [Minimization of Tree Pattern Queries, Proc. ACM SIGMOD Intl. Conf. Management of Data, 2001, pp. 497-508], Amer-Yahia, Cho, Lakshmanan and Srivastava presented an O(n4) algorithm for minimizing TPQs in the absence of integrity constraints (Case 1); n is the number of nodes in the query. Then they considered the problem of minimizing TPQs in the presence of three kinds of integrity constraints: required-child, required-descendant and subtype (Case 2). They presented an O(n6) algorithm for minimizing TPQs in the presence of only required-child and required-descendant constraints (i.e., no subtypes allowed; Case 3). We present O(n2), O(n4) and O(n2) algorithms for minimizing TPQs in these three cases, respectively, based on the concept of graph simulation. We believe that our O(n2) algorithms for Cases 1 and 3 are runtime optimal.},
	Address = {New York, NY, USA},
	Author = {Ramanan, Prakash},
	Booktitle = sigmod,
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/564691.564726},
	Isbn = {1-58113-497-5},
	Keywords = {XML, tree pattern queries, minimization, containment, type-based optimization},
	Location = {Madison, Wisconsin},
	Pages = {299--309},
	Pdf = {QueryEvaluation/XML/Containment/Ramanan_MinimizingTreePat_SIGMOD_2002.pdf},
	Publisher = {ACM Press},
	Title = {{Efficient Algorithms for Minimizing Tree Pattern Queries}},
	Url = {http://www.cs.wichita.edu/~ramanan/PAPERS/querymin.PDF},
	Year = {2002}}

@inproceedings{Rao.Moon_PRIXIndex_ICDE_2004,
	Abstract = {We propose a new way of indexing XML
	 documents and processing twig patterns in an XML database. Every
	 XML document in the database can be transformed into a sequence of
	 labels by Pr{\"u}fer?s method that constructs a one-to-one correspondence
	 between trees and sequences. During query processing, a twig pattern is
	 also transformed into its Pr{\"u}fer sequence. By performing subsequence
	 matching on the set of sequences in the database, and performing
	 a series of refinement phases that we have developed, we can find
	 all the occurrences of a twig pattern in the database. Our approach
	 allows holistic processing of a twig pattern without breaking the twig
	 into root-to-leaf paths and processing these paths individually.
	 Furthermore, we show in the paper that all correct answers are found
	 without any false dismissals or false alarms. Experimental results
	 demonstrate the performance benefits of our proposed techniques.},
	Author = {Rao, Praveen R. and Moon, Bongki},
	Booktitle = {Proc. Int. Conf. on Data Engineering},
	Conference-Abbr = {ICDE},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML PRIX indexing},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/Rao.Moon_PRIXIndex_ICDE_2004.pdf},
	Title = {{PRIX: Indexing and Querying XML Using Prufer Sequences}},
	Url = {http://www.cs.ucr.edu/~tsotras/cs267/prix.pdf},
	Year = {2004}}

@inproceedings{Sahuguet.Alexe_SubdocumentQueries_WWW_2005,
	Abstract = {This paper describes XSQirrel, a new XML query language that
	 transforms a document into a sub-document, i.e. a tree where the
	 root-to-leaf paths are a subset of the root-to-leaf paths from the original
	 document.We show that this type of queries is extremely useful for various
	 applications (e.g. web services) and that the currently existing
	 query languages are poorly equipped to express, reason and evaluate
	 such queries. In particular, we emphasize the need to be able to
	 compose such queries. We present the XSQirrel language with its syntax,
	 semantics and two language specific operators, union and composition.For
	 the evaluation of the language, we leverage well established query
	 technologies by translating XSQirrel expressions into XPath programs, XQuery
	 queries or XSLT stylesheets.We provide some experimental results
	 that compare our various evaluation strategies. We also show the
	 runtime benefits of query composition over sequential evaluation.},
	Address = {New York, NY, USA},
	Author = {Sahuguet, Arnaud and Alexe, Bogdan},
	Booktitle = {Proc. Int. Conf. on World Wide Web},
	Conference-Abbr = {WWW},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1060745.1060787},
	Isbn = {1-59593-046-9},
	Keywords = {XML XQuery sub-documents identity querying},
	Location = {Chiba, Japan},
	Pages = {268--277},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/XQuery/Sahuguet.Alexe_SubdocumentQueries_WWW_2005.pdf},
	Publisher = {ACM Press},
	Title = {{Sub-document Queries over XML with XSQirrel}},
	Url = {http://portal.acm.org/citation.cfm?id=1060787},
	Year = {2005}}

@inproceedings{Schenkel.Theobald.ea_HOPI_EDBT_2004,
	Abstract = {In this paper we present HOPI, a new connection index for
	 XML documents based on the concept of the 2?hop cover of a directed
	 graph introduced by Cohen et al. In contrast to most of the prior
	 work on XML indexing we consider not only paths with child or parent
	 relationships between the nodes, but also provide space? and time?efficient
	 reachability tests along the ancestor, descendant, and link axes to
	 support path expressions with wildcards in our XXL search engine. We
	 improve the theoretical concept of a 2?hop cover by developing scalable
	 methods for index creation on very large XML data collections with long
	 paths and extensive cross?linkage. Our experiments show substantial
	 savings in the query performance of the HOPI index over previously
	 proposed index structures in combination with low space requirements.},
	Author = {Schenkel, R. and Theobald, A. and Weikum, G.},
	Booktitle = {Proc. Extending Database Technology},
	Conference-Abbr = {EDBT},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML indexing graph transitive closure HOPI},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/Schenkel.Theobald.ea_HOPI_EDBT_2004.pdf},
	Title = {{HOPI: An Efficient Connection Index for Complex XML Document Collections}},
	Url = {http://wwwcs.uni-paderborn.de/cs/ag-boettcher/lehre/SS04/seminar/download/edbt04.HOPI.An.Efficient.Connection.Index.for.Complex.XML.Document.Collections.pdf},
	Year = {2004}}

@inproceedings{Schenkel.Theobald.ea_EfficientHOPI_ICDE_2005,
	Abstract = {The HOPI index, a connection index for XML documents based on
	 the concept of a 2?hop cover, provides space? and time?efficient
	 reachability tests along the ancestor, descendant, and link axes to support
	 path expressions with wildcards in XML search engines. This paper
	 presents enhanced algorithms for building HOPI, shows how to augment the
	 index with distance information, and discusses incremental index
	 maintenance. Our experiments show substantial improvements over the existing
	 divide-and-conquer algorithm for index creation, low space overhead for
	 including distance information in the index, and efficient updates.},
	Author = {Schenkel, Ralf and Theobald, Anja and Weikum, Gerhard},
	Booktitle = {Proc. Int. Conf. on Data Engineering},
	Conference-Abbr = {ICDE},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML indexing HOPI transitive closure},
	Owner = {Tim Furche},
	Pages = {360-371},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/Schenkel.Theobald.ea_EfficientHOPI_ICDE_2005.pdf},
	Title = {{Efficient Creation and Incremental Maintenance of the HOPI Index for Complex XML Document Collections}},
	Url = {http://doi.ieeecomputersociety.org/10.1109/ICDE.2005.57},
	Year = {2005}}

@inproceedings{Schott.Noga_LazyXSLT_DocEng_2003,
	Abstract = {We introduce a lazy XSLT interpreter that provides random access to the
	 transformation result. This allows efficient pipelining of transformation
	 sequences. Nodes of the result tree are computed only upon initial access.
	 As these computations have limited fan-in, sparse output coverage
	 propagates backwards through the pipeline.In comparative measurements
	 with traditional eager implementations, our approach is on par for
	 complete coverage and excels as coverage becomes sparser. In contrast to
	 eager evaluation, lazy evaluation also admits infinite intermediate
	 results, thus extending the design space for transformation sequences.To
	 demonstrate that lazy evaluation preserves the semantics of XSLT, we reduce
	 XSLT to the lambda calculus via a functional language. While this is
	 possible for all languages, most imperative languages cannot profit from
	 the confluence of lambda as only one reduction applies at a time.},
	Author = {Schott, Steffen and Noga, Markus L.},
	Booktitle = {Proc. ACM Symposium on Document Engineering},
	Conference-Abbr = {DocEng},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/958220.958224},
	Isbn = {1-58113-724-9},
	Keywords = {XML XSLT evaluation lazy query languages processing},
	Location = {Grenoble, France},
	Pages = {9--18},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Schott.Noga_LazyXSLT_DocEng_2003.pdf},
	Publisher = {ACM Press},
	Title = {{Lazy XSL Transformations}},
	Url = {http://portal.acm.org/citation.cfm?id=958224},
	Year = {2003}}

@article{Schwentick_XPathContainment_SIGR_2004,
	Abstract = {Consider an XML publish-subscribe scenario with hundreds of subscribers and tens
	 of thousands of XML documents to be delivered per day. Subscribers
	 specify the documents in which they are interested in by means of XPath
	 [8] expressions. If an expression matches a (part of a) document
	 it is delivered to the subscriber. Naturally, it is desired that
	 the decision to which subscriber a document must be sent should be
	 taken quickly. Although the test whether a single XPath expression
	 matches can be done in polynomial time, it is not efficient to test
	 every such expression for every document. Fortunately, there is a
	 partial order on expressions, i.e., for some expressions p; q it might
	 hold that whenever a document matches p it also matches q (denoted
	 p 0 q). If we already know that a document matches p, we do not
	 need to test q anymore, as it matches automatically. Correspond-
	 ingly, if we know that q does not match then p will not match either.
	 Hence, the inclusion structure of the XPath expressions should be
	 computed in advance to decrease online computation time. This leads to
	 the algorithmic problem of XPath Query Containment, i.e., checking
	 whether p 0 q (for a different, index- based approach see, e.g., [6]).},
	Address = {New York, NY, USA},
	Author = {Schwentick, Thomas},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/974121.974140},
	Issn = {0163-5808},
	Journal = {SIGMOD Record},
	Journal-Abbr = {SIGR},
	Keywords = {XML, XPath, containment, type-based optimization, rewriting},
	Number = {1},
	Pages = {101--109},
	Pdf = {QueryEvaluation/XML/Containment/Schwentick_XPathContainment_SIGR_2004.pdf},
	Publisher = {ACM Press},
	Title = {{XPath Query Containment}},
	Url = {http://portal.acm.org/citation.cfm?id=974140},
	Volume = {33},
	Year = {2004}}

@inproceedings{Silberstein.He.ea_BOXesLabel_ICDE_2005,
	Abstract = {Order-based element labeling for tree-structured XML
	 data is an important technique in XML processing. It lies at the
	 core of many fundamental XML operations such as containment join
	 and twig matching. While labeling for static XML documents is well
	 understood, less is known about how to maintain accurate labeling for
	 dynamic XML documents, when elements and subtrees are inserted and
	 deleted. Most existing approaches do not work well for arbitrary
	 update patterns; they either produce unacceptably long labels or incur
	 enormous relabeling costs. We present two novel I/O-efficient data
	 structures, W-BOX and B-BOX, that efficiently maintain labeling for large,
	 dynamic XML documents. We show analytically and experimentally that
	 both, despite consuming minimal amounts of storage, gracefully handle
	 arbitrary update patterns without sacrificing lookup efficiency.
	 The two structures together provide a nice tradeoff between update
	 and lookup costs: W-BOX has logarithmic amortized update cost and
	 constant worst-case lookup cost, while B-BOX has constant amortized
	 update cost and logarithmic worst-case lookup cost. We further propose
	 techniques to eliminate the lookup cost for read-heavy workloads.},
	Author = {Silberstein, Adam and He, Hao and Yi, Ke and Yang, Jun},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {Proc. Int. Conf. on Data Engineering},
	Conference-Abbr = {ICDE},
	Crossref = {DBLP:conf/icde/2005},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Ee = {http://csdl.computer.org/comp/proceedings/icde/2005/2285/00/22850285abs.htm},
	Keywords = {XML labeling indexing boxes maintenance},
	Pages = {285-296},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/Silberstein.He.ea_BOXesLabel_ICDE_2005.pdf},
	Title = {{BOXes: Efficient Maintenance of Order-Based Labeling for Dynamic XML Data}},
	Url = {http://www.cs.duke.edu/dbgroup/papers/2005-ICDE-shyy-xmlorder.pdf},
	Year = {2005}}

@inproceedings{Stefanescu.Thomo.ea_DistribGPQ_SAC_2005,
	Abstract = {Nowadays, we are required to
	 deal with more complex data, prime examples of which are data on
	 the Web, XML data, biological data, etc. There are already proposed
	 abstractions to handle these kinds of data, in particular in terms of
	 semistructured data models. A semistructured model conceives a database
	 essentially as a finite directed labeled graph whose nodes represent
	 objects, and whose edges represent relationships between objects. In
	 this paper, we focus on path queries, which are considered the basic
	 querying mechanism for semistructured data. In essence, such queries are
	 used to navigate, or discover paths that conform to specifications
	 captured by regular expressions. In order to make the navigation more
	 useful, we consider generalized path queries, in which the symbols
	 could optionally be weighted by numbers. Such numbers can express a
	 variety of information about the data that the query could possibly
	 match or navigate.Motivated by the plethora of today's applications
	 utilizing Web services and peer-to-peer architectures, we present
	 a distributed algorithm for evaluating generalized path queries.
	 We follow a realistic model with distributed (non-shared) memory
	 and message-passing between processors. An optimal solution to the
	 problem lies in the intersection of ideas related to distributed query
	 evaluation, distributed shortest path computation, and queueing systems.},
	Address = {New York, NY, USA},
	Author = {Stefanescu, Dan C. and Thomo, Alex and Thomo, Lida},
	Booktitle = {Proc. ACM Symposium on Applied Computing},
	Conference-Abbr = {SAC},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1066677.1066819},
	Isbn = {1-58113-964-0},
	Keywords = {XML general path expressions XPath distributed evaluation},
	Location = {Santa Fe, New Mexico},
	Pages = {610--616},
	Pdf = {QueryEvaluation/XML/ProcessorsAndSystems/Stefanescu.Thomo.ea_DistribGPQ_SAC_2005.pdf},
	Publisher = {ACM Press},
	Title = {{Distributed Evaluation of Generalized Path Queries}},
	Url = {http://portal.acm.org/citation.cfm?id=1066677.1066819},
	Year = {2005}}

@inproceedings{Trombetta.Montesi_EquivalencesXSLT_IDEAS_2004,
	Abstract = {XML is the standard data interchange
	 format and XSLT is the W3C proposed standard for transforming and
	 restructuring XML documents. It turns out that XSLT has very powerful query
	 capabilities as well. However, due to its complex syntax and lack of formal
	 specification, it is not a trivial task to decide whether two XSLT
	 stylesheets yield the same result, even if for an XSLT fragment. We isolate
	 such fragment, powerful enough for expressing several interesting
	 queries and for manipulating XML documents and show how to translate
	 them into queries expressed in a properly extended version of TAX, a
	 powerful XML query algebra, for which we provide a collection of
	 equivalence rules. It is then possible to reason about XSLT equivalences,
	 by translating XSLT queries into XTAX queries and then statically
	 verifying their equivalence, by means of the mentioned equivalence rules.},
	Author = {Trombetta, Alberto and Montesi, Danilo},
	Booktitle = {Proc. Int. Database Engineering and Applications Symposium},
	Conference-Abbr = {IDEAS},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XSLT query languages optimization equivalence},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Containment/Trombetta.Montesi_EquivalencesXSLT_IDEAS_2004.pdf},
	Title = {{Equivalences and Optimizations in an Expressive XSLT Fragment}},
	Url = {http://csdl.computer.org/dl/proceedings/ideas/2004/2168/00/21680171.pdf},
	Year = {2004}}

@inproceedings{Vagena.Moro.ea_TwigGraphs_WebDB_2004,
	Abstract = {XML and semi-structured data is usually modeled using graph structures.
	 Structural summaries, which have been proposed to speedup XML query
	 processing have graph forms as well. The existent approaches for
	 evaluating queries over tree structured data (i.e. data whose underlying
	 structure is a tree) are not directly applicable when the data is
	 modeled as a random graph. Moreover, they cannot be applied when
	 structural summaries are employed and, to the best of our knowledge, no
	 analogous techniques have been reported for this case either. As a
	 result, the potential of structural summaries is not fully exploited.In
	 this paper, we investigate query evaluation techniques applicable
	 to graph-structured data. We propose efficient algorithms for the
	 case of directed acyclic graphs, which appear in many real world
	 situations. We then tailor our approaches to handle other directed
	 graphs as well. Our experimental evaluation reveals the advantages
	 of our solutions over existing methods for graph-structured data.},
	Address = {New York, NY, USA},
	Author = {Vagena, Zografoula and Moro, Mirella M. and Tsotras, Vassilis J.},
	Booktitle = {Proc. Int. Workshop on the Web and Databases},
	Conference-Abbr = {WebDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1017074.1017087},
	Keywords = {XML twig joins structural joins graph-shaped},
	Location = {Paris, France},
	Pages = {43--48},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/StructuralJoins/Vagena.Moro.ea_TwigGraphs_WebDB_2004.pdf},
	Publisher = {ACM Press},
	Title = {{Twig Query Processing over Graph-Structured XML Data}},
	Url = {http://webdb2004.cs.columbia.edu/papers/4-1.pdf},
	Year = {2004}}

@inproceedings{Wang.Park.ea_ViST_SIGMOD_2003,
	Abstract = {With the growing importance of XML in data exchange, much research has been
	 done in providing flexible query facilities to extract data from
	 structured XML documents. In this paper, we propose ViST, a novel
	 index structure for searching XML documents. By representing both
	 XML documents and XML queries in structure-encoded sequences, we
	 show that querying XML data is equivalent to finding subsequence
	 matches. Unlike index methods that disassemble a query into multiple
	 sub-queries, and then join the results of these sub-queries to provide the
	 final answers, ViST uses tree structures as the basic unit of query
	 to avoid expensive join operations. Furthermore, ViST provides a
	 unified index on both content and structure of the XML documents, hence
	 it has a performance advantage over methods indexing either just
	 content or structure. ViST supports dynamic index update, and it relies
	 solely on B+ Trees without using any specialized data structures that
	 are not well supported by DBMSs. Our experiments show that ViST is
	 effective, scalable, and efficient in supporting structural queries.},
	Address = {New York, NY, USA},
	Author = {Wang, Haixun and Park, Sanghyun and Fan, Wei and Yu, Philip S.},
	Booktitle = {Proc. of ACM SIGMOD Int. Conf. on Management of Data},
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/872757.872774},
	Isbn = {1-58113-634-X},
	Keywords = {XML indexing dynamic ViST query optimization labeling},
	Location = {San Diego, California},
	Pages = {110--121},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/Wang.Park.ea_ViST_SIGMOD_2003.pdf},
	Publisher = {ACM Press},
	Title = {{ViST: A Dynamic Index Method for Querying XML Data by Tree Structures}},
	Url = {http://www.cs.ucr.edu/~tsotras/cs267/vist.pdf},
	Year = {2003}}

@inproceedings{Weigel.Meuss.ea_ContentStructureIDX_WebDB_2004,
	Abstract = {Rooted in electronic publishing,
	 XML is now widely used for modelling and storing structured text
	 documents. Especially in the WWW, retrieval of XML documents is most
	 useful in combination with a relevance-based ranking of the query
	 result. Index structures with ranking support are therefore needed
	 for fast access to relevant parts of large document collections.
	 This paper proposes a classification scheme for both XML ranking
	 models and index structures, allowing to determine which index suits
	 which ranking model. An analysis reveals that ranking parameters
	 related to both the content and structure of the data are poorly
	 supported by most known XML indices. The IR-CADG index, owing to its
	 tight integration of content and structure, supports various XML
	 ranking models in a very efficient retrieval process. Experiments show
	 that it outperforms separate content/structure indexing by more than
	 two orders of magnitude for large corpora of several hundred MB.},
	Address = {New York, NY, USA},
	Author = {Weigel, Felix and Meuss, Holger and Schulz, Klaus U. and Bry, Fran\c{c}ois},
	Booktitle = {Proc. Int. Workshop on the Web and Databases},
	Conference-Abbr = {WebDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1017074.1017092},
	Keywords = {XML indexing content index path index},
	Location = {Paris, France},
	Pages = {67--72},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/Weigel.Meuss.ea_ContentStructureIDX_WebDB_2004.pdf},
	Publisher = {ACM Press},
	Title = {{Content and Structure in Indexing and Ranking XML}},
	Url = {http://portal.acm.org/citation.cfm?id=1017092},
	Year = {2004}}

@inproceedings{Wu.Patel.ea_StructuralJoinOrder_ICDE_2003,
	Abstract = {Structural join operations are central to
	 evaluating queries against XML data, and are typically responsible
	 for consuming a lion?s share of the query processing time. Thus,
	 structural join order selection is at the heart of query optimization
	 in an XML database, just as (value-based) join order selection is
	 central to relational query optimization. In this paper, we introduce
	 five algorithms for structural join order optimization for XML tree
	 pattern matching and present an extensive experimental evaluation. Our
	 experiments demonstrate that many relational rules of thumb are no longer
	 appropriate: for instance, using dynamic programming style optimization is
	 not efficient; limiting consideration to left-deep plans usually
	 misses the best solution. Our experiments also show that a Dynamic
	 Programming optimization with Pruning (DPP) algorithm can find the
	 optimal solution, with low cost relative to the traditional Dynamic
	 Programming (DP) algorithm; and an optimization technique that only
	 considers Fully Pipelined (FP) plans can very quickly choose a plan that
	 in most cases is close to optimal. Our recommendation is that DPP
	 should be used in XML query optimizers where query execution time is
	 expected to be significant, and that FP should be used where it is
	 important to find a good (but not necessarily the best) plan quickly.},
	Author = {Wu, Yuqing and Patel, Jignesh M. and Jagadish, H. V.},
	Booktitle = {Proc. Int. Conf. on Data Engineering},
	Conference-Abbr = {ICDE},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML operators structural join query plan query optimization},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/StructuralJoins/Wu.Patel.ea_StructuralJoinOrder_ICDE_2003.pdf},
	Title = {{Structural Join Order Selection for XML Query Optimization}},
	Url = {http://csdl.computer.org/dl/proceedings/icde/2003/2071/00/20710443.pdf},
	Year = {2003}}

@inproceedings{Yang.Fontoura.ea_VirtualCursorsXML_CIKM_2004,
	Abstract = {Structural joins are a fundamental operation in XML
	 query processing and a large body of work has focused on index-based
	 algorithms for executing them. In this paper, we describe how two
	 well-known index features -- path indices and ancestor information -- can
	 be combined in a novel way to replace one or more of the physical
	 index cursors in a structural join with <i>virtual cursors</i>. The
	 position of a virtual cursor is derived from the path and ancestor
	 information of a physical cursor. Implementation results are provided to
	 show that, by eliminating index I/O, virtual cursors can improve the
	 performance of structural joins by an order of magnitude or more.},
	Address = {New York, NY, USA},
	Author = {Yang, Beverly and Fontoura, Marcus and Shekita, Eugene and Rajagopalan, Sridhar and Beyer, Kevin},
	Booktitle = {Proc. Conf. on Information and Knowledge Management},
	Conference-Abbr = {CIKM},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1031171.1031271},
	Isbn = {1-58113-874-1},
	Keywords = {XML structural joins twig joins cursors query processing},
	Location = {Washington, D.C., USA},
	Pages = {523--532},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/StructuralJoins/Yang.Fontoura.ea_VirtualCursorsXML_CIKM_2004.pdf},
	Publisher = {ACM Press},
	Title = {{Virtual Cursors for XML Joins}},
	Url = {http://portal.acm.org/citation.cfm?id=1031271},
	Year = {2004}}

@inproceedings{Zhang.Ozsu.ea_NextOfKin_ICDE_2003,
	Abstract = {Path expressions are ubiquitous in XML processing languages.
	 Existing approaches evaluate a path expression by selecting nodes that
	 satisfies the tag-name and value constraints and then joining them
	 according to the structural constraints. In this paper, we propose a
	 novel approach, next-of-kin (NoK) pattern matching, to speed up the
	 nodeselection step, and to reduce the join size significantly in the second
	 step. To efficiently perform NoK pattern matching, we also propose a
	 succinct XML physical storage scheme that is adaptive to updates
	 and streaming XML as well. Our performance results demonstrate that
	 the proposed storage scheme and path evaluation algorithm is highly
	 efficient and outperforms the other tested systems in most cases.},
	Author = {Zhang, Ning and Ozsu, M. Tamer and Kacholia, Varun},
	Booktitle = {Proc. Int. Conf. on Data Engineering},
	Conference-Abbr = {ICDE},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML next-of-kin indexing storage},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/IndexingLabelling/Zhang.Ozsu.ea_NextOfKin_ICDE_2003.pdf},
	Title = {{A Succinct Physical Storage Scheme for Single-Pass Evaluation of Next-of-Kin Path Queries in XML}},
	Url = {http://db.uwaterloo.ca/~ddbms/publications/xml/icde04_storage_NoK.pdf},
	Year = {2003}}

@inproceedings{Zhang2002Honey-I-shrunk-the-XQuery:-an-XML-Algebra-Optimization-Approach,
	Abstract = {A lot of work is being done in the database community on mapping of XML data
	 into and out of relational database systems, specifically, the query
	 processing over such data using XQuery. We discuss our solution, the XML
	 Algebra Tree (XAT), as part of our larger XML management system called
	 Rainbow.Rainbow uses XQuery to describe the loading and extracting of XML
	 data into relational systems and also for the execution of queries
	 against pre-defined XML views of that stored data. The XML algebra tree
	 of the query against those views is merged with the queries that
	 define the views to form a larger tree. Because the XML formatting
	 operators are interleaved with the computation operators, this XAT
	 must then be optimized before being translated into one or more SQL
	 statements that can be executed on the database. SQL translation is
	 composed of computation pushdown and SQL generation.The computation
	 pushdown splits the tree into the XML-specific and SQL-doable operators,
	 which is then going to be converted into SQL statements. However, the
	 XAT after computation pushdown may contain unreferenced columns or
	 unused operators. Leaving these operators in the tree will create
	 unnecessarily large SQL statements and will slow down the overall
	 execution.Our main contributions to XML query processing, outlined in
	 this paper, are threefold. One, we describe an algebra based on XATs
	 for modeling XQuery expressions. Two, we propose rewriting rules to
	 optimize XQueries by XAT operator cancel out. Lastly, we show a cutting
	 algorithm to remove unreferenced columns and operators from the trees. We
	 have fully implemented the techniques discussed in this paper in
	 the Rainbow system. A preliminary experimental study compares the
	 performance of execution before and after operator cancel out and cutting.},
	Author = {Zhang, Xin and Pielech, Bradford and Rundesnteiner, Elke A.},
	Booktitle = widm,
	Conference-Abbr = {WIDM},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-11-09 21:28:14 +0100},
	Doi = {http://doi.acm.org/10.1145/584931.584936},
	Isbn = {1-58113-593-9},
	Keywords = {XML XQuery XAT algebraic optimization XML SQL rewriting optimization},
	Location = {McLean, Virginia, USA},
	Pages = {15--22},
	Pdf = {QueryEvaluation/XML/AlgebraicOptimization/Zhang.Pielech.ea_HoneyIShrunkXAT_WIDM_2002.pdf},
	Publisher = {ACM Press},
	Title = {{Honey, I shrunk the XQuery!: an XML Algebra Optimization Approach}},
	Url = {http://portal.acm.org/citation.cfm?id=584936},
	Year = {2002}}

@inproceedings{Gottlob2002Monadic-Queries-over-Tree-Structured-Data,
	Abstract = {Monadic query languages over trees currently receive considerable interest in the database community, as the problem of selecting nodes from a tree is the most basic and widespread database query problem in the context of XML. Partly a survey of recent work done by the authors and their group on logical query languages for this problem and their expressiveness, this paper provides a number of new results related to the complexity of such languages over so-called axis relations (such as ?child? or ?descendant?) which are motivated by their presence in the XPath standard or by their utility for data extraction (wrapping).},
	Author = {Gottlob, Georg and Koch, Christoph},
	Booktitle = lics,
	Conference-Abbr = {LICS},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {0-7695-1483-9},
	Keywords = {monadic datalog, XPath, complexity, MSO, Core XPath},
	Pages = {189--202},
	Publisher = {IEEE Computer Society},
	Title = {{Monadic Queries over Tree-Structured Data}},
	Url = {http://www.dbai.tuwien.ac.at/proj/games/papers/lics2002.pdf},
	Year = {2002}}

@article{Gottlob.Koch.ea_EfficientXPath_TODS_2005,
	Abstract = {Our experimental analysis of several popular XPath processors reveals a striking fact: Query evaluation in each of the systems requires time exponential in the size of queries in the worst case. We show that XPath can be processed much more e ciently, and propose main-memory algorithms for this problem with polynomial-time combined query evaluation complexity. Moreover, we show how the main ideas of our algorithm can be pro tably integrated into existing XPath processors. Finally, we present two fragments of XPath for which linear-time query processing algorithms exist and another fragment with linear-space/quadratic-time query processing.},
	Author = {Gottlob, Georg and Koch, Christoph and Pichler, Reinhard},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Group = {Matrix Method},
	Journal = {ACM Transactions on Database Systems},
	Journal-Abbr = {TODS},
	Keywords = {XML XPath efficient processing complexity},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Comlexity/Gottlob.Koch.ea_EfficientXPath_TODS_2005.pdf},
	Title = {{Efficient Algorithms for Processing XPath Queries}},
	Url = {http://www.infosys.uni-sb.de/~koch/download/tods1.pdf},
	Year = {2005}}

@inproceedings{Libkin_LogicTrees_ICALP2005,
	Abstract = {Labeled unranked trees are used as a model of XML documents, and logical languages for them 
have been studied actively over the past several years. Such logics have different purposes: some 
are better suited for extracting data, some for expressing navigational properties, and some make 
it easy to relate complex properties of trees to the existence of tree automata for those properties. 
Furthermore, logics differ significantly in their model-checking properties, their automata models, 
and their behavior on ordered and unordered trees. In this paper we present a survey of logics for 
unranked trees.},
	Author = {Libkin, Leonid},
	Booktitle = {Proc. Intl. Colloquium on Automata, Languages and Programming},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Group = {Matrix Method},
	Pages = {35--50},
	Title = {{Logics over Unranked Trees: An Overview}},
	Url = {http://www.cs.toronto.edu/~libkin/papers/icalp05.ps.gz},
	Year = {2005}}

@article{Courcelle_InfiniteTrees_TCS1983,
	Abstract = {Infinite trees naturally arise in the formaliration and the c~udy of fhc \cm;lntic*, 01 
prog-amming languages. This paper investigates some of their i:omninatorial and :iIgcbri\ic 
propei ties that are especially relevant to semantics. 
This paper is concerned in particular with regtilar and algchraic itlfinitc trees, rlor ln.ith rzg\lI;lr 
or algebraic s4f.s of infinite trees. For this reason moss of the propertics s~atcd in rhi$ IVOIX 
become trivial when restricted either to tinite trees or to infinite words. 
It present:, a synthesis of various aspects of infinite trees, invcstigatcd bc diIlt*ic*nt ,tuthor\ III 
differenr contlbxts and hopes to he a unifying step towards a theor! of infinite trct.4 tlliit coultl 
take place near the theory of formal languages and the combina:,:r::c of tk* free monoi,., },
	Author = {Courcelle, Bruno},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {Theoretical Computer Science},
	Keywords = {infinite trees, data model, references, value identity},
	Pages = {95--169},
	Publisher = {Elsevier Science Publishers Ltd.},
	Title = {{Fundamental Properties of Infinite Trees.}},
	Volume = {25},
	Year = {1983}}

@article{Codd_ExtendingRelationalModel_TODS1979,
	Abstract = {During the last three or four years several investigators have been exploring ``semantic models'' for formatted databases. The intent is to capture (in a more or less formal way) more of the meaning of the data so that database design can become more systematic and the database system itself can behave more intelligently. Two major thrusts are clear. (1) the search for meaningful units that are as small as possible---atomic semantics; (2) the search for meaningful units that are larger than the usual n-ary relation---molecular semantics. In this paper we propose extensions to the relational model to support certain atomic and molecular semantics. These extensions represent a synthesis of many ideas from the published work in semantic modeling plus the introduction of new rules for insertion, update, and deletion, as well as new algebraic operators.},
	Address = {New York, NY, USA},
	Author = {Codd, Edgar F.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/320107.320109},
	Issn = {0362-5915},
	Journal = {ACM Transactions on Database Systems},
	Keywords = {RDBMS model surrogates identity},
	Number = {4},
	Pages = {397--434},
	Publisher = {ACM Press},
	Title = {{Extending the Database Relational Model to Capture more Meaning}},
	Url = {http://portal.acm.org/citation.cfm?id=320109},
	Volume = {4},
	Year = {1979}}

@article{Kuper1993The-Logical-Data-Model,
	Abstract = {We propose an object-oriented data model that generalizes the relational, hierarchical, and network models. A database scheme in this model is a directed graph, whose leaves represent data and whose internal nodes represent connections among the data. Instances are constructed from objects, which have separate names and values. We define a logic for the model, and describe a nonprocedural query language that is based on the logic. We also describe an algebraic query language and show that it is equivalent to the logical language.},
	Address = {New York, NY, USA},
	Author = {Kuper, Gabriel M. and Vardi, Moshe Y.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/155271.155274},
	Issn = {0362-5915},
	Journal = tods,
	Keywords = {object identity, logic, graphs, complex value, algebra},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Kuper1993The-Logical-Data-Model},
	Number = {3},
	Pages = {379--413},
	Publisher = {ACM Press},
	Title = {{The Logical Data Model}},
	Url = {http://portal.acm.org/citation.cfm?id=155274},
	Volume = {18},
	Year = {1993}}

@book{Fowler_Plato_HUP1977,
	Author = {Plato},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Editor = {(transl.), Harold N. Fowler},
	Publisher = {Harvard University Press},
	Title = {{Plato in Twelve Volumes}},
	Volume = {9},
	Year = {1977}}

@inproceedings{Grefen_MultiSetAlgebra_ICDE1994,
	Abstract = {The relational data model is based on sets of tuples, i.e. it does not allow duplicate tuples in a relation. Many database languages and systems do require multi-set semantics though, either because of functional requirements or because of the high costs of duplicate removal in database operations. Several proposals have been presented that discuss multi-set semantics. As these proposals tend to be either rather practical, lacking the formal background, or rather formal, lacking the connection...},
	Address = {Washington, DC, USA},
	Author = {Grefen, Paul W. P. J. and de By, Rolf A.},
	Booktitle = {Proc. Intl. Conf. on Data Engineering},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {0-8186-5400-7},
	Keywords = {bags, relational algebra, algebra, optimization, duplicates},
	Pages = {80--88},
	Publisher = {IEEE Computer Society},
	Title = {{A Multi-Set Extended Relational Algebra---A Formal Approach to a Practical Issue}},
	Year = {1994}}

@article{Ceri_Gottlob_Datalog_TKDE1989,
	Abstract = {Datalog, a database query language based on the logic programming paradigm, is described. The syntax and semantics of Datalog and its use for querying a relational database are presented. Optimization methods for achieving efficient evaluations of Datalog queries are classified, and the most relevant methods are presented. Various improvements of Datalog currently under study are discussed, and what is still needed in order to extend Datalog's applicability to the solution of real-life problems is indicated.},
	Address = {Piscataway, NJ, USA},
	Author = {Ceri, Stefano and Gottlob, Georg and Tanca, Letizia},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1109/69.43410},
	Issn = {1041-4347},
	Journal = {IEEE Transactions on Knowledge and Data Engineering},
	Keywords = {Datalog, Prolog, logic programming},
	Number = {1},
	Pages = {146--166},
	Publisher = {IEEE Educational Activities Department},
	Title = {{What You Always Wanted to Know About Datalog (And Never Dared to Ask)}},
	Url = {http://doi.ieeecomputersociety.org/10.1109/69.43410},
	Volume = {1},
	Year = {1989}}

@inproceedings{Grumbach1993Towards-Tractable-Algebras-for-Bags,
	Abstract = {Bags, i.e. sets with duplicates, are often used to implement relations in database systems. In this paper we study the expressive power of algebras for manipulating bags. The algebra we present is a simple extension of the nested relation algebra. Our aim is to investigate how the use of bags in the language extends its expressive power, and increases its complexity. We consider two main issues, namely (i) the relationship between the depth of bag nesting and the expressive power, and (ii) the relationship between the algebraic operations, and their complexity and expressive power. We show that the bag algebra is more expressive than the nested relation algebra (at all levels of nesting), and that the difference may be subtle. We establish a hierarchy based on the structure of algebra expressions. This hierarchy is shown to be highly related to the properties of the powerset operator.},
	Author = {Grumbach, St{\'e}phane and Milo, Tova},
	Booktitle = pods,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {bags, algebra, duplicates, optimization, complex values, nested relational algebra},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Grumbach1993Towards-Tractable-Algebras-for-Bags.pdf},
	Organization = {ACM Press},
	Pages = {49--58},
	Title = {{Towards Tractable Algebras for Bags}},
	Url = {http://portal.acm.org/citation.cfm?id=153855},
	Year = {1993}}

@inproceedings{Khoshafian_ObjectIdentity_OOPSLA1986,
	Abstract = {Identity is that property of an object which distinguishes each object from all others. Identity has been investigated almost independently in general-purpose programming languages and database languages. Its importance is growing as these two environments evolve and merge.We describe a continuum between weak and strong support of identity, and argue for the incorporation of the strong notion of identity at the conceptual level in languages for general purpose programming, database systems and their hybrids. We define a data model that can directly describe complex objects, and show that identity can easily be incorporated in it. Finally, we compare different implementation schemes for identity and argue that a surrogate-based implementation scheme is needed to support the strong notion of identity.},
	Address = {New York, NY, USA},
	Author = {Khoshafian, Setrag N. and Copeland, George P.},
	Booktitle = {Proc. Intl. Conf. on Object-oriented Programming Systems, Languages and Applications},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/28697.28739},
	Isbn = {0-89791-204-7},
	Keywords = {OODBMS, object identity, duplicates, object sharing},
	Location = {Portland, Oregon, United States},
	Pages = {406--416},
	Publisher = {ACM Press},
	Title = {{Object Identity}},
	Url = {http://portal.acm.org/citation.cfm?id=28739},
	Year = {1986}}

@article{Abiteboul_ObjectIdentityQL_JACM1998,
	Abstract = {We demonstrate the power of object identities (oids) as a database query language primitive. We develop an object-based data model, whose structural part generalizes most of the known complex-object data models: cyclicity is allowed in both its schemas and instances. Our main contribution is the operational part of the data model, the query language IQL, which uses oids for three critical purposes: (1) to represent data-structures with sharing and cycles, (2) to manipulate sets, and (3) to express any computable database query. IQL can be type checked, can be evaluated bottom-up, and naturally generalizes most popular rule-based languages. The model can also be extended to incorporate type inheritance, without changes to IQL. Finally, we investigate an analogous value-based data model, whose structural part is founded on regular infinte trees and whose operational part is IQL.},
	Address = {New York, NY, USA},
	Author = {Abiteboul, Serge and Kanellakis, Paris C.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/290179.290182},
	Issn = {0004-5411},
	Journal = {Journal of the ACM},
	Keywords = {identity, query languages, object sharing, cycles},
	Number = {5},
	Pages = {798--842},
	Publisher = {ACM Press},
	Title = {{Object Identity as a Query Language Primitive}},
	Url = {http://portal.acm.org/citation.cfm?id=290182},
	Volume = {45},
	Year = {1998}}

@incollection{Atkinson_ea_OOManifesto_MK1992,
	Abstract = {This paper attempts to define an object-oriented database system. It describes the main features and characteristics that a system must have to qualify as an object-oriented database system.
We have separated these characteristics into three groups:

Mandatory, the ones the system must satisfy in order to be termed an object-oriented database system. These are complex objects, object identity, encapsulation, types or classes, inheritance, overriding combined with late binding, extensibility, computational completeness, persistence, secondary storage management, concurrency, recovery and an ad hoc query facility.

Optional, the ones that can be added to make the system better, but which are not mandatory. These are multiple inheritance, type checking and inferencing, distribution, design transactions and versions.

Open, the points where the designer can make a number of choices. These are the programming paradigm, the representation system, the type system, and uniformity.
We have taken a position, not so much expecting it to be the final word as to erect a provisional landmark to orient further debate.},
	Address = {San Francisco, CA, USA},
	Author = {Atkinson, Malcolm and DeWitt, David and Maier, David and Bancilhon, Fran{\c c}ois and Dittrich, Klaus and Zdonik, Stanley},
	Booktitle = {{Building an Object-oriented Database System: The Story of O2}},
	Chapter = {1},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Editor = {Bancilhon, Fran{\c c}ois and Delobel, Claude and Kanellakis, Paris},
	Isbn = {1-55860-169-4},
	Keywords = {OODBMS, object identity, principles},
	Pages = {1--20},
	Publisher = {Morgan Kaufmann Publishers Inc.},
	Series = {Morgan Kaufmann Series In Data Management Systems},
	Title = {{The Object-oriented Database System Manifesto}},
	Url = {http://www.cs.cmu.edu/People/clamen/OODBMS/Manifesto/htManifesto/Manifesto.html},
	Year = {1992}}

@article{Stonebraker_ea_INGRES_TODS1976,
	Abstract = {The currently operational (March 1976) version of the INGRES database management system is described. This multiuser system gives a relational view of data, supports two high level nonprocedural data sublanguages, and runs as a collection of user processes on top of the UNIX operating system for Digital Equipment Corporation PDP 11/40, 11/45, and 11/70 computers. Emphasis is on the design decisions and tradeoffs related to (1) structuring the system into processes, (2) embedding one command language in a general purpose programming language, (3) the algorithms implemented to process interactions, (4) the access methods implemented, (5) the concurrency and recovery control currently provided, and (6) the data structures used for system catalogs and the role of the database administrator. Also discussed are (1) support for integrity constraints (which is only partly operational), (2) the not yet supported features concerning views and protection, and (3) future plans concerning the system.},
	Address = {New York, NY, USA},
	Author = {Stonebraker, Michael and Held, Gerald and Wong, Eugene and Kreps, Peter},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/320473.320476},
	Issn = {0362-5915},
	Journal = {ACM Transactions on Database Systems},
	Keywords = {RDBMS QUEL query language relational INGRES duplicates},
	Number = {3},
	Pages = {189--222},
	Publisher = {ACM Press},
	Title = {{The Design and Implementation of INGRES}},
	Url = {http://portal.acm.org/citation.cfm?id=320476},
	Volume = {1},
	Year = {1976}}

@article{Astrahan_ea_SystemR_TODS1976,
	Abstract = {System R is a database management system which provides a high level relational data interface. The systems provides a high level of data independence by isolating the end user as much as possible from underlying storage structures. The system permits definition of a variety of relational views on common underlying data. Data control features are provided, including authorization, integrity assertions, triggered transactions, a logging and recovery subsystem, and facilities for maintaining data consistency in a shared-update environment. This paper contains a description of the overall architecture and design of the system. At the present time the system is being implemented and the design evaluated. We emphasize that System R is a vehicle for research in database architecture, and is not planned as a product.},
	Address = {New York, NY, USA},
	Author = {Astrahan, M. M. and Blasgen, M. W. and Chamberlin, D. D. and Eswaran, K. P. and Gray, J. N. and Griffiths, P. P. and King, W. F. and Lorie, R. A. and McJones, P. R. and Mehl, J. W. and Putzolu, G. R. and Traiger, I. L. and Wade, B. W. and Watson, V.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/320455.320457},
	Issn = {0362-5915},
	Journal = {ACM Transactions on Database Systems},
	Keywords = {RDBMS SQL SystemR query language duplicates},
	Number = {2},
	Pages = {97--137},
	Publisher = {ACM Press},
	Title = {{System R: Relational Approach to Database Management}},
	Url = {http://portal.acm.org/citation.cfm?id=320457},
	Volume = {1},
	Year = {1976}}

@inproceedings{Warren_ea_Prolog_AIPL1977,
	Abstract = {Prolog is a simple but powerful programming language founded on symbolic logic. The basic computational mechanism is a pattern matching process (``unification'') operating on general record structures (``terms'' of logic). We briefly review the language and compare it especially with pure Lisp. The remainder of the paper discusses techniques for implementing Prolog efficiently; in particular we describe how to compile the patterns involved in the matching process. These techniques are as incorporated in our DECsystem-10 Prolog compiler (written in Prolog). The code it generates is comparable in speed with that produced by existing DEC10 Lisp compilers. We argue that pattern matching is a better method for expressing operations on structured data than conventional selectors and constructors - both for the user and for the implementor.},
	Author = {Warren, David H. D. and Pereira, Luis M. and Pereira, Fernando},
	Booktitle = {Proc. Symposium on Artificial Intelligence and Programming Languages},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {Prolog, programming language, logic, programming, bags, sets},
	Pages = {109--115},
	Title = {{Prolog - the Language and its Implementation compared with Lisp}},
	Url = {http://portal.acm.org/citation.cfm?id=806939},
	Year = {1977}}

@article{Shipman_DAPLEX_TODS1981,
	Abstract = {DAPLEX is a database language which incorporates: a formulation of data in terms of entities; a functional representation for both actual and virtual data relationships; a rich collection of language constructs for expressing entity selection criteria; a notion of subtype/supertype relationships among entity types. This paper presents and motivates the DAPLEX language and the underlying data model on which it is based.},
	Address = {New York, NY, USA},
	Author = {Shipman, David W.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/319540.319561},
	Issn = {0362-5915},
	Journal = {ACM Transactions on Database Systems},
	Keywords = {query language DAPLEX multisets identity duplicates},
	Number = {1},
	Pages = {140--173},
	Publisher = {ACM Press},
	Title = {{The Functional Data Model and the Data Languages DAPLEX}},
	Url = {http://portal.acm.org/citation.cfm?id=319561},
	Volume = {6},
	Year = {1981}}

@inproceedings{Dayal_ea_RelationalAlgebraDuplicates_PODS1982,
	Abstract = {In the pure relational model, duplicate tuples are automatically eliminated. Some real world languages such as DAPLEX, however, give users control over duplicate elimination. This paper extends the relational model to include multiset relations, i.e., relations with duplicate tuples. It considers three formalisms for expressing queries in this model: extended relational algebra, tableaux, and DAPLEX. It shows that, as in the original algebra, the equivalence problem for conjunctive expressions in the extended algebra can be solved using tableaux, and is NP-complete. Finally, it demonstrates that the extended algebra and DAPLEX have essentially the same expressiveness relative to conjunctive expressions.},
	Address = {New York, NY, USA},
	Author = {Dayal, Umeshwar and Goodman, Nathan and Katz, Randy H.},
	Booktitle = {Proc. ACM Symposium on Principles of Database Systems},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/588111.588132},
	Isbn = {0-89791-070-2},
	Keywords = {identity, multirelations, multisets, duplicates},
	Location = {Los Angeles, California},
	Pages = {117--123},
	Publisher = {ACM Press},
	Title = {{An Extended Relational Algebra with Control over Duplicate Elimination}},
	Url = {http://portal.acm.org/citation.cfm?id=588132},
	Year = {1982}}

@inproceedings{Klausner_Godman_Multirelations_VLDB1985,
	Abstract = {We argue that a multirelation (relation with duplicates) is not, a semantically independent data object, but rather it should be viewed as a sub- set of columns within a larger relation that has no duplicates. Consequently, at the level of the con- ceptual database, duplicates in base relations or in views are not allowed, nor are operations on mul- tirelations. Multirelations as query output can be specified by designating a subset of some relation's columns for output, while "hiding" the rest of the columns. Similarly, aggregate functions are applied to multirelations by applying them to a column within a relation. Our approach can be applied to extend any query language in a consistent way to have full multirelational expressiveness, and such an extension for the query language QUEL is detailed.},
	Author = {Klausner, Aviel and Goodman, Nathan},
	Booktitle = {Proc. Intl. Conf. on Very Large Data Bases},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {identity, duplicates, RDBMS, algebra, multirelations},
	Pages = {251--258},
	Publisher = {Morgan Kaufmann},
	Title = {{Multirelations --- Semantics and Languages}},
	Url = {http://www.vldb.org/conf/1985/P251.PDF},
	Volume = {11},
	Year = {1985}}

@incollection{przymusinski-local-stratification,
	Author = {Przymusinsik, Teodor},
	Booktitle = {Foundations of Deductive Databases and Logic Programming},
	Chapter = 5,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Editor = {Minker, Jack},
	Pages = {193--216},
	Publisher = {Morgan Kaufmann},
	Title = {{On the Declarative Semantics of Deductive Databases and Logic Programs}},
	Year = 1988}

@incollection{apt-stratification,
	Author = {Apt, Krzysztof and Blair, Howard and Walker, Adrian},
	Booktitle = {Foundations of Deductive Databases and Logic Programming},
	Chapter = 2,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Editor = {Minker, Jack},
	Pages = {89--148},
	Publisher = {Morgan Kaufmann},
	Title = {{Towards a Theory of Deductive Knowledge}},
	Year = 1988}

@techreport{Clark_StylesheetPI_REC_1999,
	Abstract = {This document allows a style sheet to be associated with an XML document by including one or more processing instructions with a target of xml-stylesheet in the document's prolog.},
	Author = {Clark, James},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Title = {{Associating Style Sheets with XML Documents, Version 1.0}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/xml-stylesheet/},
	Year = {1999}}

@techreport{Marsh.ea_XMLID_REC_2005,
	Abstract = {This document defines the meaning of the attribute xml:id as an ID attribute in XML documents and defines processing of this attribute to identify IDs in the absence of validation, without fetching external resources, and without relying on an internal subset.},
	Author = {Marsh, Jonathan and Veillard, Daniel and Walsh, Norman},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {XML Identifier ID References Links Uniqueness},
	Title = {{xml:id Version 1.0}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/2005/REC-xml-id-20050909/},
	Year = {2005}}

@techreport{Clark_RelaxNC_2002,
	Author = {Clark, James},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {OASIS},
	Title = {{RELAX NG Compact Syntax}},
	Type = {Committee Specification},
	Url = {http://www.relaxng.org/compact-20021121.html},
	Year = {2002}}

@techreport{Clark.ea_RelaxNG_2001,
	Author = {Clark, James and Murata, Makoto},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {OASIS},
	Title = {{RELAX NG Specification}},
	Type = {Committee Specification},
	Url = {http://www.relaxng.org/spec-20011203.html},
	Year = {2001}}

@article{Naur.ea_ALGOL_CACM_1963,
	Author = {Backus, J. W. and Bauer, F. L. and Green, J. and Katz, C. and McCarthy, J. and Perlis, A. J. and Rutishauser, H. and Samelson, K. and Vauquois, B. and Wegstein, J. H. and van Wijngaarden, A. and Woodger, M.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {Communications of the ACM},
	Number = {1},
	Pages = {1--17},
	Title = {{Revised Report on the Algorithm Language ALGOL 60}},
	Volume = {6},
	Year = {1963}}

@inproceedings{Braz_RailroadDia_SIDOC_1990,
	Author = {Braz, Liza},
	Booktitle = {Proc. Intl. Conf. on Systems Documentation},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Pages = {23--27},
	Publisher = {ACM Press},
	Title = {{Visual Syntax Diagrams for Programming Language Statements}},
	Year = {1990}}

@manual{ISO_EBNF_1996,
	Booktitle = {{ISO/IEC 14977:1996, Syntactic Metalanguage -- Extended BNF}},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Number = {14977:1996},
	Organization = {ISO/IEC},
	Title = {{ISO/IEC 14977:1996, Syntactic Metalanguage -- Extended BNF}},
	Type = {International Standard},
	Url = {http://standards.iso.org/ittf/PubliclyAvailableStandards/s026153_ISO_IEC_14977_1996(E).zip},
	Year = {1996}}

@techreport{Crocker.ea_ABNF_1997,
	Author = {Crocker, D. and Overell, P.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {IETF},
	Number = {2234},
	Title = {{Augmented BNF for Syntax Specifications: ABNF}},
	Type = {Request for Comment (RFC)},
	Url = {http://www.ietf.org/rfc/rfc2234.txt},
	Year = {1997}}

@article{Dovier.ea_RankBisimulation_ENTCS_2002,
	Author = {Dovier, Agostino and Gentilini, Raffaella and Piazza, Carla and Policriti, Alberto},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Ee = {http://www.elsevier.com/gej-ng/31/29/23/124/25/show/Products/notes/index.htt\#013},
	Journal = {Electronic Notes on Theoretical Computer Science},
	Title = {Rank-Based Symbolic Bisimulation (and Model Checking)},
	Url = {http://wotan.liu.edu/docis/dbl/enitcs/2002_67__RSBMC.html#},
	Volume = {67},
	Year = {2002}}

@article{Gentilini_BiSimulation_JAR_2003,
	Address = {Hingham, MA, USA},
	Author = {Gentilini, R. and Piazza, C. and Policriti, A.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1023/A:1027328830731},
	Issn = {0168-7433},
	Journal = {Journal of Automated Reasoning},
	Number = {1},
	Pages = {73--103},
	Publisher = {Kluwer Academic Publishers},
	Title = {{From Bisimulation to Simulation: Coarsest Partition Problems}},
	Url = {http://www.dimi.uniud.it/~policrit/Papers/JAR_finale.pdf},
	Volume = {31},
	Year = {2003}}

@article{Dovier.ea_AlgBisimulation_TCS_2004,
	Address = {Essex, UK},
	Author = {Dovier, Agostino and Piazza, Carla and Policriti, Alberto},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1016/S0304-3975(03)00361-X},
	Issn = {0304-3975},
	Journal = {Theoretical Computer Science},
	Number = {1-3},
	Pages = {221--256},
	Publisher = {Elsevier Science Publishers Ltd.},
	Title = {{An efficient Algorithm for Computing Bisimulation Equivalence}},
	Url = {http://www.dimi.uniud.it/~policrit/Papers/tcsb959.pdf},
	Volume = {311},
	Year = {2004}}

@inproceedings{Milner1971An-Algebraic-Definition-of-Simulation-Between-Programs,
	Author = {Milner, Robin},
	Booktitle = {Proc. Intl. Joint Conf. on Artificial Intelligence},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Pages = {481-489},
	Title = {{An Algebraic Definition of Simulation Between Programs}},
	Year = {1971}}

@inproceedings{Henzinger.ea_Simulation_FOCS_1995,
	Address = {Washington, DC, USA},
	Author = {Henzinger, M. R. and Henzinger, T. A. and Kopke, P. W.},
	Booktitle = {Proc. Symp. on Foundations of Computer Science (FOCS)},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {0-8186-7183-1},
	Pages = {453},
	Publisher = {IEEE Computer Society},
	Title = {{Computing Simulations on Finite and Infinite Graphs}},
	Year = {1995}}

@techreport{OMG_UML2_2005,
	Abstract = {This UML 2.0: Superstructure is the second of two complementary specifications that represent a major revision to the Object Management Group's Unified Modeling Language (UML), for which the most current version is UML v1.4. The first specification, which serves as the architectural foundation for this specification, is the UML 2.0: Infrastructure. 

This UML 2.0: Superstructure defines the user level constructs required for UML 2.0. It is complemented by UML 2.0: Infrastructure which defines the foundational language constructs required for UML 2.0. The two complementary specifications constitute a complete specification for the UML 2.0 modeling language. 
},
	Author = {{Object Management Group}},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {Object Management Group},
	Keywords = {UML modelling standard OMG},
	Title = {{UML 2.0 Superstructure Specification}},
	Type = {Specification},
	Url = {http://www.omg.org/technology/documents/formal/uml.htm},
	Year = {2005}}

@techreport{Marsh_XMLBase_2001,
	Author = {Marsh, Jonathan},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {XML URI base inclusion resolution},
	Title = {{XML Base}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/xmlbase/},
	Year = {2001}}

@techreport{Biron.ea_XMLSchemaDT_2004,
	Abstract = {XML Schema: Datatypes is part 2 of the specification of the XML Schema language. It defines facilities for defining datatypes to be used in XML Schemas as well as other XML specifications. The datatype language, which is itself represented in XML 1.0, provides a superset of the capabilities found in XML 1.0 document type definitions (DTDs) for specifying datatypes on elements and attributes.},
	Author = {Biron, Paul V. and Malhotra, Ashok},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {XML schema datatypes typing simple types},
	Title = {{XML Schema Part 2: Datatypes Second Edition}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/xmlschema-2/},
	Year = {2004}}

@techreport{Fallside.ea_XMLSchemaPr_2004,
	Abstract = {XML Schema Part 0: Primer is a non-normative document intended to provide an easily readable description of the XML Schema facilities, and is oriented towards quickly understanding how to create schemas using the XML Schema language. XML Schema Part 1: Structures and XML Schema Part 2: Datatypes provide the complete normative description of the XML Schema language. This primer describes the language features through numerous examples which are complemented by extensive references to the normative texts.},
	Author = {Fallside, David C. and Walmsley, Priscilla},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {XML schema typing},
	Title = {{XML Schema Part 0: Primer Second Edition}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/xmlschema-0/},
	Year = {2004}}

@techreport{Clark_XSLT_1999,
	Abstract = {This specification defines the syntax and semantics of XSLT, which is a language for transforming XML documents into other XML documents.

XSLT is designed for use as part of XSL, which is a stylesheet language for XML. In addition to XSLT, XSL includes an XML vocabulary for specifying formatting. XSL specifies the styling of an XML document by using XSLT to describe how the document is transformed into another XML document that uses the formatting vocabulary.

XSLT is also designed to be used independently of XSL. However, XSLT is not intended as a completely general-purpose XML transformation language. Rather it is designed primarily for the kinds of transformations that are needed when XSLT is used as part of XSL.},
	Author = {Clark, James},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {XML XSLT standard recommendation},
	Title = {{XSL Transformations, Version 1.0}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/xslt},
	Year = {1999}}

@article{Abiteboul.Quass.ea_LorelQueryLanguage_JDL_1997,
	Abstract = {We present the Lorel language, designed for querying semistructured data. Semistructured data
	 is becoming more and more prevalent, e.g., in structured documents
	 such as HTML and when performing simple integration of data from
	 multiple sources. Traditional data models and query languages are
	 inappropriate, since semistructured data often is irregular, some data is
	 missing, similar concepts are represented using different types,
	 heterogeneous sets are present, or object structure is not fully known.
	 Lorel is a user-friendly language in the SQL/OQL style for querying
	 such data effectively. For wide applicability, the simple object
	 model underlying Lorel can be viewed as an extension of the ODMG
	 data model and the Lorel language as an extension of OQL. The main
	 novelties of the Lorel language are: (i) the extensive use of coercion to
	 relieve the user from the strict typing of OQL, which is inappropriate
	 for semistructured data; and (ii) powerful path expressions, which
	 permit a flexible form of declarative navigational access and are
	 particularly suitable when the details of the structure are not known to the
	 user. Lorel also includes a declarative update language. Lorel is
	 implemented as the query language of the Lore prototype database
	 management system at Stanford. Information about Lore can be found at
	 http://www-db.stanford.edu/lore. In addition to presenting the Lorel language in full,
	 this paper briefly describes the Lore system and query processor. We
	 also briefly discuss a second implementation of Lorel on top of a
	 conventional object-oriented database management system, the O2 system.},
	Author = {Abiteboul, Serge and Quass, Dallan and McHugh, Jason and Widom, Jennifer and Wienerm, Janet L.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {Intl. Journal on Digital Libraries},
	Journal-Abbr = {JDL},
	Keywords = {XML query languages Lorel language constructs semi-structured query},
	Number = {1},
	Pages = {68--88},
	Pdf = {QueryEvaluation/XML/LanguageConstructs/PathVariables/Abiteboul.Quass.ea_LorelQueryLanguage_JDL_1997.pdf},
	Title = {{The Lorel Query Language for Semistructured Data}},
	Url = {http://www-db.stanford.edu/lore/pubs/lorel96.pdf},
	Volume = {1},
	Year = {1997}}

@techreport{IEEE_POSIX_2004,
	Author = {Group, The Austin},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {IEEE, The Open Group},
	Keywords = {IEEE POSIX, open operating system},
	Number = {1003.1},
	Title = {IEEE Standard 1003.1, 2004 Edition (aka POSIX.1)},
	Type = {IEEE Standard},
	Url = {http://www.opengroup.org/onlinepubs/009695399/},
	Year = {2001-2004}}

@techreport{Duerst.Suignard_IRI_2005,
	Author = {Duerst, M. and Suignard, M.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {IEEE},
	Keywords = {IRI, URI, identifiers, RFC, IEEE, W3C},
	Number = {3987},
	Title = {{Internationalized Resource Identifiers (IRIs)}},
	Type = {RFC (Request for Comments)},
	Url = {http://www.faqs.org/rfcs/rfc3987.html},
	Year = {2005}}

@book{Gosling.Joy.ea_JavaSpec_2005,
	Author = {Gosling, James and Joy, Bill and Steele, Guy and Bracha, Gilad},
	Booktitle = {{Java Language Specification, Third Edition}},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Edition = {3rd},
	Keywords = {Java, JLS, language specification, grammar},
	Publisher = {Addison-Wesley Professional},
	Title = {{Java Language Specification, Third Edition}},
	Url = {http://java.sun.com/docs/books/jls/},
	Year = {2005}}

@techreport{Bray.Hollander.ea_XMLNSRec_W3C_1999,
	Abstract = {XML namespaces provide a simple method for qualifying element and attribute names used in Extensible Markup Language documents by associating them with namespaces identified by URI references.},
	Author = {Bray, Tim and Hollander, Dave and Layman, Andrew},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {XML W3C recommendation namespaces},
	Owner = {Tim Furche},
	Title = {{Namespaces in XML}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/REC-xml-names/},
	Urldate = {2005/09/31},
	Year = {1999}}

@techreport{Bray.Paoli.ea_XMLRec_W3C_2004,
	Abstract = {The Extensible Markup Language (XML) is a subset of SGML that is completely described in this document. Its goal is to enable generic SGML to be served, received, and processed on the Web in the way that is now possible with HTML. XML has been designed for ease of implementation and for interoperability with both SGML and HTML.},
	Author = {Bray, Tim and Paoli, Jean and Sperberg-McQueen, C. M. and Maler, Eve and Yergeau, Fran{\c c}ois},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {XML W3C recommendation},
	Owner = {Tim Furche},
	Title = {{Extensible Markup Language (XML) 1.0 (Third Edition)}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/REC-xml/},
	Urldate = {2005/09/31},
	Year = {2004}}

@techreport{Alschuler.Dolin.ea_ClinicalDocumentArchitecture_TR_2000,
	Author = {Alschuler, Liora and Dolin, Robert H. and Boyer, Sandy and Beebe, Calvin},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {Health Level Seven (HL7)},
	Owner = {Tim Furche},
	Title = {{Clinical Document Architecture Framework}},
	Year = {2000}}

@techreport{Amer-YahiaBotev.XQuery-1.0-and-XPath.2005,
	Abstract = {This document defines the syntax and formal
	 semantics of XQuery 1.0 and XPath 2.0 Full-Text which is a language that
	 extends XQuery 1.0 [XQuery 1.0: An XML Query Language] and XPath 2.0
	 [XML Path Language (XPath) 2.0] with full-text search capabilities.},
	Author = {Amer-Yahia, Sihem and Botev, Chavdar and Buxton, Stephen and Case, Pat and Doerre, Jochen and McBeath, Darin and Rys, Michael and Shanmugasundaram, Jayavel},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {XML XQuery full-text information retrieval},
	Number = {Working Draft},
	Title = {{XQuery 1.0 and XPath 2.0 Full-Text}},
	Url = {http://www.w3.org/TR/xquery-full-text/},
	Year = {2005}}

@inproceedings{Amer-Yahia.Botev.ea_TeXQuery-Full-TextSearch_WWW_2004,
	Abstract = {One of the key benefits of XML is its ability to represent a mix of
	 structured and unstructured (text) data. Although current XML query
	 languages such as XPath and XQuery can express rich queries over
	 structured data, they can only express very rudimentary queries over
	 text data. We thus propose TeXQuery, which is a powerful full-text
	 search extension to XQuery. TeXQuery provides a rich set of fully
	 composable full-text search primitives, such as Boolean connectives,
	 phrase matching, proximity distance, stemming and thesauri. TeXQuery
	 also enables users to seamlessly query over both structured and text
	 data by embedding TeXQuery primitives in XQuery, and vice versa.
	 Finally, TeXQuery supports a flexible scoring construct that can be
	 used to score query results based on full-text predicates. TeXQuery
	 is one of the proposals submitted to the W3C Full-Text Task Force,
	 whose charter is to extend XQuery with full-text search capabilities.},
	Author = {Amer-Yahia, Sihem and Botev, Chavdar and Shanmugasundaram, Jayavel},
	Booktitle = WWW,
	Conference-Abbr = {WWW},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML IR query languages full-text information retrieval},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/InformationRetrieval/Languages/Amer-Yahia.Botev.ea_TeXQuery-Full-TextSearch_WWW_2004.pdf},
	Title = {{TeXQuery: A Full-Text Search Extension to XQuery}},
	Url = {http://www.research.att.com/~sihem/TeXQuery/TeXQuery.pdf},
	Year = {2004}}

@inproceedings{Amer-Yahia.Fernandez.ea_PIX-Exactand_SIGMOD_2003,
	Author = {Amer-Yahia, Sihem and Fernandez, Mary F. and Srivastava, Divesh and Xu, Yu},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML IR information retrieval query languages},
	Owner = {Tim Furche},
	Title = {{PIX: Exact and Approximate Phrase Matching in XML}},
	Url = {http://www.research.att.com/~sihem/publications/demopixSIGMOD03.pdf},
	Year = {2003}}

@inproceedings{Amer-Yahia.Lakshmanan.ea_FleXPath:FlexibleStructure_SIGMOD_2004,
	Abstract = {Querying XML data is a
	 well-explored topic with powerful database-style query languages
	 such as XPath and XQuery set to become W3C standards. An equally
	 compelling paradigm for querying XML documents is full-text search on
	 textual content. In this paper, we study fundamental challenges that
	 arise when we try to integrate these two querying paradigms.While
	 keyword search is based on approximate matching, XPath has exact
	 match semantics. We address this mismatch by considering queries on
	 structure as a "template", and looking for answers that best match this
	 template and the full-text search. To achieve this, we provide an
	 elegant definition of relaxation on structure and define primitive
	 operators to span the space of relaxations. Query answering is now
	 based on ranking potential answers on structural and full-text search
	 conditions. We set out certain desirable principles for ranking schemes and
	 propose natural ranking schemes that adhere to these principles. We
	 develop efficient algorithms for answering top-K queries and discuss
	 results from a comprehensive set of experiments that demonstrate the
	 utility and scalability of the proposed framework and algorithms.},
	Author = {Amer-Yahia, Sihem and Lakshmanan, Laks V. S. and Pandit, Shashank},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML IR query languages full-text information retrieval approximation structure},
	Owner = {Tim Furche},
	Title = {{FleXPath: Flexible Structure and Full-Text Querying for XML}},
	Year = {2004}}

@article{Antoniou.Baldoni.ea_ReasoningMethodsPersonalization_AMCT_2004,
	Abstract = {The Semantic Web vision of a next generation Web, in which
	 machines are enabled to understand the meaning of information in
	 order to better interoperate and better support humans in carrying
	 out their tasks, is very appealing and fosters the imagination of
	 smarter applications that can retrieve, process and present information
	 in enhanced ways. In this vision, a particular attention should be
	 devoted to personalization: By bringing the user's needs into the
	 center of interaction processes, personalized Web systems overcome the
	 one-size-fits-all paradigm and provide individually optimized access to
	 Web data and information. In this paper, we provide an overview of
	 recent trends for establishing personalization on the Semantic Web:
	 Based on a discussion on reasoning with rule- and query languages
	 for the Semantic Web, we outline an architecture for service-based
	 personalization, and show results in personalizing Web applications.},
	Author = {Antoniou, Grigoris and Baldoni, Matteo and Baroglio, Cristina and Baumgartner, Robert and Bry, Fran{\c c}ois and Eiter, Thomas and Henze, Nicola and Herzog, Marcus and May, Wolfgang and Patti, Viviana and Schindlauer, Roman and Tompits, Hans and Schaffert, Sebastian},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {Annals of Mathematics, Computing \& Teleinformatics},
	Journal-Abbr = {AMCT},
	Keywords = {Semantic Web Personalization Reasoning REWERSE},
	Number = {1},
	Pages = {1--24},
	Title = {{Reasoning Methods for Personalization on the Semantic Web}},
	Url = {http://www.dbis.informatik.uni-goettingen.de/Publics/04/AMCT04.html},
	Urldate = {2005/01/28},
	Volume = {2},
	Year = {2004}}

@techreport{Apparao.Byrne.ea_DocumentObjectModel_TR_1998,
	Abstract = {This specification defines the Document Object Model Level 1, a platform- and
	 language-neutral interface that allows programs and scripts to dynamically
	 access and update the content, structure and style of documents.
	 The Document Object Model provides a standard set of objects for
	 representing HTML and XML documents, a standard model of how these
	 objects can be combined, and a standard interface for accessing and
	 manipulating them. Vendors can support the DOM as an interface to their
	 proprietary data structures and APIs, and content authors can write
	 to the standard DOM interfaces rather than product-specific APIs,
	 thus increasing interoperability on the Web. The goal of the DOM
	 specification is to define a programmatic interface for XML and HTML. The DOM
	 Level 1 specification is separated into two parts: Core and HTML. The
	 Core DOM Level 1 section provides a low-level set of fundamental
	 interfaces that can represent any structured document, as well as
	 defining extended interfaces for representing an XML document. These
	 extended XML interfaces need not be implemented by a DOM implementation
	 that only provides access to HTML documents; all of the fundamental
	 interfaces in the Core section must be implemented. A compliant DOM
	 implementation that implements the extended XML interfaces is required to
	 also implement the fundamental Core interfaces, but not the HTML
	 interfaces. The HTML Level 1 section provides additional, higher-level
	 interfaces that are used with the fundamental interfaces defined in the
	 Core Level 1 section to provide a more convenient view of an HTML
	 document. A compliant implementation of the HTML DOM implements all
	 of the fundamental Core interfaces as well as the HTML interfaces.},
	Author = {Apparao, Vidur and Byrne, Steve and Champion, Mike and Isaacs, Scott and Jacobs, Ian and Hors, Arnaud Le and Nicol, Gavin and Robie, Jonathan and Sutor, Robert and Wilson, Chris and Wood, Lauren},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {XML DOM W3C data model document object model},
	Owner = {Tim Furche},
	Title = {{Document Object Model (DOM) Level 1 Specification}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/REC-DOM-Level-1/},
	Urldate = {2005/01/31},
	Year = {1998}}

@inproceedings{Augurusa.Braga.ea_DesignandImplementation_SAC_2003,
	Abstract = {As the use of XML is rapidly growing, a growing number of users without
	 programming skills will need to query XML data. Although designed
	 to be easily understood by humans, XQuery, the XML standard query
	 language, has the typical syntax of programming languages, which most
	 users dislike. In this paper we describe a graphical language (XQBE)
	 inspired by "Query By Example" (QBE), a popular relational query
	 language used by MS Access. XQBE covers a significant subset of XQuery
	 and is supported by a prototype enabling the formulation of queries
	 on a graphical interface and their translation into XQuery, thus
	 providing non-trivial querying capabilities to a wide spectrum of users.
	 Simple queries are easily represented in XQBE, but many "complex"
	 queries allow as well for an intuitive graphical representation.},
	Author = {Augurusa, Enrico and Braga, Daniele and Campi, Alessandro and Ceri, Stefano},
	Booktitle = SAC,
	Conference-Abbr = {SAC},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/952532.952759},
	Isbn = {1-58113-624-2},
	Keywords = {XML XQuery visual query language XQBE query-by-example},
	Location = {Melbourne, Florida},
	Pages = {1163--1167},
	Pdf = {QueryEvaluation/XML/XQuery/Augurusa.Braga.ea_DesignandImplementation_SAC_2003.pdf},
	Publisher = {ACM Press},
	Title = {{Design and Implementation of a Graphical Interface to XQuery}},
	Url = {http://dbgroup.elet.polimi.it/xquery/papers/XQBE-SAC03.pdf},
	Year = {2003}}

@inproceedings{Assmann.Henriksson.ea_Comp_PPSWR_2005,
	Abstract = {Previous approaches towards
	 combining rule languages with Description-Logic-based ontologies require
	 specialized reasoners for each specific combination. We outline a
	 general technique for combining various classes of rule languages
	 with various constraint languages including but not restricted to
	 Description-Logic-based ontologies. The combination is such that
	 existing reasoners, considered as software components, can be re-used
	 for reasoning in the combined language, if they support external
	 calls to rules or functions. We specifically formulate the approach
	 as a software component model as studied in software engineering.
	 We illustrate the technique by showing how a subset of SWRL can be
	 implemented by combination of a Datalog interpreter and OWL reasoner.},
	Author = {A{\ss}mann, Uwe and Henriksson, Jakob and Maluszynski, Jan},
	Booktitle = {Proc. Workshop on Principles and Practice of Semantic Web Reasoning},
	Conference-Abbr = {PPSWR},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {composition, Semantic Web, ontologies, rule languages, I3},
	Owner = {Tim Furche},
	Pdf = {SemanticWeb/Ontologies/Assmann.Henriksson.ea_Comp_PPSWR_2005.pdf},
	Title = {{A Hybrid Technique for Composition of Rules and Ontologies for Semantic Web Reasoning}},
	Year = {2005}}

@inproceedings{Backofen.Badea.ea_PosterTowardssemantic_SocBIN_2004,
	Author = {Backofen, Rolf and Badea, Mike and Barahona, Pedro and Badea, Liviu and Bry, Fran{\c c}ois and Dawelbait, Gihan and Doms, Andreas and Fages, Fran{\c c}ois and Goble, Carole and Henschel, Andreas and Hotaran, Anca and Huang, Bingding and Krippahl, Ludwig and Lambrix, Patrick and Nutt, Werner and Schroeder, Michael and Soliman, Sylvain and Will, Sebastian},
	Booktitle = {Prof. Bioinformatics},
	Conference-Abbr = {SocBIN},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {REWERSE Bioinformatics Semantic Web},
	Organization = {SocBIN - Society for Bioinformatics in the Nordic countries},
	Title = {{Poster: Towards a semantic web for bioinformatics}},
	Url = {http://rewerse.net/publications.html#REWERSE-RP-2004-26},
	Year = {2004}}

@inproceedings{Badea.Tilivea.ea_SemanticWebReasoning_PPSWR_2004,
	Abstract = {The Semantic Web should enhance the current World Wide Web with
	 reasoning capabilities for enabling automated processing of possibly
	 distributed information. In this paper we describe an architecture for
	 Semantic Web reasoning and query answering in a very general setting
	 involving several heterogeneous information sources, as well as domain
	 ontologies needed for offering a uniform and source-independent view on
	 the data. Since querying a Web source is very costly in terms of
	 response time, we focus mainly on the query planner of such a system,
	 as it may allow avoiding the access to queryirrelevant sources or
	 combinations of sources based on knowledge about the domain and the sources.},
	Author = {Badea, Liviu and Tilivea, Doina and Hotaran, Anca},
	Booktitle = PPSWR,
	Conference-Abbr = {PPSWR},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {Web Semantic Web REWERSE},
	Organization = {REWERSE},
	Pdf = {SemanticWeb/REWERSE/Badea.Tilivea.ea_SemanticWebReasoning_PPSWR_2004.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{Semantic Web Reasoning for Ontology-Based Integration of Resources}},
	Url = {http://www.ai.ici.ro/papers/ppswr04f.pdf},
	Urldate = {2004/11/11},
	Volume = {3208},
	Year = {2004}}

@inproceedings{Bae.Bailey_CodeXapproachdebugging_WISE_2003,
	Abstract = {XML is now a dominant
	 standard for storing and exchanging information. One very important
	 activity is the transformation of XML documents into other formats,
	 via the transformation language XSLT. XSLT provides a powerful way
	 to perform document conversion and exchange, avoiding reliance on
	 application specific solutions. However, XSLT is a complex language and the
	 current level of support for debugging tools is poor. Many tools
	 that do exist are mainly an extension of conventional techniques for
	 imperative programs and not well-suited to the task. In this paper,
	 we present CodeX, a debugger for XSLT and propose three debugging
	 techniques which are particularly suited to the language. We aim to offer
	 XSLT users a tool which is beneficial in finding errors, as well as
	 facilitating a better understanding of the XML transformation process.},
	Author = {Bae, Eric and Bailey, James},
	Booktitle = {Web Information Systems Engineering, 2003. WISE 2003. Proceedings of the Fourth International Conference on},
	Conference-Abbr = {WISE},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XSLT debugging query languages},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XSLT/Bae.Bailey_CodeXapproachdebugging_WISE_2003.pdf},
	Title = {{CodeX: an approach for debugging XSLT transformations}},
	Url = {http://www.cs.mu.oz.au/~jbailey/papers/wise.ps},
	Year = {2003}}

@inproceedings{Bailey_TransformationandReaction_ADC_2005,
	Abstract = {The transformation and manipulation of XML is an
	 increasingly important research topic. This paper examines a number of
	 issues with regard to languages for transforming and reacting to
	 changes on XML data. On the transformation side, we focus on XSLT, a
	 powerful language for converting XML data into other formats. We look
	 at analysis and optimisation issues for XSLT, as well as support
	 for debugging and automatic generation. On the reactivity side, we
	 focus on an event-condition-action rule approach, which is a natural
	 candidate for the support of reactive functionality on XML repositories.},
	Author = {Bailey, James},
	Booktitle = {Proc. Australasian Database Conference},
	Conference-Abbr = {ADC},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XSLT transformation reactivity research issues},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XSLT/Bailey_TransformationandReaction_ADC_2005.pdf},
	Title = {{Transformation and Reaction Rules for Data on the Web}},
	Url = {http://crpit.com/confpapers/CRPITV39Bailey.pdf},
	Year = {2005}}

@incollection{BaileyBry.Web-and-Semantic-Web.2005,
	Abstract = {A number of techniques have been developed to
	 facilitate powerful data retrieval on the Web and Semantic Web. Three
	 categories of Web query languages can be distinguished, according to
	 the format of the data they can retrieve: XML, RDF and Topic Maps.
	 This article introduces the spectrum of languages falling into these
	 categories and summarises their salient aspects. The languages are
	 introduced using common sample data and query types. Key aspects
	 of the query languages considered are stressed in a conclusion. },
	Author = {Bailey, James and Bry, Fran{\c c}ois and Furche, Tim and Schaffert, Sebastian},
	Booktitle = rw,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Editor = {Maluszinsky, Jan and Eisinger, Norbert},
	Keywords = {RDF, XML, query languages, survey},
	Number = {3564},
	Pages = {35-133},
	Publisher = springer,
	Series = lncs,
	Title = {{Web and Semantic Web Query Languages: A Survey}},
	Year = {2005}}

@inproceedings{Bartlett.Cook_XMLSecurityusing_SS_2003,
	Abstract = {The eXtensible Markup Language (XML) is regarded generally as having promise of
	 becoming established as the general purpose framework for enabling
	 transfer of data amongst heterogeneous environments. It is of interest
	 therefore to analyse how suitable it may be once details of applications
	 requirements and constraints are taken into account. One important
	 requirement is for the security of documents in transit. Closely
	 associated with XML is the eXtensible Stylesheet Language (XSL), whose
	 document transformation component (XSLT) may well have sufficient
	 functionality to perform all reasonable cryptographic transformations
	 to deliver a desired level of document security. We examine this
	 question by describing a real world XML application whose security
	 requirements are more complex than for a simple document transfer
	 between just two parties; proposing a document transfer architecture
	 into which XSLT can be plugged-in; and identifying those features of
	 XSLT which must be applied to meet the application requirements. We
	 conclude that XSLT is only just adequate in the proposed scenario; and
	 then only by making use of its " extension functions " capability.},
	Author = {Bartlett, Robert G. and Cook, Malcolm W.},
	Booktitle = {Proc. Intl. Conf. on System Sciences},
	Conference-Abbr = {SS},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XSLT cryptography security query languages},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XSLT/Bartlett.Cook_XMLSecurityusing_SS_2003.pdf},
	Title = {{XML Security using XSLT}},
	Url = {http://www.cit.uws.edu.au/research/reports/paper/paper02/robert-15-02.pdf},
	Year = {2003}}

@inproceedings{Baumgartner.Gottlob.ea_AnnotatingLegacyWeb_ISWC_2004,
	Abstract = {The Semantic Web is still a vision. The unstructured Web of
	 today contains millions of documents which cannot be queried and
	 where layout and structure are heavily mixed. Moreover, they are not
	 annotated at all. There is a huge gap between Web information and
	 the qualified, structured data as required in corporate information
	 systems. According to the vision of the Semantic Web, all information
	 available on the Web will be suitably structured, annotated, and
	 qualified in the future. However, until this goal is reached, and
	 also, towards a faster achievement of this goal, relevant data can be
	 (semi-)automatically extracted from HTML documents and automatically translated
	 into a structured format, e.g., XML. A program that automatically
	 extracts data and transforms it into another format (markups the content
	 with semantic information) is called a wrapper. Intelligent content
	 extraction provides the foundation for automatic generation of semantic
	 markup. Various approaches to automatic content extraction have been
	 proposed, ranging from machine learning techniques to pattern recognition
	 techniques. However, these approaches in general fail to produce
	 useful results due to the complexity of Web pages. Other approaches
	 suggest the manual editing of script files that wrap the relevant
	 data from Web pages into more structured formats. Such processes are
	 time-consuming, hard to understand for non-technical wrapper designers, and
	 script files are not easy to maintain. We propose another approach - a
	 supervised and visual definition of content extraction. Based on
	 interactively identifying and extracting relevant parts of HTML documents and
	 translating content to XML format, we designed and implemented the
	 efficient wrapper generation tool Lixto Visual Wrapper [2] which is
	 well-suited for building HTML to XML wrappers. Such a wrappeapplied to
	 continually extract relevant information from this class of Web pages.},
	Author = {Baumgartner, Robert and Gottlob, Georg and Herzog, Marcus and Slany, Wolfgang},
	Booktitle = ISWC,
	Conference-Abbr = {ISWC},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {Lixto, extraction, legacy Web, XML, Wrapper, REWERSE},
	Owner = {Tim Furche},
	Pdf = {SemanticWeb/Extraction/Baumgartner.Gottlob.ea_AnnotatingLegacyWeb_ISWC_2004.pdf},
	Title = {{Annotating the Legacy Web with Lixto}},
	Url = {http://iswc2004.semanticweb.org/demos/21/paper.pdf},
	Urldate = {2005/01/28},
	Year = {2004}}

@inproceedings{Bayardo2004An-Evaluation-of-Binary-XML-Encoding-Optimizations-for-fast-Stream-based-XML-Processing,
	Abstract = {This paper provides an objective evaluation of the performance
	 impacts of binary XML encodings, using a fast stream-based XQuery
	 processor as our representative application. Instead of proposing
	 one binary format and comparing it against standard XML parsers, we
	 investigate the individual effects of several binary encoding techniques
	 that are shared by many proposals. Our goal is to provide a deeper
	 understanding of the performance impacts of binary XML encodings in order to
	 clarify the ongoing and often contentious debate over their merits,
	 particularly in the domain of high performance XML stream processing.},
	Author = {Bayardo, Roberto J. and Gruhl, Daniel and Josifovski, Vanja and Myllymaki, Jussi},
	Booktitle = WWW,
	Conference-Abbr = {WWW},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-11-09 21:26:49 +0100},
	Doi = {http://doi.acm.org/10.1145/988672.988719},
	Isbn = {1-58113-844-X},
	Keywords = {XML XQuery stream binary encoding},
	Location = {New York, NY, USA},
	Pages = {345--354},
	Pdf = {QueryEvaluation/XML/XQuery/Bayardo.Gruhl.ea_EvaluationofBinary_WWW_2004.pdf},
	Publisher = {ACM Press},
	Title = {{An Evaluation of Binary XML Encoding Optimizations for fast Stream based XML Processing}},
	Url = {http://www.www2004.org/proceedings/docs/1p345.pdf},
	Year = {2004}}

@inproceedings{Berger.Bry.ea_XcerptandvisXcerpt_ISWC_2004,
	Abstract = {Query and transformation languages
	 such as XPath, XQuery and XSLT have evolved to standard development
	 tools for Web applications. Arguably those languages are not fully
	 suited for Semantic Web applications. The query and transformation
	 languages Xcerpt and visXcerpt have been conceived with both standard Web
	 and Semantic Web applications in mind. They are twin languages both
	 based on the same paradigms and principles. Xcerpt realizes these
	 paradigms and principles textually, visXcerpt visually. A mixed standard
	 Web and Semantic Web application scenario implemented in Xcerpt and
	 visXcerpt is presented. Xcerpt and visXcerpt are ongoing research
	 projects; prototypic implementations of the languages are available.},
	Author = {Berger, Sacha and Bry, Fran{\c c}ois and Bolzer, Oliver and Furche, Tim and Schaffert, Sebastian and Wieser, Christoph},
	Booktitle = ISWC,
	Conference-Abbr = {ISWC},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {Semantic Web XML RDF Visualization Xcerpt Demo REWERSE visXcerpt},
	Pdf = {SemanticWeb/Xcerpt/Visualization/Berger.Bry.ea_XcerptandvisXcerpt_ISWC_2004.pdf},
	Title = {{Xcerpt and visXcerpt: Twin Query Languages for the Semantic Web}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2004-23},
	Urldate = {2004/11/11},
	Year = {2004}}

@inproceedings{Berger.Bry.ea_ReasoningonWeb_EWIMT_2004,
	Abstract = {Reasoning on the Web is
	 gaining in importance because of emerging Web applications such as
	 context-adaptive Web systems (e.g. eLearning, rec ommender, personalised
	 (multi-)media, and mobile information systems), Web service retrieval and
	 composition, and Semantic Web applications of all kinds. A central issue is
	 combining automated reasoning methods with Web languages, especially with
	 Web query, schema, and update languages. This article reports on
	 prototypes of various kinds combining different forms of reasoning with
	 Web languages. The languages presented here have been conceived for
	 both, convention al Web and Semantic Web data, assuming that future
	 Web applications will require to freely combine data of both kinds.},
	Author = {Berger, Sacha and Bry, Fran{\c c}ois and Lorenz, Bernhard and Ohlbach, Hans J{\"u}rgen and P?tr{\^a}njan, Paula-Lavinia and Schaffert, Sebastian and Schwertel, Uta and Spranger, Stephanie},
	Booktitle = {Proc. European Workshop on the Integration of Knowledge, Semantics and Digital Media Technology},
	Conference-Abbr = {EWIMT},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {REWERSE Reasoning Semantic Web Query Languages Reactivity Temporal Reasoning},
	Organization = {IEEE},
	Pages = {157--164},
	Pdf = {SemanticWeb/REWERSE/Berger.Bry.ea_ReasoningonWeb_EWIMT_2004.pdf},
	Title = {{Reasoning on the Web: Language Prototypes and Perspectives}},
	Url = {http://rewerse.net/publications.html#REWERSE-RP-2004-39},
	Year = {2004}}

@inproceedings{Berger.Bry.ea_XcerptetvisXcerpt_JFPLC_2004,
	Abstract = {Web Query languages like XPath, XQuery and XSLT are
	 widely accepted tools for the development of Web applications today.
	 This article presents and motivates two new and experimental query
	 languages for the Web: Xcerpt and visXcerpt (see http://xcerpt.org).
	 Both languages are based on the same principles. They are deductive
	 languages, which is one of their central aspects: they use a sort of
	 unification similar to the unification used in logic programming and
	 deduction systems, as well as an inference mechanism similar to that
	 of logic programming and to SQL views in databases. visXcerpt is a
	 visual query language which provides a visual realization of Xcerpt's
	 textual constructs. Xcerpt's and visXcerpt's main goal is to ease the
	 development of applications for the Semantic Web applications. This
	 article introduces the essential aspects of Xcerpt and visXcerpt.},
	Author = {Berger, Sacha and Bry, Fran{\c c}ois and Schaffert, Sebastian},
	Booktitle = {Proc. Journ{\'e}es Francophones de Programmation en Logique et Programmation par Contraintes},
	Conference-Abbr = {JFPLC},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {REWERSE Query Languages Xcerpt visXcerpt Visualization},
	Organization = {INRIA},
	Pdf = {SemanticWeb/REWERSE/Berger.Bry.ea_XcerptetvisXcerpt_JFPLC_2004.pdf},
	Title = {{Xcerpt et visXcerpt : Langages d{\'e}ductifs d?interrogation du Web}},
	Url = {http://rewerse.net/publications.html#REWERSE-RP-2004-13},
	Year = {2004}}

@inproceedings{Berger.Bry.ea_XcerptundvisXcerpt_GDB_2004,
	Abstract = {Anfragesprachen f{\"u}r
	 XML-Daten sind heutzutage wesentliche Werkzeuge in der Entwicklung von
	 Webanwendungen. Die am weitesten verbreiteten Sprachen sind XQuery
	 und XSLT, die beide auf der pfadbasierten Selektionssprache XPath
	 aufbauen. Dieser Vortrag gibt einen Einblick in eine neue Anfragesprache
	 namens Xcerpt, die statt des pfadbasierten Ansatzes Anfragepattern
	 verwendet, welche eine deklarativere Spezifikation von Anfragen erlauben.
	 Xcerpt ist ausserdem eine deduktive, regelbasierte Sprache, die auch
	 die Verkn{\"u}pfung von mehreren Regeln (Chaining) und Rekursion
	 erm{\"o}glicht. Eine Xcerpt-Regel kann damit auch als Abstraktion der
	 Ausgangsdaten verstanden werden, hnlich zu Views in relationalen
	 Datenbanken.Auf Xcerpt aufbauend wird ausserdem die visuelle Anfragesprache
	 visXcerpt vorgestellt. Aufgrund des patternbasierten Ansatzes von Xcerpt
	 k{\"o}nnen in visXcerpt Anfragen auf einfache Weise visuell dargestellt
	 und bearbeitet werden.Das Ziel beider Anfragesprachen ist es, die
	 Entwicklung von Anwendungen insbesondere f{\"u}r das "Semantic Web" zu
	 vereinfachen:Anfnger k{\"o}nnen mit Hilfe von visXcerpt Anfragen
	 schnell und intuitiv formulieren und Fortgeschrittenen hilft die
	 Deklarativitt von Xcerpt bei der Gliederung komplexer Programme.},
	Author = {Berger, Sacha and Bry, Fran{\c c}ois and Schaffert, Sebastian},
	Booktitle = {Proc. Workshop Grundlagen von Datenbanken},
	Conference-Abbr = {GDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {REWERSE visXcerpt Xcerpt Query Languages Semantic Web},
	Organization = {GI},
	Pdf = {SemanticWeb/REWERSE/Berger.Bry.ea_XcerptundvisXcerpt_GDB_2004.pdf},
	Title = {{Xcerpt und visXcerpt: deduktive Anfragesprachen f{\"u}r das Web}},
	Url = {http://rewerse.net/publications.html#REWERSE-RP-2004-66},
	Year = {2004}}

@inproceedings{Berger.Bry.ea_VisualLanguageWeb_PPSWR_2003,
	Abstract = {As XML is increasingly being used to represent information on the Web, query and
	 reasoning languages for such data are needed. This article argues that in
	 contrast to the navigational approach taken in particular by XPath
	 and XQuery, a positional approach as used in the language Xcerpt
	 is better suited for a straightforward visual representation. The
	 constructs of the pattern- and rule-based query language Xcerpt are
	 introduced and it is shown how the visual representation visXcerpt
	 renders these constructs to form a visual query language for XML.},
	Author = {Berger, Sacha and Bry, Fran{\c c}ois and Schaffert, Sebastian},
	Booktitle = PPSWR,
	Conference-Abbr = {PPSWR},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {Xcerpt visXcerpt Demo Visualization Query Languages},
	Pdf = {SemanticWeb/Xcerpt/Visualization/Berger.Bry.ea_VisualLanguageWeb_PPSWR_2003.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{A Visual Language for Web Querying and Reasoning}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2003-6},
	Volume = {2901},
	Year = {2003}}

@inproceedings{Berger.Bry.ea_XcerptandvisXcerpt_VLDB_2003,
	Author = {Berger, Sacha and Bry, Fran{\c c}ois and Schaffert, Sebastian and Wieser, Christoph},
	Booktitle = VLDB,
	Conference-Abbr = {VLDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {Xcerpt visXcerpt Query Languages Visualization},
	Title = {{Xcerpt and visXcerpt: From Pattern-Based to Visual Querying of XML and Semistructured Data}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2003-2},
	Year = {2003}}

@inproceedings{Berger.Bry.ea_VisualQueryingSemantic_ER_2004,
	Abstract = {This paper presents a demonstration of visXcerpt, a visual query
	 language for both, standard Web as well as Semantic Web applications.},
	Author = {Berger, Sacha and Bry, Fran{\c c}ois and Wieser, Christoph},
	Booktitle = {Proc. Intl. Conf. on Conceptual Modeling},
	Conference-Abbr = {ER},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {REWERSE visXcerpt Visualization Query Languages Xcerpt},
	Pdf = {SemanticWeb/REWERSE/Berger.Bry.ea_VisualQueryingSemantic_ER_2004.pdf},
	Title = {{Visual Querying for the Semantic Web}},
	Url = {http://rewerse.net/publications.html#REWERSE-RP-2004-43},
	Year = {2004}}

@article{Bex.Maneth.ea_FormalModelExpressive_IS_2002,
	Abstract = {The extension of the eXtensible
	 Style sheet Language (XSL) by variables and passing of data values
	 between template rules has generated a powerful XML query language:
	 eXtensible Style sheet Language Transformations (XSLT). An informal
	 introduction to XSTL is given, on the bases of which a formal model of a
	 fragment of XSLT is defined. This formal model is in the spirit of tree
	 transducers, and its semantics is defined by rewrite relations. It is shown
	 that the expressive power of the fragment is already beyond that
	 of most other XML query languages. Finally, important properties
	 such as termination and closure under composition are considered.},
	Author = {Bex, Geert Jan and Maneth, Sebastian and Neven, Frank},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1016/S0306-4379(01)00033-3},
	Issn = {0306-4379},
	Journal = {Information Systems},
	Journal-Abbr = {IS},
	Keywords = {XML XSLT formal expressiveness},
	Number = {1},
	Pages = {21--39},
	Pdf = {QueryEvaluation/XML/XSLT/Bex.Maneth.ea_FormalModelExpressive_IS_2002.pdf},
	Publisher = {Elsevier Science Ltd.},
	Title = {{A Formal Model for an Expressive Fragment of XSLT}},
	Url = {http://alpha.luc.ac.be/~lucg5503/xsltfull.ps},
	Volume = {27},
	Year = {2002}}

@techreport{Boag.Chamberlin.ea_XQuery1.0-XML_TR_2005,
	Abstract = {XML is a versatile markup language, capable of
	 labeling the information content of diverse data sources including
	 structured and semi-structured documents, relational databases, and
	 object repositories. A query language that uses the structure of XML
	 intelligently can express queries across all these kinds of data,
	 whether physically stored in XML or viewed as XML via middleware. This
	 specification describes a query language called XQuery, which is
	 designed to be broadly applicable across many types of XML data sources.},
	Author = {Boag, Scott and Chamberlin, Don and Fern{\'a}ndez, Mary F. and Florescu, Daniela and Robie, Jonathan and Sim{\'e}on, J{\'e}r{\^o}me},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {XML XQuery W3C Query Query Languages},
	Owner = {Tim Furche},
	Title = {{XQuery 1.0: An XML Query Language}},
	Type = {Working Draft},
	Url = {http://www.w3.org/TR/xquery/},
	Urldate = {2005/01/31},
	Year = {2005}}

@inproceedings{Boley_RuleMarkupLanguage_INAP_2001,
	Abstract = {Shared declarative aspects of Prolog and XML are
	 examined. An XML version of pure Prolog is shown to be at the center of
	 the Rule Markup Language. The RuleML data model uses Order-Labeled
	 trees, combining the RDF and XML models. As part of RuleMl's hierarchy
	 of sublanguages, the RuleML-Prolog DTD is employed for practical
	 XML-to-XML and XML-to-(X)HTML transformation of Prolog on the Web.},
	Author = {Boley, Harold},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {Intl. Conf. on Applications of Prolog},
	Conference-Abbr = {INAP},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Ee = {http://link.springer.de/link/service/series/0558/bibs/2543/25430005.htm},
	Keywords = {XML RDF RuleML data model integration role tags type tags},
	Pages = {5-22},
	Pdf = {SemanticWeb/RDF/RDF-XML-Integration/Boley_RuleMarkupLanguage_INAP_2001.pdf},
	Title = {{The Rule Markup Language: RDF-XML Data Model, XML Schema Hierarchy, and XSL Transformations}},
	Url = {http://iit-iti.nrc-cnrc.gc.ca/publications/nrc-47086_e.html},
	Year = {2001}}

@mastersthesis{Bolzer_TowardsData-Integrationon_2005,
	Author = {Bolzer, Oliver},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML Xcerpt RDF integration mediation views},
	Owner = {Tim Furche},
	School = {University of Munich},
	Title = {{Towards Data-Integration on the Semantic Web: Querying RDF with Xcerpt}},
	Type = {{Diplomarbeit/Master thesis}},
	Url = {http://www.pms.ifi.lmu.de/publikationen#DA_Oliver.Bolzer},
	Year = {2005}}

@talk{Bolzer_SemanticWebQuerying_SLIDES_2004,
	Abstract = {Xcerpt is a declarative, rule-based query and transformation
	 language for XML and other semistructured data on the Web. This talk
	 investigates the suitability of Xcerpt and it's underlying formalisms
	 for querying and reasoning with both RDF and traditional XML data.},
	Author = {Bolzer, Oliver},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {Institute for Computer Science, University of Munich, Germany},
	Keywords = {RDF Semantic Web Xcerpt Views},
	Owner = {Tim Furche},
	Pdf = {SemanticWeb/Xcerpt/Bolzer_SemanticWebQuerying_SLIDES_2004.pdf},
	Title = {{Semantic Web Querying Using Xcerpt}},
	Type = {Oberseminar ?Knowledge Representation and Markup Languages?},
	Year = {2004}}

@inproceedings{Bonifati.Braga.ea_ActiveXQuery_ICDE_2002,
	Abstract = {Besides being adopted as the new interchange format for the Internet, XML is
	 finding increasing acceptance as a native data repository language. In
	 order to make XML repositories fully equipped with data management
	 capabilities, suitable query and update languages are being developed.
	 However, once the user is allowed to perform updates, it is perceivably
	 necessary to guarantee the correctness of his/her updates, especially if
	 document validity or semantic constraints are violated. We address this
	 problem by exploiting the well-grounded concept of active rules.In
	 this paper, we propose Active XQuery, an active language for XML
	 repositories that is based on a previously defined XQuery update model. In
	 particular, we present the syntax and semantics of our language, aiming at
	 emulating the trigger definition and execution model of SQL3. An
	 active extension of XQuery arises nontrivial problems, related to the
	 need of interleaving updates and triggers. These problems have led
	 us to define an algorithm for update reformulation and to devise a
	 compact semantics. In conclusion, the paper presents an architecture
	 for rapid prototyping, and hints optimization and research issues.},
	Author = {Bonifati, Angela and Braga, Daniele and Campi, Alessandro and Ceri, Stefano},
	Booktitle = ICDE,
	Conference-Abbr = {ICDE},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XQuery update reactivity active},
	Pages = {403},
	Pdf = {QueryEvaluation/XML/XQuery/Bonifati.Braga.ea_ActiveXQuery_ICDE_2002.pdf},
	Publisher = {IEEE Computer Society},
	Title = {{Active XQuery}},
	Url = {http://www.icar.cnr.it/angela/pubs/ICDE02.pdf},
	Year = {2002}}

@inproceedings{Braga.Campi.ea_XQuerybyExample_WWW_2003,
	Abstract = {XQuery, the standard query language for XML, is gaining popularity
	 among users with a SQL background; indeed, formulating XQuery and
	 SQL queries requires comparable skills. However, this nucleus of
	 programmers is not vast, and the availability of simpler XQuery ``dialects"
	 could be valuable for establishing its success. With this motivation
	 in mind, we designed XQBE, a visual dialect of XQuery inspired by
	 QBE (Query by Example). QBE was initially proposed as alternative
	 to SQL and has gained popularity as the language supported by MS
	 Access, currently presented to users with a very limited experience of
	 query languages. Coherent with the XML data model, XQBE uses one
	 or more hierarchical structures to denote the input XML documents
	 and one structure to denote the output document. Similar to QBE,
	 structures are annotated to express selection predicates; explicit
	 bindings between these structures visualize the input/output mappings.},
	Author = {Braga, Daniele and Campi, Alessandro and Ceri, Stefano and Augurusa, Enrico},
	Booktitle = WWW,
	Conference-Abbr = {WWW},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML query languages visualization XML-GL XQuery XQBE},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Visualization/Braga.Campi.ea_XQuerybyExample_WWW_2003.pdf},
	Title = {{XQuery by Example}},
	Url = {http://www2003.org/cdrom/papers/poster/p291/p291-braga.html},
	Year = {2003}}

@inproceedings{Bremer.Gertz_XQuery-IR-IntegratingXML_WebDB_2002,
	Author = {Bremer, Jan-Marco and Gertz, Michael},
	Booktitle = {Proc. Intl. Workshop on the Web and Databases},
	Conference-Abbr = {WebDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XQuery IR information retrieval ranking query languages},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/InformationRetrieval/Languages/Bremer.Gertz_XQuery-IR-IntegratingXML_WebDB_2002.pdf},
	Title = {{XQuery/IR: Integrating XML Document and Data Retrieval}},
	Url = {http://www.db.ucsd.edu/webdb2002/papers/57.pdf},
	Year = {2002}}

@book{Brundage_XQuery-XMLQuery_2004,
	Author = {Brundage, Michael},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XQuery query languages},
	Owner = {Tim Furche},
	Publisher = {Addison-Wesley},
	Title = {{XQuery: The XML Query Language}},
	Year = {2004}}

@article{Brusilovsky_AdaptiveHypermedia_UMUAI_2001,
	Abstract = {Adaptive Systems use explicit user
	 models representing user knowledge, goals, interests, etc. that enable
	 them to tailor interaction to different users. Adaptive hypermedia
	 and AdaptiveWeb have used this paradigm to allow personalization in
	 hypertext systems and the WWW, with diverse applications ranging from
	 museum guides to web-based education. The goal of this chapter is
	 to present the history of adaptive hypermedia, introduce a number
	 of classic but popular techniques, and discuss emerging research
	 directions in the context of the Adaptive and Semantic Web, that
	 challenge the adaptive hypermedia researchers in the new Millennium.},
	Author = {Brusilovsky, Peter},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {User Modeling and User Adapted Interaction},
	Journal-Abbr = {UMUAI},
	Keywords = {personalization, adaptive hypermedia, adaptation},
	Number = {1/2},
	Owner = {Tim Furche},
	Pages = {87-110},
	Pdf = {ApplicationAreas/Personalization/Brusilovsky_AdaptiveHypermedia_UMUAI_2001.pdf},
	Title = {{Adaptive Hypermedia}},
	Url = {http://www2.sis.pitt.edu/~peterb/papers/brusilovsky-umuai-2001.pdf},
	Volume = {11},
	Year = {2001}}

@book{Brusilovsky_AdaptiveHyperTextand_1998,
	Author = {Brusilovsky, Peter and Kobsa, Alfred and Vassileva, Julita},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {personalization, adaptation, adaptive hypermedia},
	Owner = {Tim Furche},
	Publisher = {Kluwer Academic Publishers},
	Title = {{Adaptive HyperText and Hypermedia}},
	Url = {http://portal.acm.org/citation.cfm?id=551201&dl=ACM&coll=GUIDE},
	Year = {1998}}

@article{Brusilovsky.Maybury_FromAdaptiveHypermedia_CACM_2002,
	Author = {Brusilovsky, Peter and Maybury, Mark T.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {Communications of the ACM},
	Journal-Abbr = {CACM},
	Keywords = {personalization, adaptive hypermedia, adaptation},
	Number = {5},
	Owner = {Tim Furche},
	Pages = {30-33},
	Title = {{From Adaptive Hypermedia to the Adaptive Web}},
	Volume = {45},
	Year = {2002}}

@incollection{Brusilovsky.Nejdl_AdaptiveHypermediaand_2003,
	Abstract = {Adaptive Systems use explicit user
	 models representing user knowledge, goals, interests, etc. that enable
	 them to tailor interaction to different users. Adaptive hypermedia
	 and AdaptiveWeb have used this paradigm to allow personalization in
	 hypertext systems and the WWW, with diverse applications ranging from
	 museum guides to web-based education. The goal of this chapter is
	 to present the history of adaptive hypermedia, introduce a number
	 of classic but popular techniques, and discuss emerging research
	 directions in the context of the Adaptive and Semantic Web, that
	 challenge the adaptive hypermedia researchers in the new Millennium.},
	Author = {Brusilovsky, Peter and Nejdl, Wolfgang},
	Booktitle = {Practical Handbook of Internet Computing},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Editor = {Singh, Munindar P.},
	Keywords = {Personalization, Web, Adaptive Hypermedia, Adaptation},
	Owner = {Tim Furche},
	Pdf = {ApplicationAreas/Personalization/Brusilovsky.Nejdl_AdaptiveHypermediaand_2003.pdf},
	Publisher = {CRC Press},
	Title = {{Adaptive Hypermedia and Adaptive Web}},
	Url = {http://www.kbs.uni-hannover.de/Arbeiten/Publikationen/2003/brusilovsky-nejdl.pdf},
	Year = {2003}}

@inproceedings{Bry.Coskun.ea_XMLStreamQuery_ICDE_2005,
	Abstract = {Data streams (e.g., [Koudas and Srivastava, VLDB,
	 2003]) are an emerging technology for data dissemination in cases
	 where the data throughput or size make it unfeasible to rely on the
	 conventional approach based on storing the data before processing it. Areas
	 where data streams are applied include monitoring of scientific data
	 (astronomy, meteorology), control data (traffic, logistics, networks),
	 and financial data (bank transactions). Data streams are a new and
	 promising setting in which many conventional database methods have to
	 be considered anew. Querying XML data streams without storing and
	 without decreasing considerably the data throughput is especially
	 challenging because XML streams convey tree structured data with (possibly)
	 unbounded size and depth. SPEX, initially described in [Olteanu et
	 al., ICDE, 2002], evaluates XPath queries against XML data streams.
	 SPEX is built upon formal frameworks for (1) rewriting XPath queries
	 into equivalent XPath queries without reverse axes [Olteanu et al.,
	 EDBT-XMLDM, 2002] and (2) correct query evaluation with polynomial
	 combined complexity using networks of pushdown transducers [Olteanu
	 et al., SAC, 2004]. Such transducers are simple, independent, and
	 can be connected in a flexible manner, thus allowing not only easy
	 extensions but also extensive query optimization, e.g., by sharing
	 transducers. A reason for the latter is that processing new query constructs
	 implemented by new transducers does not affect the processing of
	 existing ones. As a proof of concept, SPEX is extended here with novel
	 compile-time optimizations that reduce both the size of the transducer
	 network and the processing of irrelevant stream fragments. SPEX is
	 demonstrated using a practically useful application for monitoring processes
	 running on UNIX systems, and a novel, sophisticated visualization
	 of its run-time system, called SPEX Viewer. SPEX Viewer makes it
	 possible to visualize (1) the step-by-step rewriting of XPath queries
	 into equivalent queries without reverse axes, (2) the networks of
	 pushdown transducers generated from such queries, (3) the incremental
	 processing of XML streams with these networks under various novel
	 optimization settings, and (4) the progressive generation of answers.},
	Author = {Bry, Fran{\c c}ois and Coskun, Fatih and Durmaz, Serap and Furche, Tim and Olteanu, Dan and Spannagel, Markus},
	Booktitle = ICDE,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Howpublished = {Demonstration},
	Keywords = {demo, streams, query evaluation, XPath, XML, SPEX, REWERSE},
	Pages = {1120-1121},
	Pdf = {QueryEvaluation/Streams/XPath/Bry.Coskun.ea_XMLStreamQuery_ICDE_2005.pdf},
	Title = {{The XML Stream Query Processor SPEX}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2005-1},
	Urldate = {2004/11/11},
	Year = {2005}}

@inproceedings{Bry.Drabent.ea_OnSubtypingof_PPSWR_2004,
	Abstract = {This paper discusses subtyping of
	 tree-structured data encountered on the Web, e.g. XML and HTML data. Our long
	 range objective is to de ne a type system for Web and/or Semantic Web
	 query languages amenable to static type checking. We propose a type
	 formalism motivated by XML Schema and accommodating two concepts of
	 subtyping: inclusion subtyping (corresponding to XML Schema notion of type
	 restriction) and extension subtyping (motivated by XML Schema's type
	 extension). We present algorithms for checking both kinds of subtyping. The
	 algorithms are polynomial if certain conditions are imposed on the type
	 de nitions; the conditions seem natural and not too restrictive.},
	Author = {Bry, Fran{\c c}ois and Drabent, W?odzimierz and Maluszynski, Jan},
	Booktitle = PPSWR # {, St. Malo, France},
	Conference-Abbr = {PPSWR},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {REWERSE Typing Query Languages},
	Organization = {REWERSE},
	Pdf = {SemanticWeb/REWERSE/Bry.Drabent.ea_OnSubtypingof_PPSWR_2004.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{On Subtyping of Tree-structured Data A Polynomial Approach}},
	Url = {http://rewerse.net/publications.html#REWERSE-RP-2004-11},
	Volume = {3208},
	Year = {2004}}

@article{Bry.Furche.ea_QueryingWebReconsidered_JSWIS_2005,
	Abstract = {A decade of experience with research proposals as well as standardized
	 query languages for the conventional Web and the recent emergence of
	 query languages for the Semantic Web call for a reconsideration of
	 design principles for Web and Semantic Web query languages. This
	 article first argues that a new generation of versatile Web query
	 languages is needed for solving the challenges posed by the changing
	 Web: We call versatile those query languages able to cope with both
	 Web and Semantic Web data expressed in any (Web or Semantic Web)
	 markup language. This article further suggests that (well-known)
	 referential transparency and (novel) answer-closedness are essential
	 features of versatile query languages. Indeed, they allow queries to be
	 considered like forms and answers like form-fillings in the spirit of the
	 ?query-by-example? paradigm. This article finally suggests that the
	 decentralized and heterogeneous nature of the Web requires incomplete
	 data specifications (or ?incomplete queries?) and incomplete data
	 selections (or ?incomplete answers?): the form-like query can be
	 specified without precise knowledge of the queried data and answers
	 can be restricted to contain only an excerpt of the queried data.},
	Author = {Bry, Fran{\c c}ois and Furche, Tim and Badea, Liviu and Koch, Christoph and Schaffert, Sebastian and Berger, Sacha},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {Journal of Semantic Web and Information Systems},
	Keywords = {Semantic Web, versatility, Xcerpt, vision, design principles},
	Number = {2},
	Pdf = {QueryEvaluation/SemanticWeb/Bry.Furche.ea_QueryingWebReconsidered_JSWIS_2004.pdf},
	Title = {{Querying the Web Reconsidered: Design Principles for Versatile Web Query Languages}},
	Volume = {1},
	Year = {2005}}

@article{Bry.Furche.ea_Datenstroeme_IS_2004,
	Abstract = {Unter einem ?Datenstrom? versteht man kontinuierlich {\"u}bersandte Datenstze, deren
	 Gr{\"o}{\ss}e, Menge sowie schnelles Aufkommen verbieten, sie vor der
	 Verarbeitung zu speichern. Die bisherige Forschung hat in erster Linie zum
	 Ziel, Verfahren zu entwickeln, die es erlauben, ohne Verz{\"o}gerung
	 des Datenflusses (1) einen Strom auf das Vorkommen von bestimmten
	 Daten zu uberwachen und (2) die Daten aus einem Strom zu analysieren.
	 Dieser Artikel dient als kurze Einf{\"u}hrung {\"u}ber Merkmale und
	 aktuelle Forschungsergebnisse der Datenstr{\"o}menanfrage und -analyse.},
	Author = {Bry, Fran{\c c}ois and Furche, Tim and Olteanu, Dan},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {Informatik Spektrum},
	Journal-Abbr = {IS},
	Keywords = {Query Evaluation Streams XML REWERSE},
	Number = {2},
	Pdf = {QueryEvaluation/Streams/Bry.Furche.ea_Datenstroeme_IS_2004.pdf},
	Title = {{Datenstr{\"o}me}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2004-2},
	Urldate = {2004/11/11},
	Volume = {27},
	Year = {2004}}

@inproceedings{Bry.Furche.ea_DataRetrievaland_PPSWR_2004,
	Abstract = {To make use of data represented on the Semantic Web, it is
	 necessary to provide languages for Web data retrieval and evolution. This
	 article introduces into the (conventional and Semantic) Web query
	 language Xcerpt and the event and update language XChange, and shows how
	 their deductive capabilities make them well suited for querying,
	 changing and reasoning with data on both the conventional and the
	 Semantic Web. To this aim, small application scenarios are introduced.},
	Author = {Bry, Fran{\c c}ois and Furche, Tim and P?tr{\^a}njan, Paula-Lavinia and Schaffert, Sebastian},
	Booktitle = PPSWR,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Pages = {34-49},
	Publisher = springer,
	Series = lncs,
	Title = {{Data Retrieval and Evolution on the (Semantic) Web: A Deductive Approach}},
	Volume = {3208},
	Year = {2004}}

@article{Bry.Nagel.ea_Grid-Computing_IS_2004,
	Abstract = {"Grid-Computing", ein Mitte der 90er Jahre eingef{\"u}hrter Begriff, bezeichnet eine
	 Architektur f{\"u}r verteilte Systeme, die auf dem World Wide Web
	 aufbaut und die Web-Vision erweitert. Mit dem Grid-Computing werden die
	 Ressourcen einer Gemeinschaft, einer sogenannten virtuellen Organisation
	 (siehe unten), integriert. Die Hoffnung ist, dass hierdurch rechen-
	 und/oder datenintensiven Aufgaben, die eine einzelne Organisation
	 nicht l{\"o}sen kann, handhabbar werden. Ein Grid bezeichnet eine
	 nach dem Grid-Computing-Ansatz aufgebaute Rechner-, Netzwerk- und
	 Software-Infrastruktur zur Teilung von Ressourcen mit dem Ziel, die Aufgaben einer
	 virtuellen Organisation zu erledigen. Zu Beginn war die M{\"o}glichkeit,
	 ungenutzte CPU-Ressourcen an anderen Stellen f{\"u}r die eigenen Aufgaben
	 einzusetzen, die wesentlich treibende Kraft f{\"u}r erste Experimente.
	 Internet-Computing-Projekte wie SETI@Home, distributed.net u.a., bei denen die
	 unbenutzten Rechenzyklen von weltweit verteilten privaten PCs verwendet
	 werden, illustrieren das Potential des Grid-Computing. Die heutigen
	 Grid-Konzepte und die ersten -Prototypen gehen weit {\"u}ber diese
	 Anfnge hinaus. Sie versprechen die transparente Bereitstellung von
	 Diensten unabhngig von der rumlichen Nhe. Es wird erwartet, dass das
	 Grid-Computing die Nutzung von Rechnern und Rechnernetzen so grundlegend
	 verndern wird, wie das Web den Datenaustausch bereits verndert hat.},
	Author = {Bry, Fran{\c c}ois and Nagel, Wolfgang E. and Schroeder, Michael},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {Institute of Informatics, University of Munich},
	Journal = {Informatik Spektrum},
	Journal-Abbr = {IS},
	Keywords = {REWERSE Grid},
	Number = {6},
	Pdf = {SemanticWeb/REWERSE/Bry.Nagel.ea_Grid-Computing_IS_2004.pdf},
	Title = {{Grid-Computing}},
	Type = {{Forschungsbericht/research report}},
	Url = {http://rewerse.net/publications.html#PMS-FB-2004-22},
	Volume = {27},
	Year = {2004}}

@inproceedings{Bry.Patranjan_ReactivityonWeb_SAC_2005,
	Abstract = {Reactivity on the Web is an
	 emerging issue. It is essential for upcoming Web systems such as online
	 marketplaces, adaptive, Semantic Web systems as well as Web services and
	 Grids. This article first introduces the paradigms upon which the
	 high-level language XChange for programming reactive behaviour and
	 distributed applications on the Web relies. Then, it briefly presents
	 the main syntactical constructs of XChange. Finally, it sketches
	 the implementation in XChange of a reactive Web-based application.},
	Author = {Bry, Fran{\c c}ois and P{\u a}tr{\^a}njan, Paula-Lavinia},
	Booktitle = SAC,
	Conference-Abbr = {SAC},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-11-09 21:31:03 +0100},
	Keywords = {REWERSE Reactivity XChange},
	Organization = {ACM},
	Title = {{Reactivity on the Web: Paradigms and Applications of the Language XChange}},
	Url = {http://rewerse.net/publications.html#REWERSE-RP-2004-41},
	Year = {2005}}

@inproceedings{Bry.Patranjan.ea_XcerptandXChange_ICLP_2004,
	Author = {Bry, Fran{\c c}ois and P{\u a}tr{\^a}njan, Paula-Lavinia and Schaffert, Sebastian},
	Booktitle = ICLP,
	Conference-Abbr = {ICLP},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {REWERSE Query Languages Reactivity Xcerpt XChange},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{Xcerpt and XChange: Logic Programming Languages for Querying and Evolution on the Web}},
	Url = {http://www.pms.ifi.lmu.de/publikationen#PMS-FB-2004-11},
	Year = {2004}}

@inproceedings{Bry.Schaffert_EntailmentRelationReasoning_RuleML_2003,
	Abstract = {Reasoning on the Web is receiving an increasing attention because
	 of emerging fields such as Web adaption and Semantic Web. Indeed,
	 the advanced functionalities striven for in these fields call for
	 reasoning capabilities. Reasoning on the Web, however, is usually done
	 using existing techniques rarely fitting the Web. As a consequence,
	 additional data processing like data conversion from Web formats (e.g. XML
	 or HTML) into some other formats (e.g. classical logic terms and
	 formulas) is often needed and aspects of the Web (e.g. its inherent
	 inconsistency) are neglected. This article first gives requirements
	 for an entailment tuned to reasoning on the Web. Then, it describes
	 how classical logic's entailment can be modified so as to enforce
	 these requirements. Finally, it discusses how the proposed entailment
	 can be used in applying logic programming to reasoning on the Web.},
	Author = {Bry, Fran{\c c}ois and Schaffert, Sebastian},
	Booktitle = {Proc. Workshop on Rules and Rule Markup Languages for the Semantic Web},
	Conference-Abbr = {RuleML},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {Xcerpt Semantics Entailment Reasoning},
	Pdf = {SemanticWeb/Xcerpt/Bry.Schaffert_EntailmentRelationReasoning_RuleML_2003.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{An Entailment Relation for Reasoning on the Web}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2003-5},
	Volume = {2876},
	Year = {2003}}

@inproceedings{Bry.Schaffert_GentleIntroductioninto_RuleML-WS_2002,
	Abstract = {This articles introduces into Xcerpt, a rule-based query and transformation language
	 for XML. First, the design principles of Xcerpt are given. Then,
	 the essential construct of Xcerpt are explained and illustrated on
	 examples: "query terms", i.e. patterns using which Xcerpt queries are
	 posed, "construct terms", i.e. pattern re-assembling the data selected
	 in a query term into a new data item, and "construct-query rule"
	 linking queries with construct terms. Then, Xcerpt and XQuery are
	 compared on examples and the advantages of Xcerpt are discussed.
	 Finally, an outlook into Xcerpt's declarative and procedural semantics
	 as well as into Xcerpt's features currently developed are given.},
	Author = {Bry, Fran{\c c}ois and Schaffert, Sebastian},
	Booktitle = {Proc. Intl. Workshop on Rule Markup Languages for Business Rules on the Semantic Web},
	Conference-Abbr = {RuleML-WS},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML Xcerpt introduction query languages},
	Pdf = {QueryEvaluation/Xcerpt/Bry.Schaffert_GentleIntroductioninto_RuleML-WS_2002.pdf},
	Title = {{A Gentle Introduction into Xcerpt, a Rule-based Query and Transformation Language for XML}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2002-11},
	Year = {2002}}

@inproceedings{Bry.Schaffert_TowardsDeclarativeQuery_ICLP_2002,
	Abstract = {The growing importance of XML as a
	 data interchange standard demands languages for data querying and
	 transformation. Since the mid 90es, several such languages have been
	 proposed that are inspired from functional languages (such as XSLT)
	 and/or database query languages (such as XQuery). This paper addresses
	 applying logic programming concepts and techniques to designing a
	 declarative, rule-based query and transformation language for XML
	 and semistructured data.The paper first introduces issues specific
	 to XML and semistructured data such as the necessity of flexible
	 "query terms" and of "construct terms". Then, it is argued that logic
	 programming concepts are particularly appropriate for a declarative
	 query and transformation language for XML and semistructured data.
	 Finally, a new form of unification, called "simulation unification", is
	 proposed for answering "query terms", and it is illustrated on examples.},
	Author = {Bry, Fran{\c c}ois and Schaffert, Sebastian},
	Booktitle = ICLP,
	Conference-Abbr = {ICLP},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {Xcerpt Query Languages XML},
	Pdf = {SemanticWeb/Xcerpt/Bry.Schaffert_TowardsDeclarativeQuery_ICLP_2002.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{Towards a Declarative Query and Transformation Language for XML and Semistructured Data: Simulation Unification}},
	Url = {http://www.pms.ifi.lmu.de/publikationen#PMS-FB-2002-19},
	Volume = {2401},
	Year = {2002}}

@inproceedings{Bry.Schaffert_XMLQueryLanguage_GI-WebDB_2002,
	Abstract = {Most query and transformation languages developed since the mid 90es for XML and
	 semistructured data -- e.g. XQuery, the precursors of XQuery, and XSLT --
	 build upon a path-oriented node selection: A node in a data item is
	 specified in terms of a root-to-node path in the manner of the file
	 selection languages of operating systems. Constructs inspired from the
	 regular expression constructs *, +, ?, and "wildcards" give rise to a
	 flexible node retrieval from incompletely specified data items.This
	 paper further introduces into Xcerpt, a query and transformation
	 language further developing an alternative approach to querying XML
	 and semistructured data first introduced with the language UnQL. A
	 metaphor for this approach views queries as patterns, answers as
	 data items matching the queries. Formally, an answer to a query is
	 defined as a simulation of an instance of the query in a data item.},
	Author = {Bry, Fran{\c c}ois and Schaffert, Sebastian},
	Booktitle = {Proc. Intl. Workshop on Web and Databases},
	Conference-Abbr = {GI-WebDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML Xcerpt principles query languages},
	Pdf = {QueryEvaluation/Xcerpt/Bry.Schaffert_XMLQueryLanguage_GI-WebDB_2002.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{The XML Query Language Xcerpt: Design Principles, Examples, and Semantics}},
	Url = {http://www.pms.ifi.lmu.de/publikationen#PMS-FB-2002-7},
	Volume = {2593},
	Year = {2002}}

@inproceedings{Bry.Schaffert.ea_XcerptandXChange_SWSDN_2004,
	Abstract = {In this article, two deductive languages are introduced: the language Xcerpt, for querying
	 data and reasoning with data on the (Semantic) Web, and the language
	 XChange, for evolution and reactivity on the (Semantic) Web. A small
	 application scenario is given as a motivation for these languages.},
	Author = {Bry, Fran{\c c}ois and Schaffert, Sebastian and P?tr{\^a}njan, Paula-Lavinia},
	Booktitle = {Proc. Workshop on Semantic Web Services and Dynamic Networks},
	Conference-Abbr = {SWSDN},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {REWERSE Xcerpt XChange Query Languages Reactivity},
	Organization = {GI},
	Pdf = {SemanticWeb/REWERSE/Bry.Schaffert.ea_XcerptandXChange_SWSDN_2004.pdf},
	Title = {{Xcerpt and XChange: Deductive Languages for Data Retrieval and Evolution on the Web}},
	Url = {http://rewerse.net/publications.html#REWERSE-RP-2004-21},
	Year = {2004}}

@inproceedings{Bry.Schaffert.ea_contributiontoSemantics_WLP_2004,
	Abstract = {Xcerpt is a declarative and pattern-based query and transformation
	 language for the Web with deductive capabilities. In contrast to
	 Web query languages like XQuery and XSLT, Xcerpt relies on concepts
	 and techniques from logic programming and automated theorem proving
	 such as declarative ?query patterns? and ?rule chaining?. Xcerpt can
	 also be used for querying Web metadata, like OWL or RDF data, and
	 reasoning on such metadata. In contrast to specific languages for OWL and
	 RDF, however, Xcerpt is a general purpose query, transformation, and
	 reasoning language, i.e. it can be used for reasoning not only with Web
	 metadata but also with plain Web data. Salient aspects of Xcerpt
	 are its nonstandard ?query patterns? for retrieving incompletely
	 specified data and its unusual ?grouping constructs? some and all that
	 significantly depart from the standard approaches in logic programming
	 or automated theorem proving. Xcerpt relies on a new, assymmetric
	 unification, called simulation unification for evaluating query patterns
	 that incompletely specify data. Furthermore, Xcerpt does not rely on
	 meta reasoning for expressing and processing ?grouping? constructs
	 corresponding to Prolog?s metalevel predicates setof and bagof. This article
	 gives a brief overview over challenges of applying logic programming
	 techniques to Web querying. In particular it suggests two different
	 approaches for treating the meta-level grouping constructs all and some in
	 a proof calculus formalising the operational semantics of Xcerpt.},
	Author = {Bry, Fran{\c c}ois and Schaffert, Sebastian and Schr{\"o}der, Andreas},
	Booktitle = {Proc. Workshop on (Constraint) Logic Programming},
	Conference-Abbr = {WLP},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {REWERSE Query Evaluation Xcerpt Semantics},
	Organization = {GLP, GI},
	Pdf = {SemanticWeb/REWERSE/Bry.Schaffert.ea_contributiontoSemantics_WLP_2004.pdf},
	Title = {{A contribution to the Semantics of Xcerpt, a Web Query and Transformation Language}},
	Url = {http://rewerse.net/publications.html#REWERSE-RP-2004-18},
	Year = {2004}}

@inproceedings{Bry.Spranger_TowardsMulti-CalendarTemporal_PPSWR_2004,
	Abstract = {Time is omnipresent on the (Semantic) Web. However, for- malism like XML, XML
	 Schema, RDF, OWL and (Semantic) Web query languages have, if any, only
	 very limited notions of temporal data types and temporal theories
	 built-in. Recently, the development of Web Ser- vices for temporal
	 operations has begun. In this article, we describe a connection,
	 possibly the rst one, between such Web Services and Web formalisms: A
	 proposal of a type system for temporal and calendric data, called
	 multi-calendar temporal type system seamlessly integrated into a
	 host (query) language. The type system's associated type checking
	 meth- ods are beyond the scope of this article. For proof-of-concept
	 purposes, the Web and Semantic Web query language Xcerpt has been chosen.},
	Author = {Bry, Fran{\c c}ois and Spranger, Stephanie},
	Booktitle = PPSWR,
	Conference-Abbr = {PPSWR},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {REWERSE Xcerpt CATTS Temporal Reasoning},
	Organization = {REWERSE},
	Pdf = {SemanticWeb/REWERSE/Bry.Spranger_TowardsMulti-CalendarTemporal_PPSWR_2004.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{Towards a Multi-Calendar Temporal Type System for (Semantic) Web Query Languages}},
	Url = {http://rewerse.net/publications.html#REWERSE-RP-2004-19},
	Volume = {3208},
	Year = {2004}}

@inproceedings{Buneman.Semistructured-data.1997,
	Author = {Buneman, Peter},
	Booktitle = {Proc. ACM Symposium on Principles of Database Systems},
	Conference-Abbr = {PODS},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/263661.263675},
	Isbn = {0-89791-910-6},
	Location = {Tucson, Arizona, United States},
	Pages = {117--121},
	Publisher = {ACM Press},
	Title = {{Semistructured Data}},
	Year = {1997}}

@inproceedings{Buneman.Davidson.ea_QueryLanguageand_SIGMOD_1996,
	Abstract = {A new kind of data model has recently emerged in which the
	 database is not constrained by a conventional schema. Systems like
	 ACeDB, which has become very popular with biologists, and the recent
	 Tsimmis proposal for data integration organize data in tree-like
	 structures whose components can be used equally well to represent
	 sets and tuples. Such structures allow great flexibility y in data
	 representation.What query language is appropriate for such structures? Here we
	 propose a simple language UnQL for querying data organized as a rooted,
	 edge-labeled graph. In this model, relational data may be represented
	 as fixed-depth trees, and on such trees UnQL is equivalent to the
	 relational algebra. The novelty of UnQL consists in its programming
	 constructs for arbitrarily deep data and for cyclic structures. While
	 strictly more powerful than query languages with path expressions
	 like XSQL, UnQL can still be efficiently evaluated. We describe new
	 optimization techniques for the deep or "vertical" dimension of UnQL
	 queries. Furthermore, we show that known optimization techniques for
	 operators on flat relations apply to the "horizontal" dimension of UnQL.},
	Author = {Buneman, Peter and Davidson, Susan and Hillebrand, Gerd and Suciu, Dan},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/233269.233368},
	Isbn = {0-89791-794-4},
	Keywords = {XML query languages UnQL},
	Location = {Montreal, Quebec, Canada},
	Pages = {505--516},
	Pdf = {QueryEvaluation/XML/Buneman.Davidson.ea_QueryLanguageand_SIGMOD_1996.pdf},
	Publisher = {ACM Press},
	Title = {{A Query Language and Optimization Techniques for Unstructured Data}},
	Url = {http://www.cs.washington.edu/homes/suciu/camera-ready-final.ps},
	Year = {1996}}

@inproceedings{Buneman.Davidson.ea_ProgrammingConstructsUnstructured_DBLP_1996,
	Author = {Buneman, Peter and Davidson, Susan B. and Suciu, Dan},
	Booktitle = {Proc. Intl. Workshop on Database Programming Languages},
	Conference-Abbr = {DBLP},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {3-540-76086-5},
	Keywords = {XML query languages UnQL structural recursion},
	Pages = {12},
	Pdf = {QueryEvaluation/XML/Buneman.Davidson.ea_ProgrammingConstructsUnstructured_DBLP_1996.pdf},
	Publisher = {Springer-Verlag},
	Title = {{Programming Constructs for Unstructured Data}},
	Url = {http://www.cs.washington.edu/homes/suciu/file32_paper.ps},
	Year = {1996}}

@techreport{BuxtonRys.XQuery-and-XPath-Ful.2003,
	Abstract = {The document specifies requirements
	 for Full-Text search for use in XQuery [XQuery] and XPath [XPath].},
	Author = {Buxton, Stephen and Rys, Michael},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {XML XQuery full-text information retrieval requirements},
	Title = {{XQuery and XPath Full-Text Requirements}},
	Type = {Working Draft},
	Url = {http://www.w3.org/TR/xquery-full-text-requirements/},
	Year = {2003}}

@inproceedings{Calvanese.Giacomo.ea_ContainmentofConjunctive_KR_2000,
	Abstract = {Reasoning on queries is
	 a basic problem both in knowledge representation and databases. A
	 fundamental form of reasoning on queries is checking containment, i.e.,
	 verifying whether one query yields necessarily a subset of the result of
	 another query. Query containment is crucial in several contexts,
	 such as query optimization, knowledge base verification, information
	 integration, database integrity checking, and cooperative answering.
	 In this paper we address the problem of query containment in the
	 context of semistructured knowledge bases, where the basic querying
	 mechanism, namely regular path queries, asks for all pairs of objects
	 that are connected by a path conforming to a regular expression.
	 We consider conjunctive regular path queries with inverse, which
	 extend regular path queries with the possibility of using both the
	 inverse of binary relations, and conjunctions of atoms, where each atom
	 specifies that one regular path query with inverse holds between
	 two variables. We present a novel technique to check containment of
	 queries in this class, based on the use of two-way finite automata. The
	 technique shows the power of two-way automata in dealing with the inverse
	 operator and with the variables in the queries. We also characterize the
	 computational complexity of both the proposed algorithm and the problem.},
	Author = {Calvanese, Diego and Giacomo, Giuseppe De and Lenzerini, Maurizio and Vardi, Moshe Y.},
	Booktitle = {Proc. Intl. Conf. on the Principles of Knowledge Representation and Reasoning},
	Conference-Abbr = {KR},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {query processing containment path expressions inverse conjunctive},
	Pages = {176--185},
	Pdf = {QueryEvaluation/Languages/Calvanese.Giacomo.ea_ContainmentofConjunctive_KR_2000.pdf},
	Title = {{Containment of Conjunctive Regular Path Queries with Inverse}},
	Url = {http://www.inf.unibz.it/%7ecalvanese/papers/calv-degi-lenz-vard-KR-2000.ps.gz},
	Year = {2000}}

@inproceedings{Calvanese.Giacomo.ea_QueryProcessingusing_PODS_2000,
	Abstract = {Query processing using views is the problem of
	 computing the answer to a query based on a set of materialized views,
	 rather than on the raw data in the database. The problem comes in
	 two different forms, called query rewriting and query answering,
	 respectively. In the first form, we are given a query and a set of view
	 definitions, and the goal is to reformulate the query into an expression
	 that refers only to the views. In the second form, besides the query
	 and the view definitions, we are also given the extensions of the
	 views and a tuple, and the goal is to check whether the knowledge on
	 the view extensions logically implies that the tuple satisfies the
	 query. In this paper we address the problem of query processing using
	 views in the context of semistructured data, in particular for the
	 case of regular path queries extended with the inverse operator.
	 Several authors point out that the inverse operator is one of the
	 fundamental extensions for making regular path queries useful in real
	 settings. We present a novel technique based on the use of two-way finite
	 automata. Our approach demonstrates the power of this kind of automata in
	 dealing with the inverse operator, allowing us to show that both query
	 rewriting and query answering with the inverse operator has the same
	 computational complexity as for the case of standard regular path queries.},
	Author = {Calvanese, Diego and Giacomo, Giuseppe De and Lenzerini, Maurizio and Vardi, Moshe Y.},
	Booktitle = PODS,
	Conference-Abbr = {PODS},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {conjunctive queries, query languages, regular path expressions, inverse, views, optimization},
	Pages = {58--66},
	Pdf = {QueryEvaluation/Languages/Calvanese.Giacomo.ea_QueryProcessingusing_PODS_2000.pdf},
	Title = {{Query Processing using Views for Regular Path Queries with Inverse}},
	Url = {http://www.inf.unibz.it/%7ecalvanese/papers/calv-degi-lenz-vard-PODS-2000.ps.gz},
	Year = {2000}}

@article{Cardelli.Ghelli_TQL-QueryLanguage_MSCS_2004,
	Abstract = {The ambient logic is a modal
	 logic that was proposed for the description of the structural and
	 computational properties of distributed and mobile computation. The
	 structural part of the ambient logic is, essentially, a logic of
	 labelled trees, hence it turns out to be a good foundation for query
	 languages for semistructured data, much in the same way as first-order
	 logic is a fitting foundation for relational query languages. We
	 define here a query language for semistructured data that is based
	 on the ambient logic, and we outline an execution model for this
	 language. The language turns out to be quite expressive. Its strong
	 foundations and the equivalences that hold in the ambient logic are helpful
	 in the definition of the language semantics and execution model.},
	Author = {Cardelli, Luca and Ghelli, Giorgio},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1017/S0960129504004141},
	Issn = {0960-1295},
	Journal = {Mathematical Structures in Computer Science},
	Journal-Abbr = {MSCS},
	Keywords = {XML query languages TQL ambient logic pattern path TQL},
	Number = {3},
	Pages = {285--327},
	Pdf = {QueryEvaluation/XML/LogicProgrammingApproaches/Cardelli.Ghelli_TQL-QueryLanguage_MSCS_2004.pdf},
	Publisher = {Cambridge University Press},
	Title = {{TQL: a Query Language for Semistructured Data based on the Ambient Logic}},
	Url = {http://research.microsoft.com/Users/luca/Papers/A%20Query%20Language%20Based%20on%20the%20Ambient%20Logic%20MSCS.A4.pdf},
	Volume = {14},
	Year = {2004}}

@inproceedings{Cardelli.Gordon_AnytimeAnywhere-Modal_POPL_2000,
	Abstract = {The Ambient Calculus is a process calculus where processes may
	 reside within a hierarchy of locations and modify it. The purpose of
	 the calculus is to study mobility, which is seen as the change of
	 spatial configurations over time. In order to describe properties
	 of mobile computations we devise a modal logic that can talk about
	 space as well as time, and that has the Ambient Calculus as a model.},
	Author = {Cardelli, Luca and Gordon, Andrew D.},
	Booktitle = {Proc. Symposium on Principles of Programming Languages},
	Conference-Abbr = {POPL},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/325694.325742},
	Isbn = {1-58113-125-9},
	Keywords = {XML query languages ambient logic pattern TQL},
	Location = {Boston, MA, USA},
	Pages = {365--377},
	Pdf = {QueryEvaluation/XML/Cardelli.Gordon_AnytimeAnywhere-Modal_POPL_2000.pdf},
	Publisher = {ACM Press},
	Title = {{Anytime, Anywhere: Modal Logics for Mobile Ambients}},
	Url = {http://research.microsoft.com/~adg/Talks/990506-logic.pdf},
	Year = {2000}}

@inproceedings{Ceri.Comai.ea_XML-GL-GraphicalLanguage_WWW_1999,
	Abstract = {The widespreading of XML as a standard for
	 semi-structured documents on the Web opens up challenging opportunities for
	 Web query languages. In this paper we introduce XML-GL, a graphical
	 query language for XML documents. The use of a visual formalism for
	 representing both the content of XML documents (and of their DTDs) and the
	 syntax and semantics of queries enables an intuitive expression of
	 queries, even when they are rather complex. XML-GL is inspired by
	 G-log, a general purpose, logic-based language for querying structured
	 and semi-structured data. The paper presents the basic capabilities
	 of XML-GL through a sequence of examples of increasing complexity.},
	Author = {Ceri, Stefano and Comai, Sara and Damiani, Ernesto and Fraternali, Piero and Paraboschi, Stefano and Tanca, Letizia},
	Booktitle = WWW,
	Conference-Abbr = {WWW},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML query languages XML-GL visual visualization},
	Owner = {Tim Furche},
	Title = {{XML-GL: a Graphical Language for Querying and Restructuring XML Documents}},
	Url = {http://www8.org/w8-papers/1c-xml/xml-gl/xml-gl.html},
	Year = {1999}}

@inproceedings{Ceri.Comai.ea_XML-GL-GraphicalLanguage_QL98_1998,
	Abstract = {We present XML-GL, a graphical query language for XML documents. XML-GL derives
	 from GLog a general purpose, logic- and graph-based language for
	 querying structured and semi-structured data. Here we list a number of
	 interesting requirements for a query language for XML documents, and
	 give a few examples of XML-GL features addressing such requirements.},
	Author = {Ceri, Stefano and Comai, Sara and Damiani, Ernesto and Fraternali, Piero and Paraboschi, Stefano and Tanca:, Letizia},
	Booktitle = PROC # {W3C QL'98 -- Query Languages},
	Conference-Abbr = {QL98},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML query languages visual},
	Owner = {Tim Furche},
	Title = {{XML-GL: A Graphical Language for Querying and Reshaping XML Documents}},
	Url = {http://www.w3.org/TandS/QL/QL98/pp/xml-gl.html},
	Year = {1998}}

@techreport{Chamberlin.Frankhauser.ea_XMLQueryUse_TR_2005,
	Author = {Chamberlin, Don and Frankhauser, Peter and Florescu, Daniela and Marchiori, Massimo and Robie, Jonathan},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {XML XQuery Use Cases W3C Query Query Languages},
	Owner = {Tim Furche},
	Title = {{XML Query Use Cases}},
	Type = {Working Draft},
	Url = {http://www.w3.org/TR/xquery-use-cases/},
	Urldate = {2005/01/31},
	Year = {2005}}

@techreport{Chamberlin.Robie_XQueryUpdateFacility_TR_2005,
	Abstract = {This document specifies goals and requirements for the XQuery Update Facility.},
	Author = {Chamberlin, Don and Robie, Jonathan},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {XML XQuery update reactivity requirements},
	Owner = {Tim Furche},
	Title = {{XQuery Update Facility Requirements}},
	Type = {Working Draft},
	Url = {http://www.w3.org/TR/xquery-update-requirements/},
	Year = {2005}}

@article{Chinenyanga.Kushmerick_ExpressiveandEfficient_JIST_2002,
	Abstract = {Several languages for querying and
	 transforming XML, including XML-QL, Quilt, and XQL, have been proposed.
	 However, these languages do not support ranked queries based on textual
	 similarity, in the spirit of traditional IR. Several extensions to
	 these XML query languages to support keyword search have been made,
	 but the resulting languages cannot express IR-style queries such as
	 "find books and CDs with similar titles." In some of these languages
	 keywords are used merely as boolean filters without support for true
	 ranked retrieval; others permit similarity calculations only between a
	 data value and a constant, and thus cannot express the above query.
	 WHIRL avoids both problems, but assumes relational data. We propose
	 ELIXIR, an expressive and efficient language for XML information
	 retrieval that extends XML-QL with a textual similarity operator
	 that can be used for similarity joins, so ELIXIR is sufficiently
	 expressive to handle the sample query above. ELIXIR thus qualifies as a
	 general-purpose XML IR query language. Our central contribution is an efficient
	 algorithm for answering ELIXIR queries that rewrites the original
	 ELIXIR query into a series of XML-QL queries to generate intermediate
	 relational data, and uses WHIRL to efficiently evaluate the similarity
	 operators on this intermediate data, yielding an XML document with
	 nodes ranked by similarity. Our experiments demonstrate that our
	 prototype scales well with the size of the query and the XML data.},
	Author = {Chinenyanga, Taurai Tapiwa and Kushmerick, Nicholas},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {Journal of the American Society for Information Science and Technology},
	Journal-Abbr = {JIST},
	Keywords = {XML IR information retrieval ranking query languages},
	Number = {6},
	Owner = {Tim Furche},
	Pages = {438--453},
	Title = {{An Expressive and Efficient Language for XML Information Retrieval}},
	Volume = {53},
	Year = {2002}}

@techreport{Clark_RDFDataAccess_TR_2004,
	Abstract = {This document specifies use cases, requirements, and objectives for
	 an RDF query language and data access protocol. It suggests how an
	 RDF query language and data access protocol could be used in the
	 construction of novel, useful Semantic Web applications in areas like web
	 publishing, personal information management, transportation, and tourism.},
	Author = {Clark, Kendall Grant},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {RDF Data Access Use Cases W3C Query Query Languages Requirements},
	Owner = {Tim Furche},
	Title = {{RDF Data Access Use Cases and Requirements}},
	Type = {Working Draft},
	Url = {http://www.w3.org/TR/rdf-dawg-uc/},
	Urldate = {2005/01/31},
	Year = {2004}}

@inproceedings{Coelho.Florido_Type-basedXMLProcessing_PADL_2003,
	Abstract = {In this paper we propose a type-based framework for using
	 logic programming for XML processing. We transform XML documents into
	 terms and DTDs into regular types. We implemented a standard type
	 inference algorithm for logic programs and use the types corresponding to
	 the DTDs as additional type declarations for logic programs for XML
	 processing. Due to the correctness of the type inference this makes it
	 possible to use logic programs as an implicitly typed processing
	 language for XML with static type (in this case DTDs) validation.
	 As far as we know this is the first work adding type validation at
	 compile time to the use of logic programming for XML processing.},
	Author = {Coelho, Jorge and Florido, M.},
	Booktitle = {Proc. Intl. Symp. on Practical Aspects of Declarative Languages (PADL), New Orleans, Louisiana, USA},
	Comment = {READ},
	Conference-Abbr = {PADL},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML Query Evaluation Logic Programming Typing},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/LogicProgrammingApproaches/Coelho.Florido_Type-basedXMLProcessing_PADL_2003.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{Type-based XML Processing in Logic Programming}},
	Url = {http://www.dei.isep.ipp.pt/~jcoelho/x-prolog/padl03.pdf},
	Urldate = {2004/11/17},
	Volume = {2562},
	Year = {2003}}

@inproceedings{Coelho.Florido_CLPFlex-ConstraintLogic_ODBASE_2004,
	Abstract = {In this paper we present
	 an implementation of a constraint solving module, CLP(Flex), for
	 dealing with unification in an equality theory for terms with flexible
	 arity function symbols. Then we present an application of CLP(Flex)
	 to XML-processing where XML documents are abstracted by terms with
	 flexible arity symbols. This gives a highly declarative model for XML
	 processing yielding a substantial degree of flexibility in programming.},
	Author = {Coelho, Jorge and Florido, M{\'a}rio},
	Booktitle = ODBASE,
	Conference-Abbr = {ODBASE},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML Query languages Prolog Logic Programming Constraint Programming},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/LogicProgrammingApproaches/Coelho.Florido_CLP(Flex)-ConstraintLogic_ODBASE_2004.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{CLP(Flex): Constraint Logic Programming Applied to XML Processing}},
	Url = {http://www.ncc.up.pt/~jcoelho/clpflex.pdf},
	Volume = {3291},
	Year = {2004}}

@article{Cohen.Kanza.ea_EquiX-asearchand_JASIST_2002,
	Abstract = {EquiX is a search language
	 for XML that combines the power of querying with the simplicity of
	 searching. Requirements for such languages are discussed, and it is
	 shown that EquiX meets the necessary criteria. Both a graph-based
	 abstract syntax and a formal concrete syntax are presented for EquiX
	 queries. In addition, the semantics is defined and an evaluation
	 algorithm is presented. The evaluation algorithm is polynomial under
	 combined complexity. EquiX combines pattern matching, quantification,
	 and logical expressions to query both the data and meta-data of XML
	 documents. The result of a query in EquiX is a set of XML documents. A DTD
	 describing the result documents is derived automatically from the query.},
	Author = {Cohen, Sara and Kanza, Yaron and Kogan, Yakov and Sagiv, Yehoshua and Nutt, Werner and Serebrenik, Alexander},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1002/asi.10058},
	Issn = {1532-2882},
	Journal = {Journal of the American Society for Information Science and Technology},
	Journal-Abbr = {JASIST},
	Keywords = {XML query languages searching search engine metadata visual query languages},
	Number = {6},
	Pages = {454--466},
	Pdf = {QueryEvaluation/XML/Cohen.Kanza.ea_EquiX-asearchand_JASIST_2002.pdf},
	Publisher = {John Wiley \& Sons, Inc.},
	Title = {{EquiX---a search and query language for XML}},
	Url = {http://arxiv.org/abs/cs.DB/0110044},
	Volume = {53},
	Year = {2002}}

@inproceedings{Cohen.Mamou.ea_XSEarch-SemanticSearch_VLDB_2003,
	Abstract = {XSEarch, a semantic search
	 engine for XML, is presented. XSEarch has a simple query language,
	 suitable for a naive user. It returns semantically related document
	 fragments that satisfy the user's query. Query answers are ranked
	 using extended information-retrieval techniques and are generated in
	 an order similar to the ranking. Advanced indexing techniques were
	 developed to facilitate efficient implementation of XSEarch. The
	 performance of the different techniques as well as the recall and the
	 precision were measured experimentally. These experiments indicate that
	 XSEarch is efficient, scalable and ranks quality results highly.},
	Author = {Cohen, Sara and Mamou, Jonathan and Kanza, Yaron and Sagiv, Yehoshua},
	Booktitle = VLDB,
	Conference-Abbr = {VLDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML IR information retrieval query languages},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/InformationRetrieval/Languages/Cohen.Mamou.ea_XSEarch-SemanticSearch_VLDB_2003.pdf},
	Title = {{XSEarch: A Semantic Search Engine for XML}},
	Url = {Cohen.Mamou.ea_XSEarch-SemanticSearch_VLDB_2003},
	Year = {2003}}

@article{Comai.Damiani.ea_ComputingGraphicalQueries_TOIS_2001,
	Abstract = {The rapid evolution of XML from a mere data
	 exchange format to a universal syntax for encoding domain-specific
	 information raises the need for new query languages specifically
	 conceived to address the characteristics of XML. Such languages should be
	 able not only to extract information from XML documents, but also to
	 apply powerful transformation and restructuring operators, based on a
	 well-defined semantics. Moreover, XML queries should be natural to write and
	 understand, as nontechnical persons also are expected to access the
	 large XML information bases supporting their businesses. This article
	 describes XML-GL, a graphical query language for XML data. XML-GL's
	 uniqueness is in the definition of a graph-based syntax to express
	 a wide variety of XML queries, ranging from simple selections to
	 expressive data transformations involving grouping, aggregation, and
	 arithmetic calculations. XML-GL has an operational semantics based on the
	 notion of graph matching, which serves as a guideline both for the
	 implementation of native processors, and for the adoption of XML-GL as
	 a front-end to any of the XML query languages that are presently
	 under discussion as the standard paradigm for querying XML data.},
	Author = {Comai, Sara and Damiani, Ernesto and Fraternali, Piero},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/502795.502797},
	Issn = {1046-8188},
	Journal = {ACM Transactions on Information Systems},
	Journal-Abbr = {TOIS},
	Keywords = {XML query languages visual query languages XML-GL visualization},
	Number = {4},
	Pages = {371--430},
	Pdf = {QueryEvaluation/XML/Comai.Damiani.ea_ComputingGraphicalQueries_TOIS_2001.pdf},
	Publisher = {ACM Press},
	Title = {{Computing Graphical Queries over XML Data}},
	Url = {http://www.elet.polimi.it/upload/comai/Paper/TODS-Xmlgl.pdf},
	Volume = {19},
	Year = {2001}}

@inproceedings{Comai.Marrara.ea_XMLDocumentSummarization_DEXA_2004,
	Abstract = {This work presents a methodology to support approximate queries
	 over massive and heterogeneous XML data sets, based on concise data
	 statistics such as histograms or other statistical techniques. The basic
	 idea for approximate answers is to store precomputed summaries of
	 the XML data, also called synopses, and to query them instead of
	 the original database, thus saving time and computational costs. In
	 particular, We concentrate on a set of XQuery transformation rules for the
	 construction of the synopses collection and for querying the synopsis.},
	Author = {Comai, Sara and Marrara, Stefania and Tanca, Letizia},
	Booktitle = {Proc. Intl. Workshop on Database and Expert Systems Applications},
	Conference-Abbr = {DEXA},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XQuery synopsis query languages},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XQuery/Comai.Marrara.ea_XMLDocumentSummarization_DEXA_2004.pdf},
	Title = {{XML Document Summarization: Using XQuery for Synopsis Creation}},
	Year = {2004}}

@inproceedings{Conforti.Ghelli.ea_QueryLanguageTQL_WebDB_2002,
	Abstract = {This work presents the query language TQL, a
	 query language for semistructured data, that can be used to query
	 XML files. TQL substitutes the standard path-based pattern-matching
	 mechanism with a logic-based mechanism, where the programmer specifies
	 the properties of the pieces of data she is trying to extract. As a
	 result, TQL queries are more ?declarative?, or less ?operational?, than
	 queries in comparable languages. This feature makes some queries easier
	 to express, and should allow the adoption of better optimization
	 techniques. Through a set of examples, we show that the range of
	 queries that can be declaratively expressed in TQL is quite wide. The
	 implementation of TQL binding mechanism requires the adoption of
	 non-standard techniques, and some of its aspects are still open.
	 In this paper we implicitly report about the current status of the
	 implementation by writing all queries using the version of TQL that has been
	 implemented, and that can be freely downloaded from //tql.di.unipi.it/tql.},
	Author = {Conforti, Giovanni and Ghelli, Giorgio and Albano, Antonio and Colazzo, Dario and Manghi, Paolo and Sartiani, Carlo},
	Booktitle = {Proc. Intl. Workshop on the Web and Databases},
	Conference-Abbr = {WebDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML query languages TQL ambient logic patterns paths},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/LogicProgrammingApproaches/Conforti.Ghelli.ea_QueryLanguageTQL_WebDB_2002.pdf},
	Title = {{The Query Language TQL}},
	Url = {http://www.db.ucsd.edu/webdb2002/papers/43.pdf},
	Year = {2002}}

@techreport{Cowan.Tobin_XMLInformationSet_TR_2004,
	Abstract = {This specification provides a set of definitions for use in other
	 specifications that need to refer to the information in an XML document.},
	Author = {Cowan, John and Tobin, Richard},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {XML Infoset W3C data model},
	Owner = {Tim Furche},
	Title = {{XML Information Set (2nd Ed.)}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/xml-infoset/},
	Urldate = {2005/01/31},
	Year = {2004}}

@inproceedings{DeHaan.Toman.ea_ComprehensiveXQueryto_SIGMOD_2003,
	Abstract = {The W3C XQuery language
	 recommendation, based on a hierarchical and ordered document model, supports a
	 wide variety of constructs and use cases. There is a diversity of
	 approaches and strategies for evaluating XQuery expressions, in many
	 cases only dealing with limited subsets of the language. In this
	 paper we describe an implementation approach that handles XQuery with
	 arbitrarily-nested FLWR expressions, element constructors and built-in
	 functions (including structural comparisons). Our proposal maps an XQuery
	 expression to a single equivalent SQL query using a novel dynamic interval
	 encoding of a collection of XML documents as relations, augmented with
	 information tied to the query evaluation environment. The dynamic
	 interval technique enables (suitably enhanced) relational engines to
	 produce predictably good query plans that do not preclude the use of
	 sort-merge join query operators. The benefits are realized despite the
	 challenges presented by intermediate results that create arbitrary
	 documents and the need to preserve document order as prescribed by
	 semantics of XQuery. Finally, our experimental results demonstrate
	 that (native or relational) XML systems can benefit from the above
	 technique to avoid a quadratic scale up penalty that effectively
	 prevents the evaluation of nested FLWR expressions for large documents.},
	Author = {DeHaan, David and Toman, David and Consens, Mariano P. and {\"O}zsu, M. Tamer},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/872757.872832},
	Isbn = {1-58113-634-X},
	Keywords = {XML XQuery relational implementation tree encoding dynamic interval encoding},
	Location = {San Diego, California},
	Pages = {623--634},
	Pdf = {QueryEvaluation/XML/XQuery/DeHaan.Toman.ea_ComprehensiveXQueryto_SIGMOD_2003.pdf},
	Publisher = {ACM Press},
	Title = {{A Comprehensive XQuery to SQL Translation using Dynamic Interval Encoding}},
	Url = {http://db.uwaterloo.ca/~david/cs848/toman-et-al-sigmod.pdf},
	Year = {2003}}

@techreport{DeRoseMaier.XML-Linking-Language.2001,
	Author = {DeRose, Steve and Maier, Eve and Orchard, David},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {XML XLink linking relations},
	Title = {{XML Linking Language (XLink) Version 1.0}},
	Type = {Recommendation},
	Url = {http://www.w3.org/TR/xlink/},
	Year = {2001}}

@inproceedings{Deutsch.Fernandez.ea_QueryLanguageXML_WWW_1999,
	Abstract = {An important application of XML is the interchange of electronic
	 data (EDI) between multiple data sources on the Web. As XML data
	 proliferates on the Web, applications will need to integrate and
	 aggregate data from multiple source and clean and transform data to
	 facilitate exchange. Data extraction, conversion, transformation, and
	 integration are all well-understood database problems, and their
	 solutions rely on a query language. We present a query language for XML,
	 called XML-QL, which we argue is suitable for performing the above
	 tasks. XML-QL is a declarative, ``relational complete'' query language
	 and is simple enough that it can be optimized. XML-QL can extract
	 data from existing XML documents and construct new XML documents.},
	Author = {Deutsch, Alin and Fernandez, Mary and Florescu, Daniela and Levy, Alon and Suciu, Dan},
	Booktitle = WWW,
	Conference-Abbr = {WWW},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML query languages XML-QL pattern},
	Owner = {Tim Furche},
	Title = {{A Query Language for XML}},
	Url = {http://www.research.att.com/~mff/xmlql/doc/files/final.html},
	Year = {1999}}

@inproceedings{Deutsch.Fernandez.ea_XML-QL-QueryLanguage_QL98_1998,
	Author = {Deutsch, Alin and Fernandez, Mary and Florescu, Daniela and Levy, Alon and Suciu, Dan},
	Booktitle = PROC # {W3C QL'98 -- Query Languages 1998},
	Conference-Abbr = {QL98},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Howpublished = {Note},
	Institution = {W3C},
	Keywords = {XML XML-QL query languages positional},
	Organization = {W3C},
	Title = {{XML-QL: A Query Language for XML}},
	Url = {http://www.w3.org/TR/1998/NOTE-xml-ql-19980819/},
	Year = {1998}}

@inproceedings{Deutsch.Papakonstantinou.ea_NEXTLogicalFramework_VLDB_2004,
	Abstract = {Classical logical optimization techniques rely on a logical
	 semantics of the query language. The adaptation of these techniques to
	 XQuery is precluded by its definition as a functional language with
	 operational semantics. We introduce Nested XML Tableaux which enable a
	 logical foundation for XQuery semantics and provide the logical plan
	 optimization framework of our XQuery processor. As a proof of concept, we
	 develop and evaluate a minimization algorithm for removing redundant
	 navigation within and across nested subqueries. The rich XQuery features
	 create key challenges that fundamentally extend the prior work on
	 the problems of minimizing conjunctive and tree pattern queries.},
	Author = {Deutsch, Alin and Papakonstantinou, Yannis and Xu, Yu},
	Booktitle = VLDB,
	Conference-Abbr = {VLDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XQuery optimization logical query optimization rewriting},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XQuery/Deutsch.Papakonstantinou.ea_NEXTLogicalFramework_VLDB_2004.pdf},
	Title = {{The NEXT Logical Framework for XQuery}},
	Url = {http://www.vldb.org/conf/2004/RS4P5.PDF},
	Year = {2004}}

@inproceedings{deVos.Rowbotham_KnowledgeRepresentationPower_PICA_2001,
	Abstract = {Modelling power systems is an area of ongoing interest in the transmission
	 management and control systems community. Continuing development is
	 driven by two forces. The traditional tasks of model maintenance
	 and management must be achieved with fewer resources. At the same
	 time, model exchange and coordination has become a priority. The
	 latter force arises from the disaggregation of utility functions and
	 the introduction of power markets. This paper begins by identifying
	 some of the power system modelling tasks that have become important,
	 but are ill served by current tools and techniques. Among these are
	 model versioning and version control, migration of models between
	 different schema, the transformation of models for different purposes
	 or applications, and the merging of models from different sources.
	 These tasks are typically handled by semi-manual methods or heavily
	 customized software. The paper then describes the application of
	 knowledge representation to power system modelling. In particular, the
	 power of this approach to provide generic solutions to the foregoing
	 problems is explored. Knowledge representation is contrasted with
	 more common data representations and put into context with current
	 industry initiatives, EPRI CIM, UMS DAF and XML/CIM. Finally, the
	 feasibility of using knowledge representation for power system models is
	 illustrated with a case study from a major Australian distribution utility.},
	Author = {de Vos, Arnold and Rowbotham, C. T.},
	Booktitle = {IEEE Conference for Power Industry Computer Applications (PICA)},
	Conference-Abbr = {PICA},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {application, use cases, RDF},
	Owner = {Tim Furche},
	Pdf = {SemanticWeb/RDF/Applications/deVos.Rowbotham_KnowledgeRepresentationPower_PICA_2001.pdf},
	Read = {No},
	Title = {{Knowledge Representation for Power System Modelling}},
	Url = {http://www.langdale.com.au/PICA/KRforPSM.pdf},
	Urldate = {2004/12/20},
	Year = {2001}}

@inproceedings{Dolog.Henze.ea_PersonalizationinDistributed_WWW_2004,
	Author = {Dolog, Peter and Henze, Nicola and Nejdl, Wolfgang and Sintek, Michael},
	Booktitle = WWW,
	Conference-Abbr = {WWW},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {Personalization, E-Learning, Web, RDF},
	Owner = {Tim Furche},
	Pdf = {ApplicationAreas/Personalization/Dolog.Henze.ea_PersonalizationinDistributed_WWW_2004.pdf},
	Title = {{Personalization in Distributed e-Learning Environments}},
	Url = {http://www.kbs.uni-hannover.de/Arbeiten/Publikationen/2004/dolog_henze_nejdl_sintek_www2004.pdf},
	Year = {2004}}

@inproceedings{Dolog.Henze.ea_PersonalReader:Personalizing_AH_2004,
	Abstract = {Traditional adaptive hypermedia systems have focused on
	 providing adaptation functionality on a closed corpus, while Web search
	 interfaces have delivered non-personalized information to users. In this
	 paper, we show how we integrate closed corpus adaptation and global
	 context provision in a Personal Reader environment. The local context
	 consists of individually optimized recommendations to learning materials
	 within the given corpus; the global context provides individually
	 optimized recommendations to resources found on the Web, e.g., FAQs,
	 student exercises, simulations, etc. The adaptive local context of a
	 learning resource is generated by applying methods from adaptive
	 educational hypermedia in a semantic web setting. The adaptive global
	 context is generated by constructing appropriate queries, enrich them
	 based on available user pro le information, and, if necessary, relax
	 them during the querying process according to available metadata.},
	Author = {Dolog, Peter and Henze, Nicola and Nejdl, Wolfgang and Sintek, Michael},
	Booktitle = {Proc. Intl. Conf. on Adaptive Hypermedia and Adaptive Web-Based Systems},
	Conference-Abbr = {AH},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {personalization, E-Learning, Personal Reader, Semantic Web, RDF},
	Owner = {Tim Furche},
	Pdf = {ApplicationAreas/Personalization/Dolog.Henze.ea_PersonalReader:Personalizing_AH_2004.pdf},
	Title = {{The Personal Reader: Personalizing and Enriching Learning Resources using Semantic Web Technologies}},
	Url = {http://www.kbs.uni-hannover.de/Arbeiten/Publikationen/2004/ah2004_d_h_n_s.pdf},
	Year = {2004}}

@inproceedings{DomsFurche.How-to-Query-the-Gen.2005,
	Author = {Doms, Andreas and Furche, Tim and Burger, Albert and Schroeder, Michael},
	Booktitle = {Symposium on Knowledge Representation in Bioinformatics (KRBIO)},
	Conference-Abbr = {KRBIO},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {Xcerpt XML Prolog Bioinformatics GeneOntology Use cases Prova},
	Title = {How to Query the GeneOntology},
	Url = {http://www.pms.ifi.lmu.de/publikationen#PMS-FB-2005-15},
	Year = {2005}}

@inproceedings{Dong.Bailey_OptimizationofXML_WISE_2004,
	Author = {Dong, Ce and Bailey, James},
	Booktitle = {Proc. Intl. Conf. on Web Information Systems Engineering},
	Conference-Abbr = {WISE},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XSLT optimization query languages},
	Owner = {Tim Furche},
	Title = {{Optimization of XML Transformations Using Template Specialization}},
	Year = {2004}}

@techreport{Draper.Frankhauser.ea_XQuery1.0and_TR_2005,
	Abstract = {This document defines formally the semantics of XQuery 1.0 [XQuery 1.0: A Query
	 Language for XML] and XPath 2.0 [XML Path Language (XPath) 2.0].},
	Author = {Draper, Denise and Frankhauser, Peter and Fern{\'a}ndez, Mary and Malhotra, Ashok and Rose, Kristoffer and Rys, Michael and Sim{\'e}on, J{\'e}r{\^o}me and Wadler, Philip},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {XML XQuery Use Cases W3C Query Query Languages},
	Owner = {Tim Furche},
	Title = {{XQuery 1.0 and XPath 2.0 Formal Semantics}},
	Type = {Working Draft},
	Url = {http://www.w3.org/TR/xquery-semantics/},
	Urldate = {2005/01/31},
	Year = {2005}}

@article{Eisenberg.Melton_earlyLookat_SIGMOD_2004,
	Abstract = {In Feb. 2004, the period for
	 submitting Last Call Working Draft comments for most parts of the XQuery
	 specification came to a close. While there is still a great deal of work
	 to be done to make XQuery a W3C Recommendation, the documents have
	 become more stable with each public release. In this column we'd
	 like to provide an initial look at the XQuery API for Java? (XQJ), a
	 project that is taking place within the Java Community Process (JCP).},
	Author = {Eisenberg, Andrew and Melton, Jim},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1024694.1024717},
	Issn = {0163-5808},
	Journal = {SIGMOD Record},
	Journal-Abbr = {SIGMOD},
	Keywords = {XML XQuery Java XQJ API query languages},
	Number = {2},
	Pages = {105--111},
	Pdf = {QueryEvaluation/XML/XQuery/Eisenberg.Melton_earlyLookat_SIGMOD_2004.pdf},
	Publisher = {ACM Press},
	Title = {{An early Look at XQuery API for Java\texttrademark (XQJ)}},
	Url = {http://portal.acm.org/citation.cfm?id=1024694.1024717},
	Volume = {33},
	Year = {2004}}

@article{Eisenberg.Melton_earlyLookat_SIGMOD_2002,
	Author = {Eisenberg, Andrew and Melton, Jim},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/637411.637433},
	Issn = {0163-5808},
	Journal = {SIGMOD Record},
	Journal-Abbr = {SIGMOD},
	Keywords = {XML XQuery query languages historical},
	Number = {4},
	Pages = {113--120},
	Pdf = {QueryEvaluation/XML/XQuery/Eisenberg.Melton_earlyLookat_SIGMOD_2002.pdf},
	Publisher = {ACM Press},
	Title = {{An early Look at XQuery}},
	Url = {http://portal.acm.org/citation.cfm?id=637433},
	Volume = {31},
	Year = {2002}}

@inproceedings{Eiter.Ianni.ea_NonmonotonicDescriptionLogic_LPAR_2005,
	Author = {Eiter, Thomas and Ianni, Giovambattista and Schindlauer, Roman and Tompits, Hans},
	Booktitle = LPAR,
	Conference-Abbr = {LPAR},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {description logics, evaluation, Semantic Web, REWERSE},
	Owner = {Tim Furche},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{Nonmonotonic Description Logic Programs: Implementation and Experiments}},
	Year = {2005}}

@inproceedings{Eiter.Lukasiewicz.ea_CombiningAnswerSet_KR_2004,
	Abstract = {Towards the integration of rules and
	 ontologies in the Semantic Web, we propose a combination of logic
	 programming under the answer set semantics with the description logics
	 SHIF(D) and SHOIN(D), which underly the Web ontology languages OWL
	 Lite and OWL DL, respectively. This combination allows for building
	 rules on top of ontologies but also, to a limited extent, building
	 ontologies on top of rules. We introduce description logic programs
	 (dl-programs), which consist of a description logic knowledge base L and a
	 finite set of description logic rules (dl-rules) P. Such rules are
	 similar to usual rules in logic programs with negation as failure, but
	 may also contain queries to L, possibly default negated, in their
	 bodies. We define Herbrand models for dl-programs, and show that
	 satisfiable positive dl-programs have a unique least Herbrand model.
	 More generally, consistent stratified dlprograms can be associated
	 with a unique minimal Herbrand model that is characterized through
	 iterative least Herbrand models. We then generalize the (unique) minimal
	 Herbrand model semantics for positive and strati- fied dl-programs to a
	 strong answer set semantics for all dl-programs, which is based on a
	 reduction to the least model semantics of positive dl-programs. We also
	 de- fine a weak answer set semantics based on a reduction to the
	 answer sets of ordinary logic programs. Strong answer sets are weak
	 answer sets, and both properly generalize answer sets of ordinary
	 normal logic programs. We then give fixpoint characterizations for the
	 (unique) minimal Herbrand model semantics of positive and stratified
	 dl-programs, and show how to compute these models by finite fixpoint
	 iterations. Furthermore, we give a precise picture of the complexity
	 of deciding strong and weak answer set existence for a dl-program.},
	Author = {Eiter, Thomas and Lukasiewicz, Thomas and Schindlauer, Roman and Tompits, Hans},
	Booktitle = {Proc. Principles of Knowledge Representation and Reasoning (KR)},
	Conference-Abbr = {KR},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {Semantic Web Description Logics Answer-set Programming Query Languages Reasoning REWERSE},
	Owner = {Tim Furche},
	Pages = {141--151},
	Pdf = {QueryEvaluation/SemanticWeb/Eiter.Lukasiewicz.ea_CombiningAnswerSet_KR_2004.pdf},
	Title = {{Combining Answer Set Programming with Description Logics for the Semantic Web}},
	Url = {http://www.kr.tuwien.ac.at/staff/tompits/papers/kr-04-coupling.pdf},
	Urldate = {2005/01/28},
	Year = {2004}}

@inproceedings{Eiter.Lukasiewicz.ea_Well-foundedSemanticsDescription_RuleML_2004,
	Abstract = {In previous work, towards the integration of rules and ontologies in the
	 SemanticWeb, we have proposed a combination of logic programming under
	 the answer set semantics with the description logics SHIF(D) and
	 SHOIN(D), which underly the Web ontology languages OWL Lite and OWL
	 DL, respectively. More precisely, we have introduced description
	 logic programs (or dl-programs), which consist of a description logic
	 knowledge base L and a nite set of description logic rules P, and we have
	 de ned their answer set semantics. In this paper, we continue this
	 line of research. Here, as a central contribution, we present the
	 well-founded semantics for dl-programs, and we analyze its semantic
	 properties. In particular, we show that it generalizes the well-founded
	 semantics for ordinary normal programs. Furthermore, we show that in
	 the general case, the well-founded semantics of dl-programs is a
	 partial model that approximates the answer set semantics, whereas
	 in the positive and the stratified case, it is a total model that
	 coincides with the answer set semantics. Finally, we also provide
	 complexity results for dl-programs under the well-founded semantics.},
	Author = {Eiter, Thomas and Lukasiewicz, Thomas and Schindlauer, Roman and Tompits, Hans},
	Booktitle = {Proc. RuleML Workshop, ISWC},
	Conference-Abbr = {RuleML},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {Semantic Web Description Logics Semantics Querying REWERSE},
	Owner = {Tim Furche},
	Pages = {81--97},
	Pdf = {QueryEvaluation/SemanticWeb/Eiter.Lukasiewicz.ea_Well-foundedSemanticsDescription_RuleML_2004.pdf},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{Well-founded Semantics for Description Logic Programs in the Semantic Web}},
	Url = {http://www.kr.tuwien.ac.at/staff/lukasiew/ruleml04.pdf},
	Urldate = {2005/01/28},
	Volume = {3323},
	Year = {2004}}

@article{Fankhauser_XQueryFormalSemantics_SIGMOD_2001,
	Abstract = {The XQuery formalization is an ongoing effort of the
	 W3C XML Query working group to define a precise formal semantics
	 for XQuery. This paper briefly introduces the current state of the
	 formalization and discusses some of the more demanding remaining
	 challenges in formally describing an expressive query language for XML.},
	Author = {Fankhauser, Peter},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/603867.603870},
	Issn = {0163-5808},
	Journal = {SIGMOD Record},
	Journal-Abbr = {SIGMOD},
	Keywords = {XML XQuery formal semantics historical query languages},
	Number = {3},
	Pages = {14--19},
	Pdf = {QueryEvaluation/XML/XQuery/Fankhauser_XQueryFormalSemantics_SIGMOD_2001.pdf},
	Publisher = {ACM Press},
	Title = {{XQuery Formal Semantics: State and Challenges}},
	Url = {http://portal.acm.org/citation.cfm?id=603870},
	Volume = {30},
	Year = {2001}}

@inproceedings{Fankhauser_XQuerybybook_XML_2002,
	Abstract = {XQuery is being developed by the W3C XML Query working group
	 as a standard query language for XML. It is a fully compositional,
	 strongly typed functional language to flexibly select, recombine,
	 and restructure XML documents and fragments. This paper introduces
	 IPSI-XQ, a comprehensive implementation of XQuery "by the book", which
	 closely follows XQuery's formal semantics, realizing all steps of
	 the abstract XQuery processing model in an open and modular way to
	 arrive at a fully conformant, type safe implementation. It describes
	 how the formal specification can be deployed for type analysis and
	 query optimization, and discusses the pros and cons of the approach.},
	Author = {Fankhauser, Peter and Lehti, Patrick},
	Booktitle = {XML Conference \& Exhibition},
	Conference-Abbr = {XML},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XQuery implementation experience query languages},
	Owner = {Tim Furche},
	Title = {{XQuery by the book: The IPSI XQuery Demonstrator}},
	Url = {http://www.ipsi.fraunhofer.de/oasys/projects/ipsi-xq/XQuery%20by%20the%20book.rtf},
	Year = {2002}}

@techreport{Fernandez.Malhotra.ea_XQuery1.0and_TR_2005,
	Abstract = {This document defines the W3C XQuery 1.0 and XPath
	 2.0 Data Model, which is the data model of [XPath 2.0], [XSLT 2.0],
	 and [XQuery], and any other specifications that reference it. This
	 data model is based on the [XPath 1.0] data model and earlier work
	 on an [XML Query Data Model]. This document is the result of joint
	 work by the [XSL Working Group] and the [XML Query Working Group].},
	Author = {Fern{\'a}ndez, Mary and Malhotra, Ashok and Marsh, Jonathan and Nagy, Marton and Walsh, Norman},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {XML XQuery XPath data model query languages},
	Owner = {Tim Furche},
	Title = {{XQuery 1.0 and XPath 2.0 Data Model}},
	Type = {Working Draft},
	Url = {http://www.w3.org/TR/xpath-datamodel/},
	Urldate = {2005/01/31},
	Year = {2005}}

@inproceedings{Fernandez2003Implementing-XQuery-1.0-:-The-Galax-Experience,
	Abstract = {Galax is a light-weight, portable, open-source
	 implementation of XQuery 1.0. Started in December 2000 as a small prototype
	 designed to test the XQuery static type system, Galax has now become a
	 solid implementation, aiming at full conformance with the family of
	 XQuery 1.0 specifi- cations. Because of its completeness and open
	 architecture, Galax also turns out to be a very convenient platform for
	 researchers interested in experimenting with XQuery optimization. We
	 demonstrate the Galax system as well as its most advanced features,
	 including support for XPath 2.0, XML Schema and static typechecking.
	 We also present some of our first experiments with optimization.
	 Notably, we demonstrate query rewriting capabilities in the Galax
	 compiler, and the ability to run queries on documents up to a Gigabyte
	 without the need for preindexing. Although early versions of Galax
	 have been shown in industrial conferences over the last two years,
	 this is the first time it is demonstrated in the database community.},
	Author = {Fern{\'a}ndez, Mary and Sim{\'e}on, J{\'e}r{\^o}me and Choi, Byron and Marian, Am{\'e}lie and Sur, Gargi},
	Booktitle = VLDB,
	Conference-Abbr = {VLDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-11-09 21:28:32 +0100},
	Keywords = {XML XQuery galax implementation query languages},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XQuery/Fernandez.Simeon.ea_ImplementingXQuery1.0_VLDB_2003.pdf},
	Title = {{Implementing XQuery 1.0 : The Galax Experience}},
	Url = {http://www.vldb.org/conf/2003/papers/S35P07.pdf},
	Year = {2003}}

@inproceedings{Florescu.Fernandez.ea_QueryLanguageand_WMSD_1997,
	Author = {Florescu, Daniela and Fernandez, Mary and Levy, Alon and Suciu, Dan},
	Booktitle = {Proc. Workshop on Management of Semi-structured Data},
	Conference-Abbr = {WMSD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML query languages StruQL navigational path expression},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/Languages/Florescu.Fernandez.ea_QueryLanguageand_WMSD_1997.pdf},
	Title = {{A Query Language and Processor for a Web-site Management System}},
	Url = {http://www.research.att.com/~mff/strudel/doc/files/workshop97.ps.gz},
	Year = {1997}}

@article{Florescu.Levy.ea_QueryLanguageWeb-site_SIGMOD_1997,
	Author = {Florescu, Daniela and Levy, Alon and Fernandez, Mary and Suciu, Dan},
	Booktitle = {SIGMOD},
	Conference-Abbr = {WMSD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {SIGMOD Record},
	Journal-Abbr = {SIGMOD},
	Keywords = {XML query languages StruQL navigational path expression},
	Number = {3},
	Owner = {Tim Furche},
	Pages = {4--11},
	Pdf = {QueryEvaluation/Languages/Florescu.Fernandez.ea_QueryLanguageand_WMSD_1997.pdf},
	Title = {{A Query Language for a Web-site Management System}},
	Url = {http://www.research.att.com/~mff/strudel/doc/files/sigmodrec97.ps.gz},
	Volume = {26},
	Year = {1997}}

@mastersthesis{Furche_OptimizingMultipleQueries_2003,
	Abstract = {Processing and querying streams,
	 XML streams in particular, has recently become a widely recognized
	 area of interest both in research and in industry. In contrast to
	 traditional query evaluation for databases, where multiple queries
	 against the same data can be evaluated sequentially, for a streamed
	 environment only the simultaneous execution of multiple queries is
	 feasible, as the sequential evaluation requires multiple passes over the
	 stream. This work presents an overview of techniques for optimizing
	 multiple queries posed against a stream of XML data. Building upon the
	 SPEX query engine [Kiesling, Master Thesis, 2002; Olteanu et al.,
	 ICDE, 2003], the problem how to find a cost-optimal query plan that
	 allows the simultaneous evaluation of multiple queries against the
	 same stream is presented and shown to be not only hard to solve but
	 also hard to approximate, if arbitrary parts, and not only common
	 prefixes as in previous approaches, can be shared among query plans.
	 Several heuristics are investigated and compared, in particular with
	 respect to their complexity. Furthermore, it is shown how to extend the
	 SPEX query engine to support such query plans for multiple queries.
	 This extension proves to be both natural and efficient. An extensive
	 experimental evaluation shows that sharing arbitrary operators under a
	 realistic cost function results in query plans that have consistently
	 lower cost for reasonable sets of queries than query plans where
	 only common prefixes are considered. In most cases, the relative
	 improvement is higher than 50%. Although the time for generating such
	 query plans is higher than for query plans where only common prefixes
	 are shared, the increase in time is within an acceptable margin.},
	Address = {6},
	Author = {Furche, Tim},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {Query Evaluation Streams XPath XML},
	Pdf = {QueryEvaluation/Streams/XPath/Furche_OptimizingMultipleQueries_2003.pdf},
	School = {Institute of Computer Science, University of Munich, Germany},
	Title = {{Optimizing Multiple Queries against XML Streams}},
	Type = {Diplomarbeit},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#DA_Tim.Furche},
	Urldate = {2004/11/11},
	Year = {2003}}

@inproceedings{Groppe.Boettcher_XPathQueryTransformation_WIDM_2003,
	Abstract = {Whenever XML data must be shared by heterogeneous applications, transformations
	 between different application-specific XML formats are necessary. The
	 state-of-the-art method transforms entire XML documents from one
	 application format into another e.g. by using an XSLT stylesheet, so that
	 each application can work locally on its preferred format. In our
	 approach, we use an XSLT stylesheet in order to transform a given
	 XPath query such that we retrieve and transform only that part of the
	 XML document which is sufficient to answer the given query. Among
	 other things, our approach avoids problems of replication, saves
	 processing time and in distributed scenarios, transportation costs.},
	Author = {Groppe, Sven and B{\"o}ttcher, Stefan},
	Booktitle = {Proc. Intl. Workshop on Web Information and Data Management},
	Conference-Abbr = {WIDM},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/956699.956723},
	Isbn = {1-58113-725-7},
	Keywords = {XML XSLT query optimization rewriting},
	Location = {New Orleans, Louisiana, USA},
	Pages = {106--110},
	Pdf = {QueryEvaluation/XML/XSLT/Groppe.Boettcher_XPathQueryTransformation_WIDM_2003.pdf},
	Publisher = {ACM Press},
	Title = {{XPath Query Transformation based on XSLT Stylesheets}},
	Url = {http://portal.acm.org/citation.cfm?id=956723},
	Year = {2003}}

@inproceedings{Guizzardi.Wagner.ea_OntologicallyWell-FoundedProfile_CAiSE_2004,
	Abstract = {UML class diagrams can be
	 used as a language for expressing a conceptual model of a domain.
	 In a series of papers we have been using the General Ontological
	 Language (GOL) and its underlying upper level ontology to evaluate the
	 ontological correctness of a conceptual UML class model and to develop
	 guidelines for how the constructs of the UML should be used in conceptual
	 modeling. In this paper, we focus on the UML metaconcepts of classes and
	 objects from an ontological point of view. We use a philosophically and
	 psychologically well-founded theory of classifiers to propose a UML profile
	 for Ontology Representation and Conceptual Modeling. Moreover, we
	 propose a design pattern based on this profile to target a recurrent
	 problem in role modeling discussed in the literature. Finally, we
	 demonstrate the relevance of the tools proposed by applying them to
	 solve recurrent problems in the practice of conceptual modeling.},
	Author = {Guizzardi, Giancarlo and Wagner, Gerd and Guarino, Nicola and van Sinderen, Marten},
	Booktitle = {Proc. Intl. Conf. on Advanced Information Systems Engineering (CAiSE)},
	Citeseercitationcount = {0},
	Conference-Abbr = {CAiSE},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {UML Ontology Conceptual Modelling GOL},
	Owner = {Tim Furche},
	Pages = {112--126},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Title = {{An Ontologically Well-Founded Profile for UML Conceptual Models}},
	Url = {http://is.tm.tue.nl/staff/gwagner/CAiSE2004.pdf},
	Urldate = {2005/01/02},
	Volume = {3084},
	Year = {2004}}

@inproceedings{Guo.Shao.ea_XRANKRankedKeyword_SIGMOD_2003,
	Abstract = {We consider the problem of efficiently producing ranked results for
	 keyword search queries over hyperlinked XML documents. Evaluating
	 keyword search queries over hierarchical XML documents, as opposed to
	 (conceptually) flat HTML documents, introduces many new challenges. First,
	 XML keyword search queries do not always return entire documents,
	 but can return deeply nested XML elements that contain the desired
	 keywords. Second, the nested structure of XML implies that the notion of
	 ranking is no longer at the granularity of a document, but at the
	 granularity of an XML element. Finally, the notion of keyword proximity
	 is more complex in the hierarchical XML data model. In this paper,
	 we present the XRANK system that is designed to handle these novel
	 features of XML keyword search. Our experimental results show that XRANK
	 offers both space and performance benefits when compared with existing
	 approaches. An interesting feature of XRANK is that it naturally
	 generalizes a hyperlink based HTML search engine such as Google.
	 XRANK can thus be used to query a mix of HTML and XML documents.},
	Author = {Guo, Lin and Shao, Feng and Botev, Chavdar and Shanmugasundaram, Jayavel},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML query languages IR information retrieval ranking},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/InformationRetrieval/Languages/Guo.Shao.ea_XRANKRankedKeyword_SIGMOD_2003.pdf},
	Title = {{XRANK: Ranked Keyword Search over XML Documents}},
	Url = {http://www.cs.cornell.edu/People/jai/papers/XRank.pdf},
	Year = {2003}}

@article{Henze.Dolog.ea_ReasoningandOntologies_ETS_2004,
	Abstract = {The challenge of the semantic web is the provision of distributed information with well
	 defined meaning, understandable for different parties. Particularly,
	 applications should be able to provide individually optimized access
	 to information by taking the individual needs and requirements of
	 the users into account. In this paper we propose a framework for
	 personalized e-Learning in the semantic web and show how the semantic web
	 resource description formats can be utilized for automatic generation of
	 hypertext structures from distributed metadata. Ontologies and metadata
	 for three types of resources (domain, user, and observation) are
	 investigated. We investigate a logic-based approach to educational
	 hypermedia using TRIPLE, a rule and query language for the semantic web.},
	Author = {Henze, Nicola and Dolog, Peter and Nejdl, Wolfgang},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {Educational Technology Society},
	Journal-Abbr = {ETS},
	Keywords = {Personalization, Personal Reader, E-Learning, Semantic Web},
	Owner = {Tim Furche},
	Pdf = {ApplicationAreas/Personalization/Henze.Dolog.ea_ReasoningandOntologies_ETS_2004.pdf},
	Title = {{Reasoning and Ontologies for Personalized E-Learning}},
	Url = {http://www.kbs.uni-hannover.de/Arbeiten/Publikationen/2004/ifets_final.pdf},
	Year = {2004}}

@inproceedings{Henze.Herrlich_PersonalReader-Framework_ABIS_2004,
	Abstract = {The Personal Reader provides a framework for
	 designing, implementing and maintaining web content readers, which
	 provide personalized enrichment of web content for each individual
	 user. The idea of the the Personal Reader is based on a rigorous
	 approach for applying Semantic Web technologies: A modular framework
	 of components / services - for visualizing the Personal Reader and
	 providing the user interface, for mediating between user requests and
	 available personalization services, and for providing personalized
	 recommendations and access to web content forms the basis for the Personal
	 Reader. In this paper, we describe the architectural outline of the
	 framework as well as some implementation details, and discuss the
	 approach with a reference - a ?Personal Reader for Learning Resources?.},
	Author = {Henze, Nicola and Herrlich, Marc},
	Booktitle = {Proc. Workshop on Adaptation and User Modeling in Interactive Systems},
	Conference-Abbr = {ABIS},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {Personalization, Semantic Web, Personal Reader, RDF},
	Owner = {Tim Furche},
	Pdf = {ApplicationAreas/Personalization/Henze.Herrlich_PersonalReader-Framework_ABIS_2004.pdf},
	Title = {{The Personal Reader: A Framework for Enabling Personalization Services on the Semantic Web}},
	Url = {http://www.kbs.uni-hannover.de/Arbeiten/Publikationen/2004/Personal_Reader_abis04.pdf},
	Year = {2004}}

@article{Henze.Nejdl_LogicalCharacterizationof_NRHM_2004,
	Abstract = {Currently, adaptive educational hypermedia systems (AEHS) are described with
	 nonuniform methods, depending on the specific view on the system, the
	 application, or other parameters. There is no common language for expressing
	 functionality of AEHS, hence these systems are difficult to compare and
	 analyze. In this paper we investigate how a logical description can be
	 employed to characterize adaptive educational hypermedia. We propose a
	 definition of AEHS based on first-order logic, characterize some AEHS due
	 to this formalism, and discuss the applicability of this approach.},
	Author = {Henze, Nicola and Nejdl, Wolfgang},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {New Revies on Hypertext and Hypermedia},
	Journal-Abbr = {NRHM},
	Keywords = {Personalization, Personal Reader, Logic, Semantic Web},
	Owner = {Tim Furche},
	Pdf = {ApplicationAreas/Personalization/Henze.Nejdl_LogicalCharacterizationof_NRHM_2004.pdf},
	Title = {{A Logical Characterization of Adaptive Educational Hypermedia}},
	Url = {http://www.kbs.uni-hannover.de/Arbeiten/Publikationen/2004/logical_characterization_henze_nejdl.pdf},
	Year = {2004}}

@inproceedings{Hidders_SatisfiabilityofXPath_DBPL_2003,
	Abstract = {In this paper, we investigate the complexity of deciding the satisfiability
	 of XPath 2.0 expressions, i.e., whether there is an XML document
	 for which their result is nonempty. Several fragments that allow
	 certain types of expressions are classified as either in PTIME or
	 NP-hard to see which type of expression make this a hard problem.
	 Finally, we establish a link between XPath expressions and partial
	 tree descriptions which are studied in computational linguistics.},
	Author = {Hidders, Jan},
	Booktitle = {Intl. Workshop on Databse Programming Languages},
	Conference-Abbr = {DBPL},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XPath satisfiability query languages theory},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/PathExpressions/XPath/Hidders_SatisfiabilityofXPath_DBPL_2003.pdf},
	Title = {{Satisfiability of XPath Expressions}},
	Url = {http://plantijn.ruca.ua.ac.be/~adrem/biborb/bibs/ADReM/papers/hidders03xpathsat.pdf},
	Year = {2003}}

@inproceedings{Horst_ExtendingRDFSEntailment_ISWC_2004,
	Abstract = {We complement the RDF semantics specification of the W3C by proving
	 decidability of RDFS entailment. Furthermore, we show completeness and
	 decidability of entailment for RDFS extended with datatypes and a
	 property-related fragment of OWL. The RDF semantics specification provides a
	 complete set of entailment rules for reasoning with RDFS, but does not
	 prove decidability of RDFS entailment: the closure graphs used in the
	 completeness proof are infinite for finite RDF graphs. We define partial
	 closure graphs, which can be taken to be finite for finite RDF graphs,
	 which can be computed in polynomial time, and which are sufficient
	 to decide RDFS entailment. We consider the extension of RDFS with
	 datatypes and a property-related fragment of OWL: FunctionalProperty,
	 InverseFunctionalProperty, sameAs, SymmetricProperty, TransitiveProperty, and
	 inverseOf. In order to obtain a complete set of simple entailment rules,
	 the semantics that we use for these extensions is in line with the
	 'if-semantics' of RDFS, and weaker than the 'iff-semantics' defining
	 D-entailment and OWL (DL or Full) entailment. Classes can be used as
	 instances, the use of FunctionalProperty and TransitiveProperty is not
	 restricted to obtain decidability, and a partial closure that is
	 sufficient for deciding entailment can be computed in polynomial time.},
	Author = {ter Horst, Herman J.},
	Booktitle = ISWC # {, Hiroshima, Japan},
	Comment = {Two essential contributions: the notion of ?partial closure? of an RDF graph G. In contrast to the closure graph of G defined in [Hayes, RDF-MT, W3C Recommendation, 2004] that is infinite (due to the infinite number of axiomatic triples for all rdf:_i properties), the partial closure is finite by considering only the axiomatic triples for all rdf:_i actually occuring in the G. The second contribution of this paper is an interesting restriction of OWL-DL (containing, e.g., owl:FunctionalProperty, owl:InverseFunctionalProperty, owl:sameAs, owl:inverseOf) together with an interpretation and a set of entailment rules. This could be a good start for an implementation of a restricted form of OWL on top of Xcerpt.},
	Conference-Abbr = {ISWC},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {RDF Entailment RDFS},
	Owner = {Tim Furche},
	Pdf = {SemanticWeb/RDF/RDFS/Horst_ExtendingRDFSEntailment_ISWC_2004.pdf},
	Title = {{Extending the RDFS Entailment Lemma}},
	Url = {http://xobjects.seu.edu.cn/resource/ISWC2004/abstracts/32980077.html},
	Urldate = {2004/11/24},
	Year = {2004}}

@inproceedings{HungDeng.RDF-Aggregate-Querie.2005,
	Author = {Hung, E. and Deng, Y. and Subrahmanian, V. S.},
	Booktitle = {Proc. Intl. Conf. on Data Engineering},
	Conference-Abbr = {ICDE},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Title = {{RDF Aggregate Queries and Views}},
	Year = {2005}}

@inproceedings{Jain.Mahajan.ea_TranslatingXSLTPrograms_WWW_2002,
	Abstract = {We present an algorithm for translating XSLT
	 programs into SQL. Our context is that of virtual XML publishing,
	 in which a single XML view is defined from a relational database,
	 and subsequently queried with XSLT programs. Each XSLT program is
	 translated into a single SQL query and run entirely in the database
	 engine. Our translation works for a large fragment of XSLT, which we
	 define, that includes descendant/ancestor axis, recursive templates,
	 modes, parameters, and aggregates. We put considerable effort in
	 generating correct and efficient SQL queries and describe several
	 optimization techniques to achieve this efficiency. We have tested our
	 system on all 22 SQL queries of the TPC-H database benchmark which we
	 represented in XSLT and then translated back to SQL using our translator.},
	Author = {Jain, Sushant and Mahajan, Ratul and Suciu, Dan},
	Booktitle = WWW,
	Conference-Abbr = {WWW},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/511446.511526},
	Isbn = {1-58113-449-5},
	Keywords = {XML XSTL query processing relational implementation SQL},
	Location = {Honolulu, Hawaii, USA},
	Pages = {616--626},
	Publisher = {ACM Press},
	Title = {{Translating XSLT Programs to Efficient SQL Queries}},
	Url = {http://www2002.org/CDROM/refereed/226/},
	Year = {2002}}

@inproceedings{Johnson.Shneiderman_Tree-maps-Space-FillingApproach_Vis_1991,
	Abstract = {A method for visualizing
	 hierarchically structured information is described. The tree-map
	 visualization technique makes 100% use of the available display space,
	 mapping the full hierarchy onto a rectangular region in a space-filling
	 manner. This efficient use of space allows very large hierarchies to
	 be displayed in their entirety and facilitates the presentation of
	 semantic information. Tree-maps can depict both the structure and
	 content of the hierarchy. However, the approach is best suited to
	 hierarchies in which the content of the leaf nodes and the structure of the
	 hierarchy are of primary importance, and the content information
	 associated with internal nodes is largely derived from their children},
	Author = {Johnson, Brian and Shneiderman, Ben},
	Booktitle = {Proc. Intl. Conf.on Visualization},
	Conference-Abbr = {Vis},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {visualization hiearchical structures tree map},
	Owner = {Tim Furche},
	Pages = {284--291},
	Pdf = {QueryEvaluation/XML/Visualization/Johnson.Shneiderman_Tree-maps-Space-FillingApproach_Vis_1991.pdf},
	Title = {{Tree-maps: a Space-Filling Approach to the Visualization of Hierarchical Information Structures}},
	Url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?arnumber=175815&isnumber=4467&punumber=362&k2dockey=175815@ieeecnfs&query=%28shneiderman+b.%3CIN%3Eau+%29&pos=1&arSt=284&ared=291&arAuthor=Johnson%2C+B.%3B+Shneiderman%2C+B.%3B},
	Year = {1991}}

@book{Katz.Chamberlin.ea_XQueryfromExperts_2003,
	Author = {Katz, Howard and Chamberlin, Don and Draper, Denise and Fernandez, Mary and Kay, Michael and Robie, Jonathan and Rys, Michael and Simeon, Jerome and Tivy, Jim and Wadler., Philip},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Edition = {1st},
	Owner = {Tim Furche},
	Publisher = {Addison-Wesley},
	Title = {{XQuery from the Experts: A Guide to the W3C XML Query Language}},
	Year = {2003}}

@book{Kay_XPath-2.0Programmer-sReference_2004,
	Abstract = {XPath 2.0 Programmer's Reference is the only
	 authoritative reference on XPath, a sub-language within XSLT that
	 determines which part of an XML document the XSLT transforms. Written for
	 professional programmers who use XML every day but find the W3C XPath
	 specifications tough to slog through, this book explains in everyday language
	 what every construct in the language does and how to use it. It also
	 offers background material on the design thinking behind the language,
	 gentle criticism of the language specification when appropriate, and a
	 diverse range of interesting examples in various application areas.},
	Author = {Kay, Michael},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XPath query query languages},
	Owner = {Tim Furche},
	Publisher = {John Wiley},
	Title = {{XPath 2.0 Programmer's Reference}},
	Year = {2004}}

@book{Kay_XSLT2.0Programmers_2004,
	Abstract = {XSLT 2.0 Programmer's Reference, 3rd Edition, is the
	 authoritative reference guide to the language. Without using the formal and
	 inaccessible language of the W3C specifications, it tells you exactly
	 what every construct in the language does, and how it is intended
	 to be used. This book is a reference rather than a tutorial; it is
	 designed for the professional programmer who is using the language
	 every day. It is the book that people quote when they claim that a
	 particular product is giving the wrong answer, and the book that
	 implementers of the language turn to when they want clarification of
	 the specifications. At the same time, the book is readable. Reviews
	 of the previous editions of the XSLT Programmer?s Reference, which
	 this book grew from, show that readers appreciate the background
	 material on the design thinking behind the language, the essay on
	 functional programming, the occasional dry wit, the gentle criticism of
	 the language specification when appropriate, and the fact that the
	 examples stray into a diverse range of interesting application areas.},
	Author = {Kay, Michael},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Edition = {3rd},
	Keywords = {XML XSLT Programming Query languages},
	Owner = {Tim Furche},
	Publisher = {John Wiley},
	Title = {{XSLT 2.0 Programmer's Reference}},
	Year = {2004}}

@inproceedings{Kay_XSLTandXPath_XMLE_2004,
	Author = {Kay, Michael},
	Booktitle = {XML Europe},
	Conference-Abbr = {XMLE},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XSLT XPath optimization saxon practical experiences},
	Owner = {Tim Furche},
	Title = {{XSLT and XPath Optimization}},
	Url = {http://idealliance.org/papers/dx_xmle04/papers/02-03-02/02-03-02.html},
	Year = {2004}}

@techreport{Kay.Walsh.ea_XSLT2.0and_TR_2005,
	Abstract = {This document defines serialization of an
	 instance of the data model as defined in [Data Model] into a sequence of
	 octets. [Definition: Serialization is designed to be a component
	 of a expanded a host language such as[XSLT 2.0] or [XQuery 1.0].]},
	Author = {Kay, Michael and Walsh, Norman and Zongaro, Henry and Boag, Scott and Tong, Joanne},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {XML XQuery XSLT serialization query languages},
	Owner = {Tim Furche},
	Title = {{XSLT 2.0 and XQuery 1.0 Serialization}},
	Type = {Working Draft},
	Url = {http://www.w3.org/TR/xslt-xquery-serialization/This document defines serialization of an instance of the data model as defined in [Data Model] into a sequence of octets. [Definition: Serialization is designed to be a component of a expanded a host language such as[XSLT 2.0] or [XQuery 1.0].]},
	Year = {2005}}

@inproceedings{Koch.Scherzinger.ea_FluXQuery-OptimizingXQuery_VLDB_2004,
	Author = {Koch, Christoph and Scherzinger, Stefanie and Schweikardt, Nicole and Stegmaier, Bernhard},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = VLDB,
	Conference-Abbr = {VLDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Ee = {http://www.vldb.org/conf/2004/RS6P2.PDF},
	Keywords = {XML XQuery stream implementation FluXQuery},
	Pdf = {QueryEvaluation/XML/XQuery/Koch.Scherzinger.ea_FluXQuery-OptimizingXQuery_VLDB_2004.pdf},
	Title = {{FluXQuery: An Optimizing XQuery Processor for Streaming XML Data}},
	Url = {http://www.wit.at/people/scherzinger/documents/demo.pdf},
	Year = {2004}}

@inproceedings{Koffina.Serfiotis.ea_IntegratingXMLData_DOPS_2005,
	Abstract = {Semantic Web (SW) technology aims to facilitate
	 the integration of legacy data sources spread worldwide. Despite
	 the plethora of SW languages e.g., RDF/S, OWL recently proposed for
	 supporting large scale information interoperation, the vast majority of
	 legacy sources still rely on relational databases RDB published on
	 the Web or corporate intranets as virtual XML. In this paper, we
	 advocate a Datalog framework for mediating high level queries to
	 relational and or XML sources using community ontologies expressed in
	 a SW language such as RDF/S. We describe the architecture and the
	 reasoning services of our SW integration middleware, called SWIM, and we
	 present the main design choices and techniques for supporting powerful
	 mappings between different data models, as well as reformulation and
	 optimization of queries expressed against mediation schemas and views.},
	Author = {Koffina, Ioanna and Serfiotis, Giorgos and Christophides, Vassilis and Tannen, Val and Deutsch, Alin},
	Booktitle = {Dagstuhl Seminar on Semantic Interoperability and Integration},
	Conference-Abbr = {DROPS},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {integration , xml , rdf schema},
	Number = {04391},
	Pdf = {SemanticWeb/RDF/RDF-XML-Integration/Koffina.Serfiotis.ea_IntegratingXMLData_DOPS_2005.pdf},
	Publisher = {IBFI},
	Series = {Dagstuhl Seminar Proceedings},
	Title = {{Integrating XML Data Sources using RDF/S Schemas: The ICS-FORTH Semantic Web Integration Middleware (SWIM)}},
	Url = {http://drops.dagstuhl.de/opus/volltexte/2005/34/pdf/04391.ChristophidesVassilis.Paper.34.pdf},
	Year = {2005}}

@mastersthesis{Kraus_UseCasesfur_2004,
	Abstract = {In dieser Arbeit werden Anwendungsflle f{\"u}r die logische Anfragesprache Xcerpt
	 vorgestellt und implementiert. Zweck dieser Arbeit ist hierbei, die
	 Sprache Xcerpt, welche sich noch in einem Entwicklungszustand befindet,
	 bez{\"u}glich ihrer Ausdrucksfhigkeit und Mchtigkeit zu untersuchen und
	 gegebenenfalls notwendige und noch fehlende Konstrukte und Funktionalitten zu
	 identifizieren. Hierbei werden zum einem die W3C Anwendungsflle f{\"u}r
	 XQuery in Xcerpt implementiert, da diese wegen ihrer Vielzahl von
	 unterschiedlichen Szenarien und somit unterschiedlichen Anfragen als
	 Ma{\ss}stab f{\"u}r eine Anfragesprache herangezogen werden k{\"o}nnen. Zum
	 anderen werden drei kleiner Anwendungsszenarien vorgestellt, die
	 spezielle Fhigkeiten von Xcerpt hervorheben sollen. In dem ersten
	 dieser Szenarien wird der internen Referenzmechanismus von Xcerpt
	 vorgestellt. Da Xcerpt als Webanfragsprache konzipiert wurde, wird in der
	 zweiten Anwendung ein Webcrawler vorgestellt. Die dritte Anwendung
	 beinhaltet Xcerpt-Regel, wie sie ein Mediatorsystem verwenden k{\"o}nnte,
	 um die Transformationsm{\"o}glichkeiten der Sprache hervorzuheben.},
	Author = {Kraus, Sebastian},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML Xcerpt use cases},
	Pdf = {QueryEvaluation/Xcerpt/Kraus_UseCasesfur_2004.pdf},
	School = {University of Munich},
	Title = {{Use Cases f{\"u}r Xcerpt: Eine positionelle Anfrage- und Transformationssprache f{\"u}r das Web}},
	Type = {{Diplomarbeit/Master thesis}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#DA_Sebastian.Kraus},
	Year = {2004}}

@inproceedings{Li.Bohannon.ea_ComposingXSLTransformations_SIGMOD_2003,
	Abstract = {While the XML Stylesheet Language
	 for Transformations (XSLT) was not designed as a query language,
	 it is well-suited for many query-like operations on XML documents
	 including selecting and restructuring data. Further, it actively
	 fulfills the role of an XML query language in modern applications and
	 is widely supported by application platform software. However, the
	 use of database techniques to optimize and execute XSLT has only
	 recently received attention in the research community. In this paper, we
	 focus on the case where XSL transformations are to be run on XML
	 documents defined as views of relational databases. For a subset
	 of XSLT, we present an algorithm to compose a transformation with
	 an XML view, eliminating the need for the XSLT execution. We then
	 describe how to extend this algorithm to handle several additional
	 features of XSLT, including a proposed approach for handling recursion.},
	Author = {Li, Chengkai and Bohannon, Philip and Narayan, P. P. S.},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/872757.872820},
	Isbn = {1-58113-634-X},
	Keywords = {XML XSLT view query rewriting evaluation optimization},
	Location = {San Diego, California},
	Pages = {515--526},
	Publisher = {ACM Press},
	Title = {{Composing XSL Transformations with XML Publishing Views}},
	Url = {http://www.ews.uiuc.edu/~cli/417-li.pdf},
	Year = {2003}}

@inproceedings{Liu.Vincent_Querytranslationfrom_DEAS_2003,
	Abstract = {XML has been accepted as a universal
	 format for data interchange and publication. It can be applied in the
	 applications in which the data of a database needs to be viewed in
	 XML format so that the data being viewed takes more semantics and
	 is easily understood. In these applications, the user of the data
	 to be viewed sees only XML data, not the database. He may use XML
	 query languages such as XSLT to query data and the retrieved data is
	 presented in XML format to them. We are interested in the connection
	 between the data that the user sees and the data in the database. More
	 specifically, we are interested in translating XSLT queries to SQL queries.},
	Author = {Liu, Jixue and Vincent, Millist},
	Booktitle = {Proc. Intl. Database Engineering and Applications Symposium},
	Conference-Abbr = {DEAS},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XSLT relational implementation SQL query evaluation},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XSLT/Liu.Vincent_Querytranslationfrom_DEAS_2003.pdf},
	Title = {{Query translation from XSLT to SQL}},
	Year = {2003}}

@techreport{Malhotra.Melton.ea_XQuery1.0and_TR_2005,
	Abstract = {This document defines basic operators and functions on the datatypes defined in [XML
	 Schema Part 2: Datatypes Second Edition] and the datatypes defined in
	 [XQuery 1.0 and XPath 2.0 Data Model] and in this document for use
	 in [XPath 2.0], [XQuery 1.0: An XML Query Language] and [XSLT 2.0]
	 and other related XML standards. It also discusses operators and
	 functions on nodes and node sequences as defined in the [XQuery 1.0
	 and XPath 2.0 Data Model] for use in [XPath 2.0], [XQuery 1.0: An
	 XML Query Language] and [XSLT 2.0] and other related XML standards.},
	Author = {Malhotra, Ashok and Melton, Jim and Walsh, Norman},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Institution = {W3C},
	Keywords = {XML XQuery Functuions Operators XPath W3C Query Query Languages},
	Owner = {Tim Furche},
	Title = {{XQuery 1.0 and XPath 2.0 Functions and Operators}},
	Type = {Working Draft},
	Url = {http://www.w3.org/TR/xpath-functions/},
	Urldate = {2005/01/31},
	Year = {2005}}

@inproceedings{Manola.Pirotte_CQLF---aQueryLanguage_SIGMOD_1982,
	Abstract = {This paper describes CQLF (CODASYL Query Language, Flat) [MAN081].
	 CQLF is a high level language for accessing and manipulating data in
	 databases described using the 1981 ANSI dpANS version of the CODASYL Data
	 Description Language [ANSI81]. CQLF has similarities to typical relational
	 languages, such as SQL [ASTR76, CHAM76] and QUEL [STON76]. CQLF provides
	 capabilities for querying and operating on databases described both
	 in a "relational style" (having no CODASYL sets, using only values
	 to represent interrecord relationships, and having records with no
	 arrays), and in a "network style" (using CODASYL sets to represent
	 interrecord relationships, and having records containing arrays).},
	Author = {Manola, Frank and Pirotte, Alain},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/582353.582369},
	Isbn = {0-89791-073-7},
	Keywords = {CODASYL, network databases, query languages, CQLF, path expressions},
	Location = {Orlando, Florida},
	Pages = {94--103},
	Pdf = {QueryEvaluation/Languages/Manola.Pirotte_CQLF---aQueryLanguage_SIGMOD_1982.pdf},
	Publisher = {ACM Press},
	Title = {{CQLF---a Query Language for CODASYL-type Databases}},
	Url = {http://portal.acm.org/citation.cfm?id=582369},
	Year = {1982}}

@inproceedings{Martens.Neven_FrontiersofTractability_PODS_2004,
	Author = {Martens, Wim and Neven, Frank},
	Booktitle = PODS,
	Conference-Abbr = {PODS},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML transformations type checking tractability},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XSLT/Martens.Neven_FrontiersofTractability_PODS_2004.pdf},
	Title = {{Frontiers of Tractability for Typechecking Simple XML Transformations}},
	Url = {http://www.sigmod.org/sigmod/pods/proc04/pdf/P-03.pdf},
	Year = {2004}}

@inproceedings{May.Helmer.ea_QuantifiersinXQuery_WISE_2003,
	Abstract = {We present algebraic equivalences that allow to unnest nested
	 algebraic expressions containing quantifiers for order-preserving
	 algebraic operators. We illustrate how these equivalences can be
	 applied successfully to unnest nested queries formulated in XQuery.
	 Measurements illustrate the performance gains possible by unnesting.},
	Author = {May, Norman and Helmer, Sven and Moerkotte, Guido},
	Booktitle = {Proc. Intl. Conf. on Web Information Systems Engineering},
	Conference-Abbr = {WISE},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XQuery quantifiers nested queries optimization rewriting},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/XQuery/May.Helmer.ea_QuantifiersinXQuery_WISE_2003.pdf},
	Title = {{Quantifiers in XQuery}},
	Url = {http://pi3.informatik.uni-mannheim.de/~norman/unnesting_wise03.pdf},
	Year = {2003}}

@inproceedings{Meuss.Schulz.ea_TowardsAggregatedAnswers_ICDT_2001,
	Abstract = {Semistructured data are usually
	 formalized as trees or more generally as graphs. Query languages for
	 semistructured data have been proposed that, like SQL, can be seen as
	 involving a number of variables, but, in contrast to SQL, arrange
	 the variables in trees or graphs reflecting the structure of the
	 semistructured data to be retrieved. Leaving aside the ``construct''
	 parts of queries, answers can be formalized as mappings represented
	 as tuples, hence called answer tuples, that assign database nodes
	 to query variables. These answer tuples underly the semistructured
	 data delivered as answers. A simple enumeration of answer tuples
	 following the old relational approach is problematic for several reasons.
	 First, the number of answer tuples for a query may grow exponentially
	 in the size of both, the query and the database. Second, even if
	 the number of answer tuples is manageable, the frequent sharing of
	 common data between distinct answer tuples is no more apparent in
	 their enumeration. In this article, it is first argued that, in the
	 context of semistructured data, enumerating answer tuples is often
	 inappropriate and that aggregated answers are preferable. Then, a
	 notion of aggregated answers called complete answer aggregate (CAA) is
	 introduced and algorithms for computing CAAs are given. It is shown
	 that CAAs enjoy nice complexity properties: (1) While the number of
	 answer tuples may be exponential in the size of the query, the size of
	 the CAA is at most linear in the size of the query and quadratic
	 in the size of the database; (2) the complexity of computing the
	 CAA of a query depends on the query's structural complexity (i.e.
	 whether it is a sequence, tree, graph, etc.) but is independent of the
	 structural complexity of the database. For tree queries, efficient
	 polynomial algorithms are given. Besides, it is argued that CAAs are
	 particularly appropriate for answer searching and answer browsing.},
	Author = {Meuss, Holger and Schulz, Klaus U. and Bry, Fran{\c c}ois},
	Booktitle = {Proc. Intl. Conf. on Database Theory},
	Conference-Abbr = {ICDT},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {3-540-41456-8},
	Keywords = {XML query languages CAA navigation theory path visualization},
	Pages = {346--360},
	Publisher = {Springer-Verlag},
	Title = {{Towards Aggregated Answers for Semistructured Data}},
	Url = {http://www.pms.ifi.lmu.de/publikationen#PMS-FB-2000-15},
	Year = {2001}}

@article{Meuss.Schulz.ea_VisualExplorationand_JDL_2005,
	Abstract = {This article reports on the XML retrieval system X2 which has been developed
	 at the University of Munich over the last five years. In a typical
	 session with X2, the user first browses a structural summary of the
	 XML database in order to select interesting elements and keywords
	 occurring in documents. Using this intermediate result, queries combining
	 structure and textual references are composed semiautomatically.
	 After query evaluation, the full set of answers is presented in a
	 visual and structured way. X2 largely exploits the structure found in
	 documents, queries and answers to enable new interactive visualization and
	 exploration techniques that support mixed IR and database-oriented
	 querying, thus bridging the gap between these three views on the
	 data to be retrieved. Another salient characteristic of X2 which
	 distinguishes it from other visual query systems for XML is that
	 it supports various degrees of detailedness in the presentation of
	 answers, as well as techniques for dynamically reordering and grouping
	 retrieved elements once the complete answer set has been computed.},
	Author = {Meuss, Holger and Schulz, Klaus U. and Weigel, Felix and Leonardi, Simone and Bry, Fran{\c c}ois},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {Journal on Digital Libraries},
	Journal-Abbr = {JDL},
	Keywords = {XML query languages visualization exploration X2 CAA},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/Visualization/Meuss.Schulz.ea_VisualExplorationand_JDL_2005.pdf},
	Title = {{Visual Exploration and Retrieval of XML Document Collections with the Generic System X2}},
	Url = {http://www.cis.uni-muenchen.de/~weigel/Literatur/meuss04visual.pdf},
	Year = {2005}}

@inproceedings{Meyer.Bruder.ea_XircusSearchEngine_INEX_2002,
	Abstract = {Nowadays, XML is the document model in favour for both document- and data-centric web
	 applications. Its influence in other, more traditional projects and
	 applications grows as the web and associated techniques become the de-facto
	 standard in user interfaces in such systems. We present an XML-sensitive
	 search engine (Xircus) suited for processing semi-structured queries
	 over large collections of XML documents. Xircus is based on state
	 of the art information retrieval techniques. It is a test bed for
	 research in query processing for XML and semistructured data in general.},
	Author = {Meyer, Holger and Bruder, Ilvio and Heuer, Andreas and Weber, Gunnar},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {INEX Workshop},
	Conference-Abbr = {INEX},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Pages = {119-124},
	Title = {{The Xircus Search Engine}},
	Year = {2002}}

@inproceedings{Miklau.Suciu_ContainmentandEquivalence_PODS_2002,
	Abstract = {XPath is a simple language for navigating an XML document and selecting a set of element nodes. XPath expressions are used to query XML data, describe key constraints, express transformations, and reference elements in remote documents. This paper studies the containment and equivalence problems for a fragment of the XPath query language, with applications in all these contexts.In particular, we study a class of XPath queries that contain branching, label wildcards and can express descendant relationships between nodes. Prior work has shown that languages which combine any two of these three features have efficient containment algorithms. However, we show that for the combination of features, containment is coNP-complete. We provide a sound and complete EXPTIME algorithm for containment, and study parameterized PTIME special cases. While we identify two parameterized classes of queries for which containment can be decided efficiently, we also show that even with some bounded parameters, containment is coNP-complete. In response to these negative results, we describe a sound algorithm which is efficient for all queries, but may return false negatives in some cases.},
	Author = {Miklau, Gerome and Suciu, Dan},
	Booktitle = PODS,
	Conference-Abbr = {PODS},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/543613.543623},
	Isbn = {1-58113-507-6},
	Keywords = {XML XPath fragment containment query languages},
	Location = {Madison, Wisconsin},
	Pages = {65--76},
	Pdf = {QueryEvaluation/PathExpressions/XPath/Miklau.Suciu_ContainmentandEquivalence_PODS_2002.pdf},
	Publisher = {ACM Press},
	Title = {{Containment and Equivalence for an XPath Fragment}},
	Url = {http://www.cs.washington.edu/homes/suciu/pods2002MS.pdf},
	Year = {2002}}

@inproceedings{Munroe.Papakonstantinou_BBQ-VisualInterface_VDB_2000,
	Abstract = {In this paper we present BBQ (Blended Browsing and Querying),
	 a graphic user interface for seamlessly browsing and querying XML
	 data sources. BBQ displays the structure of multiple data sources
	 using a paradigm that resembles drilling-down in Windows? directory
	 structures. BBQ allows queries incorporating one or more of the sources.
	 Queries are constructed in a query-by-example (QBE) manner, where
	 DTDs play the role of schema. The queries are arbitrary conjunctive
	 queries with GROUPBY, and their results can be subsequently used and
	 refined. To support query refinement, BBQ introduces virtual result
	 views: standalone virtual data sources that (i) are constructed by
	 user queries, from elements in other data sources, and (ii) can be
	 used in subsequent queries as first-class data sources themselves.
	 Furthermore, BBQ allows users to query data sources with loose or incomplete
	 schema, and can augment such schema with a DTD inference mechanism.},
	Author = {Munroe, Kevin D. and Papakonstantinou, Yannis},
	Booktitle = {Proc. Conf. on Visual Database Systems},
	Conference-Abbr = {VDB},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {0-7923-7835-0},
	Keywords = {XML query visualization XMAS BBQ interface},
	Pages = {277--296},
	Pdf = {QueryEvaluation/XML/Visualization/Munroe.Papakonstantinou_BBQ-VisualInterface_VDB_2000.pdf},
	Publisher = {Kluwer, B.V.},
	Title = {{BBQ: A Visual Interface for Integrated Browsing and Querying of XML}},
	Url = {http://www.db.ucsd.edu/publications/bbq.pdf},
	Year = {2000}}

@inproceedings{Murata.Tozawa.ea_XMLAccessControl_CCS_2003,
	Abstract = {Access control policies
	 for XML typically use regular path expressions such as XPath for
	 specifying the objects for access control policies. However such
	 access control policies are burdens to the engines for XML query
	 languages. To relieve this burden, we introduce static analysis for XML
	 access control. Given an access control policy, query expression,
	 and an optional schema, static analysis determines if this query
	 expression is guaranteed not to access elements or attributes that are
	 permitted by the schema but hidden by the access control policy. Static
	 analysis can be performed without evaluating any query expression
	 against an actual database. Run-time checking is required only when
	 static analysis is unable to determine whether to grant or deny access
	 requests. A nice side-effect of static analysis is query optimization:
	 access-denied expressions in queries can be evaluated to empty lists at
	 compile time. We have built a prototype of static analysis for XQuery,
	 and shown the effectiveness and scalability through experiments.},
	Author = {Murata, Makoto and Tozawa, Akihiko and Kudo, Michiharu and Hada, Satoshi},
	Booktitle = {Proc. ACM Conf. on Computer and Communications Security},
	Conference-Abbr = {CCS},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/948109.948122},
	Isbn = {1-58113-738-9},
	Keywords = {XML XQuery access control policy},
	Location = {Washington D.C., USA},
	Pages = {73--84},
	Pdf = {QueryEvaluation/XML/XQuery/Murata.Tozawa.ea_XMLAccessControl_CCS_2003.pdf},
	Publisher = {ACM Press},
	Title = {{XML Access Control using Static Analysis}},
	Url = {http://portal.acm.org/citation.cfm?id=948122},
	Year = {2003}}

@article{Oliboni.Tanca_VisualLanguageshould_IS_2002,
	Abstract = {XML is spreading out as a standard for
	 semistructured documents on the Web, so the possibility of querying
	 XML documents which are linked by XML links is becoming a goal to
	 achieve. In this paper we present XML-GLrec, an extended version
	 of the graphical query language for XML documents XML-GL. XML-GL
	 allows to extract and restructure information from XML specified
	 WWW documents. We extend XML-GL in the following directions: (i)
	 XML-GLrec allows to represent XML simple finks, so that it is possible to
	 query whole XML specified WWW sites in a simple and intuitive way;
	 (ii) XML-GLrec improves the expressive power of XML-GL, where only
	 transitive closure can be expressed, by allowing generic recursion; (iii)
	 finally, we permit the user to specify queries in an easier fashion,
	 by allowing sequences of nested query, in the same way as in SQL.},
	Author = {Oliboni, Barbara and Tanca, Letizia},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://dx.doi.org/10.1016/S0306-4379(02)00007-8},
	Issn = {0306-4379},
	Journal = {Information Systems},
	Journal-Abbr = {IS},
	Keywords = {XML query languages XML-GL recursion},
	Number = {7},
	Pages = {459--486},
	Publisher = {Elsevier Science Ltd.},
	Title = {{A Visual Language should be easy to use: a Step Forward for XML-GL}},
	Volume = {27},
	Year = {2002}}

@phdthesis{Olteanu_EvaluationofXPath_2005,
	Abstract = {XML is nowadays the de facto standard for
	 electronic data interchange on the Web. Available XML data ranges from
	 small Web pages to ever-growing repositories of, e.g., biological and
	 astronomical data, and even to rapidly changing and possibly unbounded
	 streams, as used in Web data integration and publish-subscribe systems.
	 Animated by the ubiquity of XML data, the basic task of XML querying is
	 becoming of great theoretical and practical importance. The last years
	 witnessed efforts as well from practitioners, as also from theoreticians
	 towards defining an appropriate XML query language. At the core of
	 this common effort has been identified a navigational approach for
	 information localization in XML data, comprised in a practical and simple
	 query language called XPath [1]. This work brings together the two
	 aforementioned ?worlds?, i.e., the XPath query evaluation and the XML data
	 streams, and shows as well theoretical as also practical relevance
	 of this fusion. Its relevance can not be subsumed by traditional
	 database management systems, because the latter are not designed for
	 rapid and continuous loading of individual data items, and do not
	 directly support the continuous queries that are typical for stream
	 applications. The first central contribution of this work consists in the
	 definition and the theoretical investigation of three term rewriting
	 systems to rewrite queries with reverse predicates, like parent or
	 ancestor, into equivalent forward queries, i.e., queries without
	 reverse predicates. Our rewriting approach is vital to the evaluation
	 of queries with reverse predicates against unbounded XML streams,
	 because neither the storage of past fragments of the stream, nor
	 several stream traversals, as required by the evaluation of reverse
	 predicates, are affordable. Beyond their declared main purpose of providing
	 equivalences between queries with reverse predicates and forward
	 queries, the applications of our rewriting systems shed light on
	 other query language properties, like the expressivity of some of its
	 fragments, the query minimization, or even the complexity of query
	 evaluation. For example, using these systems, one can rewrite any
	 graph query into an equivalent forward forest query. The second main
	 contribution consists in a streamed and progressive evaluation strategy of
	 forward queries against XML streams. The evaluation is specified
	 using compositions of so-called stream processing functions, and is
	 implemented using networks of deterministic pushdown transducers. The
	 complexity of this evaluation strategy is polynomial in both the
	 query and the data sizes for forward forest queries and even for
	 a large fragment of graph queries. The third central contribution
	 consists in two real monitoring applications that use directly the
	 results of this work: the monitoring of processes running on UNIX
	 computers, and a system for providing graphically real-time traffic and
	 travel information, as broadcasted within ubiquitous radio signals.},
	Author = {Olteanu, Dan},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML query streams rewriting forward XPath LGQ complexity query languages XPath SPEX},
	Owner = {Tim Furche},
	School = {University of Munich},
	Title = {{Evaluation of XPath Queries against XML Streams}},
	Type = {{Dissertation/Ph.D. thesis}},
	Year = {2005}}

@inproceedings{Olteanu.Furche.ea_EfficientSingle-PassQuery_SAC_2004,
	Abstract = {Data streams might be preferable to data stored in memory in contexts where
	 the data is too large or volatile, or a standard approach to data
	 processing based on data parsing and/or storing is too time or space
	 consuming. Emerging applications such as publish-subscribe systems, data
	 monitoring in sensor networks, financial and traffic monitoring,
	 and routing of MPEG-7 call for querying data streams. In many such
	 applications, XML streams are arguably more appropriate than flat
	 data streams, for XML data is record-like, though not precluding
	 multiple occurrences of fields with the same name. Evaluating selection
	 queries against XML streams is especially challenging because XML
	 data is structured (like records) and might have unbounded size.This
	 paper proposes an efficient single-pass evaluator of XPath queries
	 against XML data streams unbounded (possibly infinite) in size. The
	 evaluator is based on networks of independent deterministic pushdown
	 transducers and it is especially suitable for implementation on devices
	 with low-memory and simple logic as used, e.g., in mobile computing.},
	Author = {Olteanu, Dan and Furche, Tim and Bry, Fran{\c c}ois},
	Booktitle = {Data Streams Track,} # SAC,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XPath, SPEX, streams},
	Pages = {627-631},
	Title = {{An Efficient Single-Pass Query Evaluator for XML Data Streams}},
	Year = {2004}}

@inproceedings{Olteanu.Furche.ea_EvaluatingComplexQueries_BNCOD_2003,
	Abstract = {Querying of XML streams is
	 receiving much attention due to its growing range of applications from
	 traffic monitoring to routing of media streams. Existing approaches to
	 querying XML streams consider restricted query language fragments,
	 in most cases with exponential worst-case complexity in the size
	 of the query. This paper investigates the complexity of the SPEX
	 evaluation method. The combined complexity of this method is shown to be
	 polynomial in the size of the data and the query. Extensive experimental
	 evaluation with a prototype confirm the theoretical complexity results.},
	Author = {Olteanu, Dan and Furche, Tim and Bry, Fran{\c c}ois},
	Booktitle = BNCOD,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {streams, XPath, evaluation, SPEX},
	Pages = {31-44},
	Pdf = {QueryEvaluation/Streams/XPath/Olteanu.Furche.ea_EvaluatingComplexQueries_BNCOD_2003.pdf},
	Title = {{Evaluating Complex Queries against XML streams with Polynomial Combined Complexity}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2003-15},
	Urldate = {2004/11/11},
	Year = {2003}}

@inproceedings{Olteanu2002XPath-Looking-Forward,
	Abstract = {The location path language XPath is of particular importance for XML applications
	 since it is a core component of many XML processing standards such
	 as XSLT or XQuery. In this paper, based on axis symmetry of XPath,
	 equivalences of XPath 1.0 location paths involving ?reverse axes?, such as
	 ancestor and preceding, are established. These equivalences are used
	 as rewriting rules in an algorithm for transforming location paths
	 with reverse axes into equivalent reverse-axis-free ones. Location
	 paths without reverse axes as generated by the presented rewriting
	 algorithm enable efficient SAX-like streamed data processing of XPath.},
	Author = {Olteanu, Dan and Meuss, Holger and Furche, Tim and Bry, Fran{\c c}ois},
	Booktitle = {Proc. EDBT Workshop on XML-Based Data Management},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Publisher = springer,
	Series = lncs,
	Title = {{XPath: Looking Forward}},
	Volume = {2490},
	Year = {2002}}

@inproceedings{Olteanu.Meuss.ea_SymmetryinXPath_RMT_2001,
	Abstract = {The location path language XPath is of particular importance for XML applications
	 since it is a core component of many XML processing standards such
	 as XSLT or XQuery. In this paper, based on axis symmetry of XPath,
	 equivalences of XPath 1.0 location paths involving ?reverse axes?, such as
	 ancestor and preceding, are established. These equivalences are used
	 as rewriting rules in an algorithm for transforming location paths
	 with reverse axes into equivalent reverse-axis-free ones. Location
	 paths without reverse axes as generated by the presented rewriting
	 algorithm enable efficient SAX-like streamed data processing of XPath.},
	Author = {Olteanu, Dan and Meuss, Holger and Furche, Tim and Bry, Fran{\c c}ois},
	Booktitle = {Proc. Seminar on Rule Markup Techniques, Schloss Dagstuhl},
	Conference-Abbr = {RMT},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Pdf = {QueryEvaluation/Streams/XPath/Olteanu.Meuss.ea_SymmetryinXPath_RMT_2001.pdf},
	Title = {{Symmetry in XPath}},
	Url = {http://www.pms.ifi.lmu.de/publikationen/#PMS-FB-2001-16},
	Urldate = {2004/11/11},
	Year = {2001}}

@inproceedings{Ono.Koyanagi.ea_XSLTStylesheetGeneration_SAINT_2002,
	Abstract = {XSLT plays an important role in data conversions between different XML
	 representations. However, besides the transformations between XML data
	 representations, conversion to an HTML document is one of the most practical
	 tasks for XSLT, because it allows XML documents to be rendered in a
	 human-readable form using Web browsers. We have developed XSLbyDemo,
	 which is an XSLT stylesheet generation module to be plugged into a
	 commercially available full-fledged HTML authoring tool. The remarkable
	 feature of XSLbyDemo is that users can create an XSLT stylesheet
	 automatically solely on the basis of their knowledge of HTML editing. We
	 briefly explain situations where stylesheets for XML rendering are
	 needed. We then introduce the rule generation method based on the
	 users' operation history recorded behind the WYSIWYG editor, and in
	 particular explain the ways of generalizing the created rules so that the
	 obtained rules can be applied to other documents slightly different from
	 the original one. Finally, we give a practical example of the rules
	 generation by XSLbyDemo, and demonstrate that our method can be used for
	 not only the conversion but also the partitioning of a real-life
	 HTML document into smaller pages represented with Compact HTML to
	 be rendered on Web-enabled cellular phones such as i-mode phones},
	Author = {Ono, Kouichi and Koyanagi, Teruo and Abe, Mari and Hori, Masahiro},
	Booktitle = {Proc. Symposium on Applications and the Internet},
	Conference-Abbr = {SAINT},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XSLT HTML visual stylesheet generation},
	Owner = {Tim Furche},
	Title = {{XSLT Stylesheet Generation by Example with WYSIWYG Editing}},
	Url = {http://doi.ieeecomputersociety.org/10.1109/SAINT.2002.994471},
	Year = {2002}}

@inproceedings{Onose.Simeon_XQueryatyour_WWW_2004,
	Abstract = {XML messaging is at the
	 heart of Web services, providing the flexibility required for their
	 deployment, composition, and maintenance. Yet, current approaches to Web
	 services development hide the messaging layer behind Java or C# APIs,
	 preventing the application to get direct access to the underlying XML
	 information. To address this problem, we advocate the use of a native XML
	 language, namely XQuery, as an integral part of the Web services
	 development infrastructure. The main contribution of the paper is a
	 binding between WSDL, the Web Services Description Language, and
	 XQuery. The approach enables the use of XQuery for both Web services
	 deployment and composition. We present a simple command-line tool that can
	 be used to automatically deploy a Web service from a given XQuery
	 module, and extend the XQuery language itself with a statement for
	 accessing one or more Web services. The binding provides tight-coupling
	 between WSDL and XQuery, yielding additional benefits, notably: the
	 ability to use WSDL as an interface language for XQuery, and the
	 ability to perform static typing on XQuery programs that include
	 Web service calls. Last but not least, the proposal requires only
	 minimal changes to the existing infrastructure. We report on our
	 experience implementing this approach in the Galax XQuery processor.},
	Author = {Onose, Nicola and Simeon, Jerome},
	Booktitle = WWW,
	Conference-Abbr = {WWW},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/988672.988754},
	Isbn = {1-58113-844-X},
	Keywords = {XML XQuery web services implementation},
	Location = {New York, NY, USA},
	Pages = {603--611},
	Pdf = {QueryEvaluation/XML/XQuery/Onose.Simeon_XQueryatyour_WWW_2004.pdf},
	Publisher = {ACM Press},
	Title = {{XQuery at your Web Service}},
	Url = {http://www.www2004.org/proceedings/docs/1p603.pdf},
	Year = {2004}}

@inproceedings{Pietriga.Vion-Dury.ea_VXT-VisualApproach_DocEng_2001,
	Abstract = {The domain of XML transformations is becoming more and more important as a result of the
	 increasing number of applications adopting XML as their format for
	 data exchange or representation. Most of the existing solutions for
	 expressing XML transformations are textual languages, such as XSLT or DOM
	 combined with a general-purpose programming language. Several tools
	 build on top of these languages, providing a graphical environment.
	 Transformations are however still specified in a textual way using the
	 underlying language (often XSLT), thus requiring the user to learn
	 the associated textual language.We believe that visual programming
	 techniques are well-suited to representing XML structures and make the
	 specification of transformations simpler. We present a visual programming
	 language for the specification of XML transformations in an interactive
	 environment, based on a zoomable user interface toolkit. Transformations can
	 be run from the application or exported to two target languages:
	 XSLT and Circus, a general-purpose structure transformation language
	 designed by the second author and briefly introduced in this paper.},
	Author = {Pietriga, Emmanuel and Vion-Dury, Jean-Yves and Quint, Vincent},
	Booktitle = {Proc. ACM Symposium on Document Engineering},
	Conference-Abbr = {DocEng},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/502187.502189},
	Isbn = {1-58113-432-0},
	Keywords = {XML query languages visual VXT transformer path based},
	Location = {Atlanta, Georgia, USA},
	Pages = {1--10},
	Pdf = {QueryEvaluation/XML/Visualization/Pietriga.Vion-Dury.ea_VXT-VisualApproach_DocEng_2001.pdf},
	Publisher = {ACM Press},
	Title = {{VXT: a Visual Approach to XML Transformations}},
	Url = {http://www.cs.uwm.edu/classes/cs790/digdoc-s2003/papers/p1-pietriga.pdf},
	Year = {2001}}

@techreport{Prudhommeaux2007SPARQL-Query-Language-for-RDF,
	Abstract = {RDF is a directed, labeled graph data format for representing information in the Web. This specification defines the syntax and semantics of the SPARQL query language for RDF. SPARQL can be used to express queries across diverse data sources, whether the data is stored natively as RDF or viewed as RDF via middleware. SPARQL contains capabilities for querying required and optional graph patterns along with their conjunctions and disjunctions. SPARQL also supports extensible value testing and constraining queries by source RDF graph. The results of SPARQL queries can be results sets or RDF graphs.},
	Author = {Prud'hommeaux, Eric and Seaborne, Andy},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-12-11 14:54:44 +0100},
	Institution = {W3C},
	Keywords = {RDF, SPARQL, query languages},
	Local-Url = {file://localhost/Users/timfu/archive/research/bibliography/bibdesk/Prudhommeaux2007SPARQL-Query-Language-for-RDF.pdf},
	Owner = {Tim Furche},
	Title = {{SPARQL Query Language for RDF}},
	Type = {Proposed Recommendation},
	Url = {http://www.w3.org/TR/rdf-sparql-query/},
	Year = {2007}}

@article{Riecken_PersonalizedViewsof_CACM_2000,
	Abstract = {Our vocabulary of Internet-related words has become socially popular and, of course, an essential
	 tool of trade in the hands of marketing initiatives. I recall in
	 the early 1990s when words like "agent" and "multimedia" were so
	 overused they became little more than meaningless marketing spin.},
	Author = {Riecken, Doug},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {Communications of the ACM},
	Journal-Abbr = {CACM},
	Keywords = {Personalization, Web, Vision},
	Number = {8},
	Owner = {Tim Furche},
	Pages = {26-28},
	Title = {{Personalized Views of Personalization}},
	Volume = {43},
	Year = {2000}}

@inproceedings{Robie.The-Syntactic-Web.2001,
	Author = {Robie, Jonathan},
	Booktitle = {Proc. XML Conference and Exhibition},
	Conference-Abbr = {XML},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Title = {{The Syntactic Web}},
	Url = {http://www.idealliance.org/pa pers/xml2001/papers/html/03-01-04.html},
	Year = {2001}}

@inproceedings{Robie_UpdatesinXQuery_XML_2001,
	Author = {Robie, Jonathan},
	Booktitle = {XML Conference \& Exhibiton},
	Conference-Abbr = {XML},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XQuery update query languages reactivity},
	Owner = {Tim Furche},
	Title = {{Updates in XQuery}},
	Year = {2001}}

@phdthesis{Schaffert2004Xcerpt,
	Abstract = {This thesis investigates querying the Web
	 and the Semantic Web. It proposes a new rulebased query language
	 called Xcerpt. Xcerpt differs from other query languages in that it
	 uses patterns instead of paths for the selection of data, and in
	 that it supports both rule chaining and recursion. Rule chaining
	 serves for structuring large queries, as well as for designing complex
	 query programs (e.g. involving queries to the Semantic Web), and
	 for modelling inference rules. Query patterns may contain special
	 constructs like partial subqueries, optional subqueries, or negated
	 subqueries that account for the particularly flexible structure of data
	 on the Web. Furthermore, this thesis introduces the syntax of the
	 language Xcerpt, which is illustrated on a large collection of use cases
	 both from the conventional Web and the Semantic Web. In addition,
	 a declarative semantics in form of a Tarski-style model theory is
	 described, and an algorithm is proposed that performs a backward chaining
	 evaluation of Xcerpt programs. This algorithm has also been implemented
	 (partly) in a prototypical runtime system. A salient aspect of this
	 algorithm is the specification of a non-standard unification algorithm
	 called simulation unification that supports the new query constructs
	 described above. This unification is symmetric in the sense that
	 variables in both terms can be bound. On the other hand it is in
	 contrast to standard unification assymmetric in the sense that the
	 unification determines that the one term is a subterm of the other term.},
	Author = {Schaffert, Sebastian},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML, Xcerpt, query language, semantics, syntax, simulation unification},
	Pdf = {QueryEvaluation/Xcerpt/Schaffert_Xcerpt-Rule-BasedQuery_2004.pdf},
	School = {University of Munich},
	Title = {{Xcerpt: A Rule-Based Query and Transformation Language for the Web}},
	Type = {{Dissertation/Ph.D. thesis}},
	Url = {http://www.pms.ifi.lmu.de/publikationen#PMS-DISS-2004-1},
	Year = {2004}}

@inproceedings{Schaffert2004Querying-the-Web-Reconsidered,
	Abstract = {Anfragesprachen f{\"u}r
	 XML-Daten sind heutzutage wesentliche Werkzeuge in der Entwicklung von
	 Webanwendungen. Die am weitesten verbreiteten Sprachen sind XQuery
	 und XSLT, die beide auf der pfadbasierten Selektionssprache XPath
	 aufbauen. Dieser Vortrag gibt einen Einblick in eine neue Anfragesprache
	 namens Xcerpt, die statt des pfadbasierten Ansatzes Anfragepattern
	 verwendet, welche eine deklarativere Spezifikation von Anfragen erlauben.
	 Xcerpt ist ausserdem eine deduktive, regelbasierte Sprache, die auch
	 die Verkn{\"u}pfung von mehreren Regeln (Chaining) und Rekursion
	 erm{\"o}glicht. Eine Xcerpt-Regel kann damit auch als Abstraktion der
	 Ausgangsdaten verstanden werden, hnlich zu Views in relationalen
	 Datenbanken.Auf Xcerpt aufbauend wird ausserdem die visuelle Anfragesprache
	 visXcerpt vorgestellt. Aufgrund des patternbasierten Ansatzes von Xcerpt
	 k{\"o}nnen in visXcerpt Anfragen auf einfache Weise visuell dargestellt
	 und bearbeitet werden.Das Ziel beider Anfragesprachen ist es, die
	 Entwicklung von Anwendungen insbesondere f{\"u}r das "Semantic Web" zu
	 vereinfachen:Anfnger k{\"o}nnen mit Hilfe von visXcerpt Anfragen
	 schnell und intuitiv formulieren und Fortgeschrittenen hilft die
	 Deklarativitt von Xcerpt bei der Gliederung komplexer Programme.},
	Author = {Schaffert, Sebastian and Bry, Fran{\c c}ois},
	Booktitle = eml,
	Conference-Abbr = {EML},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {REWERSE Xcerpt Query Languages},
	Pdf = {SemanticWeb/REWERSE/Schaffert.Bry_QueryingWebReconsidered_EML_2004.pdf.download/Schaffert.Bry_QueryingWebReconsidered_EML_2004.pdf},
	Title = {{Querying the Web Reconsidered: A Practical Introduction to Xcerpt}},
	Url = {http://www.pms.ifi.lmu.de/publikationen#PMS-FB-2004-7},
	Year = {2004}}

@inproceedings{Seipel_ProcessingXML-Documentsin_WLP_2002,
	Author = {Seipel, Dietmar},
	Booktitle = {Workshop on Logic Programming},
	Conference-Abbr = {WLP},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML query languages prolog logic programming FnQuery},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/LogicProgrammingApproaches/Seipel_ProcessingXML-Documentsin_WLP_2002.pdf},
	Title = {{Processing XML-Documents in Prolog}},
	Url = {http://www-info1.informatik.uni-wuerzburg.de/database/papers/wlp_2002.ps.gz},
	Year = {2002}}

@article{Seipel.Baumeister_DeclarativeMethodsEvaluation_KI_2004,
	Abstract = {The ontology web language Owl has been established as a standardized representation
	 for knowledge, especially in the context of the semantic web. An
	 important facet of the management of such knowledge bases consists in its
	 evaluation. Besides standard evaluation methods described in the literature
	 particular applications can require to consider further measures. In this
	 paper, we use a declarative, logic-based Xml query and transformation
	 language called FnQuery, which is suitable for fexibly defning queries
	 for evaluating Owl-based knowledge. The queries are evaluated using
	 logic programming and nonmonotonic reasoning systems. The presented
	 approach could be extended to handle complex refactorings as well.},
	Author = {Seipel, Dietmar and Baumeister, Joachim},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Journal = {KI--K{\"u}nstliche Intelligenz},
	Journal-Abbr = {KI},
	Keywords = {XML OWL FnQuery ontologies prolog logic programming},
	Owner = {Tim Furche},
	Pages = {51--57},
	Title = {{Declarative Methods for the Evaluation of Ontologies}},
	Url = {http://ki.informatik.uni-wuerzburg.de/papers/baumeister/2004/EvalOntologies_KI4_2004.pdf},
	Volume = {4},
	Year = {2004}}

@inproceedings{Seipel.Baumeister.ea_DeclarativelyQueryingand_INAP_2004,
	Abstract = {The maintenance of large knowledge systems usually is a
	 rather complex task. In this paper we will show that extensions or
	 modifications of a knowledge base can be supported by appropriate
	 visualizations techniques, e.g. by illustrating dependencies of the considered
	 knowledge. In particular, we introduce a declarative approach for
	 querying and visualizing rule-based knowledge represented as XML
	 documents; a knowledge engineer can extract and visually inspect parts
	 of the knowledge base by ad-hoc declarations in a flexible manner.},
	Author = {Seipel, Dietmar and Baumeister, Joachim and Hopfner, Marbod},
	Booktitle = {Proc. Intl. Conf. on Applications of Declarative Programming and Knowledge Management},
	Conference-Abbr = {INAP},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML query languages FnQuery visualization logic programming prolog},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/XML/LogicProgrammingApproaches/Seipel.Baumeister.ea_DeclarativelyQueryingand_INAP_2004.pdf},
	Title = {{Declaratively Querying and Visualizing Knowledge Bases in XML}},
	Url = {http://www-info1.informatik.uni-wuerzburg.de/database/papers/inap_seipel_2004.ps.gz},
	Year = {2004}}

@inproceedings{Selinger_TopFiveData_ICDE_2005,
	Author = {Selinger, Pat},
	Booktitle = ICDE,
	Conference-Abbr = {ICDE},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {data processing, metadata, unstructured, autonomic, speech},
	Owner = {Tim Furche},
	Title = {{Top Five Data Challenges for the Next Decade}},
	Year = {2005}}

@book{Simpson_XPathandXPointer_2002,
	Abstract = {Referring to specific information inside
	 an XML document is a little like finding a needle in a haystack.
	 XPath and XPointer are two closely related languages that play a key
	 role in XML processing by allowing developers to find these needles
	 and manipulate embedded information. By the time you've finished
	 XPath and XPointer, you'll know how to construct a full XPointer (one
	 that uses an XPath location path to address document content) and
	 completely understand both the XPath and XPointer features it uses.},
	Author = {Simpson, John E.},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Edition = {1st},
	Keywords = {XML XPath XPointer querying locating linking query languages},
	Owner = {Tim Furche},
	Publisher = {O'Reilly},
	Title = {{XPath and XPointer}},
	Year = {2002}}

@inproceedings{Tane.Schmitz.ea_SemanticresourceManagement_WWW_2004,
	Abstract = {Topics in education are changing with an ever faster pace.
	 ELearning resources tend to be more and more decentralized. Users
	 increasingly need to be able to use the resources of the web. For this,
	 they should have tools for finding and organizing information in a
	 decentralized way. In this paper, we show how an ontologybased tool
	 suite allows to make the most of the resources available on the web.},
	Author = {Tane, Julien and Schmitz, Christoph and Stumme, Gerd},
	Booktitle = WWW,
	Citeseerurl = {2005/02/15},
	Conference-Abbr = {WWW},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {Personalization, Web, E-Learning, KAON, L3S},
	Owner = {Tim Furche},
	Pdf = {ApplicationAreas/Personalization/Tane.Schmitz.ea_SemanticresourceManagement_WWW_2004.pdf},
	Title = {{Semantic Resource Management for the Web: An E-Learning Application}},
	Url = {http://www.l3s.de/php/detail.php?dc_title=+Semantic+resource+Management+for+the+web%3A+An+e-learning+application.&dc_creator=Julien+Tane%2C+Christoph+Schmitz%3B+Gerd+Stumme.},
	Year = {2004}}

@inproceedings{Tatarinov.Halevy_EfficientQueryReformulation_SIGMOD_2004,
	Abstract = {Peer data management systems (PDMS) offer a flexible architecture for decentralized
	 data sharing. In a PDMS, every peer is associated with a schema that
	 represents the peer's domain of interest, and semantic relationships
	 between peers are provided locally between pairs (or small sets) of
	 peers. By traversing semantic paths of mappings, a query over one peer
	 can obtain relevant data from any reachable peer in the network.
	 Semantic paths are traversed by reformulating queries at a peer into
	 queries on its neighbors.Naively following semantic paths is highly
	 inefficient in practice. We describe several techniques for optimizing the
	 reformulation process in a PDMS and validate their effectiveness
	 using real-life data sets. In particular, we develop techniques for
	 pruning paths in the reformulation process and for minimizing the
	 reformulated queries as they are created. In addition, we consider
	 the effect of the strategy we use to search through the space of
	 reformulations. Finally, we show that pre-computing semantic paths
	 in a PDMS can greatly improve the efficiency of the reformulation
	 process. Together, all of these techniques form a basis for scalable
	 query reformulation in PDMS.To enable our optimizations, we developed
	 practical algorithms, of independent interest, for checking containment
	 and minimization of XML queries, and for composing XML mappings.},
	Author = {Tatarinov, Igor and Halevy, Alon},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1007568.1007629},
	Isbn = {1-58113-859-8},
	Keywords = {XML XQuery rewriting optimization query evaluation},
	Location = {Paris, France},
	Pages = {539--550},
	Pdf = {QueryEvaluation/XML/XQuery/Tatarinov.Halevy_EfficientQueryReformulation_SIGMOD_2004.pdf},
	Publisher = {ACM Press},
	Title = {{Efficient Query Reformulation in peer Data Management Systems}},
	Url = {http://data.cs.washington.edu/papers/piazza-sigmod2004.pdf},
	Year = {2004}}

@book{Tennison_XSLTandXPath_2001,
	Abstract = {Extensible Stylesheet Language Transformations, along with the XML Path
	 Language, give you the power to transform XML documents into HTML
	 documents, or to other XML documents that you can use in Web-based
	 applications. But how do you implement XSLT in the real world? This book
	 provides the answers. Covering everything from reformatting numbers
	 to creating dynamic XSLT applications, XSLT expert Jeni Tennison
	 delivers a wealth of ready-to-use utility templates and practical XSLT
	 solutions -- everything you need to jump-start XSLT development.},
	Author = {Tennison, Jeni},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XSLT XPath query languages},
	Owner = {Tim Furche},
	Publisher = {John Wiley},
	Title = {{XSLT and XPath On The Edge}},
	Year = {2001}}

@inproceedings{Theobald.Weikum_XXLSearchEngine_SIGMOD_2002,
	Author = {Theobald, Anja and Weikum, Gerhard},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/564691.564768},
	Isbn = {1-58113-497-5},
	Keywords = {XML ranking IR information retrieval query languages},
	Location = {Madison, Wisconsin},
	Pages = {615--615},
	Publisher = {ACM Press},
	Title = {{The XXL Search Engine: Ranked Retrieval of XML Data using Indexes and Ontologies}},
	Year = {2002}}

@inproceedings{Tozawa_TowardsStaticType_DocEng_2001,
	Author = {Tozawa, Akihiko},
	Booktitle = {Proc. ACM Symposium on Document Engineering},
	Conference-Abbr = {DocEng},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/502187.502191},
	Isbn = {1-58113-432-0},
	Keywords = {XML XSLT type checking query languages},
	Location = {Atlanta, Georgia, USA},
	Pages = {18--27},
	Publisher = {ACM Press},
	Title = {{Towards Static Type Checking for XSLT}},
	Url = {http://wam.inrialpes.fr/people/roisin/mw2004/Tozawa2001.pdf},
	Year = {2001}}

@inproceedings{Villard.Layaida_IncrementalXSLTTransformation_WWW_2002,
	Abstract = {In this paper, we present an incremental transformation framework
	 called incXSLT. This framework has been experimented for the XSLT
	 language defined at the World Wide Web Consortium. For the currently
	 available tools, designing the XML content and the transformation
	 sheets is an inefficient, a tedious and an error prone experience.
	 Incremental transformation processors such as incXSLT represent a
	 better alternative to help in the design of both the content and the
	 transformation sheets. We believe that such frameworks are a first step
	 toward fully interactive transformation-based authoring environments.},
	Author = {Villard, Lionel and Laya{\"\i}da, Nabil},
	Booktitle = WWW,
	Conference-Abbr = {WWW},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/511446.511508},
	Isbn = {1-58113-449-5},
	Keywords = {XML XSLT incremental query evaluation languages},
	Location = {Honolulu, Hawaii, USA},
	Pages = {474--485},
	Pdf = {QueryEvaluation/XML/XSLT/Villard.Layaida_IncrementalXSLTTransformation_WWW_2002.pdf},
	Publisher = {ACM Press},
	Title = {{An Incremental XSLT Transformation Processor for XML Document Manipulation}},
	Url = {http://www.research.ibm.com/people/v/villard/Papiers/incXSLT.pdf},
	Year = {2002}}

@inproceedings{Walsh.RDF-Twig-accessing-.2003,
	Author = {Walsh, Norman},
	Booktitle = {Proc. Extreme Markup Languages},
	Conference-Abbr = {EML},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Title = {{RDF Twig: accessing RDF graphs in XSLT}},
	Url = {http://www.mulberrytech.com/Extreme/Proceedings/xslfo-pdf/2003/Walsh01/EML2003Walsh01.pdf},
	Year = {2003}}

@book{Walsh.Muellner_DocBook-DefinitiveGuide_1999,
	Abstract = {DocBook is a Document Type Definition (DTD) for use with XML (the Extensible
	 Markup Language) and SGML (the Standard Generalized Markup Language).
	 DocBook lets authors in technical groups exchange and reuse technical
	 information. This book contains an introduction to SGML, XML, and the
	 DocBook DTD, plus the complete reference information for DocBook.},
	Author = {Walsh, Norman and Muellner, Leonard},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Owner = {Tim Furche},
	Publisher = {O?Reilly},
	Title = {{DocBook: The Definitive Guide}},
	Url = {http://www.oreilly.com/catalog/docbook/},
	Year = {1999}}

@inproceedings{Wan.Dobbie_MiningAssociationRules_CRPIT_2004,
	Abstract = {In recent years XML has became very popular for
	 representing semistructured data and a standard for data exchange
	 over the web. Mining XML data from the web is becoming increasingly
	 important. Several encouraging attempts at developing methods for mining
	 XML data have been proposed. However, efficiency and simplicity are
	 still a barrier for further development. Normally, pre-processing or
	 post-processing are required for mining XML data, such as transforming the data
	 from XML format to relational format. In this paper, we show that
	 extracting association rules from XML documents without any pre-processing
	 or post-processing using XQuery is possible and analyze the XQuery
	 implementation of the well-known Apriori algorithm. In addition,
	 we suggest features that need to be added into XQuery in order to
	 make the implementation of the Apriori algorithm more efficient.},
	Author = {Wan, Jacky W. W. and Dobbie, Gillian},
	Booktitle = {Proc. Workshop on Australasian Information Security, Data Mining Web Intelligence, and Software Internationalisation},
	Conference-Abbr = {CRPIT},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XQuery mining assocation rules},
	Location = {Dunedin, New Zealand},
	Pages = {169--174},
	Publisher = {Australian Computer Society, Inc.},
	Title = {{Mining Association Rules from XML data using XQuery}},
	Url = {http://crpit.com/confpapers/CRPITV32Wan.pdf},
	Year = {2004}}

@inproceedings{Waworuntu.Bailey_XSLTGen-SystemAutomatically_ER_2004,
	Abstract = {XML is rapidly emerging as a
	 dominant standard for representing and exchanging information. The
	 ability to transform and present data in XML is crucial and XSLT
	 (Extensible stylesheet transformations) is a relatively recent programming
	 language, specially designed to support this activity. Despite its
	 utility, however, XSLT is widely considered a difficult language to
	 learn. In this paper, we present a novel system called XSLTGen, an
	 automatic XSLT Generator. This system automatically generates an XSLT
	 program, given a source XML document and a desired output HTML or XML
	 document. It allows users to become familiar with and learn XSLT
	 programs, based solely on their knowledge of XML or HTML. Our method for
	 automatically generating XSLT transformations is based on the use of semantic
	 mappings between the input and output documents. We show how such
	 mappings can be first discovered and then employed to create XSLT
	 programs. The results of our experiments show that XSLTGen works
	 well with a number of different varieties of XML and HTML documents.},
	Author = {Waworuntu, Stella and Bailey, James},
	Booktitle = {Proc. Intl. Conf. on Conceptual Modeling},
	Conference-Abbr = {ER},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {XML XSLT generation semantic query languages},
	Owner = {Tim Furche},
	Title = {{XSLTGen: A System for Automatically Generating XML Transformations via Semantic Mappings}},
	Url = {http://www.cs.mu.oz.au/~jbailey/papers/xsltgen.ps},
	Year = {2004}}

@article{Wiegand_InvestigatingXQueryQuerying_SIGMOD_2002,
	Abstract = {In addition to facilitating querying over the Web, XML query
	 languages may provide high level constructs for useful facilities
	 in traditional DBMSs that do not currently exist. In particular,
	 current DBMS query languages do not allow querying across database
	 object types to yield heterogeneous results. This paper motivates the
	 usefulness of heterogeneous querying in traditional DBMSs and investigates
	 XQuery, an emerging standard for XML query languages, to express
	 such queries. The usefulness of querying and storing heterogeneous
	 types is also applied to XML data within a Web information system.},
	Author = {Wiegand, Nancy},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/565117.565122},
	Issn = {0163-5808},
	Journal = {SIGMOD Record},
	Journal-Abbr = {SIGMOD},
	Keywords = {XML XQuery relational databases heterogenity},
	Number = {2},
	Pages = {28--33},
	Pdf = {QueryEvaluation/XML/XQuery/Wiegand_InvestigatingXQueryQuerying_SIGMOD_2002.pdf},
	Publisher = {ACM Press},
	Title = {{Investigating XQuery for Querying across Database Object Types}},
	Url = {http://portal.acm.org/citation.cfm?id=565122},
	Volume = {31},
	Year = {2002}}

@inproceedings{Wood_OnEquivalenceof_CL_2000,
	Author = {Wood, Peter T.},
	Booktitle = {Proc. Intl. Conf. on Computational Logic},
	Conference-Abbr = {CL},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Isbn = {3-540-67797-6},
	Keywords = {XML XPath query containment fragment equivalence},
	Pages = {1152--1166},
	Publisher = {Springer-Verlag},
	Title = {{On the Equivalence of XML Patterns}},
	Year = {2000}}

@inproceedings{Zaniolo_DatabaseLanguageGEM_SIGMOD_1983,
	Abstract = {GEM (bn acronym for General Entity Manipulator) is a
	 general-purpose query and update language for the DSIS data model,
	 which is a semantic data model of the Entity-Relationship type. GEM
	 is designed as an easy-to-use extension of the relational language
	 QUEL. providing supporr for. the notions of entities with surrogates,
	 aggregation, generalization, null values, and set-valued attributes.},
	Author = {Zaniolo, Carlo},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {Query languages GEM path expressions QUEL},
	Owner = {Tim Furche},
	Pdf = {QueryEvaluation/Languages/Zaniolo_DatabaseLanguageGEM_SIGMOD_1983.pdf},
	Title = {{The Database Language GEM}},
	Url = {http://www.cs.ucla.edu/%7Ezaniolo/papers/sigmod83.pdf},
	Year = {1983}}

@inproceedings{Zhang.Dimitrova.ea_Rainbow-multi-XQueryOptimization_SIGMOD_2003,
	Author = {Zhang, Xin and Dimitrova, Katica and Wang, Ling and Sayed, Maged El and Murphy, Brian and Pielech, Bradford and Mulchandani, Mukesh and Ding, Luping and Rundensteiner, Elke A.},
	Booktitle = SIGMOD,
	Conference-Abbr = {SIGMOD},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Doi = {http://doi.acm.org/10.1145/872757.872861},
	Isbn = {1-58113-634-X},
	Keywords = {XML XQuery view-based query optimization evalution processing},
	Location = {San Diego, California},
	Pages = {671--671},
	Pdf = {QueryEvaluation/XML/XQuery/Zhang.Dimitrova.ea_Rainbow-multi-XQueryOptimization_SIGMOD_2003.pdf},
	Publisher = {ACM Press},
	Title = {{Rainbow: multi-XQuery Optimization using Materialized XML Views}},
	Url = {http://www.cs.wpi.edu/~lisading/docs/demo.pdf},
	Year = {2003}}

@inproceedings{Zloof_QueryByExample_AFIPS_1975,
	Author = {Zloof, Mosh{\'e} M.},
	Booktitle = {AFIPS National Computer Conference},
	Conference-Abbr = {AFIPS},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Keywords = {QBE, relational, query languages},
	Owner = {Tim Furche},
	Title = {{Query By Example}},
	Year = {1975}}

@book{ODMG_ObjectDataStandard_2000,
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Editor = {Cattell, R. G. G. and Barry, Douglas K. and Berler, Mark and Eastman, Jeff and Jordan, David and Russell, Craig and Schadow, Olaf and Stanienda, Torsten and Velez, Fernando},
	Keywords = {OQL, ODMG, standard, object-oriented database, query languages},
	Owner = {Tim Furche},
	Publisher = {Morgan Kaufmann},
	Title = {{Object Data Standard: ODMG 3.0}},
	Year = {2000}}

@book{ParkHunting.XML-Topic-Maps-Creating.2002,
	Address = {Boston, MA, USA},
	Date-Added = {2007-09-20 11:00:48 +0200},
	Date-Modified = {2007-09-20 11:00:48 +0200},
	Editor = {Park, Jack and Hunting, Sam},
	Isbn = {0201749602},
	Publisher = {Addison-Wesley Longman Publishing Co., Inc.},
	Title = {{XML Topic Maps: Creating and Using Topic Maps for the Web}},
	Year = {2002}}

@comment{BibDesk Static Groups{
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<array>
	<dict>
		<key>group name</key>
		<string>Dissertation</string>
		<key>keys</key>
		<string>Berger2006Vorfuhrung-von-Xcerpt-und-visXcerpt,Bry2007GRDDLing-with-Xcerpt,Berger2007Completing-Queries:-Rewriting-of-Incomplete-Web-Queries</string>
	</dict>
	<dict>
		<key>group name</key>
		<string>STOPPED AT QUERY EVALUATION</string>
		<key>keys</key>
		<string></string>
	</dict>
</array>
</plist>
}}

@comment{BibDesk Smart Groups{
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<array>
	<dict>
		<key>conditions</key>
		<array>
			<dict>
				<key>comparison</key>
				<integer>2</integer>
				<key>key</key>
				<string>Keywords</string>
				<key>value</key>
				<string>identity</string>
				<key>version</key>
				<string>1</string>
			</dict>
			<dict>
				<key>comparison</key>
				<integer>2</integer>
				<key>key</key>
				<string>Keywords</string>
				<key>value</key>
				<string>duplicate</string>
				<key>version</key>
				<string>1</string>
			</dict>
		</array>
		<key>conjunction</key>
		<integer>1</integer>
		<key>group name</key>
		<string>Identity, Multirelations, etc.</string>
	</dict>
</array>
</plist>
}}
